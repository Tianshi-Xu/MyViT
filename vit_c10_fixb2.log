2024-03-31 15:29:52,358 - train - INFO - Training with a single process on 1 GPUs.
2024-03-31 15:30:07,958 - train - INFO - Model vit_7_4_32 created, param count:3717016
2024-03-31 15:30:08,002 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-03-31 15:30:08,002 - train - INFO - Scheduled epochs: 310
2024-03-31 15:30:10,351 - train - INFO - Verifying teacher model
2024-03-31 15:30:11,148 - train - INFO - Test: [   0/78]  Time: 0.796 (0.796)  Loss:  0.3445 (0.3445)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-03-31 15:30:11,715 - train - INFO - Test: [  50/78]  Time: 0.011 (0.027)  Loss:  0.2869 (0.3467)  Acc@1: 96.0938 (93.3211)  Acc@5: 100.0000 (99.6630)
2024-03-31 15:30:12,145 - train - INFO - Test: [  78/78]  Time: 0.109 (0.023)  Loss:  0.3740 (0.3449)  Acc@1: 93.7500 (93.5400)  Acc@5: 100.0000 (99.7600)
2024-03-31 15:30:12,145 - train - INFO - Verifying initial model
2024-03-31 15:30:14,498 - train - INFO - Test: [   0/78]  Time: 2.352 (2.352)  Loss:  2.1738 (2.1738)  Acc@1: 27.3438 (27.3438)  Acc@5: 77.3438 (77.3438)
2024-03-31 15:32:26,068 - train - INFO - Test: [  50/78]  Time: 2.637 (2.626)  Loss:  2.1816 (2.1806)  Acc@1: 20.3125 (25.9344)  Acc@5: 73.4375 (74.4945)
2024-03-31 15:33:42,484 - train - INFO - Test: [  78/78]  Time: 2.312 (2.662)  Loss:  2.1289 (2.1795)  Acc@1: 37.5000 (26.0900)  Acc@5: 75.0000 (74.8000)
2024-03-31 15:33:45,219 - train - INFO - Train: 0 [   0/390 (  0%)]  Loss:  2.228590 (2.2286)  Time: 2.732s,   46.86/s  (2.732s,   46.86/s)  LR: 1.000e-05  Data: 0.568 (0.568)
2024-03-31 15:35:58,255 - train - INFO - Train: 0 [  50/390 ( 13%)]  Loss:  2.242666 (2.2495)  Time: 2.447s,   52.31/s  (2.662s,   48.08/s)  LR: 1.000e-05  Data: 0.003 (0.017)
2024-03-31 15:38:12,207 - train - INFO - Train: 0 [ 100/390 ( 26%)]  Loss:  2.196083 (2.2364)  Time: 2.587s,   49.48/s  (2.670s,   47.93/s)  LR: 1.000e-05  Data: 0.013 (0.012)
