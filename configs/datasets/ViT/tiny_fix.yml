dataset: torch/image_folder
num_classes: 200
train_split: train
val_split: valid
img_size: 64
mean:
    - 0.480
    - 0.448
    - 0.397
std:
    - 0.272
    - 0.265
    - 0.274
crop_pct: 0.9
scale:
    - 0.08
    - 1.0
interpolation: bicubic
train_interpolation: random
aa: rand-m9-mstd0.5-inc1
mixup: 0.8
mixup_off_epoch: 0
mixup_prob: 1.0
mixup_mode: batch
mixup_switch_prob: 0.5
cutmix: 1.0
reprob: 0.25
remode: pixel
amp: True
batch_size: 128
lr: 0.0005
min_lr: 0.00001
sched: cosine
weight_decay: 5e-2
epochs: 300
cooldown_epochs: 10
warmup_epochs: 10
warmup_lr: 0.000001
opt: adamw
smoothing: 0.1
workers: 4

use_kd: true
kd_alpha: 4
seed: 3407
checkpoint_hist: 3
finetune: False
lasso_alpha: 0
tau: 1.0
budget: 0.15
fix_blocksize: 1
# 2/4/8/16, delta_z, b8
# fix_blocksize_list: 16,16,2,2,8,2,16,16,4,16,16,16,2,16,16,16,16,16,2,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,1
# b4
# fix_blocksize_list: 16,16,2,2,2,2,2,16,2,2,2,16,2,2,2,16,2,16,2,16,8,8,4,16,16,8,2,16,16,16,2,16,16,16,16,16,1
# b2
# fix_blocksize_list: 8,8,1,1,1,1,1,8,1,1,1,8,1,1,1,8,1,1,1,8,8,4,4,8,8,8,1,8,8,8,1,8,8,8,8,8,1
# b2 1/2/4
# fix_blocksize_list: 4,4,1,1,4,1,4,4,1,1,4,4,1,1,1,4,1,2,1,4,4,4,4,4,4,4,1,4,4,4,1,4,4,4,4,4,1
# b2 1/2/4/8, b2>50%
# fix_blocksize_list: 8,2,1,1,2,1,2,8,1,2,2,8,1,2,2,8,1,2,1,8,2,2,2,8,2,2,2,8,8,2,1,8,8,2,2,2,1
# b2 1/2/4, b4<25%
# fix_blocksize_list: 4,2,1,1,2,1,2,4,2,1,2,4,2,1,2,4,2,2,1,2,2,2,2,4,4,2,2,4,4,2,1,2,4,2,2,2,1
# b2 1/2/4/8, b2>75%
# fix_blocksize_list: 8,2,1,1,2,2,2,8,2,2,2,8,1,2,2,8,2,2,1,2,2,2,2,2,2,2,2,2,2,2,2,2,8,2,2,2,2
# hawq-v3, b8
# fix_blocksize_list: 16,16,16,1,16,16,16,16,16,1,16,16,16,1,16,16,16,1,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,1
# b4
# fix_blocksize_list: 16,16,4,1,16,1,16,16,16,1,16,16,2,1,16,16,16,1,16,16,16,1,16,16,16,1,16,16,16,1,1,16,16,16,16,1,1
# b8, delta_w_fim, test
# fix_blocksize_list: 16,8,4,2,16,2,4,16,4,2,16,16,4,2,16,16,8,2,16,16,16,8,16,16,16,16,16,16,16,8,16,16,16,16,16,16,1
# b8, delta_w_2_fim, train
# fix_blocksize_list: 16,8,4,2,16,2,4,16,8,2,8,16,8,2,16,16,8,2,16,16,16,4,16,16,16,8,16,16,16,8,8,16,16,16,16,16,1
# b4, 同上
# fix_blocksize_list: 16,4,2,2,4,1,2,4,2,1,4,8,2,1,8,16,4,2,8,16,4,2,16,16,16,2,4,16,8,4,4,16,16,16,4,16,2
# b2, 同上
# fix_blocksize_list: 16,2,1,1,2,1,1,2,1,1,2,4,1,1,4,4,2,1,4,4,2,1,4,4,4,1,2,4,2,2,2,4,8,4,2,8,1
# b8, baseline,正常初始化W'，其余一致
fix_blocksize_list: 16,16,16,1,16,1,16,16,16,1,16,16,16,1,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,1
log_name: vit_tiny_b8_base
teacher: vit_9_12_64
teacher_checkpoint: /home/xts/code/njeans/MyViT/pretrained/vit_tiny.pth.tar
# resume: "/home/xts/code/njeans/MyViT/output/train/20240423-145403-vit_9_12_64-64/last.pth.tar"
initial_checkpoint: /home/xts/code/njeans/MyViT/pretrained/vit_tiny.pth.tar
# b8
# resume: "/home/xts/code/njeans/MyViT/output/train/20240404-093530-vit_9_12_64-64/last.pth.tar"
# b4
# resume: "/home/xts/code/njeans/MyViT/output/train/20240404-093451-vit_9_12_64-64/last.pth.tar"
# b2
# resume: "/home/xts/code/njeans/MyViT/output/train/20240404-093326-vit_9_12_64-64/last.pth.tar"