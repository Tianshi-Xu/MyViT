2024-03-31 15:27:35,937 - train - INFO - Training with a single process on 1 GPUs.
2024-03-31 15:27:47,777 - train - INFO - Model vit_7_4_32 created, param count:3717016
2024-03-31 15:27:47,798 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-03-31 15:27:47,799 - train - INFO - Scheduled epochs: 310
2024-03-31 15:27:49,548 - train - INFO - Verifying teacher model
2024-03-31 15:27:50,244 - train - INFO - Test: [   0/78]  Time: 0.695 (0.695)  Loss:  0.3445 (0.3445)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-03-31 15:27:50,930 - train - INFO - Test: [  50/78]  Time: 0.008 (0.027)  Loss:  0.2869 (0.3467)  Acc@1: 96.0938 (93.3211)  Acc@5: 100.0000 (99.6630)
2024-03-31 15:27:51,267 - train - INFO - Test: [  78/78]  Time: 0.080 (0.022)  Loss:  0.3740 (0.3449)  Acc@1: 93.7500 (93.5400)  Acc@5: 100.0000 (99.7600)
2024-03-31 15:27:51,267 - train - INFO - Verifying initial model
2024-03-31 15:27:52,362 - train - INFO - Test: [   0/78]  Time: 1.094 (1.094)  Loss:  2.2852 (2.2852)  Acc@1: 15.6250 (15.6250)  Acc@5: 62.5000 (62.5000)
2024-03-31 15:28:44,652 - train - INFO - Test: [  50/78]  Time: 0.951 (1.047)  Loss:  2.2852 (2.3002)  Acc@1: 21.0938 (13.4191)  Acc@5: 62.5000 (56.3879)
2024-03-31 15:29:14,368 - train - INFO - Test: [  78/78]  Time: 0.886 (1.052)  Loss:  2.2988 (2.3004)  Acc@1: 18.7500 (13.4900)  Acc@5: 56.2500 (56.2100)
2024-03-31 15:29:16,028 - train - INFO - Train: 0 [   0/390 (  0%)]  Loss:  2.305594 (2.3056)  Time: 1.656s,   77.29/s  (1.656s,   77.29/s)  LR: 1.000e-05  Data: 0.503 (0.503)
2024-03-31 15:30:31,468 - train - INFO - Train: 0 [  50/390 ( 13%)]  Loss:  2.306785 (2.3026)  Time: 1.497s,   85.50/s  (1.512s,   84.68/s)  LR: 1.000e-05  Data: 0.012 (0.016)
2024-03-31 15:31:55,786 - train - INFO - Train: 0 [ 100/390 ( 26%)]  Loss:  2.287663 (2.2986)  Time: 1.869s,   68.47/s  (1.598s,   80.10/s)  LR: 1.000e-05  Data: 0.004 (0.012)
2024-03-31 15:33:21,184 - train - INFO - Train: 0 [ 150/390 ( 39%)]  Loss:  2.289674 (2.2960)  Time: 1.664s,   76.94/s  (1.634s,   78.31/s)  LR: 1.000e-05  Data: 0.014 (0.010)
2024-03-31 15:34:43,854 - train - INFO - Train: 0 [ 200/390 ( 51%)]  Loss:  2.295268 (2.2934)  Time: 1.651s,   77.53/s  (1.639s,   78.09/s)  LR: 1.000e-05  Data: 0.003 (0.010)
2024-03-31 15:36:05,239 - train - INFO - Train: 0 [ 250/390 ( 64%)]  Loss:  2.275765 (2.2911)  Time: 1.591s,   80.47/s  (1.637s,   78.20/s)  LR: 1.000e-05  Data: 0.008 (0.009)
2024-03-31 15:37:30,141 - train - INFO - Train: 0 [ 300/390 ( 77%)]  Loss:  2.284518 (2.2888)  Time: 1.573s,   81.39/s  (1.647s,   77.72/s)  LR: 1.000e-05  Data: 0.008 (0.009)
2024-03-31 15:38:52,189 - train - INFO - Train: 0 [ 350/390 ( 90%)]  Loss:  2.262753 (2.2866)  Time: 1.500s,   85.34/s  (1.646s,   77.76/s)  LR: 1.000e-05  Data: 0.004 (0.009)
2024-03-31 15:39:56,929 - train - INFO - Train: 0 [ 389/390 (100%)]  Loss:  2.250454 (2.2850)  Time: 1.656s,   77.30/s  (1.648s,   77.69/s)  LR: 1.000e-05  Data: 0.000 (0.009)
2024-03-31 15:39:58,463 - train - INFO - Test: [   0/78]  Time: 1.530 (1.530)  Loss:  2.1699 (2.1699)  Acc@1: 26.5625 (26.5625)  Acc@5: 78.9062 (78.9062)
2024-03-31 15:41:16,151 - train - INFO - Test: [  50/78]  Time: 1.965 (1.553)  Loss:  2.1641 (2.1851)  Acc@1: 27.3438 (22.7328)  Acc@5: 82.0312 (77.6195)
2024-03-31 15:42:01,209 - train - INFO - Test: [  78/78]  Time: 1.561 (1.573)  Loss:  2.1172 (2.1825)  Acc@1: 25.0000 (22.7600)  Acc@5: 93.7500 (78.0200)
2024-03-31 15:42:03,001 - train - INFO - Train: 1 [   0/390 (  0%)]  Loss:  2.272400 (2.2724)  Time: 1.643s,   77.90/s  (1.643s,   77.90/s)  LR: 6.400e-05  Data: 0.116 (0.116)
2024-03-31 15:43:26,475 - train - INFO - Train: 1 [  50/390 ( 13%)]  Loss:  2.254670 (2.2635)  Time: 2.061s,   62.09/s  (1.669s,   76.69/s)  LR: 6.400e-05  Data: 0.009 (0.008)
2024-03-31 15:44:49,617 - train - INFO - Train: 1 [ 100/390 ( 26%)]  Loss:  2.271530 (2.2572)  Time: 1.629s,   78.55/s  (1.666s,   76.83/s)  LR: 6.400e-05  Data: 0.004 (0.009)
