2024-04-01 23:21:46,431 - train - INFO - Training with a single process on 1 GPUs.
2024-04-01 23:22:08,211 - train - INFO - Model vit_7_4_32 created, param count:3716931
2024-04-01 23:22:08,260 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-04-01 23:22:08,260 - train - INFO - Scheduled epochs: 160
2024-04-01 23:22:10,486 - train - INFO - Verifying teacher model
2024-04-01 23:22:11,907 - train - INFO - Test: [   0/39]  Time: 1.402 (1.402)  Loss:  0.3433 (0.3433)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-01 23:22:13,253 - train - INFO - Test: [  39/39]  Time: 0.112 (0.069)  Loss:  0.3740 (0.3449)  Acc@1: 93.7500 (93.5400)  Acc@5: 100.0000 (99.7600)
2024-04-01 23:22:13,254 - train - INFO - Verifying initial model
2024-04-01 23:22:15,298 - train - INFO - Test: [   0/39]  Time: 2.043 (2.043)  Loss:  2.0332 (2.0332)  Acc@1: 27.7344 (27.7344)  Acc@5: 71.4844 (71.4844)
2024-04-01 23:23:27,823 - train - INFO - Test: [  39/39]  Time: 1.828 (1.864)  Loss:  1.8789 (2.0274)  Acc@1: 37.5000 (28.2900)  Acc@5: 81.2500 (73.7800)
2024-04-01 23:23:32,045 - train - INFO - Train: 0 [   0/195 (  0%)]  Loss:  2.380071 (2.3801)  Time: 4.204s,   60.90/s  (4.204s,   60.90/s)  LR: 1.000e-05  Data: 0.966 (0.966)
2024-04-01 23:26:03,387 - train - INFO - Train: 0 [  50/195 ( 26%)]  Loss:  2.360173 (2.3525)  Time: 3.095s,   82.71/s  (3.050s,   83.94/s)  LR: 1.000e-05  Data: 0.018 (0.036)
2024-04-01 23:28:32,138 - train - INFO - Train: 0 [ 100/195 ( 52%)]  Loss:  2.308604 (2.3379)  Time: 2.695s,   94.98/s  (3.013s,   84.97/s)  LR: 1.000e-05  Data: 0.028 (0.026)
2024-04-01 23:31:02,290 - train - INFO - Train: 0 [ 150/195 ( 77%)]  Loss:  2.253953 (2.3260)  Time: 2.907s,   88.07/s  (3.010s,   85.06/s)  LR: 1.000e-05  Data: 0.014 (0.022)
2024-04-01 23:33:13,657 - train - INFO - Train: 0 [ 194/195 (100%)]  Loss:  2.266334 (2.3172)  Time: 2.928s,   87.42/s  (3.004s,   85.22/s)  LR: 1.000e-05  Data: 0.000 (0.020)
2024-04-01 23:33:13,666 - train - INFO - True
2024-04-01 23:33:13,745 - train - INFO - alphas:tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,745 - train - INFO - True
2024-04-01 23:33:13,746 - train - INFO - alphas:tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,746 - train - INFO - True
2024-04-01 23:33:13,747 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,747 - train - INFO - True
2024-04-01 23:33:13,748 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,748 - train - INFO - True
2024-04-01 23:33:13,749 - train - INFO - alphas:tensor([0.5006, 0.4994], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,749 - train - INFO - True
2024-04-01 23:33:13,750 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,750 - train - INFO - True
2024-04-01 23:33:13,751 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,766 - train - INFO - True
2024-04-01 23:33:13,767 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,767 - train - INFO - True
2024-04-01 23:33:13,768 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,768 - train - INFO - True
2024-04-01 23:33:13,769 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,769 - train - INFO - True
2024-04-01 23:33:13,770 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,770 - train - INFO - True
2024-04-01 23:33:13,771 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,771 - train - INFO - True
2024-04-01 23:33:13,772 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,772 - train - INFO - True
2024-04-01 23:33:13,774 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,774 - train - INFO - True
2024-04-01 23:33:13,779 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,780 - train - INFO - True
2024-04-01 23:33:13,781 - train - INFO - alphas:tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,781 - train - INFO - True
2024-04-01 23:33:13,782 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,782 - train - INFO - True
2024-04-01 23:33:13,783 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,784 - train - INFO - True
2024-04-01 23:33:13,785 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,785 - train - INFO - True
2024-04-01 23:33:13,800 - train - INFO - alphas:tensor([0.4991, 0.5009], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,801 - train - INFO - True
2024-04-01 23:33:13,802 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,802 - train - INFO - True
2024-04-01 23:33:13,803 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,803 - train - INFO - True
2024-04-01 23:33:13,804 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,804 - train - INFO - True
2024-04-01 23:33:13,805 - train - INFO - alphas:tensor([0.5002, 0.4998], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,805 - train - INFO - True
2024-04-01 23:33:13,806 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,806 - train - INFO - True
2024-04-01 23:33:13,807 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,807 - train - INFO - True
2024-04-01 23:33:13,808 - train - INFO - alphas:tensor([0.4998, 0.5002], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,809 - train - INFO - True
2024-04-01 23:33:13,809 - train - INFO - alphas:tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,810 - train - INFO - True
2024-04-01 23:33:13,811 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:33:13,812 - train - INFO - avg block size:3.0689655172413794
2024-04-01 23:33:15,774 - train - INFO - Test: [   0/39]  Time: 1.949 (1.949)  Loss:  1.8232 (1.8232)  Acc@1: 50.7812 (50.7812)  Acc@5: 90.2344 (90.2344)
2024-04-01 23:34:28,619 - train - INFO - Test: [  39/39]  Time: 1.698 (1.870)  Loss:  1.7266 (1.8042)  Acc@1: 62.5000 (48.6000)  Acc@5: 93.7500 (91.3100)
2024-04-01 23:34:32,397 - train - INFO - Train: 1 [   0/195 (  0%)]  Loss:  2.298353 (2.2984)  Time: 3.533s,   72.45/s  (3.533s,   72.45/s)  LR: 6.400e-05  Data: 0.402 (0.402)
2024-04-01 23:37:02,796 - train - INFO - Train: 1 [  50/195 ( 26%)]  Loss:  2.300644 (2.2397)  Time: 2.969s,   86.22/s  (3.018s,   84.82/s)  LR: 6.400e-05  Data: 0.019 (0.024)
2024-04-01 23:39:28,868 - train - INFO - Train: 1 [ 100/195 ( 52%)]  Loss:  2.091336 (2.1820)  Time: 3.091s,   82.83/s  (2.970s,   86.19/s)  LR: 6.400e-05  Data: 0.018 (0.019)
2024-04-01 23:41:55,840 - train - INFO - Train: 1 [ 150/195 ( 77%)]  Loss:  1.960099 (2.1572)  Time: 3.157s,   81.10/s  (2.960s,   86.48/s)  LR: 6.400e-05  Data: 0.014 (0.017)
2024-04-01 23:44:07,205 - train - INFO - Train: 1 [ 194/195 (100%)]  Loss:  1.956577 (2.1326)  Time: 2.970s,   86.18/s  (2.966s,   86.32/s)  LR: 6.400e-05  Data: 0.000 (0.016)
2024-04-01 23:44:07,210 - train - INFO - True
2024-04-01 23:44:07,212 - train - INFO - alphas:tensor([0.5028, 0.4972], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,213 - train - INFO - True
2024-04-01 23:44:07,213 - train - INFO - alphas:tensor([0.5065, 0.4935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,214 - train - INFO - True
2024-04-01 23:44:07,215 - train - INFO - alphas:tensor([0.5091, 0.4909], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,215 - train - INFO - True
2024-04-01 23:44:07,225 - train - INFO - alphas:tensor([0.5102, 0.4898], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,225 - train - INFO - True
2024-04-01 23:44:07,226 - train - INFO - alphas:tensor([0.5087, 0.4913], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,227 - train - INFO - True
2024-04-01 23:44:07,227 - train - INFO - alphas:tensor([0.5084, 0.4916], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,228 - train - INFO - True
2024-04-01 23:44:07,228 - train - INFO - alphas:tensor([0.5082, 0.4918], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,229 - train - INFO - True
2024-04-01 23:44:07,229 - train - INFO - alphas:tensor([0.5083, 0.4917], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,230 - train - INFO - True
2024-04-01 23:44:07,231 - train - INFO - alphas:tensor([0.5085, 0.4915], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,231 - train - INFO - True
2024-04-01 23:44:07,232 - train - INFO - alphas:tensor([0.5078, 0.4922], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,233 - train - INFO - True
2024-04-01 23:44:07,233 - train - INFO - alphas:tensor([0.5076, 0.4924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,234 - train - INFO - True
2024-04-01 23:44:07,234 - train - INFO - alphas:tensor([0.5083, 0.4917], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,235 - train - INFO - True
2024-04-01 23:44:07,240 - train - INFO - alphas:tensor([0.5077, 0.4923], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,240 - train - INFO - True
2024-04-01 23:44:07,241 - train - INFO - alphas:tensor([0.5070, 0.4930], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,242 - train - INFO - True
2024-04-01 23:44:07,242 - train - INFO - alphas:tensor([0.5079, 0.4921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,243 - train - INFO - True
2024-04-01 23:44:07,243 - train - INFO - alphas:tensor([0.5057, 0.4943], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,244 - train - INFO - True
2024-04-01 23:44:07,244 - train - INFO - alphas:tensor([0.5076, 0.4924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,245 - train - INFO - True
2024-04-01 23:44:07,245 - train - INFO - alphas:tensor([0.5065, 0.4935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,246 - train - INFO - True
2024-04-01 23:44:07,246 - train - INFO - alphas:tensor([0.5056, 0.4944], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,247 - train - INFO - True
2024-04-01 23:44:07,247 - train - INFO - alphas:tensor([0.5005, 0.4995], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,248 - train - INFO - True
2024-04-01 23:44:07,255 - train - INFO - alphas:tensor([0.5065, 0.4935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,255 - train - INFO - True
2024-04-01 23:44:07,257 - train - INFO - alphas:tensor([0.5059, 0.4941], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,257 - train - INFO - True
2024-04-01 23:44:07,258 - train - INFO - alphas:tensor([0.5047, 0.4953], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,258 - train - INFO - True
2024-04-01 23:44:07,259 - train - INFO - alphas:tensor([0.5049, 0.4951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,259 - train - INFO - True
2024-04-01 23:44:07,260 - train - INFO - alphas:tensor([0.5064, 0.4936], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,260 - train - INFO - True
2024-04-01 23:44:07,262 - train - INFO - alphas:tensor([0.5052, 0.4948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,262 - train - INFO - True
2024-04-01 23:44:07,268 - train - INFO - alphas:tensor([0.5026, 0.4974], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,269 - train - INFO - True
2024-04-01 23:44:07,270 - train - INFO - alphas:tensor([0.5046, 0.4954], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,270 - train - INFO - True
2024-04-01 23:44:07,271 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:44:07,271 - train - INFO - avg block size:1.0
2024-04-01 23:44:09,086 - train - INFO - Test: [   0/39]  Time: 1.810 (1.810)  Loss:  1.1504 (1.1504)  Acc@1: 67.5781 (67.5781)  Acc@5: 97.2656 (97.2656)
2024-04-01 23:45:20,096 - train - INFO - Test: [  39/39]  Time: 1.809 (1.821)  Loss:  1.1309 (1.1201)  Acc@1: 68.7500 (66.2200)  Acc@5: 100.0000 (97.1800)
2024-04-01 23:45:23,666 - train - INFO - Train: 2 [   0/195 (  0%)]  Loss:  2.085876 (2.0859)  Time: 3.230s,   79.25/s  (3.230s,   79.25/s)  LR: 1.180e-04  Data: 0.336 (0.336)
2024-04-01 23:47:49,267 - train - INFO - Train: 2 [  50/195 ( 26%)]  Loss:  1.881657 (2.0202)  Time: 2.720s,   94.12/s  (2.918s,   87.72/s)  LR: 1.180e-04  Data: 0.029 (0.020)
2024-04-01 23:50:16,715 - train - INFO - Train: 2 [ 100/195 ( 52%)]  Loss:  1.896598 (2.0026)  Time: 2.939s,   87.09/s  (2.933s,   87.27/s)  LR: 1.180e-04  Data: 0.020 (0.016)
2024-04-01 23:52:42,908 - train - INFO - Train: 2 [ 150/195 ( 77%)]  Loss:  1.695609 (1.9889)  Time: 2.936s,   87.21/s  (2.930s,   87.37/s)  LR: 1.180e-04  Data: 0.011 (0.017)
2024-04-01 23:54:53,333 - train - INFO - Train: 2 [ 194/195 (100%)]  Loss:  2.096915 (1.9753)  Time: 3.318s,   77.15/s  (2.938s,   87.14/s)  LR: 1.180e-04  Data: 0.000 (0.016)
2024-04-01 23:54:53,343 - train - INFO - True
2024-04-01 23:54:53,349 - train - INFO - alphas:tensor([0.5113, 0.4887], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,349 - train - INFO - True
2024-04-01 23:54:53,350 - train - INFO - alphas:tensor([0.5154, 0.4846], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,350 - train - INFO - True
2024-04-01 23:54:53,351 - train - INFO - alphas:tensor([0.5239, 0.4761], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,351 - train - INFO - True
2024-04-01 23:54:53,352 - train - INFO - alphas:tensor([0.5250, 0.4750], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,352 - train - INFO - True
2024-04-01 23:54:53,353 - train - INFO - alphas:tensor([0.5214, 0.4786], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,353 - train - INFO - True
2024-04-01 23:54:53,354 - train - INFO - alphas:tensor([0.5200, 0.4800], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,354 - train - INFO - True
2024-04-01 23:54:53,355 - train - INFO - alphas:tensor([0.5201, 0.4799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,367 - train - INFO - True
2024-04-01 23:54:53,367 - train - INFO - alphas:tensor([0.5202, 0.4798], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,368 - train - INFO - True
2024-04-01 23:54:53,368 - train - INFO - alphas:tensor([0.5232, 0.4768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,369 - train - INFO - True
2024-04-01 23:54:53,369 - train - INFO - alphas:tensor([0.5220, 0.4780], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,370 - train - INFO - True
2024-04-01 23:54:53,370 - train - INFO - alphas:tensor([0.5182, 0.4818], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,371 - train - INFO - True
2024-04-01 23:54:53,371 - train - INFO - alphas:tensor([0.5193, 0.4807], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,372 - train - INFO - True
2024-04-01 23:54:53,373 - train - INFO - alphas:tensor([0.5177, 0.4823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,373 - train - INFO - True
2024-04-01 23:54:53,374 - train - INFO - alphas:tensor([0.5163, 0.4837], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,374 - train - INFO - True
2024-04-01 23:54:53,375 - train - INFO - alphas:tensor([0.5185, 0.4815], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,376 - train - INFO - True
2024-04-01 23:54:53,386 - train - INFO - alphas:tensor([0.5177, 0.4823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,386 - train - INFO - True
2024-04-01 23:54:53,387 - train - INFO - alphas:tensor([0.5147, 0.4853], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,387 - train - INFO - True
2024-04-01 23:54:53,388 - train - INFO - alphas:tensor([0.5134, 0.4866], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,388 - train - INFO - True
2024-04-01 23:54:53,389 - train - INFO - alphas:tensor([0.5131, 0.4869], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,389 - train - INFO - True
2024-04-01 23:54:53,390 - train - INFO - alphas:tensor([0.5077, 0.4923], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,390 - train - INFO - True
2024-04-01 23:54:53,391 - train - INFO - alphas:tensor([0.5115, 0.4885], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,391 - train - INFO - True
2024-04-01 23:54:53,392 - train - INFO - alphas:tensor([0.5120, 0.4880], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,392 - train - INFO - True
2024-04-01 23:54:53,393 - train - INFO - alphas:tensor([0.5107, 0.4893], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,393 - train - INFO - True
2024-04-01 23:54:53,394 - train - INFO - alphas:tensor([0.5097, 0.4903], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,394 - train - INFO - True
2024-04-01 23:54:53,395 - train - INFO - alphas:tensor([0.5103, 0.4897], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,396 - train - INFO - True
2024-04-01 23:54:53,406 - train - INFO - alphas:tensor([0.5092, 0.4908], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,406 - train - INFO - True
2024-04-01 23:54:53,407 - train - INFO - alphas:tensor([0.5074, 0.4926], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,408 - train - INFO - True
2024-04-01 23:54:53,408 - train - INFO - alphas:tensor([0.5060, 0.4940], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,409 - train - INFO - True
2024-04-01 23:54:53,419 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 23:54:53,419 - train - INFO - avg block size:1.0
2024-04-01 23:54:55,362 - train - INFO - Test: [   0/39]  Time: 1.937 (1.937)  Loss:  0.8936 (0.8936)  Acc@1: 77.3438 (77.3438)  Acc@5: 98.0469 (98.0469)
2024-04-01 23:56:08,004 - train - INFO - Test: [  39/39]  Time: 1.794 (1.864)  Loss:  0.9648 (0.8509)  Acc@1: 68.7500 (76.0800)  Acc@5: 100.0000 (98.4200)
2024-04-01 23:56:11,569 - train - INFO - Train: 3 [   0/195 (  0%)]  Loss:  2.066248 (2.0662)  Time: 3.136s,   81.64/s  (3.136s,   81.64/s)  LR: 1.720e-04  Data: 0.314 (0.314)
2024-04-01 23:58:43,380 - train - INFO - Train: 3 [  50/195 ( 26%)]  Loss:  1.731433 (1.9205)  Time: 3.171s,   80.74/s  (3.038s,   84.26/s)  LR: 1.720e-04  Data: 0.021 (0.022)
2024-04-02 00:01:09,875 - train - INFO - Train: 3 [ 100/195 ( 52%)]  Loss:  1.934871 (1.8920)  Time: 3.005s,   85.20/s  (2.985s,   85.78/s)  LR: 1.720e-04  Data: 0.014 (0.018)
2024-04-02 00:03:39,850 - train - INFO - Train: 3 [ 150/195 ( 77%)]  Loss:  1.927906 (1.8739)  Time: 2.852s,   89.78/s  (2.989s,   85.63/s)  LR: 1.720e-04  Data: 0.011 (0.017)
2024-04-02 00:05:49,211 - train - INFO - Train: 3 [ 194/195 (100%)]  Loss:  1.997983 (1.8693)  Time: 2.754s,   92.96/s  (2.978s,   85.96/s)  LR: 1.720e-04  Data: 0.000 (0.016)
2024-04-02 00:05:49,212 - train - INFO - True
2024-04-02 00:05:49,213 - train - INFO - alphas:tensor([0.5206, 0.4794], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,213 - train - INFO - tau:0.99
2024-04-02 00:05:49,213 - train - INFO - True
2024-04-02 00:05:49,214 - train - INFO - alphas:tensor([0.5233, 0.4767], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,214 - train - INFO - tau:0.99
2024-04-02 00:05:49,214 - train - INFO - True
2024-04-02 00:05:49,215 - train - INFO - alphas:tensor([0.5424, 0.4576], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,215 - train - INFO - tau:0.99
2024-04-02 00:05:49,215 - train - INFO - True
2024-04-02 00:05:49,216 - train - INFO - alphas:tensor([0.5441, 0.4559], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,216 - train - INFO - tau:0.99
2024-04-02 00:05:49,216 - train - INFO - True
2024-04-02 00:05:49,216 - train - INFO - alphas:tensor([0.5348, 0.4652], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,217 - train - INFO - tau:0.99
2024-04-02 00:05:49,217 - train - INFO - True
2024-04-02 00:05:49,218 - train - INFO - alphas:tensor([0.5338, 0.4662], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,218 - train - INFO - tau:0.99
2024-04-02 00:05:49,218 - train - INFO - True
2024-04-02 00:05:49,219 - train - INFO - alphas:tensor([0.5347, 0.4653], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,220 - train - INFO - tau:0.99
2024-04-02 00:05:49,220 - train - INFO - True
2024-04-02 00:05:49,221 - train - INFO - alphas:tensor([0.5346, 0.4654], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,221 - train - INFO - tau:0.99
2024-04-02 00:05:49,221 - train - INFO - True
2024-04-02 00:05:49,222 - train - INFO - alphas:tensor([0.5425, 0.4575], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,222 - train - INFO - tau:0.99
2024-04-02 00:05:49,223 - train - INFO - True
2024-04-02 00:05:49,223 - train - INFO - alphas:tensor([0.5433, 0.4567], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,224 - train - INFO - tau:0.99
2024-04-02 00:05:49,224 - train - INFO - True
2024-04-02 00:05:49,225 - train - INFO - alphas:tensor([0.5324, 0.4676], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,225 - train - INFO - tau:0.99
2024-04-02 00:05:49,225 - train - INFO - True
2024-04-02 00:05:49,226 - train - INFO - alphas:tensor([0.5344, 0.4656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,226 - train - INFO - tau:0.99
2024-04-02 00:05:49,226 - train - INFO - True
2024-04-02 00:05:49,227 - train - INFO - alphas:tensor([0.5329, 0.4671], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,227 - train - INFO - tau:0.99
2024-04-02 00:05:49,227 - train - INFO - True
2024-04-02 00:05:49,228 - train - INFO - alphas:tensor([0.5327, 0.4673], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,228 - train - INFO - tau:0.99
2024-04-02 00:05:49,228 - train - INFO - True
2024-04-02 00:05:49,229 - train - INFO - alphas:tensor([0.5337, 0.4663], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,230 - train - INFO - tau:0.99
2024-04-02 00:05:49,230 - train - INFO - True
2024-04-02 00:05:49,231 - train - INFO - alphas:tensor([0.5339, 0.4661], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,231 - train - INFO - tau:0.99
2024-04-02 00:05:49,231 - train - INFO - True
2024-04-02 00:05:49,232 - train - INFO - alphas:tensor([0.5239, 0.4761], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,232 - train - INFO - tau:0.99
2024-04-02 00:05:49,233 - train - INFO - True
2024-04-02 00:05:49,234 - train - INFO - alphas:tensor([0.5232, 0.4768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,234 - train - INFO - tau:0.99
2024-04-02 00:05:49,234 - train - INFO - True
2024-04-02 00:05:49,235 - train - INFO - alphas:tensor([0.5257, 0.4743], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,237 - train - INFO - tau:0.99
2024-04-02 00:05:49,237 - train - INFO - True
2024-04-02 00:05:49,239 - train - INFO - alphas:tensor([0.5218, 0.4782], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,239 - train - INFO - tau:0.99
2024-04-02 00:05:49,239 - train - INFO - True
2024-04-02 00:05:49,240 - train - INFO - alphas:tensor([0.5167, 0.4833], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,241 - train - INFO - tau:0.99
2024-04-02 00:05:49,241 - train - INFO - True
2024-04-02 00:05:49,242 - train - INFO - alphas:tensor([0.5192, 0.4808], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,242 - train - INFO - tau:0.99
2024-04-02 00:05:49,242 - train - INFO - True
2024-04-02 00:05:49,243 - train - INFO - alphas:tensor([0.5203, 0.4797], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,243 - train - INFO - tau:0.99
2024-04-02 00:05:49,243 - train - INFO - True
2024-04-02 00:05:49,244 - train - INFO - alphas:tensor([0.5176, 0.4824], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,244 - train - INFO - tau:0.99
2024-04-02 00:05:49,244 - train - INFO - True
2024-04-02 00:05:49,245 - train - INFO - alphas:tensor([0.5146, 0.4854], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,245 - train - INFO - tau:0.99
2024-04-02 00:05:49,246 - train - INFO - True
2024-04-02 00:05:49,246 - train - INFO - alphas:tensor([0.5145, 0.4855], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,247 - train - INFO - tau:0.99
2024-04-02 00:05:49,247 - train - INFO - True
2024-04-02 00:05:49,247 - train - INFO - alphas:tensor([0.5183, 0.4817], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,248 - train - INFO - tau:0.99
2024-04-02 00:05:49,248 - train - INFO - True
2024-04-02 00:05:49,249 - train - INFO - alphas:tensor([0.5106, 0.4894], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,249 - train - INFO - tau:0.99
2024-04-02 00:05:49,249 - train - INFO - True
2024-04-02 00:05:49,250 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:05:49,250 - train - INFO - tau:0.99
2024-04-02 00:05:49,251 - train - INFO - avg block size:1.0
2024-04-02 00:05:51,162 - train - INFO - Test: [   0/39]  Time: 1.907 (1.907)  Loss:  0.7959 (0.7959)  Acc@1: 77.7344 (77.7344)  Acc@5: 98.8281 (98.8281)
2024-04-02 00:07:02,710 - train - INFO - Test: [  39/39]  Time: 1.814 (1.836)  Loss:  0.8286 (0.7439)  Acc@1: 68.7500 (81.0700)  Acc@5: 100.0000 (98.8200)
2024-04-02 00:07:06,536 - train - INFO - Train: 4 [   0/195 (  0%)]  Loss:  1.981765 (1.9818)  Time: 3.569s,   71.73/s  (3.569s,   71.73/s)  LR: 2.260e-04  Data: 0.365 (0.365)
2024-04-02 00:09:35,929 - train - INFO - Train: 4 [  50/195 ( 26%)]  Loss:  1.567304 (1.8034)  Time: 2.559s,  100.02/s  (2.999s,   85.36/s)  LR: 2.260e-04  Data: 0.006 (0.021)
2024-04-02 00:12:04,631 - train - INFO - Train: 4 [ 100/195 ( 52%)]  Loss:  2.010263 (1.7917)  Time: 3.015s,   84.92/s  (2.987s,   85.71/s)  LR: 2.260e-04  Data: 0.017 (0.018)
2024-04-02 00:14:31,693 - train - INFO - Train: 4 [ 150/195 ( 77%)]  Loss:  2.090725 (1.7747)  Time: 3.120s,   82.05/s  (2.972s,   86.15/s)  LR: 2.260e-04  Data: 0.010 (0.017)
2024-04-02 00:16:39,139 - train - INFO - Train: 4 [ 194/195 (100%)]  Loss:  1.791002 (1.7693)  Time: 3.254s,   78.67/s  (2.955s,   86.64/s)  LR: 2.260e-04  Data: 0.000 (0.016)
2024-04-02 00:16:39,148 - train - INFO - True
2024-04-02 00:16:39,150 - train - INFO - alphas:tensor([0.5256, 0.4744], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,151 - train - INFO - tau:0.9801
2024-04-02 00:16:39,151 - train - INFO - True
2024-04-02 00:16:39,152 - train - INFO - alphas:tensor([0.5269, 0.4731], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,152 - train - INFO - tau:0.9801
2024-04-02 00:16:39,152 - train - INFO - True
2024-04-02 00:16:39,153 - train - INFO - alphas:tensor([0.5634, 0.4366], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,153 - train - INFO - tau:0.9801
2024-04-02 00:16:39,153 - train - INFO - True
2024-04-02 00:16:39,154 - train - INFO - alphas:tensor([0.5662, 0.4338], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,154 - train - INFO - tau:0.9801
2024-04-02 00:16:39,154 - train - INFO - True
2024-04-02 00:16:39,164 - train - INFO - alphas:tensor([0.5488, 0.4512], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,164 - train - INFO - tau:0.9801
2024-04-02 00:16:39,164 - train - INFO - True
2024-04-02 00:16:39,165 - train - INFO - alphas:tensor([0.5497, 0.4503], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,165 - train - INFO - tau:0.9801
2024-04-02 00:16:39,165 - train - INFO - True
2024-04-02 00:16:39,166 - train - INFO - alphas:tensor([0.5523, 0.4477], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,166 - train - INFO - tau:0.9801
2024-04-02 00:16:39,166 - train - INFO - True
2024-04-02 00:16:39,167 - train - INFO - alphas:tensor([0.5512, 0.4488], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,167 - train - INFO - tau:0.9801
2024-04-02 00:16:39,167 - train - INFO - True
2024-04-02 00:16:39,168 - train - INFO - alphas:tensor([0.5598, 0.4402], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,168 - train - INFO - tau:0.9801
2024-04-02 00:16:39,168 - train - INFO - True
2024-04-02 00:16:39,169 - train - INFO - alphas:tensor([0.5637, 0.4363], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,169 - train - INFO - tau:0.9801
2024-04-02 00:16:39,169 - train - INFO - True
2024-04-02 00:16:39,169 - train - INFO - alphas:tensor([0.5505, 0.4495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,170 - train - INFO - tau:0.9801
2024-04-02 00:16:39,170 - train - INFO - True
2024-04-02 00:16:39,170 - train - INFO - alphas:tensor([0.5533, 0.4467], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,171 - train - INFO - tau:0.9801
2024-04-02 00:16:39,171 - train - INFO - True
2024-04-02 00:16:39,171 - train - INFO - alphas:tensor([0.5487, 0.4513], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,171 - train - INFO - tau:0.9801
2024-04-02 00:16:39,172 - train - INFO - True
2024-04-02 00:16:39,172 - train - INFO - alphas:tensor([0.5519, 0.4481], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,172 - train - INFO - tau:0.9801
2024-04-02 00:16:39,173 - train - INFO - True
2024-04-02 00:16:39,173 - train - INFO - alphas:tensor([0.5534, 0.4466], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,173 - train - INFO - tau:0.9801
2024-04-02 00:16:39,173 - train - INFO - True
2024-04-02 00:16:39,174 - train - INFO - alphas:tensor([0.5548, 0.4452], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,174 - train - INFO - tau:0.9801
2024-04-02 00:16:39,174 - train - INFO - True
2024-04-02 00:16:39,175 - train - INFO - alphas:tensor([0.5345, 0.4655], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,175 - train - INFO - tau:0.9801
2024-04-02 00:16:39,175 - train - INFO - True
2024-04-02 00:16:39,176 - train - INFO - alphas:tensor([0.5344, 0.4656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,176 - train - INFO - tau:0.9801
2024-04-02 00:16:39,176 - train - INFO - True
2024-04-02 00:16:39,177 - train - INFO - alphas:tensor([0.5415, 0.4585], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,177 - train - INFO - tau:0.9801
2024-04-02 00:16:39,177 - train - INFO - True
2024-04-02 00:16:39,178 - train - INFO - alphas:tensor([0.5393, 0.4607], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,178 - train - INFO - tau:0.9801
2024-04-02 00:16:39,178 - train - INFO - True
2024-04-02 00:16:39,179 - train - INFO - alphas:tensor([0.5232, 0.4768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,179 - train - INFO - tau:0.9801
2024-04-02 00:16:39,179 - train - INFO - True
2024-04-02 00:16:39,180 - train - INFO - alphas:tensor([0.5282, 0.4718], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,180 - train - INFO - tau:0.9801
2024-04-02 00:16:39,180 - train - INFO - True
2024-04-02 00:16:39,181 - train - INFO - alphas:tensor([0.5336, 0.4664], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,181 - train - INFO - tau:0.9801
2024-04-02 00:16:39,181 - train - INFO - True
2024-04-02 00:16:39,182 - train - INFO - alphas:tensor([0.5292, 0.4708], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,182 - train - INFO - tau:0.9801
2024-04-02 00:16:39,182 - train - INFO - True
2024-04-02 00:16:39,183 - train - INFO - alphas:tensor([0.5206, 0.4794], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,183 - train - INFO - tau:0.9801
2024-04-02 00:16:39,183 - train - INFO - True
2024-04-02 00:16:39,184 - train - INFO - alphas:tensor([0.5217, 0.4783], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,184 - train - INFO - tau:0.9801
2024-04-02 00:16:39,184 - train - INFO - True
2024-04-02 00:16:39,184 - train - INFO - alphas:tensor([0.5321, 0.4679], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,184 - train - INFO - tau:0.9801
2024-04-02 00:16:39,185 - train - INFO - True
2024-04-02 00:16:39,185 - train - INFO - alphas:tensor([0.5174, 0.4826], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,185 - train - INFO - tau:0.9801
2024-04-02 00:16:39,185 - train - INFO - True
2024-04-02 00:16:39,195 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:16:39,195 - train - INFO - tau:0.9801
2024-04-02 00:16:39,195 - train - INFO - avg block size:1.0
2024-04-02 00:16:41,098 - train - INFO - Test: [   0/39]  Time: 1.899 (1.899)  Loss:  0.6152 (0.6152)  Acc@1: 83.9844 (83.9844)  Acc@5: 99.6094 (99.6094)
2024-04-02 00:17:53,022 - train - INFO - Test: [  39/39]  Time: 1.832 (1.846)  Loss:  0.6494 (0.5796)  Acc@1: 75.0000 (85.5800)  Acc@5: 100.0000 (99.3600)
2024-04-02 00:17:56,229 - train - INFO - Train: 5 [   0/195 (  0%)]  Loss:  1.652316 (1.6523)  Time: 3.061s,   83.63/s  (3.061s,   83.63/s)  LR: 2.800e-04  Data: 0.394 (0.394)
2024-04-02 00:20:24,389 - train - INFO - Train: 5 [  50/195 ( 26%)]  Loss:  1.633304 (1.7466)  Time: 2.685s,   95.36/s  (2.965s,   86.34/s)  LR: 2.800e-04  Data: 0.017 (0.022)
2024-04-02 00:22:58,048 - train - INFO - Train: 5 [ 100/195 ( 52%)]  Loss:  1.762578 (1.7635)  Time: 3.057s,   83.73/s  (3.019s,   84.81/s)  LR: 2.800e-04  Data: 0.020 (0.019)
2024-04-02 00:25:24,609 - train - INFO - Train: 5 [ 150/195 ( 77%)]  Loss:  1.960930 (1.7353)  Time: 2.861s,   89.47/s  (2.990s,   85.63/s)  LR: 2.800e-04  Data: 0.042 (0.018)
2024-04-02 00:27:36,192 - train - INFO - Train: 5 [ 194/195 (100%)]  Loss:  1.358895 (1.7230)  Time: 2.876s,   89.01/s  (2.990s,   85.62/s)  LR: 2.800e-04  Data: 0.000 (0.017)
2024-04-02 00:27:36,193 - train - INFO - True
2024-04-02 00:27:36,194 - train - INFO - alphas:tensor([0.5222, 0.4778], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,194 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,194 - train - INFO - True
2024-04-02 00:27:36,195 - train - INFO - alphas:tensor([0.5262, 0.4738], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,195 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,195 - train - INFO - True
2024-04-02 00:27:36,196 - train - INFO - alphas:tensor([0.5823, 0.4177], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,196 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,196 - train - INFO - True
2024-04-02 00:27:36,196 - train - INFO - alphas:tensor([0.5862, 0.4138], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,196 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,196 - train - INFO - True
2024-04-02 00:27:36,202 - train - INFO - alphas:tensor([0.5599, 0.4401], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,202 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,202 - train - INFO - True
2024-04-02 00:27:36,207 - train - INFO - alphas:tensor([0.5641, 0.4359], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,207 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,207 - train - INFO - True
2024-04-02 00:27:36,208 - train - INFO - alphas:tensor([0.5712, 0.4288], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,208 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,208 - train - INFO - True
2024-04-02 00:27:36,208 - train - INFO - alphas:tensor([0.5687, 0.4313], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,209 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,209 - train - INFO - True
2024-04-02 00:27:36,210 - train - INFO - alphas:tensor([0.5716, 0.4284], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,210 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,210 - train - INFO - True
2024-04-02 00:27:36,215 - train - INFO - alphas:tensor([0.5806, 0.4194], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,215 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,215 - train - INFO - True
2024-04-02 00:27:36,216 - train - INFO - alphas:tensor([0.5696, 0.4304], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,216 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,216 - train - INFO - True
2024-04-02 00:27:36,217 - train - INFO - alphas:tensor([0.5732, 0.4268], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,217 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,217 - train - INFO - True
2024-04-02 00:27:36,218 - train - INFO - alphas:tensor([0.5625, 0.4375], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,218 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,218 - train - INFO - True
2024-04-02 00:27:36,218 - train - INFO - alphas:tensor([0.5702, 0.4298], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,219 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,219 - train - INFO - True
2024-04-02 00:27:36,219 - train - INFO - alphas:tensor([0.5730, 0.4270], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,219 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,219 - train - INFO - True
2024-04-02 00:27:36,220 - train - INFO - alphas:tensor([0.5759, 0.4241], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,220 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,220 - train - INFO - True
2024-04-02 00:27:36,221 - train - INFO - alphas:tensor([0.5462, 0.4538], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,221 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,221 - train - INFO - True
2024-04-02 00:27:36,222 - train - INFO - alphas:tensor([0.5469, 0.4531], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,222 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,222 - train - INFO - True
2024-04-02 00:27:36,223 - train - INFO - alphas:tensor([0.5574, 0.4426], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,223 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,223 - train - INFO - True
2024-04-02 00:27:36,223 - train - INFO - alphas:tensor([0.5560, 0.4440], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,223 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,224 - train - INFO - True
2024-04-02 00:27:36,224 - train - INFO - alphas:tensor([0.5299, 0.4701], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,224 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,224 - train - INFO - True
2024-04-02 00:27:36,225 - train - INFO - alphas:tensor([0.5375, 0.4625], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,225 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,225 - train - INFO - True
2024-04-02 00:27:36,226 - train - INFO - alphas:tensor([0.5476, 0.4524], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,226 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,226 - train - INFO - True
2024-04-02 00:27:36,227 - train - INFO - alphas:tensor([0.5418, 0.4582], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,227 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,227 - train - INFO - True
2024-04-02 00:27:36,227 - train - INFO - alphas:tensor([0.5263, 0.4737], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,228 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,228 - train - INFO - True
2024-04-02 00:27:36,228 - train - INFO - alphas:tensor([0.5290, 0.4710], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,228 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,228 - train - INFO - True
2024-04-02 00:27:36,229 - train - INFO - alphas:tensor([0.5447, 0.4553], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,229 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,229 - train - INFO - True
2024-04-02 00:27:36,230 - train - INFO - alphas:tensor([0.5238, 0.4762], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,230 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,230 - train - INFO - True
2024-04-02 00:27:36,231 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:27:36,231 - train - INFO - tau:0.9702989999999999
2024-04-02 00:27:36,231 - train - INFO - avg block size:1.0
2024-04-02 00:27:38,043 - train - INFO - Test: [   0/39]  Time: 1.805 (1.805)  Loss:  0.5454 (0.5454)  Acc@1: 85.1562 (85.1562)  Acc@5: 100.0000 (100.0000)
2024-04-02 00:28:49,930 - train - INFO - Test: [  39/39]  Time: 1.740 (1.842)  Loss:  0.5391 (0.5083)  Acc@1: 81.2500 (87.9200)  Acc@5: 100.0000 (99.6000)
2024-04-02 00:28:53,393 - train - INFO - Train: 6 [   0/195 (  0%)]  Loss:  1.874865 (1.8749)  Time: 3.117s,   82.13/s  (3.117s,   82.13/s)  LR: 3.340e-04  Data: 0.329 (0.329)
2024-04-02 00:31:26,112 - train - INFO - Train: 6 [  50/195 ( 26%)]  Loss:  1.913523 (1.7457)  Time: 2.793s,   91.67/s  (3.056s,   83.78/s)  LR: 3.340e-04  Data: 0.032 (0.022)
2024-04-02 00:33:54,535 - train - INFO - Train: 6 [ 100/195 ( 52%)]  Loss:  1.859072 (1.7326)  Time: 3.050s,   83.93/s  (3.012s,   84.98/s)  LR: 3.340e-04  Data: 0.010 (0.019)
2024-04-02 00:36:23,601 - train - INFO - Train: 6 [ 150/195 ( 77%)]  Loss:  1.947371 (1.7050)  Time: 2.841s,   90.10/s  (3.002s,   85.28/s)  LR: 3.340e-04  Data: 0.013 (0.018)
2024-04-02 00:38:31,315 - train - INFO - Train: 6 [ 194/195 (100%)]  Loss:  1.945693 (1.6981)  Time: 2.711s,   94.43/s  (2.980s,   85.92/s)  LR: 3.340e-04  Data: 0.000 (0.017)
2024-04-02 00:38:31,316 - train - INFO - True
2024-04-02 00:38:31,317 - train - INFO - alphas:tensor([0.5145, 0.4855], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,317 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,317 - train - INFO - True
2024-04-02 00:38:31,318 - train - INFO - alphas:tensor([0.5231, 0.4769], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,318 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,318 - train - INFO - True
2024-04-02 00:38:31,319 - train - INFO - alphas:tensor([0.5983, 0.4017], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,319 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,319 - train - INFO - True
2024-04-02 00:38:31,320 - train - INFO - alphas:tensor([0.6028, 0.3972], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,320 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,320 - train - INFO - True
2024-04-02 00:38:31,321 - train - INFO - alphas:tensor([0.5637, 0.4363], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,321 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,321 - train - INFO - True
2024-04-02 00:38:31,321 - train - INFO - alphas:tensor([0.5735, 0.4265], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,322 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,322 - train - INFO - True
2024-04-02 00:38:31,322 - train - INFO - alphas:tensor([0.5914, 0.4086], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,322 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,322 - train - INFO - True
2024-04-02 00:38:31,323 - train - INFO - alphas:tensor([0.5873, 0.4127], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,323 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,323 - train - INFO - True
2024-04-02 00:38:31,324 - train - INFO - alphas:tensor([0.5798, 0.4202], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,324 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,325 - train - INFO - True
2024-04-02 00:38:31,339 - train - INFO - alphas:tensor([0.5955, 0.4045], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,339 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,339 - train - INFO - True
2024-04-02 00:38:31,339 - train - INFO - alphas:tensor([0.5893, 0.4107], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,340 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,340 - train - INFO - True
2024-04-02 00:38:31,340 - train - INFO - alphas:tensor([0.5937, 0.4063], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,340 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,340 - train - INFO - True
2024-04-02 00:38:31,341 - train - INFO - alphas:tensor([0.5746, 0.4254], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,341 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,341 - train - INFO - True
2024-04-02 00:38:31,342 - train - INFO - alphas:tensor([0.5869, 0.4131], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,342 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,342 - train - INFO - True
2024-04-02 00:38:31,343 - train - INFO - alphas:tensor([0.5930, 0.4070], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,343 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,343 - train - INFO - True
2024-04-02 00:38:31,344 - train - INFO - alphas:tensor([0.5966, 0.4034], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,344 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,344 - train - INFO - True
2024-04-02 00:38:31,344 - train - INFO - alphas:tensor([0.5563, 0.4437], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,345 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,345 - train - INFO - True
2024-04-02 00:38:31,345 - train - INFO - alphas:tensor([0.5587, 0.4413], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,345 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,345 - train - INFO - True
2024-04-02 00:38:31,346 - train - INFO - alphas:tensor([0.5736, 0.4264], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,346 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,346 - train - INFO - True
2024-04-02 00:38:31,347 - train - INFO - alphas:tensor([0.5725, 0.4275], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,347 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,347 - train - INFO - True
2024-04-02 00:38:31,348 - train - INFO - alphas:tensor([0.5364, 0.4636], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,348 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,348 - train - INFO - True
2024-04-02 00:38:31,349 - train - INFO - alphas:tensor([0.5464, 0.4536], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,349 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,349 - train - INFO - True
2024-04-02 00:38:31,363 - train - INFO - alphas:tensor([0.5629, 0.4371], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,363 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,363 - train - INFO - True
2024-04-02 00:38:31,363 - train - INFO - alphas:tensor([0.5571, 0.4429], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,364 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,364 - train - INFO - True
2024-04-02 00:38:31,364 - train - INFO - alphas:tensor([0.5338, 0.4662], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,364 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,364 - train - INFO - True
2024-04-02 00:38:31,365 - train - INFO - alphas:tensor([0.5374, 0.4626], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,365 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,365 - train - INFO - True
2024-04-02 00:38:31,366 - train - INFO - alphas:tensor([0.5563, 0.4437], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,366 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,366 - train - INFO - True
2024-04-02 00:38:31,367 - train - INFO - alphas:tensor([0.5284, 0.4716], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,367 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,367 - train - INFO - True
2024-04-02 00:38:31,368 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:38:31,368 - train - INFO - tau:0.96059601
2024-04-02 00:38:31,368 - train - INFO - avg block size:1.0
2024-04-02 00:38:31,368 - train - INFO - lasso_alpha:2.2000000000000003e-05
2024-04-02 00:38:33,227 - train - INFO - Test: [   0/39]  Time: 1.856 (1.856)  Loss:  0.5039 (0.5039)  Acc@1: 85.1562 (85.1562)  Acc@5: 99.6094 (99.6094)
2024-04-02 00:39:46,949 - train - INFO - Test: [  39/39]  Time: 1.809 (1.889)  Loss:  0.4827 (0.4600)  Acc@1: 81.2500 (89.3700)  Acc@5: 100.0000 (99.5400)
2024-04-02 00:39:50,309 - train - INFO - Train: 7 [   0/195 (  0%)]  Loss:  1.744466 (1.7445)  Time: 3.151s,   81.23/s  (3.151s,   81.23/s)  LR: 3.880e-04  Data: 0.332 (0.332)
2024-04-02 00:42:20,877 - train - INFO - Train: 7 [  50/195 ( 26%)]  Loss:  1.700904 (1.7197)  Time: 2.625s,   97.52/s  (3.014s,   84.93/s)  LR: 3.880e-04  Data: 0.005 (0.021)
2024-04-02 00:44:48,376 - train - INFO - Train: 7 [ 100/195 ( 52%)]  Loss:  1.688911 (1.7242)  Time: 2.861s,   89.49/s  (2.982s,   85.84/s)  LR: 3.880e-04  Data: 0.012 (0.018)
2024-04-02 00:47:21,553 - train - INFO - Train: 7 [ 150/195 ( 77%)]  Loss:  1.729023 (1.7179)  Time: 3.191s,   80.23/s  (3.009s,   85.07/s)  LR: 3.880e-04  Data: 0.006 (0.018)
2024-04-02 00:49:30,650 - train - INFO - Train: 7 [ 194/195 (100%)]  Loss:  1.710804 (1.7111)  Time: 2.584s,   99.08/s  (2.992s,   85.56/s)  LR: 3.880e-04  Data: 0.000 (0.016)
2024-04-02 00:49:30,651 - train - INFO - True
2024-04-02 00:49:30,653 - train - INFO - alphas:tensor([0.5011, 0.4989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,653 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,658 - train - INFO - True
2024-04-02 00:49:30,658 - train - INFO - alphas:tensor([0.5169, 0.4831], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,658 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,659 - train - INFO - True
2024-04-02 00:49:30,659 - train - INFO - alphas:tensor([0.6117, 0.3883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,659 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,659 - train - INFO - True
2024-04-02 00:49:30,660 - train - INFO - alphas:tensor([0.6162, 0.3838], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,660 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,660 - train - INFO - True
2024-04-02 00:49:30,661 - train - INFO - alphas:tensor([0.5648, 0.4352], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,661 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,661 - train - INFO - True
2024-04-02 00:49:30,662 - train - INFO - alphas:tensor([0.5819, 0.4181], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,662 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,662 - train - INFO - True
2024-04-02 00:49:30,663 - train - INFO - alphas:tensor([0.6095, 0.3905], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,663 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,663 - train - INFO - True
2024-04-02 00:49:30,663 - train - INFO - alphas:tensor([0.6036, 0.3964], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,664 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,664 - train - INFO - True
2024-04-02 00:49:30,665 - train - INFO - alphas:tensor([0.5844, 0.4156], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,665 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,665 - train - INFO - True
2024-04-02 00:49:30,666 - train - INFO - alphas:tensor([0.6083, 0.3917], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,666 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,666 - train - INFO - True
2024-04-02 00:49:30,666 - train - INFO - alphas:tensor([0.6066, 0.3934], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,667 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,667 - train - INFO - True
2024-04-02 00:49:30,667 - train - INFO - alphas:tensor([0.6114, 0.3886], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,667 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,667 - train - INFO - True
2024-04-02 00:49:30,668 - train - INFO - alphas:tensor([0.5825, 0.4175], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,668 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,668 - train - INFO - True
2024-04-02 00:49:30,669 - train - INFO - alphas:tensor([0.6004, 0.3996], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,669 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,669 - train - INFO - True
2024-04-02 00:49:30,670 - train - INFO - alphas:tensor([0.6103, 0.3897], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,670 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,670 - train - INFO - True
2024-04-02 00:49:30,675 - train - INFO - alphas:tensor([0.6129, 0.3871], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,675 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,675 - train - INFO - True
2024-04-02 00:49:30,676 - train - INFO - alphas:tensor([0.5639, 0.4361], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,676 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,676 - train - INFO - True
2024-04-02 00:49:30,677 - train - INFO - alphas:tensor([0.5694, 0.4306], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,677 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,677 - train - INFO - True
2024-04-02 00:49:30,678 - train - INFO - alphas:tensor([0.5883, 0.4117], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,678 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,678 - train - INFO - True
2024-04-02 00:49:30,678 - train - INFO - alphas:tensor([0.5852, 0.4148], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,678 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,679 - train - INFO - True
2024-04-02 00:49:30,679 - train - INFO - alphas:tensor([0.5417, 0.4583], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,679 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,679 - train - INFO - True
2024-04-02 00:49:30,680 - train - INFO - alphas:tensor([0.5542, 0.4458], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,680 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,680 - train - INFO - True
2024-04-02 00:49:30,681 - train - INFO - alphas:tensor([0.5759, 0.4241], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,681 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,681 - train - INFO - True
2024-04-02 00:49:30,682 - train - INFO - alphas:tensor([0.5679, 0.4321], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,682 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,682 - train - INFO - True
2024-04-02 00:49:30,682 - train - INFO - alphas:tensor([0.5391, 0.4609], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,683 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,683 - train - INFO - True
2024-04-02 00:49:30,683 - train - INFO - alphas:tensor([0.5439, 0.4561], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,683 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,683 - train - INFO - True
2024-04-02 00:49:30,688 - train - INFO - alphas:tensor([0.5615, 0.4385], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,689 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,689 - train - INFO - True
2024-04-02 00:49:30,689 - train - INFO - alphas:tensor([0.5276, 0.4724], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,689 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,689 - train - INFO - True
2024-04-02 00:49:30,690 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 00:49:30,690 - train - INFO - tau:0.9509900498999999
2024-04-02 00:49:30,690 - train - INFO - avg block size:1.0
2024-04-02 00:49:32,385 - train - INFO - Test: [   0/39]  Time: 1.692 (1.692)  Loss:  0.4807 (0.4807)  Acc@1: 87.5000 (87.5000)  Acc@5: 99.6094 (99.6094)
2024-04-02 00:50:43,988 - train - INFO - Test: [  39/39]  Time: 1.841 (1.832)  Loss:  0.4519 (0.4505)  Acc@1: 87.5000 (89.7400)  Acc@5: 100.0000 (99.7400)
2024-04-02 00:50:47,270 - train - INFO - Train: 8 [   0/195 (  0%)]  Loss:  1.873835 (1.8738)  Time: 3.060s,   83.66/s  (3.060s,   83.66/s)  LR: 4.420e-04  Data: 0.488 (0.488)
2024-04-02 00:53:16,519 - train - INFO - Train: 8 [  50/195 ( 26%)]  Loss:  1.346929 (1.6502)  Time: 3.062s,   83.61/s  (2.986s,   85.72/s)  LR: 4.420e-04  Data: 0.010 (0.026)
2024-04-02 00:55:43,296 - train - INFO - Train: 8 [ 100/195 ( 52%)]  Loss:  1.871495 (1.6604)  Time: 2.782s,   92.01/s  (2.961s,   86.45/s)  LR: 4.420e-04  Data: 0.018 (0.020)
2024-04-02 00:58:10,507 - train - INFO - Train: 8 [ 150/195 ( 77%)]  Loss:  1.834147 (1.6673)  Time: 2.706s,   94.62/s  (2.956s,   86.62/s)  LR: 4.420e-04  Data: 0.005 (0.018)
2024-04-02 01:00:23,619 - train - INFO - Train: 8 [ 194/195 (100%)]  Loss:  1.513535 (1.6626)  Time: 3.003s,   85.24/s  (2.971s,   86.16/s)  LR: 4.420e-04  Data: 0.000 (0.017)
2024-04-02 01:00:23,619 - train - INFO - True
2024-04-02 01:00:23,620 - train - INFO - alphas:tensor([0.4872, 0.5128], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,620 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,621 - train - INFO - True
2024-04-02 01:00:23,621 - train - INFO - alphas:tensor([0.5102, 0.4898], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,621 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,621 - train - INFO - True
2024-04-02 01:00:23,622 - train - INFO - alphas:tensor([0.6221, 0.3779], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,622 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,622 - train - INFO - True
2024-04-02 01:00:23,623 - train - INFO - alphas:tensor([0.6264, 0.3736], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,627 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,627 - train - INFO - True
2024-04-02 01:00:23,628 - train - INFO - alphas:tensor([0.5605, 0.4395], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,628 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,628 - train - INFO - True
2024-04-02 01:00:23,629 - train - INFO - alphas:tensor([0.5868, 0.4132], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,629 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,629 - train - INFO - True
2024-04-02 01:00:23,630 - train - INFO - alphas:tensor([0.6275, 0.3725], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,630 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,630 - train - INFO - True
2024-04-02 01:00:23,631 - train - INFO - alphas:tensor([0.6198, 0.3802], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,631 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,631 - train - INFO - True
2024-04-02 01:00:23,631 - train - INFO - alphas:tensor([0.5865, 0.4135], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,632 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,632 - train - INFO - True
2024-04-02 01:00:23,632 - train - INFO - alphas:tensor([0.6177, 0.3823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,632 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,632 - train - INFO - True
2024-04-02 01:00:23,633 - train - INFO - alphas:tensor([0.6235, 0.3765], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,633 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,633 - train - INFO - True
2024-04-02 01:00:23,634 - train - INFO - alphas:tensor([0.6275, 0.3725], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,647 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,647 - train - INFO - True
2024-04-02 01:00:23,648 - train - INFO - alphas:tensor([0.5873, 0.4127], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,648 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,648 - train - INFO - True
2024-04-02 01:00:23,649 - train - INFO - alphas:tensor([0.6112, 0.3888], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,649 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,649 - train - INFO - True
2024-04-02 01:00:23,650 - train - INFO - alphas:tensor([0.6260, 0.3740], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,650 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,650 - train - INFO - True
2024-04-02 01:00:23,650 - train - INFO - alphas:tensor([0.6264, 0.3736], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,650 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,651 - train - INFO - True
2024-04-02 01:00:23,651 - train - INFO - alphas:tensor([0.5701, 0.4299], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,651 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,651 - train - INFO - True
2024-04-02 01:00:23,652 - train - INFO - alphas:tensor([0.5780, 0.4220], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,652 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,652 - train - INFO - True
2024-04-02 01:00:23,653 - train - INFO - alphas:tensor([0.6020, 0.3980], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,653 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,653 - train - INFO - True
2024-04-02 01:00:23,654 - train - INFO - alphas:tensor([0.5940, 0.4060], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,654 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,654 - train - INFO - True
2024-04-02 01:00:23,654 - train - INFO - alphas:tensor([0.5458, 0.4542], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,654 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,655 - train - INFO - True
2024-04-02 01:00:23,655 - train - INFO - alphas:tensor([0.5614, 0.4386], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,655 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,655 - train - INFO - True
2024-04-02 01:00:23,656 - train - INFO - alphas:tensor([0.5884, 0.4116], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,656 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,656 - train - INFO - True
2024-04-02 01:00:23,661 - train - INFO - alphas:tensor([0.5745, 0.4255], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,661 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,661 - train - INFO - True
2024-04-02 01:00:23,662 - train - INFO - alphas:tensor([0.5412, 0.4588], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,662 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,662 - train - INFO - True
2024-04-02 01:00:23,663 - train - INFO - alphas:tensor([0.5489, 0.4511], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,663 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,663 - train - INFO - True
2024-04-02 01:00:23,664 - train - INFO - alphas:tensor([0.5649, 0.4351], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,664 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,664 - train - INFO - True
2024-04-02 01:00:23,664 - train - INFO - alphas:tensor([0.5245, 0.4755], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,665 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,665 - train - INFO - True
2024-04-02 01:00:23,665 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:00:23,665 - train - INFO - tau:0.9414801494009999
2024-04-02 01:00:23,665 - train - INFO - avg block size:1.5172413793103448
2024-04-02 01:00:23,665 - train - INFO - lasso_alpha:2.4200000000000005e-05
2024-04-02 01:00:25,515 - train - INFO - Test: [   0/39]  Time: 1.846 (1.846)  Loss:  0.4724 (0.4724)  Acc@1: 89.0625 (89.0625)  Acc@5: 99.6094 (99.6094)
2024-04-02 01:01:36,528 - train - INFO - Test: [  39/39]  Time: 1.762 (1.821)  Loss:  0.4734 (0.4422)  Acc@1: 81.2500 (90.2900)  Acc@5: 100.0000 (99.6800)
2024-04-02 01:01:40,404 - train - INFO - Train: 9 [   0/195 (  0%)]  Loss:  1.908983 (1.9090)  Time: 3.519s,   72.75/s  (3.519s,   72.75/s)  LR: 4.960e-04  Data: 0.387 (0.387)
2024-04-02 01:04:09,445 - train - INFO - Train: 9 [  50/195 ( 26%)]  Loss:  1.824407 (1.7245)  Time: 3.013s,   84.95/s  (2.991s,   85.59/s)  LR: 4.960e-04  Data: 0.015 (0.022)
2024-04-02 01:06:39,101 - train - INFO - Train: 9 [ 100/195 ( 52%)]  Loss:  1.951330 (1.7068)  Time: 2.968s,   86.24/s  (2.992s,   85.56/s)  LR: 4.960e-04  Data: 0.024 (0.018)
2024-04-02 01:09:06,943 - train - INFO - Train: 9 [ 150/195 ( 77%)]  Loss:  1.406839 (1.6889)  Time: 2.670s,   95.87/s  (2.980s,   85.90/s)  LR: 4.960e-04  Data: 0.011 (0.017)
2024-04-02 01:11:18,068 - train - INFO - Train: 9 [ 194/195 (100%)]  Loss:  1.414760 (1.6923)  Time: 3.427s,   74.69/s  (2.980s,   85.90/s)  LR: 4.960e-04  Data: 0.000 (0.016)
2024-04-02 01:11:18,077 - train - INFO - True
2024-04-02 01:11:18,079 - train - INFO - alphas:tensor([0.4695, 0.5305], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,079 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,079 - train - INFO - True
2024-04-02 01:11:18,080 - train - INFO - alphas:tensor([0.5002, 0.4998], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,080 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,080 - train - INFO - True
2024-04-02 01:11:18,081 - train - INFO - alphas:tensor([0.6293, 0.3707], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,081 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,081 - train - INFO - True
2024-04-02 01:11:18,082 - train - INFO - alphas:tensor([0.6326, 0.3674], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,082 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,082 - train - INFO - True
2024-04-02 01:11:18,083 - train - INFO - alphas:tensor([0.5530, 0.4470], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,083 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,083 - train - INFO - True
2024-04-02 01:11:18,083 - train - INFO - alphas:tensor([0.5903, 0.4097], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,084 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,084 - train - INFO - True
2024-04-02 01:11:18,084 - train - INFO - alphas:tensor([0.6425, 0.3575], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,084 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,084 - train - INFO - True
2024-04-02 01:11:18,085 - train - INFO - alphas:tensor([0.6322, 0.3678], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,086 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,086 - train - INFO - True
2024-04-02 01:11:18,087 - train - INFO - alphas:tensor([0.5844, 0.4156], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,087 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,087 - train - INFO - True
2024-04-02 01:11:18,087 - train - INFO - alphas:tensor([0.6239, 0.3761], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,088 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,088 - train - INFO - True
2024-04-02 01:11:18,088 - train - INFO - alphas:tensor([0.6374, 0.3626], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,088 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,088 - train - INFO - True
2024-04-02 01:11:18,089 - train - INFO - alphas:tensor([0.6393, 0.3607], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,089 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,089 - train - INFO - True
2024-04-02 01:11:18,094 - train - INFO - alphas:tensor([0.5865, 0.4135], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,094 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,094 - train - INFO - True
2024-04-02 01:11:18,095 - train - INFO - alphas:tensor([0.6167, 0.3833], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,095 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,095 - train - INFO - True
2024-04-02 01:11:18,096 - train - INFO - alphas:tensor([0.6388, 0.3612], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,096 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,096 - train - INFO - True
2024-04-02 01:11:18,101 - train - INFO - alphas:tensor([0.6353, 0.3647], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,101 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,101 - train - INFO - True
2024-04-02 01:11:18,102 - train - INFO - alphas:tensor([0.5703, 0.4297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,102 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,102 - train - INFO - True
2024-04-02 01:11:18,103 - train - INFO - alphas:tensor([0.5822, 0.4178], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,103 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,103 - train - INFO - True
2024-04-02 01:11:18,104 - train - INFO - alphas:tensor([0.6118, 0.3882], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,104 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,104 - train - INFO - True
2024-04-02 01:11:18,105 - train - INFO - alphas:tensor([0.5952, 0.4048], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,105 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,105 - train - INFO - True
2024-04-02 01:11:18,105 - train - INFO - alphas:tensor([0.5466, 0.4534], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,105 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,105 - train - INFO - True
2024-04-02 01:11:18,106 - train - INFO - alphas:tensor([0.5664, 0.4336], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,106 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,106 - train - INFO - True
2024-04-02 01:11:18,116 - train - INFO - alphas:tensor([0.5967, 0.4033], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,116 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,116 - train - INFO - True
2024-04-02 01:11:18,117 - train - INFO - alphas:tensor([0.5711, 0.4289], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,117 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,117 - train - INFO - True
2024-04-02 01:11:18,117 - train - INFO - alphas:tensor([0.5383, 0.4617], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,118 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,118 - train - INFO - True
2024-04-02 01:11:18,118 - train - INFO - alphas:tensor([0.5506, 0.4494], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,118 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,118 - train - INFO - True
2024-04-02 01:11:18,119 - train - INFO - alphas:tensor([0.5599, 0.4401], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,119 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,119 - train - INFO - True
2024-04-02 01:11:18,120 - train - INFO - alphas:tensor([0.5137, 0.4863], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,120 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,120 - train - INFO - True
2024-04-02 01:11:18,121 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:11:18,121 - train - INFO - tau:0.9320653479069899
2024-04-02 01:11:18,121 - train - INFO - avg block size:1.5172413793103448
2024-04-02 01:11:20,116 - train - INFO - Test: [   0/39]  Time: 1.992 (1.992)  Loss:  0.4546 (0.4546)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)
2024-04-02 01:12:32,171 - train - INFO - Test: [  39/39]  Time: 1.784 (1.851)  Loss:  0.5703 (0.4280)  Acc@1: 81.2500 (90.0700)  Acc@5: 100.0000 (99.5700)
2024-04-02 01:12:35,503 - train - INFO - Train: 10 [   0/195 (  0%)]  Loss:  1.792570 (1.7926)  Time: 3.131s,   81.75/s  (3.131s,   81.75/s)  LR: 5.441e-04  Data: 0.344 (0.344)
2024-04-02 01:15:04,106 - train - INFO - Train: 10 [  50/195 ( 26%)]  Loss:  1.899077 (1.7320)  Time: 3.189s,   80.27/s  (2.975s,   86.05/s)  LR: 5.441e-04  Data: 0.014 (0.020)
2024-04-02 01:17:33,087 - train - INFO - Train: 10 [ 100/195 ( 52%)]  Loss:  1.842988 (1.7121)  Time: 3.233s,   79.19/s  (2.977s,   85.98/s)  LR: 5.441e-04  Data: 0.005 (0.017)
2024-04-02 01:19:59,960 - train - INFO - Train: 10 [ 150/195 ( 77%)]  Loss:  1.290951 (1.6986)  Time: 3.147s,   81.36/s  (2.964s,   86.37/s)  LR: 5.441e-04  Data: 0.018 (0.017)
2024-04-02 01:22:09,934 - train - INFO - Train: 10 [ 194/195 (100%)]  Loss:  1.408708 (1.6844)  Time: 2.843s,   90.05/s  (2.962s,   86.43/s)  LR: 5.441e-04  Data: 0.000 (0.016)
2024-04-02 01:22:09,934 - train - INFO - True
2024-04-02 01:22:09,936 - train - INFO - alphas:tensor([0.4517, 0.5483], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,936 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,936 - train - INFO - True
2024-04-02 01:22:09,937 - train - INFO - alphas:tensor([0.4895, 0.5105], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,937 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,937 - train - INFO - True
2024-04-02 01:22:09,937 - train - INFO - alphas:tensor([0.6359, 0.3641], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,937 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,938 - train - INFO - True
2024-04-02 01:22:09,938 - train - INFO - alphas:tensor([0.6384, 0.3616], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,938 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,938 - train - INFO - True
2024-04-02 01:22:09,939 - train - INFO - alphas:tensor([0.5441, 0.4559], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,939 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,939 - train - INFO - True
2024-04-02 01:22:09,940 - train - INFO - alphas:tensor([0.5917, 0.4083], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,940 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,940 - train - INFO - True
2024-04-02 01:22:09,941 - train - INFO - alphas:tensor([0.6553, 0.3447], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,941 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,941 - train - INFO - True
2024-04-02 01:22:09,950 - train - INFO - alphas:tensor([0.6419, 0.3581], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,950 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,950 - train - INFO - True
2024-04-02 01:22:09,951 - train - INFO - alphas:tensor([0.5809, 0.4191], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,952 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,952 - train - INFO - True
2024-04-02 01:22:09,952 - train - INFO - alphas:tensor([0.6289, 0.3711], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,952 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,953 - train - INFO - True
2024-04-02 01:22:09,953 - train - INFO - alphas:tensor([0.6505, 0.3495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,953 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,953 - train - INFO - True
2024-04-02 01:22:09,954 - train - INFO - alphas:tensor([0.6502, 0.3498], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,954 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,954 - train - INFO - True
2024-04-02 01:22:09,955 - train - INFO - alphas:tensor([0.5831, 0.4169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,955 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,955 - train - INFO - True
2024-04-02 01:22:09,956 - train - INFO - alphas:tensor([0.6197, 0.3803], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,956 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,956 - train - INFO - True
2024-04-02 01:22:09,956 - train - INFO - alphas:tensor([0.6491, 0.3509], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,957 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,957 - train - INFO - True
2024-04-02 01:22:09,957 - train - INFO - alphas:tensor([0.6395, 0.3605], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,957 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,957 - train - INFO - True
2024-04-02 01:22:09,958 - train - INFO - alphas:tensor([0.5684, 0.4316], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,958 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,958 - train - INFO - True
2024-04-02 01:22:09,959 - train - INFO - alphas:tensor([0.5848, 0.4152], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,959 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,959 - train - INFO - True
2024-04-02 01:22:09,960 - train - INFO - alphas:tensor([0.6195, 0.3805], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,960 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,960 - train - INFO - True
2024-04-02 01:22:09,961 - train - INFO - alphas:tensor([0.5904, 0.4096], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,961 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,961 - train - INFO - True
2024-04-02 01:22:09,961 - train - INFO - alphas:tensor([0.5447, 0.4553], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,961 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,962 - train - INFO - True
2024-04-02 01:22:09,962 - train - INFO - alphas:tensor([0.5690, 0.4310], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,962 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,962 - train - INFO - True
2024-04-02 01:22:09,963 - train - INFO - alphas:tensor([0.6029, 0.3971], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,963 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,963 - train - INFO - True
2024-04-02 01:22:09,964 - train - INFO - alphas:tensor([0.5620, 0.4380], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,964 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,964 - train - INFO - True
2024-04-02 01:22:09,965 - train - INFO - alphas:tensor([0.5318, 0.4682], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,965 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,965 - train - INFO - True
2024-04-02 01:22:09,965 - train - INFO - alphas:tensor([0.5492, 0.4508], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,966 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,966 - train - INFO - True
2024-04-02 01:22:09,966 - train - INFO - alphas:tensor([0.5506, 0.4494], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,966 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,966 - train - INFO - True
2024-04-02 01:22:09,967 - train - INFO - alphas:tensor([0.4983, 0.5017], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,967 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,967 - train - INFO - True
2024-04-02 01:22:09,968 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:22:09,968 - train - INFO - tau:0.92274469442792
2024-04-02 01:22:09,968 - train - INFO - avg block size:2.5517241379310347
2024-04-02 01:22:09,968 - train - INFO - lasso_alpha:2.662000000000001e-05
2024-04-02 01:22:11,833 - train - INFO - Test: [   0/39]  Time: 1.861 (1.861)  Loss:  0.4353 (0.4353)  Acc@1: 88.6719 (88.6719)  Acc@5: 100.0000 (100.0000)
2024-04-02 01:23:24,044 - train - INFO - Test: [  39/39]  Time: 1.819 (1.852)  Loss:  0.4141 (0.4282)  Acc@1: 87.5000 (90.0500)  Acc@5: 100.0000 (99.6000)
2024-04-02 01:23:27,677 - train - INFO - Train: 11 [   0/195 (  0%)]  Loss:  1.753889 (1.7539)  Time: 3.447s,   74.27/s  (3.447s,   74.27/s)  LR: 5.429e-04  Data: 0.520 (0.520)
2024-04-02 01:25:53,636 - train - INFO - Train: 11 [  50/195 ( 26%)]  Loss:  1.855975 (1.6873)  Time: 2.875s,   89.06/s  (2.929s,   87.39/s)  LR: 5.429e-04  Data: 0.005 (0.025)
2024-04-02 01:28:22,232 - train - INFO - Train: 11 [ 100/195 ( 52%)]  Loss:  1.911837 (1.6799)  Time: 2.768s,   92.48/s  (2.950s,   86.77/s)  LR: 5.429e-04  Data: 0.037 (0.020)
2024-04-02 01:30:49,535 - train - INFO - Train: 11 [ 150/195 ( 77%)]  Loss:  1.498104 (1.6801)  Time: 3.435s,   74.52/s  (2.949s,   86.81/s)  LR: 5.429e-04  Data: 0.006 (0.018)
2024-04-02 01:33:01,406 - train - INFO - Train: 11 [ 194/195 (100%)]  Loss:  1.415634 (1.6759)  Time: 3.005s,   85.20/s  (2.960s,   86.49/s)  LR: 5.429e-04  Data: 0.000 (0.018)
2024-04-02 01:33:01,420 - train - INFO - True
2024-04-02 01:33:01,421 - train - INFO - alphas:tensor([0.4325, 0.5675], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,421 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,421 - train - INFO - True
2024-04-02 01:33:01,422 - train - INFO - alphas:tensor([0.4777, 0.5223], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,422 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,422 - train - INFO - True
2024-04-02 01:33:01,423 - train - INFO - alphas:tensor([0.6404, 0.3596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,423 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,423 - train - INFO - True
2024-04-02 01:33:01,428 - train - INFO - alphas:tensor([0.6416, 0.3584], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,428 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,428 - train - INFO - True
2024-04-02 01:33:01,429 - train - INFO - alphas:tensor([0.5302, 0.4698], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,429 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,429 - train - INFO - True
2024-04-02 01:33:01,430 - train - INFO - alphas:tensor([0.5891, 0.4109], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,430 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,430 - train - INFO - True
2024-04-02 01:33:01,431 - train - INFO - alphas:tensor([0.6658, 0.3342], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,431 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,440 - train - INFO - True
2024-04-02 01:33:01,440 - train - INFO - alphas:tensor([0.6491, 0.3509], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,440 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,441 - train - INFO - True
2024-04-02 01:33:01,441 - train - INFO - alphas:tensor([0.5743, 0.4257], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,441 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,441 - train - INFO - True
2024-04-02 01:33:01,442 - train - INFO - alphas:tensor([0.6310, 0.3690], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,442 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,442 - train - INFO - True
2024-04-02 01:33:01,443 - train - INFO - alphas:tensor([0.6600, 0.3400], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,443 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,443 - train - INFO - True
2024-04-02 01:33:01,444 - train - INFO - alphas:tensor([0.6555, 0.3445], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,444 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,444 - train - INFO - True
2024-04-02 01:33:01,445 - train - INFO - alphas:tensor([0.5768, 0.4232], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,445 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,445 - train - INFO - True
2024-04-02 01:33:01,445 - train - INFO - alphas:tensor([0.6220, 0.3780], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,446 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,446 - train - INFO - True
2024-04-02 01:33:01,446 - train - INFO - alphas:tensor([0.6549, 0.3451], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,446 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,446 - train - INFO - True
2024-04-02 01:33:01,447 - train - INFO - alphas:tensor([0.6373, 0.3627], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,447 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,447 - train - INFO - True
2024-04-02 01:33:01,448 - train - INFO - alphas:tensor([0.5643, 0.4357], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,448 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,448 - train - INFO - True
2024-04-02 01:33:01,449 - train - INFO - alphas:tensor([0.5860, 0.4140], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,449 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,449 - train - INFO - True
2024-04-02 01:33:01,449 - train - INFO - alphas:tensor([0.6241, 0.3759], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,450 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,450 - train - INFO - True
2024-04-02 01:33:01,450 - train - INFO - alphas:tensor([0.5811, 0.4189], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,450 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,450 - train - INFO - True
2024-04-02 01:33:01,451 - train - INFO - alphas:tensor([0.5400, 0.4600], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,451 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,451 - train - INFO - True
2024-04-02 01:33:01,452 - train - INFO - alphas:tensor([0.5685, 0.4315], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,452 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,456 - train - INFO - True
2024-04-02 01:33:01,457 - train - INFO - alphas:tensor([0.6048, 0.3952], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,457 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,457 - train - INFO - True
2024-04-02 01:33:01,458 - train - INFO - alphas:tensor([0.5461, 0.4539], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,458 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,458 - train - INFO - True
2024-04-02 01:33:01,459 - train - INFO - alphas:tensor([0.5205, 0.4795], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,459 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,459 - train - INFO - True
2024-04-02 01:33:01,460 - train - INFO - alphas:tensor([0.5453, 0.4547], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,460 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,460 - train - INFO - True
2024-04-02 01:33:01,460 - train - INFO - alphas:tensor([0.5357, 0.4643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,461 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,461 - train - INFO - True
2024-04-02 01:33:01,461 - train - INFO - alphas:tensor([0.4781, 0.5219], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,461 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,461 - train - INFO - True
2024-04-02 01:33:01,462 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:33:01,462 - train - INFO - tau:0.9135172474836407
2024-04-02 01:33:01,462 - train - INFO - avg block size:2.5517241379310347
2024-04-02 01:33:03,378 - train - INFO - Test: [   0/39]  Time: 1.912 (1.912)  Loss:  0.4441 (0.4441)  Acc@1: 89.8438 (89.8438)  Acc@5: 99.6094 (99.6094)
2024-04-02 01:34:13,627 - train - INFO - Test: [  39/39]  Time: 1.873 (1.804)  Loss:  0.4939 (0.4163)  Acc@1: 81.2500 (90.3700)  Acc@5: 100.0000 (99.6700)
2024-04-02 01:34:17,102 - train - INFO - Train: 12 [   0/195 (  0%)]  Loss:  1.530757 (1.5308)  Time: 3.273s,   78.21/s  (3.273s,   78.21/s)  LR: 5.415e-04  Data: 0.292 (0.292)
2024-04-02 01:36:45,080 - train - INFO - Train: 12 [  50/195 ( 26%)]  Loss:  1.888273 (1.6789)  Time: 2.961s,   86.45/s  (2.966s,   86.32/s)  LR: 5.415e-04  Data: 0.016 (0.020)
2024-04-02 01:39:11,798 - train - INFO - Train: 12 [ 100/195 ( 52%)]  Loss:  1.904220 (1.6864)  Time: 2.858s,   89.58/s  (2.950s,   86.78/s)  LR: 5.415e-04  Data: 0.018 (0.018)
2024-04-02 01:41:37,168 - train - INFO - Train: 12 [ 150/195 ( 77%)]  Loss:  1.725486 (1.6874)  Time: 2.864s,   89.39/s  (2.936s,   87.19/s)  LR: 5.415e-04  Data: 0.010 (0.016)
2024-04-02 01:43:47,462 - train - INFO - Train: 12 [ 194/195 (100%)]  Loss:  1.585172 (1.6731)  Time: 2.825s,   90.63/s  (2.942s,   87.03/s)  LR: 5.415e-04  Data: 0.000 (0.016)
2024-04-02 01:43:47,467 - train - INFO - True
2024-04-02 01:43:47,468 - train - INFO - alphas:tensor([0.4117, 0.5883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,468 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,469 - train - INFO - True
2024-04-02 01:43:47,469 - train - INFO - alphas:tensor([0.4621, 0.5379], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,474 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,474 - train - INFO - True
2024-04-02 01:43:47,475 - train - INFO - alphas:tensor([0.6443, 0.3557], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,475 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,475 - train - INFO - True
2024-04-02 01:43:47,476 - train - INFO - alphas:tensor([0.6439, 0.3561], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,476 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,476 - train - INFO - True
2024-04-02 01:43:47,477 - train - INFO - alphas:tensor([0.5192, 0.4808], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,477 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,477 - train - INFO - True
2024-04-02 01:43:47,478 - train - INFO - alphas:tensor([0.5851, 0.4149], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,478 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,478 - train - INFO - True
2024-04-02 01:43:47,478 - train - INFO - alphas:tensor([0.6731, 0.3269], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,479 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,479 - train - INFO - True
2024-04-02 01:43:47,479 - train - INFO - alphas:tensor([0.6528, 0.3472], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,479 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,479 - train - INFO - True
2024-04-02 01:43:47,480 - train - INFO - alphas:tensor([0.5649, 0.4351], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,480 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,480 - train - INFO - True
2024-04-02 01:43:47,481 - train - INFO - alphas:tensor([0.6308, 0.3692], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,481 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,481 - train - INFO - True
2024-04-02 01:43:47,482 - train - INFO - alphas:tensor([0.6675, 0.3325], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,482 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,482 - train - INFO - True
2024-04-02 01:43:47,483 - train - INFO - alphas:tensor([0.6578, 0.3422], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,483 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,483 - train - INFO - True
2024-04-02 01:43:47,483 - train - INFO - alphas:tensor([0.5738, 0.4262], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,484 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,484 - train - INFO - True
2024-04-02 01:43:47,493 - train - INFO - alphas:tensor([0.6245, 0.3755], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,493 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,493 - train - INFO - True
2024-04-02 01:43:47,494 - train - INFO - alphas:tensor([0.6603, 0.3397], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,494 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,494 - train - INFO - True
2024-04-02 01:43:47,495 - train - INFO - alphas:tensor([0.6333, 0.3667], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,495 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,495 - train - INFO - True
2024-04-02 01:43:47,496 - train - INFO - alphas:tensor([0.5572, 0.4428], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,496 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,496 - train - INFO - True
2024-04-02 01:43:47,496 - train - INFO - alphas:tensor([0.5842, 0.4158], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,496 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,496 - train - INFO - True
2024-04-02 01:43:47,497 - train - INFO - alphas:tensor([0.6275, 0.3725], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,497 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,497 - train - INFO - True
2024-04-02 01:43:47,498 - train - INFO - alphas:tensor([0.5680, 0.4320], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,498 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,498 - train - INFO - True
2024-04-02 01:43:47,499 - train - INFO - alphas:tensor([0.5325, 0.4675], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,499 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,499 - train - INFO - True
2024-04-02 01:43:47,500 - train - INFO - alphas:tensor([0.5667, 0.4333], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,500 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,500 - train - INFO - True
2024-04-02 01:43:47,500 - train - INFO - alphas:tensor([0.6060, 0.3940], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,501 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,501 - train - INFO - True
2024-04-02 01:43:47,501 - train - INFO - alphas:tensor([0.5308, 0.4692], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,501 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,501 - train - INFO - True
2024-04-02 01:43:47,502 - train - INFO - alphas:tensor([0.5109, 0.4891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,502 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,502 - train - INFO - True
2024-04-02 01:43:47,503 - train - INFO - alphas:tensor([0.5415, 0.4585], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,503 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,512 - train - INFO - True
2024-04-02 01:43:47,513 - train - INFO - alphas:tensor([0.5194, 0.4806], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,513 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,513 - train - INFO - True
2024-04-02 01:43:47,513 - train - INFO - alphas:tensor([0.4566, 0.5434], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,513 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,514 - train - INFO - True
2024-04-02 01:43:47,514 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:43:47,514 - train - INFO - tau:0.9043820750088043
2024-04-02 01:43:47,514 - train - INFO - avg block size:2.5517241379310347
2024-04-02 01:43:47,514 - train - INFO - lasso_alpha:2.9282000000000012e-05
2024-04-02 01:43:49,463 - train - INFO - Test: [   0/39]  Time: 1.945 (1.945)  Loss:  0.4189 (0.4189)  Acc@1: 91.0156 (91.0156)  Acc@5: 99.6094 (99.6094)
2024-04-02 01:44:59,389 - train - INFO - Test: [  39/39]  Time: 1.687 (1.797)  Loss:  0.5610 (0.4069)  Acc@1: 87.5000 (90.3700)  Acc@5: 100.0000 (99.6600)
2024-04-02 01:45:03,363 - train - INFO - Train: 13 [   0/195 (  0%)]  Loss:  1.773443 (1.7734)  Time: 3.776s,   67.79/s  (3.776s,   67.79/s)  LR: 5.401e-04  Data: 0.313 (0.313)
2024-04-02 01:47:32,657 - train - INFO - Train: 13 [  50/195 ( 26%)]  Loss:  1.606025 (1.7136)  Time: 3.136s,   81.63/s  (3.001s,   85.30/s)  LR: 5.401e-04  Data: 0.006 (0.019)
2024-04-02 01:50:02,048 - train - INFO - Train: 13 [ 100/195 ( 52%)]  Loss:  1.874730 (1.7189)  Time: 2.963s,   86.41/s  (2.995s,   85.49/s)  LR: 5.401e-04  Data: 0.009 (0.016)
2024-04-02 01:52:28,845 - train - INFO - Train: 13 [ 150/195 ( 77%)]  Loss:  1.960663 (1.7094)  Time: 2.783s,   91.99/s  (2.975s,   86.05/s)  LR: 5.401e-04  Data: 0.028 (0.015)
2024-04-02 01:54:40,441 - train - INFO - Train: 13 [ 194/195 (100%)]  Loss:  1.578751 (1.7109)  Time: 2.710s,   94.45/s  (2.979s,   85.95/s)  LR: 5.401e-04  Data: 0.000 (0.015)
2024-04-02 01:54:40,446 - train - INFO - True
2024-04-02 01:54:40,447 - train - INFO - alphas:tensor([0.3917, 0.6083], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,447 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,447 - train - INFO - True
2024-04-02 01:54:40,448 - train - INFO - alphas:tensor([0.4484, 0.5516], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,448 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,448 - train - INFO - True
2024-04-02 01:54:40,449 - train - INFO - alphas:tensor([0.6455, 0.3545], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,449 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,450 - train - INFO - True
2024-04-02 01:54:40,451 - train - INFO - alphas:tensor([0.6440, 0.3560], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,451 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,451 - train - INFO - True
2024-04-02 01:54:40,455 - train - INFO - alphas:tensor([0.5052, 0.4948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,455 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,455 - train - INFO - True
2024-04-02 01:54:40,456 - train - INFO - alphas:tensor([0.5805, 0.4195], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,456 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,456 - train - INFO - True
2024-04-02 01:54:40,457 - train - INFO - alphas:tensor([0.6766, 0.3234], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,469 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,469 - train - INFO - True
2024-04-02 01:54:40,469 - train - INFO - alphas:tensor([0.6512, 0.3488], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,469 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,469 - train - INFO - True
2024-04-02 01:54:40,470 - train - INFO - alphas:tensor([0.5560, 0.4440], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,470 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,470 - train - INFO - True
2024-04-02 01:54:40,471 - train - INFO - alphas:tensor([0.6290, 0.3710], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,472 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,473 - train - INFO - True
2024-04-02 01:54:40,473 - train - INFO - alphas:tensor([0.6720, 0.3280], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,478 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,478 - train - INFO - True
2024-04-02 01:54:40,478 - train - INFO - alphas:tensor([0.6560, 0.3440], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,479 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,479 - train - INFO - True
2024-04-02 01:54:40,479 - train - INFO - alphas:tensor([0.5645, 0.4355], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,479 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,479 - train - INFO - True
2024-04-02 01:54:40,480 - train - INFO - alphas:tensor([0.6221, 0.3779], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,480 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,480 - train - INFO - True
2024-04-02 01:54:40,481 - train - INFO - alphas:tensor([0.6630, 0.3370], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,481 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,481 - train - INFO - True
2024-04-02 01:54:40,482 - train - INFO - alphas:tensor([0.6231, 0.3769], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,482 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,482 - train - INFO - True
2024-04-02 01:54:40,483 - train - INFO - alphas:tensor([0.5489, 0.4511], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,483 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,483 - train - INFO - True
2024-04-02 01:54:40,483 - train - INFO - alphas:tensor([0.5794, 0.4206], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,484 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,484 - train - INFO - True
2024-04-02 01:54:40,484 - train - INFO - alphas:tensor([0.6262, 0.3738], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,484 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,484 - train - INFO - True
2024-04-02 01:54:40,485 - train - INFO - alphas:tensor([0.5478, 0.4522], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,485 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,485 - train - INFO - True
2024-04-02 01:54:40,490 - train - INFO - alphas:tensor([0.5226, 0.4774], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,490 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,490 - train - INFO - True
2024-04-02 01:54:40,491 - train - INFO - alphas:tensor([0.5623, 0.4377], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,491 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,491 - train - INFO - True
2024-04-02 01:54:40,496 - train - INFO - alphas:tensor([0.6031, 0.3969], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,497 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,497 - train - INFO - True
2024-04-02 01:54:40,497 - train - INFO - alphas:tensor([0.5090, 0.4910], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,497 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,497 - train - INFO - True
2024-04-02 01:54:40,498 - train - INFO - alphas:tensor([0.4962, 0.5038], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,498 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,498 - train - INFO - True
2024-04-02 01:54:40,499 - train - INFO - alphas:tensor([0.5341, 0.4659], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,499 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,499 - train - INFO - True
2024-04-02 01:54:40,500 - train - INFO - alphas:tensor([0.4976, 0.5024], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,500 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,500 - train - INFO - True
2024-04-02 01:54:40,501 - train - INFO - alphas:tensor([0.4292, 0.5708], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,501 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,501 - train - INFO - True
2024-04-02 01:54:40,501 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 01:54:40,501 - train - INFO - tau:0.8953382542587163
2024-04-02 01:54:40,502 - train - INFO - avg block size:3.586206896551724
2024-04-02 01:54:42,422 - train - INFO - Test: [   0/39]  Time: 1.908 (1.908)  Loss:  0.4526 (0.4526)  Acc@1: 90.2344 (90.2344)  Acc@5: 99.6094 (99.6094)
2024-04-02 01:55:52,950 - train - INFO - Test: [  39/39]  Time: 1.826 (1.811)  Loss:  0.6089 (0.4396)  Acc@1: 81.2500 (90.4100)  Acc@5: 100.0000 (99.6300)
2024-04-02 01:55:56,594 - train - INFO - Train: 14 [   0/195 (  0%)]  Loss:  1.689013 (1.6890)  Time: 3.460s,   74.00/s  (3.460s,   74.00/s)  LR: 5.385e-04  Data: 0.341 (0.341)
2024-04-02 01:58:24,463 - train - INFO - Train: 14 [  50/195 ( 26%)]  Loss:  1.873407 (1.7285)  Time: 2.603s,   98.34/s  (2.967s,   86.28/s)  LR: 5.385e-04  Data: 0.014 (0.021)
2024-04-02 02:00:55,249 - train - INFO - Train: 14 [ 100/195 ( 52%)]  Loss:  1.747048 (1.6980)  Time: 3.242s,   78.95/s  (2.991s,   85.58/s)  LR: 5.385e-04  Data: 0.016 (0.019)
2024-04-02 02:03:21,859 - train - INFO - Train: 14 [ 150/195 ( 77%)]  Loss:  1.655563 (1.6974)  Time: 2.819s,   90.82/s  (2.972s,   86.15/s)  LR: 5.385e-04  Data: 0.005 (0.017)
2024-04-02 02:05:32,727 - train - INFO - Train: 14 [ 194/195 (100%)]  Loss:  2.022864 (1.6964)  Time: 3.384s,   75.66/s  (2.972s,   86.13/s)  LR: 5.385e-04  Data: 0.000 (0.016)
2024-04-02 02:05:32,728 - train - INFO - True
2024-04-02 02:05:32,729 - train - INFO - alphas:tensor([0.3724, 0.6276], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,729 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,729 - train - INFO - True
2024-04-02 02:05:32,730 - train - INFO - alphas:tensor([0.4340, 0.5660], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,730 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,733 - train - INFO - True
2024-04-02 02:05:32,751 - train - INFO - alphas:tensor([0.6460, 0.3540], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,752 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,752 - train - INFO - True
2024-04-02 02:05:32,752 - train - INFO - alphas:tensor([0.6417, 0.3583], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,752 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,752 - train - INFO - True
2024-04-02 02:05:32,753 - train - INFO - alphas:tensor([0.4920, 0.5080], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,753 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,753 - train - INFO - True
2024-04-02 02:05:32,754 - train - INFO - alphas:tensor([0.5755, 0.4245], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,754 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,754 - train - INFO - True
2024-04-02 02:05:32,755 - train - INFO - alphas:tensor([0.6800, 0.3200], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,759 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,759 - train - INFO - True
2024-04-02 02:05:32,760 - train - INFO - alphas:tensor([0.6486, 0.3514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,760 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,760 - train - INFO - True
2024-04-02 02:05:32,779 - train - INFO - alphas:tensor([0.5454, 0.4546], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,779 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,779 - train - INFO - True
2024-04-02 02:05:32,779 - train - INFO - alphas:tensor([0.6269, 0.3731], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,779 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,780 - train - INFO - True
2024-04-02 02:05:32,780 - train - INFO - alphas:tensor([0.6753, 0.3247], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,780 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,780 - train - INFO - True
2024-04-02 02:05:32,781 - train - INFO - alphas:tensor([0.6525, 0.3475], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,781 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,781 - train - INFO - True
2024-04-02 02:05:32,782 - train - INFO - alphas:tensor([0.5568, 0.4432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,782 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,782 - train - INFO - True
2024-04-02 02:05:32,783 - train - INFO - alphas:tensor([0.6214, 0.3786], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,787 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,787 - train - INFO - True
2024-04-02 02:05:32,797 - train - INFO - alphas:tensor([0.6634, 0.3366], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,801 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,801 - train - INFO - True
2024-04-02 02:05:32,802 - train - INFO - alphas:tensor([0.6103, 0.3897], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,802 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,802 - train - INFO - True
2024-04-02 02:05:32,803 - train - INFO - alphas:tensor([0.5373, 0.4627], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,803 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,803 - train - INFO - True
2024-04-02 02:05:32,804 - train - INFO - alphas:tensor([0.5728, 0.4272], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,804 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,804 - train - INFO - True
2024-04-02 02:05:32,804 - train - INFO - alphas:tensor([0.6245, 0.3755], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,804 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,805 - train - INFO - True
2024-04-02 02:05:32,805 - train - INFO - alphas:tensor([0.5284, 0.4716], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,805 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,805 - train - INFO - True
2024-04-02 02:05:32,806 - train - INFO - alphas:tensor([0.5123, 0.4877], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,806 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,806 - train - INFO - True
2024-04-02 02:05:32,807 - train - INFO - alphas:tensor([0.5568, 0.4432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,807 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,807 - train - INFO - True
2024-04-02 02:05:32,831 - train - INFO - alphas:tensor([0.5981, 0.4019], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,831 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,831 - train - INFO - True
2024-04-02 02:05:32,832 - train - INFO - alphas:tensor([0.4861, 0.5139], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,835 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,835 - train - INFO - True
2024-04-02 02:05:32,836 - train - INFO - alphas:tensor([0.4831, 0.5169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,844 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,845 - train - INFO - True
2024-04-02 02:05:32,845 - train - INFO - alphas:tensor([0.5277, 0.4723], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,845 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,845 - train - INFO - True
2024-04-02 02:05:32,846 - train - INFO - alphas:tensor([0.4804, 0.5196], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,846 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,846 - train - INFO - True
2024-04-02 02:05:32,847 - train - INFO - alphas:tensor([0.4059, 0.5941], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,847 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,847 - train - INFO - True
2024-04-02 02:05:32,848 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:05:32,848 - train - INFO - tau:0.8863848717161291
2024-04-02 02:05:32,848 - train - INFO - avg block size:4.620689655172414
2024-04-02 02:05:32,848 - train - INFO - lasso_alpha:3.221020000000002e-05
2024-04-02 02:05:34,658 - train - INFO - Test: [   0/39]  Time: 1.807 (1.807)  Loss:  0.4121 (0.4121)  Acc@1: 90.2344 (90.2344)  Acc@5: 100.0000 (100.0000)
2024-04-02 02:06:44,605 - train - INFO - Test: [  39/39]  Time: 1.907 (1.794)  Loss:  0.4778 (0.4105)  Acc@1: 81.2500 (90.9800)  Acc@5: 100.0000 (99.6400)
2024-04-02 02:06:48,467 - train - INFO - Train: 15 [   0/195 (  0%)]  Loss:  2.026035 (2.0260)  Time: 3.540s,   72.31/s  (3.540s,   72.31/s)  LR: 5.368e-04  Data: 0.255 (0.255)
2024-04-02 02:09:17,519 - train - INFO - Train: 15 [  50/195 ( 26%)]  Loss:  1.775389 (1.6983)  Time: 3.121s,   82.03/s  (2.992s,   85.56/s)  LR: 5.368e-04  Data: 0.005 (0.021)
2024-04-02 02:11:44,462 - train - INFO - Train: 15 [ 100/195 ( 52%)]  Loss:  1.912816 (1.7251)  Time: 3.231s,   79.22/s  (2.966s,   86.32/s)  LR: 5.368e-04  Data: 0.017 (0.018)
2024-04-02 02:14:14,194 - train - INFO - Train: 15 [ 150/195 ( 77%)]  Loss:  1.582267 (1.7287)  Time: 2.951s,   86.74/s  (2.975s,   86.04/s)  LR: 5.368e-04  Data: 0.008 (0.017)
2024-04-02 02:16:24,860 - train - INFO - Train: 15 [ 194/195 (100%)]  Loss:  1.501851 (1.7274)  Time: 2.644s,   96.83/s  (2.974s,   86.08/s)  LR: 5.368e-04  Data: 0.000 (0.017)
2024-04-02 02:16:24,865 - train - INFO - True
2024-04-02 02:16:24,868 - train - INFO - alphas:tensor([0.3517, 0.6483], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,868 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,868 - train - INFO - True
2024-04-02 02:16:24,869 - train - INFO - alphas:tensor([0.4171, 0.5829], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,869 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,869 - train - INFO - True
2024-04-02 02:16:24,870 - train - INFO - alphas:tensor([0.6461, 0.3539], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,870 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,870 - train - INFO - True
2024-04-02 02:16:24,870 - train - INFO - alphas:tensor([0.6398, 0.3602], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,871 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,871 - train - INFO - True
2024-04-02 02:16:24,871 - train - INFO - alphas:tensor([0.4740, 0.5260], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,871 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,872 - train - INFO - True
2024-04-02 02:16:24,872 - train - INFO - alphas:tensor([0.5656, 0.4344], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,872 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,872 - train - INFO - True
2024-04-02 02:16:24,873 - train - INFO - alphas:tensor([0.6813, 0.3187], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,874 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,874 - train - INFO - True
2024-04-02 02:16:24,874 - train - INFO - alphas:tensor([0.6443, 0.3557], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,875 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,875 - train - INFO - True
2024-04-02 02:16:24,875 - train - INFO - alphas:tensor([0.5335, 0.4665], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,875 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,875 - train - INFO - True
2024-04-02 02:16:24,876 - train - INFO - alphas:tensor([0.6231, 0.3769], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,876 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,876 - train - INFO - True
2024-04-02 02:16:24,881 - train - INFO - alphas:tensor([0.6772, 0.3228], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,881 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,882 - train - INFO - True
2024-04-02 02:16:24,882 - train - INFO - alphas:tensor([0.6457, 0.3543], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,882 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,882 - train - INFO - True
2024-04-02 02:16:24,883 - train - INFO - alphas:tensor([0.5431, 0.4569], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,883 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,883 - train - INFO - True
2024-04-02 02:16:24,884 - train - INFO - alphas:tensor([0.6135, 0.3865], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,884 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,884 - train - INFO - True
2024-04-02 02:16:24,885 - train - INFO - alphas:tensor([0.6618, 0.3382], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,885 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,885 - train - INFO - True
2024-04-02 02:16:24,885 - train - INFO - alphas:tensor([0.5932, 0.4068], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,886 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,886 - train - INFO - True
2024-04-02 02:16:24,886 - train - INFO - alphas:tensor([0.5265, 0.4735], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,886 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,886 - train - INFO - True
2024-04-02 02:16:24,887 - train - INFO - alphas:tensor([0.5651, 0.4349], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,887 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,887 - train - INFO - True
2024-04-02 02:16:24,888 - train - INFO - alphas:tensor([0.6186, 0.3814], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,888 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,888 - train - INFO - True
2024-04-02 02:16:24,889 - train - INFO - alphas:tensor([0.5011, 0.4989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,889 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,889 - train - INFO - True
2024-04-02 02:16:24,890 - train - INFO - alphas:tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,890 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,890 - train - INFO - True
2024-04-02 02:16:24,890 - train - INFO - alphas:tensor([0.5486, 0.4514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,891 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,891 - train - INFO - True
2024-04-02 02:16:24,891 - train - INFO - alphas:tensor([0.5901, 0.4099], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,891 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,891 - train - INFO - True
2024-04-02 02:16:24,892 - train - INFO - alphas:tensor([0.4596, 0.5404], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,892 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,892 - train - INFO - True
2024-04-02 02:16:24,893 - train - INFO - alphas:tensor([0.4653, 0.5347], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,893 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,893 - train - INFO - True
2024-04-02 02:16:24,894 - train - INFO - alphas:tensor([0.5170, 0.4830], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,894 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,894 - train - INFO - True
2024-04-02 02:16:24,899 - train - INFO - alphas:tensor([0.4567, 0.5433], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,899 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,899 - train - INFO - True
2024-04-02 02:16:24,900 - train - INFO - alphas:tensor([0.3769, 0.6231], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,900 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,900 - train - INFO - True
2024-04-02 02:16:24,901 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:16:24,901 - train - INFO - tau:0.8775210229989678
2024-04-02 02:16:24,901 - train - INFO - avg block size:4.620689655172414
2024-04-02 02:16:26,803 - train - INFO - Test: [   0/39]  Time: 1.895 (1.895)  Loss:  0.4358 (0.4358)  Acc@1: 89.4531 (89.4531)  Acc@5: 100.0000 (100.0000)
2024-04-02 02:17:37,125 - train - INFO - Test: [  39/39]  Time: 1.805 (1.805)  Loss:  0.4526 (0.4096)  Acc@1: 87.5000 (91.0000)  Acc@5: 100.0000 (99.6400)
2024-04-02 02:17:40,817 - train - INFO - Train: 16 [   0/195 (  0%)]  Loss:  1.590905 (1.5909)  Time: 3.326s,   76.97/s  (3.326s,   76.97/s)  LR: 5.350e-04  Data: 0.351 (0.351)
2024-04-02 02:20:08,904 - train - INFO - Train: 16 [  50/195 ( 26%)]  Loss:  1.624926 (1.7244)  Time: 3.038s,   84.26/s  (2.969s,   86.23/s)  LR: 5.350e-04  Data: 0.014 (0.022)
2024-04-02 02:22:36,622 - train - INFO - Train: 16 [ 100/195 ( 52%)]  Loss:  1.674907 (1.7529)  Time: 3.136s,   81.63/s  (2.962s,   86.44/s)  LR: 5.350e-04  Data: 0.005 (0.019)
2024-04-02 02:25:07,346 - train - INFO - Train: 16 [ 150/195 ( 77%)]  Loss:  1.553959 (1.7464)  Time: 3.148s,   81.33/s  (2.979s,   85.93/s)  LR: 5.350e-04  Data: 0.005 (0.018)
2024-04-02 02:27:16,917 - train - INFO - Train: 16 [ 194/195 (100%)]  Loss:  1.679289 (1.7461)  Time: 2.457s,  104.18/s  (2.971s,   86.16/s)  LR: 5.350e-04  Data: 0.000 (0.017)
2024-04-02 02:27:16,917 - train - INFO - True
2024-04-02 02:27:16,918 - train - INFO - alphas:tensor([0.3322, 0.6678], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,918 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,918 - train - INFO - True
2024-04-02 02:27:16,919 - train - INFO - alphas:tensor([0.4003, 0.5997], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,919 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,919 - train - INFO - True
2024-04-02 02:27:16,920 - train - INFO - alphas:tensor([0.6452, 0.3548], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,920 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,920 - train - INFO - True
2024-04-02 02:27:16,921 - train - INFO - alphas:tensor([0.6365, 0.3635], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,921 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,921 - train - INFO - True
2024-04-02 02:27:16,922 - train - INFO - alphas:tensor([0.4607, 0.5393], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,922 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,922 - train - INFO - True
2024-04-02 02:27:16,922 - train - INFO - alphas:tensor([0.5591, 0.4409], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,922 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,923 - train - INFO - True
2024-04-02 02:27:16,923 - train - INFO - alphas:tensor([0.6812, 0.3188], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,923 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,923 - train - INFO - True
2024-04-02 02:27:16,924 - train - INFO - alphas:tensor([0.6388, 0.3612], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,924 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,925 - train - INFO - True
2024-04-02 02:27:16,925 - train - INFO - alphas:tensor([0.5232, 0.4768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,925 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,925 - train - INFO - True
2024-04-02 02:27:16,926 - train - INFO - alphas:tensor([0.6190, 0.3810], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,926 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,926 - train - INFO - True
2024-04-02 02:27:16,927 - train - INFO - alphas:tensor([0.6786, 0.3214], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,927 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,927 - train - INFO - True
2024-04-02 02:27:16,928 - train - INFO - alphas:tensor([0.6371, 0.3629], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,928 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,928 - train - INFO - True
2024-04-02 02:27:16,929 - train - INFO - alphas:tensor([0.5327, 0.4673], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,929 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,929 - train - INFO - True
2024-04-02 02:27:16,929 - train - INFO - alphas:tensor([0.6086, 0.3914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,929 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,930 - train - INFO - True
2024-04-02 02:27:16,930 - train - INFO - alphas:tensor([0.6609, 0.3391], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,930 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,930 - train - INFO - True
2024-04-02 02:27:16,931 - train - INFO - alphas:tensor([0.5804, 0.4196], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,931 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,931 - train - INFO - True
2024-04-02 02:27:16,932 - train - INFO - alphas:tensor([0.5160, 0.4840], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,932 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,932 - train - INFO - True
2024-04-02 02:27:16,933 - train - INFO - alphas:tensor([0.5569, 0.4431], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,933 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,933 - train - INFO - True
2024-04-02 02:27:16,933 - train - INFO - alphas:tensor([0.6147, 0.3853], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,934 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,934 - train - INFO - True
2024-04-02 02:27:16,934 - train - INFO - alphas:tensor([0.4817, 0.5183], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,934 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,934 - train - INFO - True
2024-04-02 02:27:16,935 - train - INFO - alphas:tensor([0.4880, 0.5120], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,935 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,935 - train - INFO - True
2024-04-02 02:27:16,936 - train - INFO - alphas:tensor([0.5394, 0.4606], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,936 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,936 - train - INFO - True
2024-04-02 02:27:16,937 - train - INFO - alphas:tensor([0.5825, 0.4175], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,937 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,937 - train - INFO - True
2024-04-02 02:27:16,938 - train - INFO - alphas:tensor([0.4387, 0.5613], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,938 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,938 - train - INFO - True
2024-04-02 02:27:16,938 - train - INFO - alphas:tensor([0.4523, 0.5477], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,938 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,938 - train - INFO - True
2024-04-02 02:27:16,939 - train - INFO - alphas:tensor([0.5075, 0.4925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,939 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,939 - train - INFO - True
2024-04-02 02:27:16,940 - train - INFO - alphas:tensor([0.4339, 0.5661], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,940 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,940 - train - INFO - True
2024-04-02 02:27:16,941 - train - INFO - alphas:tensor([0.3473, 0.6527], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,941 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,941 - train - INFO - True
2024-04-02 02:27:16,942 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:27:16,942 - train - INFO - tau:0.8687458127689781
2024-04-02 02:27:16,942 - train - INFO - avg block size:5.655172413793103
2024-04-02 02:27:16,942 - train - INFO - lasso_alpha:3.543122000000002e-05
2024-04-02 02:27:18,730 - train - INFO - Test: [   0/39]  Time: 1.785 (1.785)  Loss:  0.4055 (0.4055)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-04-02 02:28:29,279 - train - INFO - Test: [  39/39]  Time: 1.821 (1.808)  Loss:  0.4001 (0.4055)  Acc@1: 87.5000 (90.9800)  Acc@5: 100.0000 (99.7000)
2024-04-02 02:28:33,300 - train - INFO - Train: 17 [   0/195 (  0%)]  Loss:  1.941959 (1.9420)  Time: 3.812s,   67.16/s  (3.812s,   67.16/s)  LR: 5.331e-04  Data: 0.303 (0.303)
2024-04-02 02:31:02,726 - train - INFO - Train: 17 [  50/195 ( 26%)]  Loss:  1.704225 (1.7567)  Time: 2.862s,   89.45/s  (3.005s,   85.20/s)  LR: 5.331e-04  Data: 0.005 (0.021)
2024-04-02 02:33:29,400 - train - INFO - Train: 17 [ 100/195 ( 52%)]  Loss:  1.399138 (1.7123)  Time: 3.004s,   85.21/s  (2.969s,   86.21/s)  LR: 5.331e-04  Data: 0.022 (0.017)
2024-04-02 02:35:58,748 - train - INFO - Train: 17 [ 150/195 ( 77%)]  Loss:  1.815796 (1.7230)  Time: 3.002s,   85.27/s  (2.975s,   86.05/s)  LR: 5.331e-04  Data: 0.005 (0.016)
2024-04-02 02:38:09,200 - train - INFO - Train: 17 [ 194/195 (100%)]  Loss:  1.659447 (1.7292)  Time: 2.926s,   87.50/s  (2.973s,   86.12/s)  LR: 5.331e-04  Data: 0.000 (0.016)
2024-04-02 02:38:09,204 - train - INFO - True
2024-04-02 02:38:09,205 - train - INFO - alphas:tensor([0.3136, 0.6864], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,205 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,205 - train - INFO - True
2024-04-02 02:38:09,206 - train - INFO - alphas:tensor([0.3840, 0.6160], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,206 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,206 - train - INFO - True
2024-04-02 02:38:09,212 - train - INFO - alphas:tensor([0.6429, 0.3571], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,212 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,212 - train - INFO - True
2024-04-02 02:38:09,213 - train - INFO - alphas:tensor([0.6316, 0.3684], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,213 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,213 - train - INFO - True
2024-04-02 02:38:09,218 - train - INFO - alphas:tensor([0.4452, 0.5548], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,218 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,218 - train - INFO - True
2024-04-02 02:38:09,219 - train - INFO - alphas:tensor([0.5476, 0.4524], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,228 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,228 - train - INFO - True
2024-04-02 02:38:09,229 - train - INFO - alphas:tensor([0.6793, 0.3207], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,229 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,229 - train - INFO - True
2024-04-02 02:38:09,230 - train - INFO - alphas:tensor([0.6292, 0.3708], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,230 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,230 - train - INFO - True
2024-04-02 02:38:09,231 - train - INFO - alphas:tensor([0.5109, 0.4891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,231 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,231 - train - INFO - True
2024-04-02 02:38:09,232 - train - INFO - alphas:tensor([0.6134, 0.3866], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,232 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,232 - train - INFO - True
2024-04-02 02:38:09,233 - train - INFO - alphas:tensor([0.6762, 0.3238], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,233 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,233 - train - INFO - True
2024-04-02 02:38:09,234 - train - INFO - alphas:tensor([0.6246, 0.3754], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,234 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,234 - train - INFO - True
2024-04-02 02:38:09,235 - train - INFO - alphas:tensor([0.5244, 0.4756], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,235 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,235 - train - INFO - True
2024-04-02 02:38:09,236 - train - INFO - alphas:tensor([0.6046, 0.3954], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,236 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,236 - train - INFO - True
2024-04-02 02:38:09,237 - train - INFO - alphas:tensor([0.6574, 0.3426], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,237 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,237 - train - INFO - True
2024-04-02 02:38:09,238 - train - INFO - alphas:tensor([0.5614, 0.4386], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,238 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,238 - train - INFO - True
2024-04-02 02:38:09,239 - train - INFO - alphas:tensor([0.5028, 0.4972], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,239 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,239 - train - INFO - True
2024-04-02 02:38:09,253 - train - INFO - alphas:tensor([0.5455, 0.4545], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,253 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,253 - train - INFO - True
2024-04-02 02:38:09,254 - train - INFO - alphas:tensor([0.6055, 0.3945], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,254 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,254 - train - INFO - True
2024-04-02 02:38:09,255 - train - INFO - alphas:tensor([0.4548, 0.5452], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,255 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,255 - train - INFO - True
2024-04-02 02:38:09,256 - train - INFO - alphas:tensor([0.4721, 0.5279], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,256 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,256 - train - INFO - True
2024-04-02 02:38:09,257 - train - INFO - alphas:tensor([0.5267, 0.4733], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,257 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,257 - train - INFO - True
2024-04-02 02:38:09,258 - train - INFO - alphas:tensor([0.5728, 0.4272], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,258 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,258 - train - INFO - True
2024-04-02 02:38:09,259 - train - INFO - alphas:tensor([0.4166, 0.5834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,259 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,259 - train - INFO - True
2024-04-02 02:38:09,260 - train - INFO - alphas:tensor([0.4357, 0.5643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,260 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,260 - train - INFO - True
2024-04-02 02:38:09,261 - train - INFO - alphas:tensor([0.4941, 0.5059], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,261 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,261 - train - INFO - True
2024-04-02 02:38:09,266 - train - INFO - alphas:tensor([0.4078, 0.5922], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,266 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,266 - train - INFO - True
2024-04-02 02:38:09,267 - train - INFO - alphas:tensor([0.3179, 0.6821], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,267 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,267 - train - INFO - True
2024-04-02 02:38:09,286 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:38:09,286 - train - INFO - tau:0.8600583546412883
2024-04-02 02:38:09,286 - train - INFO - avg block size:6.172413793103448
2024-04-02 02:38:11,173 - train - INFO - Test: [   0/39]  Time: 1.883 (1.883)  Loss:  0.4365 (0.4365)  Acc@1: 90.2344 (90.2344)  Acc@5: 99.6094 (99.6094)
2024-04-02 02:39:22,020 - train - INFO - Test: [  39/39]  Time: 1.837 (1.818)  Loss:  0.4141 (0.4100)  Acc@1: 81.2500 (91.4400)  Acc@5: 100.0000 (99.6800)
2024-04-02 02:39:25,348 - train - INFO - Train: 18 [   0/195 (  0%)]  Loss:  1.368229 (1.3682)  Time: 3.101s,   82.57/s  (3.101s,   82.57/s)  LR: 5.310e-04  Data: 0.451 (0.451)
2024-04-02 02:41:54,557 - train - INFO - Train: 18 [  50/195 ( 26%)]  Loss:  1.401048 (1.7104)  Time: 2.885s,   88.72/s  (2.986s,   85.72/s)  LR: 5.310e-04  Data: 0.022 (0.024)
2024-04-02 02:44:20,245 - train - INFO - Train: 18 [ 100/195 ( 52%)]  Loss:  1.932479 (1.6961)  Time: 2.612s,   98.00/s  (2.950s,   86.77/s)  LR: 5.310e-04  Data: 0.014 (0.019)
2024-04-02 02:46:47,087 - train - INFO - Train: 18 [ 150/195 ( 77%)]  Loss:  1.784868 (1.7018)  Time: 2.829s,   90.50/s  (2.946s,   86.90/s)  LR: 5.310e-04  Data: 0.014 (0.017)
2024-04-02 02:48:55,608 - train - INFO - Train: 18 [ 194/195 (100%)]  Loss:  1.360197 (1.7085)  Time: 2.758s,   92.84/s  (2.940s,   87.07/s)  LR: 5.310e-04  Data: 0.000 (0.016)
2024-04-02 02:48:55,608 - train - INFO - True
2024-04-02 02:48:55,609 - train - INFO - alphas:tensor([0.2935, 0.7065], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,610 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,610 - train - INFO - True
2024-04-02 02:48:55,610 - train - INFO - alphas:tensor([0.3650, 0.6350], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,610 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,611 - train - INFO - True
2024-04-02 02:48:55,611 - train - INFO - alphas:tensor([0.6397, 0.3603], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,611 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,611 - train - INFO - True
2024-04-02 02:48:55,612 - train - INFO - alphas:tensor([0.6245, 0.3755], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,612 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,612 - train - INFO - True
2024-04-02 02:48:55,613 - train - INFO - alphas:tensor([0.4318, 0.5682], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,613 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,613 - train - INFO - True
2024-04-02 02:48:55,614 - train - INFO - alphas:tensor([0.5396, 0.4604], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,614 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,614 - train - INFO - True
2024-04-02 02:48:55,614 - train - INFO - alphas:tensor([0.6775, 0.3225], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,615 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,623 - train - INFO - True
2024-04-02 02:48:55,624 - train - INFO - alphas:tensor([0.6209, 0.3791], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,625 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,625 - train - INFO - True
2024-04-02 02:48:55,630 - train - INFO - alphas:tensor([0.4998, 0.5002], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,630 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,630 - train - INFO - True
2024-04-02 02:48:55,631 - train - INFO - alphas:tensor([0.6062, 0.3938], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,631 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,631 - train - INFO - True
2024-04-02 02:48:55,632 - train - INFO - alphas:tensor([0.6749, 0.3251], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,632 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,632 - train - INFO - True
2024-04-02 02:48:55,632 - train - INFO - alphas:tensor([0.6121, 0.3879], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,633 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,633 - train - INFO - True
2024-04-02 02:48:55,633 - train - INFO - alphas:tensor([0.5115, 0.4885], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,633 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,633 - train - INFO - True
2024-04-02 02:48:55,634 - train - INFO - alphas:tensor([0.5962, 0.4038], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,634 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,634 - train - INFO - True
2024-04-02 02:48:55,635 - train - INFO - alphas:tensor([0.6523, 0.3477], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,635 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,635 - train - INFO - True
2024-04-02 02:48:55,636 - train - INFO - alphas:tensor([0.5429, 0.4571], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,636 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,636 - train - INFO - True
2024-04-02 02:48:55,637 - train - INFO - alphas:tensor([0.4914, 0.5086], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,637 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,637 - train - INFO - True
2024-04-02 02:48:55,637 - train - INFO - alphas:tensor([0.5366, 0.4634], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,638 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,638 - train - INFO - True
2024-04-02 02:48:55,643 - train - INFO - alphas:tensor([0.5971, 0.4029], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,643 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,643 - train - INFO - True
2024-04-02 02:48:55,644 - train - INFO - alphas:tensor([0.4329, 0.5671], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,644 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,644 - train - INFO - True
2024-04-02 02:48:55,644 - train - INFO - alphas:tensor([0.4573, 0.5427], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,644 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,645 - train - INFO - True
2024-04-02 02:48:55,645 - train - INFO - alphas:tensor([0.5156, 0.4844], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,645 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,645 - train - INFO - True
2024-04-02 02:48:55,655 - train - INFO - alphas:tensor([0.5627, 0.4373], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,655 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,655 - train - INFO - True
2024-04-02 02:48:55,656 - train - INFO - alphas:tensor([0.3959, 0.6041], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,656 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,656 - train - INFO - True
2024-04-02 02:48:55,656 - train - INFO - alphas:tensor([0.4173, 0.5827], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,657 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,657 - train - INFO - True
2024-04-02 02:48:55,657 - train - INFO - alphas:tensor([0.4786, 0.5214], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,657 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,657 - train - INFO - True
2024-04-02 02:48:55,658 - train - INFO - alphas:tensor([0.3847, 0.6153], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,658 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,658 - train - INFO - True
2024-04-02 02:48:55,663 - train - INFO - alphas:tensor([0.2904, 0.7096], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,663 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,664 - train - INFO - True
2024-04-02 02:48:55,664 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:48:55,664 - train - INFO - tau:0.8514577710948754
2024-04-02 02:48:55,664 - train - INFO - avg block size:7.206896551724138
2024-04-02 02:48:55,664 - train - INFO - lasso_alpha:3.8974342000000026e-05
2024-04-02 02:48:57,416 - train - INFO - Test: [   0/39]  Time: 1.750 (1.750)  Loss:  0.4280 (0.4280)  Acc@1: 89.0625 (89.0625)  Acc@5: 99.6094 (99.6094)
2024-04-02 02:50:07,877 - train - INFO - Test: [  39/39]  Time: 1.787 (1.805)  Loss:  0.4480 (0.4041)  Acc@1: 87.5000 (90.8200)  Acc@5: 100.0000 (99.7400)
2024-04-02 02:50:11,231 - train - INFO - Train: 19 [   0/195 (  0%)]  Loss:  1.886670 (1.8867)  Time: 3.156s,   81.11/s  (3.156s,   81.11/s)  LR: 5.289e-04  Data: 0.291 (0.291)
2024-04-02 02:52:41,386 - train - INFO - Train: 19 [  50/195 ( 26%)]  Loss:  1.536685 (1.7838)  Time: 3.036s,   84.32/s  (3.006s,   85.16/s)  LR: 5.289e-04  Data: 0.040 (0.020)
2024-04-02 02:55:06,252 - train - INFO - Train: 19 [ 100/195 ( 52%)]  Loss:  1.549279 (1.7733)  Time: 3.120s,   82.04/s  (2.952s,   86.71/s)  LR: 5.289e-04  Data: 0.023 (0.017)
2024-04-02 02:57:34,115 - train - INFO - Train: 19 [ 150/195 ( 77%)]  Loss:  1.928766 (1.7654)  Time: 3.438s,   74.46/s  (2.954s,   86.67/s)  LR: 5.289e-04  Data: 0.019 (0.017)
2024-04-02 02:59:42,796 - train - INFO - Train: 19 [ 194/195 (100%)]  Loss:  1.767791 (1.7664)  Time: 2.905s,   88.14/s  (2.947s,   86.86/s)  LR: 5.289e-04  Data: 0.000 (0.017)
2024-04-02 02:59:42,801 - train - INFO - True
2024-04-02 02:59:42,802 - train - INFO - alphas:tensor([0.2744, 0.7256], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,802 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,802 - train - INFO - True
2024-04-02 02:59:42,803 - train - INFO - alphas:tensor([0.3485, 0.6515], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,803 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,803 - train - INFO - True
2024-04-02 02:59:42,804 - train - INFO - alphas:tensor([0.6387, 0.3613], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,804 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,804 - train - INFO - True
2024-04-02 02:59:42,805 - train - INFO - alphas:tensor([0.6209, 0.3791], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,805 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,805 - train - INFO - True
2024-04-02 02:59:42,806 - train - INFO - alphas:tensor([0.4170, 0.5830], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,806 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,806 - train - INFO - True
2024-04-02 02:59:42,807 - train - INFO - alphas:tensor([0.5275, 0.4725], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,807 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,807 - train - INFO - True
2024-04-02 02:59:42,807 - train - INFO - alphas:tensor([0.6718, 0.3282], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,808 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,808 - train - INFO - True
2024-04-02 02:59:42,808 - train - INFO - alphas:tensor([0.6080, 0.3920], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,808 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,808 - train - INFO - True
2024-04-02 02:59:42,809 - train - INFO - alphas:tensor([0.4860, 0.5140], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,809 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,809 - train - INFO - True
2024-04-02 02:59:42,810 - train - INFO - alphas:tensor([0.5966, 0.4034], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,810 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,810 - train - INFO - True
2024-04-02 02:59:42,811 - train - INFO - alphas:tensor([0.6721, 0.3279], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,811 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,811 - train - INFO - True
2024-04-02 02:59:42,812 - train - INFO - alphas:tensor([0.5972, 0.4028], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,812 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,812 - train - INFO - True
2024-04-02 02:59:42,812 - train - INFO - alphas:tensor([0.4989, 0.5011], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,813 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,813 - train - INFO - True
2024-04-02 02:59:42,813 - train - INFO - alphas:tensor([0.5877, 0.4123], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,813 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,813 - train - INFO - True
2024-04-02 02:59:42,814 - train - INFO - alphas:tensor([0.6458, 0.3542], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,814 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,814 - train - INFO - True
2024-04-02 02:59:42,815 - train - INFO - alphas:tensor([0.5201, 0.4799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,815 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,815 - train - INFO - True
2024-04-02 02:59:42,816 - train - INFO - alphas:tensor([0.4785, 0.5215], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,816 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,816 - train - INFO - True
2024-04-02 02:59:42,817 - train - INFO - alphas:tensor([0.5231, 0.4769], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,817 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,817 - train - INFO - True
2024-04-02 02:59:42,817 - train - INFO - alphas:tensor([0.5841, 0.4159], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,818 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,818 - train - INFO - True
2024-04-02 02:59:42,818 - train - INFO - alphas:tensor([0.4092, 0.5908], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,818 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,818 - train - INFO - True
2024-04-02 02:59:42,819 - train - INFO - alphas:tensor([0.4433, 0.5567], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,819 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,819 - train - INFO - True
2024-04-02 02:59:42,820 - train - INFO - alphas:tensor([0.5036, 0.4964], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,820 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,820 - train - INFO - True
2024-04-02 02:59:42,821 - train - INFO - alphas:tensor([0.5485, 0.4515], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,821 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,821 - train - INFO - True
2024-04-02 02:59:42,822 - train - INFO - alphas:tensor([0.3734, 0.6266], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,822 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,822 - train - INFO - True
2024-04-02 02:59:42,822 - train - INFO - alphas:tensor([0.4005, 0.5995], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,823 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,823 - train - INFO - True
2024-04-02 02:59:42,823 - train - INFO - alphas:tensor([0.4615, 0.5385], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,823 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,823 - train - INFO - True
2024-04-02 02:59:42,828 - train - INFO - alphas:tensor([0.3579, 0.6421], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,829 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,829 - train - INFO - True
2024-04-02 02:59:42,829 - train - INFO - alphas:tensor([0.2606, 0.7394], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,829 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,829 - train - INFO - True
2024-04-02 02:59:42,830 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 02:59:42,830 - train - INFO - tau:0.8429431933839266
2024-04-02 02:59:42,830 - train - INFO - avg block size:7.724137931034483
2024-04-02 02:59:44,727 - train - INFO - Test: [   0/39]  Time: 1.893 (1.893)  Loss:  0.4424 (0.4424)  Acc@1: 89.4531 (89.4531)  Acc@5: 99.6094 (99.6094)
2024-04-02 03:00:54,609 - train - INFO - Test: [  39/39]  Time: 1.795 (1.794)  Loss:  0.2986 (0.4138)  Acc@1: 93.7500 (90.7600)  Acc@5: 100.0000 (99.7500)
2024-04-02 03:00:57,697 - train - INFO - Train: 20 [   0/195 (  0%)]  Loss:  2.044490 (2.0445)  Time: 2.919s,   87.72/s  (2.919s,   87.72/s)  LR: 5.267e-04  Data: 0.338 (0.338)
2024-04-02 03:03:24,771 - train - INFO - Train: 20 [  50/195 ( 26%)]  Loss:  1.874808 (1.6936)  Time: 2.866s,   89.31/s  (2.941s,   87.04/s)  LR: 5.267e-04  Data: 0.018 (0.018)
2024-04-02 03:05:49,754 - train - INFO - Train: 20 [ 100/195 ( 52%)]  Loss:  1.447037 (1.7135)  Time: 2.786s,   91.88/s  (2.921s,   87.66/s)  LR: 5.267e-04  Data: 0.006 (0.016)
2024-04-02 03:08:16,583 - train - INFO - Train: 20 [ 150/195 ( 77%)]  Loss:  1.978099 (1.7270)  Time: 3.017s,   84.85/s  (2.926s,   87.50/s)  LR: 5.267e-04  Data: 0.005 (0.016)
2024-04-02 03:10:22,829 - train - INFO - Train: 20 [ 194/195 (100%)]  Loss:  1.490646 (1.7285)  Time: 2.778s,   92.15/s  (2.913s,   87.88/s)  LR: 5.267e-04  Data: 0.000 (0.015)
2024-04-02 03:10:22,830 - train - INFO - True
2024-04-02 03:10:22,832 - train - INFO - alphas:tensor([0.2552, 0.7448], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,832 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,832 - train - INFO - True
2024-04-02 03:10:22,833 - train - INFO - alphas:tensor([0.3313, 0.6687], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,833 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,833 - train - INFO - True
2024-04-02 03:10:22,834 - train - INFO - alphas:tensor([0.6350, 0.3650], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,834 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,834 - train - INFO - True
2024-04-02 03:10:22,834 - train - INFO - alphas:tensor([0.6149, 0.3851], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,834 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,834 - train - INFO - True
2024-04-02 03:10:22,835 - train - INFO - alphas:tensor([0.4046, 0.5954], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,835 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,835 - train - INFO - True
2024-04-02 03:10:22,836 - train - INFO - alphas:tensor([0.5188, 0.4812], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,836 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,836 - train - INFO - True
2024-04-02 03:10:22,837 - train - INFO - alphas:tensor([0.6678, 0.3322], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,837 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,837 - train - INFO - True
2024-04-02 03:10:22,838 - train - INFO - alphas:tensor([0.5988, 0.4012], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,838 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,838 - train - INFO - True
2024-04-02 03:10:22,839 - train - INFO - alphas:tensor([0.4742, 0.5258], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,839 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,839 - train - INFO - True
2024-04-02 03:10:22,840 - train - INFO - alphas:tensor([0.5902, 0.4098], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,840 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,840 - train - INFO - True
2024-04-02 03:10:22,841 - train - INFO - alphas:tensor([0.6703, 0.3297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,841 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,841 - train - INFO - True
2024-04-02 03:10:22,841 - train - INFO - alphas:tensor([0.5852, 0.4148], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,842 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,842 - train - INFO - True
2024-04-02 03:10:22,842 - train - INFO - alphas:tensor([0.4879, 0.5121], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,842 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,842 - train - INFO - True
2024-04-02 03:10:22,843 - train - INFO - alphas:tensor([0.5804, 0.4196], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,843 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,843 - train - INFO - True
2024-04-02 03:10:22,844 - train - INFO - alphas:tensor([0.6419, 0.3581], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,844 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,844 - train - INFO - True
2024-04-02 03:10:22,845 - train - INFO - alphas:tensor([0.5072, 0.4928], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,849 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,849 - train - INFO - True
2024-04-02 03:10:22,850 - train - INFO - alphas:tensor([0.4667, 0.5333], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,850 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,850 - train - INFO - True
2024-04-02 03:10:22,851 - train - INFO - alphas:tensor([0.5117, 0.4883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,851 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,851 - train - INFO - True
2024-04-02 03:10:22,851 - train - INFO - alphas:tensor([0.5765, 0.4235], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,852 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,852 - train - INFO - True
2024-04-02 03:10:22,852 - train - INFO - alphas:tensor([0.3969, 0.6031], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,852 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,852 - train - INFO - True
2024-04-02 03:10:22,853 - train - INFO - alphas:tensor([0.4302, 0.5698], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,853 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,853 - train - INFO - True
2024-04-02 03:10:22,854 - train - INFO - alphas:tensor([0.4922, 0.5078], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,854 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,854 - train - INFO - True
2024-04-02 03:10:22,855 - train - INFO - alphas:tensor([0.5374, 0.4626], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,855 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,855 - train - INFO - True
2024-04-02 03:10:22,855 - train - INFO - alphas:tensor([0.3578, 0.6422], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,856 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,856 - train - INFO - True
2024-04-02 03:10:22,856 - train - INFO - alphas:tensor([0.3833, 0.6167], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,856 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,856 - train - INFO - True
2024-04-02 03:10:22,857 - train - INFO - alphas:tensor([0.4440, 0.5560], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,857 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,857 - train - INFO - True
2024-04-02 03:10:22,858 - train - INFO - alphas:tensor([0.3350, 0.6650], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,858 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,858 - train - INFO - True
2024-04-02 03:10:22,859 - train - INFO - alphas:tensor([0.2346, 0.7654], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,859 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,859 - train - INFO - True
2024-04-02 03:10:22,859 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:10:22,860 - train - INFO - tau:0.8345137614500874
2024-04-02 03:10:22,860 - train - INFO - avg block size:8.241379310344827
2024-04-02 03:10:24,802 - train - INFO - Test: [   0/39]  Time: 1.939 (1.939)  Loss:  0.4309 (0.4309)  Acc@1: 88.2812 (88.2812)  Acc@5: 99.2188 (99.2188)
2024-04-02 03:11:34,802 - train - INFO - Test: [  39/39]  Time: 1.798 (1.798)  Loss:  0.3569 (0.4071)  Acc@1: 87.5000 (90.7300)  Acc@5: 100.0000 (99.7000)
2024-04-02 03:11:38,173 - train - INFO - Train: 21 [   0/195 (  0%)]  Loss:  2.062746 (2.0627)  Time: 3.182s,   80.44/s  (3.182s,   80.44/s)  LR: 5.243e-04  Data: 0.237 (0.237)
2024-04-02 03:14:02,021 - train - INFO - Train: 21 [  50/195 ( 26%)]  Loss:  1.687993 (1.7437)  Time: 2.661s,   96.19/s  (2.883s,   88.80/s)  LR: 5.243e-04  Data: 0.014 (0.020)
2024-04-02 03:16:28,894 - train - INFO - Train: 21 [ 100/195 ( 52%)]  Loss:  1.972085 (1.7667)  Time: 3.043s,   84.12/s  (2.910s,   87.98/s)  LR: 5.243e-04  Data: 0.018 (0.017)
2024-04-02 03:18:56,705 - train - INFO - Train: 21 [ 150/195 ( 77%)]  Loss:  1.630753 (1.7351)  Time: 3.021s,   84.75/s  (2.925s,   87.51/s)  LR: 5.243e-04  Data: 0.015 (0.016)
2024-04-02 03:21:05,581 - train - INFO - Train: 21 [ 194/195 (100%)]  Loss:  1.783685 (1.7399)  Time: 3.143s,   81.45/s  (2.926s,   87.49/s)  LR: 5.243e-04  Data: 0.000 (0.016)
2024-04-02 03:21:05,586 - train - INFO - True
2024-04-02 03:21:05,592 - train - INFO - alphas:tensor([0.2397, 0.7603], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,592 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,592 - train - INFO - True
2024-04-02 03:21:05,593 - train - INFO - alphas:tensor([0.3170, 0.6830], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,593 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,593 - train - INFO - True
2024-04-02 03:21:05,598 - train - INFO - alphas:tensor([0.6315, 0.3685], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,598 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,598 - train - INFO - True
2024-04-02 03:21:05,599 - train - INFO - alphas:tensor([0.6093, 0.3907], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,599 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,599 - train - INFO - True
2024-04-02 03:21:05,600 - train - INFO - alphas:tensor([0.3899, 0.6101], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,600 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,600 - train - INFO - True
2024-04-02 03:21:05,601 - train - INFO - alphas:tensor([0.5061, 0.4939], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,601 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,601 - train - INFO - True
2024-04-02 03:21:05,601 - train - INFO - alphas:tensor([0.6636, 0.3364], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,601 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,602 - train - INFO - True
2024-04-02 03:21:05,602 - train - INFO - alphas:tensor([0.5881, 0.4119], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,603 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,603 - train - INFO - True
2024-04-02 03:21:05,604 - train - INFO - alphas:tensor([0.4639, 0.5361], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,604 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,604 - train - INFO - True
2024-04-02 03:21:05,604 - train - INFO - alphas:tensor([0.5808, 0.4192], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,604 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,605 - train - INFO - True
2024-04-02 03:21:05,605 - train - INFO - alphas:tensor([0.6649, 0.3351], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,605 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,605 - train - INFO - True
2024-04-02 03:21:05,606 - train - INFO - alphas:tensor([0.5721, 0.4279], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,606 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,606 - train - INFO - True
2024-04-02 03:21:05,607 - train - INFO - alphas:tensor([0.4792, 0.5208], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,607 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,607 - train - INFO - True
2024-04-02 03:21:05,608 - train - INFO - alphas:tensor([0.5727, 0.4273], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,608 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,608 - train - INFO - True
2024-04-02 03:21:05,608 - train - INFO - alphas:tensor([0.6346, 0.3654], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,609 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,609 - train - INFO - True
2024-04-02 03:21:05,609 - train - INFO - alphas:tensor([0.4928, 0.5072], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,609 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,609 - train - INFO - True
2024-04-02 03:21:05,610 - train - INFO - alphas:tensor([0.4533, 0.5467], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,610 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,610 - train - INFO - True
2024-04-02 03:21:05,611 - train - INFO - alphas:tensor([0.4989, 0.5011], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,611 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,611 - train - INFO - True
2024-04-02 03:21:05,612 - train - INFO - alphas:tensor([0.5669, 0.4331], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,612 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,612 - train - INFO - True
2024-04-02 03:21:05,613 - train - INFO - alphas:tensor([0.3831, 0.6169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,613 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,613 - train - INFO - True
2024-04-02 03:21:05,627 - train - INFO - alphas:tensor([0.4164, 0.5836], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,627 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,627 - train - INFO - True
2024-04-02 03:21:05,627 - train - INFO - alphas:tensor([0.4788, 0.5212], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,627 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,628 - train - INFO - True
2024-04-02 03:21:05,628 - train - INFO - alphas:tensor([0.5239, 0.4761], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,628 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,628 - train - INFO - True
2024-04-02 03:21:05,629 - train - INFO - alphas:tensor([0.3419, 0.6581], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,629 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,629 - train - INFO - True
2024-04-02 03:21:05,630 - train - INFO - alphas:tensor([0.3693, 0.6307], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,630 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,630 - train - INFO - True
2024-04-02 03:21:05,631 - train - INFO - alphas:tensor([0.4264, 0.5736], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,631 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,631 - train - INFO - True
2024-04-02 03:21:05,631 - train - INFO - alphas:tensor([0.3150, 0.6850], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,632 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,632 - train - INFO - True
2024-04-02 03:21:05,632 - train - INFO - alphas:tensor([0.2115, 0.7885], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,632 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,632 - train - INFO - True
2024-04-02 03:21:05,633 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:21:05,633 - train - INFO - tau:0.8261686238355865
2024-04-02 03:21:05,633 - train - INFO - avg block size:9.275862068965518
2024-04-02 03:21:07,521 - train - INFO - Test: [   0/39]  Time: 1.885 (1.885)  Loss:  0.4690 (0.4690)  Acc@1: 89.8438 (89.8438)  Acc@5: 99.6094 (99.6094)
2024-04-02 03:22:18,251 - train - INFO - Test: [  39/39]  Time: 1.864 (1.815)  Loss:  0.4500 (0.4405)  Acc@1: 87.5000 (90.4200)  Acc@5: 100.0000 (99.6000)
2024-04-02 03:22:21,578 - train - INFO - Train: 22 [   0/195 (  0%)]  Loss:  1.791622 (1.7916)  Time: 3.038s,   84.26/s  (3.038s,   84.26/s)  LR: 5.218e-04  Data: 0.364 (0.364)
2024-04-02 03:24:47,879 - train - INFO - Train: 22 [  50/195 ( 26%)]  Loss:  1.562673 (1.7617)  Time: 3.065s,   83.52/s  (2.928s,   87.43/s)  LR: 5.218e-04  Data: 0.010 (0.021)
2024-04-02 03:27:17,750 - train - INFO - Train: 22 [ 100/195 ( 52%)]  Loss:  1.601563 (1.7497)  Time: 2.655s,   96.42/s  (2.962s,   86.42/s)  LR: 5.218e-04  Data: 0.024 (0.018)
2024-04-02 03:29:43,675 - train - INFO - Train: 22 [ 150/195 ( 77%)]  Loss:  1.594413 (1.7400)  Time: 3.222s,   79.45/s  (2.948s,   86.84/s)  LR: 5.218e-04  Data: 0.010 (0.017)
2024-04-02 03:31:53,692 - train - INFO - Train: 22 [ 194/195 (100%)]  Loss:  1.516417 (1.7231)  Time: 3.306s,   77.43/s  (2.949s,   86.80/s)  LR: 5.218e-04  Data: 0.000 (0.016)
2024-04-02 03:31:53,718 - train - INFO - True
2024-04-02 03:31:53,719 - train - INFO - alphas:tensor([0.2240, 0.7760], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,720 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,720 - train - INFO - True
2024-04-02 03:31:53,720 - train - INFO - alphas:tensor([0.3025, 0.6975], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,720 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,720 - train - INFO - True
2024-04-02 03:31:53,721 - train - INFO - alphas:tensor([0.6276, 0.3724], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,721 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,731 - train - INFO - True
2024-04-02 03:31:53,732 - train - INFO - alphas:tensor([0.6015, 0.3985], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,732 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,732 - train - INFO - True
2024-04-02 03:31:53,733 - train - INFO - alphas:tensor([0.3783, 0.6217], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,737 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,737 - train - INFO - True
2024-04-02 03:31:53,738 - train - INFO - alphas:tensor([0.4968, 0.5032], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,738 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,738 - train - INFO - True
2024-04-02 03:31:53,739 - train - INFO - alphas:tensor([0.6582, 0.3418], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,739 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,739 - train - INFO - True
2024-04-02 03:31:53,740 - train - INFO - alphas:tensor([0.5773, 0.4227], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,744 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,744 - train - INFO - True
2024-04-02 03:31:53,745 - train - INFO - alphas:tensor([0.4528, 0.5472], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,745 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,745 - train - INFO - True
2024-04-02 03:31:53,746 - train - INFO - alphas:tensor([0.5733, 0.4267], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,746 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,746 - train - INFO - True
2024-04-02 03:31:53,747 - train - INFO - alphas:tensor([0.6618, 0.3382], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,747 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,747 - train - INFO - True
2024-04-02 03:31:53,752 - train - INFO - alphas:tensor([0.5601, 0.4399], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,752 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,752 - train - INFO - True
2024-04-02 03:31:53,753 - train - INFO - alphas:tensor([0.4678, 0.5322], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,753 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,753 - train - INFO - True
2024-04-02 03:31:53,754 - train - INFO - alphas:tensor([0.5626, 0.4374], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,754 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,754 - train - INFO - True
2024-04-02 03:31:53,754 - train - INFO - alphas:tensor([0.6288, 0.3712], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,754 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,755 - train - INFO - True
2024-04-02 03:31:53,755 - train - INFO - alphas:tensor([0.4806, 0.5194], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,755 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,755 - train - INFO - True
2024-04-02 03:31:53,756 - train - INFO - alphas:tensor([0.4430, 0.5570], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,756 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,756 - train - INFO - True
2024-04-02 03:31:53,770 - train - INFO - alphas:tensor([0.4887, 0.5113], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,770 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,770 - train - INFO - True
2024-04-02 03:31:53,771 - train - INFO - alphas:tensor([0.5575, 0.4425], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,771 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,771 - train - INFO - True
2024-04-02 03:31:53,772 - train - INFO - alphas:tensor([0.3710, 0.6290], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,772 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,772 - train - INFO - True
2024-04-02 03:31:53,772 - train - INFO - alphas:tensor([0.4046, 0.5954], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,773 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,773 - train - INFO - True
2024-04-02 03:31:53,773 - train - INFO - alphas:tensor([0.4666, 0.5334], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,773 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,773 - train - INFO - True
2024-04-02 03:31:53,774 - train - INFO - alphas:tensor([0.5154, 0.4846], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,774 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,774 - train - INFO - True
2024-04-02 03:31:53,775 - train - INFO - alphas:tensor([0.3329, 0.6671], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,775 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,775 - train - INFO - True
2024-04-02 03:31:53,776 - train - INFO - alphas:tensor([0.3572, 0.6428], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,776 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,776 - train - INFO - True
2024-04-02 03:31:53,777 - train - INFO - alphas:tensor([0.4112, 0.5888], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,777 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,777 - train - INFO - True
2024-04-02 03:31:53,777 - train - INFO - alphas:tensor([0.2966, 0.7034], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,778 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,778 - train - INFO - True
2024-04-02 03:31:53,778 - train - INFO - alphas:tensor([0.1907, 0.8093], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,778 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,778 - train - INFO - True
2024-04-02 03:31:53,788 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:31:53,788 - train - INFO - tau:0.8179069375972307
2024-04-02 03:31:53,788 - train - INFO - avg block size:9.793103448275861
2024-04-02 03:31:55,702 - train - INFO - Test: [   0/39]  Time: 1.906 (1.906)  Loss:  0.4373 (0.4373)  Acc@1: 89.0625 (89.0625)  Acc@5: 100.0000 (100.0000)
2024-04-02 03:33:06,750 - train - INFO - Test: [  39/39]  Time: 1.722 (1.824)  Loss:  0.5249 (0.4051)  Acc@1: 75.0000 (90.9500)  Acc@5: 100.0000 (99.7200)
2024-04-02 03:33:09,964 - train - INFO - Train: 23 [   0/195 (  0%)]  Loss:  1.389087 (1.3891)  Time: 3.072s,   83.34/s  (3.072s,   83.34/s)  LR: 5.193e-04  Data: 0.369 (0.369)
2024-04-02 03:35:36,573 - train - INFO - Train: 23 [  50/195 ( 26%)]  Loss:  2.019244 (1.7302)  Time: 2.869s,   89.23/s  (2.935s,   87.23/s)  LR: 5.193e-04  Data: 0.014 (0.020)
2024-04-02 03:38:04,918 - train - INFO - Train: 23 [ 100/195 ( 52%)]  Loss:  1.608018 (1.7124)  Time: 3.599s,   71.14/s  (2.951s,   86.76/s)  LR: 5.193e-04  Data: 0.040 (0.017)
2024-04-02 03:40:36,833 - train - INFO - Train: 23 [ 150/195 ( 77%)]  Loss:  1.360551 (1.7042)  Time: 3.271s,   78.27/s  (2.980s,   85.92/s)  LR: 5.193e-04  Data: 0.014 (0.017)
2024-04-02 03:42:46,536 - train - INFO - Train: 23 [ 194/195 (100%)]  Loss:  1.543043 (1.7139)  Time: 3.324s,   77.02/s  (2.972s,   86.13/s)  LR: 5.193e-04  Data: 0.000 (0.016)
2024-04-02 03:42:46,537 - train - INFO - True
2024-04-02 03:42:46,539 - train - INFO - alphas:tensor([0.2103, 0.7897], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,540 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,540 - train - INFO - True
2024-04-02 03:42:46,549 - train - INFO - alphas:tensor([0.2882, 0.7118], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,565 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,566 - train - INFO - True
2024-04-02 03:42:46,566 - train - INFO - alphas:tensor([0.6248, 0.3752], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,566 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,566 - train - INFO - True
2024-04-02 03:42:46,567 - train - INFO - alphas:tensor([0.5965, 0.4035], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,572 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,572 - train - INFO - True
2024-04-02 03:42:46,572 - train - INFO - alphas:tensor([0.3665, 0.6335], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,572 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,573 - train - INFO - True
2024-04-02 03:42:46,573 - train - INFO - alphas:tensor([0.4868, 0.5132], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,573 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,573 - train - INFO - True
2024-04-02 03:42:46,574 - train - INFO - alphas:tensor([0.6548, 0.3452], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,574 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,574 - train - INFO - True
2024-04-02 03:42:46,579 - train - INFO - alphas:tensor([0.5703, 0.4297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,584 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,584 - train - INFO - True
2024-04-02 03:42:46,585 - train - INFO - alphas:tensor([0.4453, 0.5547], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,589 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,589 - train - INFO - True
2024-04-02 03:42:46,594 - train - INFO - alphas:tensor([0.5679, 0.4321], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,594 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,594 - train - INFO - True
2024-04-02 03:42:46,595 - train - INFO - alphas:tensor([0.6592, 0.3408], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,600 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,600 - train - INFO - True
2024-04-02 03:42:46,600 - train - INFO - alphas:tensor([0.5521, 0.4479], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,600 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,600 - train - INFO - True
2024-04-02 03:42:46,601 - train - INFO - alphas:tensor([0.4593, 0.5407], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,606 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,606 - train - INFO - True
2024-04-02 03:42:46,606 - train - INFO - alphas:tensor([0.5565, 0.4435], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,606 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,606 - train - INFO - True
2024-04-02 03:42:46,607 - train - INFO - alphas:tensor([0.6240, 0.3760], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,611 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,611 - train - INFO - True
2024-04-02 03:42:46,612 - train - INFO - alphas:tensor([0.4730, 0.5270], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,618 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,618 - train - INFO - True
2024-04-02 03:42:46,627 - train - INFO - alphas:tensor([0.4337, 0.5663], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,628 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,628 - train - INFO - True
2024-04-02 03:42:46,628 - train - INFO - alphas:tensor([0.4797, 0.5203], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,632 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,632 - train - INFO - True
2024-04-02 03:42:46,632 - train - INFO - alphas:tensor([0.5467, 0.4533], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,633 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,633 - train - INFO - True
2024-04-02 03:42:46,633 - train - INFO - alphas:tensor([0.3586, 0.6414], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,633 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,633 - train - INFO - True
2024-04-02 03:42:46,634 - train - INFO - alphas:tensor([0.3901, 0.6099], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,634 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,634 - train - INFO - True
2024-04-02 03:42:46,635 - train - INFO - alphas:tensor([0.4518, 0.5482], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,635 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,635 - train - INFO - True
2024-04-02 03:42:46,636 - train - INFO - alphas:tensor([0.5076, 0.4924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,636 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,636 - train - INFO - True
2024-04-02 03:42:46,637 - train - INFO - alphas:tensor([0.3225, 0.6775], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,637 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,637 - train - INFO - True
2024-04-02 03:42:46,638 - train - INFO - alphas:tensor([0.3430, 0.6570], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,638 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,638 - train - INFO - True
2024-04-02 03:42:46,638 - train - INFO - alphas:tensor([0.3939, 0.6061], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,638 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,638 - train - INFO - True
2024-04-02 03:42:46,639 - train - INFO - alphas:tensor([0.2792, 0.7208], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,639 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,639 - train - INFO - True
2024-04-02 03:42:46,640 - train - INFO - alphas:tensor([0.1707, 0.8293], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,640 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,640 - train - INFO - True
2024-04-02 03:42:46,641 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:42:46,641 - train - INFO - tau:0.8097278682212583
2024-04-02 03:42:46,641 - train - INFO - avg block size:9.793103448275861
2024-04-02 03:42:48,575 - train - INFO - Test: [   0/39]  Time: 1.877 (1.877)  Loss:  0.3884 (0.3884)  Acc@1: 91.0156 (91.0156)  Acc@5: 99.6094 (99.6094)
2024-04-02 03:43:59,685 - train - INFO - Test: [  39/39]  Time: 1.838 (1.825)  Loss:  0.4500 (0.3988)  Acc@1: 87.5000 (90.7100)  Acc@5: 100.0000 (99.5800)
2024-04-02 03:44:02,836 - train - INFO - Train: 24 [   0/195 (  0%)]  Loss:  1.664138 (1.6641)  Time: 3.058s,   83.72/s  (3.058s,   83.72/s)  LR: 5.166e-04  Data: 0.287 (0.287)
2024-04-02 03:46:31,191 - train - INFO - Train: 24 [  50/195 ( 26%)]  Loss:  1.758753 (1.6925)  Time: 2.673s,   95.77/s  (2.969s,   86.23/s)  LR: 5.166e-04  Data: 0.022 (0.020)
2024-04-02 03:48:57,220 - train - INFO - Train: 24 [ 100/195 ( 52%)]  Loss:  1.907250 (1.6856)  Time: 3.026s,   84.61/s  (2.945s,   86.93/s)  LR: 5.166e-04  Data: 0.009 (0.017)
2024-04-02 03:51:25,909 - train - INFO - Train: 24 [ 150/195 ( 77%)]  Loss:  1.345608 (1.6856)  Time: 2.843s,   90.04/s  (2.954s,   86.65/s)  LR: 5.166e-04  Data: 0.006 (0.017)
2024-04-02 03:53:33,069 - train - INFO - Train: 24 [ 194/195 (100%)]  Loss:  1.479838 (1.6927)  Time: 2.809s,   91.15/s  (2.940s,   87.08/s)  LR: 5.166e-04  Data: 0.000 (0.016)
2024-04-02 03:53:33,069 - train - INFO - True
2024-04-02 03:53:33,070 - train - INFO - alphas:tensor([0.1960, 0.8040], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,071 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,071 - train - INFO - True
2024-04-02 03:53:33,071 - train - INFO - alphas:tensor([0.2745, 0.7255], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,072 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,072 - train - INFO - True
2024-04-02 03:53:33,072 - train - INFO - alphas:tensor([0.6210, 0.3790], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,072 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,073 - train - INFO - True
2024-04-02 03:53:33,074 - train - INFO - alphas:tensor([0.5897, 0.4103], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,074 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,074 - train - INFO - True
2024-04-02 03:53:33,074 - train - INFO - alphas:tensor([0.3571, 0.6429], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,075 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,075 - train - INFO - True
2024-04-02 03:53:33,075 - train - INFO - alphas:tensor([0.4807, 0.5193], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,075 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,075 - train - INFO - True
2024-04-02 03:53:33,076 - train - INFO - alphas:tensor([0.6506, 0.3494], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,076 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,076 - train - INFO - True
2024-04-02 03:53:33,086 - train - INFO - alphas:tensor([0.5628, 0.4372], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,086 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,086 - train - INFO - True
2024-04-02 03:53:33,087 - train - INFO - alphas:tensor([0.4350, 0.5650], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,087 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,087 - train - INFO - True
2024-04-02 03:53:33,088 - train - INFO - alphas:tensor([0.5598, 0.4402], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,088 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,088 - train - INFO - True
2024-04-02 03:53:33,088 - train - INFO - alphas:tensor([0.6551, 0.3449], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,088 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,089 - train - INFO - True
2024-04-02 03:53:33,089 - train - INFO - alphas:tensor([0.5425, 0.4575], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,089 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,089 - train - INFO - True
2024-04-02 03:53:33,090 - train - INFO - alphas:tensor([0.4478, 0.5522], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,090 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,090 - train - INFO - True
2024-04-02 03:53:33,091 - train - INFO - alphas:tensor([0.5472, 0.4528], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,091 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,091 - train - INFO - True
2024-04-02 03:53:33,092 - train - INFO - alphas:tensor([0.6187, 0.3813], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,092 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,092 - train - INFO - True
2024-04-02 03:53:33,092 - train - INFO - alphas:tensor([0.4650, 0.5350], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,093 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,093 - train - INFO - True
2024-04-02 03:53:33,093 - train - INFO - alphas:tensor([0.4233, 0.5767], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,093 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,093 - train - INFO - True
2024-04-02 03:53:33,094 - train - INFO - alphas:tensor([0.4705, 0.5295], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,094 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,094 - train - INFO - True
2024-04-02 03:53:33,095 - train - INFO - alphas:tensor([0.5380, 0.4620], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,095 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,095 - train - INFO - True
2024-04-02 03:53:33,096 - train - INFO - alphas:tensor([0.3495, 0.6505], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,096 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,096 - train - INFO - True
2024-04-02 03:53:33,097 - train - INFO - alphas:tensor([0.3782, 0.6218], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,097 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,097 - train - INFO - True
2024-04-02 03:53:33,098 - train - INFO - alphas:tensor([0.4410, 0.5590], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,098 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,098 - train - INFO - True
2024-04-02 03:53:33,098 - train - INFO - alphas:tensor([0.4971, 0.5029], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,098 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,099 - train - INFO - True
2024-04-02 03:53:33,099 - train - INFO - alphas:tensor([0.3094, 0.6906], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,099 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,099 - train - INFO - True
2024-04-02 03:53:33,100 - train - INFO - alphas:tensor([0.3309, 0.6691], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,100 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,100 - train - INFO - True
2024-04-02 03:53:33,101 - train - INFO - alphas:tensor([0.3775, 0.6225], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,101 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,101 - train - INFO - True
2024-04-02 03:53:33,102 - train - INFO - alphas:tensor([0.2616, 0.7384], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,102 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,102 - train - INFO - True
2024-04-02 03:53:33,102 - train - INFO - alphas:tensor([0.1529, 0.8471], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,103 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,103 - train - INFO - True
2024-04-02 03:53:33,103 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 03:53:33,103 - train - INFO - tau:0.8016305895390458
2024-04-02 03:53:33,103 - train - INFO - avg block size:10.310344827586206
2024-04-02 03:53:35,018 - train - INFO - Test: [   0/39]  Time: 1.912 (1.912)  Loss:  0.4436 (0.4436)  Acc@1: 89.4531 (89.4531)  Acc@5: 99.6094 (99.6094)
2024-04-02 03:54:45,850 - train - INFO - Test: [  39/39]  Time: 1.813 (1.819)  Loss:  0.4563 (0.4160)  Acc@1: 87.5000 (91.0000)  Acc@5: 100.0000 (99.6100)
2024-04-02 03:54:49,204 - train - INFO - Train: 25 [   0/195 (  0%)]  Loss:  1.425008 (1.4250)  Time: 3.090s,   82.85/s  (3.090s,   82.85/s)  LR: 5.138e-04  Data: 0.224 (0.224)
2024-04-02 03:57:14,917 - train - INFO - Train: 25 [  50/195 ( 26%)]  Loss:  1.443549 (1.6917)  Time: 2.605s,   98.26/s  (2.918s,   87.74/s)  LR: 5.138e-04  Data: 0.026 (0.017)
2024-04-02 03:59:44,317 - train - INFO - Train: 25 [ 100/195 ( 52%)]  Loss:  1.814352 (1.7005)  Time: 2.944s,   86.96/s  (2.952s,   86.71/s)  LR: 5.138e-04  Data: 0.019 (0.017)
2024-04-02 04:02:08,453 - train - INFO - Train: 25 [ 150/195 ( 77%)]  Loss:  1.757548 (1.7094)  Time: 2.968s,   86.24/s  (2.929s,   87.39/s)  LR: 5.138e-04  Data: 0.008 (0.015)
2024-04-02 04:04:18,916 - train - INFO - Train: 25 [ 194/195 (100%)]  Loss:  1.919032 (1.7103)  Time: 2.484s,  103.04/s  (2.937s,   87.15/s)  LR: 5.138e-04  Data: 0.000 (0.015)
2024-04-02 04:04:18,916 - train - INFO - True
2024-04-02 04:04:18,919 - train - INFO - alphas:tensor([0.1840, 0.8160], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,919 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,919 - train - INFO - True
2024-04-02 04:04:18,920 - train - INFO - alphas:tensor([0.2624, 0.7376], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,920 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,920 - train - INFO - True
2024-04-02 04:04:18,920 - train - INFO - alphas:tensor([0.6181, 0.3819], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,920 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,921 - train - INFO - True
2024-04-02 04:04:18,921 - train - INFO - alphas:tensor([0.5853, 0.4147], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,921 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,921 - train - INFO - True
2024-04-02 04:04:18,922 - train - INFO - alphas:tensor([0.3477, 0.6523], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,922 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,922 - train - INFO - True
2024-04-02 04:04:18,923 - train - INFO - alphas:tensor([0.4709, 0.5291], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,923 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,923 - train - INFO - True
2024-04-02 04:04:18,924 - train - INFO - alphas:tensor([0.6492, 0.3508], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,924 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,924 - train - INFO - True
2024-04-02 04:04:18,925 - train - INFO - alphas:tensor([0.5583, 0.4417], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,925 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,925 - train - INFO - True
2024-04-02 04:04:18,926 - train - INFO - alphas:tensor([0.4286, 0.5714], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,926 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,926 - train - INFO - True
2024-04-02 04:04:18,927 - train - INFO - alphas:tensor([0.5528, 0.4472], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,927 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,927 - train - INFO - True
2024-04-02 04:04:18,928 - train - INFO - alphas:tensor([0.6524, 0.3476], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,928 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,928 - train - INFO - True
2024-04-02 04:04:18,928 - train - INFO - alphas:tensor([0.5363, 0.4637], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,928 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,928 - train - INFO - True
2024-04-02 04:04:18,929 - train - INFO - alphas:tensor([0.4395, 0.5605], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,929 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,929 - train - INFO - True
2024-04-02 04:04:18,930 - train - INFO - alphas:tensor([0.5395, 0.4605], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,930 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,930 - train - INFO - True
2024-04-02 04:04:18,931 - train - INFO - alphas:tensor([0.6131, 0.3869], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,931 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,931 - train - INFO - True
2024-04-02 04:04:18,932 - train - INFO - alphas:tensor([0.4569, 0.5431], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,932 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,932 - train - INFO - True
2024-04-02 04:04:18,932 - train - INFO - alphas:tensor([0.4159, 0.5841], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,932 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,933 - train - INFO - True
2024-04-02 04:04:18,933 - train - INFO - alphas:tensor([0.4642, 0.5358], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,933 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,933 - train - INFO - True
2024-04-02 04:04:18,934 - train - INFO - alphas:tensor([0.5311, 0.4689], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,934 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,934 - train - INFO - True
2024-04-02 04:04:18,935 - train - INFO - alphas:tensor([0.3429, 0.6571], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,935 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,935 - train - INFO - True
2024-04-02 04:04:18,936 - train - INFO - alphas:tensor([0.3702, 0.6298], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,936 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,936 - train - INFO - True
2024-04-02 04:04:18,936 - train - INFO - alphas:tensor([0.4323, 0.5677], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,937 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,937 - train - INFO - True
2024-04-02 04:04:18,937 - train - INFO - alphas:tensor([0.4880, 0.5120], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,937 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,937 - train - INFO - True
2024-04-02 04:04:18,938 - train - INFO - alphas:tensor([0.2991, 0.7009], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,938 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,938 - train - INFO - True
2024-04-02 04:04:18,939 - train - INFO - alphas:tensor([0.3196, 0.6804], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,939 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,939 - train - INFO - True
2024-04-02 04:04:18,940 - train - INFO - alphas:tensor([0.3613, 0.6387], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,940 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,940 - train - INFO - True
2024-04-02 04:04:18,941 - train - INFO - alphas:tensor([0.2451, 0.7549], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,941 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,941 - train - INFO - True
2024-04-02 04:04:18,941 - train - INFO - alphas:tensor([0.1354, 0.8646], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,942 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,942 - train - INFO - True
2024-04-02 04:04:18,942 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:04:18,942 - train - INFO - tau:0.7936142836436553
2024-04-02 04:04:18,942 - train - INFO - avg block size:10.310344827586206
2024-04-02 04:04:20,819 - train - INFO - Test: [   0/39]  Time: 1.874 (1.874)  Loss:  0.4468 (0.4468)  Acc@1: 89.4531 (89.4531)  Acc@5: 99.6094 (99.6094)
2024-04-02 04:05:32,440 - train - INFO - Test: [  39/39]  Time: 1.777 (1.837)  Loss:  0.3984 (0.4237)  Acc@1: 81.2500 (90.7900)  Acc@5: 100.0000 (99.6500)
2024-04-02 04:05:35,993 - train - INFO - Train: 26 [   0/195 (  0%)]  Loss:  1.879376 (1.8794)  Time: 3.292s,   77.76/s  (3.292s,   77.76/s)  LR: 5.109e-04  Data: 0.365 (0.365)
2024-04-02 04:08:05,715 - train - INFO - Train: 26 [  50/195 ( 26%)]  Loss:  1.915023 (1.7148)  Time: 2.944s,   86.95/s  (3.000s,   85.33/s)  LR: 5.109e-04  Data: 0.018 (0.020)
2024-04-02 04:10:32,617 - train - INFO - Train: 26 [ 100/195 ( 52%)]  Loss:  1.759151 (1.7230)  Time: 3.380s,   75.74/s  (2.969s,   86.21/s)  LR: 5.109e-04  Data: 0.014 (0.017)
2024-04-02 04:12:59,769 - train - INFO - Train: 26 [ 150/195 ( 77%)]  Loss:  1.667822 (1.7195)  Time: 2.831s,   90.44/s  (2.961s,   86.47/s)  LR: 5.109e-04  Data: 0.027 (0.016)
2024-04-02 04:15:08,738 - train - INFO - Train: 26 [ 194/195 (100%)]  Loss:  1.729517 (1.7062)  Time: 2.787s,   91.85/s  (2.954s,   86.66/s)  LR: 5.109e-04  Data: 0.000 (0.016)
2024-04-02 04:15:08,739 - train - INFO - True
2024-04-02 04:15:08,740 - train - INFO - alphas:tensor([0.1720, 0.8280], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,740 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,740 - train - INFO - True
2024-04-02 04:15:08,741 - train - INFO - alphas:tensor([0.2493, 0.7507], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,741 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,741 - train - INFO - True
2024-04-02 04:15:08,742 - train - INFO - alphas:tensor([0.6166, 0.3834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,742 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,742 - train - INFO - True
2024-04-02 04:15:08,743 - train - INFO - alphas:tensor([0.5825, 0.4175], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,743 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,743 - train - INFO - True
2024-04-02 04:15:08,744 - train - INFO - alphas:tensor([0.3360, 0.6640], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,744 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,744 - train - INFO - True
2024-04-02 04:15:08,745 - train - INFO - alphas:tensor([0.4606, 0.5394], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,745 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,745 - train - INFO - True
2024-04-02 04:15:08,746 - train - INFO - alphas:tensor([0.6444, 0.3556], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,746 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,746 - train - INFO - True
2024-04-02 04:15:08,746 - train - INFO - alphas:tensor([0.5507, 0.4493], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,746 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,747 - train - INFO - True
2024-04-02 04:15:08,747 - train - INFO - alphas:tensor([0.4188, 0.5812], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,747 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,747 - train - INFO - True
2024-04-02 04:15:08,748 - train - INFO - alphas:tensor([0.5439, 0.4561], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,748 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,748 - train - INFO - True
2024-04-02 04:15:08,749 - train - INFO - alphas:tensor([0.6483, 0.3517], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,749 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,749 - train - INFO - True
2024-04-02 04:15:08,750 - train - INFO - alphas:tensor([0.5286, 0.4714], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,750 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,750 - train - INFO - True
2024-04-02 04:15:08,750 - train - INFO - alphas:tensor([0.4331, 0.5669], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,751 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,751 - train - INFO - True
2024-04-02 04:15:08,751 - train - INFO - alphas:tensor([0.5347, 0.4653], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,751 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,751 - train - INFO - True
2024-04-02 04:15:08,752 - train - INFO - alphas:tensor([0.6076, 0.3924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,752 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,752 - train - INFO - True
2024-04-02 04:15:08,753 - train - INFO - alphas:tensor([0.4505, 0.5495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,753 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,753 - train - INFO - True
2024-04-02 04:15:08,754 - train - INFO - alphas:tensor([0.4063, 0.5937], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,754 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,754 - train - INFO - True
2024-04-02 04:15:08,754 - train - INFO - alphas:tensor([0.4532, 0.5468], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,755 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,755 - train - INFO - True
2024-04-02 04:15:08,755 - train - INFO - alphas:tensor([0.5227, 0.4773], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,755 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,755 - train - INFO - True
2024-04-02 04:15:08,756 - train - INFO - alphas:tensor([0.3357, 0.6643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,756 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,756 - train - INFO - True
2024-04-02 04:15:08,757 - train - INFO - alphas:tensor([0.3605, 0.6395], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,757 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,757 - train - INFO - True
2024-04-02 04:15:08,758 - train - INFO - alphas:tensor([0.4215, 0.5785], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,758 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,758 - train - INFO - True
2024-04-02 04:15:08,759 - train - INFO - alphas:tensor([0.4806, 0.5194], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,759 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,759 - train - INFO - True
2024-04-02 04:15:08,759 - train - INFO - alphas:tensor([0.2888, 0.7112], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,759 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,760 - train - INFO - True
2024-04-02 04:15:08,760 - train - INFO - alphas:tensor([0.3091, 0.6909], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,760 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,760 - train - INFO - True
2024-04-02 04:15:08,761 - train - INFO - alphas:tensor([0.3458, 0.6542], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,761 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,761 - train - INFO - True
2024-04-02 04:15:08,762 - train - INFO - alphas:tensor([0.2302, 0.7698], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,762 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,762 - train - INFO - True
2024-04-02 04:15:08,763 - train - INFO - alphas:tensor([0.1197, 0.8803], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,763 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,763 - train - INFO - True
2024-04-02 04:15:08,763 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:15:08,764 - train - INFO - tau:0.7856781408072188
2024-04-02 04:15:08,764 - train - INFO - avg block size:10.310344827586206
2024-04-02 04:15:10,602 - train - INFO - Test: [   0/39]  Time: 1.835 (1.835)  Loss:  0.4380 (0.4380)  Acc@1: 89.8438 (89.8438)  Acc@5: 100.0000 (100.0000)
2024-04-02 04:16:20,401 - train - INFO - Test: [  39/39]  Time: 1.759 (1.791)  Loss:  0.4810 (0.4316)  Acc@1: 87.5000 (90.2400)  Acc@5: 100.0000 (99.6600)
2024-04-02 04:16:23,790 - train - INFO - Train: 27 [   0/195 (  0%)]  Loss:  1.630374 (1.6304)  Time: 3.208s,   79.79/s  (3.208s,   79.79/s)  LR: 5.080e-04  Data: 0.324 (0.324)
2024-04-02 04:18:53,636 - train - INFO - Train: 27 [  50/195 ( 26%)]  Loss:  1.342546 (1.7173)  Time: 3.281s,   78.02/s  (3.001s,   85.30/s)  LR: 5.080e-04  Data: 0.019 (0.019)
2024-04-02 04:21:21,748 - train - INFO - Train: 27 [ 100/195 ( 52%)]  Loss:  1.693963 (1.7138)  Time: 2.941s,   87.03/s  (2.982s,   85.85/s)  LR: 5.080e-04  Data: 0.005 (0.018)
2024-04-02 04:23:48,802 - train - INFO - Train: 27 [ 150/195 ( 77%)]  Loss:  1.890008 (1.7028)  Time: 3.192s,   80.21/s  (2.968s,   86.24/s)  LR: 5.080e-04  Data: 0.014 (0.016)
2024-04-02 04:26:00,811 - train - INFO - Train: 27 [ 194/195 (100%)]  Loss:  1.747548 (1.7021)  Time: 2.668s,   95.97/s  (2.976s,   86.04/s)  LR: 5.080e-04  Data: 0.000 (0.015)
2024-04-02 04:26:00,829 - train - INFO - True
2024-04-02 04:26:00,830 - train - INFO - alphas:tensor([0.1606, 0.8394], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,843 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,843 - train - INFO - True
2024-04-02 04:26:00,844 - train - INFO - alphas:tensor([0.2371, 0.7629], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,844 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,844 - train - INFO - True
2024-04-02 04:26:00,844 - train - INFO - alphas:tensor([0.6138, 0.3862], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,844 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,845 - train - INFO - True
2024-04-02 04:26:00,850 - train - INFO - alphas:tensor([0.5771, 0.4229], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,850 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,850 - train - INFO - True
2024-04-02 04:26:00,850 - train - INFO - alphas:tensor([0.3291, 0.6709], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,851 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,851 - train - INFO - True
2024-04-02 04:26:00,851 - train - INFO - alphas:tensor([0.4528, 0.5472], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,851 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,851 - train - INFO - True
2024-04-02 04:26:00,852 - train - INFO - alphas:tensor([0.6395, 0.3605], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,852 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,852 - train - INFO - True
2024-04-02 04:26:00,857 - train - INFO - alphas:tensor([0.5446, 0.4554], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,857 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,858 - train - INFO - True
2024-04-02 04:26:00,858 - train - INFO - alphas:tensor([0.4120, 0.5880], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,859 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,859 - train - INFO - True
2024-04-02 04:26:00,860 - train - INFO - alphas:tensor([0.5369, 0.4631], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,860 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,860 - train - INFO - True
2024-04-02 04:26:00,860 - train - INFO - alphas:tensor([0.6454, 0.3546], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,860 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,861 - train - INFO - True
2024-04-02 04:26:00,861 - train - INFO - alphas:tensor([0.5224, 0.4776], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,861 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,861 - train - INFO - True
2024-04-02 04:26:00,862 - train - INFO - alphas:tensor([0.4248, 0.5752], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,862 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,862 - train - INFO - True
2024-04-02 04:26:00,863 - train - INFO - alphas:tensor([0.5273, 0.4727], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,863 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,863 - train - INFO - True
2024-04-02 04:26:00,864 - train - INFO - alphas:tensor([0.6038, 0.3962], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,864 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,864 - train - INFO - True
2024-04-02 04:26:00,869 - train - INFO - alphas:tensor([0.4433, 0.5567], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,869 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,869 - train - INFO - True
2024-04-02 04:26:00,870 - train - INFO - alphas:tensor([0.3971, 0.6029], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,870 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,870 - train - INFO - True
2024-04-02 04:26:00,871 - train - INFO - alphas:tensor([0.4443, 0.5557], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,871 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,871 - train - INFO - True
2024-04-02 04:26:00,871 - train - INFO - alphas:tensor([0.5147, 0.4853], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,872 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,872 - train - INFO - True
2024-04-02 04:26:00,872 - train - INFO - alphas:tensor([0.3261, 0.6739], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,872 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,872 - train - INFO - True
2024-04-02 04:26:00,882 - train - INFO - alphas:tensor([0.3522, 0.6478], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,882 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,882 - train - INFO - True
2024-04-02 04:26:00,883 - train - INFO - alphas:tensor([0.4114, 0.5886], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,883 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,883 - train - INFO - True
2024-04-02 04:26:00,884 - train - INFO - alphas:tensor([0.4733, 0.5267], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,884 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,884 - train - INFO - True
2024-04-02 04:26:00,884 - train - INFO - alphas:tensor([0.2815, 0.7185], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,885 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,885 - train - INFO - True
2024-04-02 04:26:00,885 - train - INFO - alphas:tensor([0.2994, 0.7006], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,885 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,885 - train - INFO - True
2024-04-02 04:26:00,886 - train - INFO - alphas:tensor([0.3281, 0.6719], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,886 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,886 - train - INFO - True
2024-04-02 04:26:00,887 - train - INFO - alphas:tensor([0.2175, 0.7825], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,887 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,887 - train - INFO - True
2024-04-02 04:26:00,888 - train - INFO - alphas:tensor([0.1062, 0.8938], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,888 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,888 - train - INFO - True
2024-04-02 04:26:00,889 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:26:00,889 - train - INFO - tau:0.7778213593991465
2024-04-02 04:26:00,889 - train - INFO - avg block size:10.310344827586206
2024-04-02 04:26:02,849 - train - INFO - Test: [   0/39]  Time: 1.957 (1.957)  Loss:  0.4573 (0.4573)  Acc@1: 88.6719 (88.6719)  Acc@5: 99.6094 (99.6094)
2024-04-02 04:27:14,065 - train - INFO - Test: [  39/39]  Time: 1.753 (1.829)  Loss:  0.4294 (0.4248)  Acc@1: 87.5000 (90.4600)  Acc@5: 100.0000 (99.6600)
2024-04-02 04:27:17,597 - train - INFO - Train: 28 [   0/195 (  0%)]  Loss:  1.943709 (1.9437)  Time: 3.406s,   75.17/s  (3.406s,   75.17/s)  LR: 5.049e-04  Data: 0.309 (0.309)
2024-04-02 04:29:47,516 - train - INFO - Train: 28 [  50/195 ( 26%)]  Loss:  1.612387 (1.7512)  Time: 2.961s,   86.46/s  (3.006s,   85.16/s)  LR: 5.049e-04  Data: 0.010 (0.021)
2024-04-02 04:32:16,423 - train - INFO - Train: 28 [ 100/195 ( 52%)]  Loss:  1.520434 (1.7198)  Time: 3.313s,   77.27/s  (2.992s,   85.55/s)  LR: 5.049e-04  Data: 0.012 (0.019)
2024-04-02 04:34:44,719 - train - INFO - Train: 28 [ 150/195 ( 77%)]  Loss:  1.335710 (1.7015)  Time: 2.975s,   86.06/s  (2.984s,   85.80/s)  LR: 5.049e-04  Data: 0.010 (0.018)
2024-04-02 04:36:53,636 - train - INFO - Train: 28 [ 194/195 (100%)]  Loss:  1.522892 (1.7032)  Time: 3.232s,   79.22/s  (2.971s,   86.15/s)  LR: 5.049e-04  Data: 0.000 (0.017)
2024-04-02 04:36:53,636 - train - INFO - True
2024-04-02 04:36:53,637 - train - INFO - alphas:tensor([0.1504, 0.8496], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,637 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,637 - train - INFO - True
2024-04-02 04:36:53,638 - train - INFO - alphas:tensor([0.2272, 0.7728], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,638 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,638 - train - INFO - True
2024-04-02 04:36:53,639 - train - INFO - alphas:tensor([0.6108, 0.3892], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,639 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,639 - train - INFO - True
2024-04-02 04:36:53,640 - train - INFO - alphas:tensor([0.5729, 0.4271], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,640 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,640 - train - INFO - True
2024-04-02 04:36:53,640 - train - INFO - alphas:tensor([0.3203, 0.6797], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,641 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,641 - train - INFO - True
2024-04-02 04:36:53,641 - train - INFO - alphas:tensor([0.4452, 0.5548], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,641 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,641 - train - INFO - True
2024-04-02 04:36:53,642 - train - INFO - alphas:tensor([0.6369, 0.3631], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,642 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,642 - train - INFO - True
2024-04-02 04:36:53,643 - train - INFO - alphas:tensor([0.5394, 0.4606], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,643 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,644 - train - INFO - True
2024-04-02 04:36:53,644 - train - INFO - alphas:tensor([0.4054, 0.5946], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,644 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,645 - train - INFO - True
2024-04-02 04:36:53,645 - train - INFO - alphas:tensor([0.5342, 0.4658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,645 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,645 - train - INFO - True
2024-04-02 04:36:53,646 - train - INFO - alphas:tensor([0.6426, 0.3574], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,646 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,646 - train - INFO - True
2024-04-02 04:36:53,647 - train - INFO - alphas:tensor([0.5168, 0.4832], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,647 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,647 - train - INFO - True
2024-04-02 04:36:53,648 - train - INFO - alphas:tensor([0.4189, 0.5811], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,648 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,648 - train - INFO - True
2024-04-02 04:36:53,648 - train - INFO - alphas:tensor([0.5217, 0.4783], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,649 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,649 - train - INFO - True
2024-04-02 04:36:53,649 - train - INFO - alphas:tensor([0.5992, 0.4008], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,649 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,649 - train - INFO - True
2024-04-02 04:36:53,650 - train - INFO - alphas:tensor([0.4383, 0.5617], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,650 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,650 - train - INFO - True
2024-04-02 04:36:53,651 - train - INFO - alphas:tensor([0.3899, 0.6101], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,651 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,651 - train - INFO - True
2024-04-02 04:36:53,665 - train - INFO - alphas:tensor([0.4390, 0.5610], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,666 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,666 - train - INFO - True
2024-04-02 04:36:53,666 - train - INFO - alphas:tensor([0.5079, 0.4921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,666 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,666 - train - INFO - True
2024-04-02 04:36:53,667 - train - INFO - alphas:tensor([0.3199, 0.6801], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,667 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,667 - train - INFO - True
2024-04-02 04:36:53,668 - train - INFO - alphas:tensor([0.3443, 0.6557], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,668 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,668 - train - INFO - True
2024-04-02 04:36:53,669 - train - INFO - alphas:tensor([0.4017, 0.5983], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,669 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,669 - train - INFO - True
2024-04-02 04:36:53,670 - train - INFO - alphas:tensor([0.4667, 0.5333], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,670 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,670 - train - INFO - True
2024-04-02 04:36:53,670 - train - INFO - alphas:tensor([0.2730, 0.7270], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,670 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,671 - train - INFO - True
2024-04-02 04:36:53,671 - train - INFO - alphas:tensor([0.2913, 0.7087], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,671 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,671 - train - INFO - True
2024-04-02 04:36:53,685 - train - INFO - alphas:tensor([0.3152, 0.6848], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,685 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,685 - train - INFO - True
2024-04-02 04:36:53,686 - train - INFO - alphas:tensor([0.2059, 0.7941], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,686 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,686 - train - INFO - True
2024-04-02 04:36:53,687 - train - INFO - alphas:tensor([0.0939, 0.9061], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,687 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,687 - train - INFO - True
2024-04-02 04:36:53,688 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:36:53,688 - train - INFO - tau:0.7700431458051551
2024-04-02 04:36:53,688 - train - INFO - avg block size:10.310344827586206
2024-04-02 04:36:55,446 - train - INFO - Test: [   0/39]  Time: 1.733 (1.733)  Loss:  0.4426 (0.4426)  Acc@1: 91.4062 (91.4062)  Acc@5: 99.6094 (99.6094)
2024-04-02 04:38:06,612 - train - INFO - Test: [  39/39]  Time: 1.819 (1.822)  Loss:  0.4529 (0.4153)  Acc@1: 81.2500 (91.1500)  Acc@5: 100.0000 (99.6600)
2024-04-02 04:38:09,915 - train - INFO - Train: 29 [   0/195 (  0%)]  Loss:  1.659638 (1.6596)  Time: 3.170s,   80.76/s  (3.170s,   80.76/s)  LR: 5.017e-04  Data: 0.302 (0.302)
2024-04-02 04:40:37,036 - train - INFO - Train: 29 [  50/195 ( 26%)]  Loss:  1.575065 (1.7267)  Time: 2.815s,   90.93/s  (2.947s,   86.87/s)  LR: 5.017e-04  Data: 0.027 (0.021)
2024-04-02 04:43:02,615 - train - INFO - Train: 29 [ 100/195 ( 52%)]  Loss:  1.941658 (1.7110)  Time: 2.977s,   85.98/s  (2.929s,   87.39/s)  LR: 5.017e-04  Data: 0.016 (0.018)
2024-04-02 04:45:32,416 - train - INFO - Train: 29 [ 150/195 ( 77%)]  Loss:  1.785958 (1.7105)  Time: 3.119s,   82.09/s  (2.951s,   86.74/s)  LR: 5.017e-04  Data: 0.005 (0.017)
2024-04-02 04:47:40,901 - train - INFO - Train: 29 [ 194/195 (100%)]  Loss:  1.321249 (1.7093)  Time: 2.993s,   85.53/s  (2.944s,   86.95/s)  LR: 5.017e-04  Data: 0.000 (0.016)
2024-04-02 04:47:40,905 - train - INFO - True
2024-04-02 04:47:40,907 - train - INFO - alphas:tensor([0.1398, 0.8602], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,907 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,907 - train - INFO - True
2024-04-02 04:47:40,907 - train - INFO - alphas:tensor([0.2172, 0.7828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,908 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,908 - train - INFO - True
2024-04-02 04:47:40,913 - train - INFO - alphas:tensor([0.6085, 0.3915], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,913 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,913 - train - INFO - True
2024-04-02 04:47:40,914 - train - INFO - alphas:tensor([0.5685, 0.4315], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,914 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,914 - train - INFO - True
2024-04-02 04:47:40,914 - train - INFO - alphas:tensor([0.3112, 0.6888], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,914 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,914 - train - INFO - True
2024-04-02 04:47:40,915 - train - INFO - alphas:tensor([0.4362, 0.5638], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,915 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,915 - train - INFO - True
2024-04-02 04:47:40,916 - train - INFO - alphas:tensor([0.6329, 0.3671], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,916 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,916 - train - INFO - True
2024-04-02 04:47:40,917 - train - INFO - alphas:tensor([0.5333, 0.4667], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,917 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,918 - train - INFO - True
2024-04-02 04:47:40,918 - train - INFO - alphas:tensor([0.3961, 0.6039], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,918 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,918 - train - INFO - True
2024-04-02 04:47:40,919 - train - INFO - alphas:tensor([0.5254, 0.4746], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,919 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,919 - train - INFO - True
2024-04-02 04:47:40,920 - train - INFO - alphas:tensor([0.6375, 0.3625], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,920 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,920 - train - INFO - True
2024-04-02 04:47:40,921 - train - INFO - alphas:tensor([0.5103, 0.4897], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,921 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,921 - train - INFO - True
2024-04-02 04:47:40,926 - train - INFO - alphas:tensor([0.4106, 0.5894], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,926 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,926 - train - INFO - True
2024-04-02 04:47:40,927 - train - INFO - alphas:tensor([0.5126, 0.4874], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,927 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,927 - train - INFO - True
2024-04-02 04:47:40,928 - train - INFO - alphas:tensor([0.5931, 0.4069], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,928 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,928 - train - INFO - True
2024-04-02 04:47:40,928 - train - INFO - alphas:tensor([0.4331, 0.5669], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,928 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,929 - train - INFO - True
2024-04-02 04:47:40,929 - train - INFO - alphas:tensor([0.3826, 0.6174], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,929 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,929 - train - INFO - True
2024-04-02 04:47:40,930 - train - INFO - alphas:tensor([0.4303, 0.5697], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,930 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,930 - train - INFO - True
2024-04-02 04:47:40,940 - train - INFO - alphas:tensor([0.4961, 0.5039], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,940 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,940 - train - INFO - True
2024-04-02 04:47:40,941 - train - INFO - alphas:tensor([0.3081, 0.6919], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,941 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,941 - train - INFO - True
2024-04-02 04:47:40,941 - train - INFO - alphas:tensor([0.3380, 0.6620], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,941 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,942 - train - INFO - True
2024-04-02 04:47:40,942 - train - INFO - alphas:tensor([0.3934, 0.6066], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,942 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,942 - train - INFO - True
2024-04-02 04:47:40,943 - train - INFO - alphas:tensor([0.4588, 0.5412], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,943 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,943 - train - INFO - True
2024-04-02 04:47:40,944 - train - INFO - alphas:tensor([0.2630, 0.7370], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,944 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,944 - train - INFO - True
2024-04-02 04:47:40,945 - train - INFO - alphas:tensor([0.2808, 0.7192], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,945 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,945 - train - INFO - True
2024-04-02 04:47:40,945 - train - INFO - alphas:tensor([0.3014, 0.6986], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,946 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,946 - train - INFO - True
2024-04-02 04:47:40,946 - train - INFO - alphas:tensor([0.1915, 0.8085], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,946 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,946 - train - INFO - True
2024-04-02 04:47:40,947 - train - INFO - alphas:tensor([0.0822, 0.9178], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,947 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,947 - train - INFO - True
2024-04-02 04:47:40,948 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:47:40,948 - train - INFO - tau:0.7623427143471035
2024-04-02 04:47:40,948 - train - INFO - avg block size:10.827586206896552
2024-04-02 04:47:42,882 - train - INFO - Test: [   0/39]  Time: 1.930 (1.930)  Loss:  0.4424 (0.4424)  Acc@1: 90.6250 (90.6250)  Acc@5: 99.6094 (99.6094)
2024-04-02 04:48:54,521 - train - INFO - Test: [  39/39]  Time: 1.774 (1.839)  Loss:  0.5449 (0.4335)  Acc@1: 81.2500 (90.0200)  Acc@5: 100.0000 (99.6900)
2024-04-02 04:48:57,781 - train - INFO - Train: 30 [   0/195 (  0%)]  Loss:  1.458879 (1.4589)  Time: 3.059s,   83.69/s  (3.059s,   83.69/s)  LR: 4.984e-04  Data: 0.371 (0.371)
2024-04-02 04:51:24,369 - train - INFO - Train: 30 [  50/195 ( 26%)]  Loss:  1.754434 (1.7078)  Time: 2.729s,   93.82/s  (2.934s,   87.25/s)  LR: 4.984e-04  Data: 0.006 (0.021)
2024-04-02 04:53:50,873 - train - INFO - Train: 30 [ 100/195 ( 52%)]  Loss:  1.482123 (1.7033)  Time: 2.816s,   90.90/s  (2.932s,   87.31/s)  LR: 4.984e-04  Data: 0.012 (0.017)
2024-04-02 04:56:17,569 - train - INFO - Train: 30 [ 150/195 ( 77%)]  Loss:  1.791764 (1.6996)  Time: 2.783s,   92.00/s  (2.933s,   87.29/s)  LR: 4.984e-04  Data: 0.012 (0.017)
2024-04-02 04:58:26,832 - train - INFO - Train: 30 [ 194/195 (100%)]  Loss:  1.584146 (1.6984)  Time: 2.811s,   91.08/s  (2.934s,   87.26/s)  LR: 4.984e-04  Data: 0.000 (0.016)
2024-04-02 04:58:26,833 - train - INFO - True
2024-04-02 04:58:26,838 - train - INFO - alphas:tensor([0.1317, 0.8683], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,839 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,839 - train - INFO - True
2024-04-02 04:58:26,839 - train - INFO - alphas:tensor([0.2082, 0.7918], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,840 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,840 - train - INFO - True
2024-04-02 04:58:26,840 - train - INFO - alphas:tensor([0.6054, 0.3946], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,840 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,840 - train - INFO - True
2024-04-02 04:58:26,841 - train - INFO - alphas:tensor([0.5644, 0.4356], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,841 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,841 - train - INFO - True
2024-04-02 04:58:26,842 - train - INFO - alphas:tensor([0.3043, 0.6957], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,842 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,842 - train - INFO - True
2024-04-02 04:58:26,843 - train - INFO - alphas:tensor([0.4301, 0.5699], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,843 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,843 - train - INFO - True
2024-04-02 04:58:26,844 - train - INFO - alphas:tensor([0.6296, 0.3704], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,844 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,844 - train - INFO - True
2024-04-02 04:58:26,845 - train - INFO - alphas:tensor([0.5304, 0.4696], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,845 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,845 - train - INFO - True
2024-04-02 04:58:26,846 - train - INFO - alphas:tensor([0.3936, 0.6064], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,846 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,846 - train - INFO - True
2024-04-02 04:58:26,851 - train - INFO - alphas:tensor([0.5237, 0.4763], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,851 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,851 - train - INFO - True
2024-04-02 04:58:26,852 - train - INFO - alphas:tensor([0.6339, 0.3661], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,852 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,852 - train - INFO - True
2024-04-02 04:58:26,853 - train - INFO - alphas:tensor([0.5062, 0.4938], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,853 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,853 - train - INFO - True
2024-04-02 04:58:26,854 - train - INFO - alphas:tensor([0.4050, 0.5950], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,854 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,854 - train - INFO - True
2024-04-02 04:58:26,855 - train - INFO - alphas:tensor([0.5076, 0.4924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,855 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,855 - train - INFO - True
2024-04-02 04:58:26,855 - train - INFO - alphas:tensor([0.5871, 0.4129], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,855 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,855 - train - INFO - True
2024-04-02 04:58:26,856 - train - INFO - alphas:tensor([0.4285, 0.5715], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,856 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,856 - train - INFO - True
2024-04-02 04:58:26,857 - train - INFO - alphas:tensor([0.3764, 0.6236], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,857 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,857 - train - INFO - True
2024-04-02 04:58:26,858 - train - INFO - alphas:tensor([0.4221, 0.5779], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,858 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,858 - train - INFO - True
2024-04-02 04:58:26,859 - train - INFO - alphas:tensor([0.4905, 0.5095], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,859 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,859 - train - INFO - True
2024-04-02 04:58:26,859 - train - INFO - alphas:tensor([0.3018, 0.6982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,860 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,860 - train - INFO - True
2024-04-02 04:58:26,860 - train - INFO - alphas:tensor([0.3290, 0.6710], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,860 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,860 - train - INFO - True
2024-04-02 04:58:26,861 - train - INFO - alphas:tensor([0.3831, 0.6169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,861 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,861 - train - INFO - True
2024-04-02 04:58:26,862 - train - INFO - alphas:tensor([0.4521, 0.5479], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,862 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,862 - train - INFO - True
2024-04-02 04:58:26,863 - train - INFO - alphas:tensor([0.2568, 0.7432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,863 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,863 - train - INFO - True
2024-04-02 04:58:26,864 - train - INFO - alphas:tensor([0.2711, 0.7289], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,864 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,864 - train - INFO - True
2024-04-02 04:58:26,864 - train - INFO - alphas:tensor([0.2877, 0.7123], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,865 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,865 - train - INFO - True
2024-04-02 04:58:26,865 - train - INFO - alphas:tensor([0.1782, 0.8218], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,865 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,865 - train - INFO - True
2024-04-02 04:58:26,866 - train - INFO - alphas:tensor([0.0720, 0.9280], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,866 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,866 - train - INFO - True
2024-04-02 04:58:26,867 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 04:58:26,867 - train - INFO - tau:0.7547192872036325
2024-04-02 04:58:26,867 - train - INFO - avg block size:10.827586206896552
2024-04-02 04:58:28,837 - train - INFO - Test: [   0/39]  Time: 1.968 (1.968)  Loss:  0.4006 (0.4006)  Acc@1: 90.2344 (90.2344)  Acc@5: 100.0000 (100.0000)
2024-04-02 04:59:39,964 - train - INFO - Test: [  39/39]  Time: 1.704 (1.827)  Loss:  0.5137 (0.3915)  Acc@1: 81.2500 (91.6000)  Acc@5: 100.0000 (99.6800)
2024-04-02 04:59:43,121 - train - INFO - Train: 31 [   0/195 (  0%)]  Loss:  1.669025 (1.6690)  Time: 2.987s,   85.70/s  (2.987s,   85.70/s)  LR: 4.951e-04  Data: 0.258 (0.258)
2024-04-02 05:02:11,427 - train - INFO - Train: 31 [  50/195 ( 26%)]  Loss:  1.683832 (1.6530)  Time: 2.948s,   86.85/s  (2.966s,   86.30/s)  LR: 4.951e-04  Data: 0.036 (0.019)
2024-04-02 05:04:39,844 - train - INFO - Train: 31 [ 100/195 ( 52%)]  Loss:  1.729093 (1.6749)  Time: 3.212s,   79.70/s  (2.967s,   86.27/s)  LR: 4.951e-04  Data: 0.006 (0.016)
2024-04-02 05:07:07,787 - train - INFO - Train: 31 [ 150/195 ( 77%)]  Loss:  1.967215 (1.6772)  Time: 2.896s,   88.41/s  (2.965s,   86.35/s)  LR: 4.951e-04  Data: 0.032 (0.016)
2024-04-02 05:09:20,380 - train - INFO - Train: 31 [ 194/195 (100%)]  Loss:  1.721662 (1.6851)  Time: 3.068s,   83.43/s  (2.976s,   86.03/s)  LR: 4.951e-04  Data: 0.000 (0.016)
2024-04-02 05:09:20,380 - train - INFO - True
2024-04-02 05:09:20,382 - train - INFO - alphas:tensor([0.1224, 0.8776], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,382 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,382 - train - INFO - True
2024-04-02 05:09:20,383 - train - INFO - alphas:tensor([0.1993, 0.8007], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,383 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,383 - train - INFO - True
2024-04-02 05:09:20,383 - train - INFO - alphas:tensor([0.6039, 0.3961], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,383 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,383 - train - INFO - True
2024-04-02 05:09:20,384 - train - INFO - alphas:tensor([0.5618, 0.4382], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,384 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,384 - train - INFO - True
2024-04-02 05:09:20,385 - train - INFO - alphas:tensor([0.2982, 0.7018], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,385 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,385 - train - INFO - True
2024-04-02 05:09:20,386 - train - INFO - alphas:tensor([0.4201, 0.5799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,386 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,386 - train - INFO - True
2024-04-02 05:09:20,387 - train - INFO - alphas:tensor([0.6273, 0.3727], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,387 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,387 - train - INFO - True
2024-04-02 05:09:20,387 - train - INFO - alphas:tensor([0.5283, 0.4717], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,388 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,388 - train - INFO - True
2024-04-02 05:09:20,389 - train - INFO - alphas:tensor([0.3861, 0.6139], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,389 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,389 - train - INFO - True
2024-04-02 05:09:20,390 - train - INFO - alphas:tensor([0.5157, 0.4843], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,390 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,390 - train - INFO - True
2024-04-02 05:09:20,390 - train - INFO - alphas:tensor([0.6313, 0.3687], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,390 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,390 - train - INFO - True
2024-04-02 05:09:20,391 - train - INFO - alphas:tensor([0.5055, 0.4945], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,391 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,391 - train - INFO - True
2024-04-02 05:09:20,392 - train - INFO - alphas:tensor([0.3987, 0.6013], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,392 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,392 - train - INFO - True
2024-04-02 05:09:20,393 - train - INFO - alphas:tensor([0.5048, 0.4952], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,393 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,393 - train - INFO - True
2024-04-02 05:09:20,394 - train - INFO - alphas:tensor([0.5836, 0.4164], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,394 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,394 - train - INFO - True
2024-04-02 05:09:20,394 - train - INFO - alphas:tensor([0.4257, 0.5743], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,394 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,395 - train - INFO - True
2024-04-02 05:09:20,395 - train - INFO - alphas:tensor([0.3683, 0.6317], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,395 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,395 - train - INFO - True
2024-04-02 05:09:20,396 - train - INFO - alphas:tensor([0.4133, 0.5867], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,396 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,396 - train - INFO - True
2024-04-02 05:09:20,397 - train - INFO - alphas:tensor([0.4839, 0.5161], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,397 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,397 - train - INFO - True
2024-04-02 05:09:20,398 - train - INFO - alphas:tensor([0.2955, 0.7045], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,398 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,398 - train - INFO - True
2024-04-02 05:09:20,398 - train - INFO - alphas:tensor([0.3213, 0.6787], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,399 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,399 - train - INFO - True
2024-04-02 05:09:20,399 - train - INFO - alphas:tensor([0.3757, 0.6243], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,399 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,399 - train - INFO - True
2024-04-02 05:09:20,400 - train - INFO - alphas:tensor([0.4470, 0.5530], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,400 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,400 - train - INFO - True
2024-04-02 05:09:20,401 - train - INFO - alphas:tensor([0.2515, 0.7485], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,401 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,401 - train - INFO - True
2024-04-02 05:09:20,402 - train - INFO - alphas:tensor([0.2639, 0.7361], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,402 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,402 - train - INFO - True
2024-04-02 05:09:20,403 - train - INFO - alphas:tensor([0.2740, 0.7260], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,403 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,403 - train - INFO - True
2024-04-02 05:09:20,403 - train - INFO - alphas:tensor([0.1693, 0.8307], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,403 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,404 - train - INFO - True
2024-04-02 05:09:20,404 - train - INFO - alphas:tensor([0.0631, 0.9369], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,404 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,404 - train - INFO - True
2024-04-02 05:09:20,405 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:09:20,405 - train - INFO - tau:0.7471720943315961
2024-04-02 05:09:20,405 - train - INFO - avg block size:10.827586206896552
2024-04-02 05:09:22,253 - train - INFO - Test: [   0/39]  Time: 1.845 (1.845)  Loss:  0.4683 (0.4683)  Acc@1: 88.6719 (88.6719)  Acc@5: 99.6094 (99.6094)
2024-04-02 05:10:33,126 - train - INFO - Test: [  39/39]  Time: 1.800 (1.818)  Loss:  0.4028 (0.4324)  Acc@1: 81.2500 (90.6700)  Acc@5: 100.0000 (99.6200)
2024-04-02 05:10:36,521 - train - INFO - Train: 32 [   0/195 (  0%)]  Loss:  1.753397 (1.7534)  Time: 3.196s,   80.10/s  (3.196s,   80.10/s)  LR: 4.916e-04  Data: 0.275 (0.275)
2024-04-02 05:13:01,369 - train - INFO - Train: 32 [  50/195 ( 26%)]  Loss:  1.606304 (1.7104)  Time: 2.728s,   93.85/s  (2.903s,   88.19/s)  LR: 4.916e-04  Data: 0.006 (0.019)
2024-04-02 05:15:30,625 - train - INFO - Train: 32 [ 100/195 ( 52%)]  Loss:  1.921807 (1.7143)  Time: 3.062s,   83.60/s  (2.943s,   86.97/s)  LR: 4.916e-04  Data: 0.014 (0.018)
2024-04-02 05:17:58,567 - train - INFO - Train: 32 [ 150/195 ( 77%)]  Loss:  1.923128 (1.7108)  Time: 2.900s,   88.27/s  (2.948s,   86.82/s)  LR: 4.916e-04  Data: 0.016 (0.017)
2024-04-02 05:20:10,220 - train - INFO - Train: 32 [ 194/195 (100%)]  Loss:  1.795884 (1.6982)  Time: 3.371s,   75.94/s  (2.958s,   86.54/s)  LR: 4.916e-04  Data: 0.000 (0.017)
2024-04-02 05:20:10,221 - train - INFO - True
2024-04-02 05:20:10,222 - train - INFO - alphas:tensor([0.1143, 0.8857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,222 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,222 - train - INFO - True
2024-04-02 05:20:10,223 - train - INFO - alphas:tensor([0.1911, 0.8089], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,223 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,223 - train - INFO - True
2024-04-02 05:20:10,224 - train - INFO - alphas:tensor([0.6017, 0.3983], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,224 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,224 - train - INFO - True
2024-04-02 05:20:10,224 - train - INFO - alphas:tensor([0.5579, 0.4421], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,225 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,225 - train - INFO - True
2024-04-02 05:20:10,225 - train - INFO - alphas:tensor([0.2894, 0.7106], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,225 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,225 - train - INFO - True
2024-04-02 05:20:10,226 - train - INFO - alphas:tensor([0.4109, 0.5891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,226 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,226 - train - INFO - True
2024-04-02 05:20:10,227 - train - INFO - alphas:tensor([0.6226, 0.3774], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,227 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,227 - train - INFO - True
2024-04-02 05:20:10,228 - train - INFO - alphas:tensor([0.5232, 0.4768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,228 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,228 - train - INFO - True
2024-04-02 05:20:10,229 - train - INFO - alphas:tensor([0.3803, 0.6197], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,229 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,229 - train - INFO - True
2024-04-02 05:20:10,230 - train - INFO - alphas:tensor([0.5119, 0.4881], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,230 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,230 - train - INFO - True
2024-04-02 05:20:10,231 - train - INFO - alphas:tensor([0.6278, 0.3722], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,231 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,231 - train - INFO - True
2024-04-02 05:20:10,232 - train - INFO - alphas:tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,232 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,232 - train - INFO - True
2024-04-02 05:20:10,232 - train - INFO - alphas:tensor([0.3924, 0.6076], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,232 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,232 - train - INFO - True
2024-04-02 05:20:10,233 - train - INFO - alphas:tensor([0.4991, 0.5009], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,233 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,233 - train - INFO - True
2024-04-02 05:20:10,234 - train - INFO - alphas:tensor([0.5774, 0.4226], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,234 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,234 - train - INFO - True
2024-04-02 05:20:10,235 - train - INFO - alphas:tensor([0.4178, 0.5822], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,235 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,235 - train - INFO - True
2024-04-02 05:20:10,236 - train - INFO - alphas:tensor([0.3624, 0.6376], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,236 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,236 - train - INFO - True
2024-04-02 05:20:10,236 - train - INFO - alphas:tensor([0.4064, 0.5936], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,236 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,237 - train - INFO - True
2024-04-02 05:20:10,237 - train - INFO - alphas:tensor([0.4801, 0.5199], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,237 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,237 - train - INFO - True
2024-04-02 05:20:10,238 - train - INFO - alphas:tensor([0.2936, 0.7064], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,238 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,238 - train - INFO - True
2024-04-02 05:20:10,239 - train - INFO - alphas:tensor([0.3163, 0.6837], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,239 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,239 - train - INFO - True
2024-04-02 05:20:10,240 - train - INFO - alphas:tensor([0.3699, 0.6301], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,240 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,240 - train - INFO - True
2024-04-02 05:20:10,240 - train - INFO - alphas:tensor([0.4379, 0.5621], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,241 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,241 - train - INFO - True
2024-04-02 05:20:10,241 - train - INFO - alphas:tensor([0.2418, 0.7582], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,241 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,241 - train - INFO - True
2024-04-02 05:20:10,242 - train - INFO - alphas:tensor([0.2557, 0.7443], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,242 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,242 - train - INFO - True
2024-04-02 05:20:10,243 - train - INFO - alphas:tensor([0.2606, 0.7394], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,243 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,243 - train - INFO - True
2024-04-02 05:20:10,244 - train - INFO - alphas:tensor([0.1593, 0.8407], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,244 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,244 - train - INFO - True
2024-04-02 05:20:10,245 - train - INFO - alphas:tensor([0.0551, 0.9449], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,245 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,245 - train - INFO - True
2024-04-02 05:20:10,245 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:20:10,245 - train - INFO - tau:0.7397003733882802
2024-04-02 05:20:10,245 - train - INFO - avg block size:11.344827586206897
2024-04-02 05:20:12,215 - train - INFO - Test: [   0/39]  Time: 1.967 (1.967)  Loss:  0.4390 (0.4390)  Acc@1: 89.8438 (89.8438)  Acc@5: 99.6094 (99.6094)
2024-04-02 05:21:23,571 - train - INFO - Test: [  39/39]  Time: 1.870 (1.833)  Loss:  0.5273 (0.4268)  Acc@1: 81.2500 (90.6300)  Acc@5: 100.0000 (99.5900)
2024-04-02 05:21:26,967 - train - INFO - Train: 33 [   0/195 (  0%)]  Loss:  1.829930 (1.8299)  Time: 3.231s,   79.24/s  (3.231s,   79.24/s)  LR: 4.880e-04  Data: 0.324 (0.324)
2024-04-02 05:23:52,633 - train - INFO - Train: 33 [  50/195 ( 26%)]  Loss:  1.396413 (1.6728)  Time: 2.607s,   98.19/s  (2.920s,   87.69/s)  LR: 4.880e-04  Data: 0.014 (0.019)
2024-04-02 05:26:21,608 - train - INFO - Train: 33 [ 100/195 ( 52%)]  Loss:  1.694717 (1.6954)  Time: 2.940s,   87.08/s  (2.949s,   86.81/s)  LR: 4.880e-04  Data: 0.005 (0.017)
2024-04-02 05:28:49,981 - train - INFO - Train: 33 [ 150/195 ( 77%)]  Loss:  1.558349 (1.6905)  Time: 3.349s,   76.44/s  (2.955s,   86.63/s)  LR: 4.880e-04  Data: 0.021 (0.016)
2024-04-02 05:31:00,580 - train - INFO - Train: 33 [ 194/195 (100%)]  Loss:  1.591213 (1.6894)  Time: 2.983s,   85.81/s  (2.958s,   86.54/s)  LR: 4.880e-04  Data: 0.000 (0.016)
2024-04-02 05:31:00,581 - train - INFO - True
2024-04-02 05:31:00,582 - train - INFO - alphas:tensor([0.1072, 0.8928], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,582 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,582 - train - INFO - True
2024-04-02 05:31:00,583 - train - INFO - alphas:tensor([0.1837, 0.8163], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,588 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,588 - train - INFO - True
2024-04-02 05:31:00,588 - train - INFO - alphas:tensor([0.5989, 0.4011], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,589 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,589 - train - INFO - True
2024-04-02 05:31:00,589 - train - INFO - alphas:tensor([0.5544, 0.4456], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,589 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,589 - train - INFO - True
2024-04-02 05:31:00,590 - train - INFO - alphas:tensor([0.2848, 0.7152], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,590 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,590 - train - INFO - True
2024-04-02 05:31:00,591 - train - INFO - alphas:tensor([0.4066, 0.5934], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,591 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,591 - train - INFO - True
2024-04-02 05:31:00,592 - train - INFO - alphas:tensor([0.6191, 0.3809], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,592 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,593 - train - INFO - True
2024-04-02 05:31:00,593 - train - INFO - alphas:tensor([0.5181, 0.4819], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,593 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,593 - train - INFO - True
2024-04-02 05:31:00,594 - train - INFO - alphas:tensor([0.3733, 0.6267], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,594 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,594 - train - INFO - True
2024-04-02 05:31:00,595 - train - INFO - alphas:tensor([0.5057, 0.4943], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,595 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,595 - train - INFO - True
2024-04-02 05:31:00,596 - train - INFO - alphas:tensor([0.6233, 0.3767], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,596 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,596 - train - INFO - True
2024-04-02 05:31:00,597 - train - INFO - alphas:tensor([0.4944, 0.5056], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,597 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,597 - train - INFO - True
2024-04-02 05:31:00,598 - train - INFO - alphas:tensor([0.3885, 0.6115], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,598 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,598 - train - INFO - True
2024-04-02 05:31:00,598 - train - INFO - alphas:tensor([0.4934, 0.5066], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,598 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,599 - train - INFO - True
2024-04-02 05:31:00,599 - train - INFO - alphas:tensor([0.5737, 0.4263], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,599 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,599 - train - INFO - True
2024-04-02 05:31:00,600 - train - INFO - alphas:tensor([0.4164, 0.5836], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,600 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,600 - train - INFO - True
2024-04-02 05:31:00,601 - train - INFO - alphas:tensor([0.3572, 0.6428], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,601 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,601 - train - INFO - True
2024-04-02 05:31:00,602 - train - INFO - alphas:tensor([0.4024, 0.5976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,602 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,602 - train - INFO - True
2024-04-02 05:31:00,603 - train - INFO - alphas:tensor([0.4718, 0.5282], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,603 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,603 - train - INFO - True
2024-04-02 05:31:00,608 - train - INFO - alphas:tensor([0.2869, 0.7131], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,608 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,608 - train - INFO - True
2024-04-02 05:31:00,609 - train - INFO - alphas:tensor([0.3105, 0.6895], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,609 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,609 - train - INFO - True
2024-04-02 05:31:00,610 - train - INFO - alphas:tensor([0.3651, 0.6349], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,610 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,610 - train - INFO - True
2024-04-02 05:31:00,610 - train - INFO - alphas:tensor([0.4329, 0.5671], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,611 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,611 - train - INFO - True
2024-04-02 05:31:00,611 - train - INFO - alphas:tensor([0.2344, 0.7656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,611 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,611 - train - INFO - True
2024-04-02 05:31:00,612 - train - INFO - alphas:tensor([0.2494, 0.7506], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,612 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,612 - train - INFO - True
2024-04-02 05:31:00,613 - train - INFO - alphas:tensor([0.2484, 0.7516], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,613 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,613 - train - INFO - True
2024-04-02 05:31:00,614 - train - INFO - alphas:tensor([0.1496, 0.8504], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,614 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,614 - train - INFO - True
2024-04-02 05:31:00,619 - train - INFO - alphas:tensor([0.0481, 0.9519], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,619 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,619 - train - INFO - True
2024-04-02 05:31:00,620 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:31:00,620 - train - INFO - tau:0.7323033696543974
2024-04-02 05:31:00,620 - train - INFO - avg block size:11.862068965517242
2024-04-02 05:31:02,507 - train - INFO - Test: [   0/39]  Time: 1.884 (1.884)  Loss:  0.4214 (0.4214)  Acc@1: 90.6250 (90.6250)  Acc@5: 99.6094 (99.6094)
2024-04-02 05:32:13,027 - train - INFO - Test: [  39/39]  Time: 1.829 (1.810)  Loss:  0.4788 (0.3951)  Acc@1: 81.2500 (91.2700)  Acc@5: 100.0000 (99.6200)
2024-04-02 05:32:16,790 - train - INFO - Train: 34 [   0/195 (  0%)]  Loss:  1.407151 (1.4072)  Time: 3.468s,   73.81/s  (3.468s,   73.81/s)  LR: 4.844e-04  Data: 0.285 (0.285)
2024-04-02 05:34:42,841 - train - INFO - Train: 34 [  50/195 ( 26%)]  Loss:  1.524010 (1.7065)  Time: 3.007s,   85.15/s  (2.932s,   87.32/s)  LR: 4.844e-04  Data: 0.016 (0.020)
2024-04-02 05:37:07,072 - train - INFO - Train: 34 [ 100/195 ( 52%)]  Loss:  1.587764 (1.6787)  Time: 2.960s,   86.50/s  (2.908s,   88.02/s)  LR: 4.844e-04  Data: 0.006 (0.018)
2024-04-02 05:39:33,256 - train - INFO - Train: 34 [ 150/195 ( 77%)]  Loss:  1.920046 (1.6788)  Time: 2.875s,   89.06/s  (2.913s,   87.87/s)  LR: 4.844e-04  Data: 0.013 (0.017)
2024-04-02 05:41:42,911 - train - INFO - Train: 34 [ 194/195 (100%)]  Loss:  1.917460 (1.6729)  Time: 3.122s,   82.00/s  (2.921s,   87.64/s)  LR: 4.844e-04  Data: 0.000 (0.016)
2024-04-02 05:41:42,921 - train - INFO - True
2024-04-02 05:41:42,922 - train - INFO - alphas:tensor([0.0998, 0.9002], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:42,922 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:42,922 - train - INFO - True
2024-04-02 05:41:42,923 - train - INFO - alphas:tensor([0.1761, 0.8239], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:42,923 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:42,923 - train - INFO - True
2024-04-02 05:41:42,923 - train - INFO - alphas:tensor([0.5952, 0.4048], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:42,924 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:42,924 - train - INFO - True
2024-04-02 05:41:42,924 - train - INFO - alphas:tensor([0.5496, 0.4504], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:42,924 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:42,924 - train - INFO - True
2024-04-02 05:41:42,925 - train - INFO - alphas:tensor([0.2796, 0.7204], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:42,925 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:42,925 - train - INFO - True
2024-04-02 05:41:42,926 - train - INFO - alphas:tensor([0.4003, 0.5997], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:42,926 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:42,930 - train - INFO - True
2024-04-02 05:41:42,931 - train - INFO - alphas:tensor([0.6143, 0.3857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:42,932 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:42,932 - train - INFO - True
2024-04-02 05:41:42,932 - train - INFO - alphas:tensor([0.5146, 0.4854], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:42,933 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:42,933 - train - INFO - True
2024-04-02 05:41:43,002 - train - INFO - alphas:tensor([0.3692, 0.6308], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,002 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,002 - train - INFO - True
2024-04-02 05:41:43,002 - train - INFO - alphas:tensor([0.5026, 0.4974], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,010 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,010 - train - INFO - True
2024-04-02 05:41:43,011 - train - INFO - alphas:tensor([0.6187, 0.3813], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,011 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,011 - train - INFO - True
2024-04-02 05:41:43,012 - train - INFO - alphas:tensor([0.4900, 0.5100], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,016 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,016 - train - INFO - True
2024-04-02 05:41:43,017 - train - INFO - alphas:tensor([0.3824, 0.6176], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,017 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,017 - train - INFO - True
2024-04-02 05:41:43,018 - train - INFO - alphas:tensor([0.4902, 0.5098], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,019 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,019 - train - INFO - True
2024-04-02 05:41:43,020 - train - INFO - alphas:tensor([0.5710, 0.4290], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,020 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,020 - train - INFO - True
2024-04-02 05:41:43,021 - train - INFO - alphas:tensor([0.4144, 0.5856], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,021 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,021 - train - INFO - True
2024-04-02 05:41:43,022 - train - INFO - alphas:tensor([0.3543, 0.6457], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,026 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,026 - train - INFO - True
2024-04-02 05:41:43,040 - train - INFO - alphas:tensor([0.3989, 0.6011], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,040 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,040 - train - INFO - True
2024-04-02 05:41:43,041 - train - INFO - alphas:tensor([0.4676, 0.5324], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,045 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,045 - train - INFO - True
2024-04-02 05:41:43,046 - train - INFO - alphas:tensor([0.2831, 0.7169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,046 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,046 - train - INFO - True
2024-04-02 05:41:43,047 - train - INFO - alphas:tensor([0.3023, 0.6977], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,047 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,047 - train - INFO - True
2024-04-02 05:41:43,048 - train - INFO - alphas:tensor([0.3562, 0.6438], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,048 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,048 - train - INFO - True
2024-04-02 05:41:43,049 - train - INFO - alphas:tensor([0.4286, 0.5714], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,049 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,049 - train - INFO - True
2024-04-02 05:41:43,049 - train - INFO - alphas:tensor([0.2300, 0.7700], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,049 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,049 - train - INFO - True
2024-04-02 05:41:43,050 - train - INFO - alphas:tensor([0.2427, 0.7573], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,050 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,050 - train - INFO - True
2024-04-02 05:41:43,051 - train - INFO - alphas:tensor([0.2363, 0.7637], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,051 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,051 - train - INFO - True
2024-04-02 05:41:43,056 - train - INFO - alphas:tensor([0.1417, 0.8583], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,056 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,056 - train - INFO - True
2024-04-02 05:41:43,061 - train - INFO - alphas:tensor([0.0420, 0.9580], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,062 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,062 - train - INFO - True
2024-04-02 05:41:43,062 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:41:43,062 - train - INFO - tau:0.7249803359578534
2024-04-02 05:41:43,062 - train - INFO - avg block size:11.862068965517242
2024-04-02 05:41:44,933 - train - INFO - Test: [   0/39]  Time: 1.859 (1.859)  Loss:  0.4233 (0.4233)  Acc@1: 89.4531 (89.4531)  Acc@5: 99.2188 (99.2188)
2024-04-02 05:42:55,680 - train - INFO - Test: [  39/39]  Time: 1.940 (1.815)  Loss:  0.4788 (0.3911)  Acc@1: 81.2500 (91.5300)  Acc@5: 100.0000 (99.6600)
2024-04-02 05:42:59,068 - train - INFO - Train: 35 [   0/195 (  0%)]  Loss:  1.863859 (1.8639)  Time: 3.241s,   78.99/s  (3.241s,   78.99/s)  LR: 4.806e-04  Data: 0.368 (0.368)
2024-04-02 05:45:27,250 - train - INFO - Train: 35 [  50/195 ( 26%)]  Loss:  1.830926 (1.6734)  Time: 3.019s,   84.81/s  (2.969s,   86.22/s)  LR: 4.806e-04  Data: 0.036 (0.021)
2024-04-02 05:47:53,725 - train - INFO - Train: 35 [ 100/195 ( 52%)]  Loss:  1.365284 (1.6726)  Time: 3.064s,   83.54/s  (2.949s,   86.80/s)  LR: 4.806e-04  Data: 0.019 (0.018)
2024-04-02 05:50:21,982 - train - INFO - Train: 35 [ 150/195 ( 77%)]  Loss:  1.957849 (1.6856)  Time: 3.083s,   83.04/s  (2.955s,   86.64/s)  LR: 4.806e-04  Data: 0.014 (0.017)
2024-04-02 05:52:32,002 - train - INFO - Train: 35 [ 194/195 (100%)]  Loss:  1.398553 (1.6882)  Time: 3.063s,   83.59/s  (2.955s,   86.64/s)  LR: 4.806e-04  Data: 0.000 (0.017)
2024-04-02 05:52:32,002 - train - INFO - True
2024-04-02 05:52:32,004 - train - INFO - alphas:tensor([0.0929, 0.9071], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,004 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,004 - train - INFO - True
2024-04-02 05:52:32,005 - train - INFO - alphas:tensor([0.1683, 0.8317], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,005 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,005 - train - INFO - True
2024-04-02 05:52:32,010 - train - INFO - alphas:tensor([0.5933, 0.4067], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,010 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,010 - train - INFO - True
2024-04-02 05:52:32,011 - train - INFO - alphas:tensor([0.5483, 0.4517], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,011 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,011 - train - INFO - True
2024-04-02 05:52:32,012 - train - INFO - alphas:tensor([0.2720, 0.7280], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,012 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,012 - train - INFO - True
2024-04-02 05:52:32,012 - train - INFO - alphas:tensor([0.3909, 0.6091], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,013 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,013 - train - INFO - True
2024-04-02 05:52:32,013 - train - INFO - alphas:tensor([0.6122, 0.3878], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,018 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,019 - train - INFO - True
2024-04-02 05:52:32,019 - train - INFO - alphas:tensor([0.5109, 0.4891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,019 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,019 - train - INFO - True
2024-04-02 05:52:32,020 - train - INFO - alphas:tensor([0.3646, 0.6354], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,020 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,020 - train - INFO - True
2024-04-02 05:52:32,021 - train - INFO - alphas:tensor([0.4953, 0.5047], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,021 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,021 - train - INFO - True
2024-04-02 05:52:32,022 - train - INFO - alphas:tensor([0.6152, 0.3848], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,022 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,022 - train - INFO - True
2024-04-02 05:52:32,027 - train - INFO - alphas:tensor([0.4843, 0.5157], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,027 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,027 - train - INFO - True
2024-04-02 05:52:32,028 - train - INFO - alphas:tensor([0.3758, 0.6242], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,028 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,028 - train - INFO - True
2024-04-02 05:52:32,029 - train - INFO - alphas:tensor([0.4811, 0.5189], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,029 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,029 - train - INFO - True
2024-04-02 05:52:32,034 - train - INFO - alphas:tensor([0.5666, 0.4334], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,034 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,034 - train - INFO - True
2024-04-02 05:52:32,035 - train - INFO - alphas:tensor([0.4105, 0.5895], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,035 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,035 - train - INFO - True
2024-04-02 05:52:32,036 - train - INFO - alphas:tensor([0.3486, 0.6514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,036 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,036 - train - INFO - True
2024-04-02 05:52:32,036 - train - INFO - alphas:tensor([0.3942, 0.6058], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,037 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,037 - train - INFO - True
2024-04-02 05:52:32,037 - train - INFO - alphas:tensor([0.4624, 0.5376], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,037 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,037 - train - INFO - True
2024-04-02 05:52:32,038 - train - INFO - alphas:tensor([0.2792, 0.7208], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,038 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,038 - train - INFO - True
2024-04-02 05:52:32,039 - train - INFO - alphas:tensor([0.2977, 0.7023], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,039 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,039 - train - INFO - True
2024-04-02 05:52:32,040 - train - INFO - alphas:tensor([0.3511, 0.6489], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,040 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,040 - train - INFO - True
2024-04-02 05:52:32,041 - train - INFO - alphas:tensor([0.4236, 0.5764], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,041 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,041 - train - INFO - True
2024-04-02 05:52:32,041 - train - INFO - alphas:tensor([0.2233, 0.7767], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,042 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,042 - train - INFO - True
2024-04-02 05:52:32,042 - train - INFO - alphas:tensor([0.2357, 0.7643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,042 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,042 - train - INFO - True
2024-04-02 05:52:32,047 - train - INFO - alphas:tensor([0.2241, 0.7759], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,048 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,048 - train - INFO - True
2024-04-02 05:52:32,048 - train - INFO - alphas:tensor([0.1309, 0.8691], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,048 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,048 - train - INFO - True
2024-04-02 05:52:32,049 - train - INFO - alphas:tensor([0.0365, 0.9635], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,049 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,049 - train - INFO - True
2024-04-02 05:52:32,076 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 05:52:32,076 - train - INFO - tau:0.7177305325982748
2024-04-02 05:52:32,077 - train - INFO - avg block size:12.379310344827585
2024-04-02 05:52:33,983 - train - INFO - Test: [   0/39]  Time: 1.904 (1.904)  Loss:  0.4507 (0.4507)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.6094 (99.6094)
2024-04-02 05:53:44,311 - train - INFO - Test: [  39/39]  Time: 1.855 (1.805)  Loss:  0.5771 (0.4348)  Acc@1: 81.2500 (90.9700)  Acc@5: 100.0000 (99.6600)
2024-04-02 05:53:47,990 - train - INFO - Train: 36 [   0/195 (  0%)]  Loss:  1.270184 (1.2702)  Time: 3.390s,   75.52/s  (3.390s,   75.52/s)  LR: 4.768e-04  Data: 0.347 (0.347)
2024-04-02 05:56:16,928 - train - INFO - Train: 36 [  50/195 ( 26%)]  Loss:  1.683431 (1.6542)  Time: 3.007s,   85.14/s  (2.987s,   85.71/s)  LR: 4.768e-04  Data: 0.018 (0.022)
2024-04-02 05:58:42,343 - train - INFO - Train: 36 [ 100/195 ( 52%)]  Loss:  1.823208 (1.6763)  Time: 3.012s,   85.00/s  (2.948s,   86.84/s)  LR: 4.768e-04  Data: 0.018 (0.019)
2024-04-02 06:01:10,695 - train - INFO - Train: 36 [ 150/195 ( 77%)]  Loss:  1.855124 (1.6708)  Time: 2.803s,   91.32/s  (2.954s,   86.65/s)  LR: 4.768e-04  Data: 0.005 (0.017)
2024-04-02 06:03:22,221 - train - INFO - Train: 36 [ 194/195 (100%)]  Loss:  1.901853 (1.6686)  Time: 2.665s,   96.08/s  (2.962s,   86.42/s)  LR: 4.768e-04  Data: 0.000 (0.017)
2024-04-02 06:03:22,221 - train - INFO - True
2024-04-02 06:03:22,223 - train - INFO - alphas:tensor([0.0863, 0.9137], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,223 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,223 - train - INFO - True
2024-04-02 06:03:22,228 - train - INFO - alphas:tensor([0.1635, 0.8365], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,228 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,228 - train - INFO - True
2024-04-02 06:03:22,229 - train - INFO - alphas:tensor([0.5896, 0.4104], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,229 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,229 - train - INFO - True
2024-04-02 06:03:22,230 - train - INFO - alphas:tensor([0.5427, 0.4573], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,230 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,230 - train - INFO - True
2024-04-02 06:03:22,230 - train - INFO - alphas:tensor([0.2665, 0.7335], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,231 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,231 - train - INFO - True
2024-04-02 06:03:22,231 - train - INFO - alphas:tensor([0.3876, 0.6124], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,236 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,236 - train - INFO - True
2024-04-02 06:03:22,236 - train - INFO - alphas:tensor([0.6082, 0.3918], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,238 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,246 - train - INFO - True
2024-04-02 06:03:22,247 - train - INFO - alphas:tensor([0.5057, 0.4943], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,252 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,252 - train - INFO - True
2024-04-02 06:03:22,258 - train - INFO - alphas:tensor([0.3585, 0.6415], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,258 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,258 - train - INFO - True
2024-04-02 06:03:22,258 - train - INFO - alphas:tensor([0.4913, 0.5087], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,258 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,259 - train - INFO - True
2024-04-02 06:03:22,259 - train - INFO - alphas:tensor([0.6124, 0.3876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,268 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,268 - train - INFO - True
2024-04-02 06:03:22,269 - train - INFO - alphas:tensor([0.4809, 0.5191], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,269 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,269 - train - INFO - True
2024-04-02 06:03:22,269 - train - INFO - alphas:tensor([0.3731, 0.6269], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,274 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,274 - train - INFO - True
2024-04-02 06:03:22,275 - train - INFO - alphas:tensor([0.4788, 0.5212], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,275 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,275 - train - INFO - True
2024-04-02 06:03:22,276 - train - INFO - alphas:tensor([0.5610, 0.4390], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,276 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,276 - train - INFO - True
2024-04-02 06:03:22,277 - train - INFO - alphas:tensor([0.4028, 0.5972], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,277 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,277 - train - INFO - True
2024-04-02 06:03:22,277 - train - INFO - alphas:tensor([0.3403, 0.6597], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,277 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,278 - train - INFO - True
2024-04-02 06:03:22,278 - train - INFO - alphas:tensor([0.3872, 0.6128], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,278 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,278 - train - INFO - True
2024-04-02 06:03:22,279 - train - INFO - alphas:tensor([0.4564, 0.5436], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,279 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,279 - train - INFO - True
2024-04-02 06:03:22,280 - train - INFO - alphas:tensor([0.2728, 0.7272], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,280 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,280 - train - INFO - True
2024-04-02 06:03:22,281 - train - INFO - alphas:tensor([0.2901, 0.7099], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,281 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,281 - train - INFO - True
2024-04-02 06:03:22,281 - train - INFO - alphas:tensor([0.3409, 0.6591], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,282 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,282 - train - INFO - True
2024-04-02 06:03:22,282 - train - INFO - alphas:tensor([0.4176, 0.5824], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,282 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,282 - train - INFO - True
2024-04-02 06:03:22,287 - train - INFO - alphas:tensor([0.2168, 0.7832], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,288 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,288 - train - INFO - True
2024-04-02 06:03:22,288 - train - INFO - alphas:tensor([0.2301, 0.7699], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,288 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,288 - train - INFO - True
2024-04-02 06:03:22,302 - train - INFO - alphas:tensor([0.2132, 0.7868], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,302 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,302 - train - INFO - True
2024-04-02 06:03:22,303 - train - INFO - alphas:tensor([0.1232, 0.8768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,303 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,303 - train - INFO - True
2024-04-02 06:03:22,304 - train - INFO - alphas:tensor([0.0318, 0.9682], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,304 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,304 - train - INFO - True
2024-04-02 06:03:22,305 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:03:22,305 - train - INFO - tau:0.7105532272722921
2024-04-02 06:03:22,305 - train - INFO - avg block size:12.379310344827585
2024-04-02 06:03:24,199 - train - INFO - Test: [   0/39]  Time: 1.891 (1.891)  Loss:  0.4258 (0.4258)  Acc@1: 88.6719 (88.6719)  Acc@5: 100.0000 (100.0000)
2024-04-02 06:04:34,230 - train - INFO - Test: [  39/39]  Time: 1.794 (1.798)  Loss:  0.4380 (0.4020)  Acc@1: 87.5000 (91.0000)  Acc@5: 100.0000 (99.6400)
2024-04-02 06:04:37,342 - train - INFO - Train: 37 [   0/195 (  0%)]  Loss:  1.882905 (1.8829)  Time: 2.914s,   87.84/s  (2.914s,   87.84/s)  LR: 4.729e-04  Data: 0.310 (0.310)
2024-04-02 06:07:05,455 - train - INFO - Train: 37 [  50/195 ( 26%)]  Loss:  1.664727 (1.7067)  Time: 2.868s,   89.27/s  (2.961s,   86.45/s)  LR: 4.729e-04  Data: 0.005 (0.019)
2024-04-02 06:09:32,913 - train - INFO - Train: 37 [ 100/195 ( 52%)]  Loss:  1.829170 (1.7001)  Time: 3.257s,   78.60/s  (2.955s,   86.63/s)  LR: 4.729e-04  Data: 0.018 (0.017)
2024-04-02 06:11:59,755 - train - INFO - Train: 37 [ 150/195 ( 77%)]  Loss:  1.513811 (1.6842)  Time: 2.715s,   94.30/s  (2.949s,   86.81/s)  LR: 4.729e-04  Data: 0.014 (0.016)
2024-04-02 06:14:09,949 - train - INFO - Train: 37 [ 194/195 (100%)]  Loss:  1.817699 (1.6804)  Time: 3.177s,   80.59/s  (2.951s,   86.74/s)  LR: 4.729e-04  Data: 0.000 (0.015)
2024-04-02 06:14:09,949 - train - INFO - True
2024-04-02 06:14:09,951 - train - INFO - alphas:tensor([0.0803, 0.9197], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,951 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,951 - train - INFO - True
2024-04-02 06:14:09,951 - train - INFO - alphas:tensor([0.1566, 0.8434], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,952 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,952 - train - INFO - True
2024-04-02 06:14:09,952 - train - INFO - alphas:tensor([0.5879, 0.4121], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,952 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,953 - train - INFO - True
2024-04-02 06:14:09,953 - train - INFO - alphas:tensor([0.5396, 0.4604], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,953 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,953 - train - INFO - True
2024-04-02 06:14:09,954 - train - INFO - alphas:tensor([0.2609, 0.7391], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,954 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,954 - train - INFO - True
2024-04-02 06:14:09,955 - train - INFO - alphas:tensor([0.3792, 0.6208], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,955 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,955 - train - INFO - True
2024-04-02 06:14:09,956 - train - INFO - alphas:tensor([0.6043, 0.3957], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,956 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,956 - train - INFO - True
2024-04-02 06:14:09,957 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,957 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,957 - train - INFO - True
2024-04-02 06:14:09,958 - train - INFO - alphas:tensor([0.3534, 0.6466], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,958 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,958 - train - INFO - True
2024-04-02 06:14:09,959 - train - INFO - alphas:tensor([0.4862, 0.5138], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,959 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,959 - train - INFO - True
2024-04-02 06:14:09,964 - train - INFO - alphas:tensor([0.6107, 0.3893], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,964 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,964 - train - INFO - True
2024-04-02 06:14:09,965 - train - INFO - alphas:tensor([0.4783, 0.5217], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,965 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,965 - train - INFO - True
2024-04-02 06:14:09,966 - train - INFO - alphas:tensor([0.3657, 0.6343], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,966 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,966 - train - INFO - True
2024-04-02 06:14:09,966 - train - INFO - alphas:tensor([0.4725, 0.5275], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,967 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,967 - train - INFO - True
2024-04-02 06:14:09,976 - train - INFO - alphas:tensor([0.5584, 0.4416], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,976 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,976 - train - INFO - True
2024-04-02 06:14:09,977 - train - INFO - alphas:tensor([0.4022, 0.5978], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,977 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,977 - train - INFO - True
2024-04-02 06:14:09,978 - train - INFO - alphas:tensor([0.3367, 0.6633], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,978 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,978 - train - INFO - True
2024-04-02 06:14:09,979 - train - INFO - alphas:tensor([0.3830, 0.6170], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,979 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,979 - train - INFO - True
2024-04-02 06:14:09,979 - train - INFO - alphas:tensor([0.4511, 0.5489], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,980 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,980 - train - INFO - True
2024-04-02 06:14:09,980 - train - INFO - alphas:tensor([0.2667, 0.7333], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,980 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,980 - train - INFO - True
2024-04-02 06:14:09,981 - train - INFO - alphas:tensor([0.2847, 0.7153], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,981 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,981 - train - INFO - True
2024-04-02 06:14:09,982 - train - INFO - alphas:tensor([0.3341, 0.6659], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,982 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,982 - train - INFO - True
2024-04-02 06:14:09,983 - train - INFO - alphas:tensor([0.4109, 0.5891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,983 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,983 - train - INFO - True
2024-04-02 06:14:09,984 - train - INFO - alphas:tensor([0.2110, 0.7890], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,984 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,984 - train - INFO - True
2024-04-02 06:14:09,984 - train - INFO - alphas:tensor([0.2239, 0.7761], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,984 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,985 - train - INFO - True
2024-04-02 06:14:09,985 - train - INFO - alphas:tensor([0.2033, 0.7967], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,985 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,985 - train - INFO - True
2024-04-02 06:14:09,986 - train - INFO - alphas:tensor([0.1150, 0.8850], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,986 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,986 - train - INFO - True
2024-04-02 06:14:09,987 - train - INFO - alphas:tensor([0.0276, 0.9724], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,987 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,987 - train - INFO - True
2024-04-02 06:14:09,988 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:14:09,988 - train - INFO - tau:0.7034476949995692
2024-04-02 06:14:09,988 - train - INFO - avg block size:12.379310344827585
2024-04-02 06:14:11,862 - train - INFO - Test: [   0/39]  Time: 1.871 (1.871)  Loss:  0.4150 (0.4150)  Acc@1: 89.0625 (89.0625)  Acc@5: 99.6094 (99.6094)
2024-04-02 06:15:22,916 - train - INFO - Test: [  39/39]  Time: 1.771 (1.823)  Loss:  0.4268 (0.3870)  Acc@1: 87.5000 (91.1800)  Acc@5: 100.0000 (99.6700)
2024-04-02 06:15:26,617 - train - INFO - Train: 38 [   0/195 (  0%)]  Loss:  1.527620 (1.5276)  Time: 3.517s,   72.79/s  (3.517s,   72.79/s)  LR: 4.689e-04  Data: 0.343 (0.343)
2024-04-02 06:17:50,726 - train - INFO - Train: 38 [  50/195 ( 26%)]  Loss:  1.364576 (1.6562)  Time: 3.064s,   83.55/s  (2.895s,   88.44/s)  LR: 4.689e-04  Data: 0.010 (0.020)
2024-04-02 06:20:19,207 - train - INFO - Train: 38 [ 100/195 ( 52%)]  Loss:  1.648617 (1.6599)  Time: 2.583s,   99.09/s  (2.932s,   87.32/s)  LR: 4.689e-04  Data: 0.023 (0.017)
2024-04-02 06:22:46,592 - train - INFO - Train: 38 [ 150/195 ( 77%)]  Loss:  1.659404 (1.6662)  Time: 3.164s,   80.92/s  (2.937s,   87.17/s)  LR: 4.689e-04  Data: 0.014 (0.017)
2024-04-02 06:24:54,876 - train - INFO - Train: 38 [ 194/195 (100%)]  Loss:  1.542596 (1.6689)  Time: 2.721s,   94.08/s  (2.932s,   87.31/s)  LR: 4.689e-04  Data: 0.000 (0.016)
2024-04-02 06:24:54,877 - train - INFO - True
2024-04-02 06:24:54,883 - train - INFO - alphas:tensor([0.0746, 0.9254], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,884 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,884 - train - INFO - True
2024-04-02 06:24:54,884 - train - INFO - alphas:tensor([0.1513, 0.8487], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,884 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,884 - train - INFO - True
2024-04-02 06:24:54,885 - train - INFO - alphas:tensor([0.5856, 0.4144], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,885 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,885 - train - INFO - True
2024-04-02 06:24:54,886 - train - INFO - alphas:tensor([0.5373, 0.4627], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,886 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,886 - train - INFO - True
2024-04-02 06:24:54,887 - train - INFO - alphas:tensor([0.2552, 0.7448], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,887 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,887 - train - INFO - True
2024-04-02 06:24:54,888 - train - INFO - alphas:tensor([0.3730, 0.6270], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,888 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,888 - train - INFO - True
2024-04-02 06:24:54,889 - train - INFO - alphas:tensor([0.6034, 0.3966], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,889 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,889 - train - INFO - True
2024-04-02 06:24:54,890 - train - INFO - alphas:tensor([0.5017, 0.4983], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,890 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,890 - train - INFO - True
2024-04-02 06:24:54,891 - train - INFO - alphas:tensor([0.3499, 0.6501], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,891 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,891 - train - INFO - True
2024-04-02 06:24:54,892 - train - INFO - alphas:tensor([0.4831, 0.5169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,892 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,892 - train - INFO - True
2024-04-02 06:24:54,892 - train - INFO - alphas:tensor([0.6093, 0.3907], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,892 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,893 - train - INFO - True
2024-04-02 06:24:54,893 - train - INFO - alphas:tensor([0.4781, 0.5219], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,893 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,893 - train - INFO - True
2024-04-02 06:24:54,894 - train - INFO - alphas:tensor([0.3638, 0.6362], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,894 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,894 - train - INFO - True
2024-04-02 06:24:54,895 - train - INFO - alphas:tensor([0.4719, 0.5281], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,895 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,895 - train - INFO - True
2024-04-02 06:24:54,896 - train - INFO - alphas:tensor([0.5538, 0.4462], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,896 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,896 - train - INFO - True
2024-04-02 06:24:54,896 - train - INFO - alphas:tensor([0.3976, 0.6024], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,897 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,897 - train - INFO - True
2024-04-02 06:24:54,897 - train - INFO - alphas:tensor([0.3324, 0.6676], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,897 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,897 - train - INFO - True
2024-04-02 06:24:54,898 - train - INFO - alphas:tensor([0.3790, 0.6210], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,898 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,898 - train - INFO - True
2024-04-02 06:24:54,899 - train - INFO - alphas:tensor([0.4465, 0.5535], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,899 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,899 - train - INFO - True
2024-04-02 06:24:54,900 - train - INFO - alphas:tensor([0.2645, 0.7355], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,900 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,900 - train - INFO - True
2024-04-02 06:24:54,901 - train - INFO - alphas:tensor([0.2806, 0.7194], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,901 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,901 - train - INFO - True
2024-04-02 06:24:54,901 - train - INFO - alphas:tensor([0.3299, 0.6701], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,901 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,902 - train - INFO - True
2024-04-02 06:24:54,902 - train - INFO - alphas:tensor([0.4068, 0.5932], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,902 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,902 - train - INFO - True
2024-04-02 06:24:54,903 - train - INFO - alphas:tensor([0.2055, 0.7945], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,903 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,903 - train - INFO - True
2024-04-02 06:24:54,904 - train - INFO - alphas:tensor([0.2179, 0.7821], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,904 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,904 - train - INFO - True
2024-04-02 06:24:54,905 - train - INFO - alphas:tensor([0.1932, 0.8068], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,905 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,905 - train - INFO - True
2024-04-02 06:24:54,905 - train - INFO - alphas:tensor([0.1084, 0.8916], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,906 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,906 - train - INFO - True
2024-04-02 06:24:54,906 - train - INFO - alphas:tensor([0.0241, 0.9759], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,906 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,906 - train - INFO - True
2024-04-02 06:24:54,907 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:24:54,907 - train - INFO - tau:0.6964132180495735
2024-04-02 06:24:54,907 - train - INFO - avg block size:12.379310344827585
2024-04-02 06:24:56,747 - train - INFO - Test: [   0/39]  Time: 1.837 (1.837)  Loss:  0.4133 (0.4133)  Acc@1: 91.0156 (91.0156)  Acc@5: 99.2188 (99.2188)
2024-04-02 06:26:07,553 - train - INFO - Test: [  39/39]  Time: 1.860 (1.816)  Loss:  0.4355 (0.3957)  Acc@1: 81.2500 (91.3700)  Acc@5: 100.0000 (99.6900)
2024-04-02 06:26:10,854 - train - INFO - Train: 39 [   0/195 (  0%)]  Loss:  1.806502 (1.8065)  Time: 3.092s,   82.80/s  (3.092s,   82.80/s)  LR: 4.648e-04  Data: 0.280 (0.280)
2024-04-02 06:28:39,779 - train - INFO - Train: 39 [  50/195 ( 26%)]  Loss:  1.454223 (1.6522)  Time: 3.263s,   78.46/s  (2.981s,   85.89/s)  LR: 4.648e-04  Data: 0.014 (0.017)
2024-04-02 06:31:08,137 - train - INFO - Train: 39 [ 100/195 ( 52%)]  Loss:  1.899423 (1.6811)  Time: 2.744s,   93.28/s  (2.974s,   86.09/s)  LR: 4.648e-04  Data: 0.018 (0.017)
2024-04-02 06:33:36,922 - train - INFO - Train: 39 [ 150/195 ( 77%)]  Loss:  1.800379 (1.6810)  Time: 2.607s,   98.20/s  (2.974s,   86.07/s)  LR: 4.648e-04  Data: 0.010 (0.016)
2024-04-02 06:35:44,564 - train - INFO - Train: 39 [ 194/195 (100%)]  Loss:  1.675990 (1.6648)  Time: 2.786s,   91.90/s  (2.958s,   86.55/s)  LR: 4.648e-04  Data: 0.000 (0.015)
2024-04-02 06:35:44,569 - train - INFO - True
2024-04-02 06:35:44,570 - train - INFO - alphas:tensor([0.0691, 0.9309], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,570 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,570 - train - INFO - True
2024-04-02 06:35:44,571 - train - INFO - alphas:tensor([0.1461, 0.8539], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,575 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,575 - train - INFO - True
2024-04-02 06:35:44,576 - train - INFO - alphas:tensor([0.5815, 0.4185], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,576 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,576 - train - INFO - True
2024-04-02 06:35:44,577 - train - INFO - alphas:tensor([0.5336, 0.4664], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,577 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,577 - train - INFO - True
2024-04-02 06:35:44,578 - train - INFO - alphas:tensor([0.2505, 0.7495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,578 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,578 - train - INFO - True
2024-04-02 06:35:44,587 - train - INFO - alphas:tensor([0.3680, 0.6320], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,587 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,587 - train - INFO - True
2024-04-02 06:35:44,588 - train - INFO - alphas:tensor([0.5976, 0.4024], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,593 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,593 - train - INFO - True
2024-04-02 06:35:44,593 - train - INFO - alphas:tensor([0.4945, 0.5055], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,598 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,598 - train - INFO - True
2024-04-02 06:35:44,599 - train - INFO - alphas:tensor([0.3440, 0.6560], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,599 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,599 - train - INFO - True
2024-04-02 06:35:44,600 - train - INFO - alphas:tensor([0.4785, 0.5215], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,600 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,600 - train - INFO - True
2024-04-02 06:35:44,600 - train - INFO - alphas:tensor([0.6041, 0.3959], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,600 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,601 - train - INFO - True
2024-04-02 06:35:44,601 - train - INFO - alphas:tensor([0.4704, 0.5296], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,606 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,606 - train - INFO - True
2024-04-02 06:35:44,607 - train - INFO - alphas:tensor([0.3567, 0.6433], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,607 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,607 - train - INFO - True
2024-04-02 06:35:44,607 - train - INFO - alphas:tensor([0.4655, 0.5345], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,607 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,607 - train - INFO - True
2024-04-02 06:35:44,608 - train - INFO - alphas:tensor([0.5518, 0.4482], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,608 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,608 - train - INFO - True
2024-04-02 06:35:44,609 - train - INFO - alphas:tensor([0.3962, 0.6038], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,609 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,609 - train - INFO - True
2024-04-02 06:35:44,610 - train - INFO - alphas:tensor([0.3267, 0.6733], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,610 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,610 - train - INFO - True
2024-04-02 06:35:44,611 - train - INFO - alphas:tensor([0.3735, 0.6265], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,611 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,611 - train - INFO - True
2024-04-02 06:35:44,611 - train - INFO - alphas:tensor([0.4398, 0.5602], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,612 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,612 - train - INFO - True
2024-04-02 06:35:44,643 - train - INFO - alphas:tensor([0.2570, 0.7430], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,643 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,643 - train - INFO - True
2024-04-02 06:35:44,644 - train - INFO - alphas:tensor([0.2761, 0.7239], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,644 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,644 - train - INFO - True
2024-04-02 06:35:44,645 - train - INFO - alphas:tensor([0.3249, 0.6751], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,645 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,645 - train - INFO - True
2024-04-02 06:35:44,646 - train - INFO - alphas:tensor([0.3996, 0.6004], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,650 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,650 - train - INFO - True
2024-04-02 06:35:44,651 - train - INFO - alphas:tensor([0.1984, 0.8016], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,651 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,651 - train - INFO - True
2024-04-02 06:35:44,652 - train - INFO - alphas:tensor([0.2130, 0.7870], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,652 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,652 - train - INFO - True
2024-04-02 06:35:44,653 - train - INFO - alphas:tensor([0.1837, 0.8163], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,653 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,653 - train - INFO - True
2024-04-02 06:35:44,653 - train - INFO - alphas:tensor([0.1027, 0.8973], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,654 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,654 - train - INFO - True
2024-04-02 06:35:44,654 - train - INFO - alphas:tensor([0.0210, 0.9790], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,654 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,654 - train - INFO - True
2024-04-02 06:35:44,655 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:35:44,655 - train - INFO - tau:0.6894490858690777
2024-04-02 06:35:44,655 - train - INFO - avg block size:12.89655172413793
2024-04-02 06:35:46,621 - train - INFO - Test: [   0/39]  Time: 1.928 (1.928)  Loss:  0.4138 (0.4138)  Acc@1: 89.4531 (89.4531)  Acc@5: 99.6094 (99.6094)
2024-04-02 06:36:57,159 - train - INFO - Test: [  39/39]  Time: 1.849 (1.812)  Loss:  0.5029 (0.3970)  Acc@1: 81.2500 (91.2300)  Acc@5: 100.0000 (99.6300)
2024-04-02 06:37:00,420 - train - INFO - Train: 40 [   0/195 (  0%)]  Loss:  1.879242 (1.8792)  Time: 2.959s,   86.52/s  (2.959s,   86.52/s)  LR: 4.607e-04  Data: 0.510 (0.510)
2024-04-02 06:39:25,073 - train - INFO - Train: 40 [  50/195 ( 26%)]  Loss:  1.744702 (1.6251)  Time: 3.111s,   82.29/s  (2.894s,   88.45/s)  LR: 4.607e-04  Data: 0.015 (0.026)
2024-04-02 06:41:50,135 - train - INFO - Train: 40 [ 100/195 ( 52%)]  Loss:  1.885624 (1.6375)  Time: 2.695s,   95.01/s  (2.898s,   88.34/s)  LR: 4.607e-04  Data: 0.010 (0.020)
2024-04-02 06:44:20,333 - train - INFO - Train: 40 [ 150/195 ( 77%)]  Loss:  1.890747 (1.6427)  Time: 3.224s,   79.40/s  (2.933s,   87.29/s)  LR: 4.607e-04  Data: 0.009 (0.019)
2024-04-02 06:46:31,244 - train - INFO - Train: 40 [ 194/195 (100%)]  Loss:  1.849514 (1.6556)  Time: 3.103s,   82.50/s  (2.942s,   87.00/s)  LR: 4.607e-04  Data: 0.000 (0.018)
2024-04-02 06:46:31,253 - train - INFO - True
2024-04-02 06:46:31,263 - train - INFO - alphas:tensor([0.0642, 0.9358], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,263 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,263 - train - INFO - True
2024-04-02 06:46:31,264 - train - INFO - alphas:tensor([0.1423, 0.8577], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,264 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,264 - train - INFO - True
2024-04-02 06:46:31,265 - train - INFO - alphas:tensor([0.5807, 0.4193], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,265 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,265 - train - INFO - True
2024-04-02 06:46:31,266 - train - INFO - alphas:tensor([0.5328, 0.4672], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,266 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,266 - train - INFO - True
2024-04-02 06:46:31,266 - train - INFO - alphas:tensor([0.2467, 0.7533], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,266 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,267 - train - INFO - True
2024-04-02 06:46:31,267 - train - INFO - alphas:tensor([0.3626, 0.6374], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,267 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,267 - train - INFO - True
2024-04-02 06:46:31,268 - train - INFO - alphas:tensor([0.5953, 0.4047], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,268 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,268 - train - INFO - True
2024-04-02 06:46:31,269 - train - INFO - alphas:tensor([0.4929, 0.5071], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,269 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,270 - train - INFO - True
2024-04-02 06:46:31,270 - train - INFO - alphas:tensor([0.3409, 0.6591], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,270 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,270 - train - INFO - True
2024-04-02 06:46:31,284 - train - INFO - alphas:tensor([0.4733, 0.5267], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,284 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,284 - train - INFO - True
2024-04-02 06:46:31,285 - train - INFO - alphas:tensor([0.6015, 0.3985], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,285 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,285 - train - INFO - True
2024-04-02 06:46:31,286 - train - INFO - alphas:tensor([0.4678, 0.5322], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,286 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,286 - train - INFO - True
2024-04-02 06:46:31,287 - train - INFO - alphas:tensor([0.3531, 0.6469], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,287 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,287 - train - INFO - True
2024-04-02 06:46:31,292 - train - INFO - alphas:tensor([0.4645, 0.5355], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,292 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,292 - train - INFO - True
2024-04-02 06:46:31,293 - train - INFO - alphas:tensor([0.5472, 0.4528], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,293 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,293 - train - INFO - True
2024-04-02 06:46:31,294 - train - INFO - alphas:tensor([0.3944, 0.6056], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,294 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,294 - train - INFO - True
2024-04-02 06:46:31,294 - train - INFO - alphas:tensor([0.3238, 0.6762], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,294 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,295 - train - INFO - True
2024-04-02 06:46:31,295 - train - INFO - alphas:tensor([0.3729, 0.6271], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,295 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,295 - train - INFO - True
2024-04-02 06:46:31,296 - train - INFO - alphas:tensor([0.4374, 0.5626], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,296 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,296 - train - INFO - True
2024-04-02 06:46:31,297 - train - INFO - alphas:tensor([0.2549, 0.7451], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,297 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,297 - train - INFO - True
2024-04-02 06:46:31,298 - train - INFO - alphas:tensor([0.2716, 0.7284], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,298 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,298 - train - INFO - True
2024-04-02 06:46:31,303 - train - INFO - alphas:tensor([0.3187, 0.6813], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,303 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,303 - train - INFO - True
2024-04-02 06:46:31,304 - train - INFO - alphas:tensor([0.3964, 0.6036], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,304 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,304 - train - INFO - True
2024-04-02 06:46:31,313 - train - INFO - alphas:tensor([0.1939, 0.8061], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,313 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,314 - train - INFO - True
2024-04-02 06:46:31,314 - train - INFO - alphas:tensor([0.2074, 0.7926], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,314 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,314 - train - INFO - True
2024-04-02 06:46:31,315 - train - INFO - alphas:tensor([0.1732, 0.8268], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,315 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,315 - train - INFO - True
2024-04-02 06:46:31,316 - train - INFO - alphas:tensor([0.0956, 0.9044], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,316 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,316 - train - INFO - True
2024-04-02 06:46:31,317 - train - INFO - alphas:tensor([0.0183, 0.9817], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,317 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,317 - train - INFO - True
2024-04-02 06:46:31,322 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:46:31,322 - train - INFO - tau:0.682554595010387
2024-04-02 06:46:31,322 - train - INFO - avg block size:12.89655172413793
2024-04-02 06:46:33,157 - train - INFO - Test: [   0/39]  Time: 1.833 (1.833)  Loss:  0.4451 (0.4451)  Acc@1: 89.4531 (89.4531)  Acc@5: 99.2188 (99.2188)
2024-04-02 06:47:44,181 - train - INFO - Test: [  39/39]  Time: 1.717 (1.821)  Loss:  0.5098 (0.4232)  Acc@1: 81.2500 (90.9800)  Acc@5: 100.0000 (99.6300)
2024-04-02 06:47:47,836 - train - INFO - Train: 41 [   0/195 (  0%)]  Loss:  1.310209 (1.3102)  Time: 3.454s,   74.12/s  (3.454s,   74.12/s)  LR: 4.564e-04  Data: 0.355 (0.355)
2024-04-02 06:50:14,228 - train - INFO - Train: 41 [  50/195 ( 26%)]  Loss:  1.510936 (1.6499)  Time: 2.752s,   93.04/s  (2.938s,   87.13/s)  LR: 4.564e-04  Data: 0.018 (0.021)
2024-04-02 06:52:42,093 - train - INFO - Train: 41 [ 100/195 ( 52%)]  Loss:  1.414000 (1.6508)  Time: 3.049s,   83.97/s  (2.947s,   86.86/s)  LR: 4.564e-04  Data: 0.015 (0.019)
2024-04-02 06:55:08,434 - train - INFO - Train: 41 [ 150/195 ( 77%)]  Loss:  1.293238 (1.6649)  Time: 3.026s,   84.60/s  (2.941s,   87.06/s)  LR: 4.564e-04  Data: 0.023 (0.018)
2024-04-02 06:57:16,125 - train - INFO - Train: 41 [ 194/195 (100%)]  Loss:  1.394858 (1.6641)  Time: 2.998s,   85.38/s  (2.932s,   87.32/s)  LR: 4.564e-04  Data: 0.000 (0.017)
2024-04-02 06:57:16,126 - train - INFO - True
2024-04-02 06:57:16,127 - train - INFO - alphas:tensor([0.0599, 0.9401], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,127 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,127 - train - INFO - True
2024-04-02 06:57:16,128 - train - INFO - alphas:tensor([0.1388, 0.8612], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,128 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,128 - train - INFO - True
2024-04-02 06:57:16,129 - train - INFO - alphas:tensor([0.5783, 0.4217], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,129 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,129 - train - INFO - True
2024-04-02 06:57:16,130 - train - INFO - alphas:tensor([0.5297, 0.4703], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,130 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,130 - train - INFO - True
2024-04-02 06:57:16,131 - train - INFO - alphas:tensor([0.2424, 0.7576], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,131 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,131 - train - INFO - True
2024-04-02 06:57:16,131 - train - INFO - alphas:tensor([0.3558, 0.6442], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,132 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,132 - train - INFO - True
2024-04-02 06:57:16,132 - train - INFO - alphas:tensor([0.5932, 0.4068], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,132 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,132 - train - INFO - True
2024-04-02 06:57:16,133 - train - INFO - alphas:tensor([0.4909, 0.5091], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,133 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,134 - train - INFO - True
2024-04-02 06:57:16,135 - train - INFO - alphas:tensor([0.3354, 0.6646], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,135 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,135 - train - INFO - True
2024-04-02 06:57:16,135 - train - INFO - alphas:tensor([0.4664, 0.5336], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,135 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,135 - train - INFO - True
2024-04-02 06:57:16,136 - train - INFO - alphas:tensor([0.5978, 0.4022], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,136 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,136 - train - INFO - True
2024-04-02 06:57:16,137 - train - INFO - alphas:tensor([0.4656, 0.5344], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,137 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,137 - train - INFO - True
2024-04-02 06:57:16,138 - train - INFO - alphas:tensor([0.3485, 0.6515], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,138 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,138 - train - INFO - True
2024-04-02 06:57:16,139 - train - INFO - alphas:tensor([0.4606, 0.5394], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,139 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,139 - train - INFO - True
2024-04-02 06:57:16,139 - train - INFO - alphas:tensor([0.5438, 0.4562], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,140 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,140 - train - INFO - True
2024-04-02 06:57:16,140 - train - INFO - alphas:tensor([0.3881, 0.6119], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,140 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,140 - train - INFO - True
2024-04-02 06:57:16,141 - train - INFO - alphas:tensor([0.3182, 0.6818], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,141 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,141 - train - INFO - True
2024-04-02 06:57:16,142 - train - INFO - alphas:tensor([0.3660, 0.6340], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,142 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,142 - train - INFO - True
2024-04-02 06:57:16,143 - train - INFO - alphas:tensor([0.4311, 0.5689], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,143 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,143 - train - INFO - True
2024-04-02 06:57:16,144 - train - INFO - alphas:tensor([0.2475, 0.7525], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,144 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,144 - train - INFO - True
2024-04-02 06:57:16,144 - train - INFO - alphas:tensor([0.2656, 0.7344], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,144 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,145 - train - INFO - True
2024-04-02 06:57:16,145 - train - INFO - alphas:tensor([0.3128, 0.6872], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,145 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,145 - train - INFO - True
2024-04-02 06:57:16,146 - train - INFO - alphas:tensor([0.3927, 0.6073], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,146 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,146 - train - INFO - True
2024-04-02 06:57:16,147 - train - INFO - alphas:tensor([0.1883, 0.8117], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,147 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,147 - train - INFO - True
2024-04-02 06:57:16,148 - train - INFO - alphas:tensor([0.2005, 0.7995], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,148 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,148 - train - INFO - True
2024-04-02 06:57:16,148 - train - INFO - alphas:tensor([0.1637, 0.8363], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,148 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,149 - train - INFO - True
2024-04-02 06:57:16,149 - train - INFO - alphas:tensor([0.0895, 0.9105], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,149 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,149 - train - INFO - True
2024-04-02 06:57:16,150 - train - INFO - alphas:tensor([0.0160, 0.9840], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,150 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,150 - train - INFO - True
2024-04-02 06:57:16,151 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 06:57:16,151 - train - INFO - tau:0.6757290490602831
2024-04-02 06:57:16,151 - train - INFO - avg block size:12.89655172413793
2024-04-02 06:57:18,053 - train - INFO - Test: [   0/39]  Time: 1.898 (1.898)  Loss:  0.3950 (0.3950)  Acc@1: 91.0156 (91.0156)  Acc@5: 100.0000 (100.0000)
2024-04-02 06:58:29,058 - train - INFO - Test: [  39/39]  Time: 1.815 (1.823)  Loss:  0.3862 (0.4083)  Acc@1: 87.5000 (91.0100)  Acc@5: 100.0000 (99.7200)
2024-04-02 06:58:32,616 - train - INFO - Train: 42 [   0/195 (  0%)]  Loss:  1.821981 (1.8220)  Time: 3.270s,   78.29/s  (3.270s,   78.29/s)  LR: 4.521e-04  Data: 0.386 (0.386)
2024-04-02 07:01:02,941 - train - INFO - Train: 42 [  50/195 ( 26%)]  Loss:  1.682103 (1.6831)  Time: 2.634s,   97.18/s  (3.012s,   85.00/s)  LR: 4.521e-04  Data: 0.016 (0.021)
2024-04-02 07:03:33,389 - train - INFO - Train: 42 [ 100/195 ( 52%)]  Loss:  1.666485 (1.6955)  Time: 2.964s,   86.37/s  (3.010s,   85.04/s)  LR: 4.521e-04  Data: 0.005 (0.019)
2024-04-02 07:06:01,323 - train - INFO - Train: 42 [ 150/195 ( 77%)]  Loss:  1.717660 (1.6836)  Time: 3.107s,   82.40/s  (2.993s,   85.53/s)  LR: 4.521e-04  Data: 0.005 (0.018)
2024-04-02 07:08:12,043 - train - INFO - Train: 42 [ 194/195 (100%)]  Loss:  1.613222 (1.6835)  Time: 2.954s,   86.65/s  (2.988s,   85.67/s)  LR: 4.521e-04  Data: 0.000 (0.016)
2024-04-02 07:08:12,057 - train - INFO - True
2024-04-02 07:08:12,059 - train - INFO - alphas:tensor([0.0553, 0.9447], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,059 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,059 - train - INFO - True
2024-04-02 07:08:12,060 - train - INFO - alphas:tensor([0.1343, 0.8657], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,060 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,060 - train - INFO - True
2024-04-02 07:08:12,061 - train - INFO - alphas:tensor([0.5756, 0.4244], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,061 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,061 - train - INFO - True
2024-04-02 07:08:12,062 - train - INFO - alphas:tensor([0.5259, 0.4741], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,062 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,062 - train - INFO - True
2024-04-02 07:08:12,063 - train - INFO - alphas:tensor([0.2385, 0.7615], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,063 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,063 - train - INFO - True
2024-04-02 07:08:12,063 - train - INFO - alphas:tensor([0.3517, 0.6483], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,068 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,069 - train - INFO - True
2024-04-02 07:08:12,069 - train - INFO - alphas:tensor([0.5905, 0.4095], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,069 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,070 - train - INFO - True
2024-04-02 07:08:12,070 - train - INFO - alphas:tensor([0.4861, 0.5139], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,070 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,070 - train - INFO - True
2024-04-02 07:08:12,071 - train - INFO - alphas:tensor([0.3307, 0.6693], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,071 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,071 - train - INFO - True
2024-04-02 07:08:12,072 - train - INFO - alphas:tensor([0.4636, 0.5364], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,072 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,072 - train - INFO - True
2024-04-02 07:08:12,073 - train - INFO - alphas:tensor([0.5938, 0.4062], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,073 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,073 - train - INFO - True
2024-04-02 07:08:12,074 - train - INFO - alphas:tensor([0.4607, 0.5393], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,074 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,074 - train - INFO - True
2024-04-02 07:08:12,074 - train - INFO - alphas:tensor([0.3454, 0.6546], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,074 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,075 - train - INFO - True
2024-04-02 07:08:12,075 - train - INFO - alphas:tensor([0.4564, 0.5436], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,075 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,075 - train - INFO - True
2024-04-02 07:08:12,076 - train - INFO - alphas:tensor([0.5400, 0.4600], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,076 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,076 - train - INFO - True
2024-04-02 07:08:12,077 - train - INFO - alphas:tensor([0.3857, 0.6143], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,077 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,077 - train - INFO - True
2024-04-02 07:08:12,078 - train - INFO - alphas:tensor([0.3140, 0.6860], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,078 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,078 - train - INFO - True
2024-04-02 07:08:12,078 - train - INFO - alphas:tensor([0.3615, 0.6385], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,079 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,079 - train - INFO - True
2024-04-02 07:08:12,079 - train - INFO - alphas:tensor([0.4263, 0.5737], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,079 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,079 - train - INFO - True
2024-04-02 07:08:12,080 - train - INFO - alphas:tensor([0.2433, 0.7567], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,080 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,080 - train - INFO - True
2024-04-02 07:08:12,081 - train - INFO - alphas:tensor([0.2624, 0.7376], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,081 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,081 - train - INFO - True
2024-04-02 07:08:12,082 - train - INFO - alphas:tensor([0.3085, 0.6915], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,082 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,082 - train - INFO - True
2024-04-02 07:08:12,083 - train - INFO - alphas:tensor([0.3867, 0.6133], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,083 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,083 - train - INFO - True
2024-04-02 07:08:12,083 - train - INFO - alphas:tensor([0.1825, 0.8175], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,083 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,083 - train - INFO - True
2024-04-02 07:08:12,084 - train - INFO - alphas:tensor([0.1975, 0.8025], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,084 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,084 - train - INFO - True
2024-04-02 07:08:12,085 - train - INFO - alphas:tensor([0.1553, 0.8447], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,085 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,085 - train - INFO - True
2024-04-02 07:08:12,090 - train - INFO - alphas:tensor([0.0833, 0.9167], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,090 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,090 - train - INFO - True
2024-04-02 07:08:12,091 - train - INFO - alphas:tensor([0.0140, 0.9860], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,091 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,091 - train - INFO - True
2024-04-02 07:08:12,092 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:08:12,092 - train - INFO - tau:0.6689717585696803
2024-04-02 07:08:12,092 - train - INFO - avg block size:12.89655172413793
2024-04-02 07:08:13,938 - train - INFO - Test: [   0/39]  Time: 1.842 (1.842)  Loss:  0.4216 (0.4216)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.2188 (99.2188)
2024-04-02 07:09:24,651 - train - INFO - Test: [  39/39]  Time: 1.705 (1.814)  Loss:  0.4446 (0.4137)  Acc@1: 87.5000 (91.2600)  Acc@5: 100.0000 (99.6700)
2024-04-02 07:09:28,505 - train - INFO - Train: 43 [   0/195 (  0%)]  Loss:  1.892090 (1.8921)  Time: 3.472s,   73.73/s  (3.472s,   73.73/s)  LR: 4.477e-04  Data: 0.389 (0.389)
2024-04-02 07:11:57,878 - train - INFO - Train: 43 [  50/195 ( 26%)]  Loss:  1.329432 (1.6602)  Time: 2.819s,   90.83/s  (2.997s,   85.42/s)  LR: 4.477e-04  Data: 0.005 (0.024)
2024-04-02 07:14:21,755 - train - INFO - Train: 43 [ 100/195 ( 52%)]  Loss:  1.310314 (1.6606)  Time: 2.602s,   98.39/s  (2.938s,   87.14/s)  LR: 4.477e-04  Data: 0.015 (0.019)
2024-04-02 07:16:48,013 - train - INFO - Train: 43 [ 150/195 ( 77%)]  Loss:  1.739591 (1.6398)  Time: 2.722s,   94.04/s  (2.933s,   87.27/s)  LR: 4.477e-04  Data: 0.008 (0.019)
2024-04-02 07:18:57,506 - train - INFO - Train: 43 [ 194/195 (100%)]  Loss:  1.427856 (1.6433)  Time: 2.939s,   87.10/s  (2.936s,   87.21/s)  LR: 4.477e-04  Data: 0.000 (0.018)
2024-04-02 07:18:57,511 - train - INFO - True
2024-04-02 07:18:57,512 - train - INFO - alphas:tensor([0.0512, 0.9488], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,512 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,512 - train - INFO - True
2024-04-02 07:18:57,513 - train - INFO - alphas:tensor([0.1314, 0.8686], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,513 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,513 - train - INFO - True
2024-04-02 07:18:57,514 - train - INFO - alphas:tensor([0.5726, 0.4274], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,514 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,514 - train - INFO - True
2024-04-02 07:18:57,515 - train - INFO - alphas:tensor([0.5222, 0.4778], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,515 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,515 - train - INFO - True
2024-04-02 07:18:57,515 - train - INFO - alphas:tensor([0.2333, 0.7667], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,516 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,516 - train - INFO - True
2024-04-02 07:18:57,516 - train - INFO - alphas:tensor([0.3453, 0.6547], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,516 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,516 - train - INFO - True
2024-04-02 07:18:57,517 - train - INFO - alphas:tensor([0.5867, 0.4133], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,517 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,517 - train - INFO - True
2024-04-02 07:18:57,518 - train - INFO - alphas:tensor([0.4825, 0.5175], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,518 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,519 - train - INFO - True
2024-04-02 07:18:57,519 - train - INFO - alphas:tensor([0.3280, 0.6720], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,519 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,519 - train - INFO - True
2024-04-02 07:18:57,520 - train - INFO - alphas:tensor([0.4620, 0.5380], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,520 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,520 - train - INFO - True
2024-04-02 07:18:57,521 - train - INFO - alphas:tensor([0.5899, 0.4101], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,521 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,521 - train - INFO - True
2024-04-02 07:18:57,522 - train - INFO - alphas:tensor([0.4579, 0.5421], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,522 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,522 - train - INFO - True
2024-04-02 07:18:57,522 - train - INFO - alphas:tensor([0.3422, 0.6578], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,523 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,523 - train - INFO - True
2024-04-02 07:18:57,523 - train - INFO - alphas:tensor([0.4533, 0.5467], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,523 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,523 - train - INFO - True
2024-04-02 07:18:57,524 - train - INFO - alphas:tensor([0.5363, 0.4637], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,524 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,524 - train - INFO - True
2024-04-02 07:18:57,529 - train - INFO - alphas:tensor([0.3860, 0.6140], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,529 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,529 - train - INFO - True
2024-04-02 07:18:57,530 - train - INFO - alphas:tensor([0.3096, 0.6904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,530 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,530 - train - INFO - True
2024-04-02 07:18:57,531 - train - INFO - alphas:tensor([0.3584, 0.6416], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,531 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,531 - train - INFO - True
2024-04-02 07:18:57,532 - train - INFO - alphas:tensor([0.4240, 0.5760], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,532 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,532 - train - INFO - True
2024-04-02 07:18:57,533 - train - INFO - alphas:tensor([0.2420, 0.7580], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,533 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,533 - train - INFO - True
2024-04-02 07:18:57,533 - train - INFO - alphas:tensor([0.2562, 0.7438], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,533 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,533 - train - INFO - True
2024-04-02 07:18:57,534 - train - INFO - alphas:tensor([0.3031, 0.6969], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,534 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,534 - train - INFO - True
2024-04-02 07:18:57,535 - train - INFO - alphas:tensor([0.3850, 0.6150], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,535 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,535 - train - INFO - True
2024-04-02 07:18:57,536 - train - INFO - alphas:tensor([0.1788, 0.8212], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,536 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,536 - train - INFO - True
2024-04-02 07:18:57,537 - train - INFO - alphas:tensor([0.1918, 0.8082], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,537 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,537 - train - INFO - True
2024-04-02 07:18:57,537 - train - INFO - alphas:tensor([0.1468, 0.8532], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,537 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,537 - train - INFO - True
2024-04-02 07:18:57,538 - train - INFO - alphas:tensor([0.0784, 0.9216], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,538 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,538 - train - INFO - True
2024-04-02 07:18:57,539 - train - INFO - alphas:tensor([0.0122, 0.9878], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,539 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,539 - train - INFO - True
2024-04-02 07:18:57,540 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:18:57,540 - train - INFO - tau:0.6622820409839835
2024-04-02 07:18:57,540 - train - INFO - avg block size:12.89655172413793
2024-04-02 07:18:59,472 - train - INFO - Test: [   0/39]  Time: 1.929 (1.929)  Loss:  0.4377 (0.4377)  Acc@1: 90.6250 (90.6250)  Acc@5: 99.6094 (99.6094)
2024-04-02 07:20:10,224 - train - INFO - Test: [  39/39]  Time: 1.874 (1.817)  Loss:  0.5024 (0.4149)  Acc@1: 81.2500 (90.9100)  Acc@5: 100.0000 (99.6400)
2024-04-02 07:20:13,534 - train - INFO - Train: 44 [   0/195 (  0%)]  Loss:  1.757460 (1.7575)  Time: 3.151s,   81.25/s  (3.151s,   81.25/s)  LR: 4.432e-04  Data: 0.336 (0.336)
2024-04-02 07:22:38,926 - train - INFO - Train: 44 [  50/195 ( 26%)]  Loss:  1.524934 (1.6112)  Time: 2.693s,   95.06/s  (2.913s,   87.89/s)  LR: 4.432e-04  Data: 0.014 (0.020)
2024-04-02 07:25:07,822 - train - INFO - Train: 44 [ 100/195 ( 52%)]  Loss:  1.895988 (1.6315)  Time: 3.022s,   84.71/s  (2.945s,   86.93/s)  LR: 4.432e-04  Data: 0.018 (0.018)
2024-04-02 07:27:37,473 - train - INFO - Train: 44 [ 150/195 ( 77%)]  Loss:  1.423734 (1.6274)  Time: 2.938s,   87.14/s  (2.961s,   86.46/s)  LR: 4.432e-04  Data: 0.023 (0.017)
2024-04-02 07:29:44,994 - train - INFO - Train: 44 [ 194/195 (100%)]  Loss:  1.654545 (1.6448)  Time: 2.438s,  105.01/s  (2.947s,   86.88/s)  LR: 4.432e-04  Data: 0.000 (0.016)
2024-04-02 07:29:44,994 - train - INFO - True
2024-04-02 07:29:44,995 - train - INFO - alphas:tensor([0.0476, 0.9524], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:44,996 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:44,996 - train - INFO - True
2024-04-02 07:29:44,996 - train - INFO - alphas:tensor([0.1278, 0.8722], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:44,996 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:44,997 - train - INFO - True
2024-04-02 07:29:44,997 - train - INFO - alphas:tensor([0.5718, 0.4282], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:44,997 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:44,997 - train - INFO - True
2024-04-02 07:29:44,998 - train - INFO - alphas:tensor([0.5225, 0.4775], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:44,998 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:44,998 - train - INFO - True
2024-04-02 07:29:44,999 - train - INFO - alphas:tensor([0.2298, 0.7702], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:44,999 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:44,999 - train - INFO - True
2024-04-02 07:29:45,000 - train - INFO - alphas:tensor([0.3403, 0.6597], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,000 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,000 - train - INFO - True
2024-04-02 07:29:45,000 - train - INFO - alphas:tensor([0.5845, 0.4155], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,001 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,001 - train - INFO - True
2024-04-02 07:29:45,001 - train - INFO - alphas:tensor([0.4808, 0.5192], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,001 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,001 - train - INFO - True
2024-04-02 07:29:45,002 - train - INFO - alphas:tensor([0.3252, 0.6748], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,002 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,003 - train - INFO - True
2024-04-02 07:29:45,003 - train - INFO - alphas:tensor([0.4563, 0.5437], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,004 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,004 - train - INFO - True
2024-04-02 07:29:45,004 - train - INFO - alphas:tensor([0.5879, 0.4121], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,004 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,004 - train - INFO - True
2024-04-02 07:29:45,005 - train - INFO - alphas:tensor([0.4562, 0.5438], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,005 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,005 - train - INFO - True
2024-04-02 07:29:45,006 - train - INFO - alphas:tensor([0.3373, 0.6627], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,006 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,006 - train - INFO - True
2024-04-02 07:29:45,007 - train - INFO - alphas:tensor([0.4470, 0.5530], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,007 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,007 - train - INFO - True
2024-04-02 07:29:45,008 - train - INFO - alphas:tensor([0.5317, 0.4683], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,008 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,008 - train - INFO - True
2024-04-02 07:29:45,008 - train - INFO - alphas:tensor([0.3783, 0.6217], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,008 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,009 - train - INFO - True
2024-04-02 07:29:45,009 - train - INFO - alphas:tensor([0.3073, 0.6927], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,009 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,009 - train - INFO - True
2024-04-02 07:29:45,010 - train - INFO - alphas:tensor([0.3568, 0.6432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,010 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,010 - train - INFO - True
2024-04-02 07:29:45,011 - train - INFO - alphas:tensor([0.4197, 0.5803], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,011 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,011 - train - INFO - True
2024-04-02 07:29:45,012 - train - INFO - alphas:tensor([0.2373, 0.7627], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,012 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,012 - train - INFO - True
2024-04-02 07:29:45,012 - train - INFO - alphas:tensor([0.2539, 0.7461], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,012 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,013 - train - INFO - True
2024-04-02 07:29:45,013 - train - INFO - alphas:tensor([0.2979, 0.7021], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,013 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,013 - train - INFO - True
2024-04-02 07:29:45,014 - train - INFO - alphas:tensor([0.3806, 0.6194], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,014 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,014 - train - INFO - True
2024-04-02 07:29:45,015 - train - INFO - alphas:tensor([0.1738, 0.8262], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,015 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,015 - train - INFO - True
2024-04-02 07:29:45,016 - train - INFO - alphas:tensor([0.1896, 0.8104], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,016 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,016 - train - INFO - True
2024-04-02 07:29:45,016 - train - INFO - alphas:tensor([0.1404, 0.8596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,017 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,017 - train - INFO - True
2024-04-02 07:29:45,017 - train - INFO - alphas:tensor([0.0732, 0.9268], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,017 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,017 - train - INFO - True
2024-04-02 07:29:45,018 - train - INFO - alphas:tensor([0.0107, 0.9893], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,018 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,018 - train - INFO - True
2024-04-02 07:29:45,019 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:29:45,019 - train - INFO - tau:0.6556592205741436
2024-04-02 07:29:45,019 - train - INFO - avg block size:12.89655172413793
2024-04-02 07:29:46,940 - train - INFO - Test: [   0/39]  Time: 1.918 (1.918)  Loss:  0.4226 (0.4226)  Acc@1: 89.0625 (89.0625)  Acc@5: 99.6094 (99.6094)
2024-04-02 07:30:58,405 - train - INFO - Test: [  39/39]  Time: 1.857 (1.835)  Loss:  0.3875 (0.3978)  Acc@1: 87.5000 (91.0700)  Acc@5: 100.0000 (99.6700)
2024-04-02 07:31:02,351 - train - INFO - Train: 45 [   0/195 (  0%)]  Loss:  1.510896 (1.5109)  Time: 3.703s,   69.14/s  (3.703s,   69.14/s)  LR: 4.387e-04  Data: 0.394 (0.394)
2024-04-02 07:33:30,398 - train - INFO - Train: 45 [  50/195 ( 26%)]  Loss:  1.878448 (1.6562)  Time: 3.314s,   77.26/s  (2.975s,   86.04/s)  LR: 4.387e-04  Data: 0.032 (0.022)
2024-04-02 07:35:57,182 - train - INFO - Train: 45 [ 100/195 ( 52%)]  Loss:  1.349547 (1.6419)  Time: 3.160s,   81.01/s  (2.956s,   86.61/s)  LR: 4.387e-04  Data: 0.021 (0.019)
2024-04-02 07:38:25,490 - train - INFO - Train: 45 [ 150/195 ( 77%)]  Loss:  1.579433 (1.6354)  Time: 2.873s,   89.11/s  (2.959s,   86.51/s)  LR: 4.387e-04  Data: 0.010 (0.018)
2024-04-02 07:40:35,093 - train - INFO - Train: 45 [ 194/195 (100%)]  Loss:  1.460910 (1.6361)  Time: 3.121s,   82.03/s  (2.956s,   86.60/s)  LR: 4.387e-04  Data: 0.000 (0.017)
2024-04-02 07:40:35,094 - train - INFO - True
2024-04-02 07:40:35,095 - train - INFO - alphas:tensor([0.0441, 0.9559], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,095 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,095 - train - INFO - True
2024-04-02 07:40:35,096 - train - INFO - alphas:tensor([0.1246, 0.8754], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,096 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,096 - train - INFO - True
2024-04-02 07:40:35,097 - train - INFO - alphas:tensor([0.5704, 0.4296], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,097 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,097 - train - INFO - True
2024-04-02 07:40:35,098 - train - INFO - alphas:tensor([0.5195, 0.4805], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,098 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,098 - train - INFO - True
2024-04-02 07:40:35,099 - train - INFO - alphas:tensor([0.2257, 0.7743], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,099 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,099 - train - INFO - True
2024-04-02 07:40:35,099 - train - INFO - alphas:tensor([0.3370, 0.6630], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,099 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,100 - train - INFO - True
2024-04-02 07:40:35,100 - train - INFO - alphas:tensor([0.5834, 0.4166], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,100 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,101 - train - INFO - True
2024-04-02 07:40:35,102 - train - INFO - alphas:tensor([0.4795, 0.5205], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,102 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,102 - train - INFO - True
2024-04-02 07:40:35,102 - train - INFO - alphas:tensor([0.3218, 0.6782], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,103 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,103 - train - INFO - True
2024-04-02 07:40:35,108 - train - INFO - alphas:tensor([0.4553, 0.5447], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,108 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,108 - train - INFO - True
2024-04-02 07:40:35,108 - train - INFO - alphas:tensor([0.5873, 0.4127], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,109 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,109 - train - INFO - True
2024-04-02 07:40:35,109 - train - INFO - alphas:tensor([0.4583, 0.5417], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,109 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,109 - train - INFO - True
2024-04-02 07:40:35,110 - train - INFO - alphas:tensor([0.3365, 0.6635], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,110 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,110 - train - INFO - True
2024-04-02 07:40:35,111 - train - INFO - alphas:tensor([0.4454, 0.5546], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,111 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,111 - train - INFO - True
2024-04-02 07:40:35,112 - train - INFO - alphas:tensor([0.5292, 0.4708], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,112 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,112 - train - INFO - True
2024-04-02 07:40:35,113 - train - INFO - alphas:tensor([0.3770, 0.6230], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,113 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,113 - train - INFO - True
2024-04-02 07:40:35,113 - train - INFO - alphas:tensor([0.3027, 0.6973], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,113 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,114 - train - INFO - True
2024-04-02 07:40:35,114 - train - INFO - alphas:tensor([0.3502, 0.6498], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,114 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,114 - train - INFO - True
2024-04-02 07:40:35,115 - train - INFO - alphas:tensor([0.4177, 0.5823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,115 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,115 - train - INFO - True
2024-04-02 07:40:35,116 - train - INFO - alphas:tensor([0.2350, 0.7650], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,116 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,116 - train - INFO - True
2024-04-02 07:40:35,117 - train - INFO - alphas:tensor([0.2504, 0.7496], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,117 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,117 - train - INFO - True
2024-04-02 07:40:35,117 - train - INFO - alphas:tensor([0.2940, 0.7060], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,118 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,118 - train - INFO - True
2024-04-02 07:40:35,118 - train - INFO - alphas:tensor([0.3757, 0.6243], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,118 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,118 - train - INFO - True
2024-04-02 07:40:35,119 - train - INFO - alphas:tensor([0.1688, 0.8312], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,119 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,119 - train - INFO - True
2024-04-02 07:40:35,120 - train - INFO - alphas:tensor([0.1839, 0.8161], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,120 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,120 - train - INFO - True
2024-04-02 07:40:35,121 - train - INFO - alphas:tensor([0.1327, 0.8673], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,121 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,121 - train - INFO - True
2024-04-02 07:40:35,122 - train - INFO - alphas:tensor([0.0680, 0.9320], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,122 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,122 - train - INFO - True
2024-04-02 07:40:35,122 - train - INFO - alphas:tensor([0.0094, 0.9906], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,122 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,123 - train - INFO - True
2024-04-02 07:40:35,123 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:40:35,123 - train - INFO - tau:0.6491026283684022
2024-04-02 07:40:35,123 - train - INFO - avg block size:12.89655172413793
2024-04-02 07:40:36,992 - train - INFO - Test: [   0/39]  Time: 1.866 (1.866)  Loss:  0.4141 (0.4141)  Acc@1: 90.6250 (90.6250)  Acc@5: 99.2188 (99.2188)
2024-04-02 07:41:49,153 - train - INFO - Test: [  39/39]  Time: 1.834 (1.851)  Loss:  0.4060 (0.3895)  Acc@1: 87.5000 (91.1600)  Acc@5: 100.0000 (99.6900)
2024-04-02 07:41:52,876 - train - INFO - Train: 46 [   0/195 (  0%)]  Loss:  1.882578 (1.8826)  Time: 3.537s,   72.37/s  (3.537s,   72.37/s)  LR: 4.341e-04  Data: 0.420 (0.420)
2024-04-02 07:44:18,793 - train - INFO - Train: 46 [  50/195 ( 26%)]  Loss:  1.904931 (1.6869)  Time: 2.488s,  102.88/s  (2.930s,   87.36/s)  LR: 4.341e-04  Data: 0.026 (0.024)
2024-04-02 07:46:47,688 - train - INFO - Train: 46 [ 100/195 ( 52%)]  Loss:  1.807008 (1.6603)  Time: 2.790s,   91.76/s  (2.954s,   86.67/s)  LR: 4.341e-04  Data: 0.005 (0.019)
2024-04-02 07:49:16,379 - train - INFO - Train: 46 [ 150/195 ( 77%)]  Loss:  1.863837 (1.6454)  Time: 2.702s,   94.75/s  (2.960s,   86.47/s)  LR: 4.341e-04  Data: 0.010 (0.018)
2024-04-02 07:51:26,836 - train - INFO - Train: 46 [ 194/195 (100%)]  Loss:  1.703329 (1.6547)  Time: 2.893s,   88.48/s  (2.961s,   86.44/s)  LR: 4.341e-04  Data: 0.000 (0.017)
2024-04-02 07:51:26,841 - train - INFO - True
2024-04-02 07:51:26,842 - train - INFO - alphas:tensor([0.0405, 0.9595], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,842 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,842 - train - INFO - True
2024-04-02 07:51:26,843 - train - INFO - alphas:tensor([0.1212, 0.8788], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,843 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,843 - train - INFO - True
2024-04-02 07:51:26,844 - train - INFO - alphas:tensor([0.5671, 0.4329], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,844 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,844 - train - INFO - True
2024-04-02 07:51:26,845 - train - INFO - alphas:tensor([0.5153, 0.4847], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,845 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,845 - train - INFO - True
2024-04-02 07:51:26,845 - train - INFO - alphas:tensor([0.2223, 0.7777], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,846 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,846 - train - INFO - True
2024-04-02 07:51:26,846 - train - INFO - alphas:tensor([0.3347, 0.6653], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,846 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,846 - train - INFO - True
2024-04-02 07:51:26,847 - train - INFO - alphas:tensor([0.5798, 0.4202], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,847 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,847 - train - INFO - True
2024-04-02 07:51:26,848 - train - INFO - alphas:tensor([0.4763, 0.5237], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,848 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,848 - train - INFO - True
2024-04-02 07:51:26,849 - train - INFO - alphas:tensor([0.3191, 0.6809], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,854 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,854 - train - INFO - True
2024-04-02 07:51:26,855 - train - INFO - alphas:tensor([0.4512, 0.5488], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,855 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,855 - train - INFO - True
2024-04-02 07:51:26,855 - train - INFO - alphas:tensor([0.5846, 0.4154], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,855 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,856 - train - INFO - True
2024-04-02 07:51:26,856 - train - INFO - alphas:tensor([0.4558, 0.5442], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,856 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,856 - train - INFO - True
2024-04-02 07:51:26,861 - train - INFO - alphas:tensor([0.3323, 0.6677], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,862 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,862 - train - INFO - True
2024-04-02 07:51:26,862 - train - INFO - alphas:tensor([0.4413, 0.5587], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,862 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,862 - train - INFO - True
2024-04-02 07:51:26,863 - train - INFO - alphas:tensor([0.5263, 0.4737], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,863 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,863 - train - INFO - True
2024-04-02 07:51:26,864 - train - INFO - alphas:tensor([0.3740, 0.6260], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,864 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,864 - train - INFO - True
2024-04-02 07:51:26,865 - train - INFO - alphas:tensor([0.2993, 0.7007], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,865 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,865 - train - INFO - True
2024-04-02 07:51:26,866 - train - INFO - alphas:tensor([0.3463, 0.6537], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,866 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,866 - train - INFO - True
2024-04-02 07:51:26,866 - train - INFO - alphas:tensor([0.4135, 0.5865], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,866 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,867 - train - INFO - True
2024-04-02 07:51:26,867 - train - INFO - alphas:tensor([0.2320, 0.7680], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,867 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,867 - train - INFO - True
2024-04-02 07:51:26,868 - train - INFO - alphas:tensor([0.2458, 0.7542], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,868 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,868 - train - INFO - True
2024-04-02 07:51:26,869 - train - INFO - alphas:tensor([0.2894, 0.7106], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,869 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,869 - train - INFO - True
2024-04-02 07:51:26,870 - train - INFO - alphas:tensor([0.3701, 0.6299], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,870 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,870 - train - INFO - True
2024-04-02 07:51:26,870 - train - INFO - alphas:tensor([0.1624, 0.8376], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,871 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,871 - train - INFO - True
2024-04-02 07:51:26,876 - train - INFO - alphas:tensor([0.1804, 0.8196], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,876 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,876 - train - INFO - True
2024-04-02 07:51:26,877 - train - INFO - alphas:tensor([0.1256, 0.8744], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,877 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,877 - train - INFO - True
2024-04-02 07:51:26,877 - train - INFO - alphas:tensor([0.0632, 0.9368], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,877 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,878 - train - INFO - True
2024-04-02 07:51:26,878 - train - INFO - alphas:tensor([0.0082, 0.9918], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,878 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,878 - train - INFO - True
2024-04-02 07:51:26,879 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 07:51:26,879 - train - INFO - tau:0.6426116020847181
2024-04-02 07:51:26,879 - train - INFO - avg block size:12.89655172413793
2024-04-02 07:51:28,783 - train - INFO - Test: [   0/39]  Time: 1.897 (1.897)  Loss:  0.4065 (0.4065)  Acc@1: 90.2344 (90.2344)  Acc@5: 100.0000 (100.0000)
2024-04-02 07:52:39,257 - train - INFO - Test: [  39/39]  Time: 1.841 (1.809)  Loss:  0.4490 (0.4018)  Acc@1: 81.2500 (91.1400)  Acc@5: 100.0000 (99.7000)
2024-04-02 07:52:42,685 - train - INFO - Train: 47 [   0/195 (  0%)]  Loss:  1.750486 (1.7505)  Time: 3.192s,   80.20/s  (3.192s,   80.20/s)  LR: 4.294e-04  Data: 0.394 (0.394)
2024-04-02 07:55:10,003 - train - INFO - Train: 47 [  50/195 ( 26%)]  Loss:  1.814218 (1.6520)  Time: 2.780s,   92.09/s  (2.950s,   86.77/s)  LR: 4.294e-04  Data: 0.006 (0.022)
2024-04-02 07:57:38,853 - train - INFO - Train: 47 [ 100/195 ( 52%)]  Loss:  1.369469 (1.6488)  Time: 2.879s,   88.91/s  (2.964s,   86.38/s)  LR: 4.294e-04  Data: 0.005 (0.019)
2024-04-02 08:00:07,348 - train - INFO - Train: 47 [ 150/195 ( 77%)]  Loss:  1.429083 (1.6616)  Time: 2.770s,   92.41/s  (2.966s,   86.32/s)  LR: 4.294e-04  Data: 0.020 (0.018)
2024-04-02 08:02:14,865 - train - INFO - Train: 47 [ 194/195 (100%)]  Loss:  1.518378 (1.6561)  Time: 2.898s,   88.35/s  (2.950s,   86.77/s)  LR: 4.294e-04  Data: 0.000 (0.016)
2024-04-02 08:02:14,865 - train - INFO - True
2024-04-02 08:02:14,866 - train - INFO - alphas:tensor([0.0374, 0.9626], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,867 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,867 - train - INFO - True
2024-04-02 08:02:14,872 - train - INFO - alphas:tensor([0.1192, 0.8808], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,872 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,872 - train - INFO - True
2024-04-02 08:02:14,873 - train - INFO - alphas:tensor([0.5646, 0.4354], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,873 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,873 - train - INFO - True
2024-04-02 08:02:14,874 - train - INFO - alphas:tensor([0.5136, 0.4864], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,874 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,874 - train - INFO - True
2024-04-02 08:02:14,874 - train - INFO - alphas:tensor([0.2175, 0.7825], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,874 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,874 - train - INFO - True
2024-04-02 08:02:14,875 - train - INFO - alphas:tensor([0.3305, 0.6695], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,875 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,875 - train - INFO - True
2024-04-02 08:02:14,876 - train - INFO - alphas:tensor([0.5783, 0.4217], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,876 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,876 - train - INFO - True
2024-04-02 08:02:14,877 - train - INFO - alphas:tensor([0.4723, 0.5277], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,877 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,877 - train - INFO - True
2024-04-02 08:02:14,878 - train - INFO - alphas:tensor([0.3162, 0.6838], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,878 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,878 - train - INFO - True
2024-04-02 08:02:14,879 - train - INFO - alphas:tensor([0.4473, 0.5527], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,879 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,879 - train - INFO - True
2024-04-02 08:02:14,880 - train - INFO - alphas:tensor([0.5825, 0.4175], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,880 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,880 - train - INFO - True
2024-04-02 08:02:14,880 - train - INFO - alphas:tensor([0.4543, 0.5457], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,881 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,881 - train - INFO - True
2024-04-02 08:02:14,881 - train - INFO - alphas:tensor([0.3286, 0.6714], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,881 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,881 - train - INFO - True
2024-04-02 08:02:14,882 - train - INFO - alphas:tensor([0.4364, 0.5636], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,882 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,882 - train - INFO - True
2024-04-02 08:02:14,883 - train - INFO - alphas:tensor([0.5218, 0.4782], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,883 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,883 - train - INFO - True
2024-04-02 08:02:14,884 - train - INFO - alphas:tensor([0.3725, 0.6275], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,884 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,884 - train - INFO - True
2024-04-02 08:02:14,884 - train - INFO - alphas:tensor([0.2984, 0.7016], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,885 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,885 - train - INFO - True
2024-04-02 08:02:14,885 - train - INFO - alphas:tensor([0.3431, 0.6569], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,885 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,886 - train - INFO - True
2024-04-02 08:02:14,886 - train - INFO - alphas:tensor([0.4074, 0.5926], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,886 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,886 - train - INFO - True
2024-04-02 08:02:14,887 - train - INFO - alphas:tensor([0.2272, 0.7728], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,887 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,887 - train - INFO - True
2024-04-02 08:02:14,888 - train - INFO - alphas:tensor([0.2425, 0.7575], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,888 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,888 - train - INFO - True
2024-04-02 08:02:14,889 - train - INFO - alphas:tensor([0.2867, 0.7133], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,889 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,889 - train - INFO - True
2024-04-02 08:02:14,889 - train - INFO - alphas:tensor([0.3651, 0.6349], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,889 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,890 - train - INFO - True
2024-04-02 08:02:14,890 - train - INFO - alphas:tensor([0.1579, 0.8421], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,890 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,890 - train - INFO - True
2024-04-02 08:02:14,891 - train - INFO - alphas:tensor([0.1774, 0.8226], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,891 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,891 - train - INFO - True
2024-04-02 08:02:14,892 - train - INFO - alphas:tensor([0.1189, 0.8811], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,892 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,892 - train - INFO - True
2024-04-02 08:02:14,893 - train - INFO - alphas:tensor([0.0588, 0.9412], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,893 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,893 - train - INFO - True
2024-04-02 08:02:14,893 - train - INFO - alphas:tensor([0.0072, 0.9928], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,893 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,898 - train - INFO - True
2024-04-02 08:02:14,903 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:02:14,903 - train - INFO - tau:0.6361854860638709
2024-04-02 08:02:14,903 - train - INFO - avg block size:12.89655172413793
2024-04-02 08:02:16,616 - train - INFO - Test: [   0/39]  Time: 1.710 (1.710)  Loss:  0.4526 (0.4526)  Acc@1: 89.8438 (89.8438)  Acc@5: 99.6094 (99.6094)
2024-04-02 08:03:27,624 - train - INFO - Test: [  39/39]  Time: 1.867 (1.817)  Loss:  0.5605 (0.4329)  Acc@1: 81.2500 (91.1500)  Acc@5: 100.0000 (99.6500)
2024-04-02 08:03:31,081 - train - INFO - Train: 48 [   0/195 (  0%)]  Loss:  1.645065 (1.6451)  Time: 3.200s,   80.01/s  (3.200s,   80.01/s)  LR: 4.247e-04  Data: 0.366 (0.366)
2024-04-02 08:06:00,128 - train - INFO - Train: 48 [  50/195 ( 26%)]  Loss:  1.616878 (1.6618)  Time: 2.810s,   91.09/s  (2.985s,   85.76/s)  LR: 4.247e-04  Data: 0.018 (0.023)
2024-04-02 08:08:24,134 - train - INFO - Train: 48 [ 100/195 ( 52%)]  Loss:  1.369711 (1.6381)  Time: 2.935s,   87.23/s  (2.933s,   87.28/s)  LR: 4.247e-04  Data: 0.013 (0.019)
2024-04-02 08:10:46,259 - train - INFO - Train: 48 [ 150/195 ( 77%)]  Loss:  1.842732 (1.6355)  Time: 2.603s,   98.35/s  (2.903s,   88.18/s)  LR: 4.247e-04  Data: 0.005 (0.017)
2024-04-02 08:12:57,179 - train - INFO - Train: 48 [ 194/195 (100%)]  Loss:  1.337346 (1.6352)  Time: 2.739s,   93.46/s  (2.919s,   87.69/s)  LR: 4.247e-04  Data: 0.000 (0.016)
2024-04-02 08:12:57,180 - train - INFO - True
2024-04-02 08:12:57,181 - train - INFO - alphas:tensor([0.0344, 0.9656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,181 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,181 - train - INFO - True
2024-04-02 08:12:57,182 - train - INFO - alphas:tensor([0.1160, 0.8840], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,182 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,182 - train - INFO - True
2024-04-02 08:12:57,191 - train - INFO - alphas:tensor([0.5626, 0.4374], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,192 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,192 - train - INFO - True
2024-04-02 08:12:57,192 - train - INFO - alphas:tensor([0.5105, 0.4895], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,192 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,192 - train - INFO - True
2024-04-02 08:12:57,193 - train - INFO - alphas:tensor([0.2135, 0.7865], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,193 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,193 - train - INFO - True
2024-04-02 08:12:57,194 - train - INFO - alphas:tensor([0.3261, 0.6739], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,194 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,195 - train - INFO - True
2024-04-02 08:12:57,195 - train - INFO - alphas:tensor([0.5766, 0.4234], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,195 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,196 - train - INFO - True
2024-04-02 08:12:57,196 - train - INFO - alphas:tensor([0.4719, 0.5281], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,196 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,196 - train - INFO - True
2024-04-02 08:12:57,197 - train - INFO - alphas:tensor([0.3128, 0.6872], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,197 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,197 - train - INFO - True
2024-04-02 08:12:57,198 - train - INFO - alphas:tensor([0.4455, 0.5545], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,198 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,198 - train - INFO - True
2024-04-02 08:12:57,199 - train - INFO - alphas:tensor([0.5776, 0.4224], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,199 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,199 - train - INFO - True
2024-04-02 08:12:57,199 - train - INFO - alphas:tensor([0.4466, 0.5534], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,200 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,200 - train - INFO - True
2024-04-02 08:12:57,200 - train - INFO - alphas:tensor([0.3250, 0.6750], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,200 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,201 - train - INFO - True
2024-04-02 08:12:57,201 - train - INFO - alphas:tensor([0.4322, 0.5678], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,201 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,201 - train - INFO - True
2024-04-02 08:12:57,202 - train - INFO - alphas:tensor([0.5209, 0.4791], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,202 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,202 - train - INFO - True
2024-04-02 08:12:57,203 - train - INFO - alphas:tensor([0.3719, 0.6281], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,203 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,207 - train - INFO - True
2024-04-02 08:12:57,208 - train - INFO - alphas:tensor([0.2949, 0.7051], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,208 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,208 - train - INFO - True
2024-04-02 08:12:57,209 - train - INFO - alphas:tensor([0.3404, 0.6596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,209 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,209 - train - INFO - True
2024-04-02 08:12:57,210 - train - INFO - alphas:tensor([0.4067, 0.5933], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,210 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,210 - train - INFO - True
2024-04-02 08:12:57,210 - train - INFO - alphas:tensor([0.2247, 0.7753], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,210 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,211 - train - INFO - True
2024-04-02 08:12:57,211 - train - INFO - alphas:tensor([0.2377, 0.7623], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,211 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,211 - train - INFO - True
2024-04-02 08:12:57,212 - train - INFO - alphas:tensor([0.2832, 0.7168], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,212 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,212 - train - INFO - True
2024-04-02 08:12:57,213 - train - INFO - alphas:tensor([0.3614, 0.6386], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,213 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,213 - train - INFO - True
2024-04-02 08:12:57,214 - train - INFO - alphas:tensor([0.1545, 0.8455], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,214 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,214 - train - INFO - True
2024-04-02 08:12:57,214 - train - INFO - alphas:tensor([0.1745, 0.8255], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,214 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,215 - train - INFO - True
2024-04-02 08:12:57,215 - train - INFO - alphas:tensor([0.1132, 0.8868], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,215 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,215 - train - INFO - True
2024-04-02 08:12:57,216 - train - INFO - alphas:tensor([0.0546, 0.9454], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,216 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,216 - train - INFO - True
2024-04-02 08:12:57,217 - train - INFO - alphas:tensor([0.0063, 0.9937], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,217 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,217 - train - INFO - True
2024-04-02 08:12:57,218 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:12:57,218 - train - INFO - tau:0.6298236312032323
2024-04-02 08:12:57,218 - train - INFO - avg block size:12.89655172413793
2024-04-02 08:12:59,109 - train - INFO - Test: [   0/39]  Time: 1.888 (1.888)  Loss:  0.4050 (0.4050)  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)
2024-04-02 08:14:09,769 - train - INFO - Test: [  39/39]  Time: 1.779 (1.814)  Loss:  0.4131 (0.3908)  Acc@1: 81.2500 (91.3800)  Acc@5: 100.0000 (99.7300)
2024-04-02 08:14:13,015 - train - INFO - Train: 49 [   0/195 (  0%)]  Loss:  1.447027 (1.4470)  Time: 3.043s,   84.13/s  (3.043s,   84.13/s)  LR: 4.199e-04  Data: 0.269 (0.269)
2024-04-02 08:16:40,777 - train - INFO - Train: 49 [  50/195 ( 26%)]  Loss:  1.547175 (1.6605)  Time: 2.500s,  102.41/s  (2.957s,   86.58/s)  LR: 4.199e-04  Data: 0.013 (0.019)
2024-04-02 08:19:07,365 - train - INFO - Train: 49 [ 100/195 ( 52%)]  Loss:  1.719000 (1.6521)  Time: 2.784s,   91.95/s  (2.944s,   86.94/s)  LR: 4.199e-04  Data: 0.014 (0.015)
2024-04-02 08:21:33,524 - train - INFO - Train: 49 [ 150/195 ( 77%)]  Loss:  1.833839 (1.6474)  Time: 2.663s,   96.13/s  (2.937s,   87.15/s)  LR: 4.199e-04  Data: 0.010 (0.015)
2024-04-02 08:23:41,737 - train - INFO - Train: 49 [ 194/195 (100%)]  Loss:  1.814808 (1.6391)  Time: 2.589s,   98.88/s  (2.932s,   87.31/s)  LR: 4.199e-04  Data: 0.000 (0.015)
2024-04-02 08:23:41,739 - train - INFO - True
2024-04-02 08:23:41,741 - train - INFO - alphas:tensor([0.0316, 0.9684], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,741 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,741 - train - INFO - True
2024-04-02 08:23:41,742 - train - INFO - alphas:tensor([0.1129, 0.8871], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,742 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,742 - train - INFO - True
2024-04-02 08:23:41,747 - train - INFO - alphas:tensor([0.5609, 0.4391], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,747 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,747 - train - INFO - True
2024-04-02 08:23:41,748 - train - INFO - alphas:tensor([0.5092, 0.4908], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,748 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,748 - train - INFO - True
2024-04-02 08:23:41,749 - train - INFO - alphas:tensor([0.2095, 0.7905], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,749 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,749 - train - INFO - True
2024-04-02 08:23:41,750 - train - INFO - alphas:tensor([0.3203, 0.6797], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,750 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,750 - train - INFO - True
2024-04-02 08:23:41,751 - train - INFO - alphas:tensor([0.5743, 0.4257], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,751 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,751 - train - INFO - True
2024-04-02 08:23:41,752 - train - INFO - alphas:tensor([0.4691, 0.5309], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,752 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,752 - train - INFO - True
2024-04-02 08:23:41,753 - train - INFO - alphas:tensor([0.3088, 0.6912], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,753 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,753 - train - INFO - True
2024-04-02 08:23:41,753 - train - INFO - alphas:tensor([0.4438, 0.5562], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,753 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,754 - train - INFO - True
2024-04-02 08:23:41,754 - train - INFO - alphas:tensor([0.5758, 0.4242], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,754 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,754 - train - INFO - True
2024-04-02 08:23:41,755 - train - INFO - alphas:tensor([0.4469, 0.5531], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,755 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,755 - train - INFO - True
2024-04-02 08:23:41,756 - train - INFO - alphas:tensor([0.3231, 0.6769], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,756 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,756 - train - INFO - True
2024-04-02 08:23:41,757 - train - INFO - alphas:tensor([0.4325, 0.5675], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,757 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,757 - train - INFO - True
2024-04-02 08:23:41,757 - train - INFO - alphas:tensor([0.5175, 0.4825], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,758 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,758 - train - INFO - True
2024-04-02 08:23:41,758 - train - INFO - alphas:tensor([0.3695, 0.6305], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,758 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,758 - train - INFO - True
2024-04-02 08:23:41,759 - train - INFO - alphas:tensor([0.2913, 0.7087], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,759 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,759 - train - INFO - True
2024-04-02 08:23:41,760 - train - INFO - alphas:tensor([0.3397, 0.6603], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,760 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,760 - train - INFO - True
2024-04-02 08:23:41,761 - train - INFO - alphas:tensor([0.4001, 0.5999], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,761 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,761 - train - INFO - True
2024-04-02 08:23:41,762 - train - INFO - alphas:tensor([0.2191, 0.7809], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,762 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,762 - train - INFO - True
2024-04-02 08:23:41,762 - train - INFO - alphas:tensor([0.2360, 0.7640], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,762 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,763 - train - INFO - True
2024-04-02 08:23:41,763 - train - INFO - alphas:tensor([0.2797, 0.7203], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,763 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,763 - train - INFO - True
2024-04-02 08:23:41,764 - train - INFO - alphas:tensor([0.3604, 0.6396], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,764 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,764 - train - INFO - True
2024-04-02 08:23:41,765 - train - INFO - alphas:tensor([0.1502, 0.8498], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,765 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,765 - train - INFO - True
2024-04-02 08:23:41,766 - train - INFO - alphas:tensor([0.1708, 0.8292], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,766 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,766 - train - INFO - True
2024-04-02 08:23:41,766 - train - INFO - alphas:tensor([0.1068, 0.8932], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,766 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,771 - train - INFO - True
2024-04-02 08:23:41,772 - train - INFO - alphas:tensor([0.0504, 0.9496], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,772 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,772 - train - INFO - True
2024-04-02 08:23:41,772 - train - INFO - alphas:tensor([0.0055, 0.9945], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,773 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,773 - train - INFO - True
2024-04-02 08:23:41,773 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:23:41,773 - train - INFO - tau:0.6235253948912
2024-04-02 08:23:41,773 - train - INFO - avg block size:12.89655172413793
2024-04-02 08:23:43,688 - train - INFO - Test: [   0/39]  Time: 1.912 (1.912)  Loss:  0.4268 (0.4268)  Acc@1: 90.2344 (90.2344)  Acc@5: 100.0000 (100.0000)
2024-04-02 08:24:53,903 - train - INFO - Test: [  39/39]  Time: 1.830 (1.803)  Loss:  0.5435 (0.4010)  Acc@1: 81.2500 (90.9600)  Acc@5: 100.0000 (99.6800)
2024-04-02 08:24:57,576 - train - INFO - Train: 50 [   0/195 (  0%)]  Loss:  1.539704 (1.5397)  Time: 3.348s,   76.47/s  (3.348s,   76.47/s)  LR: 4.150e-04  Data: 0.237 (0.237)
2024-04-02 08:27:26,005 - train - INFO - Train: 50 [  50/195 ( 26%)]  Loss:  1.459558 (1.6126)  Time: 2.910s,   87.96/s  (2.976s,   86.02/s)  LR: 4.150e-04  Data: 0.005 (0.018)
2024-04-02 08:29:52,005 - train - INFO - Train: 50 [ 100/195 ( 52%)]  Loss:  1.510079 (1.6301)  Time: 2.711s,   94.42/s  (2.948s,   86.83/s)  LR: 4.150e-04  Data: 0.018 (0.016)
2024-04-02 08:32:20,466 - train - INFO - Train: 50 [ 150/195 ( 77%)]  Loss:  1.283997 (1.6374)  Time: 3.481s,   73.54/s  (2.955s,   86.63/s)  LR: 4.150e-04  Data: 0.025 (0.015)
2024-04-02 08:34:28,953 - train - INFO - Train: 50 [ 194/195 (100%)]  Loss:  1.310428 (1.6363)  Time: 3.185s,   80.37/s  (2.947s,   86.86/s)  LR: 4.150e-04  Data: 0.000 (0.015)
2024-04-02 08:34:28,962 - train - INFO - True
2024-04-02 08:34:28,963 - train - INFO - alphas:tensor([0.0293, 0.9707], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,963 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,963 - train - INFO - True
2024-04-02 08:34:28,964 - train - INFO - alphas:tensor([0.1116, 0.8884], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,964 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,964 - train - INFO - True
2024-04-02 08:34:28,965 - train - INFO - alphas:tensor([0.5595, 0.4405], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,965 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,965 - train - INFO - True
2024-04-02 08:34:28,966 - train - INFO - alphas:tensor([0.5062, 0.4938], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,966 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,966 - train - INFO - True
2024-04-02 08:34:28,967 - train - INFO - alphas:tensor([0.2073, 0.7927], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,967 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,967 - train - INFO - True
2024-04-02 08:34:28,967 - train - INFO - alphas:tensor([0.3177, 0.6823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,968 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,968 - train - INFO - True
2024-04-02 08:34:28,968 - train - INFO - alphas:tensor([0.5720, 0.4280], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,968 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,968 - train - INFO - True
2024-04-02 08:34:28,969 - train - INFO - alphas:tensor([0.4679, 0.5321], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,969 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,969 - train - INFO - True
2024-04-02 08:34:28,970 - train - INFO - alphas:tensor([0.3044, 0.6956], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,970 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,971 - train - INFO - True
2024-04-02 08:34:28,971 - train - INFO - alphas:tensor([0.4381, 0.5619], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,971 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,971 - train - INFO - True
2024-04-02 08:34:28,972 - train - INFO - alphas:tensor([0.5748, 0.4252], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,972 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,972 - train - INFO - True
2024-04-02 08:34:28,973 - train - INFO - alphas:tensor([0.4449, 0.5551], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,973 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,973 - train - INFO - True
2024-04-02 08:34:28,974 - train - INFO - alphas:tensor([0.3197, 0.6803], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,974 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,974 - train - INFO - True
2024-04-02 08:34:28,975 - train - INFO - alphas:tensor([0.4289, 0.5711], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,975 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,983 - train - INFO - True
2024-04-02 08:34:28,984 - train - INFO - alphas:tensor([0.5149, 0.4851], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,984 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,984 - train - INFO - True
2024-04-02 08:34:28,985 - train - INFO - alphas:tensor([0.3677, 0.6323], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,985 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,985 - train - INFO - True
2024-04-02 08:34:28,986 - train - INFO - alphas:tensor([0.2881, 0.7119], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,986 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,986 - train - INFO - True
2024-04-02 08:34:28,987 - train - INFO - alphas:tensor([0.3371, 0.6629], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,987 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,987 - train - INFO - True
2024-04-02 08:34:28,987 - train - INFO - alphas:tensor([0.3951, 0.6049], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,988 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,988 - train - INFO - True
2024-04-02 08:34:28,988 - train - INFO - alphas:tensor([0.2149, 0.7851], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,988 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,988 - train - INFO - True
2024-04-02 08:34:28,989 - train - INFO - alphas:tensor([0.2326, 0.7674], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,989 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,989 - train - INFO - True
2024-04-02 08:34:28,990 - train - INFO - alphas:tensor([0.2766, 0.7234], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,990 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,990 - train - INFO - True
2024-04-02 08:34:28,991 - train - INFO - alphas:tensor([0.3565, 0.6435], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,991 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,991 - train - INFO - True
2024-04-02 08:34:28,992 - train - INFO - alphas:tensor([0.1451, 0.8549], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,992 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,992 - train - INFO - True
2024-04-02 08:34:28,992 - train - INFO - alphas:tensor([0.1679, 0.8321], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,992 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,992 - train - INFO - True
2024-04-02 08:34:28,998 - train - INFO - alphas:tensor([0.1006, 0.8994], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,998 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,998 - train - INFO - True
2024-04-02 08:34:28,998 - train - INFO - alphas:tensor([0.0460, 0.9540], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,998 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,999 - train - INFO - True
2024-04-02 08:34:28,999 - train - INFO - alphas:tensor([0.0049, 0.9951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:28,999 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:28,999 - train - INFO - True
2024-04-02 08:34:29,000 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:34:29,000 - train - INFO - tau:0.617290140942288
2024-04-02 08:34:29,000 - train - INFO - avg block size:12.89655172413793
2024-04-02 08:34:30,827 - train - INFO - Test: [   0/39]  Time: 1.824 (1.824)  Loss:  0.4111 (0.4111)  Acc@1: 90.6250 (90.6250)  Acc@5: 99.6094 (99.6094)
2024-04-02 08:35:41,676 - train - INFO - Test: [  39/39]  Time: 1.780 (1.817)  Loss:  0.4651 (0.3934)  Acc@1: 87.5000 (91.5200)  Acc@5: 100.0000 (99.6500)
2024-04-02 08:35:45,747 - train - INFO - Train: 51 [   0/195 (  0%)]  Loss:  1.828636 (1.8286)  Time: 3.795s,   67.45/s  (3.795s,   67.45/s)  LR: 4.101e-04  Data: 0.359 (0.359)
2024-04-02 08:38:13,572 - train - INFO - Train: 51 [  50/195 ( 26%)]  Loss:  1.842727 (1.6577)  Time: 2.945s,   86.92/s  (2.973s,   86.11/s)  LR: 4.101e-04  Data: 0.014 (0.021)
2024-04-02 08:40:41,086 - train - INFO - Train: 51 [ 100/195 ( 52%)]  Loss:  1.847731 (1.6406)  Time: 3.252s,   78.73/s  (2.962s,   86.44/s)  LR: 4.101e-04  Data: 0.022 (0.018)
2024-04-02 08:43:05,490 - train - INFO - Train: 51 [ 150/195 ( 77%)]  Loss:  1.864926 (1.6273)  Time: 2.466s,  103.79/s  (2.937s,   87.16/s)  LR: 4.101e-04  Data: 0.006 (0.017)
2024-04-02 08:45:14,738 - train - INFO - Train: 51 [ 194/195 (100%)]  Loss:  1.672837 (1.6290)  Time: 3.059s,   83.69/s  (2.937s,   87.16/s)  LR: 4.101e-04  Data: 0.000 (0.016)
2024-04-02 08:45:14,747 - train - INFO - True
2024-04-02 08:45:14,748 - train - INFO - alphas:tensor([0.0269, 0.9731], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,748 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,748 - train - INFO - True
2024-04-02 08:45:14,749 - train - INFO - alphas:tensor([0.1089, 0.8911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,749 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,749 - train - INFO - True
2024-04-02 08:45:14,750 - train - INFO - alphas:tensor([0.5573, 0.4427], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,750 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,750 - train - INFO - True
2024-04-02 08:45:14,751 - train - INFO - alphas:tensor([0.5032, 0.4968], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,751 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,751 - train - INFO - True
2024-04-02 08:45:14,752 - train - INFO - alphas:tensor([0.2032, 0.7968], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,752 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,752 - train - INFO - True
2024-04-02 08:45:14,752 - train - INFO - alphas:tensor([0.3126, 0.6874], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,753 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,753 - train - INFO - True
2024-04-02 08:45:14,753 - train - INFO - alphas:tensor([0.5694, 0.4306], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,753 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,753 - train - INFO - True
2024-04-02 08:45:14,754 - train - INFO - alphas:tensor([0.4658, 0.5342], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,754 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,754 - train - INFO - True
2024-04-02 08:45:14,755 - train - INFO - alphas:tensor([0.3033, 0.6967], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,756 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,756 - train - INFO - True
2024-04-02 08:45:14,756 - train - INFO - alphas:tensor([0.4379, 0.5621], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,756 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,757 - train - INFO - True
2024-04-02 08:45:14,757 - train - INFO - alphas:tensor([0.5725, 0.4275], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,757 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,757 - train - INFO - True
2024-04-02 08:45:14,767 - train - INFO - alphas:tensor([0.4429, 0.5571], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,767 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,767 - train - INFO - True
2024-04-02 08:45:14,768 - train - INFO - alphas:tensor([0.3185, 0.6815], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,768 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,768 - train - INFO - True
2024-04-02 08:45:14,768 - train - INFO - alphas:tensor([0.4285, 0.5715], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,769 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,769 - train - INFO - True
2024-04-02 08:45:14,769 - train - INFO - alphas:tensor([0.5114, 0.4886], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,769 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,769 - train - INFO - True
2024-04-02 08:45:14,770 - train - INFO - alphas:tensor([0.3637, 0.6363], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,770 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,770 - train - INFO - True
2024-04-02 08:45:14,771 - train - INFO - alphas:tensor([0.2829, 0.7171], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,771 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,771 - train - INFO - True
2024-04-02 08:45:14,772 - train - INFO - alphas:tensor([0.3327, 0.6673], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,772 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,772 - train - INFO - True
2024-04-02 08:45:14,773 - train - INFO - alphas:tensor([0.3926, 0.6074], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,773 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,773 - train - INFO - True
2024-04-02 08:45:14,773 - train - INFO - alphas:tensor([0.2121, 0.7879], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,773 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,774 - train - INFO - True
2024-04-02 08:45:14,774 - train - INFO - alphas:tensor([0.2282, 0.7718], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,774 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,774 - train - INFO - True
2024-04-02 08:45:14,775 - train - INFO - alphas:tensor([0.2704, 0.7296], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,775 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,775 - train - INFO - True
2024-04-02 08:45:14,785 - train - INFO - alphas:tensor([0.3529, 0.6471], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,785 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,785 - train - INFO - True
2024-04-02 08:45:14,785 - train - INFO - alphas:tensor([0.1417, 0.8583], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,786 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,786 - train - INFO - True
2024-04-02 08:45:14,786 - train - INFO - alphas:tensor([0.1638, 0.8362], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,786 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,786 - train - INFO - True
2024-04-02 08:45:14,787 - train - INFO - alphas:tensor([0.0945, 0.9055], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,787 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,787 - train - INFO - True
2024-04-02 08:45:14,788 - train - INFO - alphas:tensor([0.0423, 0.9577], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,788 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,788 - train - INFO - True
2024-04-02 08:45:14,789 - train - INFO - alphas:tensor([0.0043, 0.9957], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,789 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,789 - train - INFO - True
2024-04-02 08:45:14,790 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:45:14,790 - train - INFO - tau:0.6111172395328651
2024-04-02 08:45:14,790 - train - INFO - avg block size:12.89655172413793
2024-04-02 08:45:16,748 - train - INFO - Test: [   0/39]  Time: 1.954 (1.954)  Loss:  0.4368 (0.4368)  Acc@1: 87.5000 (87.5000)  Acc@5: 99.6094 (99.6094)
2024-04-02 08:46:29,087 - train - INFO - Test: [  39/39]  Time: 1.873 (1.857)  Loss:  0.3857 (0.4103)  Acc@1: 87.5000 (90.9900)  Acc@5: 100.0000 (99.6900)
2024-04-02 08:46:32,329 - train - INFO - Train: 52 [   0/195 (  0%)]  Loss:  1.758295 (1.7583)  Time: 2.914s,   87.85/s  (2.914s,   87.85/s)  LR: 4.051e-04  Data: 0.284 (0.284)
2024-04-02 08:48:57,417 - train - INFO - Train: 52 [  50/195 ( 26%)]  Loss:  1.396540 (1.6352)  Time: 3.466s,   73.86/s  (2.902s,   88.22/s)  LR: 4.051e-04  Data: 0.006 (0.021)
2024-04-02 08:51:25,820 - train - INFO - Train: 52 [ 100/195 ( 52%)]  Loss:  1.850674 (1.6427)  Time: 2.804s,   91.30/s  (2.935s,   87.23/s)  LR: 4.051e-04  Data: 0.015 (0.018)
2024-04-02 08:53:54,673 - train - INFO - Train: 52 [ 150/195 ( 77%)]  Loss:  1.817831 (1.6323)  Time: 2.897s,   88.38/s  (2.949s,   86.82/s)  LR: 4.051e-04  Data: 0.005 (0.017)
2024-04-02 08:56:02,408 - train - INFO - Train: 52 [ 194/195 (100%)]  Loss:  1.679243 (1.6238)  Time: 3.118s,   82.12/s  (2.938s,   87.12/s)  LR: 4.051e-04  Data: 0.000 (0.016)
2024-04-02 08:56:02,409 - train - INFO - True
2024-04-02 08:56:02,410 - train - INFO - alphas:tensor([0.0247, 0.9753], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,410 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,410 - train - INFO - True
2024-04-02 08:56:02,411 - train - INFO - alphas:tensor([0.1069, 0.8931], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,411 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,411 - train - INFO - True
2024-04-02 08:56:02,412 - train - INFO - alphas:tensor([0.5556, 0.4444], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,412 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,412 - train - INFO - True
2024-04-02 08:56:02,412 - train - INFO - alphas:tensor([0.5018, 0.4982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,412 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,413 - train - INFO - True
2024-04-02 08:56:02,413 - train - INFO - alphas:tensor([0.1995, 0.8005], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,413 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,413 - train - INFO - True
2024-04-02 08:56:02,414 - train - INFO - alphas:tensor([0.3089, 0.6911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,414 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,414 - train - INFO - True
2024-04-02 08:56:02,428 - train - INFO - alphas:tensor([0.5680, 0.4320], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,428 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,428 - train - INFO - True
2024-04-02 08:56:02,429 - train - INFO - alphas:tensor([0.4653, 0.5347], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,429 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,429 - train - INFO - True
2024-04-02 08:56:02,430 - train - INFO - alphas:tensor([0.3002, 0.6998], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,430 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,430 - train - INFO - True
2024-04-02 08:56:02,430 - train - INFO - alphas:tensor([0.4331, 0.5669], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,435 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,435 - train - INFO - True
2024-04-02 08:56:02,436 - train - INFO - alphas:tensor([0.5683, 0.4317], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,436 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,436 - train - INFO - True
2024-04-02 08:56:02,436 - train - INFO - alphas:tensor([0.4379, 0.5621], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,437 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,437 - train - INFO - True
2024-04-02 08:56:02,446 - train - INFO - alphas:tensor([0.3142, 0.6858], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,446 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,446 - train - INFO - True
2024-04-02 08:56:02,447 - train - INFO - alphas:tensor([0.4236, 0.5764], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,447 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,447 - train - INFO - True
2024-04-02 08:56:02,448 - train - INFO - alphas:tensor([0.5108, 0.4892], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,448 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,448 - train - INFO - True
2024-04-02 08:56:02,449 - train - INFO - alphas:tensor([0.3632, 0.6368], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,449 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,449 - train - INFO - True
2024-04-02 08:56:02,449 - train - INFO - alphas:tensor([0.2797, 0.7203], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,449 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,450 - train - INFO - True
2024-04-02 08:56:02,450 - train - INFO - alphas:tensor([0.3286, 0.6714], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,450 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,450 - train - INFO - True
2024-04-02 08:56:02,451 - train - INFO - alphas:tensor([0.3890, 0.6110], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,451 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,451 - train - INFO - True
2024-04-02 08:56:02,452 - train - INFO - alphas:tensor([0.2099, 0.7901], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,452 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,452 - train - INFO - True
2024-04-02 08:56:02,453 - train - INFO - alphas:tensor([0.2276, 0.7724], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,453 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,453 - train - INFO - True
2024-04-02 08:56:02,453 - train - INFO - alphas:tensor([0.2686, 0.7314], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,454 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,454 - train - INFO - True
2024-04-02 08:56:02,454 - train - INFO - alphas:tensor([0.3491, 0.6509], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,454 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,454 - train - INFO - True
2024-04-02 08:56:02,469 - train - INFO - alphas:tensor([0.1384, 0.8616], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,469 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,469 - train - INFO - True
2024-04-02 08:56:02,470 - train - INFO - alphas:tensor([0.1600, 0.8400], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,470 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,470 - train - INFO - True
2024-04-02 08:56:02,471 - train - INFO - alphas:tensor([0.0888, 0.9112], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,471 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,471 - train - INFO - True
2024-04-02 08:56:02,472 - train - INFO - alphas:tensor([0.0388, 0.9612], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,472 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,472 - train - INFO - True
2024-04-02 08:56:02,472 - train - INFO - alphas:tensor([0.0038, 0.9962], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,472 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,472 - train - INFO - True
2024-04-02 08:56:02,473 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 08:56:02,473 - train - INFO - tau:0.6050060671375365
2024-04-02 08:56:02,473 - train - INFO - avg block size:12.89655172413793
2024-04-02 08:56:04,267 - train - INFO - Test: [   0/39]  Time: 1.790 (1.790)  Loss:  0.4443 (0.4443)  Acc@1: 88.2812 (88.2812)  Acc@5: 100.0000 (100.0000)
2024-04-02 08:57:14,871 - train - INFO - Test: [  39/39]  Time: 1.765 (1.810)  Loss:  0.4902 (0.4097)  Acc@1: 87.5000 (91.1500)  Acc@5: 100.0000 (99.7400)
2024-04-02 08:57:18,415 - train - INFO - Train: 53 [   0/195 (  0%)]  Loss:  1.856745 (1.8567)  Time: 3.283s,   77.99/s  (3.283s,   77.99/s)  LR: 4.001e-04  Data: 0.383 (0.383)
2024-04-02 08:59:45,371 - train - INFO - Train: 53 [  50/195 ( 26%)]  Loss:  1.831015 (1.6561)  Time: 3.137s,   81.61/s  (2.946s,   86.91/s)  LR: 4.001e-04  Data: 0.014 (0.022)
2024-04-02 09:02:18,069 - train - INFO - Train: 53 [ 100/195 ( 52%)]  Loss:  1.738902 (1.6549)  Time: 2.827s,   90.56/s  (2.999s,   85.36/s)  LR: 4.001e-04  Data: 0.023 (0.020)
2024-04-02 09:04:45,133 - train - INFO - Train: 53 [ 150/195 ( 77%)]  Loss:  1.420462 (1.6308)  Time: 2.765s,   92.60/s  (2.980s,   85.91/s)  LR: 4.001e-04  Data: 0.014 (0.019)
2024-04-02 09:06:55,003 - train - INFO - Train: 53 [ 194/195 (100%)]  Loss:  1.273071 (1.6254)  Time: 3.109s,   82.33/s  (2.974s,   86.09/s)  LR: 4.001e-04  Data: 0.000 (0.018)
2024-04-02 09:06:55,004 - train - INFO - True
2024-04-02 09:06:55,009 - train - INFO - alphas:tensor([0.0226, 0.9774], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,009 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,009 - train - INFO - True
2024-04-02 09:06:55,010 - train - INFO - alphas:tensor([0.1052, 0.8948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,010 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,010 - train - INFO - True
2024-04-02 09:06:55,011 - train - INFO - alphas:tensor([0.5541, 0.4459], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,011 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,011 - train - INFO - True
2024-04-02 09:06:55,012 - train - INFO - alphas:tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,012 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,012 - train - INFO - True
2024-04-02 09:06:55,013 - train - INFO - alphas:tensor([0.1964, 0.8036], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,013 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,013 - train - INFO - True
2024-04-02 09:06:55,018 - train - INFO - alphas:tensor([0.3049, 0.6951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,018 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,018 - train - INFO - True
2024-04-02 09:06:55,019 - train - INFO - alphas:tensor([0.5639, 0.4361], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,019 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,019 - train - INFO - True
2024-04-02 09:06:55,020 - train - INFO - alphas:tensor([0.4620, 0.5380], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,020 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,020 - train - INFO - True
2024-04-02 09:06:55,021 - train - INFO - alphas:tensor([0.2968, 0.7032], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,021 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,021 - train - INFO - True
2024-04-02 09:06:55,022 - train - INFO - alphas:tensor([0.4310, 0.5690], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,022 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,022 - train - INFO - True
2024-04-02 09:06:55,023 - train - INFO - alphas:tensor([0.5659, 0.4341], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,023 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,023 - train - INFO - True
2024-04-02 09:06:55,024 - train - INFO - alphas:tensor([0.4337, 0.5663], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,024 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,024 - train - INFO - True
2024-04-02 09:06:55,025 - train - INFO - alphas:tensor([0.3118, 0.6882], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,025 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,025 - train - INFO - True
2024-04-02 09:06:55,025 - train - INFO - alphas:tensor([0.4192, 0.5808], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,025 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,026 - train - INFO - True
2024-04-02 09:06:55,026 - train - INFO - alphas:tensor([0.5086, 0.4914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,026 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,026 - train - INFO - True
2024-04-02 09:06:55,040 - train - INFO - alphas:tensor([0.3623, 0.6377], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,040 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,040 - train - INFO - True
2024-04-02 09:06:55,041 - train - INFO - alphas:tensor([0.2765, 0.7235], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,041 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,041 - train - INFO - True
2024-04-02 09:06:55,042 - train - INFO - alphas:tensor([0.3240, 0.6760], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,042 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,042 - train - INFO - True
2024-04-02 09:06:55,043 - train - INFO - alphas:tensor([0.3859, 0.6141], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,043 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,043 - train - INFO - True
2024-04-02 09:06:55,044 - train - INFO - alphas:tensor([0.2037, 0.7963], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,044 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,044 - train - INFO - True
2024-04-02 09:06:55,044 - train - INFO - alphas:tensor([0.2230, 0.7770], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,045 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,045 - train - INFO - True
2024-04-02 09:06:55,045 - train - INFO - alphas:tensor([0.2656, 0.7344], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,045 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,045 - train - INFO - True
2024-04-02 09:06:55,046 - train - INFO - alphas:tensor([0.3462, 0.6538], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,046 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,046 - train - INFO - True
2024-04-02 09:06:55,047 - train - INFO - alphas:tensor([0.1347, 0.8653], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,047 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,047 - train - INFO - True
2024-04-02 09:06:55,048 - train - INFO - alphas:tensor([0.1569, 0.8431], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,048 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,048 - train - INFO - True
2024-04-02 09:06:55,049 - train - INFO - alphas:tensor([0.0836, 0.9164], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,049 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,049 - train - INFO - True
2024-04-02 09:06:55,058 - train - INFO - alphas:tensor([0.0357, 0.9643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,058 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,058 - train - INFO - True
2024-04-02 09:06:55,059 - train - INFO - alphas:tensor([0.0033, 0.9967], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,059 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,059 - train - INFO - True
2024-04-02 09:06:55,060 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:06:55,060 - train - INFO - tau:0.5989560064661611
2024-04-02 09:06:55,060 - train - INFO - avg block size:12.89655172413793
2024-04-02 09:06:57,014 - train - INFO - Test: [   0/39]  Time: 1.941 (1.941)  Loss:  0.4131 (0.4131)  Acc@1: 91.7969 (91.7969)  Acc@5: 100.0000 (100.0000)
2024-04-02 09:08:07,653 - train - INFO - Test: [  39/39]  Time: 1.776 (1.814)  Loss:  0.5088 (0.4030)  Acc@1: 81.2500 (91.2600)  Acc@5: 100.0000 (99.6600)
2024-04-02 09:08:10,817 - train - INFO - Train: 54 [   0/195 (  0%)]  Loss:  1.490528 (1.4905)  Time: 3.001s,   85.30/s  (3.001s,   85.30/s)  LR: 3.950e-04  Data: 0.290 (0.290)
2024-04-02 09:10:42,962 - train - INFO - Train: 54 [  50/195 ( 26%)]  Loss:  1.746784 (1.6056)  Time: 3.249s,   78.80/s  (3.042s,   84.16/s)  LR: 3.950e-04  Data: 0.010 (0.019)
2024-04-02 09:13:12,958 - train - INFO - Train: 54 [ 100/195 ( 52%)]  Loss:  1.797047 (1.6233)  Time: 2.994s,   85.50/s  (3.021s,   84.74/s)  LR: 3.950e-04  Data: 0.023 (0.016)
2024-04-02 09:15:40,439 - train - INFO - Train: 54 [ 150/195 ( 77%)]  Loss:  1.750813 (1.6318)  Time: 2.804s,   91.31/s  (2.997s,   85.41/s)  LR: 3.950e-04  Data: 0.028 (0.016)
2024-04-02 09:17:51,397 - train - INFO - Train: 54 [ 194/195 (100%)]  Loss:  1.486875 (1.6281)  Time: 2.533s,  101.05/s  (2.993s,   85.54/s)  LR: 3.950e-04  Data: 0.000 (0.015)
2024-04-02 09:17:51,398 - train - INFO - True
2024-04-02 09:17:51,399 - train - INFO - alphas:tensor([0.0208, 0.9792], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,399 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,399 - train - INFO - True
2024-04-02 09:17:51,400 - train - INFO - alphas:tensor([0.1039, 0.8961], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,400 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,400 - train - INFO - True
2024-04-02 09:17:51,405 - train - INFO - alphas:tensor([0.5514, 0.4486], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,405 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,405 - train - INFO - True
2024-04-02 09:17:51,406 - train - INFO - alphas:tensor([0.4973, 0.5027], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,406 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,406 - train - INFO - True
2024-04-02 09:17:51,407 - train - INFO - alphas:tensor([0.1923, 0.8077], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,407 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,407 - train - INFO - True
2024-04-02 09:17:51,408 - train - INFO - alphas:tensor([0.3007, 0.6993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,408 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,408 - train - INFO - True
2024-04-02 09:17:51,409 - train - INFO - alphas:tensor([0.5611, 0.4389], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,409 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,409 - train - INFO - True
2024-04-02 09:17:51,410 - train - INFO - alphas:tensor([0.4576, 0.5424], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,410 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,410 - train - INFO - True
2024-04-02 09:17:51,411 - train - INFO - alphas:tensor([0.2946, 0.7054], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,411 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,411 - train - INFO - True
2024-04-02 09:17:51,412 - train - INFO - alphas:tensor([0.4285, 0.5715], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,412 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,412 - train - INFO - True
2024-04-02 09:17:51,413 - train - INFO - alphas:tensor([0.5658, 0.4342], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,413 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,413 - train - INFO - True
2024-04-02 09:17:51,418 - train - INFO - alphas:tensor([0.4339, 0.5661], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,418 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,419 - train - INFO - True
2024-04-02 09:17:51,419 - train - INFO - alphas:tensor([0.3109, 0.6891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,420 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,420 - train - INFO - True
2024-04-02 09:17:51,420 - train - INFO - alphas:tensor([0.4166, 0.5834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,420 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,421 - train - INFO - True
2024-04-02 09:17:51,421 - train - INFO - alphas:tensor([0.5065, 0.4935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,421 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,422 - train - INFO - True
2024-04-02 09:17:51,422 - train - INFO - alphas:tensor([0.3585, 0.6415], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,422 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,423 - train - INFO - True
2024-04-02 09:17:51,423 - train - INFO - alphas:tensor([0.2751, 0.7249], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,423 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,424 - train - INFO - True
2024-04-02 09:17:51,424 - train - INFO - alphas:tensor([0.3232, 0.6768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,424 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,425 - train - INFO - True
2024-04-02 09:17:51,425 - train - INFO - alphas:tensor([0.3833, 0.6167], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,425 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,425 - train - INFO - True
2024-04-02 09:17:51,426 - train - INFO - alphas:tensor([0.2023, 0.7977], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,426 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,426 - train - INFO - True
2024-04-02 09:17:51,427 - train - INFO - alphas:tensor([0.2210, 0.7790], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,427 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,428 - train - INFO - True
2024-04-02 09:17:51,428 - train - INFO - alphas:tensor([0.2624, 0.7376], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,429 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,429 - train - INFO - True
2024-04-02 09:17:51,429 - train - INFO - alphas:tensor([0.3410, 0.6590], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,434 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,434 - train - INFO - True
2024-04-02 09:17:51,435 - train - INFO - alphas:tensor([0.1284, 0.8716], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,435 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,435 - train - INFO - True
2024-04-02 09:17:51,436 - train - INFO - alphas:tensor([0.1528, 0.8472], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,436 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,436 - train - INFO - True
2024-04-02 09:17:51,437 - train - INFO - alphas:tensor([0.0778, 0.9222], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,437 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,437 - train - INFO - True
2024-04-02 09:17:51,438 - train - INFO - alphas:tensor([0.0322, 0.9678], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,438 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,438 - train - INFO - True
2024-04-02 09:17:51,439 - train - INFO - alphas:tensor([0.0029, 0.9971], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,439 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,439 - train - INFO - True
2024-04-02 09:17:51,440 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:17:51,440 - train - INFO - tau:0.5929664464014994
2024-04-02 09:17:51,440 - train - INFO - avg block size:13.413793103448276
2024-04-02 09:17:53,223 - train - INFO - Test: [   0/39]  Time: 1.780 (1.780)  Loss:  0.3945 (0.3945)  Acc@1: 90.2344 (90.2344)  Acc@5: 100.0000 (100.0000)
2024-04-02 09:19:04,460 - train - INFO - Test: [  39/39]  Time: 1.788 (1.825)  Loss:  0.4890 (0.3721)  Acc@1: 81.2500 (91.5400)  Acc@5: 100.0000 (99.6300)
2024-04-02 09:19:08,452 - train - INFO - Train: 55 [   0/195 (  0%)]  Loss:  1.377003 (1.3770)  Time: 3.647s,   70.20/s  (3.647s,   70.20/s)  LR: 3.898e-04  Data: 0.349 (0.349)
2024-04-02 09:21:37,068 - train - INFO - Train: 55 [  50/195 ( 26%)]  Loss:  1.252147 (1.6470)  Time: 2.796s,   91.56/s  (2.986s,   85.75/s)  LR: 3.898e-04  Data: 0.033 (0.020)
2024-04-02 09:24:06,185 - train - INFO - Train: 55 [ 100/195 ( 52%)]  Loss:  1.415554 (1.6614)  Time: 3.085s,   82.97/s  (2.984s,   85.79/s)  LR: 3.898e-04  Data: 0.014 (0.018)
2024-04-02 09:26:36,499 - train - INFO - Train: 55 [ 150/195 ( 77%)]  Loss:  1.814863 (1.6458)  Time: 3.210s,   79.75/s  (2.991s,   85.58/s)  LR: 3.898e-04  Data: 0.011 (0.017)
2024-04-02 09:28:47,367 - train - INFO - Train: 55 [ 194/195 (100%)]  Loss:  1.544826 (1.6337)  Time: 3.451s,   74.18/s  (2.987s,   85.69/s)  LR: 3.898e-04  Data: 0.000 (0.016)
2024-04-02 09:28:47,372 - train - INFO - True
2024-04-02 09:28:47,379 - train - INFO - alphas:tensor([0.0190, 0.9810], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,379 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,379 - train - INFO - True
2024-04-02 09:28:47,380 - train - INFO - alphas:tensor([0.1020, 0.8980], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,380 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,380 - train - INFO - True
2024-04-02 09:28:47,381 - train - INFO - alphas:tensor([0.5501, 0.4499], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,381 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,381 - train - INFO - True
2024-04-02 09:28:47,382 - train - INFO - alphas:tensor([0.4956, 0.5044], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,382 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,382 - train - INFO - True
2024-04-02 09:28:47,383 - train - INFO - alphas:tensor([0.1907, 0.8093], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,383 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,384 - train - INFO - True
2024-04-02 09:28:47,384 - train - INFO - alphas:tensor([0.2991, 0.7009], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,385 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,385 - train - INFO - True
2024-04-02 09:28:47,390 - train - INFO - alphas:tensor([0.5586, 0.4414], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,390 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,390 - train - INFO - True
2024-04-02 09:28:47,391 - train - INFO - alphas:tensor([0.4548, 0.5452], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,391 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,391 - train - INFO - True
2024-04-02 09:28:47,392 - train - INFO - alphas:tensor([0.2906, 0.7094], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,392 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,392 - train - INFO - True
2024-04-02 09:28:47,393 - train - INFO - alphas:tensor([0.4243, 0.5757], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,393 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,393 - train - INFO - True
2024-04-02 09:28:47,403 - train - INFO - alphas:tensor([0.5628, 0.4372], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,403 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,403 - train - INFO - True
2024-04-02 09:28:47,404 - train - INFO - alphas:tensor([0.4306, 0.5694], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,404 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,404 - train - INFO - True
2024-04-02 09:28:47,405 - train - INFO - alphas:tensor([0.3086, 0.6914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,405 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,405 - train - INFO - True
2024-04-02 09:28:47,406 - train - INFO - alphas:tensor([0.4146, 0.5854], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,406 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,406 - train - INFO - True
2024-04-02 09:28:47,420 - train - INFO - alphas:tensor([0.5035, 0.4965], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,420 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,420 - train - INFO - True
2024-04-02 09:28:47,421 - train - INFO - alphas:tensor([0.3567, 0.6433], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,421 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,421 - train - INFO - True
2024-04-02 09:28:47,422 - train - INFO - alphas:tensor([0.2710, 0.7290], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,422 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,423 - train - INFO - True
2024-04-02 09:28:47,423 - train - INFO - alphas:tensor([0.3215, 0.6785], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,423 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,424 - train - INFO - True
2024-04-02 09:28:47,424 - train - INFO - alphas:tensor([0.3803, 0.6197], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,424 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,425 - train - INFO - True
2024-04-02 09:28:47,425 - train - INFO - alphas:tensor([0.1993, 0.8007], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,425 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,426 - train - INFO - True
2024-04-02 09:28:47,426 - train - INFO - alphas:tensor([0.2185, 0.7815], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,427 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,427 - train - INFO - True
2024-04-02 09:28:47,427 - train - INFO - alphas:tensor([0.2598, 0.7402], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,428 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,428 - train - INFO - True
2024-04-02 09:28:47,428 - train - INFO - alphas:tensor([0.3368, 0.6632], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,429 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,429 - train - INFO - True
2024-04-02 09:28:47,429 - train - INFO - alphas:tensor([0.1244, 0.8756], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,430 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,430 - train - INFO - True
2024-04-02 09:28:47,435 - train - INFO - alphas:tensor([0.1502, 0.8498], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,435 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,435 - train - INFO - True
2024-04-02 09:28:47,436 - train - INFO - alphas:tensor([0.0732, 0.9268], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,436 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,436 - train - INFO - True
2024-04-02 09:28:47,437 - train - INFO - alphas:tensor([0.0292, 0.9708], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,437 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,437 - train - INFO - True
2024-04-02 09:28:47,442 - train - INFO - alphas:tensor([0.0026, 0.9974], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,443 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,443 - train - INFO - True
2024-04-02 09:28:47,443 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:28:47,444 - train - INFO - tau:0.5870367819374844
2024-04-02 09:28:47,444 - train - INFO - avg block size:13.413793103448276
2024-04-02 09:28:49,424 - train - INFO - Test: [   0/39]  Time: 1.967 (1.967)  Loss:  0.4417 (0.4417)  Acc@1: 89.4531 (89.4531)  Acc@5: 99.6094 (99.6094)
2024-04-02 09:30:00,489 - train - INFO - Test: [  39/39]  Time: 1.649 (1.826)  Loss:  0.3618 (0.4109)  Acc@1: 93.7500 (91.2000)  Acc@5: 100.0000 (99.7100)
2024-04-02 09:30:03,831 - train - INFO - Train: 56 [   0/195 (  0%)]  Loss:  1.386057 (1.3861)  Time: 3.147s,   81.34/s  (3.147s,   81.34/s)  LR: 3.846e-04  Data: 0.349 (0.349)
2024-04-02 09:32:30,588 - train - INFO - Train: 56 [  50/195 ( 26%)]  Loss:  1.916783 (1.6434)  Time: 3.027s,   84.57/s  (2.939s,   87.10/s)  LR: 3.846e-04  Data: 0.005 (0.021)
2024-04-02 09:35:01,041 - train - INFO - Train: 56 [ 100/195 ( 52%)]  Loss:  1.831760 (1.6384)  Time: 2.761s,   92.72/s  (2.974s,   86.09/s)  LR: 3.846e-04  Data: 0.028 (0.018)
2024-04-02 09:37:32,285 - train - INFO - Train: 56 [ 150/195 ( 77%)]  Loss:  1.889633 (1.6396)  Time: 2.906s,   88.08/s  (2.991s,   85.60/s)  LR: 3.846e-04  Data: 0.014 (0.017)
2024-04-02 09:39:42,977 - train - INFO - Train: 56 [ 194/195 (100%)]  Loss:  1.838652 (1.6494)  Time: 3.118s,   82.09/s  (2.986s,   85.73/s)  LR: 3.846e-04  Data: 0.000 (0.016)
2024-04-02 09:39:42,977 - train - INFO - True
2024-04-02 09:39:42,979 - train - INFO - alphas:tensor([0.0174, 0.9826], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:42,979 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:42,979 - train - INFO - True
2024-04-02 09:39:42,980 - train - INFO - alphas:tensor([0.0998, 0.9002], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:42,980 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:42,980 - train - INFO - True
2024-04-02 09:39:42,985 - train - INFO - alphas:tensor([0.5502, 0.4498], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:42,985 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:42,986 - train - INFO - True
2024-04-02 09:39:42,986 - train - INFO - alphas:tensor([0.4953, 0.5047], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:42,987 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:42,987 - train - INFO - True
2024-04-02 09:39:42,987 - train - INFO - alphas:tensor([0.1883, 0.8117], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:42,988 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:42,997 - train - INFO - True
2024-04-02 09:39:42,997 - train - INFO - alphas:tensor([0.2952, 0.7048], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:42,997 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:42,998 - train - INFO - True
2024-04-02 09:39:42,998 - train - INFO - alphas:tensor([0.5588, 0.4412], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:42,998 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:42,999 - train - INFO - True
2024-04-02 09:39:42,999 - train - INFO - alphas:tensor([0.4553, 0.5447], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,000 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,000 - train - INFO - True
2024-04-02 09:39:43,001 - train - INFO - alphas:tensor([0.2891, 0.7109], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,001 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,001 - train - INFO - True
2024-04-02 09:39:43,002 - train - INFO - alphas:tensor([0.4215, 0.5785], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,002 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,002 - train - INFO - True
2024-04-02 09:39:43,003 - train - INFO - alphas:tensor([0.5612, 0.4388], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,003 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,003 - train - INFO - True
2024-04-02 09:39:43,004 - train - INFO - alphas:tensor([0.4317, 0.5683], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,004 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,005 - train - INFO - True
2024-04-02 09:39:43,005 - train - INFO - alphas:tensor([0.3047, 0.6953], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,005 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,006 - train - INFO - True
2024-04-02 09:39:43,006 - train - INFO - alphas:tensor([0.4111, 0.5889], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,006 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,007 - train - INFO - True
2024-04-02 09:39:43,012 - train - INFO - alphas:tensor([0.5014, 0.4986], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,012 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,012 - train - INFO - True
2024-04-02 09:39:43,013 - train - INFO - alphas:tensor([0.3557, 0.6443], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,013 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,013 - train - INFO - True
2024-04-02 09:39:43,014 - train - INFO - alphas:tensor([0.2710, 0.7290], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,014 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,014 - train - INFO - True
2024-04-02 09:39:43,015 - train - INFO - alphas:tensor([0.3202, 0.6798], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,015 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,015 - train - INFO - True
2024-04-02 09:39:43,016 - train - INFO - alphas:tensor([0.3763, 0.6237], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,016 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,016 - train - INFO - True
2024-04-02 09:39:43,017 - train - INFO - alphas:tensor([0.1955, 0.8045], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,017 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,017 - train - INFO - True
2024-04-02 09:39:43,018 - train - INFO - alphas:tensor([0.2136, 0.7864], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,018 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,018 - train - INFO - True
2024-04-02 09:39:43,019 - train - INFO - alphas:tensor([0.2545, 0.7455], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,019 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,019 - train - INFO - True
2024-04-02 09:39:43,020 - train - INFO - alphas:tensor([0.3317, 0.6683], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,020 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,020 - train - INFO - True
2024-04-02 09:39:43,021 - train - INFO - alphas:tensor([0.1193, 0.8807], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,021 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,021 - train - INFO - True
2024-04-02 09:39:43,022 - train - INFO - alphas:tensor([0.1475, 0.8525], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,022 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,022 - train - INFO - True
2024-04-02 09:39:43,023 - train - INFO - alphas:tensor([0.0680, 0.9320], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,028 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,028 - train - INFO - True
2024-04-02 09:39:43,029 - train - INFO - alphas:tensor([0.0264, 0.9736], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,029 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,029 - train - INFO - True
2024-04-02 09:39:43,030 - train - INFO - alphas:tensor([0.0023, 0.9977], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,030 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,030 - train - INFO - True
2024-04-02 09:39:43,031 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:39:43,031 - train - INFO - tau:0.5811664141181095
2024-04-02 09:39:43,031 - train - INFO - avg block size:13.413793103448276
2024-04-02 09:39:44,793 - train - INFO - Test: [   0/39]  Time: 1.751 (1.751)  Loss:  0.4146 (0.4146)  Acc@1: 91.0156 (91.0156)  Acc@5: 99.2188 (99.2188)
2024-04-02 09:40:55,713 - train - INFO - Test: [  39/39]  Time: 1.851 (1.817)  Loss:  0.3906 (0.3976)  Acc@1: 87.5000 (91.4100)  Acc@5: 100.0000 (99.6100)
2024-04-02 09:40:59,116 - train - INFO - Train: 57 [   0/195 (  0%)]  Loss:  1.253676 (1.2537)  Time: 3.180s,   80.49/s  (3.180s,   80.49/s)  LR: 3.794e-04  Data: 0.449 (0.449)
2024-04-02 09:43:26,412 - train - INFO - Train: 57 [  50/195 ( 26%)]  Loss:  1.866999 (1.6040)  Time: 2.965s,   86.33/s  (2.950s,   86.77/s)  LR: 3.794e-04  Data: 0.017 (0.022)
2024-04-02 09:45:52,975 - train - INFO - Train: 57 [ 100/195 ( 52%)]  Loss:  1.782406 (1.6165)  Time: 2.946s,   86.91/s  (2.941s,   87.05/s)  LR: 3.794e-04  Data: 0.014 (0.019)
2024-04-02 09:48:18,324 - train - INFO - Train: 57 [ 150/195 ( 77%)]  Loss:  1.811666 (1.6172)  Time: 2.615s,   97.91/s  (2.930s,   87.38/s)  LR: 3.794e-04  Data: 0.019 (0.017)
2024-04-02 09:50:29,248 - train - INFO - Train: 57 [ 194/195 (100%)]  Loss:  1.352079 (1.6151)  Time: 2.717s,   94.23/s  (2.940s,   87.07/s)  LR: 3.794e-04  Data: 0.000 (0.017)
2024-04-02 09:50:29,258 - train - INFO - True
2024-04-02 09:50:29,259 - train - INFO - alphas:tensor([0.0158, 0.9842], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,259 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,259 - train - INFO - True
2024-04-02 09:50:29,260 - train - INFO - alphas:tensor([0.0978, 0.9022], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,260 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,260 - train - INFO - True
2024-04-02 09:50:29,261 - train - INFO - alphas:tensor([0.5469, 0.4531], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,261 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,261 - train - INFO - True
2024-04-02 09:50:29,262 - train - INFO - alphas:tensor([0.4911, 0.5089], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,262 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,262 - train - INFO - True
2024-04-02 09:50:29,263 - train - INFO - alphas:tensor([0.1847, 0.8153], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,263 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,264 - train - INFO - True
2024-04-02 09:50:29,264 - train - INFO - alphas:tensor([0.2916, 0.7084], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,265 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,265 - train - INFO - True
2024-04-02 09:50:29,266 - train - INFO - alphas:tensor([0.5570, 0.4430], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,266 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,267 - train - INFO - True
2024-04-02 09:50:29,267 - train - INFO - alphas:tensor([0.4538, 0.5462], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,267 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,268 - train - INFO - True
2024-04-02 09:50:29,268 - train - INFO - alphas:tensor([0.2883, 0.7117], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,269 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,269 - train - INFO - True
2024-04-02 09:50:29,269 - train - INFO - alphas:tensor([0.4205, 0.5795], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,270 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,270 - train - INFO - True
2024-04-02 09:50:29,270 - train - INFO - alphas:tensor([0.5605, 0.4395], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,271 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,271 - train - INFO - True
2024-04-02 09:50:29,272 - train - INFO - alphas:tensor([0.4311, 0.5689], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,272 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,272 - train - INFO - True
2024-04-02 09:50:29,273 - train - INFO - alphas:tensor([0.3041, 0.6959], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,273 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,273 - train - INFO - True
2024-04-02 09:50:29,274 - train - INFO - alphas:tensor([0.4118, 0.5882], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,274 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,274 - train - INFO - True
2024-04-02 09:50:29,275 - train - INFO - alphas:tensor([0.5002, 0.4998], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,275 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,275 - train - INFO - True
2024-04-02 09:50:29,276 - train - INFO - alphas:tensor([0.3544, 0.6456], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,276 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,276 - train - INFO - True
2024-04-02 09:50:29,277 - train - INFO - alphas:tensor([0.2700, 0.7300], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,277 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,277 - train - INFO - True
2024-04-02 09:50:29,282 - train - INFO - alphas:tensor([0.3186, 0.6814], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,283 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,283 - train - INFO - True
2024-04-02 09:50:29,283 - train - INFO - alphas:tensor([0.3760, 0.6240], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,284 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,284 - train - INFO - True
2024-04-02 09:50:29,284 - train - INFO - alphas:tensor([0.1950, 0.8050], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,285 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,285 - train - INFO - True
2024-04-02 09:50:29,286 - train - INFO - alphas:tensor([0.2130, 0.7870], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,286 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,286 - train - INFO - True
2024-04-02 09:50:29,287 - train - INFO - alphas:tensor([0.2539, 0.7461], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,287 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,287 - train - INFO - True
2024-04-02 09:50:29,288 - train - INFO - alphas:tensor([0.3312, 0.6688], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,288 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,288 - train - INFO - True
2024-04-02 09:50:29,289 - train - INFO - alphas:tensor([0.1167, 0.8833], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,289 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,289 - train - INFO - True
2024-04-02 09:50:29,290 - train - INFO - alphas:tensor([0.1446, 0.8554], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,290 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,290 - train - INFO - True
2024-04-02 09:50:29,291 - train - INFO - alphas:tensor([0.0638, 0.9362], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,291 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,291 - train - INFO - True
2024-04-02 09:50:29,292 - train - INFO - alphas:tensor([0.0240, 0.9760], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,292 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,292 - train - INFO - True
2024-04-02 09:50:29,293 - train - INFO - alphas:tensor([0.0020, 0.9980], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,293 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,293 - train - INFO - True
2024-04-02 09:50:29,298 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 09:50:29,298 - train - INFO - tau:0.5753547499769285
2024-04-02 09:50:29,299 - train - INFO - avg block size:13.413793103448276
2024-04-02 09:50:31,168 - train - INFO - Test: [   0/39]  Time: 1.866 (1.866)  Loss:  0.4192 (0.4192)  Acc@1: 89.4531 (89.4531)  Acc@5: 99.6094 (99.6094)
2024-04-02 09:51:42,585 - train - INFO - Test: [  39/39]  Time: 1.815 (1.832)  Loss:  0.3650 (0.3933)  Acc@1: 87.5000 (91.7600)  Acc@5: 100.0000 (99.6500)
2024-04-02 09:51:46,046 - train - INFO - Train: 58 [   0/195 (  0%)]  Loss:  1.406388 (1.4064)  Time: 3.059s,   83.68/s  (3.059s,   83.68/s)  LR: 3.741e-04  Data: 0.470 (0.470)
2024-04-02 09:54:15,133 - train - INFO - Train: 58 [  50/195 ( 26%)]  Loss:  1.586217 (1.6081)  Time: 3.022s,   84.70/s  (2.983s,   85.82/s)  LR: 3.741e-04  Data: 0.015 (0.021)
2024-04-02 09:56:43,508 - train - INFO - Train: 58 [ 100/195 ( 52%)]  Loss:  1.810906 (1.6171)  Time: 3.007s,   85.12/s  (2.975s,   86.04/s)  LR: 3.741e-04  Data: 0.014 (0.018)
2024-04-02 09:59:08,395 - train - INFO - Train: 58 [ 150/195 ( 77%)]  Loss:  1.689971 (1.6202)  Time: 2.664s,   96.11/s  (2.950s,   86.79/s)  LR: 3.741e-04  Data: 0.005 (0.017)
2024-04-02 10:01:16,926 - train - INFO - Train: 58 [ 194/195 (100%)]  Loss:  1.368621 (1.6171)  Time: 2.979s,   85.93/s  (2.943s,   86.98/s)  LR: 3.741e-04  Data: 0.000 (0.016)
2024-04-02 10:01:16,927 - train - INFO - True
2024-04-02 10:01:16,937 - train - INFO - alphas:tensor([0.0144, 0.9856], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,938 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,938 - train - INFO - True
2024-04-02 10:01:16,939 - train - INFO - alphas:tensor([0.0968, 0.9032], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,939 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,939 - train - INFO - True
2024-04-02 10:01:16,940 - train - INFO - alphas:tensor([0.5458, 0.4542], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,940 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,940 - train - INFO - True
2024-04-02 10:01:16,941 - train - INFO - alphas:tensor([0.4904, 0.5096], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,942 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,942 - train - INFO - True
2024-04-02 10:01:16,942 - train - INFO - alphas:tensor([0.1827, 0.8173], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,943 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,943 - train - INFO - True
2024-04-02 10:01:16,944 - train - INFO - alphas:tensor([0.2892, 0.7108], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,944 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,945 - train - INFO - True
2024-04-02 10:01:16,945 - train - INFO - alphas:tensor([0.5543, 0.4457], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,946 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,946 - train - INFO - True
2024-04-02 10:01:16,947 - train - INFO - alphas:tensor([0.4502, 0.5498], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,947 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,947 - train - INFO - True
2024-04-02 10:01:16,948 - train - INFO - alphas:tensor([0.2850, 0.7150], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,949 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,949 - train - INFO - True
2024-04-02 10:01:16,950 - train - INFO - alphas:tensor([0.4161, 0.5839], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,950 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,950 - train - INFO - True
2024-04-02 10:01:16,951 - train - INFO - alphas:tensor([0.5572, 0.4428], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,951 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,951 - train - INFO - True
2024-04-02 10:01:16,952 - train - INFO - alphas:tensor([0.4251, 0.5749], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,952 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,953 - train - INFO - True
2024-04-02 10:01:16,954 - train - INFO - alphas:tensor([0.3003, 0.6997], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,954 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,954 - train - INFO - True
2024-04-02 10:01:16,955 - train - INFO - alphas:tensor([0.4088, 0.5912], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,955 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,956 - train - INFO - True
2024-04-02 10:01:16,956 - train - INFO - alphas:tensor([0.4966, 0.5034], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,957 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,957 - train - INFO - True
2024-04-02 10:01:16,963 - train - INFO - alphas:tensor([0.3495, 0.6505], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,963 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,963 - train - INFO - True
2024-04-02 10:01:16,964 - train - INFO - alphas:tensor([0.2659, 0.7341], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,964 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,964 - train - INFO - True
2024-04-02 10:01:16,965 - train - INFO - alphas:tensor([0.3132, 0.6868], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,965 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,965 - train - INFO - True
2024-04-02 10:01:16,966 - train - INFO - alphas:tensor([0.3722, 0.6278], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,966 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,967 - train - INFO - True
2024-04-02 10:01:16,967 - train - INFO - alphas:tensor([0.1920, 0.8080], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,968 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,968 - train - INFO - True
2024-04-02 10:01:16,969 - train - INFO - alphas:tensor([0.2100, 0.7900], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,969 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,969 - train - INFO - True
2024-04-02 10:01:16,970 - train - INFO - alphas:tensor([0.2516, 0.7484], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,970 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,970 - train - INFO - True
2024-04-02 10:01:16,976 - train - INFO - alphas:tensor([0.3278, 0.6722], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,976 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,976 - train - INFO - True
2024-04-02 10:01:16,978 - train - INFO - alphas:tensor([0.1113, 0.8887], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,978 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,978 - train - INFO - True
2024-04-02 10:01:16,979 - train - INFO - alphas:tensor([0.1404, 0.8596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,979 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,980 - train - INFO - True
2024-04-02 10:01:16,981 - train - INFO - alphas:tensor([0.0592, 0.9408], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,981 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,981 - train - INFO - True
2024-04-02 10:01:16,982 - train - INFO - alphas:tensor([0.0217, 0.9783], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,982 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,983 - train - INFO - True
2024-04-02 10:01:16,983 - train - INFO - alphas:tensor([0.0017, 0.9983], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,984 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,984 - train - INFO - True
2024-04-02 10:01:16,985 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:01:16,985 - train - INFO - tau:0.5696012024771592
2024-04-02 10:01:16,985 - train - INFO - avg block size:13.931034482758621
2024-04-02 10:01:18,959 - train - INFO - Test: [   0/39]  Time: 1.967 (1.967)  Loss:  0.4077 (0.4077)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-02 10:02:30,990 - train - INFO - Test: [  39/39]  Time: 1.748 (1.850)  Loss:  0.4319 (0.3912)  Acc@1: 81.2500 (91.2500)  Acc@5: 100.0000 (99.7600)
2024-04-02 10:02:34,594 - train - INFO - Train: 59 [   0/195 (  0%)]  Loss:  1.237473 (1.2375)  Time: 3.306s,   77.43/s  (3.306s,   77.43/s)  LR: 3.688e-04  Data: 0.264 (0.264)
2024-04-02 10:05:03,605 - train - INFO - Train: 59 [  50/195 ( 26%)]  Loss:  1.574482 (1.6588)  Time: 3.012s,   84.99/s  (2.987s,   85.72/s)  LR: 3.688e-04  Data: 0.014 (0.019)
2024-04-02 10:07:30,039 - train - INFO - Train: 59 [ 100/195 ( 52%)]  Loss:  1.799955 (1.6577)  Time: 3.090s,   82.85/s  (2.958s,   86.55/s)  LR: 3.688e-04  Data: 0.010 (0.016)
2024-04-02 10:09:57,780 - train - INFO - Train: 59 [ 150/195 ( 77%)]  Loss:  1.243840 (1.6385)  Time: 3.042s,   84.14/s  (2.957s,   86.58/s)  LR: 3.688e-04  Data: 0.005 (0.015)
2024-04-02 10:12:08,674 - train - INFO - Train: 59 [ 194/195 (100%)]  Loss:  1.661160 (1.6447)  Time: 2.431s,  105.29/s  (2.961s,   86.46/s)  LR: 3.688e-04  Data: 0.000 (0.015)
2024-04-02 10:12:08,675 - train - INFO - True
2024-04-02 10:12:08,677 - train - INFO - alphas:tensor([0.0131, 0.9869], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,678 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,678 - train - INFO - True
2024-04-02 10:12:08,679 - train - INFO - alphas:tensor([0.0946, 0.9054], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,679 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,679 - train - INFO - True
2024-04-02 10:12:08,680 - train - INFO - alphas:tensor([0.5437, 0.4563], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,680 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,680 - train - INFO - True
2024-04-02 10:12:08,681 - train - INFO - alphas:tensor([0.4883, 0.5117], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,681 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,681 - train - INFO - True
2024-04-02 10:12:08,682 - train - INFO - alphas:tensor([0.1796, 0.8204], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,683 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,683 - train - INFO - True
2024-04-02 10:12:08,684 - train - INFO - alphas:tensor([0.2858, 0.7142], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,684 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,684 - train - INFO - True
2024-04-02 10:12:08,685 - train - INFO - alphas:tensor([0.5511, 0.4489], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,685 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,686 - train - INFO - True
2024-04-02 10:12:08,686 - train - INFO - alphas:tensor([0.4471, 0.5529], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,687 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,687 - train - INFO - True
2024-04-02 10:12:08,687 - train - INFO - alphas:tensor([0.2821, 0.7179], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,688 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,688 - train - INFO - True
2024-04-02 10:12:08,689 - train - INFO - alphas:tensor([0.4135, 0.5865], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,689 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,689 - train - INFO - True
2024-04-02 10:12:08,690 - train - INFO - alphas:tensor([0.5555, 0.4445], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,690 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,690 - train - INFO - True
2024-04-02 10:12:08,691 - train - INFO - alphas:tensor([0.4247, 0.5753], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,691 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,691 - train - INFO - True
2024-04-02 10:12:08,692 - train - INFO - alphas:tensor([0.2962, 0.7038], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,692 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,693 - train - INFO - True
2024-04-02 10:12:08,693 - train - INFO - alphas:tensor([0.4051, 0.5949], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,694 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,694 - train - INFO - True
2024-04-02 10:12:08,695 - train - INFO - alphas:tensor([0.4945, 0.5055], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,695 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,695 - train - INFO - True
2024-04-02 10:12:08,696 - train - INFO - alphas:tensor([0.3472, 0.6528], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,696 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,696 - train - INFO - True
2024-04-02 10:12:08,697 - train - INFO - alphas:tensor([0.2630, 0.7370], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,697 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,697 - train - INFO - True
2024-04-02 10:12:08,698 - train - INFO - alphas:tensor([0.3095, 0.6905], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,698 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,698 - train - INFO - True
2024-04-02 10:12:08,699 - train - INFO - alphas:tensor([0.3693, 0.6307], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,700 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,700 - train - INFO - True
2024-04-02 10:12:08,700 - train - INFO - alphas:tensor([0.1887, 0.8113], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,701 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,701 - train - INFO - True
2024-04-02 10:12:08,702 - train - INFO - alphas:tensor([0.2086, 0.7914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,702 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,702 - train - INFO - True
2024-04-02 10:12:08,703 - train - INFO - alphas:tensor([0.2479, 0.7521], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,703 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,703 - train - INFO - True
2024-04-02 10:12:08,708 - train - INFO - alphas:tensor([0.3242, 0.6758], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,709 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,709 - train - INFO - True
2024-04-02 10:12:08,710 - train - INFO - alphas:tensor([0.1066, 0.8934], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,710 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,710 - train - INFO - True
2024-04-02 10:12:08,711 - train - INFO - alphas:tensor([0.1397, 0.8603], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,711 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,711 - train - INFO - True
2024-04-02 10:12:08,712 - train - INFO - alphas:tensor([0.0553, 0.9447], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,712 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,712 - train - INFO - True
2024-04-02 10:12:08,713 - train - INFO - alphas:tensor([0.0197, 0.9803], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,713 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,714 - train - INFO - True
2024-04-02 10:12:08,714 - train - INFO - alphas:tensor([0.0015, 0.9985], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,715 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,715 - train - INFO - True
2024-04-02 10:12:08,715 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:12:08,716 - train - INFO - tau:0.5639051904523876
2024-04-02 10:12:08,716 - train - INFO - avg block size:13.931034482758621
2024-04-02 10:12:10,636 - train - INFO - Test: [   0/39]  Time: 1.916 (1.916)  Loss:  0.4053 (0.4053)  Acc@1: 91.0156 (91.0156)  Acc@5: 99.6094 (99.6094)
2024-04-02 10:13:22,913 - train - INFO - Test: [  39/39]  Time: 1.762 (1.855)  Loss:  0.4207 (0.3894)  Acc@1: 81.2500 (91.7000)  Acc@5: 100.0000 (99.6500)
2024-04-02 10:13:26,454 - train - INFO - Train: 60 [   0/195 (  0%)]  Loss:  1.426813 (1.4268)  Time: 3.323s,   77.05/s  (3.323s,   77.05/s)  LR: 3.634e-04  Data: 0.394 (0.394)
2024-04-02 10:15:56,539 - train - INFO - Train: 60 [  50/195 ( 26%)]  Loss:  1.800231 (1.5754)  Time: 3.001s,   85.29/s  (3.008s,   85.11/s)  LR: 3.634e-04  Data: 0.024 (0.021)
2024-04-02 10:18:26,793 - train - INFO - Train: 60 [ 100/195 ( 52%)]  Loss:  1.725514 (1.5940)  Time: 3.163s,   80.95/s  (3.007s,   85.15/s)  LR: 3.634e-04  Data: 0.033 (0.020)
2024-04-02 10:20:56,930 - train - INFO - Train: 60 [ 150/195 ( 77%)]  Loss:  1.471790 (1.5866)  Time: 2.942s,   87.01/s  (3.005s,   85.19/s)  LR: 3.634e-04  Data: 0.015 (0.019)
2024-04-02 10:23:09,850 - train - INFO - Train: 60 [ 194/195 (100%)]  Loss:  1.885289 (1.5980)  Time: 3.217s,   79.57/s  (3.009s,   85.09/s)  LR: 3.634e-04  Data: 0.000 (0.017)
2024-04-02 10:23:09,863 - train - INFO - True
2024-04-02 10:23:09,865 - train - INFO - alphas:tensor([0.0119, 0.9881], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,865 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,865 - train - INFO - True
2024-04-02 10:23:09,866 - train - INFO - alphas:tensor([0.0927, 0.9073], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,866 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,866 - train - INFO - True
2024-04-02 10:23:09,867 - train - INFO - alphas:tensor([0.5443, 0.4557], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,867 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,867 - train - INFO - True
2024-04-02 10:23:09,868 - train - INFO - alphas:tensor([0.4877, 0.5123], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,868 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,869 - train - INFO - True
2024-04-02 10:23:09,869 - train - INFO - alphas:tensor([0.1765, 0.8235], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,870 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,870 - train - INFO - True
2024-04-02 10:23:09,871 - train - INFO - alphas:tensor([0.2833, 0.7167], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,871 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,871 - train - INFO - True
2024-04-02 10:23:09,872 - train - INFO - alphas:tensor([0.5528, 0.4472], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,873 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,873 - train - INFO - True
2024-04-02 10:23:09,891 - train - INFO - alphas:tensor([0.4500, 0.5500], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,891 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,892 - train - INFO - True
2024-04-02 10:23:09,892 - train - INFO - alphas:tensor([0.2802, 0.7198], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,893 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,893 - train - INFO - True
2024-04-02 10:23:09,893 - train - INFO - alphas:tensor([0.4124, 0.5876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,894 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,894 - train - INFO - True
2024-04-02 10:23:09,895 - train - INFO - alphas:tensor([0.5556, 0.4444], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,895 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,895 - train - INFO - True
2024-04-02 10:23:09,896 - train - INFO - alphas:tensor([0.4264, 0.5736], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,896 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,896 - train - INFO - True
2024-04-02 10:23:09,901 - train - INFO - alphas:tensor([0.2960, 0.7040], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,902 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,902 - train - INFO - True
2024-04-02 10:23:09,903 - train - INFO - alphas:tensor([0.4060, 0.5940], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,903 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,903 - train - INFO - True
2024-04-02 10:23:09,904 - train - INFO - alphas:tensor([0.4941, 0.5059], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,904 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,904 - train - INFO - True
2024-04-02 10:23:09,905 - train - INFO - alphas:tensor([0.3492, 0.6508], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,905 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,905 - train - INFO - True
2024-04-02 10:23:09,906 - train - INFO - alphas:tensor([0.2620, 0.7380], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,906 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,906 - train - INFO - True
2024-04-02 10:23:09,907 - train - INFO - alphas:tensor([0.3120, 0.6880], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,907 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,908 - train - INFO - True
2024-04-02 10:23:09,908 - train - INFO - alphas:tensor([0.3672, 0.6328], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,909 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,913 - train - INFO - True
2024-04-02 10:23:09,914 - train - INFO - alphas:tensor([0.1868, 0.8132], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,914 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,914 - train - INFO - True
2024-04-02 10:23:09,915 - train - INFO - alphas:tensor([0.2050, 0.7950], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,915 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,916 - train - INFO - True
2024-04-02 10:23:09,916 - train - INFO - alphas:tensor([0.2433, 0.7567], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,917 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,917 - train - INFO - True
2024-04-02 10:23:09,918 - train - INFO - alphas:tensor([0.3221, 0.6779], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,918 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,918 - train - INFO - True
2024-04-02 10:23:09,919 - train - INFO - alphas:tensor([0.1037, 0.8963], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,919 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,919 - train - INFO - True
2024-04-02 10:23:09,920 - train - INFO - alphas:tensor([0.1378, 0.8622], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,920 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,920 - train - INFO - True
2024-04-02 10:23:09,921 - train - INFO - alphas:tensor([0.0519, 0.9481], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,921 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,921 - train - INFO - True
2024-04-02 10:23:09,922 - train - INFO - alphas:tensor([0.0179, 0.9821], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,922 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,923 - train - INFO - True
2024-04-02 10:23:09,923 - train - INFO - alphas:tensor([0.0014, 0.9986], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,924 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,924 - train - INFO - True
2024-04-02 10:23:09,924 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:23:09,925 - train - INFO - tau:0.5582661385478638
2024-04-02 10:23:09,925 - train - INFO - avg block size:13.931034482758621
2024-04-02 10:23:11,867 - train - INFO - Test: [   0/39]  Time: 1.938 (1.938)  Loss:  0.4233 (0.4233)  Acc@1: 89.4531 (89.4531)  Acc@5: 99.6094 (99.6094)
2024-04-02 10:24:22,453 - train - INFO - Test: [  39/39]  Time: 1.542 (1.813)  Loss:  0.3521 (0.4055)  Acc@1: 87.5000 (91.2500)  Acc@5: 100.0000 (99.6700)
2024-04-02 10:24:25,886 - train - INFO - Train: 61 [   0/195 (  0%)]  Loss:  1.395213 (1.3952)  Time: 3.138s,   81.59/s  (3.138s,   81.59/s)  LR: 3.580e-04  Data: 0.307 (0.307)
2024-04-02 10:26:58,854 - train - INFO - Train: 61 [  50/195 ( 26%)]  Loss:  1.886119 (1.6459)  Time: 2.834s,   90.34/s  (3.061s,   83.64/s)  LR: 3.580e-04  Data: 0.024 (0.020)
2024-04-02 10:29:26,695 - train - INFO - Train: 61 [ 100/195 ( 52%)]  Loss:  1.749244 (1.6267)  Time: 2.692s,   95.11/s  (3.009s,   85.07/s)  LR: 3.580e-04  Data: 0.007 (0.019)
2024-04-02 10:31:54,973 - train - INFO - Train: 61 [ 150/195 ( 77%)]  Loss:  1.879838 (1.6332)  Time: 2.882s,   88.83/s  (2.995s,   85.48/s)  LR: 3.580e-04  Data: 0.014 (0.018)
2024-04-02 10:34:05,053 - train - INFO - Train: 61 [ 194/195 (100%)]  Loss:  1.459590 (1.6278)  Time: 3.449s,   74.22/s  (2.986s,   85.73/s)  LR: 3.580e-04  Data: 0.000 (0.017)
2024-04-02 10:34:05,053 - train - INFO - True
2024-04-02 10:34:05,055 - train - INFO - alphas:tensor([0.0109, 0.9891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,055 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,055 - train - INFO - True
2024-04-02 10:34:05,056 - train - INFO - alphas:tensor([0.0915, 0.9085], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,056 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,056 - train - INFO - True
2024-04-02 10:34:05,057 - train - INFO - alphas:tensor([0.5408, 0.4592], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,057 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,058 - train - INFO - True
2024-04-02 10:34:05,058 - train - INFO - alphas:tensor([0.4836, 0.5164], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,058 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,059 - train - INFO - True
2024-04-02 10:34:05,059 - train - INFO - alphas:tensor([0.1733, 0.8267], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,060 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,060 - train - INFO - True
2024-04-02 10:34:05,061 - train - INFO - alphas:tensor([0.2792, 0.7208], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,061 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,061 - train - INFO - True
2024-04-02 10:34:05,062 - train - INFO - alphas:tensor([0.5507, 0.4493], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,062 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,062 - train - INFO - True
2024-04-02 10:34:05,063 - train - INFO - alphas:tensor([0.4460, 0.5540], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,064 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,064 - train - INFO - True
2024-04-02 10:34:05,065 - train - INFO - alphas:tensor([0.2792, 0.7208], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,065 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,065 - train - INFO - True
2024-04-02 10:34:05,066 - train - INFO - alphas:tensor([0.4107, 0.5893], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,066 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,066 - train - INFO - True
2024-04-02 10:34:05,067 - train - INFO - alphas:tensor([0.5539, 0.4461], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,067 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,067 - train - INFO - True
2024-04-02 10:34:05,068 - train - INFO - alphas:tensor([0.4218, 0.5782], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,071 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,072 - train - INFO - True
2024-04-02 10:34:05,073 - train - INFO - alphas:tensor([0.2946, 0.7054], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,073 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,073 - train - INFO - True
2024-04-02 10:34:05,074 - train - INFO - alphas:tensor([0.4040, 0.5960], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,074 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,074 - train - INFO - True
2024-04-02 10:34:05,075 - train - INFO - alphas:tensor([0.4903, 0.5097], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,075 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,075 - train - INFO - True
2024-04-02 10:34:05,076 - train - INFO - alphas:tensor([0.3446, 0.6554], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,076 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,076 - train - INFO - True
2024-04-02 10:34:05,077 - train - INFO - alphas:tensor([0.2596, 0.7404], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,077 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,078 - train - INFO - True
2024-04-02 10:34:05,078 - train - INFO - alphas:tensor([0.3080, 0.6920], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,079 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,079 - train - INFO - True
2024-04-02 10:34:05,080 - train - INFO - alphas:tensor([0.3641, 0.6359], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,080 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,080 - train - INFO - True
2024-04-02 10:34:05,081 - train - INFO - alphas:tensor([0.1841, 0.8159], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,081 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,081 - train - INFO - True
2024-04-02 10:34:05,082 - train - INFO - alphas:tensor([0.2027, 0.7973], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,082 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,082 - train - INFO - True
2024-04-02 10:34:05,083 - train - INFO - alphas:tensor([0.2422, 0.7578], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,083 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,083 - train - INFO - True
2024-04-02 10:34:05,084 - train - INFO - alphas:tensor([0.3212, 0.6788], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,085 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,085 - train - INFO - True
2024-04-02 10:34:05,085 - train - INFO - alphas:tensor([0.1003, 0.8997], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,086 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,086 - train - INFO - True
2024-04-02 10:34:05,087 - train - INFO - alphas:tensor([0.1348, 0.8652], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,087 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,087 - train - INFO - True
2024-04-02 10:34:05,088 - train - INFO - alphas:tensor([0.0486, 0.9514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,088 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,088 - train - INFO - True
2024-04-02 10:34:05,089 - train - INFO - alphas:tensor([0.0160, 0.9840], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,089 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,089 - train - INFO - True
2024-04-02 10:34:05,090 - train - INFO - alphas:tensor([0.0012, 0.9988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,090 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,091 - train - INFO - True
2024-04-02 10:34:05,091 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:34:05,091 - train - INFO - tau:0.5526834771623851
2024-04-02 10:34:05,092 - train - INFO - avg block size:13.931034482758621
2024-04-02 10:34:06,756 - train - INFO - Test: [   0/39]  Time: 1.661 (1.661)  Loss:  0.3933 (0.3933)  Acc@1: 92.5781 (92.5781)  Acc@5: 99.2188 (99.2188)
2024-04-02 10:35:17,285 - train - INFO - Test: [  39/39]  Time: 1.853 (1.805)  Loss:  0.4902 (0.3912)  Acc@1: 81.2500 (91.6300)  Acc@5: 100.0000 (99.5400)
2024-04-02 10:35:20,813 - train - INFO - Train: 62 [   0/195 (  0%)]  Loss:  1.239578 (1.2396)  Time: 3.232s,   79.21/s  (3.232s,   79.21/s)  LR: 3.526e-04  Data: 0.293 (0.293)
2024-04-02 10:37:49,201 - train - INFO - Train: 62 [  50/195 ( 26%)]  Loss:  1.758962 (1.6095)  Time: 3.269s,   78.31/s  (2.973s,   86.12/s)  LR: 3.526e-04  Data: 0.032 (0.021)
2024-04-02 10:40:19,220 - train - INFO - Train: 62 [ 100/195 ( 52%)]  Loss:  1.692815 (1.6225)  Time: 2.862s,   89.45/s  (2.986s,   85.72/s)  LR: 3.526e-04  Data: 0.005 (0.018)
2024-04-02 10:42:47,090 - train - INFO - Train: 62 [ 150/195 ( 77%)]  Loss:  1.503258 (1.6216)  Time: 2.897s,   88.35/s  (2.977s,   86.00/s)  LR: 3.526e-04  Data: 0.014 (0.017)
2024-04-02 10:44:57,617 - train - INFO - Train: 62 [ 194/195 (100%)]  Loss:  1.370103 (1.6164)  Time: 2.834s,   90.34/s  (2.974s,   86.07/s)  LR: 3.526e-04  Data: 0.000 (0.016)
2024-04-02 10:44:57,618 - train - INFO - True
2024-04-02 10:44:57,624 - train - INFO - alphas:tensor([0.0099, 0.9901], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,625 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,625 - train - INFO - True
2024-04-02 10:44:57,626 - train - INFO - alphas:tensor([0.0890, 0.9110], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,626 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,626 - train - INFO - True
2024-04-02 10:44:57,632 - train - INFO - alphas:tensor([0.5396, 0.4604], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,632 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,632 - train - INFO - True
2024-04-02 10:44:57,633 - train - INFO - alphas:tensor([0.4816, 0.5184], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,634 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,635 - train - INFO - True
2024-04-02 10:44:57,640 - train - INFO - alphas:tensor([0.1712, 0.8288], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,640 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,645 - train - INFO - True
2024-04-02 10:44:57,646 - train - INFO - alphas:tensor([0.2771, 0.7229], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,646 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,646 - train - INFO - True
2024-04-02 10:44:57,647 - train - INFO - alphas:tensor([0.5465, 0.4535], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,648 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,648 - train - INFO - True
2024-04-02 10:44:57,649 - train - INFO - alphas:tensor([0.4412, 0.5588], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,649 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,649 - train - INFO - True
2024-04-02 10:44:57,650 - train - INFO - alphas:tensor([0.2765, 0.7235], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,651 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,651 - train - INFO - True
2024-04-02 10:44:57,652 - train - INFO - alphas:tensor([0.4051, 0.5949], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,652 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,653 - train - INFO - True
2024-04-02 10:44:57,653 - train - INFO - alphas:tensor([0.5508, 0.4492], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,654 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,654 - train - INFO - True
2024-04-02 10:44:57,655 - train - INFO - alphas:tensor([0.4215, 0.5785], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,655 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,656 - train - INFO - True
2024-04-02 10:44:57,656 - train - INFO - alphas:tensor([0.2889, 0.7111], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,657 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,657 - train - INFO - True
2024-04-02 10:44:57,667 - train - INFO - alphas:tensor([0.3991, 0.6009], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,667 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,667 - train - INFO - True
2024-04-02 10:44:57,668 - train - INFO - alphas:tensor([0.4901, 0.5099], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,669 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,669 - train - INFO - True
2024-04-02 10:44:57,670 - train - INFO - alphas:tensor([0.3476, 0.6524], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,670 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,670 - train - INFO - True
2024-04-02 10:44:57,671 - train - INFO - alphas:tensor([0.2569, 0.7431], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,671 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,672 - train - INFO - True
2024-04-02 10:44:57,672 - train - INFO - alphas:tensor([0.3072, 0.6928], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,673 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,673 - train - INFO - True
2024-04-02 10:44:57,674 - train - INFO - alphas:tensor([0.3628, 0.6372], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,674 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,674 - train - INFO - True
2024-04-02 10:44:57,675 - train - INFO - alphas:tensor([0.1827, 0.8173], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,675 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,676 - train - INFO - True
2024-04-02 10:44:57,690 - train - INFO - alphas:tensor([0.2007, 0.7993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,690 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,690 - train - INFO - True
2024-04-02 10:44:57,691 - train - INFO - alphas:tensor([0.2381, 0.7619], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,692 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,692 - train - INFO - True
2024-04-02 10:44:57,693 - train - INFO - alphas:tensor([0.3175, 0.6825], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,694 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,694 - train - INFO - True
2024-04-02 10:44:57,700 - train - INFO - alphas:tensor([0.0960, 0.9040], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,700 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,701 - train - INFO - True
2024-04-02 10:44:57,702 - train - INFO - alphas:tensor([0.1331, 0.8669], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,702 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,717 - train - INFO - True
2024-04-02 10:44:57,718 - train - INFO - alphas:tensor([0.0451, 0.9549], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,721 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,721 - train - INFO - True
2024-04-02 10:44:57,722 - train - INFO - alphas:tensor([0.0145, 0.9855], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,723 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,736 - train - INFO - True
2024-04-02 10:44:57,737 - train - INFO - alphas:tensor([0.0011, 0.9989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,737 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,738 - train - INFO - True
2024-04-02 10:44:57,738 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:44:57,739 - train - INFO - tau:0.5471566423907612
2024-04-02 10:44:57,752 - train - INFO - avg block size:13.931034482758621
2024-04-02 10:44:59,668 - train - INFO - Test: [   0/39]  Time: 1.911 (1.911)  Loss:  0.4136 (0.4136)  Acc@1: 91.7969 (91.7969)  Acc@5: 100.0000 (100.0000)
2024-04-02 10:46:09,906 - train - INFO - Test: [  39/39]  Time: 1.793 (1.804)  Loss:  0.4397 (0.4020)  Acc@1: 81.2500 (91.5900)  Acc@5: 100.0000 (99.6400)
2024-04-02 10:46:13,506 - train - INFO - Train: 63 [   0/195 (  0%)]  Loss:  1.685883 (1.6859)  Time: 3.327s,   76.95/s  (3.327s,   76.95/s)  LR: 3.471e-04  Data: 0.329 (0.329)
2024-04-02 10:48:44,157 - train - INFO - Train: 63 [  50/195 ( 26%)]  Loss:  1.737751 (1.6673)  Time: 2.988s,   85.69/s  (3.019s,   84.79/s)  LR: 3.471e-04  Data: 0.010 (0.020)
2024-04-02 10:51:10,131 - train - INFO - Train: 63 [ 100/195 ( 52%)]  Loss:  1.765186 (1.6520)  Time: 3.176s,   80.62/s  (2.970s,   86.20/s)  LR: 3.471e-04  Data: 0.014 (0.019)
2024-04-02 10:53:39,590 - train - INFO - Train: 63 [ 150/195 ( 77%)]  Loss:  1.805593 (1.6594)  Time: 2.845s,   89.98/s  (2.976s,   86.02/s)  LR: 3.471e-04  Data: 0.023 (0.017)
2024-04-02 10:55:48,224 - train - INFO - Train: 63 [ 194/195 (100%)]  Loss:  1.839489 (1.6471)  Time: 2.936s,   87.18/s  (2.964s,   86.36/s)  LR: 3.471e-04  Data: 0.000 (0.016)
2024-04-02 10:55:48,225 - train - INFO - True
2024-04-02 10:55:48,227 - train - INFO - alphas:tensor([0.0089, 0.9911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,227 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,227 - train - INFO - True
2024-04-02 10:55:48,228 - train - INFO - alphas:tensor([0.0879, 0.9121], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,228 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,228 - train - INFO - True
2024-04-02 10:55:48,238 - train - INFO - alphas:tensor([0.5384, 0.4616], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,238 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,238 - train - INFO - True
2024-04-02 10:55:48,239 - train - INFO - alphas:tensor([0.4801, 0.5199], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,239 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,240 - train - INFO - True
2024-04-02 10:55:48,240 - train - INFO - alphas:tensor([0.1689, 0.8311], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,241 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,241 - train - INFO - True
2024-04-02 10:55:48,242 - train - INFO - alphas:tensor([0.2729, 0.7271], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,242 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,243 - train - INFO - True
2024-04-02 10:55:48,243 - train - INFO - alphas:tensor([0.5447, 0.4553], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,244 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,244 - train - INFO - True
2024-04-02 10:55:48,245 - train - INFO - alphas:tensor([0.4382, 0.5618], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,246 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,246 - train - INFO - True
2024-04-02 10:55:48,260 - train - INFO - alphas:tensor([0.2743, 0.7257], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,260 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,261 - train - INFO - True
2024-04-02 10:55:48,262 - train - INFO - alphas:tensor([0.4037, 0.5963], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,262 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,262 - train - INFO - True
2024-04-02 10:55:48,263 - train - INFO - alphas:tensor([0.5476, 0.4524], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,263 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,264 - train - INFO - True
2024-04-02 10:55:48,265 - train - INFO - alphas:tensor([0.4191, 0.5809], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,265 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,265 - train - INFO - True
2024-04-02 10:55:48,266 - train - INFO - alphas:tensor([0.2885, 0.7115], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,266 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,267 - train - INFO - True
2024-04-02 10:55:48,268 - train - INFO - alphas:tensor([0.4010, 0.5990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,268 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,268 - train - INFO - True
2024-04-02 10:55:48,269 - train - INFO - alphas:tensor([0.4878, 0.5122], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,269 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,270 - train - INFO - True
2024-04-02 10:55:48,270 - train - INFO - alphas:tensor([0.3447, 0.6553], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,271 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,271 - train - INFO - True
2024-04-02 10:55:48,272 - train - INFO - alphas:tensor([0.2540, 0.7460], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,272 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,277 - train - INFO - True
2024-04-02 10:55:48,278 - train - INFO - alphas:tensor([0.3043, 0.6957], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,278 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,278 - train - INFO - True
2024-04-02 10:55:48,279 - train - INFO - alphas:tensor([0.3606, 0.6394], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,280 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,280 - train - INFO - True
2024-04-02 10:55:48,281 - train - INFO - alphas:tensor([0.1789, 0.8211], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,281 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,281 - train - INFO - True
2024-04-02 10:55:48,282 - train - INFO - alphas:tensor([0.1974, 0.8026], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,283 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,283 - train - INFO - True
2024-04-02 10:55:48,284 - train - INFO - alphas:tensor([0.2348, 0.7652], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,284 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,284 - train - INFO - True
2024-04-02 10:55:48,285 - train - INFO - alphas:tensor([0.3143, 0.6857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,286 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,286 - train - INFO - True
2024-04-02 10:55:48,287 - train - INFO - alphas:tensor([0.0923, 0.9077], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,287 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,287 - train - INFO - True
2024-04-02 10:55:48,288 - train - INFO - alphas:tensor([0.1306, 0.8694], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,289 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,303 - train - INFO - True
2024-04-02 10:55:48,304 - train - INFO - alphas:tensor([0.0416, 0.9584], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,304 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,304 - train - INFO - True
2024-04-02 10:55:48,305 - train - INFO - alphas:tensor([0.0129, 0.9871], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,306 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,306 - train - INFO - True
2024-04-02 10:55:48,307 - train - INFO - alphas:tensor([9.3303e-04, 9.9907e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,307 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,307 - train - INFO - True
2024-04-02 10:55:48,308 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 10:55:48,308 - train - INFO - tau:0.5416850759668536
2024-04-02 10:55:48,308 - train - INFO - avg block size:13.931034482758621
2024-04-02 10:55:50,108 - train - INFO - Test: [   0/39]  Time: 1.797 (1.797)  Loss:  0.4053 (0.4053)  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)
2024-04-02 10:57:00,350 - train - INFO - Test: [  39/39]  Time: 1.716 (1.801)  Loss:  0.4763 (0.3837)  Acc@1: 87.5000 (91.8900)  Acc@5: 100.0000 (99.6500)
2024-04-02 10:57:03,939 - train - INFO - Train: 64 [   0/195 (  0%)]  Loss:  1.427941 (1.4279)  Time: 3.268s,   78.33/s  (3.268s,   78.33/s)  LR: 3.417e-04  Data: 0.361 (0.361)
2024-04-02 10:59:30,845 - train - INFO - Train: 64 [  50/195 ( 26%)]  Loss:  1.600353 (1.5837)  Time: 3.379s,   75.77/s  (2.944s,   86.94/s)  LR: 3.417e-04  Data: 0.009 (0.022)
2024-04-02 11:02:01,714 - train - INFO - Train: 64 [ 100/195 ( 52%)]  Loss:  1.339480 (1.6024)  Time: 2.681s,   95.49/s  (2.980s,   85.89/s)  LR: 3.417e-04  Data: 0.006 (0.019)
2024-04-02 11:04:31,134 - train - INFO - Train: 64 [ 150/195 ( 77%)]  Loss:  1.683263 (1.5998)  Time: 2.489s,  102.84/s  (2.983s,   85.82/s)  LR: 3.417e-04  Data: 0.028 (0.019)
2024-04-02 11:06:44,329 - train - INFO - Train: 64 [ 194/195 (100%)]  Loss:  1.296101 (1.6002)  Time: 3.071s,   83.36/s  (2.993s,   85.53/s)  LR: 3.417e-04  Data: 0.000 (0.018)
2024-04-02 11:06:44,330 - train - INFO - True
2024-04-02 11:06:44,337 - train - INFO - alphas:tensor([0.0081, 0.9919], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,337 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,337 - train - INFO - True
2024-04-02 11:06:44,338 - train - INFO - alphas:tensor([0.0881, 0.9119], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,339 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,339 - train - INFO - True
2024-04-02 11:06:44,340 - train - INFO - alphas:tensor([0.5370, 0.4630], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,340 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,340 - train - INFO - True
2024-04-02 11:06:44,341 - train - INFO - alphas:tensor([0.4799, 0.5201], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,344 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,344 - train - INFO - True
2024-04-02 11:06:44,345 - train - INFO - alphas:tensor([0.1652, 0.8348], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,345 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,345 - train - INFO - True
2024-04-02 11:06:44,346 - train - INFO - alphas:tensor([0.2705, 0.7295], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,346 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,347 - train - INFO - True
2024-04-02 11:06:44,347 - train - INFO - alphas:tensor([0.5443, 0.4557], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,348 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,348 - train - INFO - True
2024-04-02 11:06:44,349 - train - INFO - alphas:tensor([0.4389, 0.5611], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,349 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,349 - train - INFO - True
2024-04-02 11:06:44,350 - train - INFO - alphas:tensor([0.2737, 0.7263], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,350 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,351 - train - INFO - True
2024-04-02 11:06:44,351 - train - INFO - alphas:tensor([0.4034, 0.5966], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,352 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,352 - train - INFO - True
2024-04-02 11:06:44,353 - train - INFO - alphas:tensor([0.5461, 0.4539], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,353 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,353 - train - INFO - True
2024-04-02 11:06:44,354 - train - INFO - alphas:tensor([0.4178, 0.5822], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,354 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,354 - train - INFO - True
2024-04-02 11:06:44,355 - train - INFO - alphas:tensor([0.2868, 0.7132], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,356 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,356 - train - INFO - True
2024-04-02 11:06:44,357 - train - INFO - alphas:tensor([0.3990, 0.6010], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,357 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,357 - train - INFO - True
2024-04-02 11:06:44,358 - train - INFO - alphas:tensor([0.4860, 0.5140], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,358 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,358 - train - INFO - True
2024-04-02 11:06:44,359 - train - INFO - alphas:tensor([0.3424, 0.6576], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,359 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,360 - train - INFO - True
2024-04-02 11:06:44,360 - train - INFO - alphas:tensor([0.2528, 0.7472], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,361 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,361 - train - INFO - True
2024-04-02 11:06:44,362 - train - INFO - alphas:tensor([0.3041, 0.6959], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,362 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,362 - train - INFO - True
2024-04-02 11:06:44,367 - train - INFO - alphas:tensor([0.3558, 0.6442], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,368 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,368 - train - INFO - True
2024-04-02 11:06:44,369 - train - INFO - alphas:tensor([0.1761, 0.8239], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,369 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,369 - train - INFO - True
2024-04-02 11:06:44,370 - train - INFO - alphas:tensor([0.1963, 0.8037], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,371 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,371 - train - INFO - True
2024-04-02 11:06:44,372 - train - INFO - alphas:tensor([0.2333, 0.7667], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,372 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,372 - train - INFO - True
2024-04-02 11:06:44,373 - train - INFO - alphas:tensor([0.3112, 0.6888], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,373 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,373 - train - INFO - True
2024-04-02 11:06:44,374 - train - INFO - alphas:tensor([0.0887, 0.9113], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,375 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,375 - train - INFO - True
2024-04-02 11:06:44,376 - train - INFO - alphas:tensor([0.1291, 0.8709], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,376 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,377 - train - INFO - True
2024-04-02 11:06:44,378 - train - INFO - alphas:tensor([0.0385, 0.9615], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,378 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,378 - train - INFO - True
2024-04-02 11:06:44,379 - train - INFO - alphas:tensor([0.0117, 0.9883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,379 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,379 - train - INFO - True
2024-04-02 11:06:44,380 - train - INFO - alphas:tensor([8.2393e-04, 9.9918e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,380 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,380 - train - INFO - True
2024-04-02 11:06:44,381 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:06:44,382 - train - INFO - tau:0.536268225207185
2024-04-02 11:06:44,382 - train - INFO - avg block size:13.931034482758621
2024-04-02 11:06:46,246 - train - INFO - Test: [   0/39]  Time: 1.856 (1.856)  Loss:  0.4048 (0.4048)  Acc@1: 90.6250 (90.6250)  Acc@5: 99.6094 (99.6094)
2024-04-02 11:07:58,689 - train - INFO - Test: [  39/39]  Time: 1.852 (1.857)  Loss:  0.4507 (0.4007)  Acc@1: 81.2500 (91.6400)  Acc@5: 100.0000 (99.7400)
2024-04-02 11:08:02,746 - train - INFO - Train: 65 [   0/195 (  0%)]  Loss:  1.314731 (1.3147)  Time: 3.641s,   70.32/s  (3.641s,   70.32/s)  LR: 3.361e-04  Data: 0.260 (0.260)
2024-04-02 11:10:36,234 - train - INFO - Train: 65 [  50/195 ( 26%)]  Loss:  1.672035 (1.6399)  Time: 2.722s,   94.05/s  (3.081s,   83.09/s)  LR: 3.361e-04  Data: 0.010 (0.021)
2024-04-02 11:13:05,205 - train - INFO - Train: 65 [ 100/195 ( 52%)]  Loss:  1.803593 (1.6652)  Time: 3.235s,   79.12/s  (3.030s,   84.47/s)  LR: 3.361e-04  Data: 0.006 (0.019)
2024-04-02 11:15:33,419 - train - INFO - Train: 65 [ 150/195 ( 77%)]  Loss:  1.828239 (1.6622)  Time: 2.956s,   86.60/s  (3.009s,   85.09/s)  LR: 3.361e-04  Data: 0.039 (0.018)
2024-04-02 11:17:47,620 - train - INFO - Train: 65 [ 194/195 (100%)]  Loss:  1.829202 (1.6467)  Time: 2.792s,   91.69/s  (3.018s,   84.83/s)  LR: 3.361e-04  Data: 0.000 (0.017)
2024-04-02 11:17:47,621 - train - INFO - True
2024-04-02 11:17:47,622 - train - INFO - alphas:tensor([0.0074, 0.9926], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,622 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,622 - train - INFO - True
2024-04-02 11:17:47,623 - train - INFO - alphas:tensor([0.0870, 0.9130], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,623 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,624 - train - INFO - True
2024-04-02 11:17:47,624 - train - INFO - alphas:tensor([0.5359, 0.4641], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,625 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,625 - train - INFO - True
2024-04-02 11:17:47,626 - train - INFO - alphas:tensor([0.4769, 0.5231], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,626 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,626 - train - INFO - True
2024-04-02 11:17:47,627 - train - INFO - alphas:tensor([0.1643, 0.8357], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,627 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,628 - train - INFO - True
2024-04-02 11:17:47,628 - train - INFO - alphas:tensor([0.2673, 0.7327], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,629 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,629 - train - INFO - True
2024-04-02 11:17:47,630 - train - INFO - alphas:tensor([0.5419, 0.4581], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,630 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,630 - train - INFO - True
2024-04-02 11:17:47,631 - train - INFO - alphas:tensor([0.4380, 0.5620], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,631 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,632 - train - INFO - True
2024-04-02 11:17:47,633 - train - INFO - alphas:tensor([0.2705, 0.7295], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,633 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,633 - train - INFO - True
2024-04-02 11:17:47,634 - train - INFO - alphas:tensor([0.4026, 0.5974], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,634 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,634 - train - INFO - True
2024-04-02 11:17:47,635 - train - INFO - alphas:tensor([0.5454, 0.4546], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,636 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,636 - train - INFO - True
2024-04-02 11:17:47,637 - train - INFO - alphas:tensor([0.4167, 0.5833], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,637 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,637 - train - INFO - True
2024-04-02 11:17:47,638 - train - INFO - alphas:tensor([0.2855, 0.7145], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,638 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,638 - train - INFO - True
2024-04-02 11:17:47,639 - train - INFO - alphas:tensor([0.3923, 0.6077], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,639 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,640 - train - INFO - True
2024-04-02 11:17:47,640 - train - INFO - alphas:tensor([0.4829, 0.5171], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,641 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,642 - train - INFO - True
2024-04-02 11:17:47,642 - train - INFO - alphas:tensor([0.3377, 0.6623], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,643 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,643 - train - INFO - True
2024-04-02 11:17:47,644 - train - INFO - alphas:tensor([0.2527, 0.7473], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,644 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,644 - train - INFO - True
2024-04-02 11:17:47,645 - train - INFO - alphas:tensor([0.3021, 0.6979], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,645 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,645 - train - INFO - True
2024-04-02 11:17:47,646 - train - INFO - alphas:tensor([0.3562, 0.6438], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,647 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,647 - train - INFO - True
2024-04-02 11:17:47,648 - train - INFO - alphas:tensor([0.1753, 0.8247], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,648 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,648 - train - INFO - True
2024-04-02 11:17:47,649 - train - INFO - alphas:tensor([0.1952, 0.8048], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,649 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,649 - train - INFO - True
2024-04-02 11:17:47,650 - train - INFO - alphas:tensor([0.2307, 0.7693], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,650 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,651 - train - INFO - True
2024-04-02 11:17:47,651 - train - INFO - alphas:tensor([0.3060, 0.6940], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,652 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,652 - train - INFO - True
2024-04-02 11:17:47,653 - train - INFO - alphas:tensor([0.0843, 0.9157], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,653 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,653 - train - INFO - True
2024-04-02 11:17:47,654 - train - INFO - alphas:tensor([0.1263, 0.8737], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,654 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,665 - train - INFO - True
2024-04-02 11:17:47,666 - train - INFO - alphas:tensor([0.0356, 0.9644], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,666 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,667 - train - INFO - True
2024-04-02 11:17:47,667 - train - INFO - alphas:tensor([0.0104, 0.9896], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,668 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,668 - train - INFO - True
2024-04-02 11:17:47,669 - train - INFO - alphas:tensor([7.2631e-04, 9.9927e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,669 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,669 - train - INFO - True
2024-04-02 11:17:47,670 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:17:47,670 - train - INFO - tau:0.5309055429551132
2024-04-02 11:17:47,670 - train - INFO - avg block size:13.931034482758621
2024-04-02 11:17:49,651 - train - INFO - Test: [   0/39]  Time: 1.978 (1.978)  Loss:  0.3923 (0.3923)  Acc@1: 90.2344 (90.2344)  Acc@5: 100.0000 (100.0000)
2024-04-02 11:19:02,727 - train - INFO - Test: [  39/39]  Time: 1.819 (1.876)  Loss:  0.4207 (0.3859)  Acc@1: 87.5000 (91.4600)  Acc@5: 100.0000 (99.7200)
2024-04-02 11:19:06,132 - train - INFO - Train: 66 [   0/195 (  0%)]  Loss:  1.854795 (1.8548)  Time: 3.221s,   79.49/s  (3.221s,   79.49/s)  LR: 3.306e-04  Data: 0.255 (0.255)
2024-04-02 11:21:35,719 - train - INFO - Train: 66 [  50/195 ( 26%)]  Loss:  1.252215 (1.6278)  Time: 3.100s,   82.57/s  (2.996s,   85.44/s)  LR: 3.306e-04  Data: 0.019 (0.018)
2024-04-02 11:24:03,137 - train - INFO - Train: 66 [ 100/195 ( 52%)]  Loss:  1.261333 (1.5972)  Time: 2.810s,   91.12/s  (2.972s,   86.12/s)  LR: 3.306e-04  Data: 0.014 (0.016)
2024-04-02 11:26:34,145 - train - INFO - Train: 66 [ 150/195 ( 77%)]  Loss:  1.311096 (1.5930)  Time: 2.831s,   90.44/s  (2.988s,   85.67/s)  LR: 3.306e-04  Data: 0.009 (0.016)
2024-04-02 11:28:45,057 - train - INFO - Train: 66 [ 194/195 (100%)]  Loss:  1.857258 (1.5883)  Time: 3.013s,   84.95/s  (2.985s,   85.75/s)  LR: 3.306e-04  Data: 0.000 (0.016)
2024-04-02 11:28:45,058 - train - INFO - True
2024-04-02 11:28:45,059 - train - INFO - alphas:tensor([0.0067, 0.9933], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,059 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,073 - train - INFO - True
2024-04-02 11:28:45,074 - train - INFO - alphas:tensor([0.0862, 0.9138], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,074 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,074 - train - INFO - True
2024-04-02 11:28:45,075 - train - INFO - alphas:tensor([0.5353, 0.4647], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,075 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,076 - train - INFO - True
2024-04-02 11:28:45,076 - train - INFO - alphas:tensor([0.4759, 0.5241], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,077 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,077 - train - INFO - True
2024-04-02 11:28:45,078 - train - INFO - alphas:tensor([0.1616, 0.8384], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,078 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,078 - train - INFO - True
2024-04-02 11:28:45,079 - train - INFO - alphas:tensor([0.2634, 0.7366], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,079 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,079 - train - INFO - True
2024-04-02 11:28:45,080 - train - INFO - alphas:tensor([0.5418, 0.4582], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,080 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,081 - train - INFO - True
2024-04-02 11:28:45,081 - train - INFO - alphas:tensor([0.4376, 0.5624], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,082 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,082 - train - INFO - True
2024-04-02 11:28:45,083 - train - INFO - alphas:tensor([0.2670, 0.7330], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,083 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,083 - train - INFO - True
2024-04-02 11:28:45,084 - train - INFO - alphas:tensor([0.3983, 0.6017], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,084 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,084 - train - INFO - True
2024-04-02 11:28:45,085 - train - INFO - alphas:tensor([0.5440, 0.4560], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,085 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,086 - train - INFO - True
2024-04-02 11:28:45,086 - train - INFO - alphas:tensor([0.4183, 0.5817], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,087 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,087 - train - INFO - True
2024-04-02 11:28:45,088 - train - INFO - alphas:tensor([0.2827, 0.7173], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,088 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,088 - train - INFO - True
2024-04-02 11:28:45,089 - train - INFO - alphas:tensor([0.3913, 0.6087], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,089 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,089 - train - INFO - True
2024-04-02 11:28:45,090 - train - INFO - alphas:tensor([0.4831, 0.5169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,091 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,091 - train - INFO - True
2024-04-02 11:28:45,092 - train - INFO - alphas:tensor([0.3412, 0.6588], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,092 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,092 - train - INFO - True
2024-04-02 11:28:45,093 - train - INFO - alphas:tensor([0.2490, 0.7510], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,093 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,093 - train - INFO - True
2024-04-02 11:28:45,094 - train - INFO - alphas:tensor([0.2974, 0.7026], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,094 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,095 - train - INFO - True
2024-04-02 11:28:45,095 - train - INFO - alphas:tensor([0.3544, 0.6456], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,096 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,099 - train - INFO - True
2024-04-02 11:28:45,139 - train - INFO - alphas:tensor([0.1740, 0.8260], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,139 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,140 - train - INFO - True
2024-04-02 11:28:45,140 - train - INFO - alphas:tensor([0.1932, 0.8068], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,141 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,141 - train - INFO - True
2024-04-02 11:28:45,142 - train - INFO - alphas:tensor([0.2298, 0.7702], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,142 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,142 - train - INFO - True
2024-04-02 11:28:45,143 - train - INFO - alphas:tensor([0.3042, 0.6958], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,143 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,143 - train - INFO - True
2024-04-02 11:28:45,144 - train - INFO - alphas:tensor([0.0811, 0.9189], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,144 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,144 - train - INFO - True
2024-04-02 11:28:45,145 - train - INFO - alphas:tensor([0.1238, 0.8762], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,146 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,146 - train - INFO - True
2024-04-02 11:28:45,147 - train - INFO - alphas:tensor([0.0326, 0.9674], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,147 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,160 - train - INFO - True
2024-04-02 11:28:45,165 - train - INFO - alphas:tensor([0.0093, 0.9907], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,166 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,166 - train - INFO - True
2024-04-02 11:28:45,167 - train - INFO - alphas:tensor([6.4111e-04, 9.9936e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,167 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,167 - train - INFO - True
2024-04-02 11:28:45,168 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:28:45,168 - train - INFO - tau:0.525596487525562
2024-04-02 11:28:45,168 - train - INFO - avg block size:13.931034482758621
2024-04-02 11:28:47,025 - train - INFO - Test: [   0/39]  Time: 1.839 (1.839)  Loss:  0.4221 (0.4221)  Acc@1: 91.0156 (91.0156)  Acc@5: 99.6094 (99.6094)
2024-04-02 11:29:59,099 - train - INFO - Test: [  39/39]  Time: 1.796 (1.848)  Loss:  0.5029 (0.3929)  Acc@1: 81.2500 (91.4000)  Acc@5: 100.0000 (99.6400)
2024-04-02 11:30:02,588 - train - INFO - Train: 67 [   0/195 (  0%)]  Loss:  1.536413 (1.5364)  Time: 3.122s,   81.99/s  (3.122s,   81.99/s)  LR: 3.250e-04  Data: 0.334 (0.334)
2024-04-02 11:32:28,373 - train - INFO - Train: 67 [  50/195 ( 26%)]  Loss:  1.680189 (1.6300)  Time: 3.109s,   82.34/s  (2.920s,   87.68/s)  LR: 3.250e-04  Data: 0.005 (0.021)
2024-04-02 11:34:57,449 - train - INFO - Train: 67 [ 100/195 ( 52%)]  Loss:  1.931141 (1.6076)  Time: 2.983s,   85.82/s  (2.950s,   86.77/s)  LR: 3.250e-04  Data: 0.023 (0.018)
2024-04-02 11:37:28,988 - train - INFO - Train: 67 [ 150/195 ( 77%)]  Loss:  1.279251 (1.6180)  Time: 3.513s,   72.87/s  (2.977s,   86.00/s)  LR: 3.250e-04  Data: 0.010 (0.017)
2024-04-02 11:39:37,559 - train - INFO - Train: 67 [ 194/195 (100%)]  Loss:  1.835998 (1.6117)  Time: 2.793s,   91.66/s  (2.965s,   86.35/s)  LR: 3.250e-04  Data: 0.000 (0.016)
2024-04-02 11:39:37,565 - train - INFO - True
2024-04-02 11:39:37,575 - train - INFO - alphas:tensor([0.0061, 0.9939], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,575 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,575 - train - INFO - True
2024-04-02 11:39:37,576 - train - INFO - alphas:tensor([0.0849, 0.9151], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,576 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,577 - train - INFO - True
2024-04-02 11:39:37,577 - train - INFO - alphas:tensor([0.5355, 0.4645], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,578 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,578 - train - INFO - True
2024-04-02 11:39:37,579 - train - INFO - alphas:tensor([0.4761, 0.5239], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,579 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,579 - train - INFO - True
2024-04-02 11:39:37,584 - train - INFO - alphas:tensor([0.1602, 0.8398], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,584 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,585 - train - INFO - True
2024-04-02 11:39:37,585 - train - INFO - alphas:tensor([0.2634, 0.7366], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,586 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,586 - train - INFO - True
2024-04-02 11:39:37,587 - train - INFO - alphas:tensor([0.5398, 0.4602], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,588 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,588 - train - INFO - True
2024-04-02 11:39:37,589 - train - INFO - alphas:tensor([0.4337, 0.5663], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,589 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,589 - train - INFO - True
2024-04-02 11:39:37,590 - train - INFO - alphas:tensor([0.2677, 0.7323], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,590 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,590 - train - INFO - True
2024-04-02 11:39:37,591 - train - INFO - alphas:tensor([0.4001, 0.5999], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,591 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,592 - train - INFO - True
2024-04-02 11:39:37,606 - train - INFO - alphas:tensor([0.5419, 0.4581], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,606 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,606 - train - INFO - True
2024-04-02 11:39:37,607 - train - INFO - alphas:tensor([0.4141, 0.5859], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,607 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,607 - train - INFO - True
2024-04-02 11:39:37,608 - train - INFO - alphas:tensor([0.2798, 0.7202], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,609 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,609 - train - INFO - True
2024-04-02 11:39:37,610 - train - INFO - alphas:tensor([0.3872, 0.6128], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,610 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,610 - train - INFO - True
2024-04-02 11:39:37,611 - train - INFO - alphas:tensor([0.4810, 0.5190], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,611 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,611 - train - INFO - True
2024-04-02 11:39:37,612 - train - INFO - alphas:tensor([0.3393, 0.6607], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,612 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,613 - train - INFO - True
2024-04-02 11:39:37,613 - train - INFO - alphas:tensor([0.2486, 0.7514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,614 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,614 - train - INFO - True
2024-04-02 11:39:37,615 - train - INFO - alphas:tensor([0.2979, 0.7021], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,615 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,615 - train - INFO - True
2024-04-02 11:39:37,616 - train - INFO - alphas:tensor([0.3510, 0.6490], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,616 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,616 - train - INFO - True
2024-04-02 11:39:37,617 - train - INFO - alphas:tensor([0.1702, 0.8298], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,618 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,618 - train - INFO - True
2024-04-02 11:39:37,619 - train - INFO - alphas:tensor([0.1903, 0.8097], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,619 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,619 - train - INFO - True
2024-04-02 11:39:37,620 - train - INFO - alphas:tensor([0.2284, 0.7716], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,620 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,620 - train - INFO - True
2024-04-02 11:39:37,621 - train - INFO - alphas:tensor([0.3012, 0.6988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,621 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,622 - train - INFO - True
2024-04-02 11:39:37,631 - train - INFO - alphas:tensor([0.0776, 0.9224], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,631 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,632 - train - INFO - True
2024-04-02 11:39:37,632 - train - INFO - alphas:tensor([0.1220, 0.8780], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,633 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,633 - train - INFO - True
2024-04-02 11:39:37,634 - train - INFO - alphas:tensor([0.0300, 0.9700], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,634 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,634 - train - INFO - True
2024-04-02 11:39:37,635 - train - INFO - alphas:tensor([0.0084, 0.9916], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,635 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,636 - train - INFO - True
2024-04-02 11:39:37,637 - train - INFO - alphas:tensor([5.6586e-04, 9.9943e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,637 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,637 - train - INFO - True
2024-04-02 11:39:37,638 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:39:37,638 - train - INFO - tau:0.5203405226503064
2024-04-02 11:39:37,639 - train - INFO - avg block size:13.931034482758621
2024-04-02 11:39:39,576 - train - INFO - Test: [   0/39]  Time: 1.934 (1.934)  Loss:  0.4268 (0.4268)  Acc@1: 90.2344 (90.2344)  Acc@5: 99.6094 (99.6094)
2024-04-02 11:40:52,871 - train - INFO - Test: [  39/39]  Time: 1.829 (1.881)  Loss:  0.4934 (0.4012)  Acc@1: 81.2500 (91.3600)  Acc@5: 100.0000 (99.7000)
2024-04-02 11:40:56,869 - train - INFO - Train: 68 [   0/195 (  0%)]  Loss:  1.678733 (1.6787)  Time: 3.665s,   69.86/s  (3.665s,   69.86/s)  LR: 3.194e-04  Data: 0.324 (0.324)
2024-04-02 11:43:28,738 - train - INFO - Train: 68 [  50/195 ( 26%)]  Loss:  1.259454 (1.6153)  Time: 3.307s,   77.41/s  (3.050s,   83.95/s)  LR: 3.194e-04  Data: 0.015 (0.021)
2024-04-02 11:45:57,001 - train - INFO - Train: 68 [ 100/195 ( 52%)]  Loss:  1.378976 (1.6194)  Time: 3.004s,   85.22/s  (3.008s,   85.11/s)  LR: 3.194e-04  Data: 0.012 (0.018)
2024-04-02 11:48:28,280 - train - INFO - Train: 68 [ 150/195 ( 77%)]  Loss:  1.732260 (1.6231)  Time: 3.311s,   77.31/s  (3.014s,   84.95/s)  LR: 3.194e-04  Data: 0.014 (0.018)
2024-04-02 11:50:39,364 - train - INFO - Train: 68 [ 194/195 (100%)]  Loss:  1.667897 (1.6193)  Time: 2.948s,   86.84/s  (3.006s,   85.17/s)  LR: 3.194e-04  Data: 0.000 (0.017)
2024-04-02 11:50:39,365 - train - INFO - True
2024-04-02 11:50:39,371 - train - INFO - alphas:tensor([0.0055, 0.9945], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,376 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,376 - train - INFO - True
2024-04-02 11:50:39,377 - train - INFO - alphas:tensor([0.0827, 0.9173], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,377 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,377 - train - INFO - True
2024-04-02 11:50:39,378 - train - INFO - alphas:tensor([0.5328, 0.4672], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,378 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,378 - train - INFO - True
2024-04-02 11:50:39,379 - train - INFO - alphas:tensor([0.4728, 0.5272], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,380 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,380 - train - INFO - True
2024-04-02 11:50:39,381 - train - INFO - alphas:tensor([0.1583, 0.8417], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,381 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,381 - train - INFO - True
2024-04-02 11:50:39,382 - train - INFO - alphas:tensor([0.2629, 0.7371], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,383 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,383 - train - INFO - True
2024-04-02 11:50:39,384 - train - INFO - alphas:tensor([0.5375, 0.4625], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,385 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,385 - train - INFO - True
2024-04-02 11:50:39,386 - train - INFO - alphas:tensor([0.4304, 0.5696], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,386 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,386 - train - INFO - True
2024-04-02 11:50:39,387 - train - INFO - alphas:tensor([0.2642, 0.7358], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,387 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,387 - train - INFO - True
2024-04-02 11:50:39,388 - train - INFO - alphas:tensor([0.3974, 0.6026], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,388 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,389 - train - INFO - True
2024-04-02 11:50:39,389 - train - INFO - alphas:tensor([0.5420, 0.4580], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,390 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,390 - train - INFO - True
2024-04-02 11:50:39,391 - train - INFO - alphas:tensor([0.4152, 0.5848], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,391 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,391 - train - INFO - True
2024-04-02 11:50:39,392 - train - INFO - alphas:tensor([0.2796, 0.7204], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,392 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,392 - train - INFO - True
2024-04-02 11:50:39,393 - train - INFO - alphas:tensor([0.3858, 0.6142], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,394 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,394 - train - INFO - True
2024-04-02 11:50:39,395 - train - INFO - alphas:tensor([0.4803, 0.5197], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,395 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,395 - train - INFO - True
2024-04-02 11:50:39,396 - train - INFO - alphas:tensor([0.3380, 0.6620], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,396 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,396 - train - INFO - True
2024-04-02 11:50:39,397 - train - INFO - alphas:tensor([0.2465, 0.7535], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,397 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,398 - train - INFO - True
2024-04-02 11:50:39,398 - train - INFO - alphas:tensor([0.2974, 0.7026], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,399 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,399 - train - INFO - True
2024-04-02 11:50:39,400 - train - INFO - alphas:tensor([0.3485, 0.6515], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,400 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,400 - train - INFO - True
2024-04-02 11:50:39,401 - train - INFO - alphas:tensor([0.1683, 0.8317], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,401 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,401 - train - INFO - True
2024-04-02 11:50:39,407 - train - INFO - alphas:tensor([0.1885, 0.8115], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,407 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,407 - train - INFO - True
2024-04-02 11:50:39,408 - train - INFO - alphas:tensor([0.2250, 0.7750], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,408 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,408 - train - INFO - True
2024-04-02 11:50:39,409 - train - INFO - alphas:tensor([0.2986, 0.7014], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,409 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,410 - train - INFO - True
2024-04-02 11:50:39,410 - train - INFO - alphas:tensor([0.0736, 0.9264], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,411 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,411 - train - INFO - True
2024-04-02 11:50:39,416 - train - INFO - alphas:tensor([0.1199, 0.8801], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,416 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,417 - train - INFO - True
2024-04-02 11:50:39,417 - train - INFO - alphas:tensor([0.0274, 0.9726], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,418 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,418 - train - INFO - True
2024-04-02 11:50:39,419 - train - INFO - alphas:tensor([0.0075, 0.9925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,419 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,419 - train - INFO - True
2024-04-02 11:50:39,420 - train - INFO - alphas:tensor([4.9907e-04, 9.9950e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,420 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,420 - train - INFO - True
2024-04-02 11:50:39,421 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 11:50:39,421 - train - INFO - tau:0.5151371174238033
2024-04-02 11:50:39,421 - train - INFO - avg block size:13.931034482758621
2024-04-02 11:50:41,449 - train - INFO - Test: [   0/39]  Time: 2.023 (2.023)  Loss:  0.4106 (0.4106)  Acc@1: 90.2344 (90.2344)  Acc@5: 100.0000 (100.0000)
2024-04-02 11:51:54,464 - train - INFO - Test: [  39/39]  Time: 1.906 (1.876)  Loss:  0.5005 (0.3926)  Acc@1: 81.2500 (91.5200)  Acc@5: 100.0000 (99.7100)
2024-04-02 11:51:58,136 - train - INFO - Train: 69 [   0/195 (  0%)]  Loss:  1.491298 (1.4913)  Time: 3.296s,   77.68/s  (3.296s,   77.68/s)  LR: 3.138e-04  Data: 0.349 (0.349)
2024-04-02 11:54:30,108 - train - INFO - Train: 69 [  50/195 ( 26%)]  Loss:  1.324002 (1.6375)  Time: 2.661s,   96.19/s  (3.044s,   84.09/s)  LR: 3.138e-04  Data: 0.031 (0.023)
2024-04-02 11:56:59,319 - train - INFO - Train: 69 [ 100/195 ( 52%)]  Loss:  1.651283 (1.6133)  Time: 3.172s,   80.71/s  (3.015s,   84.92/s)  LR: 3.138e-04  Data: 0.005 (0.019)
2024-04-02 11:59:27,658 - train - INFO - Train: 69 [ 150/195 ( 77%)]  Loss:  1.845012 (1.6282)  Time: 3.076s,   83.22/s  (2.999s,   85.37/s)  LR: 3.138e-04  Data: 0.011 (0.018)
2024-04-02 12:01:37,032 - train - INFO - Train: 69 [ 194/195 (100%)]  Loss:  1.823209 (1.6347)  Time: 2.932s,   87.33/s  (2.986s,   85.75/s)  LR: 3.138e-04  Data: 0.000 (0.018)
2024-04-02 12:01:37,033 - train - INFO - True
2024-04-02 12:01:37,048 - train - INFO - alphas:tensor([0.0049, 0.9951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,049 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,049 - train - INFO - True
2024-04-02 12:01:37,050 - train - INFO - alphas:tensor([0.0824, 0.9176], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,050 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,050 - train - INFO - True
2024-04-02 12:01:37,051 - train - INFO - alphas:tensor([0.5316, 0.4684], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,051 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,051 - train - INFO - True
2024-04-02 12:01:37,052 - train - INFO - alphas:tensor([0.4706, 0.5294], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,053 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,053 - train - INFO - True
2024-04-02 12:01:37,054 - train - INFO - alphas:tensor([0.1550, 0.8450], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,054 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,054 - train - INFO - True
2024-04-02 12:01:37,055 - train - INFO - alphas:tensor([0.2589, 0.7411], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,064 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,065 - train - INFO - True
2024-04-02 12:01:37,065 - train - INFO - alphas:tensor([0.5355, 0.4645], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,066 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,066 - train - INFO - True
2024-04-02 12:01:37,067 - train - INFO - alphas:tensor([0.4308, 0.5692], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,067 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,080 - train - INFO - True
2024-04-02 12:01:37,081 - train - INFO - alphas:tensor([0.2631, 0.7369], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,081 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,082 - train - INFO - True
2024-04-02 12:01:37,082 - train - INFO - alphas:tensor([0.3944, 0.6056], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,083 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,083 - train - INFO - True
2024-04-02 12:01:37,084 - train - INFO - alphas:tensor([0.5404, 0.4596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,084 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,084 - train - INFO - True
2024-04-02 12:01:37,085 - train - INFO - alphas:tensor([0.4125, 0.5875], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,085 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,085 - train - INFO - True
2024-04-02 12:01:37,086 - train - INFO - alphas:tensor([0.2763, 0.7237], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,086 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,087 - train - INFO - True
2024-04-02 12:01:37,087 - train - INFO - alphas:tensor([0.3836, 0.6164], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,088 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,088 - train - INFO - True
2024-04-02 12:01:37,089 - train - INFO - alphas:tensor([0.4787, 0.5213], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,089 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,089 - train - INFO - True
2024-04-02 12:01:37,090 - train - INFO - alphas:tensor([0.3337, 0.6663], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,090 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,090 - train - INFO - True
2024-04-02 12:01:37,091 - train - INFO - alphas:tensor([0.2448, 0.7552], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,091 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,092 - train - INFO - True
2024-04-02 12:01:37,092 - train - INFO - alphas:tensor([0.2935, 0.7065], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,093 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,093 - train - INFO - True
2024-04-02 12:01:37,098 - train - INFO - alphas:tensor([0.3462, 0.6538], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,098 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,099 - train - INFO - True
2024-04-02 12:01:37,099 - train - INFO - alphas:tensor([0.1645, 0.8355], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,100 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,100 - train - INFO - True
2024-04-02 12:01:37,101 - train - INFO - alphas:tensor([0.1869, 0.8131], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,101 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,101 - train - INFO - True
2024-04-02 12:01:37,102 - train - INFO - alphas:tensor([0.2217, 0.7783], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,102 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,102 - train - INFO - True
2024-04-02 12:01:37,103 - train - INFO - alphas:tensor([0.2957, 0.7043], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,103 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,104 - train - INFO - True
2024-04-02 12:01:37,104 - train - INFO - alphas:tensor([0.0703, 0.9297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,113 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,114 - train - INFO - True
2024-04-02 12:01:37,114 - train - INFO - alphas:tensor([0.1180, 0.8820], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,115 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,115 - train - INFO - True
2024-04-02 12:01:37,116 - train - INFO - alphas:tensor([0.0253, 0.9747], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,116 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,116 - train - INFO - True
2024-04-02 12:01:37,117 - train - INFO - alphas:tensor([0.0067, 0.9933], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,117 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,118 - train - INFO - True
2024-04-02 12:01:37,118 - train - INFO - alphas:tensor([4.4041e-04, 9.9956e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,119 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,119 - train - INFO - True
2024-04-02 12:01:37,120 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:01:37,120 - train - INFO - tau:0.5099857462495653
2024-04-02 12:01:37,120 - train - INFO - avg block size:13.931034482758621
2024-04-02 12:01:39,103 - train - INFO - Test: [   0/39]  Time: 1.980 (1.980)  Loss:  0.3745 (0.3745)  Acc@1: 91.4062 (91.4062)  Acc@5: 100.0000 (100.0000)
2024-04-02 12:02:52,316 - train - INFO - Test: [  39/39]  Time: 1.829 (1.880)  Loss:  0.3862 (0.3719)  Acc@1: 87.5000 (92.0200)  Acc@5: 100.0000 (99.7200)
2024-04-02 12:02:55,929 - train - INFO - Train: 70 [   0/195 (  0%)]  Loss:  1.565990 (1.5660)  Time: 3.118s,   82.11/s  (3.118s,   82.11/s)  LR: 3.082e-04  Data: 0.331 (0.331)
2024-04-02 12:05:22,656 - train - INFO - Train: 70 [  50/195 ( 26%)]  Loss:  1.445902 (1.6248)  Time: 2.841s,   90.10/s  (2.938s,   87.13/s)  LR: 3.082e-04  Data: 0.010 (0.019)
2024-04-02 12:07:50,756 - train - INFO - Train: 70 [ 100/195 ( 52%)]  Loss:  1.874367 (1.6031)  Time: 3.188s,   80.30/s  (2.950s,   86.78/s)  LR: 3.082e-04  Data: 0.005 (0.016)
2024-04-02 12:10:19,593 - train - INFO - Train: 70 [ 150/195 ( 77%)]  Loss:  1.517359 (1.6036)  Time: 2.996s,   85.45/s  (2.959s,   86.53/s)  LR: 3.082e-04  Data: 0.024 (0.016)
2024-04-02 12:12:29,099 - train - INFO - Train: 70 [ 194/195 (100%)]  Loss:  1.810905 (1.6157)  Time: 2.754s,   92.96/s  (2.955s,   86.63/s)  LR: 3.082e-04  Data: 0.000 (0.016)
2024-04-02 12:12:29,099 - train - INFO - True
2024-04-02 12:12:29,100 - train - INFO - alphas:tensor([0.0045, 0.9955], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,101 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,101 - train - INFO - True
2024-04-02 12:12:29,106 - train - INFO - alphas:tensor([0.0821, 0.9179], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,106 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,106 - train - INFO - True
2024-04-02 12:12:29,107 - train - INFO - alphas:tensor([0.5307, 0.4693], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,107 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,107 - train - INFO - True
2024-04-02 12:12:29,108 - train - INFO - alphas:tensor([0.4692, 0.5308], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,108 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,108 - train - INFO - True
2024-04-02 12:12:29,109 - train - INFO - alphas:tensor([0.1546, 0.8454], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,109 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,109 - train - INFO - True
2024-04-02 12:12:29,110 - train - INFO - alphas:tensor([0.2568, 0.7432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,110 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,110 - train - INFO - True
2024-04-02 12:12:29,111 - train - INFO - alphas:tensor([0.5328, 0.4672], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,111 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,111 - train - INFO - True
2024-04-02 12:12:29,112 - train - INFO - alphas:tensor([0.4309, 0.5691], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,113 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,113 - train - INFO - True
2024-04-02 12:12:29,114 - train - INFO - alphas:tensor([0.2611, 0.7389], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,114 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,114 - train - INFO - True
2024-04-02 12:12:29,115 - train - INFO - alphas:tensor([0.3914, 0.6086], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,115 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,115 - train - INFO - True
2024-04-02 12:12:29,116 - train - INFO - alphas:tensor([0.5370, 0.4630], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,116 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,116 - train - INFO - True
2024-04-02 12:12:29,117 - train - INFO - alphas:tensor([0.4104, 0.5896], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,117 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,118 - train - INFO - True
2024-04-02 12:12:29,118 - train - INFO - alphas:tensor([0.2745, 0.7255], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,119 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,119 - train - INFO - True
2024-04-02 12:12:29,120 - train - INFO - alphas:tensor([0.3843, 0.6157], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,124 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,125 - train - INFO - True
2024-04-02 12:12:29,125 - train - INFO - alphas:tensor([0.4761, 0.5239], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,126 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,126 - train - INFO - True
2024-04-02 12:12:29,127 - train - INFO - alphas:tensor([0.3329, 0.6671], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,127 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,127 - train - INFO - True
2024-04-02 12:12:29,128 - train - INFO - alphas:tensor([0.2435, 0.7565], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,128 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,128 - train - INFO - True
2024-04-02 12:12:29,129 - train - INFO - alphas:tensor([0.2926, 0.7074], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,129 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,130 - train - INFO - True
2024-04-02 12:12:29,130 - train - INFO - alphas:tensor([0.3438, 0.6562], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,131 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,131 - train - INFO - True
2024-04-02 12:12:29,132 - train - INFO - alphas:tensor([0.1630, 0.8370], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,132 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,132 - train - INFO - True
2024-04-02 12:12:29,133 - train - INFO - alphas:tensor([0.1870, 0.8130], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,133 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,133 - train - INFO - True
2024-04-02 12:12:29,134 - train - INFO - alphas:tensor([0.2214, 0.7786], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,134 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,135 - train - INFO - True
2024-04-02 12:12:29,135 - train - INFO - alphas:tensor([0.2924, 0.7076], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,136 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,136 - train - INFO - True
2024-04-02 12:12:29,137 - train - INFO - alphas:tensor([0.0669, 0.9331], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,137 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,137 - train - INFO - True
2024-04-02 12:12:29,138 - train - INFO - alphas:tensor([0.1167, 0.8833], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,138 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,138 - train - INFO - True
2024-04-02 12:12:29,139 - train - INFO - alphas:tensor([0.0232, 0.9768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,139 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,139 - train - INFO - True
2024-04-02 12:12:29,140 - train - INFO - alphas:tensor([0.0059, 0.9941], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,141 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,141 - train - INFO - True
2024-04-02 12:12:29,141 - train - INFO - alphas:tensor([3.8857e-04, 9.9961e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,142 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,142 - train - INFO - True
2024-04-02 12:12:29,143 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:12:29,147 - train - INFO - tau:0.5048858887870696
2024-04-02 12:12:29,147 - train - INFO - avg block size:13.931034482758621
2024-04-02 12:12:31,016 - train - INFO - Test: [   0/39]  Time: 1.865 (1.865)  Loss:  0.4209 (0.4209)  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)
2024-04-02 12:13:41,161 - train - INFO - Test: [  39/39]  Time: 1.898 (1.800)  Loss:  0.3376 (0.3982)  Acc@1: 87.5000 (91.7900)  Acc@5: 100.0000 (99.6900)
2024-04-02 12:13:44,825 - train - INFO - Train: 71 [   0/195 (  0%)]  Loss:  1.367621 (1.3676)  Time: 3.275s,   78.17/s  (3.275s,   78.17/s)  LR: 3.026e-04  Data: 0.403 (0.403)
2024-04-02 12:16:09,129 - train - INFO - Train: 71 [  50/195 ( 26%)]  Loss:  1.887966 (1.5629)  Time: 2.757s,   92.86/s  (2.894s,   88.47/s)  LR: 3.026e-04  Data: 0.023 (0.023)
2024-04-02 12:18:37,151 - train - INFO - Train: 71 [ 100/195 ( 52%)]  Loss:  1.811104 (1.5903)  Time: 2.708s,   94.54/s  (2.927s,   87.47/s)  LR: 3.026e-04  Data: 0.024 (0.020)
2024-04-02 12:21:05,093 - train - INFO - Train: 71 [ 150/195 ( 77%)]  Loss:  1.411438 (1.5826)  Time: 3.001s,   85.30/s  (2.937s,   87.15/s)  LR: 3.026e-04  Data: 0.018 (0.019)
2024-04-02 12:23:16,098 - train - INFO - Train: 71 [ 194/195 (100%)]  Loss:  1.909719 (1.5879)  Time: 3.134s,   81.70/s  (2.946s,   86.89/s)  LR: 3.026e-04  Data: 0.000 (0.018)
2024-04-02 12:23:16,099 - train - INFO - True
2024-04-02 12:23:16,100 - train - INFO - alphas:tensor([0.0040, 0.9960], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,100 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,100 - train - INFO - True
2024-04-02 12:23:16,101 - train - INFO - alphas:tensor([0.0807, 0.9193], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,101 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,101 - train - INFO - True
2024-04-02 12:23:16,102 - train - INFO - alphas:tensor([0.5290, 0.4710], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,102 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,102 - train - INFO - True
2024-04-02 12:23:16,103 - train - INFO - alphas:tensor([0.4668, 0.5332], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,103 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,103 - train - INFO - True
2024-04-02 12:23:16,104 - train - INFO - alphas:tensor([0.1531, 0.8469], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,104 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,104 - train - INFO - True
2024-04-02 12:23:16,105 - train - INFO - alphas:tensor([0.2542, 0.7458], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,105 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,105 - train - INFO - True
2024-04-02 12:23:16,106 - train - INFO - alphas:tensor([0.5319, 0.4681], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,106 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,106 - train - INFO - True
2024-04-02 12:23:16,107 - train - INFO - alphas:tensor([0.4300, 0.5700], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,107 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,107 - train - INFO - True
2024-04-02 12:23:16,108 - train - INFO - alphas:tensor([0.2597, 0.7403], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,108 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,108 - train - INFO - True
2024-04-02 12:23:16,109 - train - INFO - alphas:tensor([0.3910, 0.6090], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,109 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,109 - train - INFO - True
2024-04-02 12:23:16,110 - train - INFO - alphas:tensor([0.5377, 0.4623], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,110 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,110 - train - INFO - True
2024-04-02 12:23:16,115 - train - INFO - alphas:tensor([0.4131, 0.5869], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,115 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,116 - train - INFO - True
2024-04-02 12:23:16,116 - train - INFO - alphas:tensor([0.2738, 0.7262], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,116 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,117 - train - INFO - True
2024-04-02 12:23:16,117 - train - INFO - alphas:tensor([0.3861, 0.6139], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,117 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,117 - train - INFO - True
2024-04-02 12:23:16,118 - train - INFO - alphas:tensor([0.4753, 0.5247], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,118 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,118 - train - INFO - True
2024-04-02 12:23:16,119 - train - INFO - alphas:tensor([0.3329, 0.6671], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,119 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,119 - train - INFO - True
2024-04-02 12:23:16,120 - train - INFO - alphas:tensor([0.2437, 0.7563], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,120 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,120 - train - INFO - True
2024-04-02 12:23:16,121 - train - INFO - alphas:tensor([0.2942, 0.7058], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,121 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,121 - train - INFO - True
2024-04-02 12:23:16,122 - train - INFO - alphas:tensor([0.3414, 0.6586], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,122 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,122 - train - INFO - True
2024-04-02 12:23:16,123 - train - INFO - alphas:tensor([0.1606, 0.8394], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,123 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,123 - train - INFO - True
2024-04-02 12:23:16,124 - train - INFO - alphas:tensor([0.1839, 0.8161], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,124 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,124 - train - INFO - True
2024-04-02 12:23:16,125 - train - INFO - alphas:tensor([0.2179, 0.7821], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,125 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,125 - train - INFO - True
2024-04-02 12:23:16,126 - train - INFO - alphas:tensor([0.2930, 0.7070], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,126 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,126 - train - INFO - True
2024-04-02 12:23:16,127 - train - INFO - alphas:tensor([0.0643, 0.9357], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,127 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,127 - train - INFO - True
2024-04-02 12:23:16,128 - train - INFO - alphas:tensor([0.1150, 0.8850], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,128 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,128 - train - INFO - True
2024-04-02 12:23:16,133 - train - INFO - alphas:tensor([0.0213, 0.9787], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,133 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,133 - train - INFO - True
2024-04-02 12:23:16,134 - train - INFO - alphas:tensor([0.0053, 0.9947], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,134 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,134 - train - INFO - True
2024-04-02 12:23:16,135 - train - INFO - alphas:tensor([3.4303e-04, 9.9966e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,135 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,135 - train - INFO - True
2024-04-02 12:23:16,136 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:23:16,136 - train - INFO - tau:0.4998370298991989
2024-04-02 12:23:16,136 - train - INFO - avg block size:13.931034482758621
2024-04-02 12:23:18,155 - train - INFO - Test: [   0/39]  Time: 2.012 (2.012)  Loss:  0.4016 (0.4016)  Acc@1: 91.0156 (91.0156)  Acc@5: 100.0000 (100.0000)
2024-04-02 12:24:29,511 - train - INFO - Test: [  39/39]  Time: 1.780 (1.834)  Loss:  0.5181 (0.3972)  Acc@1: 81.2500 (91.7200)  Acc@5: 100.0000 (99.6800)
2024-04-02 12:24:33,052 - train - INFO - Train: 72 [   0/195 (  0%)]  Loss:  1.486723 (1.4867)  Time: 3.323s,   77.03/s  (3.323s,   77.03/s)  LR: 2.970e-04  Data: 0.315 (0.315)
2024-04-02 12:27:00,183 - train - INFO - Train: 72 [  50/195 ( 26%)]  Loss:  1.322398 (1.5652)  Time: 2.681s,   95.49/s  (2.950s,   86.78/s)  LR: 2.970e-04  Data: 0.016 (0.020)
2024-04-02 12:29:26,975 - train - INFO - Train: 72 [ 100/195 ( 52%)]  Loss:  1.789114 (1.5918)  Time: 2.904s,   88.17/s  (2.943s,   86.99/s)  LR: 2.970e-04  Data: 0.033 (0.017)
2024-04-02 12:31:50,703 - train - INFO - Train: 72 [ 150/195 ( 77%)]  Loss:  1.738880 (1.6016)  Time: 2.918s,   87.74/s  (2.920s,   87.66/s)  LR: 2.970e-04  Data: 0.005 (0.015)
2024-04-02 12:33:59,741 - train - INFO - Train: 72 [ 194/195 (100%)]  Loss:  1.713486 (1.6033)  Time: 2.554s,  100.23/s  (2.923s,   87.58/s)  LR: 2.970e-04  Data: 0.000 (0.015)
2024-04-02 12:33:59,741 - train - INFO - True
2024-04-02 12:33:59,743 - train - INFO - alphas:tensor([0.0037, 0.9963], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,743 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,743 - train - INFO - True
2024-04-02 12:33:59,744 - train - INFO - alphas:tensor([0.0800, 0.9200], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,744 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,744 - train - INFO - True
2024-04-02 12:33:59,745 - train - INFO - alphas:tensor([0.5278, 0.4722], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,745 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,745 - train - INFO - True
2024-04-02 12:33:59,746 - train - INFO - alphas:tensor([0.4666, 0.5334], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,746 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,746 - train - INFO - True
2024-04-02 12:33:59,747 - train - INFO - alphas:tensor([0.1502, 0.8498], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,747 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,747 - train - INFO - True
2024-04-02 12:33:59,748 - train - INFO - alphas:tensor([0.2517, 0.7483], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,748 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,748 - train - INFO - True
2024-04-02 12:33:59,748 - train - INFO - alphas:tensor([0.5319, 0.4681], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,749 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,749 - train - INFO - True
2024-04-02 12:33:59,750 - train - INFO - alphas:tensor([0.4294, 0.5706], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,750 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,750 - train - INFO - True
2024-04-02 12:33:59,751 - train - INFO - alphas:tensor([0.2568, 0.7432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,751 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,751 - train - INFO - True
2024-04-02 12:33:59,752 - train - INFO - alphas:tensor([0.3889, 0.6111], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,752 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,752 - train - INFO - True
2024-04-02 12:33:59,753 - train - INFO - alphas:tensor([0.5371, 0.4629], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,753 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,753 - train - INFO - True
2024-04-02 12:33:59,754 - train - INFO - alphas:tensor([0.4103, 0.5897], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,754 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,758 - train - INFO - True
2024-04-02 12:33:59,759 - train - INFO - alphas:tensor([0.2720, 0.7280], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,759 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,759 - train - INFO - True
2024-04-02 12:33:59,760 - train - INFO - alphas:tensor([0.3838, 0.6162], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,760 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,760 - train - INFO - True
2024-04-02 12:33:59,765 - train - INFO - alphas:tensor([0.4717, 0.5283], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,766 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,766 - train - INFO - True
2024-04-02 12:33:59,766 - train - INFO - alphas:tensor([0.3300, 0.6700], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,766 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,767 - train - INFO - True
2024-04-02 12:33:59,767 - train - INFO - alphas:tensor([0.2403, 0.7597], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,767 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,767 - train - INFO - True
2024-04-02 12:33:59,768 - train - INFO - alphas:tensor([0.2905, 0.7095], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,768 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,768 - train - INFO - True
2024-04-02 12:33:59,769 - train - INFO - alphas:tensor([0.3412, 0.6588], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,769 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,769 - train - INFO - True
2024-04-02 12:33:59,770 - train - INFO - alphas:tensor([0.1577, 0.8423], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,770 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,770 - train - INFO - True
2024-04-02 12:33:59,771 - train - INFO - alphas:tensor([0.1817, 0.8183], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,771 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,771 - train - INFO - True
2024-04-02 12:33:59,772 - train - INFO - alphas:tensor([0.2164, 0.7836], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,772 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,772 - train - INFO - True
2024-04-02 12:33:59,777 - train - INFO - alphas:tensor([0.2900, 0.7100], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,777 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,777 - train - INFO - True
2024-04-02 12:33:59,778 - train - INFO - alphas:tensor([0.0611, 0.9389], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,778 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,778 - train - INFO - True
2024-04-02 12:33:59,779 - train - INFO - alphas:tensor([0.1129, 0.8871], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,779 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,779 - train - INFO - True
2024-04-02 12:33:59,780 - train - INFO - alphas:tensor([0.0196, 0.9804], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,780 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,780 - train - INFO - True
2024-04-02 12:33:59,781 - train - INFO - alphas:tensor([0.0047, 0.9953], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,781 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,781 - train - INFO - True
2024-04-02 12:33:59,786 - train - INFO - alphas:tensor([3.0291e-04, 9.9970e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,786 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,786 - train - INFO - True
2024-04-02 12:33:59,787 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:33:59,787 - train - INFO - tau:0.49483865960020695
2024-04-02 12:33:59,787 - train - INFO - avg block size:13.931034482758621
2024-04-02 12:34:01,679 - train - INFO - Test: [   0/39]  Time: 1.883 (1.883)  Loss:  0.3943 (0.3943)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.6094 (99.6094)
2024-04-02 12:35:14,108 - train - INFO - Test: [  39/39]  Time: 1.723 (1.858)  Loss:  0.3843 (0.3864)  Acc@1: 87.5000 (91.8000)  Acc@5: 100.0000 (99.6500)
2024-04-02 12:35:17,766 - train - INFO - Train: 73 [   0/195 (  0%)]  Loss:  1.649758 (1.6498)  Time: 3.410s,   75.08/s  (3.410s,   75.08/s)  LR: 2.913e-04  Data: 0.291 (0.291)
2024-04-02 12:37:46,215 - train - INFO - Train: 73 [  50/195 ( 26%)]  Loss:  1.265155 (1.6360)  Time: 2.855s,   89.66/s  (2.978s,   85.98/s)  LR: 2.913e-04  Data: 0.019 (0.020)
2024-04-02 12:40:12,424 - train - INFO - Train: 73 [ 100/195 ( 52%)]  Loss:  1.309569 (1.5957)  Time: 3.264s,   78.42/s  (2.951s,   86.75/s)  LR: 2.913e-04  Data: 0.020 (0.018)
2024-04-02 12:42:40,516 - train - INFO - Train: 73 [ 150/195 ( 77%)]  Loss:  1.425039 (1.5905)  Time: 3.127s,   81.87/s  (2.955s,   86.64/s)  LR: 2.913e-04  Data: 0.014 (0.017)
2024-04-02 12:44:49,970 - train - INFO - Train: 73 [ 194/195 (100%)]  Loss:  1.771319 (1.6008)  Time: 3.296s,   77.67/s  (2.952s,   86.73/s)  LR: 2.913e-04  Data: 0.000 (0.016)
2024-04-02 12:44:49,971 - train - INFO - True
2024-04-02 12:44:49,972 - train - INFO - alphas:tensor([0.0033, 0.9967], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,973 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,973 - train - INFO - True
2024-04-02 12:44:49,974 - train - INFO - alphas:tensor([0.0789, 0.9211], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,974 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,974 - train - INFO - True
2024-04-02 12:44:49,975 - train - INFO - alphas:tensor([0.5284, 0.4716], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,975 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,975 - train - INFO - True
2024-04-02 12:44:49,976 - train - INFO - alphas:tensor([0.4657, 0.5343], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,977 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,977 - train - INFO - True
2024-04-02 12:44:49,987 - train - INFO - alphas:tensor([0.1482, 0.8518], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,987 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,987 - train - INFO - True
2024-04-02 12:44:49,988 - train - INFO - alphas:tensor([0.2492, 0.7508], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,988 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,988 - train - INFO - True
2024-04-02 12:44:49,989 - train - INFO - alphas:tensor([0.5299, 0.4701], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,989 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,990 - train - INFO - True
2024-04-02 12:44:49,990 - train - INFO - alphas:tensor([0.4270, 0.5730], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,991 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,991 - train - INFO - True
2024-04-02 12:44:49,992 - train - INFO - alphas:tensor([0.2561, 0.7439], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,992 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,992 - train - INFO - True
2024-04-02 12:44:49,993 - train - INFO - alphas:tensor([0.3881, 0.6119], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,993 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,993 - train - INFO - True
2024-04-02 12:44:49,994 - train - INFO - alphas:tensor([0.5344, 0.4656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,994 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,994 - train - INFO - True
2024-04-02 12:44:49,995 - train - INFO - alphas:tensor([0.4066, 0.5934], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,996 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,996 - train - INFO - True
2024-04-02 12:44:49,997 - train - INFO - alphas:tensor([0.2717, 0.7283], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,997 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,997 - train - INFO - True
2024-04-02 12:44:49,998 - train - INFO - alphas:tensor([0.3849, 0.6151], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,998 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,998 - train - INFO - True
2024-04-02 12:44:49,999 - train - INFO - alphas:tensor([0.4695, 0.5305], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:49,999 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:49,999 - train - INFO - True
2024-04-02 12:44:50,000 - train - INFO - alphas:tensor([0.3301, 0.6699], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:50,000 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:50,001 - train - INFO - True
2024-04-02 12:44:50,001 - train - INFO - alphas:tensor([0.2398, 0.7602], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:50,002 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:50,002 - train - INFO - True
2024-04-02 12:44:50,003 - train - INFO - alphas:tensor([0.2899, 0.7101], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:50,003 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:50,003 - train - INFO - True
2024-04-02 12:44:50,004 - train - INFO - alphas:tensor([0.3382, 0.6618], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:50,004 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:50,004 - train - INFO - True
2024-04-02 12:44:50,005 - train - INFO - alphas:tensor([0.1561, 0.8439], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:50,005 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:50,014 - train - INFO - True
2024-04-02 12:44:50,015 - train - INFO - alphas:tensor([0.1802, 0.8198], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:50,015 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:50,016 - train - INFO - True
2024-04-02 12:44:50,016 - train - INFO - alphas:tensor([0.2141, 0.7859], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:50,017 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:50,017 - train - INFO - True
2024-04-02 12:44:50,018 - train - INFO - alphas:tensor([0.2879, 0.7121], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:50,018 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:50,018 - train - INFO - True
2024-04-02 12:44:50,019 - train - INFO - alphas:tensor([0.0583, 0.9417], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:50,019 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:50,019 - train - INFO - True
2024-04-02 12:44:50,020 - train - INFO - alphas:tensor([0.1104, 0.8896], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:50,020 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:50,021 - train - INFO - True
2024-04-02 12:44:50,021 - train - INFO - alphas:tensor([0.0179, 0.9821], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:50,022 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:50,022 - train - INFO - True
2024-04-02 12:44:50,023 - train - INFO - alphas:tensor([0.0042, 0.9958], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:50,023 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:50,023 - train - INFO - True
2024-04-02 12:44:50,024 - train - INFO - alphas:tensor([2.6749e-04, 9.9973e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:50,028 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:50,029 - train - INFO - True
2024-04-02 12:44:50,029 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:44:50,030 - train - INFO - tau:0.4898902730042049
2024-04-02 12:44:50,030 - train - INFO - avg block size:13.931034482758621
2024-04-02 12:44:51,870 - train - INFO - Test: [   0/39]  Time: 1.836 (1.836)  Loss:  0.3843 (0.3843)  Acc@1: 91.7969 (91.7969)  Acc@5: 100.0000 (100.0000)
2024-04-02 12:46:02,239 - train - INFO - Test: [  39/39]  Time: 1.809 (1.805)  Loss:  0.3760 (0.3828)  Acc@1: 87.5000 (91.8700)  Acc@5: 100.0000 (99.7000)
2024-04-02 12:46:05,995 - train - INFO - Train: 74 [   0/195 (  0%)]  Loss:  1.334683 (1.3347)  Time: 3.438s,   74.47/s  (3.438s,   74.47/s)  LR: 2.857e-04  Data: 0.345 (0.345)
2024-04-02 12:48:33,396 - train - INFO - Train: 74 [  50/195 ( 26%)]  Loss:  1.396962 (1.5875)  Time: 2.910s,   87.96/s  (2.958s,   86.56/s)  LR: 2.857e-04  Data: 0.023 (0.021)
2024-04-02 12:50:59,571 - train - INFO - Train: 74 [ 100/195 ( 52%)]  Loss:  1.738322 (1.6066)  Time: 2.999s,   85.37/s  (2.941s,   87.05/s)  LR: 2.857e-04  Data: 0.012 (0.017)
2024-04-02 12:53:31,192 - train - INFO - Train: 74 [ 150/195 ( 77%)]  Loss:  1.684489 (1.6059)  Time: 2.968s,   86.26/s  (2.971s,   86.16/s)  LR: 2.857e-04  Data: 0.010 (0.017)
2024-04-02 12:55:37,867 - train - INFO - Train: 74 [ 194/195 (100%)]  Loss:  1.530059 (1.5912)  Time: 3.040s,   84.22/s  (2.950s,   86.77/s)  LR: 2.857e-04  Data: 0.000 (0.017)
2024-04-02 12:55:37,868 - train - INFO - True
2024-04-02 12:55:37,874 - train - INFO - alphas:tensor([0.0030, 0.9970], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,874 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,874 - train - INFO - True
2024-04-02 12:55:37,875 - train - INFO - alphas:tensor([0.0782, 0.9218], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,876 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,876 - train - INFO - True
2024-04-02 12:55:37,877 - train - INFO - alphas:tensor([0.5263, 0.4737], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,877 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,882 - train - INFO - True
2024-04-02 12:55:37,883 - train - INFO - alphas:tensor([0.4636, 0.5364], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,883 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,883 - train - INFO - True
2024-04-02 12:55:37,884 - train - INFO - alphas:tensor([0.1462, 0.8538], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,884 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,885 - train - INFO - True
2024-04-02 12:55:37,885 - train - INFO - alphas:tensor([0.2467, 0.7533], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,886 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,886 - train - INFO - True
2024-04-02 12:55:37,887 - train - INFO - alphas:tensor([0.5294, 0.4706], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,888 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,888 - train - INFO - True
2024-04-02 12:55:37,893 - train - INFO - alphas:tensor([0.4258, 0.5742], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,894 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,894 - train - INFO - True
2024-04-02 12:55:37,895 - train - INFO - alphas:tensor([0.2565, 0.7435], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,895 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,895 - train - INFO - True
2024-04-02 12:55:37,896 - train - INFO - alphas:tensor([0.3861, 0.6139], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,897 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,897 - train - INFO - True
2024-04-02 12:55:37,898 - train - INFO - alphas:tensor([0.5329, 0.4671], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,898 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,898 - train - INFO - True
2024-04-02 12:55:37,899 - train - INFO - alphas:tensor([0.4036, 0.5964], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,899 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,900 - train - INFO - True
2024-04-02 12:55:37,900 - train - INFO - alphas:tensor([0.2708, 0.7292], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,901 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,901 - train - INFO - True
2024-04-02 12:55:37,902 - train - INFO - alphas:tensor([0.3851, 0.6149], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,902 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,902 - train - INFO - True
2024-04-02 12:55:37,903 - train - INFO - alphas:tensor([0.4701, 0.5299], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,904 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,904 - train - INFO - True
2024-04-02 12:55:37,905 - train - INFO - alphas:tensor([0.3304, 0.6696], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,905 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,905 - train - INFO - True
2024-04-02 12:55:37,906 - train - INFO - alphas:tensor([0.2361, 0.7639], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,911 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,911 - train - INFO - True
2024-04-02 12:55:37,912 - train - INFO - alphas:tensor([0.2882, 0.7118], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,912 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,913 - train - INFO - True
2024-04-02 12:55:37,914 - train - INFO - alphas:tensor([0.3346, 0.6654], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,914 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,914 - train - INFO - True
2024-04-02 12:55:37,915 - train - INFO - alphas:tensor([0.1538, 0.8462], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,915 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,916 - train - INFO - True
2024-04-02 12:55:37,917 - train - INFO - alphas:tensor([0.1796, 0.8204], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,917 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,924 - train - INFO - True
2024-04-02 12:55:37,925 - train - INFO - alphas:tensor([0.2138, 0.7862], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,927 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,928 - train - INFO - True
2024-04-02 12:55:37,937 - train - INFO - alphas:tensor([0.2876, 0.7124], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,938 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,938 - train - INFO - True
2024-04-02 12:55:37,939 - train - INFO - alphas:tensor([0.0555, 0.9445], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,939 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,939 - train - INFO - True
2024-04-02 12:55:37,940 - train - INFO - alphas:tensor([0.1089, 0.8911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,940 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,940 - train - INFO - True
2024-04-02 12:55:37,941 - train - INFO - alphas:tensor([0.0163, 0.9837], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,941 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,942 - train - INFO - True
2024-04-02 12:55:37,942 - train - INFO - alphas:tensor([0.0038, 0.9962], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,943 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,943 - train - INFO - True
2024-04-02 12:55:37,944 - train - INFO - alphas:tensor([2.3603e-04, 9.9976e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,944 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,945 - train - INFO - True
2024-04-02 12:55:37,951 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 12:55:37,951 - train - INFO - tau:0.48499137027416284
2024-04-02 12:55:37,951 - train - INFO - avg block size:13.931034482758621
2024-04-02 12:55:39,945 - train - INFO - Test: [   0/39]  Time: 1.979 (1.979)  Loss:  0.3877 (0.3877)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-04-02 12:56:52,301 - train - INFO - Test: [  39/39]  Time: 1.852 (1.858)  Loss:  0.4541 (0.3813)  Acc@1: 81.2500 (91.8200)  Acc@5: 100.0000 (99.6800)
2024-04-02 12:56:55,694 - train - INFO - Train: 75 [   0/195 (  0%)]  Loss:  1.294334 (1.2943)  Time: 3.100s,   82.58/s  (3.100s,   82.58/s)  LR: 2.800e-04  Data: 0.280 (0.280)
2024-04-02 12:59:23,466 - train - INFO - Train: 75 [  50/195 ( 26%)]  Loss:  1.599112 (1.5620)  Time: 3.182s,   80.46/s  (2.958s,   86.54/s)  LR: 2.800e-04  Data: 0.019 (0.020)
2024-04-02 13:01:47,615 - train - INFO - Train: 75 [ 100/195 ( 52%)]  Loss:  1.686739 (1.5950)  Time: 3.075s,   83.24/s  (2.921s,   87.64/s)  LR: 2.800e-04  Data: 0.018 (0.018)
2024-04-02 13:04:17,452 - train - INFO - Train: 75 [ 150/195 ( 77%)]  Loss:  1.476780 (1.5765)  Time: 2.770s,   92.41/s  (2.946s,   86.90/s)  LR: 2.800e-04  Data: 0.005 (0.017)
2024-04-02 13:06:26,905 - train - INFO - Train: 75 [ 194/195 (100%)]  Loss:  1.321783 (1.5892)  Time: 3.200s,   79.99/s  (2.945s,   86.92/s)  LR: 2.800e-04  Data: 0.000 (0.017)
2024-04-02 13:06:26,905 - train - INFO - True
2024-04-02 13:06:26,907 - train - INFO - alphas:tensor([0.0027, 0.9973], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,907 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,907 - train - INFO - True
2024-04-02 13:06:26,908 - train - INFO - alphas:tensor([0.0774, 0.9226], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,908 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,908 - train - INFO - True
2024-04-02 13:06:26,909 - train - INFO - alphas:tensor([0.5257, 0.4743], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,909 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,909 - train - INFO - True
2024-04-02 13:06:26,909 - train - INFO - alphas:tensor([0.4629, 0.5371], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,910 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,910 - train - INFO - True
2024-04-02 13:06:26,910 - train - INFO - alphas:tensor([0.1441, 0.8559], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,911 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,911 - train - INFO - True
2024-04-02 13:06:26,920 - train - INFO - alphas:tensor([0.2455, 0.7545], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,920 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,920 - train - INFO - True
2024-04-02 13:06:26,921 - train - INFO - alphas:tensor([0.5289, 0.4711], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,922 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,922 - train - INFO - True
2024-04-02 13:06:26,923 - train - INFO - alphas:tensor([0.4235, 0.5765], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,923 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,923 - train - INFO - True
2024-04-02 13:06:26,924 - train - INFO - alphas:tensor([0.2543, 0.7457], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,924 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,924 - train - INFO - True
2024-04-02 13:06:26,924 - train - INFO - alphas:tensor([0.3838, 0.6162], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,925 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,925 - train - INFO - True
2024-04-02 13:06:26,925 - train - INFO - alphas:tensor([0.5317, 0.4683], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,926 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,926 - train - INFO - True
2024-04-02 13:06:26,926 - train - INFO - alphas:tensor([0.4042, 0.5958], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,926 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,927 - train - INFO - True
2024-04-02 13:06:26,927 - train - INFO - alphas:tensor([0.2675, 0.7325], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,928 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,928 - train - INFO - True
2024-04-02 13:06:26,929 - train - INFO - alphas:tensor([0.3812, 0.6188], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,929 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,929 - train - INFO - True
2024-04-02 13:06:26,930 - train - INFO - alphas:tensor([0.4697, 0.5303], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,930 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,930 - train - INFO - True
2024-04-02 13:06:26,931 - train - INFO - alphas:tensor([0.3307, 0.6693], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,931 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,932 - train - INFO - True
2024-04-02 13:06:26,932 - train - INFO - alphas:tensor([0.2354, 0.7646], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,933 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,933 - train - INFO - True
2024-04-02 13:06:26,934 - train - INFO - alphas:tensor([0.2864, 0.7136], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,934 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,935 - train - INFO - True
2024-04-02 13:06:26,935 - train - INFO - alphas:tensor([0.3335, 0.6665], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,936 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,936 - train - INFO - True
2024-04-02 13:06:26,937 - train - INFO - alphas:tensor([0.1520, 0.8480], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,937 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,937 - train - INFO - True
2024-04-02 13:06:26,938 - train - INFO - alphas:tensor([0.1770, 0.8230], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,938 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,938 - train - INFO - True
2024-04-02 13:06:26,939 - train - INFO - alphas:tensor([0.2099, 0.7901], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,940 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,940 - train - INFO - True
2024-04-02 13:06:26,941 - train - INFO - alphas:tensor([0.2833, 0.7167], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,941 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,941 - train - INFO - True
2024-04-02 13:06:26,942 - train - INFO - alphas:tensor([0.0521, 0.9479], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,942 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,942 - train - INFO - True
2024-04-02 13:06:26,943 - train - INFO - alphas:tensor([0.1071, 0.8929], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,943 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,944 - train - INFO - True
2024-04-02 13:06:26,944 - train - INFO - alphas:tensor([0.0149, 0.9851], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,945 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,945 - train - INFO - True
2024-04-02 13:06:26,946 - train - INFO - alphas:tensor([0.0034, 0.9966], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,946 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,946 - train - INFO - True
2024-04-02 13:06:26,947 - train - INFO - alphas:tensor([2.0832e-04, 9.9979e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,947 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,947 - train - INFO - True
2024-04-02 13:06:26,948 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:06:26,948 - train - INFO - tau:0.4801414565714212
2024-04-02 13:06:26,948 - train - INFO - avg block size:13.931034482758621
2024-04-02 13:06:28,769 - train - INFO - Test: [   0/39]  Time: 1.818 (1.818)  Loss:  0.3850 (0.3850)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-02 13:07:39,682 - train - INFO - Test: [  39/39]  Time: 1.857 (1.818)  Loss:  0.3989 (0.3867)  Acc@1: 81.2500 (91.6500)  Acc@5: 100.0000 (99.6600)
2024-04-02 13:07:43,362 - train - INFO - Train: 76 [   0/195 (  0%)]  Loss:  1.388106 (1.3881)  Time: 3.359s,   76.22/s  (3.359s,   76.22/s)  LR: 2.743e-04  Data: 0.249 (0.249)
2024-04-02 13:10:15,911 - train - INFO - Train: 76 [  50/195 ( 26%)]  Loss:  1.270461 (1.6016)  Time: 3.273s,   78.21/s  (3.057s,   83.74/s)  LR: 2.743e-04  Data: 0.014 (0.021)
2024-04-02 13:12:41,924 - train - INFO - Train: 76 [ 100/195 ( 52%)]  Loss:  1.741015 (1.5889)  Time: 2.750s,   93.08/s  (2.989s,   85.64/s)  LR: 2.743e-04  Data: 0.005 (0.018)
2024-04-02 13:15:08,037 - train - INFO - Train: 76 [ 150/195 ( 77%)]  Loss:  1.746103 (1.6044)  Time: 2.954s,   86.65/s  (2.967s,   86.28/s)  LR: 2.743e-04  Data: 0.019 (0.017)
2024-04-02 13:17:19,969 - train - INFO - Train: 76 [ 194/195 (100%)]  Loss:  1.790820 (1.6058)  Time: 2.708s,   94.52/s  (2.974s,   86.08/s)  LR: 2.743e-04  Data: 0.000 (0.016)
2024-04-02 13:17:19,970 - train - INFO - True
2024-04-02 13:17:19,972 - train - INFO - alphas:tensor([0.0024, 0.9976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,972 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,973 - train - INFO - True
2024-04-02 13:17:19,974 - train - INFO - alphas:tensor([0.0755, 0.9245], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,974 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,974 - train - INFO - True
2024-04-02 13:17:19,975 - train - INFO - alphas:tensor([0.5247, 0.4753], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,975 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,975 - train - INFO - True
2024-04-02 13:17:19,976 - train - INFO - alphas:tensor([0.4610, 0.5390], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,976 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,977 - train - INFO - True
2024-04-02 13:17:19,977 - train - INFO - alphas:tensor([0.1417, 0.8583], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,978 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,979 - train - INFO - True
2024-04-02 13:17:19,979 - train - INFO - alphas:tensor([0.2434, 0.7566], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,980 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,980 - train - INFO - True
2024-04-02 13:17:19,981 - train - INFO - alphas:tensor([0.5272, 0.4728], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,981 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,981 - train - INFO - True
2024-04-02 13:17:19,982 - train - INFO - alphas:tensor([0.4222, 0.5778], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,982 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,982 - train - INFO - True
2024-04-02 13:17:19,983 - train - INFO - alphas:tensor([0.2525, 0.7475], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,983 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,984 - train - INFO - True
2024-04-02 13:17:19,984 - train - INFO - alphas:tensor([0.3812, 0.6188], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,985 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,985 - train - INFO - True
2024-04-02 13:17:19,986 - train - INFO - alphas:tensor([0.5297, 0.4703], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,986 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,986 - train - INFO - True
2024-04-02 13:17:19,992 - train - INFO - alphas:tensor([0.4012, 0.5988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,992 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,992 - train - INFO - True
2024-04-02 13:17:19,993 - train - INFO - alphas:tensor([0.2672, 0.7328], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,993 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,993 - train - INFO - True
2024-04-02 13:17:19,994 - train - INFO - alphas:tensor([0.3802, 0.6198], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,994 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,995 - train - INFO - True
2024-04-02 13:17:19,995 - train - INFO - alphas:tensor([0.4679, 0.5321], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,996 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,996 - train - INFO - True
2024-04-02 13:17:19,997 - train - INFO - alphas:tensor([0.3288, 0.6712], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,997 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,997 - train - INFO - True
2024-04-02 13:17:19,998 - train - INFO - alphas:tensor([0.2336, 0.7664], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,998 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:19,998 - train - INFO - True
2024-04-02 13:17:19,999 - train - INFO - alphas:tensor([0.2845, 0.7155], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:19,999 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:20,000 - train - INFO - True
2024-04-02 13:17:20,000 - train - INFO - alphas:tensor([0.3322, 0.6678], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:20,001 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:20,001 - train - INFO - True
2024-04-02 13:17:20,002 - train - INFO - alphas:tensor([0.1497, 0.8503], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:20,002 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:20,002 - train - INFO - True
2024-04-02 13:17:20,003 - train - INFO - alphas:tensor([0.1762, 0.8238], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:20,003 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:20,003 - train - INFO - True
2024-04-02 13:17:20,004 - train - INFO - alphas:tensor([0.2091, 0.7909], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:20,005 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:20,005 - train - INFO - True
2024-04-02 13:17:20,006 - train - INFO - alphas:tensor([0.2805, 0.7195], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:20,006 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:20,006 - train - INFO - True
2024-04-02 13:17:20,007 - train - INFO - alphas:tensor([0.0491, 0.9509], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:20,007 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:20,007 - train - INFO - True
2024-04-02 13:17:20,008 - train - INFO - alphas:tensor([0.1059, 0.8941], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:20,008 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:20,009 - train - INFO - True
2024-04-02 13:17:20,009 - train - INFO - alphas:tensor([0.0135, 0.9865], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:20,010 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:20,014 - train - INFO - True
2024-04-02 13:17:20,015 - train - INFO - alphas:tensor([0.0030, 0.9970], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:20,015 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:20,016 - train - INFO - True
2024-04-02 13:17:20,016 - train - INFO - alphas:tensor([1.8382e-04, 9.9982e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:20,017 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:20,017 - train - INFO - True
2024-04-02 13:17:20,018 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:17:20,018 - train - INFO - tau:0.475340042005707
2024-04-02 13:17:20,018 - train - INFO - avg block size:13.931034482758621
2024-04-02 13:17:21,946 - train - INFO - Test: [   0/39]  Time: 1.925 (1.925)  Loss:  0.3774 (0.3774)  Acc@1: 92.1875 (92.1875)  Acc@5: 99.6094 (99.6094)
2024-04-02 13:18:32,602 - train - INFO - Test: [  39/39]  Time: 1.798 (1.814)  Loss:  0.4033 (0.3688)  Acc@1: 81.2500 (92.0300)  Acc@5: 100.0000 (99.7300)
2024-04-02 13:18:36,723 - train - INFO - Train: 77 [   0/195 (  0%)]  Loss:  1.644522 (1.6445)  Time: 3.835s,   66.75/s  (3.835s,   66.75/s)  LR: 2.687e-04  Data: 0.347 (0.347)
2024-04-02 13:21:04,371 - train - INFO - Train: 77 [  50/195 ( 26%)]  Loss:  1.494011 (1.6471)  Time: 2.817s,   90.88/s  (2.970s,   86.20/s)  LR: 2.687e-04  Data: 0.014 (0.021)
2024-04-02 13:23:31,196 - train - INFO - Train: 77 [ 100/195 ( 52%)]  Loss:  1.748573 (1.6305)  Time: 3.136s,   81.64/s  (2.953s,   86.68/s)  LR: 2.687e-04  Data: 0.005 (0.019)
2024-04-02 13:25:59,773 - train - INFO - Train: 77 [ 150/195 ( 77%)]  Loss:  1.788100 (1.6090)  Time: 3.330s,   76.87/s  (2.959s,   86.51/s)  LR: 2.687e-04  Data: 0.010 (0.017)
2024-04-02 13:28:12,621 - train - INFO - Train: 77 [ 194/195 (100%)]  Loss:  1.752694 (1.6096)  Time: 2.887s,   88.68/s  (2.973s,   86.11/s)  LR: 2.687e-04  Data: 0.000 (0.017)
2024-04-02 13:28:12,622 - train - INFO - True
2024-04-02 13:28:12,623 - train - INFO - alphas:tensor([0.0022, 0.9978], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,623 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,623 - train - INFO - True
2024-04-02 13:28:12,624 - train - INFO - alphas:tensor([0.0746, 0.9254], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,624 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,624 - train - INFO - True
2024-04-02 13:28:12,625 - train - INFO - alphas:tensor([0.5234, 0.4766], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,625 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,626 - train - INFO - True
2024-04-02 13:28:12,626 - train - INFO - alphas:tensor([0.4608, 0.5392], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,627 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,627 - train - INFO - True
2024-04-02 13:28:12,628 - train - INFO - alphas:tensor([0.1405, 0.8595], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,628 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,628 - train - INFO - True
2024-04-02 13:28:12,629 - train - INFO - alphas:tensor([0.2431, 0.7569], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,629 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,629 - train - INFO - True
2024-04-02 13:28:12,630 - train - INFO - alphas:tensor([0.5257, 0.4743], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,630 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,630 - train - INFO - True
2024-04-02 13:28:12,631 - train - INFO - alphas:tensor([0.4213, 0.5787], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,632 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,632 - train - INFO - True
2024-04-02 13:28:12,633 - train - INFO - alphas:tensor([0.2520, 0.7480], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,633 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,633 - train - INFO - True
2024-04-02 13:28:12,634 - train - INFO - alphas:tensor([0.3825, 0.6175], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,634 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,635 - train - INFO - True
2024-04-02 13:28:12,635 - train - INFO - alphas:tensor([0.5292, 0.4708], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,636 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,636 - train - INFO - True
2024-04-02 13:28:12,637 - train - INFO - alphas:tensor([0.4011, 0.5989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,637 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,637 - train - INFO - True
2024-04-02 13:28:12,638 - train - INFO - alphas:tensor([0.2665, 0.7335], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,638 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,638 - train - INFO - True
2024-04-02 13:28:12,639 - train - INFO - alphas:tensor([0.3801, 0.6199], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,640 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,640 - train - INFO - True
2024-04-02 13:28:12,641 - train - INFO - alphas:tensor([0.4657, 0.5343], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,641 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,641 - train - INFO - True
2024-04-02 13:28:12,642 - train - INFO - alphas:tensor([0.3249, 0.6751], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,642 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,642 - train - INFO - True
2024-04-02 13:28:12,643 - train - INFO - alphas:tensor([0.2321, 0.7679], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,643 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,644 - train - INFO - True
2024-04-02 13:28:12,644 - train - INFO - alphas:tensor([0.2849, 0.7151], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,645 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,645 - train - INFO - True
2024-04-02 13:28:12,646 - train - INFO - alphas:tensor([0.3320, 0.6680], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,646 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,646 - train - INFO - True
2024-04-02 13:28:12,647 - train - INFO - alphas:tensor([0.1483, 0.8517], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,647 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,647 - train - INFO - True
2024-04-02 13:28:12,648 - train - INFO - alphas:tensor([0.1745, 0.8255], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,648 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,649 - train - INFO - True
2024-04-02 13:28:12,649 - train - INFO - alphas:tensor([0.2064, 0.7936], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,650 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,650 - train - INFO - True
2024-04-02 13:28:12,651 - train - INFO - alphas:tensor([0.2804, 0.7196], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,651 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,651 - train - INFO - True
2024-04-02 13:28:12,652 - train - INFO - alphas:tensor([0.0469, 0.9531], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,652 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,652 - train - INFO - True
2024-04-02 13:28:12,653 - train - INFO - alphas:tensor([0.1044, 0.8956], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,654 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,654 - train - INFO - True
2024-04-02 13:28:12,655 - train - INFO - alphas:tensor([0.0123, 0.9877], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,655 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,655 - train - INFO - True
2024-04-02 13:28:12,656 - train - INFO - alphas:tensor([0.0027, 0.9973], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,656 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,656 - train - INFO - True
2024-04-02 13:28:12,657 - train - INFO - alphas:tensor([1.6214e-04, 9.9984e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,662 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,662 - train - INFO - True
2024-04-02 13:28:12,663 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:28:12,663 - train - INFO - tau:0.47058664158564995
2024-04-02 13:28:12,663 - train - INFO - avg block size:13.931034482758621
2024-04-02 13:28:14,568 - train - INFO - Test: [   0/39]  Time: 1.898 (1.898)  Loss:  0.3694 (0.3694)  Acc@1: 91.4062 (91.4062)  Acc@5: 100.0000 (100.0000)
2024-04-02 13:29:26,243 - train - INFO - Test: [  39/39]  Time: 1.889 (1.839)  Loss:  0.4685 (0.3815)  Acc@1: 81.2500 (91.7300)  Acc@5: 100.0000 (99.6700)
2024-04-02 13:29:29,824 - train - INFO - Train: 78 [   0/195 (  0%)]  Loss:  1.399655 (1.3997)  Time: 3.240s,   79.02/s  (3.240s,   79.02/s)  LR: 2.630e-04  Data: 0.369 (0.369)
2024-04-02 13:31:57,327 - train - INFO - Train: 78 [  50/195 ( 26%)]  Loss:  1.555294 (1.6084)  Time: 2.970s,   86.19/s  (2.956s,   86.61/s)  LR: 2.630e-04  Data: 0.052 (0.022)
2024-04-02 13:34:21,882 - train - INFO - Train: 78 [ 100/195 ( 52%)]  Loss:  1.311171 (1.5998)  Time: 2.666s,   96.02/s  (2.924s,   87.56/s)  LR: 2.630e-04  Data: 0.006 (0.018)
2024-04-02 13:36:45,571 - train - INFO - Train: 78 [ 150/195 ( 77%)]  Loss:  1.594480 (1.6053)  Time: 2.688s,   95.22/s  (2.907s,   88.06/s)  LR: 2.630e-04  Data: 0.014 (0.017)
2024-04-02 13:38:53,167 - train - INFO - Train: 78 [ 194/195 (100%)]  Loss:  1.352087 (1.5969)  Time: 2.559s,  100.05/s  (2.905s,   88.11/s)  LR: 2.630e-04  Data: 0.000 (0.017)
2024-04-02 13:38:53,168 - train - INFO - True
2024-04-02 13:38:53,170 - train - INFO - alphas:tensor([0.0020, 0.9980], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,170 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,170 - train - INFO - True
2024-04-02 13:38:53,171 - train - INFO - alphas:tensor([0.0735, 0.9265], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,172 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,172 - train - INFO - True
2024-04-02 13:38:53,173 - train - INFO - alphas:tensor([0.5220, 0.4780], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,173 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,173 - train - INFO - True
2024-04-02 13:38:53,174 - train - INFO - alphas:tensor([0.4588, 0.5412], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,174 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,175 - train - INFO - True
2024-04-02 13:38:53,176 - train - INFO - alphas:tensor([0.1389, 0.8611], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,176 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,176 - train - INFO - True
2024-04-02 13:38:53,177 - train - INFO - alphas:tensor([0.2403, 0.7597], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,178 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,178 - train - INFO - True
2024-04-02 13:38:53,179 - train - INFO - alphas:tensor([0.5249, 0.4751], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,179 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,180 - train - INFO - True
2024-04-02 13:38:53,180 - train - INFO - alphas:tensor([0.4215, 0.5785], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,181 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,181 - train - INFO - True
2024-04-02 13:38:53,182 - train - INFO - alphas:tensor([0.2501, 0.7499], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,182 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,182 - train - INFO - True
2024-04-02 13:38:53,183 - train - INFO - alphas:tensor([0.3800, 0.6200], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,183 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,184 - train - INFO - True
2024-04-02 13:38:53,185 - train - INFO - alphas:tensor([0.5270, 0.4730], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,185 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,185 - train - INFO - True
2024-04-02 13:38:53,186 - train - INFO - alphas:tensor([0.4007, 0.5993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,186 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,187 - train - INFO - True
2024-04-02 13:38:53,187 - train - INFO - alphas:tensor([0.2645, 0.7355], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,188 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,188 - train - INFO - True
2024-04-02 13:38:53,189 - train - INFO - alphas:tensor([0.3766, 0.6234], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,189 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,194 - train - INFO - True
2024-04-02 13:38:53,195 - train - INFO - alphas:tensor([0.4657, 0.5343], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,195 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,195 - train - INFO - True
2024-04-02 13:38:53,196 - train - INFO - alphas:tensor([0.3253, 0.6747], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,196 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,197 - train - INFO - True
2024-04-02 13:38:53,197 - train - INFO - alphas:tensor([0.2332, 0.7668], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,198 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,198 - train - INFO - True
2024-04-02 13:38:53,199 - train - INFO - alphas:tensor([0.2845, 0.7155], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,199 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,199 - train - INFO - True
2024-04-02 13:38:53,200 - train - INFO - alphas:tensor([0.3281, 0.6719], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,200 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,201 - train - INFO - True
2024-04-02 13:38:53,202 - train - INFO - alphas:tensor([0.1443, 0.8557], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,202 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,202 - train - INFO - True
2024-04-02 13:38:53,207 - train - INFO - alphas:tensor([0.1736, 0.8264], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,208 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,208 - train - INFO - True
2024-04-02 13:38:53,209 - train - INFO - alphas:tensor([0.2056, 0.7944], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,209 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,209 - train - INFO - True
2024-04-02 13:38:53,210 - train - INFO - alphas:tensor([0.2759, 0.7241], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,210 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,211 - train - INFO - True
2024-04-02 13:38:53,212 - train - INFO - alphas:tensor([0.0439, 0.9561], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,212 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,212 - train - INFO - True
2024-04-02 13:38:53,213 - train - INFO - alphas:tensor([0.1033, 0.8967], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,213 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,213 - train - INFO - True
2024-04-02 13:38:53,214 - train - INFO - alphas:tensor([0.0113, 0.9887], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,215 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,215 - train - INFO - True
2024-04-02 13:38:53,216 - train - INFO - alphas:tensor([0.0024, 0.9976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,216 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,216 - train - INFO - True
2024-04-02 13:38:53,217 - train - INFO - alphas:tensor([1.4304e-04, 9.9986e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,217 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,218 - train - INFO - True
2024-04-02 13:38:53,218 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:38:53,219 - train - INFO - tau:0.4658807751697934
2024-04-02 13:38:53,219 - train - INFO - avg block size:13.931034482758621
2024-04-02 13:38:55,052 - train - INFO - Test: [   0/39]  Time: 1.830 (1.830)  Loss:  0.3987 (0.3987)  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)
2024-04-02 13:40:06,122 - train - INFO - Test: [  39/39]  Time: 1.803 (1.822)  Loss:  0.3582 (0.3802)  Acc@1: 93.7500 (92.0400)  Acc@5: 100.0000 (99.7200)
2024-04-02 13:40:10,123 - train - INFO - Train: 79 [   0/195 (  0%)]  Loss:  1.498401 (1.4984)  Time: 3.687s,   69.43/s  (3.687s,   69.43/s)  LR: 2.574e-04  Data: 0.337 (0.337)
2024-04-02 13:42:37,228 - train - INFO - Train: 79 [  50/195 ( 26%)]  Loss:  1.342897 (1.5605)  Time: 3.271s,   78.27/s  (2.956s,   86.60/s)  LR: 2.574e-04  Data: 0.006 (0.021)
2024-04-02 13:45:05,152 - train - INFO - Train: 79 [ 100/195 ( 52%)]  Loss:  1.807107 (1.5602)  Time: 2.655s,   96.42/s  (2.957s,   86.56/s)  LR: 2.574e-04  Data: 0.005 (0.019)
2024-04-02 13:47:36,620 - train - INFO - Train: 79 [ 150/195 ( 77%)]  Loss:  1.252375 (1.5687)  Time: 2.743s,   93.31/s  (2.981s,   85.87/s)  LR: 2.574e-04  Data: 0.022 (0.018)
2024-04-02 13:49:48,516 - train - INFO - Train: 79 [ 194/195 (100%)]  Loss:  1.414955 (1.5721)  Time: 2.880s,   88.87/s  (2.985s,   85.77/s)  LR: 2.574e-04  Data: 0.000 (0.017)
2024-04-02 13:49:48,521 - train - INFO - True
2024-04-02 13:49:48,527 - train - INFO - alphas:tensor([0.0018, 0.9982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,527 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,527 - train - INFO - True
2024-04-02 13:49:48,528 - train - INFO - alphas:tensor([0.0722, 0.9278], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,528 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,528 - train - INFO - True
2024-04-02 13:49:48,528 - train - INFO - alphas:tensor([0.5217, 0.4783], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,529 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,529 - train - INFO - True
2024-04-02 13:49:48,529 - train - INFO - alphas:tensor([0.4587, 0.5413], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,529 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,529 - train - INFO - True
2024-04-02 13:49:48,530 - train - INFO - alphas:tensor([0.1375, 0.8625], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,530 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,531 - train - INFO - True
2024-04-02 13:49:48,532 - train - INFO - alphas:tensor([0.2385, 0.7615], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,536 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,536 - train - INFO - True
2024-04-02 13:49:48,537 - train - INFO - alphas:tensor([0.5253, 0.4747], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,553 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,553 - train - INFO - True
2024-04-02 13:49:48,554 - train - INFO - alphas:tensor([0.4210, 0.5790], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,554 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,554 - train - INFO - True
2024-04-02 13:49:48,555 - train - INFO - alphas:tensor([0.2475, 0.7525], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,555 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,556 - train - INFO - True
2024-04-02 13:49:48,557 - train - INFO - alphas:tensor([0.3785, 0.6215], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,557 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,557 - train - INFO - True
2024-04-02 13:49:48,558 - train - INFO - alphas:tensor([0.5273, 0.4727], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,558 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,558 - train - INFO - True
2024-04-02 13:49:48,559 - train - INFO - alphas:tensor([0.4007, 0.5993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,564 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,564 - train - INFO - True
2024-04-02 13:49:48,565 - train - INFO - alphas:tensor([0.2623, 0.7377], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,565 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,565 - train - INFO - True
2024-04-02 13:49:48,566 - train - INFO - alphas:tensor([0.3741, 0.6259], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,566 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,567 - train - INFO - True
2024-04-02 13:49:48,568 - train - INFO - alphas:tensor([0.4648, 0.5352], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,568 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,568 - train - INFO - True
2024-04-02 13:49:48,569 - train - INFO - alphas:tensor([0.3248, 0.6752], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,569 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,569 - train - INFO - True
2024-04-02 13:49:48,575 - train - INFO - alphas:tensor([0.2298, 0.7702], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,575 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,575 - train - INFO - True
2024-04-02 13:49:48,576 - train - INFO - alphas:tensor([0.2809, 0.7191], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,576 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,576 - train - INFO - True
2024-04-02 13:49:48,577 - train - INFO - alphas:tensor([0.3293, 0.6707], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,577 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,578 - train - INFO - True
2024-04-02 13:49:48,578 - train - INFO - alphas:tensor([0.1444, 0.8556], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,583 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,583 - train - INFO - True
2024-04-02 13:49:48,584 - train - INFO - alphas:tensor([0.1715, 0.8285], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,584 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,585 - train - INFO - True
2024-04-02 13:49:48,585 - train - INFO - alphas:tensor([0.2050, 0.7950], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,586 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,586 - train - INFO - True
2024-04-02 13:49:48,587 - train - INFO - alphas:tensor([0.2739, 0.7261], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,587 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,587 - train - INFO - True
2024-04-02 13:49:48,592 - train - INFO - alphas:tensor([0.0413, 0.9587], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,593 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,593 - train - INFO - True
2024-04-02 13:49:48,594 - train - INFO - alphas:tensor([0.1019, 0.8981], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,594 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,594 - train - INFO - True
2024-04-02 13:49:48,595 - train - INFO - alphas:tensor([0.0102, 0.9898], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,595 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,595 - train - INFO - True
2024-04-02 13:49:48,605 - train - INFO - alphas:tensor([0.0021, 0.9979], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,606 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,606 - train - INFO - True
2024-04-02 13:49:48,607 - train - INFO - alphas:tensor([1.2617e-04, 9.9987e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,607 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,607 - train - INFO - True
2024-04-02 13:49:48,608 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 13:49:48,608 - train - INFO - tau:0.4612219674180955
2024-04-02 13:49:48,609 - train - INFO - avg block size:13.931034482758621
2024-04-02 13:49:50,627 - train - INFO - Test: [   0/39]  Time: 2.009 (2.009)  Loss:  0.3811 (0.3811)  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)
2024-04-02 13:51:02,750 - train - INFO - Test: [  39/39]  Time: 1.855 (1.853)  Loss:  0.3755 (0.3743)  Acc@1: 87.5000 (91.9400)  Acc@5: 100.0000 (99.7700)
2024-04-02 13:51:06,349 - train - INFO - Train: 80 [   0/195 (  0%)]  Loss:  1.293637 (1.2936)  Time: 3.304s,   77.49/s  (3.304s,   77.49/s)  LR: 2.518e-04  Data: 0.321 (0.321)
2024-04-02 13:53:32,581 - train - INFO - Train: 80 [  50/195 ( 26%)]  Loss:  1.759233 (1.6139)  Time: 3.442s,   74.37/s  (2.932s,   87.31/s)  LR: 2.518e-04  Data: 0.016 (0.022)
2024-04-02 13:56:00,010 - train - INFO - Train: 80 [ 100/195 ( 52%)]  Loss:  1.597635 (1.5978)  Time: 2.724s,   94.00/s  (2.940s,   87.07/s)  LR: 2.518e-04  Data: 0.021 (0.019)
2024-04-02 13:58:26,387 - train - INFO - Train: 80 [ 150/195 ( 77%)]  Loss:  1.843585 (1.6027)  Time: 2.662s,   96.16/s  (2.936s,   87.20/s)  LR: 2.518e-04  Data: 0.035 (0.018)
2024-04-02 14:00:37,965 - train - INFO - Train: 80 [ 194/195 (100%)]  Loss:  1.845774 (1.5955)  Time: 2.599s,   98.49/s  (2.948s,   86.83/s)  LR: 2.518e-04  Data: 0.000 (0.017)
2024-04-02 14:00:37,966 - train - INFO - True
2024-04-02 14:00:37,969 - train - INFO - alphas:tensor([0.0016, 0.9984], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:37,974 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:37,974 - train - INFO - True
2024-04-02 14:00:37,975 - train - INFO - alphas:tensor([0.0713, 0.9287], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:37,975 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:37,975 - train - INFO - True
2024-04-02 14:00:37,980 - train - INFO - alphas:tensor([0.5202, 0.4798], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:37,981 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:37,981 - train - INFO - True
2024-04-02 14:00:37,982 - train - INFO - alphas:tensor([0.4569, 0.5431], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:37,982 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:37,982 - train - INFO - True
2024-04-02 14:00:37,983 - train - INFO - alphas:tensor([0.1349, 0.8651], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:37,983 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:37,984 - train - INFO - True
2024-04-02 14:00:37,984 - train - INFO - alphas:tensor([0.2366, 0.7634], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:37,985 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:37,985 - train - INFO - True
2024-04-02 14:00:37,986 - train - INFO - alphas:tensor([0.5243, 0.4757], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:37,986 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:37,986 - train - INFO - True
2024-04-02 14:00:37,987 - train - INFO - alphas:tensor([0.4202, 0.5798], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:37,987 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:37,987 - train - INFO - True
2024-04-02 14:00:37,988 - train - INFO - alphas:tensor([0.2454, 0.7546], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:37,989 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:37,989 - train - INFO - True
2024-04-02 14:00:37,990 - train - INFO - alphas:tensor([0.3774, 0.6226], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:37,990 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:37,990 - train - INFO - True
2024-04-02 14:00:37,991 - train - INFO - alphas:tensor([0.5247, 0.4753], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:37,991 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:37,991 - train - INFO - True
2024-04-02 14:00:37,992 - train - INFO - alphas:tensor([0.3998, 0.6002], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:37,992 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:37,993 - train - INFO - True
2024-04-02 14:00:37,993 - train - INFO - alphas:tensor([0.2621, 0.7379], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:37,994 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:37,994 - train - INFO - True
2024-04-02 14:00:37,995 - train - INFO - alphas:tensor([0.3741, 0.6259], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:37,995 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:37,995 - train - INFO - True
2024-04-02 14:00:38,000 - train - INFO - alphas:tensor([0.4626, 0.5374], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,000 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,001 - train - INFO - True
2024-04-02 14:00:38,001 - train - INFO - alphas:tensor([0.3236, 0.6764], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,002 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,006 - train - INFO - True
2024-04-02 14:00:38,007 - train - INFO - alphas:tensor([0.2270, 0.7730], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,007 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,008 - train - INFO - True
2024-04-02 14:00:38,008 - train - INFO - alphas:tensor([0.2781, 0.7219], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,009 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,009 - train - INFO - True
2024-04-02 14:00:38,010 - train - INFO - alphas:tensor([0.3250, 0.6750], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,010 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,010 - train - INFO - True
2024-04-02 14:00:38,011 - train - INFO - alphas:tensor([0.1406, 0.8594], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,011 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,011 - train - INFO - True
2024-04-02 14:00:38,012 - train - INFO - alphas:tensor([0.1696, 0.8304], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,012 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,013 - train - INFO - True
2024-04-02 14:00:38,013 - train - INFO - alphas:tensor([0.2042, 0.7958], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,014 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,014 - train - INFO - True
2024-04-02 14:00:38,015 - train - INFO - alphas:tensor([0.2723, 0.7277], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,015 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,015 - train - INFO - True
2024-04-02 14:00:38,016 - train - INFO - alphas:tensor([0.0387, 0.9613], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,016 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,017 - train - INFO - True
2024-04-02 14:00:38,017 - train - INFO - alphas:tensor([0.1008, 0.8992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,018 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,018 - train - INFO - True
2024-04-02 14:00:38,019 - train - INFO - alphas:tensor([0.0093, 0.9907], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,019 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,019 - train - INFO - True
2024-04-02 14:00:38,020 - train - INFO - alphas:tensor([0.0019, 0.9981], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,020 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,020 - train - INFO - True
2024-04-02 14:00:38,021 - train - INFO - alphas:tensor([1.1126e-04, 9.9989e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,021 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,022 - train - INFO - True
2024-04-02 14:00:38,022 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:00:38,023 - train - INFO - tau:0.45660974774391455
2024-04-02 14:00:38,023 - train - INFO - avg block size:13.931034482758621
2024-04-02 14:00:39,880 - train - INFO - Test: [   0/39]  Time: 1.854 (1.854)  Loss:  0.4016 (0.4016)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-04-02 14:01:51,150 - train - INFO - Test: [  39/39]  Time: 1.908 (1.828)  Loss:  0.4482 (0.3882)  Acc@1: 81.2500 (91.9200)  Acc@5: 100.0000 (99.6900)
2024-04-02 14:01:55,340 - train - INFO - Train: 81 [   0/195 (  0%)]  Loss:  1.534450 (1.5344)  Time: 3.860s,   66.33/s  (3.860s,   66.33/s)  LR: 2.462e-04  Data: 0.293 (0.293)
2024-04-02 14:04:23,911 - train - INFO - Train: 81 [  50/195 ( 26%)]  Loss:  1.676450 (1.6244)  Time: 3.064s,   83.54/s  (2.989s,   85.65/s)  LR: 2.462e-04  Data: 0.014 (0.019)
2024-04-02 14:06:50,956 - train - INFO - Train: 81 [ 100/195 ( 52%)]  Loss:  1.656795 (1.5834)  Time: 2.652s,   96.53/s  (2.965s,   86.34/s)  LR: 2.462e-04  Data: 0.010 (0.017)
2024-04-02 14:09:18,281 - train - INFO - Train: 81 [ 150/195 ( 77%)]  Loss:  1.355965 (1.6012)  Time: 3.100s,   82.57/s  (2.959s,   86.52/s)  LR: 2.462e-04  Data: 0.005 (0.016)
2024-04-02 14:11:29,522 - train - INFO - Train: 81 [ 194/195 (100%)]  Loss:  1.803719 (1.5887)  Time: 3.124s,   81.94/s  (2.964s,   86.36/s)  LR: 2.462e-04  Data: 0.000 (0.015)
2024-04-02 14:11:29,522 - train - INFO - True
2024-04-02 14:11:29,523 - train - INFO - alphas:tensor([0.0014, 0.9986], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,524 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,524 - train - INFO - True
2024-04-02 14:11:29,525 - train - INFO - alphas:tensor([0.0700, 0.9300], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,525 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,525 - train - INFO - True
2024-04-02 14:11:29,526 - train - INFO - alphas:tensor([0.5195, 0.4805], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,526 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,526 - train - INFO - True
2024-04-02 14:11:29,528 - train - INFO - alphas:tensor([0.4548, 0.5452], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,528 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,528 - train - INFO - True
2024-04-02 14:11:29,533 - train - INFO - alphas:tensor([0.1344, 0.8656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,533 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,534 - train - INFO - True
2024-04-02 14:11:29,535 - train - INFO - alphas:tensor([0.2353, 0.7647], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,535 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,535 - train - INFO - True
2024-04-02 14:11:29,536 - train - INFO - alphas:tensor([0.5217, 0.4783], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,536 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,536 - train - INFO - True
2024-04-02 14:11:29,537 - train - INFO - alphas:tensor([0.4164, 0.5836], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,537 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,538 - train - INFO - True
2024-04-02 14:11:29,538 - train - INFO - alphas:tensor([0.2442, 0.7558], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,539 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,539 - train - INFO - True
2024-04-02 14:11:29,540 - train - INFO - alphas:tensor([0.3768, 0.6232], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,540 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,540 - train - INFO - True
2024-04-02 14:11:29,554 - train - INFO - alphas:tensor([0.5249, 0.4751], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,555 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,555 - train - INFO - True
2024-04-02 14:11:29,556 - train - INFO - alphas:tensor([0.3972, 0.6028], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,556 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,556 - train - INFO - True
2024-04-02 14:11:29,557 - train - INFO - alphas:tensor([0.2615, 0.7385], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,557 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,557 - train - INFO - True
2024-04-02 14:11:29,558 - train - INFO - alphas:tensor([0.3715, 0.6285], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,558 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,559 - train - INFO - True
2024-04-02 14:11:29,559 - train - INFO - alphas:tensor([0.4628, 0.5372], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,560 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,560 - train - INFO - True
2024-04-02 14:11:29,561 - train - INFO - alphas:tensor([0.3235, 0.6765], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,561 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,561 - train - INFO - True
2024-04-02 14:11:29,562 - train - INFO - alphas:tensor([0.2266, 0.7734], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,562 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,563 - train - INFO - True
2024-04-02 14:11:29,563 - train - INFO - alphas:tensor([0.2755, 0.7245], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,564 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,564 - train - INFO - True
2024-04-02 14:11:29,565 - train - INFO - alphas:tensor([0.3230, 0.6770], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,565 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,565 - train - INFO - True
2024-04-02 14:11:29,566 - train - INFO - alphas:tensor([0.1381, 0.8619], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,566 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,571 - train - INFO - True
2024-04-02 14:11:29,572 - train - INFO - alphas:tensor([0.1681, 0.8319], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,572 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,572 - train - INFO - True
2024-04-02 14:11:29,573 - train - INFO - alphas:tensor([0.2018, 0.7982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,573 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,587 - train - INFO - True
2024-04-02 14:11:29,587 - train - INFO - alphas:tensor([0.2714, 0.7286], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,588 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,588 - train - INFO - True
2024-04-02 14:11:29,589 - train - INFO - alphas:tensor([0.0364, 0.9636], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,589 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,589 - train - INFO - True
2024-04-02 14:11:29,590 - train - INFO - alphas:tensor([0.0997, 0.9003], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,590 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,591 - train - INFO - True
2024-04-02 14:11:29,591 - train - INFO - alphas:tensor([0.0084, 0.9916], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,592 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,592 - train - INFO - True
2024-04-02 14:11:29,593 - train - INFO - alphas:tensor([0.0017, 0.9983], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,593 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,593 - train - INFO - True
2024-04-02 14:11:29,594 - train - INFO - alphas:tensor([9.8122e-05, 9.9990e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,594 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,594 - train - INFO - True
2024-04-02 14:11:29,595 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:11:29,595 - train - INFO - tau:0.4520436502664754
2024-04-02 14:11:29,600 - train - INFO - avg block size:13.931034482758621
2024-04-02 14:11:31,529 - train - INFO - Test: [   0/39]  Time: 1.925 (1.925)  Loss:  0.3687 (0.3687)  Acc@1: 91.0156 (91.0156)  Acc@5: 100.0000 (100.0000)
2024-04-02 14:12:44,506 - train - INFO - Test: [  39/39]  Time: 1.818 (1.873)  Loss:  0.3789 (0.3698)  Acc@1: 87.5000 (91.8300)  Acc@5: 100.0000 (99.7000)
2024-04-02 14:12:48,126 - train - INFO - Train: 82 [   0/195 (  0%)]  Loss:  1.434184 (1.4342)  Time: 3.365s,   76.09/s  (3.365s,   76.09/s)  LR: 2.406e-04  Data: 0.409 (0.409)
2024-04-02 14:15:19,236 - train - INFO - Train: 82 [  50/195 ( 26%)]  Loss:  1.863329 (1.5843)  Time: 2.671s,   95.84/s  (3.029s,   84.52/s)  LR: 2.406e-04  Data: 0.035 (0.024)
2024-04-02 14:17:48,920 - train - INFO - Train: 82 [ 100/195 ( 52%)]  Loss:  1.238471 (1.5730)  Time: 2.769s,   92.47/s  (3.011s,   85.01/s)  LR: 2.406e-04  Data: 0.005 (0.021)
2024-04-02 14:20:17,722 - train - INFO - Train: 82 [ 150/195 ( 77%)]  Loss:  1.721849 (1.5817)  Time: 2.938s,   87.12/s  (3.000s,   85.34/s)  LR: 2.406e-04  Data: 0.014 (0.019)
2024-04-02 14:22:29,230 - train - INFO - Train: 82 [ 194/195 (100%)]  Loss:  1.818933 (1.5956)  Time: 3.146s,   81.38/s  (2.997s,   85.41/s)  LR: 2.406e-04  Data: 0.000 (0.017)
2024-04-02 14:22:29,231 - train - INFO - True
2024-04-02 14:22:29,232 - train - INFO - alphas:tensor([0.0013, 0.9987], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,232 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,232 - train - INFO - True
2024-04-02 14:22:29,233 - train - INFO - alphas:tensor([0.0684, 0.9316], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,233 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,234 - train - INFO - True
2024-04-02 14:22:29,235 - train - INFO - alphas:tensor([0.5190, 0.4810], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,235 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,235 - train - INFO - True
2024-04-02 14:22:29,236 - train - INFO - alphas:tensor([0.4537, 0.5463], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,236 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,236 - train - INFO - True
2024-04-02 14:22:29,237 - train - INFO - alphas:tensor([0.1330, 0.8670], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,237 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,238 - train - INFO - True
2024-04-02 14:22:29,238 - train - INFO - alphas:tensor([0.2348, 0.7652], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,239 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,239 - train - INFO - True
2024-04-02 14:22:29,240 - train - INFO - alphas:tensor([0.5220, 0.4780], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,240 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,241 - train - INFO - True
2024-04-02 14:22:29,242 - train - INFO - alphas:tensor([0.4158, 0.5842], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,242 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,242 - train - INFO - True
2024-04-02 14:22:29,243 - train - INFO - alphas:tensor([0.2436, 0.7564], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,243 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,243 - train - INFO - True
2024-04-02 14:22:29,244 - train - INFO - alphas:tensor([0.3754, 0.6246], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,245 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,245 - train - INFO - True
2024-04-02 14:22:29,246 - train - INFO - alphas:tensor([0.5232, 0.4768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,246 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,250 - train - INFO - True
2024-04-02 14:22:29,251 - train - INFO - alphas:tensor([0.3961, 0.6039], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,252 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,252 - train - INFO - True
2024-04-02 14:22:29,253 - train - INFO - alphas:tensor([0.2589, 0.7411], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,253 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,253 - train - INFO - True
2024-04-02 14:22:29,254 - train - INFO - alphas:tensor([0.3688, 0.6312], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,254 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,254 - train - INFO - True
2024-04-02 14:22:29,255 - train - INFO - alphas:tensor([0.4612, 0.5388], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,255 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,256 - train - INFO - True
2024-04-02 14:22:29,256 - train - INFO - alphas:tensor([0.3234, 0.6766], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,257 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,257 - train - INFO - True
2024-04-02 14:22:29,258 - train - INFO - alphas:tensor([0.2248, 0.7752], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,258 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,258 - train - INFO - True
2024-04-02 14:22:29,259 - train - INFO - alphas:tensor([0.2739, 0.7261], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,259 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,260 - train - INFO - True
2024-04-02 14:22:29,260 - train - INFO - alphas:tensor([0.3218, 0.6782], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,261 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,261 - train - INFO - True
2024-04-02 14:22:29,262 - train - INFO - alphas:tensor([0.1360, 0.8640], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,262 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,262 - train - INFO - True
2024-04-02 14:22:29,267 - train - INFO - alphas:tensor([0.1679, 0.8321], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,268 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,268 - train - INFO - True
2024-04-02 14:22:29,269 - train - INFO - alphas:tensor([0.1996, 0.8004], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,269 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,269 - train - INFO - True
2024-04-02 14:22:29,270 - train - INFO - alphas:tensor([0.2686, 0.7314], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,270 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,271 - train - INFO - True
2024-04-02 14:22:29,271 - train - INFO - alphas:tensor([0.0338, 0.9662], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,272 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,272 - train - INFO - True
2024-04-02 14:22:29,273 - train - INFO - alphas:tensor([0.0978, 0.9022], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,273 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,273 - train - INFO - True
2024-04-02 14:22:29,274 - train - INFO - alphas:tensor([0.0076, 0.9924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,274 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,274 - train - INFO - True
2024-04-02 14:22:29,275 - train - INFO - alphas:tensor([0.0015, 0.9985], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,275 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,276 - train - INFO - True
2024-04-02 14:22:29,276 - train - INFO - alphas:tensor([8.6535e-05, 9.9991e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,277 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,277 - train - INFO - True
2024-04-02 14:22:29,278 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:22:29,278 - train - INFO - tau:0.44752321376381066
2024-04-02 14:22:29,278 - train - INFO - avg block size:13.931034482758621
2024-04-02 14:22:31,153 - train - INFO - Test: [   0/39]  Time: 1.872 (1.872)  Loss:  0.3723 (0.3723)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-04-02 14:23:42,145 - train - INFO - Test: [  39/39]  Time: 1.840 (1.822)  Loss:  0.3435 (0.3745)  Acc@1: 87.5000 (92.0700)  Acc@5: 100.0000 (99.6800)
2024-04-02 14:23:46,302 - train - INFO - Train: 83 [   0/195 (  0%)]  Loss:  1.428713 (1.4287)  Time: 3.833s,   66.78/s  (3.833s,   66.78/s)  LR: 2.350e-04  Data: 0.478 (0.478)
2024-04-02 14:26:13,594 - train - INFO - Train: 83 [  50/195 ( 26%)]  Loss:  1.793742 (1.5794)  Time: 2.728s,   93.84/s  (2.963s,   86.39/s)  LR: 2.350e-04  Data: 0.033 (0.023)
2024-04-02 14:28:40,508 - train - INFO - Train: 83 [ 100/195 ( 52%)]  Loss:  1.842122 (1.5768)  Time: 2.726s,   93.90/s  (2.951s,   86.75/s)  LR: 2.350e-04  Data: 0.010 (0.019)
2024-04-02 14:31:08,634 - train - INFO - Train: 83 [ 150/195 ( 77%)]  Loss:  1.823865 (1.5747)  Time: 3.359s,   76.20/s  (2.955s,   86.64/s)  LR: 2.350e-04  Data: 0.023 (0.017)
2024-04-02 14:33:19,854 - train - INFO - Train: 83 [ 194/195 (100%)]  Loss:  1.850667 (1.5775)  Time: 3.424s,   74.77/s  (2.961s,   86.46/s)  LR: 2.350e-04  Data: 0.000 (0.017)
2024-04-02 14:33:19,855 - train - INFO - True
2024-04-02 14:33:19,856 - train - INFO - alphas:tensor([0.0011, 0.9988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,856 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,857 - train - INFO - True
2024-04-02 14:33:19,866 - train - INFO - alphas:tensor([0.0683, 0.9317], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,866 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,867 - train - INFO - True
2024-04-02 14:33:19,867 - train - INFO - alphas:tensor([0.5181, 0.4819], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,868 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,868 - train - INFO - True
2024-04-02 14:33:19,869 - train - INFO - alphas:tensor([0.4514, 0.5486], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,869 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,869 - train - INFO - True
2024-04-02 14:33:19,870 - train - INFO - alphas:tensor([0.1313, 0.8687], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,870 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,871 - train - INFO - True
2024-04-02 14:33:19,871 - train - INFO - alphas:tensor([0.2316, 0.7684], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,872 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,872 - train - INFO - True
2024-04-02 14:33:19,873 - train - INFO - alphas:tensor([0.5193, 0.4807], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,873 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,873 - train - INFO - True
2024-04-02 14:33:19,874 - train - INFO - alphas:tensor([0.4136, 0.5864], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,874 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,874 - train - INFO - True
2024-04-02 14:33:19,876 - train - INFO - alphas:tensor([0.2425, 0.7575], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,876 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,876 - train - INFO - True
2024-04-02 14:33:19,877 - train - INFO - alphas:tensor([0.3729, 0.6271], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,877 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,878 - train - INFO - True
2024-04-02 14:33:19,878 - train - INFO - alphas:tensor([0.5234, 0.4766], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,879 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,879 - train - INFO - True
2024-04-02 14:33:19,880 - train - INFO - alphas:tensor([0.3977, 0.6023], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,880 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,880 - train - INFO - True
2024-04-02 14:33:19,881 - train - INFO - alphas:tensor([0.2595, 0.7405], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,881 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,886 - train - INFO - True
2024-04-02 14:33:19,887 - train - INFO - alphas:tensor([0.3707, 0.6293], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,887 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,887 - train - INFO - True
2024-04-02 14:33:19,897 - train - INFO - alphas:tensor([0.4603, 0.5397], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,897 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,897 - train - INFO - True
2024-04-02 14:33:19,898 - train - INFO - alphas:tensor([0.3213, 0.6787], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,898 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,899 - train - INFO - True
2024-04-02 14:33:19,900 - train - INFO - alphas:tensor([0.2239, 0.7761], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,900 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,900 - train - INFO - True
2024-04-02 14:33:19,901 - train - INFO - alphas:tensor([0.2754, 0.7246], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,901 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,901 - train - INFO - True
2024-04-02 14:33:19,902 - train - INFO - alphas:tensor([0.3207, 0.6793], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,902 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,903 - train - INFO - True
2024-04-02 14:33:19,903 - train - INFO - alphas:tensor([0.1356, 0.8644], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,904 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,904 - train - INFO - True
2024-04-02 14:33:19,905 - train - INFO - alphas:tensor([0.1652, 0.8348], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,905 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,905 - train - INFO - True
2024-04-02 14:33:19,906 - train - INFO - alphas:tensor([0.1975, 0.8025], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,906 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,906 - train - INFO - True
2024-04-02 14:33:19,907 - train - INFO - alphas:tensor([0.2674, 0.7326], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,908 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,908 - train - INFO - True
2024-04-02 14:33:19,909 - train - INFO - alphas:tensor([0.0317, 0.9683], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,909 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,909 - train - INFO - True
2024-04-02 14:33:19,910 - train - INFO - alphas:tensor([0.0972, 0.9028], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,910 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,910 - train - INFO - True
2024-04-02 14:33:19,911 - train - INFO - alphas:tensor([0.0070, 0.9930], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,912 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,912 - train - INFO - True
2024-04-02 14:33:19,913 - train - INFO - alphas:tensor([0.0013, 0.9987], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,913 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,913 - train - INFO - True
2024-04-02 14:33:19,914 - train - INFO - alphas:tensor([7.6277e-05, 9.9992e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,914 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,914 - train - INFO - True
2024-04-02 14:33:19,915 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:33:19,915 - train - INFO - tau:0.44304798162617254
2024-04-02 14:33:19,916 - train - INFO - avg block size:13.931034482758621
2024-04-02 14:33:21,694 - train - INFO - Test: [   0/39]  Time: 1.771 (1.771)  Loss:  0.3794 (0.3794)  Acc@1: 91.4062 (91.4062)  Acc@5: 99.6094 (99.6094)
2024-04-02 14:34:33,730 - train - INFO - Test: [  39/39]  Time: 1.825 (1.845)  Loss:  0.4446 (0.3728)  Acc@1: 81.2500 (91.9200)  Acc@5: 100.0000 (99.7700)
2024-04-02 14:34:37,478 - train - INFO - Train: 84 [   0/195 (  0%)]  Loss:  1.474553 (1.4746)  Time: 3.497s,   73.21/s  (3.497s,   73.21/s)  LR: 2.294e-04  Data: 0.508 (0.508)
2024-04-02 14:37:07,827 - train - INFO - Train: 84 [  50/195 ( 26%)]  Loss:  1.690830 (1.5946)  Time: 2.999s,   85.36/s  (3.016s,   84.87/s)  LR: 2.294e-04  Data: 0.022 (0.023)
2024-04-02 14:39:35,684 - train - INFO - Train: 84 [ 100/195 ( 52%)]  Loss:  1.798377 (1.6114)  Time: 2.836s,   90.26/s  (2.987s,   85.70/s)  LR: 2.294e-04  Data: 0.017 (0.019)
2024-04-02 14:42:06,806 - train - INFO - Train: 84 [ 150/195 ( 77%)]  Loss:  1.821493 (1.5884)  Time: 2.954s,   86.65/s  (2.999s,   85.37/s)  LR: 2.294e-04  Data: 0.017 (0.017)
2024-04-02 14:44:19,334 - train - INFO - Train: 84 [ 194/195 (100%)]  Loss:  1.764427 (1.5853)  Time: 3.108s,   82.36/s  (3.002s,   85.28/s)  LR: 2.294e-04  Data: 0.000 (0.016)
2024-04-02 14:44:19,339 - train - INFO - True
2024-04-02 14:44:19,345 - train - INFO - alphas:tensor([0.0010, 0.9990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,345 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,346 - train - INFO - True
2024-04-02 14:44:19,347 - train - INFO - alphas:tensor([0.0677, 0.9323], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,347 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,347 - train - INFO - True
2024-04-02 14:44:19,348 - train - INFO - alphas:tensor([0.5166, 0.4834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,348 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,348 - train - INFO - True
2024-04-02 14:44:19,349 - train - INFO - alphas:tensor([0.4498, 0.5502], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,349 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,350 - train - INFO - True
2024-04-02 14:44:19,356 - train - INFO - alphas:tensor([0.1291, 0.8709], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,356 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,356 - train - INFO - True
2024-04-02 14:44:19,362 - train - INFO - alphas:tensor([0.2296, 0.7704], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,373 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,373 - train - INFO - True
2024-04-02 14:44:19,374 - train - INFO - alphas:tensor([0.5189, 0.4811], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,374 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,375 - train - INFO - True
2024-04-02 14:44:19,379 - train - INFO - alphas:tensor([0.4124, 0.5876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,380 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,397 - train - INFO - True
2024-04-02 14:44:19,398 - train - INFO - alphas:tensor([0.2415, 0.7585], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,398 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,399 - train - INFO - True
2024-04-02 14:44:19,400 - train - INFO - alphas:tensor([0.3716, 0.6284], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,409 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,409 - train - INFO - True
2024-04-02 14:44:19,410 - train - INFO - alphas:tensor([0.5209, 0.4791], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,410 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,410 - train - INFO - True
2024-04-02 14:44:19,411 - train - INFO - alphas:tensor([0.3936, 0.6064], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,421 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,421 - train - INFO - True
2024-04-02 14:44:19,422 - train - INFO - alphas:tensor([0.2579, 0.7421], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,435 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,435 - train - INFO - True
2024-04-02 14:44:19,436 - train - INFO - alphas:tensor([0.3704, 0.6296], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,436 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,436 - train - INFO - True
2024-04-02 14:44:19,437 - train - INFO - alphas:tensor([0.4592, 0.5408], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,437 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,438 - train - INFO - True
2024-04-02 14:44:19,439 - train - INFO - alphas:tensor([0.3190, 0.6810], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,439 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,439 - train - INFO - True
2024-04-02 14:44:19,440 - train - INFO - alphas:tensor([0.2220, 0.7780], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,441 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,441 - train - INFO - True
2024-04-02 14:44:19,442 - train - INFO - alphas:tensor([0.2756, 0.7244], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,442 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,442 - train - INFO - True
2024-04-02 14:44:19,443 - train - INFO - alphas:tensor([0.3193, 0.6807], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,443 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,443 - train - INFO - True
2024-04-02 14:44:19,444 - train - INFO - alphas:tensor([0.1332, 0.8668], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,444 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,445 - train - INFO - True
2024-04-02 14:44:19,445 - train - INFO - alphas:tensor([0.1639, 0.8361], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,446 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,446 - train - INFO - True
2024-04-02 14:44:19,447 - train - INFO - alphas:tensor([0.1952, 0.8048], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,447 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,447 - train - INFO - True
2024-04-02 14:44:19,448 - train - INFO - alphas:tensor([0.2671, 0.7329], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,448 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,449 - train - INFO - True
2024-04-02 14:44:19,449 - train - INFO - alphas:tensor([0.0295, 0.9705], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,450 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,450 - train - INFO - True
2024-04-02 14:44:19,451 - train - INFO - alphas:tensor([0.0961, 0.9039], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,451 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,451 - train - INFO - True
2024-04-02 14:44:19,465 - train - INFO - alphas:tensor([0.0063, 0.9937], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,466 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,466 - train - INFO - True
2024-04-02 14:44:19,467 - train - INFO - alphas:tensor([0.0012, 0.9988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,467 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,467 - train - INFO - True
2024-04-02 14:44:19,468 - train - INFO - alphas:tensor([6.7244e-05, 9.9993e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,468 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,468 - train - INFO - True
2024-04-02 14:44:19,469 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:44:19,469 - train - INFO - tau:0.4386175018099108
2024-04-02 14:44:19,470 - train - INFO - avg block size:13.931034482758621
2024-04-02 14:44:21,365 - train - INFO - Test: [   0/39]  Time: 1.892 (1.892)  Loss:  0.3811 (0.3811)  Acc@1: 91.7969 (91.7969)  Acc@5: 100.0000 (100.0000)
2024-04-02 14:45:33,140 - train - INFO - Test: [  39/39]  Time: 1.849 (1.842)  Loss:  0.3091 (0.3739)  Acc@1: 93.7500 (91.9100)  Acc@5: 100.0000 (99.7200)
2024-04-02 14:45:36,232 - train - INFO - Train: 85 [   0/195 (  0%)]  Loss:  1.420612 (1.4206)  Time: 2.860s,   89.50/s  (2.860s,   89.50/s)  LR: 2.239e-04  Data: 0.280 (0.280)
2024-04-02 14:48:05,383 - train - INFO - Train: 85 [  50/195 ( 26%)]  Loss:  1.777984 (1.5734)  Time: 2.755s,   92.93/s  (2.981s,   85.89/s)  LR: 2.239e-04  Data: 0.010 (0.021)
2024-04-02 14:50:35,455 - train - INFO - Train: 85 [ 100/195 ( 52%)]  Loss:  1.743065 (1.6138)  Time: 2.866s,   89.33/s  (2.991s,   85.59/s)  LR: 2.239e-04  Data: 0.019 (0.018)
2024-04-02 14:53:01,662 - train - INFO - Train: 85 [ 150/195 ( 77%)]  Loss:  1.618377 (1.6022)  Time: 3.175s,   80.62/s  (2.969s,   86.23/s)  LR: 2.239e-04  Data: 0.010 (0.017)
2024-04-02 14:55:13,328 - train - INFO - Train: 85 [ 194/195 (100%)]  Loss:  1.388775 (1.5904)  Time: 3.050s,   83.95/s  (2.974s,   86.08/s)  LR: 2.239e-04  Data: 0.000 (0.016)
2024-04-02 14:55:13,329 - train - INFO - True
2024-04-02 14:55:13,340 - train - INFO - alphas:tensor([9.3045e-04, 9.9907e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,340 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,341 - train - INFO - True
2024-04-02 14:55:13,341 - train - INFO - alphas:tensor([0.0661, 0.9339], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,342 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,342 - train - INFO - True
2024-04-02 14:55:13,347 - train - INFO - alphas:tensor([0.5161, 0.4839], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,347 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,348 - train - INFO - True
2024-04-02 14:55:13,348 - train - INFO - alphas:tensor([0.4489, 0.5511], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,349 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,349 - train - INFO - True
2024-04-02 14:55:13,350 - train - INFO - alphas:tensor([0.1280, 0.8720], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,350 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,351 - train - INFO - True
2024-04-02 14:55:13,352 - train - INFO - alphas:tensor([0.2287, 0.7713], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,352 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,352 - train - INFO - True
2024-04-02 14:55:13,353 - train - INFO - alphas:tensor([0.5177, 0.4823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,353 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,353 - train - INFO - True
2024-04-02 14:55:13,354 - train - INFO - alphas:tensor([0.4109, 0.5891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,354 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,355 - train - INFO - True
2024-04-02 14:55:13,369 - train - INFO - alphas:tensor([0.2408, 0.7592], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,369 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,369 - train - INFO - True
2024-04-02 14:55:13,370 - train - INFO - alphas:tensor([0.3710, 0.6290], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,370 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,370 - train - INFO - True
2024-04-02 14:55:13,371 - train - INFO - alphas:tensor([0.5211, 0.4789], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,372 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,372 - train - INFO - True
2024-04-02 14:55:13,373 - train - INFO - alphas:tensor([0.3922, 0.6078], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,373 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,373 - train - INFO - True
2024-04-02 14:55:13,374 - train - INFO - alphas:tensor([0.2553, 0.7447], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,374 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,374 - train - INFO - True
2024-04-02 14:55:13,375 - train - INFO - alphas:tensor([0.3658, 0.6342], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,375 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,376 - train - INFO - True
2024-04-02 14:55:13,377 - train - INFO - alphas:tensor([0.4583, 0.5417], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,377 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,377 - train - INFO - True
2024-04-02 14:55:13,382 - train - INFO - alphas:tensor([0.3191, 0.6809], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,383 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,383 - train - INFO - True
2024-04-02 14:55:13,384 - train - INFO - alphas:tensor([0.2226, 0.7774], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,384 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,384 - train - INFO - True
2024-04-02 14:55:13,385 - train - INFO - alphas:tensor([0.2736, 0.7264], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,385 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,385 - train - INFO - True
2024-04-02 14:55:13,386 - train - INFO - alphas:tensor([0.3169, 0.6831], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,386 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,391 - train - INFO - True
2024-04-02 14:55:13,392 - train - INFO - alphas:tensor([0.1303, 0.8697], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,392 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,392 - train - INFO - True
2024-04-02 14:55:13,393 - train - INFO - alphas:tensor([0.1633, 0.8367], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,393 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,394 - train - INFO - True
2024-04-02 14:55:13,403 - train - INFO - alphas:tensor([0.1948, 0.8052], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,403 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,404 - train - INFO - True
2024-04-02 14:55:13,405 - train - INFO - alphas:tensor([0.2663, 0.7337], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,405 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,405 - train - INFO - True
2024-04-02 14:55:13,406 - train - INFO - alphas:tensor([0.0276, 0.9724], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,406 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,406 - train - INFO - True
2024-04-02 14:55:13,407 - train - INFO - alphas:tensor([0.0952, 0.9048], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,407 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,408 - train - INFO - True
2024-04-02 14:55:13,409 - train - INFO - alphas:tensor([0.0057, 0.9943], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,422 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,422 - train - INFO - True
2024-04-02 14:55:13,423 - train - INFO - alphas:tensor([0.0010, 0.9990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,423 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,424 - train - INFO - True
2024-04-02 14:55:13,424 - train - INFO - alphas:tensor([5.9246e-05, 9.9994e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,425 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,425 - train - INFO - True
2024-04-02 14:55:13,426 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 14:55:13,426 - train - INFO - tau:0.4342313267918117
2024-04-02 14:55:13,426 - train - INFO - avg block size:13.931034482758621
2024-04-02 14:55:15,378 - train - INFO - Test: [   0/39]  Time: 1.949 (1.949)  Loss:  0.3779 (0.3779)  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)
2024-04-02 14:56:26,687 - train - INFO - Test: [  39/39]  Time: 1.893 (1.831)  Loss:  0.3655 (0.3687)  Acc@1: 87.5000 (92.1900)  Acc@5: 100.0000 (99.7200)
2024-04-02 14:56:30,302 - train - INFO - Train: 86 [   0/195 (  0%)]  Loss:  1.695011 (1.6950)  Time: 3.375s,   75.84/s  (3.375s,   75.84/s)  LR: 2.183e-04  Data: 0.300 (0.300)
2024-04-02 14:58:59,639 - train - INFO - Train: 86 [  50/195 ( 26%)]  Loss:  1.449258 (1.5539)  Time: 3.307s,   77.42/s  (2.994s,   85.49/s)  LR: 2.183e-04  Data: 0.005 (0.022)
2024-04-02 15:01:24,727 - train - INFO - Train: 86 [ 100/195 ( 52%)]  Loss:  1.334611 (1.5845)  Time: 3.093s,   82.75/s  (2.948s,   86.82/s)  LR: 2.183e-04  Data: 0.005 (0.018)
2024-04-02 15:03:54,369 - train - INFO - Train: 86 [ 150/195 ( 77%)]  Loss:  1.718758 (1.5946)  Time: 2.839s,   90.17/s  (2.963s,   86.39/s)  LR: 2.183e-04  Data: 0.015 (0.016)
2024-04-02 15:06:00,625 - train - INFO - Train: 86 [ 194/195 (100%)]  Loss:  1.329711 (1.5859)  Time: 3.216s,   79.60/s  (2.942s,   87.02/s)  LR: 2.183e-04  Data: 0.000 (0.016)
2024-04-02 15:06:00,634 - train - INFO - True
2024-04-02 15:06:00,635 - train - INFO - alphas:tensor([8.3624e-04, 9.9916e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,636 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,636 - train - INFO - True
2024-04-02 15:06:00,637 - train - INFO - alphas:tensor([0.0649, 0.9351], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,637 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,637 - train - INFO - True
2024-04-02 15:06:00,638 - train - INFO - alphas:tensor([0.5145, 0.4855], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,638 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,638 - train - INFO - True
2024-04-02 15:06:00,639 - train - INFO - alphas:tensor([0.4486, 0.5514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,639 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,639 - train - INFO - True
2024-04-02 15:06:00,640 - train - INFO - alphas:tensor([0.1267, 0.8733], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,640 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,640 - train - INFO - True
2024-04-02 15:06:00,641 - train - INFO - alphas:tensor([0.2280, 0.7720], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,641 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,642 - train - INFO - True
2024-04-02 15:06:00,642 - train - INFO - alphas:tensor([0.5173, 0.4827], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,652 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,652 - train - INFO - True
2024-04-02 15:06:00,653 - train - INFO - alphas:tensor([0.4123, 0.5877], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,653 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,654 - train - INFO - True
2024-04-02 15:06:00,654 - train - INFO - alphas:tensor([0.2392, 0.7608], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,655 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,655 - train - INFO - True
2024-04-02 15:06:00,656 - train - INFO - alphas:tensor([0.3696, 0.6304], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,656 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,656 - train - INFO - True
2024-04-02 15:06:00,657 - train - INFO - alphas:tensor([0.5202, 0.4798], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,657 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,658 - train - INFO - True
2024-04-02 15:06:00,658 - train - INFO - alphas:tensor([0.3911, 0.6089], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,659 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,659 - train - INFO - True
2024-04-02 15:06:00,660 - train - INFO - alphas:tensor([0.2551, 0.7449], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,660 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,660 - train - INFO - True
2024-04-02 15:06:00,661 - train - INFO - alphas:tensor([0.3675, 0.6325], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,661 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,661 - train - INFO - True
2024-04-02 15:06:00,663 - train - INFO - alphas:tensor([0.4566, 0.5434], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,663 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,663 - train - INFO - True
2024-04-02 15:06:00,664 - train - INFO - alphas:tensor([0.3174, 0.6826], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,664 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,664 - train - INFO - True
2024-04-02 15:06:00,665 - train - INFO - alphas:tensor([0.2201, 0.7799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,670 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,670 - train - INFO - True
2024-04-02 15:06:00,671 - train - INFO - alphas:tensor([0.2707, 0.7293], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,671 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,671 - train - INFO - True
2024-04-02 15:06:00,677 - train - INFO - alphas:tensor([0.3152, 0.6848], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,677 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,677 - train - INFO - True
2024-04-02 15:06:00,678 - train - INFO - alphas:tensor([0.1296, 0.8704], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,678 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,678 - train - INFO - True
2024-04-02 15:06:00,679 - train - INFO - alphas:tensor([0.1623, 0.8377], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,680 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,680 - train - INFO - True
2024-04-02 15:06:00,681 - train - INFO - alphas:tensor([0.1934, 0.8066], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,681 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,681 - train - INFO - True
2024-04-02 15:06:00,682 - train - INFO - alphas:tensor([0.2629, 0.7371], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,682 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,682 - train - INFO - True
2024-04-02 15:06:00,683 - train - INFO - alphas:tensor([0.0257, 0.9743], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,683 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,684 - train - INFO - True
2024-04-02 15:06:00,684 - train - INFO - alphas:tensor([0.0931, 0.9069], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,685 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,685 - train - INFO - True
2024-04-02 15:06:00,686 - train - INFO - alphas:tensor([0.0052, 0.9948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,686 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,686 - train - INFO - True
2024-04-02 15:06:00,687 - train - INFO - alphas:tensor([9.2514e-04, 9.9907e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,687 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,687 - train - INFO - True
2024-04-02 15:06:00,688 - train - INFO - alphas:tensor([5.2206e-05, 9.9995e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,688 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,689 - train - INFO - True
2024-04-02 15:06:00,689 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:06:00,690 - train - INFO - tau:0.4298890135238936
2024-04-02 15:06:00,690 - train - INFO - avg block size:13.931034482758621
2024-04-02 15:06:02,600 - train - INFO - Test: [   0/39]  Time: 1.898 (1.898)  Loss:  0.3958 (0.3958)  Acc@1: 91.7969 (91.7969)  Acc@5: 100.0000 (100.0000)
2024-04-02 15:07:12,296 - train - INFO - Test: [  39/39]  Time: 1.801 (1.790)  Loss:  0.3823 (0.3821)  Acc@1: 87.5000 (91.9000)  Acc@5: 100.0000 (99.6900)
2024-04-02 15:07:15,773 - train - INFO - Train: 87 [   0/195 (  0%)]  Loss:  1.558706 (1.5587)  Time: 3.112s,   82.25/s  (3.112s,   82.25/s)  LR: 2.129e-04  Data: 0.436 (0.436)
2024-04-02 15:09:43,619 - train - INFO - Train: 87 [  50/195 ( 26%)]  Loss:  1.237347 (1.5871)  Time: 2.744s,   93.29/s  (2.960s,   86.49/s)  LR: 2.129e-04  Data: 0.005 (0.024)
2024-04-02 15:12:08,379 - train - INFO - Train: 87 [ 100/195 ( 52%)]  Loss:  1.598883 (1.5969)  Time: 2.879s,   88.93/s  (2.928s,   87.44/s)  LR: 2.129e-04  Data: 0.014 (0.019)
2024-04-02 15:14:32,382 - train - INFO - Train: 87 [ 150/195 ( 77%)]  Loss:  1.628321 (1.5887)  Time: 2.543s,  100.67/s  (2.912s,   87.91/s)  LR: 2.129e-04  Data: 0.013 (0.017)
2024-04-02 15:16:42,627 - train - INFO - Train: 87 [ 194/195 (100%)]  Loss:  1.828329 (1.5845)  Time: 3.161s,   81.00/s  (2.923s,   87.59/s)  LR: 2.129e-04  Data: 0.000 (0.016)
2024-04-02 15:16:42,632 - train - INFO - True
2024-04-02 15:16:42,638 - train - INFO - alphas:tensor([7.5183e-04, 9.9925e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,638 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,638 - train - INFO - True
2024-04-02 15:16:42,639 - train - INFO - alphas:tensor([0.0642, 0.9358], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,639 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,640 - train - INFO - True
2024-04-02 15:16:42,640 - train - INFO - alphas:tensor([0.5151, 0.4849], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,641 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,641 - train - INFO - True
2024-04-02 15:16:42,642 - train - INFO - alphas:tensor([0.4469, 0.5531], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,646 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,647 - train - INFO - True
2024-04-02 15:16:42,647 - train - INFO - alphas:tensor([0.1246, 0.8754], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,648 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,648 - train - INFO - True
2024-04-02 15:16:42,649 - train - INFO - alphas:tensor([0.2266, 0.7734], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,649 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,649 - train - INFO - True
2024-04-02 15:16:42,650 - train - INFO - alphas:tensor([0.5160, 0.4840], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,651 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,651 - train - INFO - True
2024-04-02 15:16:42,652 - train - INFO - alphas:tensor([0.4083, 0.5917], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,652 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,652 - train - INFO - True
2024-04-02 15:16:42,653 - train - INFO - alphas:tensor([0.2374, 0.7626], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,653 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,654 - train - INFO - True
2024-04-02 15:16:42,655 - train - INFO - alphas:tensor([0.3676, 0.6324], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,655 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,655 - train - INFO - True
2024-04-02 15:16:42,660 - train - INFO - alphas:tensor([0.5178, 0.4822], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,661 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,661 - train - INFO - True
2024-04-02 15:16:42,662 - train - INFO - alphas:tensor([0.3900, 0.6100], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,662 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,662 - train - INFO - True
2024-04-02 15:16:42,668 - train - INFO - alphas:tensor([0.2532, 0.7468], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,668 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,669 - train - INFO - True
2024-04-02 15:16:42,669 - train - INFO - alphas:tensor([0.3663, 0.6337], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,670 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,670 - train - INFO - True
2024-04-02 15:16:42,670 - train - INFO - alphas:tensor([0.4547, 0.5453], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,671 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,671 - train - INFO - True
2024-04-02 15:16:42,672 - train - INFO - alphas:tensor([0.3153, 0.6847], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,672 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,672 - train - INFO - True
2024-04-02 15:16:42,673 - train - INFO - alphas:tensor([0.2191, 0.7809], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,673 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,673 - train - INFO - True
2024-04-02 15:16:42,674 - train - INFO - alphas:tensor([0.2702, 0.7298], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,674 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,675 - train - INFO - True
2024-04-02 15:16:42,675 - train - INFO - alphas:tensor([0.3146, 0.6854], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,676 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,676 - train - INFO - True
2024-04-02 15:16:42,677 - train - INFO - alphas:tensor([0.1279, 0.8721], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,677 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,677 - train - INFO - True
2024-04-02 15:16:42,678 - train - INFO - alphas:tensor([0.1615, 0.8385], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,678 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,678 - train - INFO - True
2024-04-02 15:16:42,679 - train - INFO - alphas:tensor([0.1915, 0.8085], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,680 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,680 - train - INFO - True
2024-04-02 15:16:42,681 - train - INFO - alphas:tensor([0.2603, 0.7397], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,681 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,681 - train - INFO - True
2024-04-02 15:16:42,682 - train - INFO - alphas:tensor([0.0239, 0.9761], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,682 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,682 - train - INFO - True
2024-04-02 15:16:42,683 - train - INFO - alphas:tensor([0.0913, 0.9087], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,683 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,683 - train - INFO - True
2024-04-02 15:16:42,689 - train - INFO - alphas:tensor([0.0047, 0.9953], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,689 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,689 - train - INFO - True
2024-04-02 15:16:42,690 - train - INFO - alphas:tensor([8.2324e-04, 9.9918e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,690 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,695 - train - INFO - True
2024-04-02 15:16:42,696 - train - INFO - alphas:tensor([4.5976e-05, 9.9995e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,696 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,696 - train - INFO - True
2024-04-02 15:16:42,697 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:16:42,697 - train - INFO - tau:0.42559012338865465
2024-04-02 15:16:42,697 - train - INFO - avg block size:13.931034482758621
2024-04-02 15:16:44,558 - train - INFO - Test: [   0/39]  Time: 1.859 (1.859)  Loss:  0.3755 (0.3755)  Acc@1: 92.5781 (92.5781)  Acc@5: 99.2188 (99.2188)
2024-04-02 15:17:55,789 - train - INFO - Test: [  39/39]  Time: 1.796 (1.827)  Loss:  0.3550 (0.3694)  Acc@1: 93.7500 (91.9800)  Acc@5: 100.0000 (99.6600)
2024-04-02 15:17:59,358 - train - INFO - Train: 88 [   0/195 (  0%)]  Loss:  1.785836 (1.7858)  Time: 3.348s,   76.46/s  (3.348s,   76.46/s)  LR: 2.074e-04  Data: 0.465 (0.465)
2024-04-02 15:20:23,856 - train - INFO - Train: 88 [  50/195 ( 26%)]  Loss:  1.530065 (1.5813)  Time: 2.541s,  100.76/s  (2.899s,   88.31/s)  LR: 2.074e-04  Data: 0.018 (0.023)
2024-04-02 15:22:52,242 - train - INFO - Train: 88 [ 100/195 ( 52%)]  Loss:  1.248399 (1.6136)  Time: 2.725s,   93.96/s  (2.933s,   87.29/s)  LR: 2.074e-04  Data: 0.014 (0.021)
2024-04-02 15:25:20,392 - train - INFO - Train: 88 [ 150/195 ( 77%)]  Loss:  1.474961 (1.6012)  Time: 2.780s,   92.08/s  (2.943s,   86.99/s)  LR: 2.074e-04  Data: 0.019 (0.019)
2024-04-02 15:27:31,274 - train - INFO - Train: 88 [ 194/195 (100%)]  Loss:  1.334458 (1.6045)  Time: 2.718s,   94.18/s  (2.950s,   86.78/s)  LR: 2.074e-04  Data: 0.000 (0.018)
2024-04-02 15:27:31,275 - train - INFO - True
2024-04-02 15:27:31,277 - train - INFO - alphas:tensor([6.7372e-04, 9.9933e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,277 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,278 - train - INFO - True
2024-04-02 15:27:31,278 - train - INFO - alphas:tensor([0.0632, 0.9368], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,279 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,279 - train - INFO - True
2024-04-02 15:27:31,284 - train - INFO - alphas:tensor([0.5156, 0.4844], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,284 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,285 - train - INFO - True
2024-04-02 15:27:31,286 - train - INFO - alphas:tensor([0.4465, 0.5535], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,286 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,286 - train - INFO - True
2024-04-02 15:27:31,287 - train - INFO - alphas:tensor([0.1236, 0.8764], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,287 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,287 - train - INFO - True
2024-04-02 15:27:31,288 - train - INFO - alphas:tensor([0.2249, 0.7751], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,288 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,289 - train - INFO - True
2024-04-02 15:27:31,289 - train - INFO - alphas:tensor([0.5144, 0.4856], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,290 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,291 - train - INFO - True
2024-04-02 15:27:31,291 - train - INFO - alphas:tensor([0.4096, 0.5904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,292 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,292 - train - INFO - True
2024-04-02 15:27:31,293 - train - INFO - alphas:tensor([0.2371, 0.7629], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,293 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,293 - train - INFO - True
2024-04-02 15:27:31,294 - train - INFO - alphas:tensor([0.3678, 0.6322], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,294 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,295 - train - INFO - True
2024-04-02 15:27:31,300 - train - INFO - alphas:tensor([0.5177, 0.4823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,300 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,300 - train - INFO - True
2024-04-02 15:27:31,301 - train - INFO - alphas:tensor([0.3892, 0.6108], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,301 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,302 - train - INFO - True
2024-04-02 15:27:31,302 - train - INFO - alphas:tensor([0.2521, 0.7479], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,303 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,303 - train - INFO - True
2024-04-02 15:27:31,304 - train - INFO - alphas:tensor([0.3633, 0.6367], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,304 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,304 - train - INFO - True
2024-04-02 15:27:31,305 - train - INFO - alphas:tensor([0.4528, 0.5472], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,305 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,305 - train - INFO - True
2024-04-02 15:27:31,306 - train - INFO - alphas:tensor([0.3126, 0.6874], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,307 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,307 - train - INFO - True
2024-04-02 15:27:31,308 - train - INFO - alphas:tensor([0.2185, 0.7815], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,308 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,308 - train - INFO - True
2024-04-02 15:27:31,309 - train - INFO - alphas:tensor([0.2705, 0.7295], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,309 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,309 - train - INFO - True
2024-04-02 15:27:31,310 - train - INFO - alphas:tensor([0.3151, 0.6849], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,311 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,311 - train - INFO - True
2024-04-02 15:27:31,312 - train - INFO - alphas:tensor([0.1257, 0.8743], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,312 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,312 - train - INFO - True
2024-04-02 15:27:31,313 - train - INFO - alphas:tensor([0.1591, 0.8409], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,313 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,313 - train - INFO - True
2024-04-02 15:27:31,314 - train - INFO - alphas:tensor([0.1901, 0.8099], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,314 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,315 - train - INFO - True
2024-04-02 15:27:31,315 - train - INFO - alphas:tensor([0.2601, 0.7399], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,316 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,316 - train - INFO - True
2024-04-02 15:27:31,317 - train - INFO - alphas:tensor([0.0223, 0.9777], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,317 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,317 - train - INFO - True
2024-04-02 15:27:31,323 - train - INFO - alphas:tensor([0.0898, 0.9102], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,323 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,323 - train - INFO - True
2024-04-02 15:27:31,328 - train - INFO - alphas:tensor([0.0042, 0.9958], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,328 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,329 - train - INFO - True
2024-04-02 15:27:31,329 - train - INFO - alphas:tensor([7.3055e-04, 9.9927e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,330 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,330 - train - INFO - True
2024-04-02 15:27:31,331 - train - INFO - alphas:tensor([4.0478e-05, 9.9996e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,331 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,331 - train - INFO - True
2024-04-02 15:27:31,332 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:27:31,332 - train - INFO - tau:0.4213342221547681
2024-04-02 15:27:31,332 - train - INFO - avg block size:13.931034482758621
2024-04-02 15:27:33,184 - train - INFO - Test: [   0/39]  Time: 1.848 (1.848)  Loss:  0.3831 (0.3831)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-04-02 15:28:42,281 - train - INFO - Test: [  39/39]  Time: 1.751 (1.774)  Loss:  0.4109 (0.3774)  Acc@1: 81.2500 (92.3100)  Acc@5: 100.0000 (99.7300)
2024-04-02 15:28:46,163 - train - INFO - Train: 89 [   0/195 (  0%)]  Loss:  1.711929 (1.7119)  Time: 3.431s,   74.62/s  (3.431s,   74.62/s)  LR: 2.020e-04  Data: 0.409 (0.409)
2024-04-02 15:31:12,192 - train - INFO - Train: 89 [  50/195 ( 26%)]  Loss:  1.769557 (1.6000)  Time: 3.174s,   80.65/s  (2.931s,   87.36/s)  LR: 2.020e-04  Data: 0.005 (0.020)
2024-04-02 15:33:38,493 - train - INFO - Train: 89 [ 100/195 ( 52%)]  Loss:  1.745020 (1.5927)  Time: 2.718s,   94.17/s  (2.928s,   87.42/s)  LR: 2.020e-04  Data: 0.005 (0.018)
2024-04-02 15:36:07,033 - train - INFO - Train: 89 [ 150/195 ( 77%)]  Loss:  1.245821 (1.5951)  Time: 3.603s,   71.06/s  (2.942s,   87.01/s)  LR: 2.020e-04  Data: 0.021 (0.018)
2024-04-02 15:38:16,692 - train - INFO - Train: 89 [ 194/195 (100%)]  Loss:  1.457526 (1.5830)  Time: 2.946s,   86.90/s  (2.943s,   86.98/s)  LR: 2.020e-04  Data: 0.000 (0.016)
2024-04-02 15:38:16,693 - train - INFO - True
2024-04-02 15:38:16,694 - train - INFO - alphas:tensor([6.0405e-04, 9.9940e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,695 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,695 - train - INFO - True
2024-04-02 15:38:16,695 - train - INFO - alphas:tensor([0.0620, 0.9380], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,696 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,696 - train - INFO - True
2024-04-02 15:38:16,696 - train - INFO - alphas:tensor([0.5154, 0.4846], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,696 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,697 - train - INFO - True
2024-04-02 15:38:16,697 - train - INFO - alphas:tensor([0.4459, 0.5541], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,697 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,697 - train - INFO - True
2024-04-02 15:38:16,698 - train - INFO - alphas:tensor([0.1225, 0.8775], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,698 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,698 - train - INFO - True
2024-04-02 15:38:16,704 - train - INFO - alphas:tensor([0.2239, 0.7761], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,704 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,705 - train - INFO - True
2024-04-02 15:38:16,706 - train - INFO - alphas:tensor([0.5132, 0.4868], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,706 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,706 - train - INFO - True
2024-04-02 15:38:16,707 - train - INFO - alphas:tensor([0.4076, 0.5924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,707 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,707 - train - INFO - True
2024-04-02 15:38:16,708 - train - INFO - alphas:tensor([0.2358, 0.7642], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,708 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,709 - train - INFO - True
2024-04-02 15:38:16,709 - train - INFO - alphas:tensor([0.3666, 0.6334], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,710 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,710 - train - INFO - True
2024-04-02 15:38:16,711 - train - INFO - alphas:tensor([0.5158, 0.4842], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,711 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,711 - train - INFO - True
2024-04-02 15:38:16,712 - train - INFO - alphas:tensor([0.3885, 0.6115], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,712 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,712 - train - INFO - True
2024-04-02 15:38:16,713 - train - INFO - alphas:tensor([0.2518, 0.7482], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,714 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,714 - train - INFO - True
2024-04-02 15:38:16,715 - train - INFO - alphas:tensor([0.3634, 0.6366], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,715 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,715 - train - INFO - True
2024-04-02 15:38:16,716 - train - INFO - alphas:tensor([0.4527, 0.5473], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,716 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,716 - train - INFO - True
2024-04-02 15:38:16,717 - train - INFO - alphas:tensor([0.3127, 0.6873], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,718 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,718 - train - INFO - True
2024-04-02 15:38:16,719 - train - INFO - alphas:tensor([0.2177, 0.7823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,719 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,719 - train - INFO - True
2024-04-02 15:38:16,720 - train - INFO - alphas:tensor([0.2706, 0.7294], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,720 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,720 - train - INFO - True
2024-04-02 15:38:16,721 - train - INFO - alphas:tensor([0.3126, 0.6874], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,721 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,722 - train - INFO - True
2024-04-02 15:38:16,723 - train - INFO - alphas:tensor([0.1232, 0.8768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,723 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,723 - train - INFO - True
2024-04-02 15:38:16,724 - train - INFO - alphas:tensor([0.1579, 0.8421], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,724 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,724 - train - INFO - True
2024-04-02 15:38:16,730 - train - INFO - alphas:tensor([0.1879, 0.8121], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,730 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,730 - train - INFO - True
2024-04-02 15:38:16,731 - train - INFO - alphas:tensor([0.2586, 0.7414], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,731 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,731 - train - INFO - True
2024-04-02 15:38:16,732 - train - INFO - alphas:tensor([0.0205, 0.9795], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,733 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,733 - train - INFO - True
2024-04-02 15:38:16,742 - train - INFO - alphas:tensor([0.0896, 0.9104], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,743 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,743 - train - INFO - True
2024-04-02 15:38:16,744 - train - INFO - alphas:tensor([0.0038, 0.9962], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,744 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,744 - train - INFO - True
2024-04-02 15:38:16,745 - train - INFO - alphas:tensor([6.4893e-04, 9.9935e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,745 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,745 - train - INFO - True
2024-04-02 15:38:16,746 - train - INFO - alphas:tensor([3.5617e-05, 9.9996e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,747 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,747 - train - INFO - True
2024-04-02 15:38:16,748 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:38:16,748 - train - INFO - tau:0.41712087993322045
2024-04-02 15:38:16,748 - train - INFO - avg block size:13.931034482758621
2024-04-02 15:38:18,690 - train - INFO - Test: [   0/39]  Time: 1.929 (1.929)  Loss:  0.3857 (0.3857)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-04-02 15:39:30,195 - train - INFO - Test: [  39/39]  Time: 1.855 (1.836)  Loss:  0.3914 (0.3873)  Acc@1: 87.5000 (92.0000)  Acc@5: 100.0000 (99.6900)
2024-04-02 15:39:33,133 - train - INFO - Train: 90 [   0/195 (  0%)]  Loss:  1.658652 (1.6587)  Time: 2.611s,   98.05/s  (2.611s,   98.05/s)  LR: 1.966e-04  Data: 0.301 (0.301)
2024-04-02 15:42:04,547 - train - INFO - Train: 90 [  50/195 ( 26%)]  Loss:  1.569756 (1.5683)  Time: 3.179s,   80.53/s  (3.020s,   84.77/s)  LR: 1.966e-04  Data: 0.009 (0.020)
2024-04-02 15:44:32,625 - train - INFO - Train: 90 [ 100/195 ( 52%)]  Loss:  1.443808 (1.5699)  Time: 2.979s,   85.92/s  (2.991s,   85.59/s)  LR: 1.966e-04  Data: 0.018 (0.017)
2024-04-02 15:47:05,900 - train - INFO - Train: 90 [ 150/195 ( 77%)]  Loss:  1.715915 (1.5853)  Time: 2.892s,   88.52/s  (3.016s,   84.89/s)  LR: 1.966e-04  Data: 0.010 (0.017)
2024-04-02 15:49:16,186 - train - INFO - Train: 90 [ 194/195 (100%)]  Loss:  1.667633 (1.5971)  Time: 3.297s,   77.64/s  (3.003s,   85.24/s)  LR: 1.966e-04  Data: 0.000 (0.017)
2024-04-02 15:49:16,187 - train - INFO - True
2024-04-02 15:49:16,188 - train - INFO - alphas:tensor([5.4185e-04, 9.9946e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,189 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,189 - train - INFO - True
2024-04-02 15:49:16,190 - train - INFO - alphas:tensor([0.0607, 0.9393], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,191 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,191 - train - INFO - True
2024-04-02 15:49:16,192 - train - INFO - alphas:tensor([0.5142, 0.4858], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,192 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,192 - train - INFO - True
2024-04-02 15:49:16,193 - train - INFO - alphas:tensor([0.4447, 0.5553], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,193 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,193 - train - INFO - True
2024-04-02 15:49:16,194 - train - INFO - alphas:tensor([0.1210, 0.8790], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,195 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,195 - train - INFO - True
2024-04-02 15:49:16,196 - train - INFO - alphas:tensor([0.2229, 0.7771], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,196 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,196 - train - INFO - True
2024-04-02 15:49:16,197 - train - INFO - alphas:tensor([0.5120, 0.4880], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,197 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,197 - train - INFO - True
2024-04-02 15:49:16,198 - train - INFO - alphas:tensor([0.4052, 0.5948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,199 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,199 - train - INFO - True
2024-04-02 15:49:16,200 - train - INFO - alphas:tensor([0.2342, 0.7658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,205 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,205 - train - INFO - True
2024-04-02 15:49:16,206 - train - INFO - alphas:tensor([0.3651, 0.6349], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,206 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,207 - train - INFO - True
2024-04-02 15:49:16,208 - train - INFO - alphas:tensor([0.5144, 0.4856], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,208 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,208 - train - INFO - True
2024-04-02 15:49:16,209 - train - INFO - alphas:tensor([0.3882, 0.6118], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,209 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,209 - train - INFO - True
2024-04-02 15:49:16,210 - train - INFO - alphas:tensor([0.2497, 0.7503], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,210 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,211 - train - INFO - True
2024-04-02 15:49:16,211 - train - INFO - alphas:tensor([0.3623, 0.6377], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,212 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,212 - train - INFO - True
2024-04-02 15:49:16,213 - train - INFO - alphas:tensor([0.4520, 0.5480], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,213 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,213 - train - INFO - True
2024-04-02 15:49:16,214 - train - INFO - alphas:tensor([0.3136, 0.6864], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,214 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,215 - train - INFO - True
2024-04-02 15:49:16,215 - train - INFO - alphas:tensor([0.2158, 0.7842], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,216 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,216 - train - INFO - True
2024-04-02 15:49:16,217 - train - INFO - alphas:tensor([0.2675, 0.7325], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,217 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,217 - train - INFO - True
2024-04-02 15:49:16,218 - train - INFO - alphas:tensor([0.3114, 0.6886], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,218 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,219 - train - INFO - True
2024-04-02 15:49:16,219 - train - INFO - alphas:tensor([0.1216, 0.8784], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,220 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,220 - train - INFO - True
2024-04-02 15:49:16,221 - train - INFO - alphas:tensor([0.1573, 0.8427], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,221 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,221 - train - INFO - True
2024-04-02 15:49:16,222 - train - INFO - alphas:tensor([0.1872, 0.8128], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,222 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,222 - train - INFO - True
2024-04-02 15:49:16,223 - train - INFO - alphas:tensor([0.2567, 0.7433], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,224 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,224 - train - INFO - True
2024-04-02 15:49:16,225 - train - INFO - alphas:tensor([0.0190, 0.9810], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,225 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,225 - train - INFO - True
2024-04-02 15:49:16,226 - train - INFO - alphas:tensor([0.0889, 0.9111], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,226 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,226 - train - INFO - True
2024-04-02 15:49:16,227 - train - INFO - alphas:tensor([0.0035, 0.9965], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,227 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,228 - train - INFO - True
2024-04-02 15:49:16,228 - train - INFO - alphas:tensor([5.7731e-04, 9.9942e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,229 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,229 - train - INFO - True
2024-04-02 15:49:16,230 - train - INFO - alphas:tensor([3.1358e-05, 9.9997e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,230 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,230 - train - INFO - True
2024-04-02 15:49:16,231 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 15:49:16,231 - train - INFO - tau:0.41294967113388825
2024-04-02 15:49:16,231 - train - INFO - avg block size:13.931034482758621
2024-04-02 15:49:18,188 - train - INFO - Test: [   0/39]  Time: 1.952 (1.952)  Loss:  0.3577 (0.3577)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-04-02 15:50:29,860 - train - INFO - Test: [  39/39]  Time: 1.841 (1.840)  Loss:  0.3667 (0.3648)  Acc@1: 87.5000 (91.9400)  Acc@5: 100.0000 (99.7000)
2024-04-02 15:50:33,167 - train - INFO - Train: 91 [   0/195 (  0%)]  Loss:  1.692747 (1.6927)  Time: 3.032s,   84.45/s  (3.032s,   84.45/s)  LR: 1.912e-04  Data: 0.269 (0.269)
2024-04-02 15:53:01,509 - train - INFO - Train: 91 [  50/195 ( 26%)]  Loss:  1.230447 (1.5537)  Time: 3.267s,   78.35/s  (2.968s,   86.26/s)  LR: 1.912e-04  Data: 0.005 (0.019)
2024-04-02 15:55:31,120 - train - INFO - Train: 91 [ 100/195 ( 52%)]  Loss:  1.594590 (1.5448)  Time: 2.702s,   94.74/s  (2.980s,   85.91/s)  LR: 1.912e-04  Data: 0.023 (0.017)
2024-04-02 15:57:59,711 - train - INFO - Train: 91 [ 150/195 ( 77%)]  Loss:  1.801682 (1.5601)  Time: 2.999s,   85.37/s  (2.977s,   85.99/s)  LR: 1.912e-04  Data: 0.010 (0.017)
2024-04-02 16:00:08,825 - train - INFO - Train: 91 [ 194/195 (100%)]  Loss:  1.525695 (1.5667)  Time: 2.693s,   95.05/s  (2.968s,   86.27/s)  LR: 1.912e-04  Data: 0.000 (0.016)
2024-04-02 16:00:08,826 - train - INFO - True
2024-04-02 16:00:08,828 - train - INFO - alphas:tensor([4.8677e-04, 9.9951e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,829 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,829 - train - INFO - True
2024-04-02 16:00:08,830 - train - INFO - alphas:tensor([0.0601, 0.9399], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,830 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,830 - train - INFO - True
2024-04-02 16:00:08,840 - train - INFO - alphas:tensor([0.5129, 0.4871], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,840 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,841 - train - INFO - True
2024-04-02 16:00:08,841 - train - INFO - alphas:tensor([0.4423, 0.5577], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,842 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,842 - train - INFO - True
2024-04-02 16:00:08,843 - train - INFO - alphas:tensor([0.1194, 0.8806], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,844 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,844 - train - INFO - True
2024-04-02 16:00:08,845 - train - INFO - alphas:tensor([0.2224, 0.7776], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,845 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,845 - train - INFO - True
2024-04-02 16:00:08,846 - train - INFO - alphas:tensor([0.5117, 0.4883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,846 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,846 - train - INFO - True
2024-04-02 16:00:08,847 - train - INFO - alphas:tensor([0.4053, 0.5947], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,847 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,848 - train - INFO - True
2024-04-02 16:00:08,849 - train - INFO - alphas:tensor([0.2340, 0.7660], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,849 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,849 - train - INFO - True
2024-04-02 16:00:08,850 - train - INFO - alphas:tensor([0.3648, 0.6352], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,850 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,850 - train - INFO - True
2024-04-02 16:00:08,851 - train - INFO - alphas:tensor([0.5142, 0.4858], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,851 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,852 - train - INFO - True
2024-04-02 16:00:08,852 - train - INFO - alphas:tensor([0.3878, 0.6122], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,853 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,853 - train - INFO - True
2024-04-02 16:00:08,854 - train - INFO - alphas:tensor([0.2489, 0.7511], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,854 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,854 - train - INFO - True
2024-04-02 16:00:08,855 - train - INFO - alphas:tensor([0.3626, 0.6374], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,856 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,856 - train - INFO - True
2024-04-02 16:00:08,857 - train - INFO - alphas:tensor([0.4508, 0.5492], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,857 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,857 - train - INFO - True
2024-04-02 16:00:08,867 - train - INFO - alphas:tensor([0.3122, 0.6878], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,867 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,867 - train - INFO - True
2024-04-02 16:00:08,868 - train - INFO - alphas:tensor([0.2156, 0.7844], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,868 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,869 - train - INFO - True
2024-04-02 16:00:08,870 - train - INFO - alphas:tensor([0.2659, 0.7341], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,870 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,870 - train - INFO - True
2024-04-02 16:00:08,871 - train - INFO - alphas:tensor([0.3096, 0.6904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,871 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,871 - train - INFO - True
2024-04-02 16:00:08,872 - train - INFO - alphas:tensor([0.1203, 0.8797], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,872 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,873 - train - INFO - True
2024-04-02 16:00:08,874 - train - INFO - alphas:tensor([0.1564, 0.8436], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,874 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,874 - train - INFO - True
2024-04-02 16:00:08,875 - train - INFO - alphas:tensor([0.1881, 0.8119], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,875 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,875 - train - INFO - True
2024-04-02 16:00:08,876 - train - INFO - alphas:tensor([0.2550, 0.7450], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,876 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,877 - train - INFO - True
2024-04-02 16:00:08,877 - train - INFO - alphas:tensor([0.0177, 0.9823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,878 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,878 - train - INFO - True
2024-04-02 16:00:08,879 - train - INFO - alphas:tensor([0.0873, 0.9127], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,879 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,879 - train - INFO - True
2024-04-02 16:00:08,880 - train - INFO - alphas:tensor([0.0031, 0.9969], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,880 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,881 - train - INFO - True
2024-04-02 16:00:08,881 - train - INFO - alphas:tensor([5.1428e-04, 9.9949e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,882 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,882 - train - INFO - True
2024-04-02 16:00:08,883 - train - INFO - alphas:tensor([2.7583e-05, 9.9997e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,883 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,883 - train - INFO - True
2024-04-02 16:00:08,884 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:00:08,884 - train - INFO - tau:0.40882017442254937
2024-04-02 16:00:08,884 - train - INFO - avg block size:13.931034482758621
2024-04-02 16:00:10,836 - train - INFO - Test: [   0/39]  Time: 1.949 (1.949)  Loss:  0.3887 (0.3887)  Acc@1: 91.0156 (91.0156)  Acc@5: 99.6094 (99.6094)
2024-04-02 16:01:23,391 - train - INFO - Test: [  39/39]  Time: 1.706 (1.863)  Loss:  0.4060 (0.3783)  Acc@1: 81.2500 (92.0800)  Acc@5: 100.0000 (99.7200)
2024-04-02 16:01:27,366 - train - INFO - Train: 92 [   0/195 (  0%)]  Loss:  1.692945 (1.6929)  Time: 3.799s,   67.39/s  (3.799s,   67.39/s)  LR: 1.859e-04  Data: 0.345 (0.345)
2024-04-02 16:03:55,529 - train - INFO - Train: 92 [  50/195 ( 26%)]  Loss:  1.768593 (1.6237)  Time: 2.756s,   92.90/s  (2.980s,   85.92/s)  LR: 1.859e-04  Data: 0.014 (0.019)
2024-04-02 16:06:23,236 - train - INFO - Train: 92 [ 100/195 ( 52%)]  Loss:  1.307373 (1.5795)  Time: 3.010s,   85.04/s  (2.967s,   86.29/s)  LR: 1.859e-04  Data: 0.014 (0.018)
2024-04-02 16:08:51,814 - train - INFO - Train: 92 [ 150/195 ( 77%)]  Loss:  1.757405 (1.5711)  Time: 3.374s,   75.87/s  (2.968s,   86.24/s)  LR: 1.859e-04  Data: 0.040 (0.018)
2024-04-02 16:11:02,740 - train - INFO - Train: 92 [ 194/195 (100%)]  Loss:  1.821430 (1.5681)  Time: 2.844s,   90.02/s  (2.970s,   86.20/s)  LR: 1.859e-04  Data: 0.000 (0.017)
2024-04-02 16:11:02,741 - train - INFO - True
2024-04-02 16:11:02,742 - train - INFO - alphas:tensor([4.3562e-04, 9.9956e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,742 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,742 - train - INFO - True
2024-04-02 16:11:02,743 - train - INFO - alphas:tensor([0.0593, 0.9407], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,743 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,743 - train - INFO - True
2024-04-02 16:11:02,744 - train - INFO - alphas:tensor([0.5133, 0.4867], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,744 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,744 - train - INFO - True
2024-04-02 16:11:02,745 - train - INFO - alphas:tensor([0.4419, 0.5581], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,745 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,745 - train - INFO - True
2024-04-02 16:11:02,746 - train - INFO - alphas:tensor([0.1182, 0.8818], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,746 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,746 - train - INFO - True
2024-04-02 16:11:02,747 - train - INFO - alphas:tensor([0.2228, 0.7772], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,747 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,747 - train - INFO - True
2024-04-02 16:11:02,748 - train - INFO - alphas:tensor([0.5115, 0.4885], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,748 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,749 - train - INFO - True
2024-04-02 16:11:02,750 - train - INFO - alphas:tensor([0.4044, 0.5956], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,750 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,750 - train - INFO - True
2024-04-02 16:11:02,751 - train - INFO - alphas:tensor([0.2327, 0.7673], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,751 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,752 - train - INFO - True
2024-04-02 16:11:02,752 - train - INFO - alphas:tensor([0.3659, 0.6341], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,753 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,753 - train - INFO - True
2024-04-02 16:11:02,754 - train - INFO - alphas:tensor([0.5126, 0.4874], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,754 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,754 - train - INFO - True
2024-04-02 16:11:02,755 - train - INFO - alphas:tensor([0.3869, 0.6131], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,755 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,755 - train - INFO - True
2024-04-02 16:11:02,756 - train - INFO - alphas:tensor([0.2486, 0.7514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,757 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,757 - train - INFO - True
2024-04-02 16:11:02,758 - train - INFO - alphas:tensor([0.3619, 0.6381], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,758 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,758 - train - INFO - True
2024-04-02 16:11:02,759 - train - INFO - alphas:tensor([0.4508, 0.5492], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,759 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,759 - train - INFO - True
2024-04-02 16:11:02,760 - train - INFO - alphas:tensor([0.3129, 0.6871], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,760 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,761 - train - INFO - True
2024-04-02 16:11:02,762 - train - INFO - alphas:tensor([0.2160, 0.7840], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,762 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,762 - train - INFO - True
2024-04-02 16:11:02,763 - train - INFO - alphas:tensor([0.2682, 0.7318], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,763 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,763 - train - INFO - True
2024-04-02 16:11:02,764 - train - INFO - alphas:tensor([0.3089, 0.6911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,764 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,765 - train - INFO - True
2024-04-02 16:11:02,765 - train - INFO - alphas:tensor([0.1186, 0.8814], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,766 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,766 - train - INFO - True
2024-04-02 16:11:02,767 - train - INFO - alphas:tensor([0.1555, 0.8445], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,767 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,767 - train - INFO - True
2024-04-02 16:11:02,768 - train - INFO - alphas:tensor([0.1859, 0.8141], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,768 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,769 - train - INFO - True
2024-04-02 16:11:02,769 - train - INFO - alphas:tensor([0.2545, 0.7455], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,770 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,770 - train - INFO - True
2024-04-02 16:11:02,771 - train - INFO - alphas:tensor([0.0164, 0.9836], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,771 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,771 - train - INFO - True
2024-04-02 16:11:02,772 - train - INFO - alphas:tensor([0.0864, 0.9136], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,772 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,773 - train - INFO - True
2024-04-02 16:11:02,773 - train - INFO - alphas:tensor([0.0028, 0.9972], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,774 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,774 - train - INFO - True
2024-04-02 16:11:02,775 - train - INFO - alphas:tensor([4.5733e-04, 9.9954e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,775 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,775 - train - INFO - True
2024-04-02 16:11:02,776 - train - INFO - alphas:tensor([2.4252e-05, 9.9998e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,776 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,776 - train - INFO - True
2024-04-02 16:11:02,777 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:11:02,777 - train - INFO - tau:0.4047319726783239
2024-04-02 16:11:02,778 - train - INFO - avg block size:13.931034482758621
2024-04-02 16:11:04,620 - train - INFO - Test: [   0/39]  Time: 1.839 (1.839)  Loss:  0.3833 (0.3833)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.6094 (99.6094)
2024-04-02 16:12:16,755 - train - INFO - Test: [  39/39]  Time: 1.825 (1.849)  Loss:  0.3845 (0.3707)  Acc@1: 81.2500 (92.0100)  Acc@5: 100.0000 (99.6800)
2024-04-02 16:12:20,034 - train - INFO - Train: 93 [   0/195 (  0%)]  Loss:  1.208588 (1.2086)  Time: 3.008s,   85.11/s  (3.008s,   85.11/s)  LR: 1.806e-04  Data: 0.282 (0.282)
2024-04-02 16:14:51,491 - train - INFO - Train: 93 [  50/195 ( 26%)]  Loss:  1.790292 (1.6165)  Time: 3.401s,   75.28/s  (3.029s,   84.53/s)  LR: 1.806e-04  Data: 0.014 (0.020)
2024-04-02 16:17:22,839 - train - INFO - Train: 93 [ 100/195 ( 52%)]  Loss:  1.477689 (1.5831)  Time: 3.025s,   84.64/s  (3.028s,   84.56/s)  LR: 1.806e-04  Data: 0.010 (0.018)
2024-04-02 16:19:51,359 - train - INFO - Train: 93 [ 150/195 ( 77%)]  Loss:  1.818262 (1.5992)  Time: 3.068s,   83.44/s  (3.009s,   85.09/s)  LR: 1.806e-04  Data: 0.009 (0.017)
2024-04-02 16:22:05,331 - train - INFO - Train: 93 [ 194/195 (100%)]  Loss:  1.709199 (1.5860)  Time: 3.551s,   72.09/s  (3.017s,   84.86/s)  LR: 1.806e-04  Data: 0.000 (0.017)
2024-04-02 16:22:05,333 - train - INFO - True
2024-04-02 16:22:05,334 - train - INFO - alphas:tensor([3.9063e-04, 9.9961e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,334 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,334 - train - INFO - True
2024-04-02 16:22:05,344 - train - INFO - alphas:tensor([0.0585, 0.9415], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,344 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,345 - train - INFO - True
2024-04-02 16:22:05,346 - train - INFO - alphas:tensor([0.5117, 0.4883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,346 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,347 - train - INFO - True
2024-04-02 16:22:05,348 - train - INFO - alphas:tensor([0.4402, 0.5598], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,348 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,348 - train - INFO - True
2024-04-02 16:22:05,349 - train - INFO - alphas:tensor([0.1164, 0.8836], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,350 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,350 - train - INFO - True
2024-04-02 16:22:05,351 - train - INFO - alphas:tensor([0.2198, 0.7802], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,351 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,351 - train - INFO - True
2024-04-02 16:22:05,357 - train - INFO - alphas:tensor([0.5105, 0.4895], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,357 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,357 - train - INFO - True
2024-04-02 16:22:05,358 - train - INFO - alphas:tensor([0.4038, 0.5962], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,358 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,359 - train - INFO - True
2024-04-02 16:22:05,360 - train - INFO - alphas:tensor([0.2302, 0.7698], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,360 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,360 - train - INFO - True
2024-04-02 16:22:05,361 - train - INFO - alphas:tensor([0.3632, 0.6368], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,361 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,362 - train - INFO - True
2024-04-02 16:22:05,363 - train - INFO - alphas:tensor([0.5120, 0.4880], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,363 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,363 - train - INFO - True
2024-04-02 16:22:05,364 - train - INFO - alphas:tensor([0.3874, 0.6126], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,364 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,365 - train - INFO - True
2024-04-02 16:22:05,366 - train - INFO - alphas:tensor([0.2468, 0.7532], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,370 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,370 - train - INFO - True
2024-04-02 16:22:05,371 - train - INFO - alphas:tensor([0.3615, 0.6385], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,372 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,372 - train - INFO - True
2024-04-02 16:22:05,373 - train - INFO - alphas:tensor([0.4505, 0.5495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,373 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,373 - train - INFO - True
2024-04-02 16:22:05,374 - train - INFO - alphas:tensor([0.3131, 0.6869], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,375 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,375 - train - INFO - True
2024-04-02 16:22:05,376 - train - INFO - alphas:tensor([0.2134, 0.7866], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,376 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,376 - train - INFO - True
2024-04-02 16:22:05,377 - train - INFO - alphas:tensor([0.2653, 0.7347], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,378 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,378 - train - INFO - True
2024-04-02 16:22:05,379 - train - INFO - alphas:tensor([0.3070, 0.6930], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,379 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,393 - train - INFO - True
2024-04-02 16:22:05,394 - train - INFO - alphas:tensor([0.1170, 0.8830], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,394 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,394 - train - INFO - True
2024-04-02 16:22:05,395 - train - INFO - alphas:tensor([0.1544, 0.8456], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,395 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,396 - train - INFO - True
2024-04-02 16:22:05,396 - train - INFO - alphas:tensor([0.1833, 0.8167], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,397 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,397 - train - INFO - True
2024-04-02 16:22:05,398 - train - INFO - alphas:tensor([0.2516, 0.7484], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,398 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,398 - train - INFO - True
2024-04-02 16:22:05,399 - train - INFO - alphas:tensor([0.0151, 0.9849], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,400 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,400 - train - INFO - True
2024-04-02 16:22:05,405 - train - INFO - alphas:tensor([0.0850, 0.9150], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,406 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,406 - train - INFO - True
2024-04-02 16:22:05,407 - train - INFO - alphas:tensor([0.0026, 0.9974], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,407 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,407 - train - INFO - True
2024-04-02 16:22:05,408 - train - INFO - alphas:tensor([4.0631e-04, 9.9959e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,409 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,409 - train - INFO - True
2024-04-02 16:22:05,410 - train - INFO - alphas:tensor([2.1310e-05, 9.9998e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,410 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,411 - train - INFO - True
2024-04-02 16:22:05,412 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:22:05,412 - train - INFO - tau:0.40068465295154065
2024-04-02 16:22:05,412 - train - INFO - avg block size:13.931034482758621
2024-04-02 16:22:07,353 - train - INFO - Test: [   0/39]  Time: 1.937 (1.937)  Loss:  0.3901 (0.3901)  Acc@1: 89.8438 (89.8438)  Acc@5: 100.0000 (100.0000)
2024-04-02 16:23:19,004 - train - INFO - Test: [  39/39]  Time: 1.877 (1.840)  Loss:  0.3538 (0.3772)  Acc@1: 87.5000 (91.8500)  Acc@5: 100.0000 (99.7400)
2024-04-02 16:23:23,183 - train - INFO - Train: 94 [   0/195 (  0%)]  Loss:  1.312108 (1.3121)  Time: 3.767s,   67.96/s  (3.767s,   67.96/s)  LR: 1.754e-04  Data: 0.344 (0.344)
2024-04-02 16:25:59,076 - train - INFO - Train: 94 [  50/195 ( 26%)]  Loss:  1.773748 (1.5811)  Time: 2.830s,   90.47/s  (3.131s,   81.77/s)  LR: 1.754e-04  Data: 0.012 (0.019)
2024-04-02 16:28:27,047 - train - INFO - Train: 94 [ 100/195 ( 52%)]  Loss:  1.723139 (1.5971)  Time: 2.880s,   88.88/s  (3.046s,   84.05/s)  LR: 1.754e-04  Data: 0.014 (0.017)
2024-04-02 16:30:56,508 - train - INFO - Train: 94 [ 150/195 ( 77%)]  Loss:  1.746742 (1.5919)  Time: 3.048s,   84.00/s  (3.027s,   84.57/s)  LR: 1.754e-04  Data: 0.016 (0.016)
2024-04-02 16:33:11,170 - train - INFO - Train: 94 [ 194/195 (100%)]  Loss:  1.645317 (1.5952)  Time: 2.827s,   90.57/s  (3.035s,   84.36/s)  LR: 1.754e-04  Data: 0.000 (0.015)
2024-04-02 16:33:11,171 - train - INFO - True
2024-04-02 16:33:11,172 - train - INFO - alphas:tensor([3.4978e-04, 9.9965e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,173 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,173 - train - INFO - True
2024-04-02 16:33:11,173 - train - INFO - alphas:tensor([0.0574, 0.9426], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,174 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,174 - train - INFO - True
2024-04-02 16:33:11,174 - train - INFO - alphas:tensor([0.5108, 0.4892], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,175 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,175 - train - INFO - True
2024-04-02 16:33:11,175 - train - INFO - alphas:tensor([0.4384, 0.5616], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,176 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,176 - train - INFO - True
2024-04-02 16:33:11,176 - train - INFO - alphas:tensor([0.1146, 0.8854], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,177 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,177 - train - INFO - True
2024-04-02 16:33:11,177 - train - INFO - alphas:tensor([0.2178, 0.7822], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,178 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,178 - train - INFO - True
2024-04-02 16:33:11,179 - train - INFO - alphas:tensor([0.5097, 0.4903], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,180 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,180 - train - INFO - True
2024-04-02 16:33:11,181 - train - INFO - alphas:tensor([0.4028, 0.5972], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,181 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,181 - train - INFO - True
2024-04-02 16:33:11,182 - train - INFO - alphas:tensor([0.2311, 0.7689], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,182 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,182 - train - INFO - True
2024-04-02 16:33:11,183 - train - INFO - alphas:tensor([0.3640, 0.6360], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,183 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,184 - train - INFO - True
2024-04-02 16:33:11,184 - train - INFO - alphas:tensor([0.5113, 0.4887], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,185 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,185 - train - INFO - True
2024-04-02 16:33:11,190 - train - INFO - alphas:tensor([0.3859, 0.6141], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,190 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,191 - train - INFO - True
2024-04-02 16:33:11,191 - train - INFO - alphas:tensor([0.2454, 0.7546], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,192 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,192 - train - INFO - True
2024-04-02 16:33:11,193 - train - INFO - alphas:tensor([0.3595, 0.6405], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,193 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,193 - train - INFO - True
2024-04-02 16:33:11,194 - train - INFO - alphas:tensor([0.4484, 0.5516], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,194 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,195 - train - INFO - True
2024-04-02 16:33:11,195 - train - INFO - alphas:tensor([0.3132, 0.6868], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,196 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,196 - train - INFO - True
2024-04-02 16:33:11,197 - train - INFO - alphas:tensor([0.2121, 0.7879], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,197 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,197 - train - INFO - True
2024-04-02 16:33:11,198 - train - INFO - alphas:tensor([0.2645, 0.7355], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,198 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,198 - train - INFO - True
2024-04-02 16:33:11,199 - train - INFO - alphas:tensor([0.3052, 0.6948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,200 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,200 - train - INFO - True
2024-04-02 16:33:11,201 - train - INFO - alphas:tensor([0.1143, 0.8857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,201 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,201 - train - INFO - True
2024-04-02 16:33:11,202 - train - INFO - alphas:tensor([0.1534, 0.8466], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,202 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,202 - train - INFO - True
2024-04-02 16:33:11,203 - train - INFO - alphas:tensor([0.1816, 0.8184], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,203 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,204 - train - INFO - True
2024-04-02 16:33:11,204 - train - INFO - alphas:tensor([0.2501, 0.7499], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,205 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,205 - train - INFO - True
2024-04-02 16:33:11,206 - train - INFO - alphas:tensor([0.0139, 0.9861], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,206 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,206 - train - INFO - True
2024-04-02 16:33:11,207 - train - INFO - alphas:tensor([0.0843, 0.9157], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,207 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,207 - train - INFO - True
2024-04-02 16:33:11,208 - train - INFO - alphas:tensor([0.0023, 0.9977], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,209 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,209 - train - INFO - True
2024-04-02 16:33:11,209 - train - INFO - alphas:tensor([3.6079e-04, 9.9964e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,210 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,210 - train - INFO - True
2024-04-02 16:33:11,211 - train - INFO - alphas:tensor([1.8719e-05, 9.9998e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,211 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,211 - train - INFO - True
2024-04-02 16:33:11,212 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:33:11,212 - train - INFO - tau:0.39667780642202527
2024-04-02 16:33:11,212 - train - INFO - avg block size:13.931034482758621
2024-04-02 16:33:13,060 - train - INFO - Test: [   0/39]  Time: 1.844 (1.844)  Loss:  0.3926 (0.3926)  Acc@1: 92.1875 (92.1875)  Acc@5: 99.6094 (99.6094)
2024-04-02 16:34:23,571 - train - INFO - Test: [  39/39]  Time: 1.702 (1.809)  Loss:  0.4636 (0.3770)  Acc@1: 81.2500 (92.0900)  Acc@5: 100.0000 (99.7300)
2024-04-02 16:34:27,309 - train - INFO - Train: 95 [   0/195 (  0%)]  Loss:  1.373232 (1.3732)  Time: 3.375s,   75.86/s  (3.375s,   75.86/s)  LR: 1.702e-04  Data: 0.244 (0.244)
2024-04-02 16:36:53,972 - train - INFO - Train: 95 [  50/195 ( 26%)]  Loss:  1.806700 (1.5940)  Time: 2.662s,   96.17/s  (2.942s,   87.02/s)  LR: 1.702e-04  Data: 0.024 (0.019)
2024-04-02 16:39:19,382 - train - INFO - Train: 95 [ 100/195 ( 52%)]  Loss:  1.847448 (1.5825)  Time: 2.827s,   90.55/s  (2.925s,   87.52/s)  LR: 1.702e-04  Data: 0.014 (0.018)
2024-04-02 16:41:45,670 - train - INFO - Train: 95 [ 150/195 ( 77%)]  Loss:  1.742231 (1.6008)  Time: 2.891s,   88.56/s  (2.925s,   87.51/s)  LR: 1.702e-04  Data: 0.014 (0.016)
2024-04-02 16:43:56,712 - train - INFO - Train: 95 [ 194/195 (100%)]  Loss:  1.793840 (1.5894)  Time: 2.708s,   94.54/s  (2.937s,   87.16/s)  LR: 1.702e-04  Data: 0.000 (0.015)
2024-04-02 16:43:56,713 - train - INFO - True
2024-04-02 16:43:56,715 - train - INFO - alphas:tensor([3.1343e-04, 9.9969e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,715 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,715 - train - INFO - True
2024-04-02 16:43:56,716 - train - INFO - alphas:tensor([0.0564, 0.9436], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,717 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,717 - train - INFO - True
2024-04-02 16:43:56,718 - train - INFO - alphas:tensor([0.5122, 0.4878], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,718 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,718 - train - INFO - True
2024-04-02 16:43:56,719 - train - INFO - alphas:tensor([0.4398, 0.5602], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,720 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,720 - train - INFO - True
2024-04-02 16:43:56,721 - train - INFO - alphas:tensor([0.1141, 0.8859], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,721 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,721 - train - INFO - True
2024-04-02 16:43:56,722 - train - INFO - alphas:tensor([0.2190, 0.7810], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,722 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,723 - train - INFO - True
2024-04-02 16:43:56,723 - train - INFO - alphas:tensor([0.5079, 0.4921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,724 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,725 - train - INFO - True
2024-04-02 16:43:56,728 - train - INFO - alphas:tensor([0.4015, 0.5985], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,728 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,728 - train - INFO - True
2024-04-02 16:43:56,729 - train - INFO - alphas:tensor([0.2294, 0.7706], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,730 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,730 - train - INFO - True
2024-04-02 16:43:56,731 - train - INFO - alphas:tensor([0.3619, 0.6381], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,731 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,731 - train - INFO - True
2024-04-02 16:43:56,732 - train - INFO - alphas:tensor([0.5117, 0.4883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,733 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,733 - train - INFO - True
2024-04-02 16:43:56,734 - train - INFO - alphas:tensor([0.3858, 0.6142], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,734 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,734 - train - INFO - True
2024-04-02 16:43:56,735 - train - INFO - alphas:tensor([0.2455, 0.7545], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,744 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,744 - train - INFO - True
2024-04-02 16:43:56,745 - train - INFO - alphas:tensor([0.3588, 0.6412], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,746 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,746 - train - INFO - True
2024-04-02 16:43:56,747 - train - INFO - alphas:tensor([0.4468, 0.5532], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,747 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,747 - train - INFO - True
2024-04-02 16:43:56,748 - train - INFO - alphas:tensor([0.3109, 0.6891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,748 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,749 - train - INFO - True
2024-04-02 16:43:56,750 - train - INFO - alphas:tensor([0.2121, 0.7879], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,750 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,750 - train - INFO - True
2024-04-02 16:43:56,751 - train - INFO - alphas:tensor([0.2648, 0.7352], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,751 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,752 - train - INFO - True
2024-04-02 16:43:56,752 - train - INFO - alphas:tensor([0.3051, 0.6949], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,753 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,753 - train - INFO - True
2024-04-02 16:43:56,758 - train - INFO - alphas:tensor([0.1124, 0.8876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,759 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,759 - train - INFO - True
2024-04-02 16:43:56,760 - train - INFO - alphas:tensor([0.1529, 0.8471], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,760 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,760 - train - INFO - True
2024-04-02 16:43:56,761 - train - INFO - alphas:tensor([0.1812, 0.8188], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,761 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,762 - train - INFO - True
2024-04-02 16:43:56,763 - train - INFO - alphas:tensor([0.2503, 0.7497], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,763 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,763 - train - INFO - True
2024-04-02 16:43:56,764 - train - INFO - alphas:tensor([0.0128, 0.9872], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,764 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,765 - train - INFO - True
2024-04-02 16:43:56,766 - train - INFO - alphas:tensor([0.0828, 0.9172], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,766 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,766 - train - INFO - True
2024-04-02 16:43:56,771 - train - INFO - alphas:tensor([0.0021, 0.9979], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,772 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,772 - train - INFO - True
2024-04-02 16:43:56,773 - train - INFO - alphas:tensor([3.2119e-04, 9.9968e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,773 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,773 - train - INFO - True
2024-04-02 16:43:56,774 - train - INFO - alphas:tensor([1.6443e-05, 9.9998e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,774 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,775 - train - INFO - True
2024-04-02 16:43:56,780 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:43:56,780 - train - INFO - tau:0.392711028357805
2024-04-02 16:43:56,781 - train - INFO - avg block size:13.931034482758621
2024-04-02 16:43:58,546 - train - INFO - Test: [   0/39]  Time: 1.761 (1.761)  Loss:  0.3857 (0.3857)  Acc@1: 92.5781 (92.5781)  Acc@5: 99.6094 (99.6094)
2024-04-02 16:45:09,055 - train - INFO - Test: [  39/39]  Time: 1.822 (1.807)  Loss:  0.4055 (0.3714)  Acc@1: 87.5000 (92.0600)  Acc@5: 100.0000 (99.7400)
2024-04-02 16:45:12,142 - train - INFO - Train: 96 [   0/195 (  0%)]  Loss:  1.844510 (1.8445)  Time: 2.857s,   89.60/s  (2.857s,   89.60/s)  LR: 1.650e-04  Data: 0.334 (0.334)
2024-04-02 16:47:39,191 - train - INFO - Train: 96 [  50/195 ( 26%)]  Loss:  1.245522 (1.5594)  Time: 2.753s,   92.98/s  (2.939s,   87.10/s)  LR: 1.650e-04  Data: 0.008 (0.021)
2024-04-02 16:50:06,430 - train - INFO - Train: 96 [ 100/195 ( 52%)]  Loss:  1.714069 (1.5822)  Time: 2.806s,   91.24/s  (2.942s,   87.02/s)  LR: 1.650e-04  Data: 0.037 (0.018)
2024-04-02 16:52:34,163 - train - INFO - Train: 96 [ 150/195 ( 77%)]  Loss:  1.787851 (1.5973)  Time: 2.905s,   88.14/s  (2.946s,   86.89/s)  LR: 1.650e-04  Data: 0.037 (0.017)
2024-04-02 16:54:48,991 - train - INFO - Train: 96 [ 194/195 (100%)]  Loss:  1.835859 (1.5771)  Time: 2.822s,   90.71/s  (2.973s,   86.11/s)  LR: 1.650e-04  Data: 0.000 (0.017)
2024-04-02 16:54:48,992 - train - INFO - True
2024-04-02 16:54:48,995 - train - INFO - alphas:tensor([2.8020e-04, 9.9972e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:48,995 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:48,995 - train - INFO - True
2024-04-02 16:54:48,996 - train - INFO - alphas:tensor([0.0549, 0.9451], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:48,996 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:48,996 - train - INFO - True
2024-04-02 16:54:48,997 - train - INFO - alphas:tensor([0.5100, 0.4900], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:48,998 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:48,998 - train - INFO - True
2024-04-02 16:54:49,003 - train - INFO - alphas:tensor([0.4367, 0.5633], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,003 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,004 - train - INFO - True
2024-04-02 16:54:49,004 - train - INFO - alphas:tensor([0.1121, 0.8879], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,005 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,005 - train - INFO - True
2024-04-02 16:54:49,011 - train - INFO - alphas:tensor([0.2171, 0.7829], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,011 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,011 - train - INFO - True
2024-04-02 16:54:49,012 - train - INFO - alphas:tensor([0.5078, 0.4922], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,012 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,013 - train - INFO - True
2024-04-02 16:54:49,013 - train - INFO - alphas:tensor([0.4003, 0.5997], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,014 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,014 - train - INFO - True
2024-04-02 16:54:49,015 - train - INFO - alphas:tensor([0.2289, 0.7711], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,015 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,015 - train - INFO - True
2024-04-02 16:54:49,016 - train - INFO - alphas:tensor([0.3609, 0.6391], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,016 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,017 - train - INFO - True
2024-04-02 16:54:49,017 - train - INFO - alphas:tensor([0.5099, 0.4901], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,018 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,018 - train - INFO - True
2024-04-02 16:54:49,023 - train - INFO - alphas:tensor([0.3843, 0.6157], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,023 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,024 - train - INFO - True
2024-04-02 16:54:49,024 - train - INFO - alphas:tensor([0.2445, 0.7555], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,025 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,025 - train - INFO - True
2024-04-02 16:54:49,026 - train - INFO - alphas:tensor([0.3579, 0.6421], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,026 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,026 - train - INFO - True
2024-04-02 16:54:49,027 - train - INFO - alphas:tensor([0.4470, 0.5530], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,027 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,028 - train - INFO - True
2024-04-02 16:54:49,028 - train - INFO - alphas:tensor([0.3091, 0.6909], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,029 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,029 - train - INFO - True
2024-04-02 16:54:49,030 - train - INFO - alphas:tensor([0.2107, 0.7893], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,030 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,030 - train - INFO - True
2024-04-02 16:54:49,035 - train - INFO - alphas:tensor([0.2629, 0.7371], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,036 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,036 - train - INFO - True
2024-04-02 16:54:49,037 - train - INFO - alphas:tensor([0.3049, 0.6951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,037 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,037 - train - INFO - True
2024-04-02 16:54:49,038 - train - INFO - alphas:tensor([0.1116, 0.8884], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,038 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,039 - train - INFO - True
2024-04-02 16:54:49,039 - train - INFO - alphas:tensor([0.1519, 0.8481], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,040 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,040 - train - INFO - True
2024-04-02 16:54:49,041 - train - INFO - alphas:tensor([0.1812, 0.8188], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,041 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,041 - train - INFO - True
2024-04-02 16:54:49,042 - train - INFO - alphas:tensor([0.2501, 0.7499], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,042 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,043 - train - INFO - True
2024-04-02 16:54:49,043 - train - INFO - alphas:tensor([0.0119, 0.9881], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,044 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,049 - train - INFO - True
2024-04-02 16:54:49,050 - train - INFO - alphas:tensor([0.0817, 0.9183], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,050 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,050 - train - INFO - True
2024-04-02 16:54:49,051 - train - INFO - alphas:tensor([0.0019, 0.9981], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,051 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,051 - train - INFO - True
2024-04-02 16:54:49,052 - train - INFO - alphas:tensor([2.8539e-04, 9.9971e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,052 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,053 - train - INFO - True
2024-04-02 16:54:49,053 - train - INFO - alphas:tensor([1.4431e-05, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,054 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,054 - train - INFO - True
2024-04-02 16:54:49,055 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 16:54:49,055 - train - INFO - tau:0.38878391807422696
2024-04-02 16:54:49,055 - train - INFO - avg block size:13.931034482758621
2024-04-02 16:54:50,991 - train - INFO - Test: [   0/39]  Time: 1.933 (1.933)  Loss:  0.3833 (0.3833)  Acc@1: 92.5781 (92.5781)  Acc@5: 99.6094 (99.6094)
2024-04-02 16:56:02,602 - train - INFO - Test: [  39/39]  Time: 2.077 (1.839)  Loss:  0.3521 (0.3749)  Acc@1: 87.5000 (92.0800)  Acc@5: 100.0000 (99.7100)
2024-04-02 16:56:06,477 - train - INFO - Train: 97 [   0/195 (  0%)]  Loss:  1.784852 (1.7849)  Time: 3.435s,   74.53/s  (3.435s,   74.53/s)  LR: 1.599e-04  Data: 0.336 (0.336)
2024-04-02 16:58:37,314 - train - INFO - Train: 97 [  50/195 ( 26%)]  Loss:  1.431571 (1.5945)  Time: 2.865s,   89.36/s  (3.025s,   84.63/s)  LR: 1.599e-04  Data: 0.009 (0.022)
2024-04-02 17:01:07,650 - train - INFO - Train: 97 [ 100/195 ( 52%)]  Loss:  1.536922 (1.5670)  Time: 3.307s,   77.41/s  (3.016s,   84.88/s)  LR: 1.599e-04  Data: 0.010 (0.019)
2024-04-02 17:03:40,030 - train - INFO - Train: 97 [ 150/195 ( 77%)]  Loss:  1.867592 (1.5841)  Time: 3.014s,   84.93/s  (3.026s,   84.59/s)  LR: 1.599e-04  Data: 0.010 (0.018)
2024-04-02 17:05:51,415 - train - INFO - Train: 97 [ 194/195 (100%)]  Loss:  1.554729 (1.5815)  Time: 2.947s,   86.88/s  (3.017s,   84.85/s)  LR: 1.599e-04  Data: 0.000 (0.017)
2024-04-02 17:05:51,420 - train - INFO - True
2024-04-02 17:05:51,421 - train - INFO - alphas:tensor([2.5111e-04, 9.9975e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,421 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,422 - train - INFO - True
2024-04-02 17:05:51,422 - train - INFO - alphas:tensor([0.0540, 0.9460], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,423 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,423 - train - INFO - True
2024-04-02 17:05:51,423 - train - INFO - alphas:tensor([0.5102, 0.4898], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,424 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,424 - train - INFO - True
2024-04-02 17:05:51,424 - train - INFO - alphas:tensor([0.4365, 0.5635], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,425 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,425 - train - INFO - True
2024-04-02 17:05:51,430 - train - INFO - alphas:tensor([0.1105, 0.8895], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,430 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,430 - train - INFO - True
2024-04-02 17:05:51,431 - train - INFO - alphas:tensor([0.2156, 0.7844], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,431 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,431 - train - INFO - True
2024-04-02 17:05:51,432 - train - INFO - alphas:tensor([0.5065, 0.4935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,432 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,432 - train - INFO - True
2024-04-02 17:05:51,433 - train - INFO - alphas:tensor([0.4008, 0.5992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,433 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,434 - train - INFO - True
2024-04-02 17:05:51,435 - train - INFO - alphas:tensor([0.2278, 0.7722], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,435 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,436 - train - INFO - True
2024-04-02 17:05:51,436 - train - INFO - alphas:tensor([0.3613, 0.6387], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,437 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,437 - train - INFO - True
2024-04-02 17:05:51,438 - train - INFO - alphas:tensor([0.5108, 0.4892], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,438 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,438 - train - INFO - True
2024-04-02 17:05:51,439 - train - INFO - alphas:tensor([0.3855, 0.6145], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,439 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,439 - train - INFO - True
2024-04-02 17:05:51,440 - train - INFO - alphas:tensor([0.2432, 0.7568], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,441 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,441 - train - INFO - True
2024-04-02 17:05:51,442 - train - INFO - alphas:tensor([0.3570, 0.6430], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,442 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,442 - train - INFO - True
2024-04-02 17:05:51,447 - train - INFO - alphas:tensor([0.4469, 0.5531], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,448 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,448 - train - INFO - True
2024-04-02 17:05:51,449 - train - INFO - alphas:tensor([0.3086, 0.6914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,449 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,449 - train - INFO - True
2024-04-02 17:05:51,450 - train - INFO - alphas:tensor([0.2108, 0.7892], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,450 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,450 - train - INFO - True
2024-04-02 17:05:51,451 - train - INFO - alphas:tensor([0.2632, 0.7368], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,451 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,452 - train - INFO - True
2024-04-02 17:05:51,452 - train - INFO - alphas:tensor([0.3036, 0.6964], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,453 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,453 - train - INFO - True
2024-04-02 17:05:51,454 - train - INFO - alphas:tensor([0.1101, 0.8899], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,454 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,454 - train - INFO - True
2024-04-02 17:05:51,455 - train - INFO - alphas:tensor([0.1501, 0.8499], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,455 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,455 - train - INFO - True
2024-04-02 17:05:51,456 - train - INFO - alphas:tensor([0.1794, 0.8206], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,457 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,457 - train - INFO - True
2024-04-02 17:05:51,458 - train - INFO - alphas:tensor([0.2496, 0.7504], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,458 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,458 - train - INFO - True
2024-04-02 17:05:51,459 - train - INFO - alphas:tensor([0.0110, 0.9890], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,459 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,459 - train - INFO - True
2024-04-02 17:05:51,460 - train - INFO - alphas:tensor([0.0816, 0.9184], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,460 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,461 - train - INFO - True
2024-04-02 17:05:51,461 - train - INFO - alphas:tensor([0.0017, 0.9983], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,462 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,462 - train - INFO - True
2024-04-02 17:05:51,463 - train - INFO - alphas:tensor([2.5387e-04, 9.9975e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,463 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,463 - train - INFO - True
2024-04-02 17:05:51,464 - train - INFO - alphas:tensor([1.2661e-05, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,464 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,465 - train - INFO - True
2024-04-02 17:05:51,465 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:05:51,466 - train - INFO - tau:0.3848960788934847
2024-04-02 17:05:51,466 - train - INFO - avg block size:13.931034482758621
2024-04-02 17:05:53,435 - train - INFO - Test: [   0/39]  Time: 1.961 (1.961)  Loss:  0.3689 (0.3689)  Acc@1: 92.9688 (92.9688)  Acc@5: 99.6094 (99.6094)
2024-04-02 17:07:04,762 - train - INFO - Test: [  39/39]  Time: 1.863 (1.832)  Loss:  0.3865 (0.3692)  Acc@1: 87.5000 (92.1400)  Acc@5: 100.0000 (99.7200)
2024-04-02 17:07:08,351 - train - INFO - Train: 98 [   0/195 (  0%)]  Loss:  1.558478 (1.5585)  Time: 3.303s,   77.50/s  (3.303s,   77.50/s)  LR: 1.549e-04  Data: 0.289 (0.289)
2024-04-02 17:09:36,989 - train - INFO - Train: 98 [  50/195 ( 26%)]  Loss:  1.824350 (1.5695)  Time: 2.742s,   93.36/s  (2.979s,   85.93/s)  LR: 1.549e-04  Data: 0.014 (0.017)
2024-04-02 17:12:02,657 - train - INFO - Train: 98 [ 100/195 ( 52%)]  Loss:  1.673577 (1.5566)  Time: 2.942s,   87.01/s  (2.947s,   86.88/s)  LR: 1.549e-04  Data: 0.018 (0.016)
2024-04-02 17:14:31,913 - train - INFO - Train: 98 [ 150/195 ( 77%)]  Loss:  1.695014 (1.5591)  Time: 3.227s,   79.34/s  (2.959s,   86.51/s)  LR: 1.549e-04  Data: 0.018 (0.016)
2024-04-02 17:16:43,709 - train - INFO - Train: 98 [ 194/195 (100%)]  Loss:  1.339112 (1.5686)  Time: 2.687s,   95.26/s  (2.967s,   86.27/s)  LR: 1.549e-04  Data: 0.000 (0.015)
2024-04-02 17:16:43,723 - train - INFO - True
2024-04-02 17:16:43,724 - train - INFO - alphas:tensor([2.2481e-04, 9.9978e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,725 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,725 - train - INFO - True
2024-04-02 17:16:43,726 - train - INFO - alphas:tensor([0.0529, 0.9471], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,726 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,726 - train - INFO - True
2024-04-02 17:16:43,727 - train - INFO - alphas:tensor([0.5102, 0.4898], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,727 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,728 - train - INFO - True
2024-04-02 17:16:43,729 - train - INFO - alphas:tensor([0.4362, 0.5638], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,729 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,729 - train - INFO - True
2024-04-02 17:16:43,730 - train - INFO - alphas:tensor([0.1098, 0.8902], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,730 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,730 - train - INFO - True
2024-04-02 17:16:43,731 - train - INFO - alphas:tensor([0.2154, 0.7846], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,731 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,732 - train - INFO - True
2024-04-02 17:16:43,732 - train - INFO - alphas:tensor([0.5057, 0.4943], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,733 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,733 - train - INFO - True
2024-04-02 17:16:43,734 - train - INFO - alphas:tensor([0.3982, 0.6018], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,734 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,735 - train - INFO - True
2024-04-02 17:16:43,736 - train - INFO - alphas:tensor([0.2261, 0.7739], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,745 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,745 - train - INFO - True
2024-04-02 17:16:43,746 - train - INFO - alphas:tensor([0.3604, 0.6396], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,746 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,746 - train - INFO - True
2024-04-02 17:16:43,751 - train - INFO - alphas:tensor([0.5099, 0.4901], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,752 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,752 - train - INFO - True
2024-04-02 17:16:43,753 - train - INFO - alphas:tensor([0.3840, 0.6160], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,753 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,753 - train - INFO - True
2024-04-02 17:16:43,754 - train - INFO - alphas:tensor([0.2427, 0.7573], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,754 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,755 - train - INFO - True
2024-04-02 17:16:43,755 - train - INFO - alphas:tensor([0.3579, 0.6421], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,756 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,756 - train - INFO - True
2024-04-02 17:16:43,757 - train - INFO - alphas:tensor([0.4461, 0.5539], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,757 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,757 - train - INFO - True
2024-04-02 17:16:43,758 - train - INFO - alphas:tensor([0.3082, 0.6918], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,758 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,758 - train - INFO - True
2024-04-02 17:16:43,759 - train - INFO - alphas:tensor([0.2098, 0.7902], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,759 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,768 - train - INFO - True
2024-04-02 17:16:43,769 - train - INFO - alphas:tensor([0.2620, 0.7380], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,770 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,770 - train - INFO - True
2024-04-02 17:16:43,771 - train - INFO - alphas:tensor([0.3021, 0.6979], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,771 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,771 - train - INFO - True
2024-04-02 17:16:43,772 - train - INFO - alphas:tensor([0.1084, 0.8916], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,772 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,772 - train - INFO - True
2024-04-02 17:16:43,773 - train - INFO - alphas:tensor([0.1506, 0.8494], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,774 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,774 - train - INFO - True
2024-04-02 17:16:43,775 - train - INFO - alphas:tensor([0.1793, 0.8207], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,775 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,775 - train - INFO - True
2024-04-02 17:16:43,776 - train - INFO - alphas:tensor([0.2491, 0.7509], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,776 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,776 - train - INFO - True
2024-04-02 17:16:43,777 - train - INFO - alphas:tensor([0.0101, 0.9899], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,777 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,778 - train - INFO - True
2024-04-02 17:16:43,778 - train - INFO - alphas:tensor([0.0805, 0.9195], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,779 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,779 - train - INFO - True
2024-04-02 17:16:43,793 - train - INFO - alphas:tensor([0.0015, 0.9985], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,794 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,794 - train - INFO - True
2024-04-02 17:16:43,795 - train - INFO - alphas:tensor([2.2592e-04, 9.9977e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,795 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,795 - train - INFO - True
2024-04-02 17:16:43,796 - train - INFO - alphas:tensor([1.1104e-05, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,796 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,796 - train - INFO - True
2024-04-02 17:16:43,797 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:16:43,797 - train - INFO - tau:0.38104711810454983
2024-04-02 17:16:43,798 - train - INFO - avg block size:13.931034482758621
2024-04-02 17:16:45,558 - train - INFO - Test: [   0/39]  Time: 1.757 (1.757)  Loss:  0.3633 (0.3633)  Acc@1: 92.5781 (92.5781)  Acc@5: 99.6094 (99.6094)
2024-04-02 17:17:57,644 - train - INFO - Test: [  39/39]  Time: 1.846 (1.846)  Loss:  0.3870 (0.3700)  Acc@1: 87.5000 (92.0800)  Acc@5: 100.0000 (99.7100)
2024-04-02 17:18:01,133 - train - INFO - Train: 99 [   0/195 (  0%)]  Loss:  1.566926 (1.5669)  Time: 3.249s,   78.80/s  (3.249s,   78.80/s)  LR: 1.499e-04  Data: 0.270 (0.270)
2024-04-02 17:20:28,879 - train - INFO - Train: 99 [  50/195 ( 26%)]  Loss:  1.243257 (1.5823)  Time: 2.628s,   97.40/s  (2.961s,   86.47/s)  LR: 1.499e-04  Data: 0.017 (0.020)
2024-04-02 17:22:58,205 - train - INFO - Train: 99 [ 100/195 ( 52%)]  Loss:  1.463154 (1.5650)  Time: 2.793s,   91.67/s  (2.973s,   86.10/s)  LR: 1.499e-04  Data: 0.019 (0.018)
2024-04-02 17:25:26,486 - train - INFO - Train: 99 [ 150/195 ( 77%)]  Loss:  1.815459 (1.5579)  Time: 2.877s,   88.99/s  (2.971s,   86.17/s)  LR: 1.499e-04  Data: 0.009 (0.017)
2024-04-02 17:27:35,946 - train - INFO - Train: 99 [ 194/195 (100%)]  Loss:  1.780111 (1.5566)  Time: 3.300s,   77.57/s  (2.964s,   86.36/s)  LR: 1.499e-04  Data: 0.000 (0.016)
2024-04-02 17:27:35,946 - train - INFO - True
2024-04-02 17:27:35,948 - train - INFO - alphas:tensor([2.0111e-04, 9.9980e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,948 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,948 - train - INFO - True
2024-04-02 17:27:35,949 - train - INFO - alphas:tensor([0.0517, 0.9483], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,949 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,950 - train - INFO - True
2024-04-02 17:27:35,951 - train - INFO - alphas:tensor([0.5096, 0.4904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,951 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,951 - train - INFO - True
2024-04-02 17:27:35,952 - train - INFO - alphas:tensor([0.4352, 0.5648], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,952 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,952 - train - INFO - True
2024-04-02 17:27:35,953 - train - INFO - alphas:tensor([0.1089, 0.8911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,954 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,954 - train - INFO - True
2024-04-02 17:27:35,955 - train - INFO - alphas:tensor([0.2153, 0.7847], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,956 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,956 - train - INFO - True
2024-04-02 17:27:35,957 - train - INFO - alphas:tensor([0.5055, 0.4945], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,962 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,962 - train - INFO - True
2024-04-02 17:27:35,963 - train - INFO - alphas:tensor([0.3969, 0.6031], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,963 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,963 - train - INFO - True
2024-04-02 17:27:35,964 - train - INFO - alphas:tensor([0.2259, 0.7741], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,964 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,965 - train - INFO - True
2024-04-02 17:27:35,966 - train - INFO - alphas:tensor([0.3589, 0.6411], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,966 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,966 - train - INFO - True
2024-04-02 17:27:35,967 - train - INFO - alphas:tensor([0.5090, 0.4910], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,967 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,968 - train - INFO - True
2024-04-02 17:27:35,969 - train - INFO - alphas:tensor([0.3818, 0.6182], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,969 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,969 - train - INFO - True
2024-04-02 17:27:35,970 - train - INFO - alphas:tensor([0.2424, 0.7576], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,970 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,970 - train - INFO - True
2024-04-02 17:27:35,971 - train - INFO - alphas:tensor([0.3575, 0.6425], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,972 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,972 - train - INFO - True
2024-04-02 17:27:35,973 - train - INFO - alphas:tensor([0.4463, 0.5537], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,973 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,973 - train - INFO - True
2024-04-02 17:27:35,974 - train - INFO - alphas:tensor([0.3086, 0.6914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,974 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,975 - train - INFO - True
2024-04-02 17:27:35,975 - train - INFO - alphas:tensor([0.2087, 0.7913], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,976 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,976 - train - INFO - True
2024-04-02 17:27:35,977 - train - INFO - alphas:tensor([0.2619, 0.7381], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,977 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,977 - train - INFO - True
2024-04-02 17:27:35,978 - train - INFO - alphas:tensor([0.3007, 0.6993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,979 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,979 - train - INFO - True
2024-04-02 17:27:35,980 - train - INFO - alphas:tensor([0.1071, 0.8929], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,980 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,980 - train - INFO - True
2024-04-02 17:27:35,981 - train - INFO - alphas:tensor([0.1499, 0.8501], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,982 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,982 - train - INFO - True
2024-04-02 17:27:35,983 - train - INFO - alphas:tensor([0.1775, 0.8225], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,983 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,983 - train - INFO - True
2024-04-02 17:27:35,984 - train - INFO - alphas:tensor([0.2472, 0.7528], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,985 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,985 - train - INFO - True
2024-04-02 17:27:35,986 - train - INFO - alphas:tensor([0.0093, 0.9907], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,986 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,986 - train - INFO - True
2024-04-02 17:27:35,987 - train - INFO - alphas:tensor([0.0791, 0.9209], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,988 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,992 - train - INFO - True
2024-04-02 17:27:35,993 - train - INFO - alphas:tensor([0.0014, 0.9986], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,993 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,994 - train - INFO - True
2024-04-02 17:27:35,995 - train - INFO - alphas:tensor([2.0087e-04, 9.9980e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,995 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,995 - train - INFO - True
2024-04-02 17:27:35,996 - train - INFO - alphas:tensor([9.7297e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,996 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,996 - train - INFO - True
2024-04-02 17:27:35,997 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:27:35,997 - train - INFO - tau:0.37723664692350434
2024-04-02 17:27:35,998 - train - INFO - avg block size:13.931034482758621
2024-04-02 17:27:37,970 - train - INFO - Test: [   0/39]  Time: 1.969 (1.969)  Loss:  0.3806 (0.3806)  Acc@1: 91.4062 (91.4062)  Acc@5: 99.2188 (99.2188)
2024-04-02 17:28:50,848 - train - INFO - Test: [  39/39]  Time: 1.919 (1.871)  Loss:  0.3855 (0.3793)  Acc@1: 87.5000 (91.9600)  Acc@5: 100.0000 (99.7100)
2024-04-02 17:28:54,361 - train - INFO - Train: 100 [   0/195 (  0%)]  Loss:  1.265687 (1.2657)  Time: 3.295s,   77.69/s  (3.295s,   77.69/s)  LR: 1.450e-04  Data: 0.271 (0.271)
2024-04-02 17:31:22,396 - train - INFO - Train: 100 [  50/195 ( 26%)]  Loss:  1.464737 (1.5642)  Time: 2.859s,   89.54/s  (2.967s,   86.28/s)  LR: 1.450e-04  Data: 0.005 (0.021)
2024-04-02 17:33:53,355 - train - INFO - Train: 100 [ 100/195 ( 52%)]  Loss:  1.559495 (1.5697)  Time: 3.209s,   79.76/s  (2.993s,   85.54/s)  LR: 1.450e-04  Data: 0.005 (0.019)
2024-04-02 17:36:24,065 - train - INFO - Train: 100 [ 150/195 ( 77%)]  Loss:  1.430820 (1.5839)  Time: 2.966s,   86.33/s  (3.000s,   85.34/s)  LR: 1.450e-04  Data: 0.028 (0.018)
2024-04-02 17:38:37,053 - train - INFO - Train: 100 [ 194/195 (100%)]  Loss:  1.702441 (1.5790)  Time: 2.773s,   92.33/s  (3.005s,   85.19/s)  LR: 1.450e-04  Data: 0.000 (0.017)
2024-04-02 17:38:37,079 - train - INFO - True
2024-04-02 17:38:37,080 - train - INFO - alphas:tensor([1.8025e-04, 9.9982e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,082 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,082 - train - INFO - True
2024-04-02 17:38:37,083 - train - INFO - alphas:tensor([0.0512, 0.9488], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,083 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,083 - train - INFO - True
2024-04-02 17:38:37,084 - train - INFO - alphas:tensor([0.5095, 0.4905], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,084 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,084 - train - INFO - True
2024-04-02 17:38:37,085 - train - INFO - alphas:tensor([0.4341, 0.5659], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,085 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,085 - train - INFO - True
2024-04-02 17:38:37,102 - train - INFO - alphas:tensor([0.1075, 0.8925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,102 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,102 - train - INFO - True
2024-04-02 17:38:37,103 - train - INFO - alphas:tensor([0.2132, 0.7868], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,103 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,103 - train - INFO - True
2024-04-02 17:38:37,104 - train - INFO - alphas:tensor([0.5071, 0.4929], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,108 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,108 - train - INFO - True
2024-04-02 17:38:37,109 - train - INFO - alphas:tensor([0.4004, 0.5996], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,109 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,110 - train - INFO - True
2024-04-02 17:38:37,110 - train - INFO - alphas:tensor([0.2242, 0.7758], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,115 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,115 - train - INFO - True
2024-04-02 17:38:37,116 - train - INFO - alphas:tensor([0.3581, 0.6419], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,117 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,117 - train - INFO - True
2024-04-02 17:38:37,118 - train - INFO - alphas:tensor([0.5078, 0.4922], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,118 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,118 - train - INFO - True
2024-04-02 17:38:37,119 - train - INFO - alphas:tensor([0.3810, 0.6190], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,119 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,120 - train - INFO - True
2024-04-02 17:38:37,121 - train - INFO - alphas:tensor([0.2404, 0.7596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,121 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,121 - train - INFO - True
2024-04-02 17:38:37,122 - train - INFO - alphas:tensor([0.3568, 0.6432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,122 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,122 - train - INFO - True
2024-04-02 17:38:37,123 - train - INFO - alphas:tensor([0.4450, 0.5550], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,123 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,124 - train - INFO - True
2024-04-02 17:38:37,124 - train - INFO - alphas:tensor([0.3083, 0.6917], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,125 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,125 - train - INFO - True
2024-04-02 17:38:37,126 - train - INFO - alphas:tensor([0.2072, 0.7928], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,126 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,126 - train - INFO - True
2024-04-02 17:38:37,127 - train - INFO - alphas:tensor([0.2609, 0.7391], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,127 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,128 - train - INFO - True
2024-04-02 17:38:37,128 - train - INFO - alphas:tensor([0.2988, 0.7012], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,129 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,129 - train - INFO - True
2024-04-02 17:38:37,130 - train - INFO - alphas:tensor([0.1046, 0.8954], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,130 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,130 - train - INFO - True
2024-04-02 17:38:37,131 - train - INFO - alphas:tensor([0.1483, 0.8517], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,131 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,132 - train - INFO - True
2024-04-02 17:38:37,133 - train - INFO - alphas:tensor([0.1766, 0.8234], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,142 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,142 - train - INFO - True
2024-04-02 17:38:37,143 - train - INFO - alphas:tensor([0.2468, 0.7532], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,143 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,143 - train - INFO - True
2024-04-02 17:38:37,144 - train - INFO - alphas:tensor([0.0086, 0.9914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,144 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,144 - train - INFO - True
2024-04-02 17:38:37,145 - train - INFO - alphas:tensor([0.0780, 0.9220], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,146 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,146 - train - INFO - True
2024-04-02 17:38:37,151 - train - INFO - alphas:tensor([0.0012, 0.9988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,151 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,151 - train - INFO - True
2024-04-02 17:38:37,152 - train - INFO - alphas:tensor([1.7839e-04, 9.9982e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,153 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,153 - train - INFO - True
2024-04-02 17:38:37,154 - train - INFO - alphas:tensor([8.5233e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,154 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,154 - train - INFO - True
2024-04-02 17:38:37,155 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:38:37,159 - train - INFO - tau:0.37346428045426927
2024-04-02 17:38:37,160 - train - INFO - avg block size:13.931034482758621
2024-04-02 17:38:39,082 - train - INFO - Test: [   0/39]  Time: 1.919 (1.919)  Loss:  0.3662 (0.3662)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-04-02 17:39:50,971 - train - INFO - Test: [  39/39]  Time: 1.876 (1.845)  Loss:  0.2961 (0.3591)  Acc@1: 87.5000 (92.2500)  Acc@5: 100.0000 (99.7000)
2024-04-02 17:39:54,606 - train - INFO - Train: 101 [   0/195 (  0%)]  Loss:  1.412698 (1.4127)  Time: 3.229s,   79.28/s  (3.229s,   79.28/s)  LR: 1.401e-04  Data: 0.340 (0.340)
2024-04-02 17:42:21,732 - train - INFO - Train: 101 [  50/195 ( 26%)]  Loss:  1.349272 (1.5760)  Time: 3.223s,   79.44/s  (2.948s,   86.84/s)  LR: 1.401e-04  Data: 0.014 (0.020)
2024-04-02 17:44:51,618 - train - INFO - Train: 101 [ 100/195 ( 52%)]  Loss:  1.468869 (1.5702)  Time: 3.078s,   83.16/s  (2.973s,   86.12/s)  LR: 1.401e-04  Data: 0.006 (0.017)
2024-04-02 17:47:15,164 - train - INFO - Train: 101 [ 150/195 ( 77%)]  Loss:  1.619457 (1.5839)  Time: 2.946s,   86.91/s  (2.939s,   87.11/s)  LR: 1.401e-04  Data: 0.019 (0.017)
2024-04-02 17:49:24,832 - train - INFO - Train: 101 [ 194/195 (100%)]  Loss:  1.702445 (1.5869)  Time: 2.821s,   90.75/s  (2.941s,   87.05/s)  LR: 1.401e-04  Data: 0.000 (0.016)
2024-04-02 17:49:24,833 - train - INFO - True
2024-04-02 17:49:24,834 - train - INFO - alphas:tensor([1.6129e-04, 9.9984e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,834 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,835 - train - INFO - True
2024-04-02 17:49:24,836 - train - INFO - alphas:tensor([0.0503, 0.9497], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,836 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,836 - train - INFO - True
2024-04-02 17:49:24,837 - train - INFO - alphas:tensor([0.5076, 0.4924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,837 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,837 - train - INFO - True
2024-04-02 17:49:24,838 - train - INFO - alphas:tensor([0.4328, 0.5672], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,839 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,839 - train - INFO - True
2024-04-02 17:49:24,840 - train - INFO - alphas:tensor([0.1061, 0.8939], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,840 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,840 - train - INFO - True
2024-04-02 17:49:24,841 - train - INFO - alphas:tensor([0.2120, 0.7880], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,842 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,842 - train - INFO - True
2024-04-02 17:49:24,843 - train - INFO - alphas:tensor([0.5045, 0.4955], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,843 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,843 - train - INFO - True
2024-04-02 17:49:24,844 - train - INFO - alphas:tensor([0.3978, 0.6022], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,844 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,845 - train - INFO - True
2024-04-02 17:49:24,845 - train - INFO - alphas:tensor([0.2240, 0.7760], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,846 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,846 - train - INFO - True
2024-04-02 17:49:24,847 - train - INFO - alphas:tensor([0.3584, 0.6416], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,847 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,847 - train - INFO - True
2024-04-02 17:49:24,852 - train - INFO - alphas:tensor([0.5069, 0.4931], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,853 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,853 - train - INFO - True
2024-04-02 17:49:24,854 - train - INFO - alphas:tensor([0.3782, 0.6218], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,854 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,854 - train - INFO - True
2024-04-02 17:49:24,855 - train - INFO - alphas:tensor([0.2402, 0.7598], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,860 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,860 - train - INFO - True
2024-04-02 17:49:24,861 - train - INFO - alphas:tensor([0.3568, 0.6432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,861 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,861 - train - INFO - True
2024-04-02 17:49:24,862 - train - INFO - alphas:tensor([0.4435, 0.5565], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,862 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,863 - train - INFO - True
2024-04-02 17:49:24,863 - train - INFO - alphas:tensor([0.3053, 0.6947], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,864 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,864 - train - INFO - True
2024-04-02 17:49:24,865 - train - INFO - alphas:tensor([0.2081, 0.7919], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,865 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,865 - train - INFO - True
2024-04-02 17:49:24,866 - train - INFO - alphas:tensor([0.2612, 0.7388], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,866 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,867 - train - INFO - True
2024-04-02 17:49:24,867 - train - INFO - alphas:tensor([0.2965, 0.7035], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,868 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,868 - train - INFO - True
2024-04-02 17:49:24,869 - train - INFO - alphas:tensor([0.1027, 0.8973], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,869 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,869 - train - INFO - True
2024-04-02 17:49:24,870 - train - INFO - alphas:tensor([0.1467, 0.8533], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,870 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,870 - train - INFO - True
2024-04-02 17:49:24,871 - train - INFO - alphas:tensor([0.1754, 0.8246], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,872 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,872 - train - INFO - True
2024-04-02 17:49:24,873 - train - INFO - alphas:tensor([0.2455, 0.7545], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,873 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,873 - train - INFO - True
2024-04-02 17:49:24,874 - train - INFO - alphas:tensor([0.0079, 0.9921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,874 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,874 - train - INFO - True
2024-04-02 17:49:24,875 - train - INFO - alphas:tensor([0.0765, 0.9235], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,875 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,876 - train - INFO - True
2024-04-02 17:49:24,877 - train - INFO - alphas:tensor([0.0011, 0.9989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,877 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,877 - train - INFO - True
2024-04-02 17:49:24,878 - train - INFO - alphas:tensor([1.5839e-04, 9.9984e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,878 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,878 - train - INFO - True
2024-04-02 17:49:24,879 - train - INFO - alphas:tensor([7.4623e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,879 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,880 - train - INFO - True
2024-04-02 17:49:24,880 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 17:49:24,881 - train - INFO - tau:0.36972963764972655
2024-04-02 17:49:24,890 - train - INFO - avg block size:13.931034482758621
2024-04-02 17:49:26,670 - train - INFO - Test: [   0/39]  Time: 1.776 (1.776)  Loss:  0.3752 (0.3752)  Acc@1: 93.7500 (93.7500)  Acc@5: 99.2188 (99.2188)
2024-04-02 17:50:37,754 - train - INFO - Test: [  39/39]  Time: 1.880 (1.821)  Loss:  0.3706 (0.3809)  Acc@1: 87.5000 (92.0400)  Acc@5: 100.0000 (99.7300)
2024-04-02 17:50:41,670 - train - INFO - Train: 102 [   0/195 (  0%)]  Loss:  1.433270 (1.4333)  Time: 3.699s,   69.21/s  (3.699s,   69.21/s)  LR: 1.353e-04  Data: 0.425 (0.425)
2024-04-02 17:53:08,716 - train - INFO - Train: 102 [  50/195 ( 26%)]  Loss:  1.416212 (1.5243)  Time: 2.718s,   94.18/s  (2.956s,   86.62/s)  LR: 1.353e-04  Data: 0.016 (0.019)
2024-04-02 17:55:34,595 - train - INFO - Train: 102 [ 100/195 ( 52%)]  Loss:  1.428257 (1.5495)  Time: 3.092s,   82.80/s  (2.937s,   87.17/s)  LR: 1.353e-04  Data: 0.019 (0.016)
2024-04-02 17:58:01,682 - train - INFO - Train: 102 [ 150/195 ( 77%)]  Loss:  1.303686 (1.5653)  Time: 2.994s,   85.50/s  (2.938s,   87.13/s)  LR: 1.353e-04  Data: 0.005 (0.016)
2024-04-02 18:00:09,780 - train - INFO - Train: 102 [ 194/195 (100%)]  Loss:  1.329288 (1.5704)  Time: 3.043s,   84.13/s  (2.932s,   87.31/s)  LR: 1.353e-04  Data: 0.000 (0.016)
2024-04-02 18:00:09,781 - train - INFO - True
2024-04-02 18:00:09,782 - train - INFO - alphas:tensor([1.4425e-04, 9.9986e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,782 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,782 - train - INFO - True
2024-04-02 18:00:09,792 - train - INFO - alphas:tensor([0.0493, 0.9507], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,792 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,792 - train - INFO - True
2024-04-02 18:00:09,793 - train - INFO - alphas:tensor([0.5073, 0.4927], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,794 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,794 - train - INFO - True
2024-04-02 18:00:09,795 - train - INFO - alphas:tensor([0.4327, 0.5673], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,795 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,795 - train - INFO - True
2024-04-02 18:00:09,796 - train - INFO - alphas:tensor([0.1049, 0.8951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,796 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,796 - train - INFO - True
2024-04-02 18:00:09,797 - train - INFO - alphas:tensor([0.2106, 0.7894], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,798 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,798 - train - INFO - True
2024-04-02 18:00:09,799 - train - INFO - alphas:tensor([0.5035, 0.4965], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,800 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,800 - train - INFO - True
2024-04-02 18:00:09,801 - train - INFO - alphas:tensor([0.3976, 0.6024], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,801 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,801 - train - INFO - True
2024-04-02 18:00:09,802 - train - INFO - alphas:tensor([0.2236, 0.7764], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,815 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,816 - train - INFO - True
2024-04-02 18:00:09,816 - train - INFO - alphas:tensor([0.3573, 0.6427], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,817 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,817 - train - INFO - True
2024-04-02 18:00:09,818 - train - INFO - alphas:tensor([0.5070, 0.4930], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,818 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,818 - train - INFO - True
2024-04-02 18:00:09,819 - train - INFO - alphas:tensor([0.3786, 0.6214], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,819 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,820 - train - INFO - True
2024-04-02 18:00:09,820 - train - INFO - alphas:tensor([0.2395, 0.7605], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,821 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,821 - train - INFO - True
2024-04-02 18:00:09,822 - train - INFO - alphas:tensor([0.3558, 0.6442], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,822 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,822 - train - INFO - True
2024-04-02 18:00:09,823 - train - INFO - alphas:tensor([0.4430, 0.5570], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,823 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,824 - train - INFO - True
2024-04-02 18:00:09,824 - train - INFO - alphas:tensor([0.3048, 0.6952], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,825 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,825 - train - INFO - True
2024-04-02 18:00:09,826 - train - INFO - alphas:tensor([0.2066, 0.7934], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,826 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,826 - train - INFO - True
2024-04-02 18:00:09,827 - train - INFO - alphas:tensor([0.2613, 0.7387], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,827 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,828 - train - INFO - True
2024-04-02 18:00:09,833 - train - INFO - alphas:tensor([0.2966, 0.7034], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,833 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,833 - train - INFO - True
2024-04-02 18:00:09,834 - train - INFO - alphas:tensor([0.1008, 0.8992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,834 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,835 - train - INFO - True
2024-04-02 18:00:09,835 - train - INFO - alphas:tensor([0.1464, 0.8536], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,836 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,836 - train - INFO - True
2024-04-02 18:00:09,837 - train - INFO - alphas:tensor([0.1744, 0.8256], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,837 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,846 - train - INFO - True
2024-04-02 18:00:09,847 - train - INFO - alphas:tensor([0.2441, 0.7559], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,847 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,847 - train - INFO - True
2024-04-02 18:00:09,848 - train - INFO - alphas:tensor([0.0073, 0.9927], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,848 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,849 - train - INFO - True
2024-04-02 18:00:09,849 - train - INFO - alphas:tensor([0.0757, 0.9243], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,850 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,850 - train - INFO - True
2024-04-02 18:00:09,855 - train - INFO - alphas:tensor([0.0010, 0.9990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,856 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,856 - train - INFO - True
2024-04-02 18:00:09,857 - train - INFO - alphas:tensor([1.4085e-04, 9.9986e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,857 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,857 - train - INFO - True
2024-04-02 18:00:09,858 - train - INFO - alphas:tensor([6.5304e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,859 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,859 - train - INFO - True
2024-04-02 18:00:09,869 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:00:09,869 - train - INFO - tau:0.36603234127322926
2024-04-02 18:00:09,869 - train - INFO - avg block size:13.931034482758621
2024-04-02 18:00:11,774 - train - INFO - Test: [   0/39]  Time: 1.901 (1.901)  Loss:  0.3643 (0.3643)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-02 18:01:22,540 - train - INFO - Test: [  39/39]  Time: 1.813 (1.817)  Loss:  0.3645 (0.3727)  Acc@1: 87.5000 (92.0200)  Acc@5: 100.0000 (99.7600)
2024-04-02 18:01:26,375 - train - INFO - Train: 103 [   0/195 (  0%)]  Loss:  1.809906 (1.8099)  Time: 3.412s,   75.02/s  (3.412s,   75.02/s)  LR: 1.306e-04  Data: 0.393 (0.393)
2024-04-02 18:03:55,476 - train - INFO - Train: 103 [  50/195 ( 26%)]  Loss:  1.202272 (1.6023)  Time: 3.019s,   84.80/s  (2.990s,   85.61/s)  LR: 1.306e-04  Data: 0.005 (0.020)
2024-04-02 18:06:22,556 - train - INFO - Train: 103 [ 100/195 ( 52%)]  Loss:  1.784244 (1.5654)  Time: 3.189s,   80.26/s  (2.966s,   86.31/s)  LR: 1.306e-04  Data: 0.021 (0.017)
2024-04-02 18:08:48,562 - train - INFO - Train: 103 [ 150/195 ( 77%)]  Loss:  1.486987 (1.5652)  Time: 2.801s,   91.40/s  (2.951s,   86.75/s)  LR: 1.306e-04  Data: 0.009 (0.016)
2024-04-02 18:10:58,870 - train - INFO - Train: 103 [ 194/195 (100%)]  Loss:  1.265385 (1.5711)  Time: 2.869s,   89.22/s  (2.953s,   86.68/s)  LR: 1.306e-04  Data: 0.000 (0.016)
2024-04-02 18:10:58,870 - train - INFO - True
2024-04-02 18:10:58,872 - train - INFO - alphas:tensor([1.2890e-04, 9.9987e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,872 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,872 - train - INFO - True
2024-04-02 18:10:58,878 - train - INFO - alphas:tensor([0.0480, 0.9520], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,878 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,878 - train - INFO - True
2024-04-02 18:10:58,879 - train - INFO - alphas:tensor([0.5074, 0.4926], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,879 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,880 - train - INFO - True
2024-04-02 18:10:58,880 - train - INFO - alphas:tensor([0.4324, 0.5676], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,881 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,881 - train - INFO - True
2024-04-02 18:10:58,882 - train - INFO - alphas:tensor([0.1036, 0.8964], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,882 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,882 - train - INFO - True
2024-04-02 18:10:58,883 - train - INFO - alphas:tensor([0.2097, 0.7903], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,883 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,883 - train - INFO - True
2024-04-02 18:10:58,884 - train - INFO - alphas:tensor([0.5026, 0.4974], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,885 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,885 - train - INFO - True
2024-04-02 18:10:58,886 - train - INFO - alphas:tensor([0.3967, 0.6033], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,886 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,887 - train - INFO - True
2024-04-02 18:10:58,888 - train - INFO - alphas:tensor([0.2219, 0.7781], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,888 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,888 - train - INFO - True
2024-04-02 18:10:58,889 - train - INFO - alphas:tensor([0.3560, 0.6440], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,889 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,889 - train - INFO - True
2024-04-02 18:10:58,890 - train - INFO - alphas:tensor([0.5057, 0.4943], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,890 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,891 - train - INFO - True
2024-04-02 18:10:58,891 - train - INFO - alphas:tensor([0.3777, 0.6223], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,892 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,892 - train - INFO - True
2024-04-02 18:10:58,893 - train - INFO - alphas:tensor([0.2380, 0.7620], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,893 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,893 - train - INFO - True
2024-04-02 18:10:58,894 - train - INFO - alphas:tensor([0.3540, 0.6460], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,894 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,895 - train - INFO - True
2024-04-02 18:10:58,895 - train - INFO - alphas:tensor([0.4420, 0.5580], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,896 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,896 - train - INFO - True
2024-04-02 18:10:58,897 - train - INFO - alphas:tensor([0.3028, 0.6972], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,897 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,897 - train - INFO - True
2024-04-02 18:10:58,898 - train - INFO - alphas:tensor([0.2049, 0.7951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,898 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,899 - train - INFO - True
2024-04-02 18:10:58,899 - train - INFO - alphas:tensor([0.2605, 0.7395], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,900 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,900 - train - INFO - True
2024-04-02 18:10:58,901 - train - INFO - alphas:tensor([0.2949, 0.7051], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,901 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,901 - train - INFO - True
2024-04-02 18:10:58,902 - train - INFO - alphas:tensor([0.0992, 0.9008], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,902 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,903 - train - INFO - True
2024-04-02 18:10:58,903 - train - INFO - alphas:tensor([0.1459, 0.8541], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,904 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,904 - train - INFO - True
2024-04-02 18:10:58,905 - train - INFO - alphas:tensor([0.1738, 0.8262], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,905 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,906 - train - INFO - True
2024-04-02 18:10:58,906 - train - INFO - alphas:tensor([0.2444, 0.7556], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,907 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,907 - train - INFO - True
2024-04-02 18:10:58,908 - train - INFO - alphas:tensor([0.0067, 0.9933], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,908 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,908 - train - INFO - True
2024-04-02 18:10:58,909 - train - INFO - alphas:tensor([0.0749, 0.9251], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,909 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,909 - train - INFO - True
2024-04-02 18:10:58,910 - train - INFO - alphas:tensor([9.1217e-04, 9.9909e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,910 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,911 - train - INFO - True
2024-04-02 18:10:58,911 - train - INFO - alphas:tensor([1.2529e-04, 9.9987e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,912 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,912 - train - INFO - True
2024-04-02 18:10:58,913 - train - INFO - alphas:tensor([5.7110e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,913 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,913 - train - INFO - True
2024-04-02 18:10:58,914 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:10:58,914 - train - INFO - tau:0.36237201786049694
2024-04-02 18:10:58,914 - train - INFO - avg block size:13.931034482758621
2024-04-02 18:11:00,784 - train - INFO - Test: [   0/39]  Time: 1.867 (1.867)  Loss:  0.3674 (0.3674)  Acc@1: 91.4062 (91.4062)  Acc@5: 100.0000 (100.0000)
2024-04-02 18:12:11,396 - train - INFO - Test: [  39/39]  Time: 1.796 (1.812)  Loss:  0.3789 (0.3679)  Acc@1: 81.2500 (92.1500)  Acc@5: 100.0000 (99.7500)
2024-04-02 18:12:14,958 - train - INFO - Train: 104 [   0/195 (  0%)]  Loss:  1.687665 (1.6877)  Time: 3.174s,   80.65/s  (3.174s,   80.65/s)  LR: 1.259e-04  Data: 0.251 (0.251)
2024-04-02 18:14:44,087 - train - INFO - Train: 104 [  50/195 ( 26%)]  Loss:  1.619173 (1.5647)  Time: 2.823s,   90.68/s  (2.986s,   85.72/s)  LR: 1.259e-04  Data: 0.031 (0.020)
2024-04-02 18:17:13,502 - train - INFO - Train: 104 [ 100/195 ( 52%)]  Loss:  1.663742 (1.5519)  Time: 2.697s,   94.91/s  (2.987s,   85.70/s)  LR: 1.259e-04  Data: 0.020 (0.018)
2024-04-02 18:19:46,567 - train - INFO - Train: 104 [ 150/195 ( 77%)]  Loss:  1.796178 (1.5522)  Time: 2.861s,   89.48/s  (3.012s,   85.00/s)  LR: 1.259e-04  Data: 0.005 (0.017)
2024-04-02 18:21:57,718 - train - INFO - Train: 104 [ 194/195 (100%)]  Loss:  1.748569 (1.5448)  Time: 2.885s,   88.75/s  (3.005s,   85.20/s)  LR: 1.259e-04  Data: 0.000 (0.016)
2024-04-02 18:21:57,719 - train - INFO - True
2024-04-02 18:21:57,730 - train - INFO - alphas:tensor([1.1520e-04, 9.9988e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,731 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,731 - train - INFO - True
2024-04-02 18:21:57,732 - train - INFO - alphas:tensor([0.0469, 0.9531], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,732 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,732 - train - INFO - True
2024-04-02 18:21:57,733 - train - INFO - alphas:tensor([0.5072, 0.4928], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,733 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,733 - train - INFO - True
2024-04-02 18:21:57,734 - train - INFO - alphas:tensor([0.4313, 0.5687], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,734 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,735 - train - INFO - True
2024-04-02 18:21:57,736 - train - INFO - alphas:tensor([0.1031, 0.8969], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,748 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,748 - train - INFO - True
2024-04-02 18:21:57,749 - train - INFO - alphas:tensor([0.2093, 0.7907], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,749 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,749 - train - INFO - True
2024-04-02 18:21:57,750 - train - INFO - alphas:tensor([0.5021, 0.4979], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,750 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,751 - train - INFO - True
2024-04-02 18:21:57,751 - train - INFO - alphas:tensor([0.3965, 0.6035], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,752 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,755 - train - INFO - True
2024-04-02 18:21:57,756 - train - INFO - alphas:tensor([0.2212, 0.7788], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,756 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,756 - train - INFO - True
2024-04-02 18:21:57,757 - train - INFO - alphas:tensor([0.3562, 0.6438], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,757 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,758 - train - INFO - True
2024-04-02 18:21:57,758 - train - INFO - alphas:tensor([0.5061, 0.4939], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,759 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,759 - train - INFO - True
2024-04-02 18:21:57,760 - train - INFO - alphas:tensor([0.3791, 0.6209], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,760 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,760 - train - INFO - True
2024-04-02 18:21:57,761 - train - INFO - alphas:tensor([0.2373, 0.7627], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,761 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,762 - train - INFO - True
2024-04-02 18:21:57,762 - train - INFO - alphas:tensor([0.3560, 0.6440], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,767 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,767 - train - INFO - True
2024-04-02 18:21:57,768 - train - INFO - alphas:tensor([0.4429, 0.5571], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,768 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,769 - train - INFO - True
2024-04-02 18:21:57,769 - train - INFO - alphas:tensor([0.3051, 0.6949], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,770 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,770 - train - INFO - True
2024-04-02 18:21:57,771 - train - INFO - alphas:tensor([0.2047, 0.7953], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,771 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,771 - train - INFO - True
2024-04-02 18:21:57,772 - train - INFO - alphas:tensor([0.2610, 0.7390], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,772 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,772 - train - INFO - True
2024-04-02 18:21:57,782 - train - INFO - alphas:tensor([0.2940, 0.7060], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,782 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,783 - train - INFO - True
2024-04-02 18:21:57,783 - train - INFO - alphas:tensor([0.0974, 0.9026], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,784 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,784 - train - INFO - True
2024-04-02 18:21:57,785 - train - INFO - alphas:tensor([0.1446, 0.8554], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,785 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,785 - train - INFO - True
2024-04-02 18:21:57,786 - train - INFO - alphas:tensor([0.1720, 0.8280], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,786 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,786 - train - INFO - True
2024-04-02 18:21:57,787 - train - INFO - alphas:tensor([0.2438, 0.7562], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,788 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,788 - train - INFO - True
2024-04-02 18:21:57,789 - train - INFO - alphas:tensor([0.0062, 0.9938], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,789 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,789 - train - INFO - True
2024-04-02 18:21:57,790 - train - INFO - alphas:tensor([0.0739, 0.9261], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,790 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,790 - train - INFO - True
2024-04-02 18:21:57,791 - train - INFO - alphas:tensor([8.2356e-04, 9.9918e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,791 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,792 - train - INFO - True
2024-04-02 18:21:57,792 - train - INFO - alphas:tensor([1.1139e-04, 9.9989e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,797 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,798 - train - INFO - True
2024-04-02 18:21:57,798 - train - INFO - alphas:tensor([4.9915e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,799 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,799 - train - INFO - True
2024-04-02 18:21:57,800 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:21:57,800 - train - INFO - tau:0.358748297681892
2024-04-02 18:21:57,800 - train - INFO - avg block size:13.931034482758621
2024-04-02 18:21:59,715 - train - INFO - Test: [   0/39]  Time: 1.911 (1.911)  Loss:  0.3582 (0.3582)  Acc@1: 92.9688 (92.9688)  Acc@5: 99.6094 (99.6094)
2024-04-02 18:23:10,535 - train - INFO - Test: [  39/39]  Time: 1.686 (1.818)  Loss:  0.3340 (0.3655)  Acc@1: 87.5000 (92.1800)  Acc@5: 100.0000 (99.7100)
2024-04-02 18:23:14,270 - train - INFO - Train: 105 [   0/195 (  0%)]  Loss:  1.631534 (1.6315)  Time: 3.455s,   74.09/s  (3.455s,   74.09/s)  LR: 1.213e-04  Data: 0.280 (0.280)
2024-04-02 18:25:38,358 - train - INFO - Train: 105 [  50/195 ( 26%)]  Loss:  1.674510 (1.6156)  Time: 2.191s,  116.85/s  (2.893s,   88.49/s)  LR: 1.213e-04  Data: 0.018 (0.018)
2024-04-02 18:28:07,948 - train - INFO - Train: 105 [ 100/195 ( 52%)]  Loss:  1.831146 (1.5897)  Time: 2.906s,   88.10/s  (2.942s,   87.02/s)  LR: 1.213e-04  Data: 0.006 (0.017)
2024-04-02 18:30:37,246 - train - INFO - Train: 105 [ 150/195 ( 77%)]  Loss:  1.800760 (1.5900)  Time: 3.691s,   69.36/s  (2.956s,   86.59/s)  LR: 1.213e-04  Data: 0.021 (0.016)
2024-04-02 18:32:49,876 - train - INFO - Train: 105 [ 194/195 (100%)]  Loss:  1.411179 (1.5892)  Time: 2.889s,   88.62/s  (2.969s,   86.21/s)  LR: 1.213e-04  Data: 0.000 (0.016)
2024-04-02 18:32:49,881 - train - INFO - True
2024-04-02 18:32:49,883 - train - INFO - alphas:tensor([1.0288e-04, 9.9990e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,883 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,883 - train - INFO - True
2024-04-02 18:32:49,884 - train - INFO - alphas:tensor([0.0461, 0.9539], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,884 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,884 - train - INFO - True
2024-04-02 18:32:49,885 - train - INFO - alphas:tensor([0.5070, 0.4930], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,885 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,885 - train - INFO - True
2024-04-02 18:32:49,886 - train - INFO - alphas:tensor([0.4308, 0.5692], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,886 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,887 - train - INFO - True
2024-04-02 18:32:49,887 - train - INFO - alphas:tensor([0.1021, 0.8979], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,888 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,888 - train - INFO - True
2024-04-02 18:32:49,889 - train - INFO - alphas:tensor([0.2087, 0.7913], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,889 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,889 - train - INFO - True
2024-04-02 18:32:49,890 - train - INFO - alphas:tensor([0.5012, 0.4988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,890 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,891 - train - INFO - True
2024-04-02 18:32:49,892 - train - INFO - alphas:tensor([0.3946, 0.6054], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,892 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,892 - train - INFO - True
2024-04-02 18:32:49,893 - train - INFO - alphas:tensor([0.2206, 0.7794], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,893 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,893 - train - INFO - True
2024-04-02 18:32:49,894 - train - INFO - alphas:tensor([0.3543, 0.6457], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,894 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,895 - train - INFO - True
2024-04-02 18:32:49,896 - train - INFO - alphas:tensor([0.5046, 0.4954], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,896 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,897 - train - INFO - True
2024-04-02 18:32:49,898 - train - INFO - alphas:tensor([0.3762, 0.6238], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,898 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,898 - train - INFO - True
2024-04-02 18:32:49,903 - train - INFO - alphas:tensor([0.2369, 0.7631], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,904 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,904 - train - INFO - True
2024-04-02 18:32:49,905 - train - INFO - alphas:tensor([0.3553, 0.6447], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,905 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,905 - train - INFO - True
2024-04-02 18:32:49,906 - train - INFO - alphas:tensor([0.4410, 0.5590], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,906 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,907 - train - INFO - True
2024-04-02 18:32:49,907 - train - INFO - alphas:tensor([0.3037, 0.6963], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,908 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,908 - train - INFO - True
2024-04-02 18:32:49,909 - train - INFO - alphas:tensor([0.2034, 0.7966], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,909 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,909 - train - INFO - True
2024-04-02 18:32:49,910 - train - INFO - alphas:tensor([0.2604, 0.7396], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,910 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,910 - train - INFO - True
2024-04-02 18:32:49,911 - train - INFO - alphas:tensor([0.2928, 0.7072], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,912 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,912 - train - INFO - True
2024-04-02 18:32:49,913 - train - INFO - alphas:tensor([0.0955, 0.9045], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,913 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,913 - train - INFO - True
2024-04-02 18:32:49,914 - train - INFO - alphas:tensor([0.1433, 0.8567], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,914 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,915 - train - INFO - True
2024-04-02 18:32:49,916 - train - INFO - alphas:tensor([0.1706, 0.8294], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,916 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,916 - train - INFO - True
2024-04-02 18:32:49,917 - train - INFO - alphas:tensor([0.2423, 0.7577], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,922 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,922 - train - INFO - True
2024-04-02 18:32:49,923 - train - INFO - alphas:tensor([0.0056, 0.9944], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,923 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,923 - train - INFO - True
2024-04-02 18:32:49,924 - train - INFO - alphas:tensor([0.0734, 0.9266], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,924 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,924 - train - INFO - True
2024-04-02 18:32:49,925 - train - INFO - alphas:tensor([7.4346e-04, 9.9926e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,925 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,926 - train - INFO - True
2024-04-02 18:32:49,926 - train - INFO - alphas:tensor([9.9015e-05, 9.9990e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,927 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,927 - train - INFO - True
2024-04-02 18:32:49,928 - train - INFO - alphas:tensor([4.3599e-06, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,928 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,928 - train - INFO - True
2024-04-02 18:32:49,929 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:32:49,929 - train - INFO - tau:0.35516081470507305
2024-04-02 18:32:49,929 - train - INFO - avg block size:13.931034482758621
2024-04-02 18:32:51,859 - train - INFO - Test: [   0/39]  Time: 1.927 (1.927)  Loss:  0.3735 (0.3735)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-02 18:34:03,583 - train - INFO - Test: [  39/39]  Time: 1.808 (1.841)  Loss:  0.4136 (0.3714)  Acc@1: 81.2500 (92.2400)  Acc@5: 100.0000 (99.7300)
2024-04-02 18:34:07,338 - train - INFO - Train: 106 [   0/195 (  0%)]  Loss:  1.706269 (1.7063)  Time: 3.344s,   76.56/s  (3.344s,   76.56/s)  LR: 1.168e-04  Data: 0.343 (0.343)
2024-04-02 18:36:33,825 - train - INFO - Train: 106 [  50/195 ( 26%)]  Loss:  1.760801 (1.5632)  Time: 3.082s,   83.06/s  (2.938s,   87.14/s)  LR: 1.168e-04  Data: 0.022 (0.020)
2024-04-02 18:38:59,298 - train - INFO - Train: 106 [ 100/195 ( 52%)]  Loss:  1.499788 (1.5918)  Time: 2.982s,   85.86/s  (2.924s,   87.56/s)  LR: 1.168e-04  Data: 0.010 (0.017)
2024-04-02 18:41:23,896 - train - INFO - Train: 106 [ 150/195 ( 77%)]  Loss:  1.271093 (1.5966)  Time: 2.682s,   95.44/s  (2.913s,   87.88/s)  LR: 1.168e-04  Data: 0.015 (0.016)
2024-04-02 18:43:35,486 - train - INFO - Train: 106 [ 194/195 (100%)]  Loss:  1.223928 (1.5853)  Time: 3.183s,   80.43/s  (2.931s,   87.35/s)  LR: 1.168e-04  Data: 0.000 (0.016)
2024-04-02 18:43:35,487 - train - INFO - True
2024-04-02 18:43:35,488 - train - INFO - alphas:tensor([9.1767e-05, 9.9991e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,489 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,489 - train - INFO - True
2024-04-02 18:43:35,490 - train - INFO - alphas:tensor([0.0450, 0.9550], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,490 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,490 - train - INFO - True
2024-04-02 18:43:35,491 - train - INFO - alphas:tensor([0.5058, 0.4942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,491 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,491 - train - INFO - True
2024-04-02 18:43:35,492 - train - INFO - alphas:tensor([0.4285, 0.5715], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,492 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,492 - train - INFO - True
2024-04-02 18:43:35,506 - train - INFO - alphas:tensor([0.1012, 0.8988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,507 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,507 - train - INFO - True
2024-04-02 18:43:35,508 - train - INFO - alphas:tensor([0.2079, 0.7921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,508 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,508 - train - INFO - True
2024-04-02 18:43:35,509 - train - INFO - alphas:tensor([0.5004, 0.4996], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,510 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,510 - train - INFO - True
2024-04-02 18:43:35,511 - train - INFO - alphas:tensor([0.3935, 0.6065], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,511 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,511 - train - INFO - True
2024-04-02 18:43:35,512 - train - INFO - alphas:tensor([0.2198, 0.7802], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,512 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,512 - train - INFO - True
2024-04-02 18:43:35,513 - train - INFO - alphas:tensor([0.3544, 0.6456], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,514 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,514 - train - INFO - True
2024-04-02 18:43:35,515 - train - INFO - alphas:tensor([0.5045, 0.4955], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,515 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,515 - train - INFO - True
2024-04-02 18:43:35,516 - train - INFO - alphas:tensor([0.3745, 0.6255], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,516 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,516 - train - INFO - True
2024-04-02 18:43:35,517 - train - INFO - alphas:tensor([0.2360, 0.7640], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,517 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,518 - train - INFO - True
2024-04-02 18:43:35,519 - train - INFO - alphas:tensor([0.3547, 0.6453], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,519 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,519 - train - INFO - True
2024-04-02 18:43:35,529 - train - INFO - alphas:tensor([0.4407, 0.5593], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,529 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,530 - train - INFO - True
2024-04-02 18:43:35,530 - train - INFO - alphas:tensor([0.3039, 0.6961], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,531 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,531 - train - INFO - True
2024-04-02 18:43:35,532 - train - INFO - alphas:tensor([0.2023, 0.7977], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,532 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,532 - train - INFO - True
2024-04-02 18:43:35,533 - train - INFO - alphas:tensor([0.2591, 0.7409], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,533 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,534 - train - INFO - True
2024-04-02 18:43:35,534 - train - INFO - alphas:tensor([0.2898, 0.7102], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,535 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,535 - train - INFO - True
2024-04-02 18:43:35,536 - train - INFO - alphas:tensor([0.0943, 0.9057], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,536 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,536 - train - INFO - True
2024-04-02 18:43:35,537 - train - INFO - alphas:tensor([0.1429, 0.8571], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,537 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,538 - train - INFO - True
2024-04-02 18:43:35,538 - train - INFO - alphas:tensor([0.1709, 0.8291], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,539 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,539 - train - INFO - True
2024-04-02 18:43:35,540 - train - INFO - alphas:tensor([0.2406, 0.7594], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,540 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,540 - train - INFO - True
2024-04-02 18:43:35,546 - train - INFO - alphas:tensor([0.0052, 0.9948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,550 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,550 - train - INFO - True
2024-04-02 18:43:35,551 - train - INFO - alphas:tensor([0.0726, 0.9274], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,552 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,552 - train - INFO - True
2024-04-02 18:43:35,553 - train - INFO - alphas:tensor([6.7048e-04, 9.9933e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,553 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,553 - train - INFO - True
2024-04-02 18:43:35,554 - train - INFO - alphas:tensor([8.7861e-05, 9.9991e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,554 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,554 - train - INFO - True
2024-04-02 18:43:35,560 - train - INFO - alphas:tensor([3.8044e-06, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,564 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,565 - train - INFO - True
2024-04-02 18:43:35,565 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:43:35,566 - train - INFO - tau:0.3516092065580223
2024-04-02 18:43:35,566 - train - INFO - avg block size:13.931034482758621
2024-04-02 18:43:37,517 - train - INFO - Test: [   0/39]  Time: 1.947 (1.947)  Loss:  0.3779 (0.3779)  Acc@1: 91.7969 (91.7969)  Acc@5: 100.0000 (100.0000)
2024-04-02 18:44:48,553 - train - INFO - Test: [  39/39]  Time: 1.785 (1.825)  Loss:  0.3491 (0.3717)  Acc@1: 87.5000 (92.2300)  Acc@5: 100.0000 (99.7700)
2024-04-02 18:44:52,054 - train - INFO - Train: 107 [   0/195 (  0%)]  Loss:  1.776146 (1.7761)  Time: 3.190s,   80.25/s  (3.190s,   80.25/s)  LR: 1.123e-04  Data: 0.334 (0.334)
2024-04-02 18:47:15,802 - train - INFO - Train: 107 [  50/195 ( 26%)]  Loss:  1.263768 (1.5753)  Time: 2.553s,  100.28/s  (2.881s,   88.86/s)  LR: 1.123e-04  Data: 0.010 (0.020)
2024-04-02 18:49:42,169 - train - INFO - Train: 107 [ 100/195 ( 52%)]  Loss:  1.791381 (1.5775)  Time: 3.083s,   83.03/s  (2.904s,   88.16/s)  LR: 1.123e-04  Data: 0.005 (0.018)
2024-04-02 18:52:08,705 - train - INFO - Train: 107 [ 150/195 ( 77%)]  Loss:  1.832177 (1.5750)  Time: 3.174s,   80.66/s  (2.913s,   87.89/s)  LR: 1.123e-04  Data: 0.005 (0.016)
2024-04-02 18:54:19,391 - train - INFO - Train: 107 [ 194/195 (100%)]  Loss:  1.421919 (1.5753)  Time: 3.349s,   76.44/s  (2.926s,   87.50/s)  LR: 1.123e-04  Data: 0.000 (0.016)
2024-04-02 18:54:19,395 - train - INFO - True
2024-04-02 18:54:19,397 - train - INFO - alphas:tensor([8.1934e-05, 9.9992e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,397 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,402 - train - INFO - True
2024-04-02 18:54:19,402 - train - INFO - alphas:tensor([0.0442, 0.9558], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,403 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,403 - train - INFO - True
2024-04-02 18:54:19,404 - train - INFO - alphas:tensor([0.5068, 0.4932], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,404 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,404 - train - INFO - True
2024-04-02 18:54:19,405 - train - INFO - alphas:tensor([0.4292, 0.5708], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,405 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,406 - train - INFO - True
2024-04-02 18:54:19,406 - train - INFO - alphas:tensor([0.1001, 0.8999], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,407 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,407 - train - INFO - True
2024-04-02 18:54:19,408 - train - INFO - alphas:tensor([0.2070, 0.7930], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,426 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,426 - train - INFO - True
2024-04-02 18:54:19,427 - train - INFO - alphas:tensor([0.4996, 0.5004], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,431 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,432 - train - INFO - True
2024-04-02 18:54:19,432 - train - INFO - alphas:tensor([0.3923, 0.6077], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,433 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,433 - train - INFO - True
2024-04-02 18:54:19,434 - train - INFO - alphas:tensor([0.2189, 0.7811], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,434 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,434 - train - INFO - True
2024-04-02 18:54:19,435 - train - INFO - alphas:tensor([0.3538, 0.6462], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,435 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,435 - train - INFO - True
2024-04-02 18:54:19,436 - train - INFO - alphas:tensor([0.5036, 0.4964], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,437 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,437 - train - INFO - True
2024-04-02 18:54:19,455 - train - INFO - alphas:tensor([0.3734, 0.6266], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,455 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,456 - train - INFO - True
2024-04-02 18:54:19,456 - train - INFO - alphas:tensor([0.2356, 0.7644], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,457 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,457 - train - INFO - True
2024-04-02 18:54:19,458 - train - INFO - alphas:tensor([0.3538, 0.6462], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,458 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,458 - train - INFO - True
2024-04-02 18:54:19,459 - train - INFO - alphas:tensor([0.4398, 0.5602], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,459 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,459 - train - INFO - True
2024-04-02 18:54:19,460 - train - INFO - alphas:tensor([0.3022, 0.6978], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,468 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,468 - train - INFO - True
2024-04-02 18:54:19,469 - train - INFO - alphas:tensor([0.2016, 0.7984], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,469 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,469 - train - INFO - True
2024-04-02 18:54:19,470 - train - INFO - alphas:tensor([0.2569, 0.7431], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,470 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,471 - train - INFO - True
2024-04-02 18:54:19,484 - train - INFO - alphas:tensor([0.2898, 0.7102], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,486 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,486 - train - INFO - True
2024-04-02 18:54:19,487 - train - INFO - alphas:tensor([0.0927, 0.9073], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,488 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,489 - train - INFO - True
2024-04-02 18:54:19,490 - train - INFO - alphas:tensor([0.1429, 0.8571], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,490 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,490 - train - INFO - True
2024-04-02 18:54:19,491 - train - INFO - alphas:tensor([0.1705, 0.8295], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,504 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,505 - train - INFO - True
2024-04-02 18:54:19,505 - train - INFO - alphas:tensor([0.2396, 0.7604], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,506 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,506 - train - INFO - True
2024-04-02 18:54:19,508 - train - INFO - alphas:tensor([0.0048, 0.9952], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,509 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,509 - train - INFO - True
2024-04-02 18:54:19,514 - train - INFO - alphas:tensor([0.0712, 0.9288], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,514 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,514 - train - INFO - True
2024-04-02 18:54:19,515 - train - INFO - alphas:tensor([6.0409e-04, 9.9940e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,516 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,516 - train - INFO - True
2024-04-02 18:54:19,517 - train - INFO - alphas:tensor([7.8139e-05, 9.9992e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,517 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,517 - train - INFO - True
2024-04-02 18:54:19,518 - train - INFO - alphas:tensor([3.3182e-06, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,518 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,518 - train - INFO - True
2024-04-02 18:54:19,519 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 18:54:19,519 - train - INFO - tau:0.34809311449244207
2024-04-02 18:54:19,520 - train - INFO - avg block size:14.448275862068966
2024-04-02 18:54:21,649 - train - INFO - Test: [   0/39]  Time: 2.124 (2.124)  Loss:  0.3667 (0.3667)  Acc@1: 91.7969 (91.7969)  Acc@5: 100.0000 (100.0000)
2024-04-02 18:55:35,006 - train - INFO - Test: [  39/39]  Time: 1.813 (1.887)  Loss:  0.3171 (0.3651)  Acc@1: 87.5000 (92.2100)  Acc@5: 100.0000 (99.7700)
2024-04-02 18:55:38,363 - train - INFO - Train: 108 [   0/195 (  0%)]  Loss:  1.268378 (1.2684)  Time: 3.143s,   81.44/s  (3.143s,   81.44/s)  LR: 1.079e-04  Data: 0.253 (0.253)
