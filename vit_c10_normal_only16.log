2024-04-01 14:45:38,532 - train - INFO - Training with a single process on 1 GPUs.
2024-04-01 14:46:01,157 - train - INFO - Model vit_7_4_32 created, param count:3716931
2024-04-01 14:46:01,203 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-04-01 14:46:01,203 - train - INFO - Scheduled epochs: 160
2024-04-01 14:46:04,102 - train - INFO - Verifying teacher model
2024-04-01 14:46:05,561 - train - INFO - Test: [   0/39]  Time: 1.457 (1.457)  Loss:  0.3433 (0.3433)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-01 14:46:06,941 - train - INFO - Test: [  39/39]  Time: 0.131 (0.071)  Loss:  0.3740 (0.3449)  Acc@1: 93.7500 (93.5400)  Acc@5: 100.0000 (99.7600)
2024-04-01 14:46:06,942 - train - INFO - Verifying initial model
2024-04-01 14:46:08,811 - train - INFO - Test: [   0/39]  Time: 1.868 (1.868)  Loss:  2.0332 (2.0332)  Acc@1: 27.7344 (27.7344)  Acc@5: 71.4844 (71.4844)
2024-04-01 14:47:32,014 - train - INFO - Test: [  39/39]  Time: 1.581 (2.127)  Loss:  1.8789 (2.0274)  Acc@1: 37.5000 (28.2900)  Acc@5: 81.2500 (73.7800)
2024-04-01 14:47:36,918 - train - INFO - Train: 0 [   0/195 (  0%)]  Loss:  2.338976 (2.3390)  Time: 4.899s,   52.25/s  (4.899s,   52.25/s)  LR: 1.000e-05  Data: 0.803 (0.803)
2024-04-01 14:50:31,432 - train - INFO - Train: 0 [  50/195 ( 26%)]  Loss:  2.319045 (2.3114)  Time: 3.270s,   78.28/s  (3.518s,   72.77/s)  LR: 1.000e-05  Data: 0.005 (0.035)
2024-04-01 14:53:22,817 - train - INFO - Train: 0 [ 100/195 ( 52%)]  Loss:  2.267416 (2.2968)  Time: 3.746s,   68.35/s  (3.473s,   73.71/s)  LR: 1.000e-05  Data: 0.016 (0.025)
2024-04-01 14:56:13,667 - train - INFO - Train: 0 [ 150/195 ( 77%)]  Loss:  2.212688 (2.2848)  Time: 3.204s,   79.89/s  (3.455s,   74.11/s)  LR: 1.000e-05  Data: 0.023 (0.023)
2024-04-01 14:58:46,545 - train - INFO - Train: 0 [ 194/195 (100%)]  Loss:  2.225019 (2.2760)  Time: 3.794s,   67.47/s  (3.459s,   74.01/s)  LR: 1.000e-05  Data: 0.000 (0.021)
2024-04-01 14:58:46,568 - train - INFO - True
2024-04-01 14:58:46,677 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,678 - train - INFO - True
2024-04-01 14:58:46,679 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,679 - train - INFO - True
2024-04-01 14:58:46,680 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,680 - train - INFO - True
2024-04-01 14:58:46,681 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,681 - train - INFO - True
2024-04-01 14:58:46,682 - train - INFO - alphas:tensor([0.5011, 0.4989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,683 - train - INFO - True
2024-04-01 14:58:46,683 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,684 - train - INFO - True
2024-04-01 14:58:46,693 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,694 - train - INFO - True
2024-04-01 14:58:46,699 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,700 - train - INFO - True
2024-04-01 14:58:46,701 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,701 - train - INFO - True
2024-04-01 14:58:46,716 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,716 - train - INFO - True
2024-04-01 14:58:46,717 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,717 - train - INFO - True
2024-04-01 14:58:46,718 - train - INFO - alphas:tensor([0.5011, 0.4989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,719 - train - INFO - True
2024-04-01 14:58:46,720 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,722 - train - INFO - True
2024-04-01 14:58:46,723 - train - INFO - alphas:tensor([0.5011, 0.4989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,726 - train - INFO - True
2024-04-01 14:58:46,727 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,728 - train - INFO - True
2024-04-01 14:58:46,728 - train - INFO - alphas:tensor([0.5008, 0.4992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,729 - train - INFO - True
2024-04-01 14:58:46,730 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,730 - train - INFO - True
2024-04-01 14:58:46,740 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,740 - train - INFO - True
2024-04-01 14:58:46,741 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,741 - train - INFO - True
2024-04-01 14:58:46,742 - train - INFO - alphas:tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,742 - train - INFO - True
2024-04-01 14:58:46,743 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,743 - train - INFO - True
2024-04-01 14:58:46,749 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,749 - train - INFO - True
2024-04-01 14:58:46,750 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,751 - train - INFO - True
2024-04-01 14:58:46,752 - train - INFO - alphas:tensor([0.5008, 0.4992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,752 - train - INFO - True
2024-04-01 14:58:46,753 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,753 - train - INFO - True
2024-04-01 14:58:46,755 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,760 - train - INFO - True
2024-04-01 14:58:46,761 - train - INFO - alphas:tensor([0.5006, 0.4994], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,761 - train - INFO - True
2024-04-01 14:58:46,767 - train - INFO - alphas:tensor([0.5008, 0.4992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,767 - train - INFO - True
2024-04-01 14:58:46,768 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 14:58:46,769 - train - INFO - avg block size:tensor(1., device='cuda:0')
2024-04-01 14:58:49,121 - train - INFO - Test: [   0/39]  Time: 2.348 (2.348)  Loss:  1.8232 (1.8232)  Acc@1: 50.7812 (50.7812)  Acc@5: 90.2344 (90.2344)
2024-04-01 15:00:11,178 - train - INFO - Test: [  39/39]  Time: 2.213 (2.110)  Loss:  1.7266 (1.8040)  Acc@1: 62.5000 (48.6000)  Acc@5: 93.7500 (91.3100)
2024-04-01 15:00:15,103 - train - INFO - Train: 1 [   0/195 (  0%)]  Loss:  2.257061 (2.2571)  Time: 3.734s,   68.56/s  (3.734s,   68.56/s)  LR: 6.400e-05  Data: 0.349 (0.349)
2024-04-01 15:03:09,617 - train - INFO - Train: 1 [  50/195 ( 26%)]  Loss:  2.259063 (2.1982)  Time: 3.350s,   76.42/s  (3.495s,   73.25/s)  LR: 6.400e-05  Data: 0.005 (0.022)
2024-04-01 15:06:01,009 - train - INFO - Train: 1 [ 100/195 ( 52%)]  Loss:  2.048971 (2.1403)  Time: 3.601s,   71.08/s  (3.462s,   73.95/s)  LR: 6.400e-05  Data: 0.005 (0.020)
2024-04-01 15:08:51,546 - train - INFO - Train: 1 [ 150/195 ( 77%)]  Loss:  1.917429 (2.1152)  Time: 2.944s,   86.94/s  (3.445s,   74.31/s)  LR: 6.400e-05  Data: 0.024 (0.018)
2024-04-01 15:11:23,538 - train - INFO - Train: 1 [ 194/195 (100%)]  Loss:  1.913672 (2.0905)  Time: 3.456s,   74.08/s  (3.447s,   74.27/s)  LR: 6.400e-05  Data: 0.000 (0.017)
2024-04-01 15:11:23,539 - train - INFO - True
2024-04-01 15:11:23,541 - train - INFO - alphas:tensor([0.5083, 0.4917], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,541 - train - INFO - True
2024-04-01 15:11:23,542 - train - INFO - alphas:tensor([0.5076, 0.4924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,542 - train - INFO - True
2024-04-01 15:11:23,548 - train - INFO - alphas:tensor([0.5090, 0.4910], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,549 - train - INFO - True
2024-04-01 15:11:23,550 - train - INFO - alphas:tensor([0.5099, 0.4901], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,550 - train - INFO - True
2024-04-01 15:11:23,551 - train - INFO - alphas:tensor([0.5091, 0.4909], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,552 - train - INFO - True
2024-04-01 15:11:23,552 - train - INFO - alphas:tensor([0.5086, 0.4914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,553 - train - INFO - True
2024-04-01 15:11:23,554 - train - INFO - alphas:tensor([0.5082, 0.4918], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,555 - train - INFO - True
2024-04-01 15:11:23,561 - train - INFO - alphas:tensor([0.5083, 0.4917], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,561 - train - INFO - True
2024-04-01 15:11:23,568 - train - INFO - alphas:tensor([0.5085, 0.4915], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,568 - train - INFO - True
2024-04-01 15:11:23,574 - train - INFO - alphas:tensor([0.5079, 0.4921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,575 - train - INFO - True
2024-04-01 15:11:23,576 - train - INFO - alphas:tensor([0.5076, 0.4924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,576 - train - INFO - True
2024-04-01 15:11:23,577 - train - INFO - alphas:tensor([0.5084, 0.4916], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,588 - train - INFO - True
2024-04-01 15:11:23,589 - train - INFO - alphas:tensor([0.5078, 0.4922], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,589 - train - INFO - True
2024-04-01 15:11:23,590 - train - INFO - alphas:tensor([0.5072, 0.4928], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,591 - train - INFO - True
2024-04-01 15:11:23,592 - train - INFO - alphas:tensor([0.5079, 0.4921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,592 - train - INFO - True
2024-04-01 15:11:23,594 - train - INFO - alphas:tensor([0.5088, 0.4912], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,594 - train - INFO - True
2024-04-01 15:11:23,595 - train - INFO - alphas:tensor([0.5077, 0.4923], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,596 - train - INFO - True
2024-04-01 15:11:23,597 - train - INFO - alphas:tensor([0.5067, 0.4933], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,597 - train - INFO - True
2024-04-01 15:11:23,598 - train - INFO - alphas:tensor([0.5059, 0.4941], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,599 - train - INFO - True
2024-04-01 15:11:23,625 - train - INFO - alphas:tensor([0.5066, 0.4934], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,625 - train - INFO - True
2024-04-01 15:11:23,626 - train - INFO - alphas:tensor([0.5067, 0.4933], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,631 - train - INFO - True
2024-04-01 15:11:23,632 - train - INFO - alphas:tensor([0.5061, 0.4939], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,633 - train - INFO - True
2024-04-01 15:11:23,634 - train - INFO - alphas:tensor([0.5052, 0.4948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,634 - train - INFO - True
2024-04-01 15:11:23,635 - train - INFO - alphas:tensor([0.5071, 0.4929], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,635 - train - INFO - True
2024-04-01 15:11:23,637 - train - INFO - alphas:tensor([0.5066, 0.4934], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,637 - train - INFO - True
2024-04-01 15:11:23,638 - train - INFO - alphas:tensor([0.5054, 0.4946], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,639 - train - INFO - True
2024-04-01 15:11:23,640 - train - INFO - alphas:tensor([0.5061, 0.4939], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,640 - train - INFO - True
2024-04-01 15:11:23,641 - train - INFO - alphas:tensor([0.5066, 0.4934], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,642 - train - INFO - True
2024-04-01 15:11:23,643 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:11:23,644 - train - INFO - avg block size:tensor(1., device='cuda:0')
2024-04-01 15:11:25,823 - train - INFO - Test: [   0/39]  Time: 2.159 (2.159)  Loss:  1.1494 (1.1494)  Acc@1: 67.5781 (67.5781)  Acc@5: 97.2656 (97.2656)
2024-04-01 15:12:45,457 - train - INFO - Test: [  39/39]  Time: 2.251 (2.045)  Loss:  1.1299 (1.1188)  Acc@1: 68.7500 (66.2700)  Acc@5: 100.0000 (97.1900)
2024-04-01 15:12:49,584 - train - INFO - Train: 2 [   0/195 (  0%)]  Loss:  2.043181 (2.0432)  Time: 3.929s,   65.15/s  (3.929s,   65.15/s)  LR: 1.180e-04  Data: 0.472 (0.472)
2024-04-01 15:15:41,411 - train - INFO - Train: 2 [  50/195 ( 26%)]  Loss:  1.837753 (1.9770)  Time: 3.298s,   77.63/s  (3.446s,   74.29/s)  LR: 1.180e-04  Data: 0.014 (0.025)
2024-04-01 15:18:33,221 - train - INFO - Train: 2 [ 100/195 ( 52%)]  Loss:  1.852038 (1.9591)  Time: 3.838s,   66.71/s  (3.441s,   74.39/s)  LR: 1.180e-04  Data: 0.018 (0.021)
2024-04-01 15:21:25,959 - train - INFO - Train: 2 [ 150/195 ( 77%)]  Loss:  1.649886 (1.9450)  Time: 3.533s,   72.46/s  (3.446s,   74.30/s)  LR: 1.180e-04  Data: 0.015 (0.020)
2024-04-01 15:23:55,152 - train - INFO - Train: 2 [ 194/195 (100%)]  Loss:  2.051990 (1.9311)  Time: 3.762s,   68.06/s  (3.433s,   74.57/s)  LR: 1.180e-04  Data: 0.000 (0.019)
2024-04-01 15:23:55,162 - train - INFO - True
2024-04-01 15:23:55,164 - train - INFO - alphas:tensor([0.5209, 0.4791], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,164 - train - INFO - True
2024-04-01 15:23:55,165 - train - INFO - alphas:tensor([0.5183, 0.4817], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,166 - train - INFO - True
2024-04-01 15:23:55,167 - train - INFO - alphas:tensor([0.5237, 0.4763], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,167 - train - INFO - True
2024-04-01 15:23:55,168 - train - INFO - alphas:tensor([0.5247, 0.4753], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,168 - train - INFO - True
2024-04-01 15:23:55,170 - train - INFO - alphas:tensor([0.5223, 0.4777], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,170 - train - INFO - True
2024-04-01 15:23:55,180 - train - INFO - alphas:tensor([0.5207, 0.4793], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,189 - train - INFO - True
2024-04-01 15:23:55,190 - train - INFO - alphas:tensor([0.5202, 0.4798], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,191 - train - INFO - True
2024-04-01 15:23:55,192 - train - INFO - alphas:tensor([0.5204, 0.4796], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,192 - train - INFO - True
2024-04-01 15:23:55,193 - train - INFO - alphas:tensor([0.5232, 0.4768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,193 - train - INFO - True
2024-04-01 15:23:55,194 - train - INFO - alphas:tensor([0.5221, 0.4779], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,194 - train - INFO - True
2024-04-01 15:23:55,195 - train - INFO - alphas:tensor([0.5184, 0.4816], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,196 - train - INFO - True
2024-04-01 15:23:55,197 - train - INFO - alphas:tensor([0.5199, 0.4801], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,197 - train - INFO - True
2024-04-01 15:23:55,198 - train - INFO - alphas:tensor([0.5184, 0.4816], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,199 - train - INFO - True
2024-04-01 15:23:55,199 - train - INFO - alphas:tensor([0.5171, 0.4829], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,200 - train - INFO - True
2024-04-01 15:23:55,201 - train - INFO - alphas:tensor([0.5189, 0.4811], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,201 - train - INFO - True
2024-04-01 15:23:55,202 - train - INFO - alphas:tensor([0.5221, 0.4779], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,202 - train - INFO - True
2024-04-01 15:23:55,203 - train - INFO - alphas:tensor([0.5155, 0.4845], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,203 - train - INFO - True
2024-04-01 15:23:55,222 - train - INFO - alphas:tensor([0.5143, 0.4857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,223 - train - INFO - True
2024-04-01 15:23:55,224 - train - INFO - alphas:tensor([0.5143, 0.4857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,224 - train - INFO - True
2024-04-01 15:23:55,225 - train - INFO - alphas:tensor([0.5182, 0.4818], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,226 - train - INFO - True
2024-04-01 15:23:55,236 - train - INFO - alphas:tensor([0.5126, 0.4874], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,236 - train - INFO - True
2024-04-01 15:23:55,238 - train - INFO - alphas:tensor([0.5128, 0.4872], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,238 - train - INFO - True
2024-04-01 15:23:55,239 - train - INFO - alphas:tensor([0.5124, 0.4876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,240 - train - INFO - True
2024-04-01 15:23:55,241 - train - INFO - alphas:tensor([0.5152, 0.4848], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,241 - train - INFO - True
2024-04-01 15:23:55,242 - train - INFO - alphas:tensor([0.5114, 0.4886], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,242 - train - INFO - True
2024-04-01 15:23:55,244 - train - INFO - alphas:tensor([0.5099, 0.4901], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,244 - train - INFO - True
2024-04-01 15:23:55,245 - train - INFO - alphas:tensor([0.5136, 0.4864], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,246 - train - INFO - True
2024-04-01 15:23:55,246 - train - INFO - alphas:tensor([0.5100, 0.4900], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,247 - train - INFO - True
2024-04-01 15:23:55,248 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:23:55,249 - train - INFO - avg block size:tensor(1., device='cuda:0')
2024-04-01 15:23:57,219 - train - INFO - Test: [   0/39]  Time: 1.952 (1.952)  Loss:  0.8896 (0.8896)  Acc@1: 77.3438 (77.3438)  Acc@5: 98.0469 (98.0469)
2024-04-01 15:25:17,488 - train - INFO - Test: [  39/39]  Time: 2.031 (2.056)  Loss:  0.9614 (0.8472)  Acc@1: 68.7500 (76.2100)  Acc@5: 100.0000 (98.4600)
2024-04-01 15:25:21,403 - train - INFO - Train: 3 [   0/195 (  0%)]  Loss:  2.021247 (2.0212)  Time: 3.694s,   69.31/s  (3.694s,   69.31/s)  LR: 1.720e-04  Data: 0.402 (0.402)
2024-04-01 15:28:13,045 - train - INFO - Train: 3 [  50/195 ( 26%)]  Loss:  1.683755 (1.8744)  Time: 3.554s,   72.03/s  (3.438s,   74.47/s)  LR: 1.720e-04  Data: 0.005 (0.025)
2024-04-01 15:31:08,066 - train - INFO - Train: 3 [ 100/195 ( 52%)]  Loss:  1.887263 (1.8453)  Time: 3.687s,   69.43/s  (3.469s,   73.80/s)  LR: 1.720e-04  Data: 0.012 (0.022)
2024-04-01 15:33:59,389 - train - INFO - Train: 3 [ 150/195 ( 77%)]  Loss:  1.879720 (1.8267)  Time: 3.281s,   78.03/s  (3.455s,   74.10/s)  LR: 1.720e-04  Data: 0.005 (0.021)
2024-04-01 15:36:34,948 - train - INFO - Train: 3 [ 194/195 (100%)]  Loss:  1.948990 (1.8218)  Time: 4.157s,   61.58/s  (3.473s,   73.71/s)  LR: 1.720e-04  Data: 0.000 (0.019)
2024-04-01 15:36:34,958 - train - INFO - True
2024-04-01 15:36:34,960 - train - INFO - alphas:tensor([0.5357, 0.4643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:34,961 - train - INFO - tau:0.99
2024-04-01 15:36:34,966 - train - INFO - True
2024-04-01 15:36:34,967 - train - INFO - alphas:tensor([0.5296, 0.4704], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:34,968 - train - INFO - tau:0.99
2024-04-01 15:36:34,968 - train - INFO - True
2024-04-01 15:36:34,970 - train - INFO - alphas:tensor([0.5422, 0.4578], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:34,993 - train - INFO - tau:0.99
2024-04-01 15:36:34,993 - train - INFO - True
2024-04-01 15:36:34,994 - train - INFO - alphas:tensor([0.5439, 0.4561], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:34,994 - train - INFO - tau:0.99
2024-04-01 15:36:34,995 - train - INFO - True
2024-04-01 15:36:34,996 - train - INFO - alphas:tensor([0.5374, 0.4626], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:34,996 - train - INFO - tau:0.99
2024-04-01 15:36:34,996 - train - INFO - True
2024-04-01 15:36:34,997 - train - INFO - alphas:tensor([0.5356, 0.4644], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:34,998 - train - INFO - tau:0.99
2024-04-01 15:36:34,999 - train - INFO - True
2024-04-01 15:36:35,000 - train - INFO - alphas:tensor([0.5352, 0.4648], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,000 - train - INFO - tau:0.99
2024-04-01 15:36:35,005 - train - INFO - True
2024-04-01 15:36:35,011 - train - INFO - alphas:tensor([0.5354, 0.4646], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,012 - train - INFO - tau:0.99
2024-04-01 15:36:35,012 - train - INFO - True
2024-04-01 15:36:35,013 - train - INFO - alphas:tensor([0.5427, 0.4573], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,013 - train - INFO - tau:0.99
2024-04-01 15:36:35,013 - train - INFO - True
2024-04-01 15:36:35,038 - train - INFO - alphas:tensor([0.5432, 0.4568], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,038 - train - INFO - tau:0.99
2024-04-01 15:36:35,038 - train - INFO - True
2024-04-01 15:36:35,039 - train - INFO - alphas:tensor([0.5331, 0.4669], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,040 - train - INFO - tau:0.99
2024-04-01 15:36:35,040 - train - INFO - True
2024-04-01 15:36:35,041 - train - INFO - alphas:tensor([0.5357, 0.4643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,043 - train - INFO - tau:0.99
2024-04-01 15:36:35,043 - train - INFO - True
2024-04-01 15:36:35,044 - train - INFO - alphas:tensor([0.5342, 0.4658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,049 - train - INFO - tau:0.99
2024-04-01 15:36:35,050 - train - INFO - True
2024-04-01 15:36:35,078 - train - INFO - alphas:tensor([0.5340, 0.4660], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,078 - train - INFO - tau:0.99
2024-04-01 15:36:35,079 - train - INFO - True
2024-04-01 15:36:35,080 - train - INFO - alphas:tensor([0.5346, 0.4654], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,080 - train - INFO - tau:0.99
2024-04-01 15:36:35,080 - train - INFO - True
2024-04-01 15:36:35,081 - train - INFO - alphas:tensor([0.5398, 0.4602], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,082 - train - INFO - tau:0.99
2024-04-01 15:36:35,082 - train - INFO - True
2024-04-01 15:36:35,083 - train - INFO - alphas:tensor([0.5260, 0.4740], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,084 - train - INFO - tau:0.99
2024-04-01 15:36:35,085 - train - INFO - True
2024-04-01 15:36:35,086 - train - INFO - alphas:tensor([0.5251, 0.4749], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,086 - train - INFO - tau:0.99
2024-04-01 15:36:35,086 - train - INFO - True
2024-04-01 15:36:35,087 - train - INFO - alphas:tensor([0.5279, 0.4721], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,088 - train - INFO - tau:0.99
2024-04-01 15:36:35,088 - train - INFO - True
2024-04-01 15:36:35,102 - train - INFO - alphas:tensor([0.5359, 0.4641], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,103 - train - INFO - tau:0.99
2024-04-01 15:36:35,103 - train - INFO - True
2024-04-01 15:36:35,104 - train - INFO - alphas:tensor([0.5194, 0.4806], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,104 - train - INFO - tau:0.99
2024-04-01 15:36:35,105 - train - INFO - True
2024-04-01 15:36:35,110 - train - INFO - alphas:tensor([0.5211, 0.4789], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,111 - train - INFO - tau:0.99
2024-04-01 15:36:35,111 - train - INFO - True
2024-04-01 15:36:35,112 - train - INFO - alphas:tensor([0.5237, 0.4763], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,112 - train - INFO - tau:0.99
2024-04-01 15:36:35,113 - train - INFO - True
2024-04-01 15:36:35,114 - train - INFO - alphas:tensor([0.5272, 0.4728], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,114 - train - INFO - tau:0.99
2024-04-01 15:36:35,114 - train - INFO - True
2024-04-01 15:36:35,115 - train - INFO - alphas:tensor([0.5174, 0.4826], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,115 - train - INFO - tau:0.99
2024-04-01 15:36:35,116 - train - INFO - True
2024-04-01 15:36:35,117 - train - INFO - alphas:tensor([0.5161, 0.4839], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,117 - train - INFO - tau:0.99
2024-04-01 15:36:35,118 - train - INFO - True
2024-04-01 15:36:35,119 - train - INFO - alphas:tensor([0.5271, 0.4729], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,119 - train - INFO - tau:0.99
2024-04-01 15:36:35,119 - train - INFO - True
2024-04-01 15:36:35,121 - train - INFO - alphas:tensor([0.5171, 0.4829], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,122 - train - INFO - tau:0.99
2024-04-01 15:36:35,123 - train - INFO - True
2024-04-01 15:36:35,129 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-01 15:36:35,129 - train - INFO - tau:0.99
2024-04-01 15:36:35,131 - train - INFO - avg block size:tensor(1., device='cuda:0')
2024-04-01 15:36:37,484 - train - INFO - Test: [   0/39]  Time: 2.344 (2.344)  Loss:  0.7910 (0.7910)  Acc@1: 78.1250 (78.1250)  Acc@5: 98.8281 (98.8281)
2024-04-01 15:38:03,343 - train - INFO - Test: [  39/39]  Time: 2.513 (2.205)  Loss:  0.8237 (0.7394)  Acc@1: 68.7500 (81.3000)  Acc@5: 100.0000 (98.8400)
2024-04-01 15:38:07,799 - train - INFO - Train: 4 [   0/195 (  0%)]  Loss:  1.933491 (1.9335)  Time: 4.154s,   61.63/s  (4.154s,   61.63/s)  LR: 2.260e-04  Data: 0.540 (0.540)
2024-04-01 15:41:03,252 - train - INFO - Train: 4 [  50/195 ( 26%)]  Loss:  1.515938 (1.7535)  Time: 3.416s,   74.94/s  (3.522s,   72.69/s)  LR: 2.260e-04  Data: 0.010 (0.027)
2024-04-01 15:43:59,316 - train - INFO - Train: 4 [ 100/195 ( 52%)]  Loss:  1.959317 (1.7413)  Time: 3.021s,   84.75/s  (3.521s,   72.70/s)  LR: 2.260e-04  Data: 0.006 (0.021)
2024-04-01 15:46:49,669 - train - INFO - Train: 4 [ 150/195 ( 77%)]  Loss:  2.039302 (1.7238)  Time: 3.015s,   84.91/s  (3.484s,   73.49/s)  LR: 2.260e-04  Data: 0.010 (0.019)
