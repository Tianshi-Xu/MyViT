2024-04-17 15:42:37,659 - train - INFO - aa: rand-m9-mstd0.5-inc1
amp: true
apex_amp: false
aug_splits: 0
batch_size: 128
bn_eps: null
bn_momentum: null
bn_tf: false
budget: 0.25
channels_last: false
checkpoint_hist: 3
clip_grad: null
clip_mode: norm
color_jitter: 0.4
cooldown_epochs: 10
crop_pct: 0.9
cutmix: 1.0
cutmix_minmax: null
data_dir: /home/xts/code/dataset/tiny-imagenet-200
dataset: torch/image_folder
decay_epochs: 30
decay_rate: 0.1
dist_bn: ''
drop: 0.0
drop_block: null
drop_connect: null
drop_path: null
epoch_repeats: 0.0
epochs: 300
eval_metric: top1
experiment: ''
finetune: false
fix_blocksize: -1
fix_blocksize_list: 1,1,1,1,1,1,16,8,16,8,1,1,16,16,16,16,16,16,1,2,16,16,16,16,1,2,16,16,16,16,1,8
gp: null
hflip: 0.5
img_size: 64
initial_checkpoint: /home/xts/code/njeans/MyViT/pretrained/mbv2_tiny.pth.tar
input_size: null
interpolation: bicubic
jsd: false
kd_alpha: 4
lasso_alpha: 0
lasso_beta: 1
local_rank: 0
log_interval: 50
log_name: mbv2_tiny_b4_hawq
log_wandb: false
lr: 0.00055
lr_cycle_limit: 1
lr_cycle_mul: 1.0
lr_noise: null
lr_noise_pct: 0.67
lr_noise_std: 1.0
mean:
- 0.485
- 0.456
- 0.406
min_lr: 1.0e-05
mixup: 0.8
mixup_mode: batch
mixup_off_epoch: 0
mixup_prob: 1.0
mixup_switch_prob: 0.5
model: tiny_nas_mobilenetv2
model_ema: false
model_ema_decay: 0.9998
model_ema_force_cpu: false
momentum: 0.9
native_amp: false
no_aug: false
no_prefetcher: false
no_resume_opt: false
num_classes: 200
opt: adamw
opt_betas: null
opt_eps: null
output: ''
patience_epochs: 10
pin_mem: false
pretrained: false
ratio:
- 0.75
- 1.3333333333333333
recount: 1
recovery_interval: 0
remode: pixel
reprob: 0.25
resplit: false
resume: ''
save_images: false
scale:
- 0.8
- 1.0
sched: cosine
seed: 3407
smoothing: 0.1
split_bn: false
start_epoch: null
std:
- 0.229
- 0.224
- 0.225
sync_bn: false
tau: 1
teacher: tiny_mobilenetv2
teacher_checkpoint: /home/xts/code/njeans/MyViT/pretrained/mbv2_tiny.pth.tar
torchscript: false
train_interpolation: random
train_split: train
tta: 0
use_kd: true
use_multi_epochs_loader: false
val_split: valid
validation_batch_size_multiplier: 1
vflip: 0.0
warmup_epochs: 10
warmup_lr: 1.0e-05
weight_decay: 0.06
workers: 4

2024-04-17 15:42:37,660 - train - INFO - Training with a single process on 1 GPUs.
2024-04-17 15:42:38,120 - train - INFO - MobileNetV2(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (1): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (8): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (9): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (10): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (11): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (12): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (14): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)
        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (15): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (16): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (17): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv): Sequential(
    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=1280, out_features=200, bias=True)
)
2024-04-17 15:42:40,140 - train - INFO - Model tiny_nas_mobilenetv2 created, param count:2480263
2024-04-17 15:42:40,154 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-04-17 15:42:40,155 - train - INFO - Scheduled epochs: 310
2024-04-17 15:42:40,569 - train - INFO - Verifying teacher model
2024-04-17 15:42:41,434 - train - INFO - Test: [   0/78]  Time: 0.864 (0.864)  Loss:  0.9253 (0.9253)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-17 15:42:41,975 - train - INFO - Test: [  50/78]  Time: 0.009 (0.028)  Loss:  1.4883 (1.5408)  Acc@1: 69.5312 (66.6207)  Acc@5: 89.8438 (86.7188)
2024-04-17 15:42:42,634 - train - INFO - Test: [  78/78]  Time: 0.361 (0.026)  Loss:  1.7324 (1.5640)  Acc@1: 68.7500 (66.1400)  Acc@5: 100.0000 (86.4500)
2024-04-17 15:42:42,634 - train - INFO - Verifying initial model
2024-04-17 15:42:42,773 - train - INFO - Test: [   0/78]  Time: 0.137 (0.137)  Loss: 12.2188 (12.2188)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
2024-04-17 15:42:44,042 - train - INFO - Test: [  50/78]  Time: 0.025 (0.028)  Loss:  4.7266 (8.0924)  Acc@1:  1.5625 ( 0.7812)  Acc@5: 48.4375 ( 2.3131)
2024-04-17 15:42:44,834 - train - INFO - Test: [  78/78]  Time: 0.022 (0.028)  Loss:  7.1406 (8.0591)  Acc@1:  0.0000 ( 0.6400)  Acc@5:  0.0000 ( 2.8300)
2024-04-17 15:42:46,103 - train - INFO - Train: 0 [   0/781 (  0%)]  Loss:  5.440799 (5.4408)  Time: 1.267s,  101.04/s  (1.267s,  101.04/s)  LR: 1.000e-05  Data: 0.234 (0.234)
2024-04-17 15:42:51,417 - train - INFO - Train: 0 [  50/781 (  6%)]  Loss:  5.392580 (5.3206)  Time: 0.108s, 1185.28/s  (0.129s,  992.34/s)  LR: 1.000e-05  Data: 0.008 (0.012)
2024-04-17 15:42:56,618 - train - INFO - Train: 0 [ 100/781 ( 13%)]  Loss:  5.041999 (5.2578)  Time: 0.087s, 1477.22/s  (0.117s, 1097.76/s)  LR: 1.000e-05  Data: 0.007 (0.010)
2024-04-17 15:43:01,578 - train - INFO - Train: 0 [ 150/781 ( 19%)]  Loss:  5.109828 (5.2119)  Time: 0.105s, 1216.00/s  (0.111s, 1154.95/s)  LR: 1.000e-05  Data: 0.009 (0.009)
2024-04-17 15:43:06,407 - train - INFO - Train: 0 [ 200/781 ( 26%)]  Loss:  5.082803 (5.1789)  Time: 0.095s, 1350.23/s  (0.107s, 1193.18/s)  LR: 1.000e-05  Data: 0.007 (0.009)
2024-04-17 15:43:11,142 - train - INFO - Train: 0 [ 250/781 ( 32%)]  Loss:  5.006811 (5.1490)  Time: 0.095s, 1342.97/s  (0.105s, 1221.77/s)  LR: 1.000e-05  Data: 0.007 (0.009)
2024-04-17 15:43:16,281 - train - INFO - Train: 0 [ 300/781 ( 38%)]  Loss:  4.983908 (5.1159)  Time: 0.107s, 1194.26/s  (0.104s, 1225.72/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-17 15:43:21,072 - train - INFO - Train: 0 [ 350/781 ( 45%)]  Loss:  4.941753 (5.0887)  Time: 0.087s, 1475.99/s  (0.103s, 1240.32/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-17 15:43:25,721 - train - INFO - Train: 0 [ 400/781 ( 51%)]  Loss:  4.968748 (5.0704)  Time: 0.111s, 1157.77/s  (0.102s, 1255.88/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-17 15:43:30,408 - train - INFO - Train: 0 [ 450/781 ( 58%)]  Loss:  4.942870 (5.0522)  Time: 0.093s, 1377.26/s  (0.101s, 1267.20/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-17 15:43:35,404 - train - INFO - Train: 0 [ 500/781 ( 64%)]  Loss:  4.971768 (5.0314)  Time: 0.080s, 1597.21/s  (0.101s, 1268.58/s)  LR: 1.000e-05  Data: 0.004 (0.008)
2024-04-17 15:43:40,356 - train - INFO - Train: 0 [ 550/781 ( 71%)]  Loss:  4.861588 (5.0148)  Time: 0.086s, 1485.79/s  (0.101s, 1270.75/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-17 15:43:45,074 - train - INFO - Train: 0 [ 600/781 ( 77%)]  Loss:  4.488594 (4.9958)  Time: 0.090s, 1421.30/s  (0.100s, 1277.50/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-17 15:43:49,832 - train - INFO - Train: 0 [ 650/781 ( 83%)]  Loss:  5.035501 (4.9833)  Time: 0.105s, 1217.38/s  (0.100s, 1282.47/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-17 15:43:54,838 - train - INFO - Train: 0 [ 700/781 ( 90%)]  Loss:  4.557128 (4.9701)  Time: 0.086s, 1481.14/s  (0.100s, 1282.22/s)  LR: 1.000e-05  Data: 0.005 (0.008)
2024-04-17 15:43:59,549 - train - INFO - Train: 0 [ 750/781 ( 96%)]  Loss:  5.003270 (4.9564)  Time: 0.090s, 1423.88/s  (0.099s, 1287.07/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-17 15:44:02,365 - train - INFO - Train: 0 [ 780/781 (100%)]  Loss:  4.993304 (4.9498)  Time: 0.082s, 1552.58/s  (0.099s, 1289.85/s)  LR: 1.000e-05  Data: 0.000 (0.008)
2024-04-17 15:44:02,479 - train - INFO - Test: [   0/78]  Time: 0.112 (0.112)  Loss:  2.8633 (2.8633)  Acc@1: 39.0625 (39.0625)  Acc@5: 62.5000 (62.5000)
2024-04-17 15:44:03,866 - train - INFO - Test: [  50/78]  Time: 0.026 (0.029)  Loss:  3.6504 (3.9295)  Acc@1: 21.8750 (16.4216)  Acc@5: 48.4375 (38.2353)
2024-04-17 15:44:04,593 - train - INFO - Test: [  78/78]  Time: 0.024 (0.028)  Loss:  3.3008 (3.9051)  Acc@1: 37.5000 (17.3100)  Acc@5: 43.7500 (39.1000)
2024-04-17 15:44:04,896 - train - INFO - Train: 1 [   0/781 (  0%)]  Loss:  4.876980 (4.8770)  Time: 0.220s,  582.46/s  (0.220s,  582.46/s)  LR: 6.400e-05  Data: 0.120 (0.120)
2024-04-17 15:44:09,549 - train - INFO - Train: 1 [  50/781 (  6%)]  Loss:  4.857801 (4.7478)  Time: 0.105s, 1224.48/s  (0.096s, 1339.80/s)  LR: 6.400e-05  Data: 0.008 (0.010)
2024-04-17 15:44:14,436 - train - INFO - Train: 1 [ 100/781 ( 13%)]  Loss:  4.727823 (4.6889)  Time: 0.102s, 1249.45/s  (0.097s, 1324.92/s)  LR: 6.400e-05  Data: 0.009 (0.009)
2024-04-17 15:44:19,230 - train - INFO - Train: 1 [ 150/781 ( 19%)]  Loss:  4.286883 (4.6468)  Time: 0.094s, 1363.38/s  (0.096s, 1328.36/s)  LR: 6.400e-05  Data: 0.007 (0.008)
2024-04-17 15:44:23,992 - train - INFO - Train: 1 [ 200/781 ( 26%)]  Loss:  4.577913 (4.6222)  Time: 0.091s, 1408.39/s  (0.096s, 1332.33/s)  LR: 6.400e-05  Data: 0.008 (0.008)
2024-04-17 15:44:28,482 - train - INFO - Train: 1 [ 250/781 ( 32%)]  Loss:  4.220306 (4.6103)  Time: 0.082s, 1567.70/s  (0.095s, 1349.97/s)  LR: 6.400e-05  Data: 0.006 (0.008)
2024-04-17 15:44:33,334 - train - INFO - Train: 1 [ 300/781 ( 38%)]  Loss:  4.397378 (4.5844)  Time: 0.110s, 1163.18/s  (0.095s, 1344.80/s)  LR: 6.400e-05  Data: 0.009 (0.008)
2024-04-17 15:44:38,242 - train - INFO - Train: 1 [ 350/781 ( 45%)]  Loss:  4.412224 (4.5658)  Time: 0.087s, 1477.13/s  (0.096s, 1338.86/s)  LR: 6.400e-05  Data: 0.007 (0.008)
2024-04-17 15:44:42,988 - train - INFO - Train: 1 [ 400/781 ( 51%)]  Loss:  4.737433 (4.5490)  Time: 0.103s, 1243.80/s  (0.096s, 1340.09/s)  LR: 6.400e-05  Data: 0.008 (0.008)
2024-04-17 15:44:47,953 - train - INFO - Train: 1 [ 450/781 ( 58%)]  Loss:  4.332452 (4.5249)  Time: 0.100s, 1281.96/s  (0.096s, 1334.27/s)  LR: 6.400e-05  Data: 0.008 (0.008)
2024-04-17 15:44:52,845 - train - INFO - Train: 1 [ 500/781 ( 64%)]  Loss:  4.460498 (4.5029)  Time: 0.092s, 1390.97/s  (0.096s, 1331.69/s)  LR: 6.400e-05  Data: 0.006 (0.008)
2024-04-17 15:44:57,833 - train - INFO - Train: 1 [ 550/781 ( 71%)]  Loss:  3.877296 (4.4826)  Time: 0.109s, 1171.54/s  (0.096s, 1327.15/s)  LR: 6.400e-05  Data: 0.008 (0.008)
2024-04-17 15:45:02,672 - train - INFO - Train: 1 [ 600/781 ( 77%)]  Loss:  4.466160 (4.4707)  Time: 0.099s, 1290.50/s  (0.096s, 1326.81/s)  LR: 6.400e-05  Data: 0.006 (0.008)
2024-04-17 15:45:07,421 - train - INFO - Train: 1 [ 650/781 ( 83%)]  Loss:  4.304735 (4.4544)  Time: 0.089s, 1438.80/s  (0.096s, 1328.40/s)  LR: 6.400e-05  Data: 0.007 (0.008)
2024-04-17 15:45:12,247 - train - INFO - Train: 1 [ 700/781 ( 90%)]  Loss:  3.835352 (4.4337)  Time: 0.103s, 1245.75/s  (0.096s, 1328.28/s)  LR: 6.400e-05  Data: 0.007 (0.008)
2024-04-17 15:45:17,370 - train - INFO - Train: 1 [ 750/781 ( 96%)]  Loss:  4.462873 (4.4209)  Time: 0.096s, 1336.72/s  (0.097s, 1322.75/s)  LR: 6.400e-05  Data: 0.007 (0.008)
2024-04-17 15:45:20,292 - train - INFO - Train: 1 [ 780/781 (100%)]  Loss:  4.140614 (4.4119)  Time: 0.091s, 1401.37/s  (0.097s, 1322.43/s)  LR: 6.400e-05  Data: 0.000 (0.008)
2024-04-17 15:45:20,390 - train - INFO - Test: [   0/78]  Time: 0.096 (0.096)  Loss:  1.8398 (1.8398)  Acc@1: 59.3750 (59.3750)  Acc@5: 82.0312 (82.0312)
2024-04-17 15:45:21,721 - train - INFO - Test: [  50/78]  Time: 0.027 (0.028)  Loss:  2.7637 (2.8694)  Acc@1: 42.9688 (34.7426)  Acc@5: 60.1562 (63.1587)
2024-04-17 15:45:22,475 - train - INFO - Test: [  78/78]  Time: 0.047 (0.028)  Loss:  3.2969 (2.8708)  Acc@1: 25.0000 (34.9600)  Acc@5: 50.0000 (62.8400)
2024-04-17 15:45:22,773 - train - INFO - Train: 2 [   0/781 (  0%)]  Loss:  3.964783 (3.9648)  Time: 0.209s,  610.99/s  (0.209s,  610.99/s)  LR: 1.180e-04  Data: 0.133 (0.133)
2024-04-17 15:45:27,629 - train - INFO - Train: 2 [  50/781 (  6%)]  Loss:  4.292984 (4.2913)  Time: 0.093s, 1381.34/s  (0.099s, 1289.09/s)  LR: 1.180e-04  Data: 0.007 (0.010)
2024-04-17 15:45:32,479 - train - INFO - Train: 2 [ 100/781 ( 13%)]  Loss:  3.987674 (4.2517)  Time: 0.105s, 1224.35/s  (0.098s, 1304.24/s)  LR: 1.180e-04  Data: 0.006 (0.009)
2024-04-17 15:45:37,364 - train - INFO - Train: 2 [ 150/781 ( 19%)]  Loss:  3.933164 (4.2258)  Time: 0.108s, 1183.43/s  (0.098s, 1306.30/s)  LR: 1.180e-04  Data: 0.009 (0.008)
2024-04-17 15:45:42,128 - train - INFO - Train: 2 [ 200/781 ( 26%)]  Loss:  4.438139 (4.2120)  Time: 0.094s, 1362.60/s  (0.097s, 1315.42/s)  LR: 1.180e-04  Data: 0.009 (0.008)
2024-04-17 15:45:46,862 - train - INFO - Train: 2 [ 250/781 ( 32%)]  Loss:  3.948581 (4.2005)  Time: 0.097s, 1318.22/s  (0.097s, 1322.60/s)  LR: 1.180e-04  Data: 0.008 (0.008)
2024-04-17 15:45:51,607 - train - INFO - Train: 2 [ 300/781 ( 38%)]  Loss:  4.669068 (4.1966)  Time: 0.088s, 1448.24/s  (0.096s, 1326.96/s)  LR: 1.180e-04  Data: 0.006 (0.008)
2024-04-17 15:45:56,509 - train - INFO - Train: 2 [ 350/781 ( 45%)]  Loss:  4.203195 (4.1866)  Time: 0.092s, 1398.46/s  (0.097s, 1323.90/s)  LR: 1.180e-04  Data: 0.008 (0.008)
2024-04-17 15:46:01,366 - train - INFO - Train: 2 [ 400/781 ( 51%)]  Loss:  4.372506 (4.1772)  Time: 0.098s, 1307.72/s  (0.097s, 1323.20/s)  LR: 1.180e-04  Data: 0.008 (0.008)
2024-04-17 15:46:06,152 - train - INFO - Train: 2 [ 450/781 ( 58%)]  Loss:  3.897235 (4.1657)  Time: 0.092s, 1386.10/s  (0.097s, 1324.77/s)  LR: 1.180e-04  Data: 0.008 (0.008)
2024-04-17 15:46:10,958 - train - INFO - Train: 2 [ 500/781 ( 64%)]  Loss:  3.959780 (4.1498)  Time: 0.108s, 1183.45/s  (0.097s, 1325.49/s)  LR: 1.180e-04  Data: 0.008 (0.008)
2024-04-17 15:46:15,781 - train - INFO - Train: 2 [ 550/781 ( 71%)]  Loss:  4.112132 (4.1360)  Time: 0.099s, 1295.97/s  (0.097s, 1325.65/s)  LR: 1.180e-04  Data: 0.007 (0.008)
2024-04-17 15:46:20,589 - train - INFO - Train: 2 [ 600/781 ( 77%)]  Loss:  4.056204 (4.1267)  Time: 0.088s, 1450.81/s  (0.097s, 1326.14/s)  LR: 1.180e-04  Data: 0.008 (0.008)
2024-04-17 15:46:25,462 - train - INFO - Train: 2 [ 650/781 ( 83%)]  Loss:  4.532578 (4.1208)  Time: 0.101s, 1263.03/s  (0.097s, 1325.17/s)  LR: 1.180e-04  Data: 0.008 (0.008)
2024-04-17 15:46:30,382 - train - INFO - Train: 2 [ 700/781 ( 90%)]  Loss:  4.355759 (4.1117)  Time: 0.105s, 1217.32/s  (0.097s, 1323.44/s)  LR: 1.180e-04  Data: 0.008 (0.008)
2024-04-17 15:46:35,412 - train - INFO - Train: 2 [ 750/781 ( 96%)]  Loss:  4.481480 (4.1065)  Time: 0.082s, 1567.96/s  (0.097s, 1319.93/s)  LR: 1.180e-04  Data: 0.005 (0.008)
2024-04-17 15:46:38,370 - train - INFO - Train: 2 [ 780/781 (100%)]  Loss:  3.669642 (4.1027)  Time: 0.101s, 1272.18/s  (0.097s, 1319.10/s)  LR: 1.180e-04  Data: 0.000 (0.008)
2024-04-17 15:46:38,490 - train - INFO - Test: [   0/78]  Time: 0.118 (0.118)  Loss:  1.3926 (1.3926)  Acc@1: 71.8750 (71.8750)  Acc@5: 87.5000 (87.5000)
2024-04-17 15:46:40,047 - train - INFO - Test: [  50/78]  Time: 0.026 (0.033)  Loss:  2.4844 (2.4705)  Acc@1: 45.3125 (42.9994)  Acc@5: 69.5312 (70.5576)
2024-04-17 15:46:40,799 - train - INFO - Test: [  78/78]  Time: 0.031 (0.031)  Loss:  2.9961 (2.4765)  Acc@1: 18.7500 (43.1700)  Acc@5: 68.7500 (70.5500)
2024-04-17 15:46:41,101 - train - INFO - Train: 3 [   0/781 (  0%)]  Loss:  4.330813 (4.3308)  Time: 0.211s,  607.81/s  (0.211s,  607.81/s)  LR: 1.720e-04  Data: 0.119 (0.119)
2024-04-17 15:46:46,063 - train - INFO - Train: 3 [  50/781 (  6%)]  Loss:  4.472362 (4.0207)  Time: 0.093s, 1370.46/s  (0.101s, 1262.41/s)  LR: 1.720e-04  Data: 0.008 (0.010)
2024-04-17 15:46:50,660 - train - INFO - Train: 3 [ 100/781 ( 13%)]  Loss:  4.408855 (3.9644)  Time: 0.085s, 1507.16/s  (0.097s, 1323.65/s)  LR: 1.720e-04  Data: 0.007 (0.009)
2024-04-17 15:46:55,399 - train - INFO - Train: 3 [ 150/781 ( 19%)]  Loss:  4.391161 (3.9350)  Time: 0.090s, 1423.70/s  (0.096s, 1332.60/s)  LR: 1.720e-04  Data: 0.007 (0.008)
2024-04-17 15:47:00,245 - train - INFO - Train: 3 [ 200/781 ( 26%)]  Loss:  4.141346 (3.9175)  Time: 0.097s, 1324.85/s  (0.096s, 1329.69/s)  LR: 1.720e-04  Data: 0.007 (0.008)
2024-04-17 15:47:05,119 - train - INFO - Train: 3 [ 250/781 ( 32%)]  Loss:  3.356090 (3.9289)  Time: 0.083s, 1548.58/s  (0.097s, 1326.42/s)  LR: 1.720e-04  Data: 0.004 (0.008)
2024-04-17 15:47:10,003 - train - INFO - Train: 3 [ 300/781 ( 38%)]  Loss:  4.357209 (3.9359)  Time: 0.093s, 1380.90/s  (0.097s, 1323.83/s)  LR: 1.720e-04  Data: 0.008 (0.008)
2024-04-17 15:47:14,851 - train - INFO - Train: 3 [ 350/781 ( 45%)]  Loss:  4.287937 (3.9306)  Time: 0.101s, 1271.93/s  (0.097s, 1323.33/s)  LR: 1.720e-04  Data: 0.009 (0.008)
2024-04-17 15:47:19,579 - train - INFO - Train: 3 [ 400/781 ( 51%)]  Loss:  3.960902 (3.9272)  Time: 0.096s, 1340.22/s  (0.096s, 1327.10/s)  LR: 1.720e-04  Data: 0.006 (0.008)
2024-04-17 15:47:24,409 - train - INFO - Train: 3 [ 450/781 ( 58%)]  Loss:  4.091219 (3.9230)  Time: 0.097s, 1321.88/s  (0.096s, 1326.92/s)  LR: 1.720e-04  Data: 0.007 (0.008)
2024-04-17 15:47:29,638 - train - INFO - Train: 3 [ 500/781 ( 64%)]  Loss:  3.465936 (3.9204)  Time: 0.115s, 1111.38/s  (0.097s, 1315.92/s)  LR: 1.720e-04  Data: 0.005 (0.008)
2024-04-17 15:47:34,717 - train - INFO - Train: 3 [ 550/781 ( 71%)]  Loss:  3.725435 (3.9099)  Time: 0.092s, 1385.55/s  (0.098s, 1310.70/s)  LR: 1.720e-04  Data: 0.007 (0.008)
2024-04-17 15:47:39,634 - train - INFO - Train: 3 [ 600/781 ( 77%)]  Loss:  3.924483 (3.9076)  Time: 0.091s, 1402.08/s  (0.098s, 1309.97/s)  LR: 1.720e-04  Data: 0.008 (0.008)
2024-04-17 15:47:44,386 - train - INFO - Train: 3 [ 650/781 ( 83%)]  Loss:  3.848055 (3.9059)  Time: 0.097s, 1315.52/s  (0.098s, 1312.76/s)  LR: 1.720e-04  Data: 0.007 (0.008)
2024-04-17 15:47:49,230 - train - INFO - Train: 3 [ 700/781 ( 90%)]  Loss:  3.517645 (3.9044)  Time: 0.108s, 1187.09/s  (0.097s, 1313.39/s)  LR: 1.720e-04  Data: 0.009 (0.008)
2024-04-17 15:47:54,182 - train - INFO - Train: 3 [ 750/781 ( 96%)]  Loss:  3.335059 (3.9021)  Time: 0.086s, 1481.62/s  (0.098s, 1312.00/s)  LR: 1.720e-04  Data: 0.006 (0.008)
2024-04-17 15:47:57,198 - train - INFO - Train: 3 [ 780/781 (100%)]  Loss:  3.566634 (3.9001)  Time: 0.102s, 1253.30/s  (0.098s, 1310.49/s)  LR: 1.720e-04  Data: 0.000 (0.008)
2024-04-17 15:47:57,317 - train - INFO - Test: [   0/78]  Time: 0.116 (0.116)  Loss:  1.5342 (1.5342)  Acc@1: 67.1875 (67.1875)  Acc@5: 86.7188 (86.7188)
2024-04-17 15:47:58,598 - train - INFO - Test: [  50/78]  Time: 0.025 (0.027)  Loss:  2.4004 (2.2647)  Acc@1: 45.3125 (46.3542)  Acc@5: 68.7500 (74.0809)
2024-04-17 15:47:59,312 - train - INFO - Test: [  78/78]  Time: 0.023 (0.027)  Loss:  2.9746 (2.2615)  Acc@1: 25.0000 (47.0600)  Acc@5: 56.2500 (74.3600)
2024-04-17 15:47:59,605 - train - INFO - Train: 4 [   0/781 (  0%)]  Loss:  3.493557 (3.4936)  Time: 0.213s,  600.04/s  (0.213s,  600.04/s)  LR: 2.260e-04  Data: 0.119 (0.119)
2024-04-17 15:48:04,411 - train - INFO - Train: 4 [  50/781 (  6%)]  Loss:  4.067260 (3.7953)  Time: 0.091s, 1405.97/s  (0.098s, 1300.66/s)  LR: 2.260e-04  Data: 0.007 (0.010)
2024-04-17 15:48:09,594 - train - INFO - Train: 4 [ 100/781 ( 13%)]  Loss:  4.070974 (3.8263)  Time: 0.100s, 1283.64/s  (0.101s, 1267.39/s)  LR: 2.260e-04  Data: 0.008 (0.009)
2024-04-17 15:48:14,330 - train - INFO - Train: 4 [ 150/781 ( 19%)]  Loss:  4.162789 (3.8320)  Time: 0.102s, 1250.09/s  (0.099s, 1294.17/s)  LR: 2.260e-04  Data: 0.008 (0.008)
2024-04-17 15:48:19,584 - train - INFO - Train: 4 [ 200/781 ( 26%)]  Loss:  3.538467 (3.8441)  Time: 0.104s, 1225.39/s  (0.100s, 1274.41/s)  LR: 2.260e-04  Data: 0.008 (0.008)
2024-04-17 15:48:24,593 - train - INFO - Train: 4 [ 250/781 ( 32%)]  Loss:  3.952832 (3.8324)  Time: 0.105s, 1218.08/s  (0.100s, 1275.18/s)  LR: 2.260e-04  Data: 0.008 (0.008)
2024-04-17 15:48:29,739 - train - INFO - Train: 4 [ 300/781 ( 38%)]  Loss:  4.161781 (3.8164)  Time: 0.106s, 1209.77/s  (0.101s, 1269.89/s)  LR: 2.260e-04  Data: 0.009 (0.008)
2024-04-17 15:48:34,529 - train - INFO - Train: 4 [ 350/781 ( 45%)]  Loss:  3.862171 (3.8228)  Time: 0.084s, 1529.84/s  (0.100s, 1278.98/s)  LR: 2.260e-04  Data: 0.006 (0.008)
2024-04-17 15:48:39,183 - train - INFO - Train: 4 [ 400/781 ( 51%)]  Loss:  3.389247 (3.8229)  Time: 0.091s, 1408.62/s  (0.099s, 1290.27/s)  LR: 2.260e-04  Data: 0.008 (0.008)
2024-04-17 15:48:44,209 - train - INFO - Train: 4 [ 450/781 ( 58%)]  Loss:  3.381062 (3.8194)  Time: 0.109s, 1177.07/s  (0.099s, 1288.41/s)  LR: 2.260e-04  Data: 0.008 (0.008)
2024-04-17 15:48:49,139 - train - INFO - Train: 4 [ 500/781 ( 64%)]  Loss:  4.277026 (3.8242)  Time: 0.090s, 1420.76/s  (0.099s, 1289.44/s)  LR: 2.260e-04  Data: 0.007 (0.008)
2024-04-17 15:48:53,889 - train - INFO - Train: 4 [ 550/781 ( 71%)]  Loss:  3.812444 (3.8320)  Time: 0.091s, 1403.63/s  (0.099s, 1294.51/s)  LR: 2.260e-04  Data: 0.006 (0.008)
2024-04-17 15:48:58,715 - train - INFO - Train: 4 [ 600/781 ( 77%)]  Loss:  4.227179 (3.8244)  Time: 0.094s, 1356.83/s  (0.099s, 1297.13/s)  LR: 2.260e-04  Data: 0.008 (0.008)
2024-04-17 15:49:03,855 - train - INFO - Train: 4 [ 650/781 ( 83%)]  Loss:  3.565102 (3.8147)  Time: 0.096s, 1333.77/s  (0.099s, 1293.01/s)  LR: 2.260e-04  Data: 0.007 (0.008)
2024-04-17 15:49:08,756 - train - INFO - Train: 4 [ 700/781 ( 90%)]  Loss:  4.127113 (3.8133)  Time: 0.108s, 1188.92/s  (0.099s, 1293.95/s)  LR: 2.260e-04  Data: 0.008 (0.008)
2024-04-17 15:49:13,980 - train - INFO - Train: 4 [ 750/781 ( 96%)]  Loss:  3.631082 (3.8082)  Time: 0.092s, 1397.24/s  (0.099s, 1289.16/s)  LR: 2.260e-04  Data: 0.008 (0.008)
2024-04-17 15:49:16,985 - train - INFO - Train: 4 [ 780/781 (100%)]  Loss:  3.507573 (3.8069)  Time: 0.078s, 1651.30/s  (0.099s, 1288.73/s)  LR: 2.260e-04  Data: 0.000 (0.008)
2024-04-17 15:49:17,089 - train - INFO - Test: [   0/78]  Time: 0.102 (0.102)  Loss:  1.0967 (1.0967)  Acc@1: 77.3438 (77.3438)  Acc@5: 92.1875 (92.1875)
2024-04-17 15:49:18,415 - train - INFO - Test: [  50/78]  Time: 0.025 (0.028)  Loss:  2.1348 (2.1731)  Acc@1: 51.5625 (49.2494)  Acc@5: 78.1250 (76.0876)
2024-04-17 15:49:19,121 - train - INFO - Test: [  78/78]  Time: 0.023 (0.027)  Loss:  2.0469 (2.1786)  Acc@1: 50.0000 (49.3600)  Acc@5: 87.5000 (75.9200)
2024-04-17 15:49:19,415 - train - INFO - Train: 5 [   0/781 (  0%)]  Loss:  3.372308 (3.3723)  Time: 0.213s,  602.03/s  (0.213s,  602.03/s)  LR: 2.800e-04  Data: 0.124 (0.124)
2024-04-17 15:49:24,266 - train - INFO - Train: 5 [  50/781 (  6%)]  Loss:  4.017391 (3.7044)  Time: 0.087s, 1478.62/s  (0.099s, 1289.58/s)  LR: 2.800e-04  Data: 0.004 (0.010)
2024-04-17 15:49:29,146 - train - INFO - Train: 5 [ 100/781 ( 13%)]  Loss:  3.199205 (3.7104)  Time: 0.107s, 1190.95/s  (0.098s, 1300.53/s)  LR: 2.800e-04  Data: 0.009 (0.009)
2024-04-17 15:49:33,957 - train - INFO - Train: 5 [ 150/781 ( 19%)]  Loss:  4.263769 (3.7150)  Time: 0.095s, 1350.69/s  (0.098s, 1310.34/s)  LR: 2.800e-04  Data: 0.007 (0.008)
2024-04-17 15:49:38,870 - train - INFO - Train: 5 [ 200/781 ( 26%)]  Loss:  3.155620 (3.6926)  Time: 0.099s, 1290.26/s  (0.098s, 1308.50/s)  LR: 2.800e-04  Data: 0.008 (0.008)
2024-04-17 15:49:43,827 - train - INFO - Train: 5 [ 250/781 ( 32%)]  Loss:  3.711884 (3.7041)  Time: 0.099s, 1298.37/s  (0.098s, 1305.10/s)  LR: 2.800e-04  Data: 0.005 (0.008)
2024-04-17 15:49:48,706 - train - INFO - Train: 5 [ 300/781 ( 38%)]  Loss:  3.043136 (3.7064)  Time: 0.089s, 1440.66/s  (0.098s, 1306.25/s)  LR: 2.800e-04  Data: 0.006 (0.008)
2024-04-17 15:49:53,508 - train - INFO - Train: 5 [ 350/781 ( 45%)]  Loss:  4.038585 (3.7208)  Time: 0.094s, 1361.13/s  (0.098s, 1310.02/s)  LR: 2.800e-04  Data: 0.009 (0.008)
2024-04-17 15:49:58,326 - train - INFO - Train: 5 [ 400/781 ( 51%)]  Loss:  3.985963 (3.7243)  Time: 0.090s, 1422.47/s  (0.098s, 1312.33/s)  LR: 2.800e-04  Data: 0.006 (0.008)
2024-04-17 15:50:03,343 - train - INFO - Train: 5 [ 450/781 ( 58%)]  Loss:  3.088160 (3.7240)  Time: 0.106s, 1204.48/s  (0.098s, 1308.20/s)  LR: 2.800e-04  Data: 0.009 (0.008)
2024-04-17 15:50:08,234 - train - INFO - Train: 5 [ 500/781 ( 64%)]  Loss:  3.481953 (3.7247)  Time: 0.094s, 1355.45/s  (0.098s, 1308.25/s)  LR: 2.800e-04  Data: 0.006 (0.008)
2024-04-17 15:50:13,232 - train - INFO - Train: 5 [ 550/781 ( 71%)]  Loss:  3.070349 (3.7168)  Time: 0.084s, 1523.12/s  (0.098s, 1305.73/s)  LR: 2.800e-04  Data: 0.005 (0.008)
2024-04-17 15:50:18,323 - train - INFO - Train: 5 [ 600/781 ( 77%)]  Loss:  4.002616 (3.7152)  Time: 0.126s, 1015.70/s  (0.098s, 1301.57/s)  LR: 2.800e-04  Data: 0.008 (0.008)
2024-04-17 15:50:23,135 - train - INFO - Train: 5 [ 650/781 ( 83%)]  Loss:  3.115717 (3.7131)  Time: 0.101s, 1273.11/s  (0.098s, 1303.75/s)  LR: 2.800e-04  Data: 0.005 (0.008)
2024-04-17 15:50:28,174 - train - INFO - Train: 5 [ 700/781 ( 90%)]  Loss:  3.422713 (3.7149)  Time: 0.109s, 1175.19/s  (0.098s, 1301.33/s)  LR: 2.800e-04  Data: 0.006 (0.008)
2024-04-17 15:50:32,952 - train - INFO - Train: 5 [ 750/781 ( 96%)]  Loss:  4.177791 (3.7164)  Time: 0.096s, 1333.45/s  (0.098s, 1303.82/s)  LR: 2.800e-04  Data: 0.007 (0.008)
2024-04-17 15:50:35,907 - train - INFO - Train: 5 [ 780/781 (100%)]  Loss:  4.163914 (3.7185)  Time: 0.081s, 1581.63/s  (0.098s, 1303.67/s)  LR: 2.800e-04  Data: 0.000 (0.008)
2024-04-17 15:50:36,023 - train - INFO - Test: [   0/78]  Time: 0.115 (0.115)  Loss:  0.9971 (0.9971)  Acc@1: 80.4688 (80.4688)  Acc@5: 92.1875 (92.1875)
2024-04-17 15:50:37,371 - train - INFO - Test: [  50/78]  Time: 0.051 (0.029)  Loss:  1.8008 (2.1621)  Acc@1: 60.1562 (49.5404)  Acc@5: 82.0312 (75.9804)
2024-04-17 15:50:38,233 - train - INFO - Test: [  78/78]  Time: 0.023 (0.029)  Loss:  2.1621 (2.1531)  Acc@1: 43.7500 (50.1200)  Acc@5: 81.2500 (76.5700)
2024-04-17 15:50:38,539 - train - INFO - Train: 6 [   0/781 (  0%)]  Loss:  3.557952 (3.5580)  Time: 0.227s,  564.68/s  (0.227s,  564.68/s)  LR: 3.340e-04  Data: 0.121 (0.121)
2024-04-17 15:50:43,412 - train - INFO - Train: 6 [  50/781 (  6%)]  Loss:  3.559066 (3.6971)  Time: 0.081s, 1577.68/s  (0.100s, 1280.43/s)  LR: 3.340e-04  Data: 0.006 (0.010)
2024-04-17 15:50:48,046 - train - INFO - Train: 6 [ 100/781 ( 13%)]  Loss:  3.497870 (3.7323)  Time: 0.093s, 1381.37/s  (0.096s, 1328.49/s)  LR: 3.340e-04  Data: 0.008 (0.008)
2024-04-17 15:50:53,147 - train - INFO - Train: 6 [ 150/781 ( 19%)]  Loss:  4.296302 (3.7450)  Time: 0.110s, 1164.38/s  (0.098s, 1303.22/s)  LR: 3.340e-04  Data: 0.008 (0.008)
2024-04-17 15:50:57,935 - train - INFO - Train: 6 [ 200/781 ( 26%)]  Loss:  4.132192 (3.7284)  Time: 0.091s, 1411.33/s  (0.098s, 1311.52/s)  LR: 3.340e-04  Data: 0.008 (0.008)
2024-04-17 15:51:02,692 - train - INFO - Train: 6 [ 250/781 ( 32%)]  Loss:  3.950477 (3.7365)  Time: 0.089s, 1439.02/s  (0.097s, 1318.22/s)  LR: 3.340e-04  Data: 0.007 (0.008)
2024-04-17 15:51:07,622 - train - INFO - Train: 6 [ 300/781 ( 38%)]  Loss:  3.490677 (3.7341)  Time: 0.108s, 1182.77/s  (0.097s, 1314.92/s)  LR: 3.340e-04  Data: 0.009 (0.008)
2024-04-17 15:51:12,640 - train - INFO - Train: 6 [ 350/781 ( 45%)]  Loss:  3.077759 (3.7317)  Time: 0.111s, 1153.82/s  (0.098s, 1309.21/s)  LR: 3.340e-04  Data: 0.009 (0.008)
2024-04-17 15:51:17,491 - train - INFO - Train: 6 [ 400/781 ( 51%)]  Loss:  4.227754 (3.7276)  Time: 0.109s, 1171.52/s  (0.098s, 1310.52/s)  LR: 3.340e-04  Data: 0.008 (0.008)
2024-04-17 15:51:22,485 - train - INFO - Train: 6 [ 450/781 ( 58%)]  Loss:  3.365621 (3.7205)  Time: 0.096s, 1332.29/s  (0.098s, 1307.27/s)  LR: 3.340e-04  Data: 0.006 (0.008)
2024-04-17 15:51:27,409 - train - INFO - Train: 6 [ 500/781 ( 64%)]  Loss:  3.337356 (3.7148)  Time: 0.094s, 1367.53/s  (0.098s, 1306.54/s)  LR: 3.340e-04  Data: 0.007 (0.008)
2024-04-17 15:51:32,302 - train - INFO - Train: 6 [ 550/781 ( 71%)]  Loss:  3.151644 (3.7067)  Time: 0.090s, 1429.47/s  (0.098s, 1306.71/s)  LR: 3.340e-04  Data: 0.009 (0.008)
2024-04-17 15:51:37,200 - train - INFO - Train: 6 [ 600/781 ( 77%)]  Loss:  3.531981 (3.7084)  Time: 0.108s, 1184.17/s  (0.098s, 1306.74/s)  LR: 3.340e-04  Data: 0.008 (0.008)
2024-04-17 15:51:42,024 - train - INFO - Train: 6 [ 650/781 ( 83%)]  Loss:  4.146957 (3.7149)  Time: 0.095s, 1342.55/s  (0.098s, 1308.29/s)  LR: 3.340e-04  Data: 0.007 (0.008)
2024-04-17 15:51:46,867 - train - INFO - Train: 6 [ 700/781 ( 90%)]  Loss:  3.089192 (3.7148)  Time: 0.103s, 1241.22/s  (0.098s, 1309.25/s)  LR: 3.340e-04  Data: 0.009 (0.008)
2024-04-17 15:51:51,859 - train - INFO - Train: 6 [ 750/781 ( 96%)]  Loss:  3.158564 (3.7108)  Time: 0.099s, 1288.97/s  (0.098s, 1307.42/s)  LR: 3.340e-04  Data: 0.009 (0.008)
2024-04-17 15:51:54,800 - train - INFO - Train: 6 [ 780/781 (100%)]  Loss:  3.724438 (3.7069)  Time: 0.081s, 1582.11/s  (0.098s, 1307.37/s)  LR: 3.340e-04  Data: 0.000 (0.008)
2024-04-17 15:51:54,917 - train - INFO - Test: [   0/78]  Time: 0.115 (0.115)  Loss:  1.2744 (1.2744)  Acc@1: 72.6562 (72.6562)  Acc@5: 90.6250 (90.6250)
2024-04-17 15:51:56,332 - train - INFO - Test: [  50/78]  Time: 0.025 (0.030)  Loss:  2.2012 (2.1256)  Acc@1: 48.4375 (50.5515)  Acc@5: 70.3125 (76.9761)
2024-04-17 15:51:57,036 - train - INFO - Test: [  78/78]  Time: 0.023 (0.028)  Loss:  2.1523 (2.1132)  Acc@1: 37.5000 (50.9800)  Acc@5: 75.0000 (77.0600)
2024-04-17 15:51:57,335 - train - INFO - Train: 7 [   0/781 (  0%)]  Loss:  3.321385 (3.3214)  Time: 0.219s,  584.58/s  (0.219s,  584.58/s)  LR: 3.880e-04  Data: 0.122 (0.122)
2024-04-17 15:52:02,196 - train - INFO - Train: 7 [  50/781 (  6%)]  Loss:  4.003660 (3.6422)  Time: 0.099s, 1296.40/s  (0.100s, 1285.35/s)  LR: 3.880e-04  Data: 0.006 (0.010)
2024-04-17 15:52:06,920 - train - INFO - Train: 7 [ 100/781 ( 13%)]  Loss:  4.083556 (3.6620)  Time: 0.087s, 1466.44/s  (0.097s, 1318.95/s)  LR: 3.880e-04  Data: 0.006 (0.008)
2024-04-17 15:52:11,723 - train - INFO - Train: 7 [ 150/781 ( 19%)]  Loss:  4.142695 (3.6572)  Time: 0.110s, 1168.25/s  (0.097s, 1323.50/s)  LR: 3.880e-04  Data: 0.008 (0.008)
2024-04-17 15:52:16,732 - train - INFO - Train: 7 [ 200/781 ( 26%)]  Loss:  4.211442 (3.6793)  Time: 0.102s, 1249.58/s  (0.098s, 1311.90/s)  LR: 3.880e-04  Data: 0.006 (0.008)
2024-04-17 15:52:21,518 - train - INFO - Train: 7 [ 250/781 ( 32%)]  Loss:  4.096380 (3.6732)  Time: 0.097s, 1313.57/s  (0.097s, 1316.93/s)  LR: 3.880e-04  Data: 0.008 (0.008)
2024-04-17 15:52:26,556 - train - INFO - Train: 7 [ 300/781 ( 38%)]  Loss:  3.494737 (3.6757)  Time: 0.093s, 1375.84/s  (0.098s, 1309.03/s)  LR: 3.880e-04  Data: 0.009 (0.008)
2024-04-17 15:52:31,704 - train - INFO - Train: 7 [ 350/781 ( 45%)]  Loss:  3.219874 (3.6769)  Time: 0.090s, 1420.45/s  (0.099s, 1299.28/s)  LR: 3.880e-04  Data: 0.005 (0.008)
2024-04-17 15:52:36,699 - train - INFO - Train: 7 [ 400/781 ( 51%)]  Loss:  3.800349 (3.6797)  Time: 0.104s, 1227.22/s  (0.099s, 1297.05/s)  LR: 3.880e-04  Data: 0.006 (0.008)
2024-04-17 15:52:41,443 - train - INFO - Train: 7 [ 450/781 ( 58%)]  Loss:  3.476765 (3.6855)  Time: 0.098s, 1304.95/s  (0.098s, 1302.67/s)  LR: 3.880e-04  Data: 0.008 (0.008)
2024-04-17 15:52:46,358 - train - INFO - Train: 7 [ 500/781 ( 64%)]  Loss:  3.229382 (3.6808)  Time: 0.107s, 1191.79/s  (0.098s, 1302.66/s)  LR: 3.880e-04  Data: 0.008 (0.008)
2024-04-17 15:52:51,251 - train - INFO - Train: 7 [ 550/781 ( 71%)]  Loss:  3.785182 (3.6926)  Time: 0.094s, 1368.40/s  (0.098s, 1303.17/s)  LR: 3.880e-04  Data: 0.005 (0.008)
2024-04-17 15:52:56,097 - train - INFO - Train: 7 [ 600/781 ( 77%)]  Loss:  3.103286 (3.6945)  Time: 0.097s, 1320.91/s  (0.098s, 1304.63/s)  LR: 3.880e-04  Data: 0.010 (0.008)
2024-04-17 15:53:01,008 - train - INFO - Train: 7 [ 650/781 ( 83%)]  Loss:  3.963420 (3.6925)  Time: 0.088s, 1455.78/s  (0.098s, 1304.55/s)  LR: 3.880e-04  Data: 0.004 (0.008)
2024-04-17 15:53:05,888 - train - INFO - Train: 7 [ 700/781 ( 90%)]  Loss:  3.932507 (3.6940)  Time: 0.100s, 1282.55/s  (0.098s, 1305.08/s)  LR: 3.880e-04  Data: 0.008 (0.008)
2024-04-17 15:53:10,847 - train - INFO - Train: 7 [ 750/781 ( 96%)]  Loss:  3.566743 (3.6909)  Time: 0.091s, 1403.67/s  (0.098s, 1304.12/s)  LR: 3.880e-04  Data: 0.008 (0.008)
2024-04-17 15:53:13,796 - train - INFO - Train: 7 [ 780/781 (100%)]  Loss:  3.418982 (3.6890)  Time: 0.098s, 1307.14/s  (0.098s, 1304.06/s)  LR: 3.880e-04  Data: 0.000 (0.008)
2024-04-17 15:53:13,921 - train - INFO - Test: [   0/78]  Time: 0.123 (0.123)  Loss:  1.3965 (1.3965)  Acc@1: 71.0938 (71.0938)  Acc@5: 89.0625 (89.0625)
2024-04-17 15:53:15,199 - train - INFO - Test: [  50/78]  Time: 0.026 (0.027)  Loss:  2.1348 (2.1342)  Acc@1: 50.7812 (50.6434)  Acc@5: 82.8125 (76.4093)
2024-04-17 15:53:15,905 - train - INFO - Test: [  78/78]  Time: 0.023 (0.027)  Loss:  2.5605 (2.1402)  Acc@1: 31.2500 (51.0400)  Acc@5: 75.0000 (76.5500)
2024-04-17 15:53:16,179 - train - INFO - Train: 8 [   0/781 (  0%)]  Loss:  3.211677 (3.2117)  Time: 0.194s,  660.39/s  (0.194s,  660.39/s)  LR: 4.420e-04  Data: 0.114 (0.114)
2024-04-17 15:53:21,066 - train - INFO - Train: 8 [  50/781 (  6%)]  Loss:  3.963246 (3.7405)  Time: 0.089s, 1431.38/s  (0.100s, 1285.04/s)  LR: 4.420e-04  Data: 0.007 (0.009)
2024-04-17 15:53:25,821 - train - INFO - Train: 8 [ 100/781 ( 13%)]  Loss:  3.357233 (3.7281)  Time: 0.097s, 1313.43/s  (0.097s, 1314.64/s)  LR: 4.420e-04  Data: 0.009 (0.008)
2024-04-17 15:53:30,702 - train - INFO - Train: 8 [ 150/781 ( 19%)]  Loss:  3.125201 (3.7160)  Time: 0.089s, 1438.34/s  (0.097s, 1313.62/s)  LR: 4.420e-04  Data: 0.007 (0.008)
2024-04-17 15:53:35,515 - train - INFO - Train: 8 [ 200/781 ( 26%)]  Loss:  3.759464 (3.7307)  Time: 0.108s, 1180.71/s  (0.097s, 1317.70/s)  LR: 4.420e-04  Data: 0.008 (0.008)
2024-04-17 15:53:40,575 - train - INFO - Train: 8 [ 250/781 ( 32%)]  Loss:  3.715709 (3.7049)  Time: 0.091s, 1407.68/s  (0.098s, 1306.89/s)  LR: 4.420e-04  Data: 0.008 (0.008)
2024-04-17 15:53:45,319 - train - INFO - Train: 8 [ 300/781 ( 38%)]  Loss:  3.148294 (3.6956)  Time: 0.091s, 1408.20/s  (0.097s, 1313.73/s)  LR: 4.420e-04  Data: 0.008 (0.008)
2024-04-17 15:53:50,287 - train - INFO - Train: 8 [ 350/781 ( 45%)]  Loss:  4.277396 (3.6876)  Time: 0.107s, 1195.61/s  (0.098s, 1310.11/s)  LR: 4.420e-04  Data: 0.009 (0.008)
2024-04-17 15:53:55,303 - train - INFO - Train: 8 [ 400/781 ( 51%)]  Loss:  4.247899 (3.6938)  Time: 0.108s, 1186.31/s  (0.098s, 1305.79/s)  LR: 4.420e-04  Data: 0.008 (0.008)
2024-04-17 15:53:59,941 - train - INFO - Train: 8 [ 450/781 ( 58%)]  Loss:  3.304715 (3.6906)  Time: 0.106s, 1207.11/s  (0.097s, 1313.65/s)  LR: 4.420e-04  Data: 0.006 (0.008)
2024-04-17 15:54:04,712 - train - INFO - Train: 8 [ 500/781 ( 64%)]  Loss:  3.797887 (3.6987)  Time: 0.088s, 1452.85/s  (0.097s, 1316.40/s)  LR: 4.420e-04  Data: 0.007 (0.008)
2024-04-17 15:54:09,497 - train - INFO - Train: 8 [ 550/781 ( 71%)]  Loss:  4.223442 (3.7038)  Time: 0.087s, 1470.96/s  (0.097s, 1318.31/s)  LR: 4.420e-04  Data: 0.004 (0.008)
2024-04-17 15:54:14,475 - train - INFO - Train: 8 [ 600/781 ( 77%)]  Loss:  3.193289 (3.6984)  Time: 0.086s, 1480.63/s  (0.097s, 1315.58/s)  LR: 4.420e-04  Data: 0.008 (0.008)
2024-04-17 15:54:19,300 - train - INFO - Train: 8 [ 650/781 ( 83%)]  Loss:  3.232925 (3.7009)  Time: 0.089s, 1439.70/s  (0.097s, 1316.44/s)  LR: 4.420e-04  Data: 0.004 (0.008)
2024-04-17 15:54:24,097 - train - INFO - Train: 8 [ 700/781 ( 90%)]  Loss:  3.862593 (3.7002)  Time: 0.093s, 1375.67/s  (0.097s, 1317.71/s)  LR: 4.420e-04  Data: 0.008 (0.008)
2024-04-17 15:54:29,102 - train - INFO - Train: 8 [ 750/781 ( 96%)]  Loss:  3.321548 (3.6952)  Time: 0.088s, 1461.59/s  (0.097s, 1315.07/s)  LR: 4.420e-04  Data: 0.008 (0.008)
2024-04-17 15:54:32,033 - train - INFO - Train: 8 [ 780/781 (100%)]  Loss:  3.267391 (3.6944)  Time: 0.105s, 1216.22/s  (0.097s, 1314.91/s)  LR: 4.420e-04  Data: 0.000 (0.008)
2024-04-17 15:54:32,146 - train - INFO - Test: [   0/78]  Time: 0.110 (0.110)  Loss:  1.4111 (1.4111)  Acc@1: 67.1875 (67.1875)  Acc@5: 89.8438 (89.8438)
2024-04-17 15:54:33,468 - train - INFO - Test: [  50/78]  Time: 0.025 (0.028)  Loss:  1.9062 (2.0788)  Acc@1: 53.9062 (51.4859)  Acc@5: 80.4688 (77.6195)
2024-04-17 15:54:34,171 - train - INFO - Test: [  78/78]  Time: 0.023 (0.027)  Loss:  2.2402 (2.0897)  Acc@1: 31.2500 (51.2200)  Acc@5: 93.7500 (77.1700)
2024-04-17 15:54:34,478 - train - INFO - Train: 9 [   0/781 (  0%)]  Loss:  4.159290 (4.1593)  Time: 0.228s,  561.18/s  (0.228s,  561.18/s)  LR: 4.960e-04  Data: 0.120 (0.120)
2024-04-17 15:54:39,479 - train - INFO - Train: 9 [  50/781 (  6%)]  Loss:  3.753919 (3.6497)  Time: 0.098s, 1303.16/s  (0.102s, 1248.85/s)  LR: 4.960e-04  Data: 0.008 (0.009)
2024-04-17 15:54:44,420 - train - INFO - Train: 9 [ 100/781 ( 13%)]  Loss:  3.829468 (3.6267)  Time: 0.109s, 1172.25/s  (0.101s, 1271.62/s)  LR: 4.960e-04  Data: 0.008 (0.008)
2024-04-17 15:54:49,287 - train - INFO - Train: 9 [ 150/781 ( 19%)]  Loss:  3.380643 (3.6477)  Time: 0.105s, 1215.11/s  (0.100s, 1285.80/s)  LR: 4.960e-04  Data: 0.008 (0.008)
2024-04-17 15:54:54,103 - train - INFO - Train: 9 [ 200/781 ( 26%)]  Loss:  4.014907 (3.6571)  Time: 0.093s, 1382.99/s  (0.099s, 1296.30/s)  LR: 4.960e-04  Data: 0.007 (0.008)
2024-04-17 15:54:58,916 - train - INFO - Train: 9 [ 250/781 ( 32%)]  Loss:  4.070928 (3.6722)  Time: 0.099s, 1298.56/s  (0.098s, 1302.90/s)  LR: 4.960e-04  Data: 0.007 (0.008)
2024-04-17 15:55:03,900 - train - INFO - Train: 9 [ 300/781 ( 38%)]  Loss:  3.886787 (3.6777)  Time: 0.103s, 1245.24/s  (0.098s, 1299.81/s)  LR: 4.960e-04  Data: 0.007 (0.008)
2024-04-17 15:55:08,823 - train - INFO - Train: 9 [ 350/781 ( 45%)]  Loss:  3.488881 (3.6745)  Time: 0.111s, 1154.87/s  (0.098s, 1299.90/s)  LR: 4.960e-04  Data: 0.007 (0.008)
2024-04-17 15:55:13,629 - train - INFO - Train: 9 [ 400/781 ( 51%)]  Loss:  3.812069 (3.6776)  Time: 0.092s, 1394.14/s  (0.098s, 1303.85/s)  LR: 4.960e-04  Data: 0.007 (0.008)
2024-04-17 15:55:18,265 - train - INFO - Train: 9 [ 450/781 ( 58%)]  Loss:  3.292453 (3.6759)  Time: 0.084s, 1527.84/s  (0.098s, 1311.96/s)  LR: 4.960e-04  Data: 0.006 (0.008)
2024-04-17 15:55:23,244 - train - INFO - Train: 9 [ 500/781 ( 64%)]  Loss:  3.651361 (3.6805)  Time: 0.103s, 1241.53/s  (0.098s, 1309.31/s)  LR: 4.960e-04  Data: 0.007 (0.008)
2024-04-17 15:55:28,139 - train - INFO - Train: 9 [ 550/781 ( 71%)]  Loss:  3.866473 (3.6821)  Time: 0.101s, 1265.49/s  (0.098s, 1309.17/s)  LR: 4.960e-04  Data: 0.007 (0.008)
2024-04-17 15:55:32,880 - train - INFO - Train: 9 [ 600/781 ( 77%)]  Loss:  3.630929 (3.6851)  Time: 0.087s, 1465.10/s  (0.098s, 1312.52/s)  LR: 4.960e-04  Data: 0.010 (0.008)
2024-04-17 15:55:37,666 - train - INFO - Train: 9 [ 650/781 ( 83%)]  Loss:  3.973663 (3.6788)  Time: 0.097s, 1314.74/s  (0.097s, 1314.41/s)  LR: 4.960e-04  Data: 0.008 (0.008)
2024-04-17 15:55:42,692 - train - INFO - Train: 9 [ 700/781 ( 90%)]  Loss:  4.108794 (3.6800)  Time: 0.093s, 1371.50/s  (0.098s, 1311.43/s)  LR: 4.960e-04  Data: 0.008 (0.008)
2024-04-17 15:55:47,494 - train - INFO - Train: 9 [ 750/781 ( 96%)]  Loss:  3.597671 (3.6784)  Time: 0.091s, 1403.44/s  (0.097s, 1312.85/s)  LR: 4.960e-04  Data: 0.007 (0.008)
2024-04-17 15:55:50,357 - train - INFO - Train: 9 [ 780/781 (100%)]  Loss:  3.541158 (3.6756)  Time: 0.082s, 1568.62/s  (0.097s, 1313.92/s)  LR: 4.960e-04  Data: 0.000 (0.008)
2024-04-17 15:55:50,474 - train - INFO - Test: [   0/78]  Time: 0.115 (0.115)  Loss:  1.1670 (1.1670)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
2024-04-17 15:55:51,767 - train - INFO - Test: [  50/78]  Time: 0.026 (0.028)  Loss:  2.1504 (2.0068)  Acc@1: 50.7812 (52.8186)  Acc@5: 74.2188 (78.1097)
2024-04-17 15:55:52,482 - train - INFO - Test: [  78/78]  Time: 0.024 (0.027)  Loss:  2.0918 (2.0476)  Acc@1: 50.0000 (52.0800)  Acc@5: 75.0000 (77.3200)
2024-04-17 15:55:52,796 - train - INFO - Train: 10 [   0/781 (  0%)]  Loss:  3.442175 (3.4422)  Time: 0.234s,  546.57/s  (0.234s,  546.57/s)  LR: 5.485e-04  Data: 0.129 (0.129)
2024-04-17 15:55:57,490 - train - INFO - Train: 10 [  50/781 (  6%)]  Loss:  4.059257 (3.7025)  Time: 0.108s, 1190.48/s  (0.097s, 1324.92/s)  LR: 5.485e-04  Data: 0.008 (0.010)
2024-04-17 15:56:02,444 - train - INFO - Train: 10 [ 100/781 ( 13%)]  Loss:  3.868493 (3.6888)  Time: 0.107s, 1192.13/s  (0.098s, 1308.56/s)  LR: 5.485e-04  Data: 0.008 (0.009)
2024-04-17 15:56:07,256 - train - INFO - Train: 10 [ 150/781 ( 19%)]  Loss:  3.100500 (3.6925)  Time: 0.092s, 1395.21/s  (0.097s, 1315.69/s)  LR: 5.485e-04  Data: 0.007 (0.008)
2024-04-17 15:56:11,968 - train - INFO - Train: 10 [ 200/781 ( 26%)]  Loss:  3.976503 (3.6762)  Time: 0.087s, 1479.70/s  (0.097s, 1326.15/s)  LR: 5.485e-04  Data: 0.005 (0.008)
2024-04-17 15:56:16,842 - train - INFO - Train: 10 [ 250/781 ( 32%)]  Loss:  4.158433 (3.6767)  Time: 0.090s, 1428.77/s  (0.097s, 1323.62/s)  LR: 5.485e-04  Data: 0.007 (0.008)
2024-04-17 15:56:21,514 - train - INFO - Train: 10 [ 300/781 ( 38%)]  Loss:  3.839816 (3.6849)  Time: 0.105s, 1220.37/s  (0.096s, 1331.14/s)  LR: 5.485e-04  Data: 0.007 (0.008)
2024-04-17 15:56:26,306 - train - INFO - Train: 10 [ 350/781 ( 45%)]  Loss:  3.044306 (3.6788)  Time: 0.108s, 1187.70/s  (0.096s, 1331.85/s)  LR: 5.485e-04  Data: 0.008 (0.008)
2024-04-17 15:56:31,195 - train - INFO - Train: 10 [ 400/781 ( 51%)]  Loss:  4.325849 (3.6682)  Time: 0.101s, 1262.44/s  (0.096s, 1329.00/s)  LR: 5.485e-04  Data: 0.008 (0.008)
2024-04-17 15:56:36,430 - train - INFO - Train: 10 [ 450/781 ( 58%)]  Loss:  3.392660 (3.6791)  Time: 0.091s, 1402.21/s  (0.097s, 1316.34/s)  LR: 5.485e-04  Data: 0.008 (0.008)
2024-04-17 15:56:41,204 - train - INFO - Train: 10 [ 500/781 ( 64%)]  Loss:  3.842807 (3.6756)  Time: 0.113s, 1132.87/s  (0.097s, 1318.76/s)  LR: 5.485e-04  Data: 0.009 (0.008)
2024-04-17 15:56:46,094 - train - INFO - Train: 10 [ 550/781 ( 71%)]  Loss:  3.017973 (3.6768)  Time: 0.092s, 1388.52/s  (0.097s, 1317.91/s)  LR: 5.485e-04  Data: 0.006 (0.008)
2024-04-17 15:56:51,053 - train - INFO - Train: 10 [ 600/781 ( 77%)]  Loss:  3.394349 (3.6709)  Time: 0.095s, 1352.16/s  (0.097s, 1315.61/s)  LR: 5.485e-04  Data: 0.009 (0.008)
2024-04-17 15:56:55,745 - train - INFO - Train: 10 [ 650/781 ( 83%)]  Loss:  3.156336 (3.6771)  Time: 0.093s, 1382.54/s  (0.097s, 1319.23/s)  LR: 5.485e-04  Data: 0.009 (0.008)
2024-04-17 15:57:00,558 - train - INFO - Train: 10 [ 700/781 ( 90%)]  Loss:  4.052416 (3.6763)  Time: 0.106s, 1204.85/s  (0.097s, 1320.01/s)  LR: 5.485e-04  Data: 0.006 (0.008)
2024-04-17 15:57:05,372 - train - INFO - Train: 10 [ 750/781 ( 96%)]  Loss:  3.534398 (3.6744)  Time: 0.096s, 1329.85/s  (0.097s, 1320.66/s)  LR: 5.485e-04  Data: 0.007 (0.008)
2024-04-17 15:57:08,093 - train - INFO - Train: 10 [ 780/781 (100%)]  Loss:  4.154616 (3.6752)  Time: 0.079s, 1613.12/s  (0.097s, 1323.95/s)  LR: 5.485e-04  Data: 0.000 (0.008)
2024-04-17 15:57:08,202 - train - INFO - Test: [   0/78]  Time: 0.107 (0.107)  Loss:  1.1104 (1.1104)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.1875 (92.1875)
2024-04-17 15:57:09,471 - train - INFO - Test: [  50/78]  Time: 0.026 (0.027)  Loss:  2.2949 (2.1061)  Acc@1: 45.3125 (51.3327)  Acc@5: 74.2188 (77.6042)
2024-04-17 15:57:10,174 - train - INFO - Test: [  78/78]  Time: 0.023 (0.026)  Loss:  2.3379 (2.1268)  Acc@1: 37.5000 (51.2500)  Acc@5: 81.2500 (77.0000)
2024-04-17 15:57:10,481 - train - INFO - Train: 11 [   0/781 (  0%)]  Loss:  4.050591 (4.0506)  Time: 0.227s,  564.79/s  (0.227s,  564.79/s)  LR: 5.482e-04  Data: 0.122 (0.122)
2024-04-17 15:57:15,520 - train - INFO - Train: 11 [  50/781 (  6%)]  Loss:  4.012895 (3.6850)  Time: 0.112s, 1145.07/s  (0.103s, 1240.17/s)  LR: 5.482e-04  Data: 0.009 (0.010)
2024-04-17 15:57:20,331 - train - INFO - Train: 11 [ 100/781 ( 13%)]  Loss:  3.578569 (3.6456)  Time: 0.088s, 1462.14/s  (0.100s, 1283.30/s)  LR: 5.482e-04  Data: 0.008 (0.009)
2024-04-17 15:57:25,119 - train - INFO - Train: 11 [ 150/781 ( 19%)]  Loss:  4.214579 (3.6229)  Time: 0.092s, 1395.27/s  (0.098s, 1300.65/s)  LR: 5.482e-04  Data: 0.008 (0.008)
2024-04-17 15:57:30,014 - train - INFO - Train: 11 [ 200/781 ( 26%)]  Loss:  3.640267 (3.6327)  Time: 0.103s, 1237.95/s  (0.098s, 1302.46/s)  LR: 5.482e-04  Data: 0.009 (0.008)
2024-04-17 15:57:34,978 - train - INFO - Train: 11 [ 250/781 ( 32%)]  Loss:  3.716495 (3.6351)  Time: 0.090s, 1424.61/s  (0.098s, 1299.91/s)  LR: 5.482e-04  Data: 0.006 (0.008)
2024-04-17 15:57:39,645 - train - INFO - Train: 11 [ 300/781 ( 38%)]  Loss:  4.056101 (3.6543)  Time: 0.107s, 1199.28/s  (0.098s, 1311.32/s)  LR: 5.482e-04  Data: 0.009 (0.008)
2024-04-17 15:57:44,904 - train - INFO - Train: 11 [ 350/781 ( 45%)]  Loss:  2.953707 (3.6625)  Time: 0.102s, 1257.83/s  (0.099s, 1297.03/s)  LR: 5.482e-04  Data: 0.007 (0.008)
2024-04-17 15:57:49,871 - train - INFO - Train: 11 [ 400/781 ( 51%)]  Loss:  3.512398 (3.6789)  Time: 0.090s, 1427.77/s  (0.099s, 1296.01/s)  LR: 5.482e-04  Data: 0.007 (0.008)
2024-04-17 15:57:54,558 - train - INFO - Train: 11 [ 450/781 ( 58%)]  Loss:  3.476214 (3.6757)  Time: 0.090s, 1426.70/s  (0.098s, 1303.42/s)  LR: 5.482e-04  Data: 0.005 (0.008)
2024-04-17 15:57:59,685 - train - INFO - Train: 11 [ 500/781 ( 64%)]  Loss:  4.020118 (3.6757)  Time: 0.104s, 1231.09/s  (0.099s, 1297.73/s)  LR: 5.482e-04  Data: 0.008 (0.008)
2024-04-17 15:58:04,538 - train - INFO - Train: 11 [ 550/781 ( 71%)]  Loss:  3.412866 (3.6682)  Time: 0.098s, 1307.62/s  (0.098s, 1299.65/s)  LR: 5.482e-04  Data: 0.008 (0.008)
2024-04-17 15:58:09,211 - train - INFO - Train: 11 [ 600/781 ( 77%)]  Loss:  3.606129 (3.6718)  Time: 0.088s, 1449.38/s  (0.098s, 1305.23/s)  LR: 5.482e-04  Data: 0.006 (0.008)
2024-04-17 15:58:13,770 - train - INFO - Train: 11 [ 650/781 ( 83%)]  Loss:  4.093081 (3.6744)  Time: 0.092s, 1386.42/s  (0.098s, 1312.33/s)  LR: 5.482e-04  Data: 0.009 (0.008)
2024-04-17 15:58:18,580 - train - INFO - Train: 11 [ 700/781 ( 90%)]  Loss:  3.818172 (3.6696)  Time: 0.101s, 1268.29/s  (0.097s, 1313.64/s)  LR: 5.482e-04  Data: 0.009 (0.008)
2024-04-17 15:58:23,642 - train - INFO - Train: 11 [ 750/781 ( 96%)]  Loss:  4.139824 (3.6658)  Time: 0.095s, 1353.16/s  (0.098s, 1310.27/s)  LR: 5.482e-04  Data: 0.008 (0.008)
2024-04-17 15:58:26,653 - train - INFO - Train: 11 [ 780/781 (100%)]  Loss:  4.017489 (3.6658)  Time: 0.103s, 1248.62/s  (0.098s, 1308.90/s)  LR: 5.482e-04  Data: 0.000 (0.008)
2024-04-17 15:58:26,769 - train - INFO - Test: [   0/78]  Time: 0.112 (0.112)  Loss:  1.2637 (1.2637)  Acc@1: 69.5312 (69.5312)  Acc@5: 89.8438 (89.8438)
2024-04-17 15:58:28,030 - train - INFO - Test: [  50/78]  Time: 0.025 (0.027)  Loss:  2.3535 (2.1000)  Acc@1: 45.3125 (51.1795)  Acc@5: 75.7812 (77.1752)
2024-04-17 15:58:28,734 - train - INFO - Test: [  78/78]  Time: 0.023 (0.026)  Loss:  2.7461 (2.1156)  Acc@1: 43.7500 (51.4300)  Acc@5: 68.7500 (76.9000)
2024-04-17 15:58:29,050 - train - INFO - Train: 12 [   0/781 (  0%)]  Loss:  3.544106 (3.5441)  Time: 0.232s,  552.44/s  (0.232s,  552.44/s)  LR: 5.479e-04  Data: 0.128 (0.128)
2024-04-17 15:58:34,102 - train - INFO - Train: 12 [  50/781 (  6%)]  Loss:  4.020163 (3.5951)  Time: 0.109s, 1171.69/s  (0.104s, 1235.67/s)  LR: 5.479e-04  Data: 0.008 (0.010)
2024-04-17 15:58:38,874 - train - INFO - Train: 12 [ 100/781 ( 13%)]  Loss:  4.098234 (3.6565)  Time: 0.083s, 1541.32/s  (0.100s, 1285.88/s)  LR: 5.479e-04  Data: 0.006 (0.009)
2024-04-17 15:58:43,797 - train - INFO - Train: 12 [ 150/781 ( 19%)]  Loss:  3.609568 (3.6488)  Time: 0.103s, 1245.79/s  (0.099s, 1290.67/s)  LR: 5.479e-04  Data: 0.007 (0.008)
2024-04-17 15:58:48,782 - train - INFO - Train: 12 [ 200/781 ( 26%)]  Loss:  3.930505 (3.6614)  Time: 0.096s, 1326.71/s  (0.099s, 1289.09/s)  LR: 5.479e-04  Data: 0.008 (0.008)
2024-04-17 15:58:53,449 - train - INFO - Train: 12 [ 250/781 ( 32%)]  Loss:  4.071971 (3.6443)  Time: 0.111s, 1151.03/s  (0.098s, 1304.75/s)  LR: 5.479e-04  Data: 0.008 (0.008)
2024-04-17 15:58:58,283 - train - INFO - Train: 12 [ 300/781 ( 38%)]  Loss:  3.182639 (3.6423)  Time: 0.097s, 1324.18/s  (0.098s, 1307.97/s)  LR: 5.479e-04  Data: 0.006 (0.008)
2024-04-17 15:59:03,259 - train - INFO - Train: 12 [ 350/781 ( 45%)]  Loss:  3.972110 (3.6407)  Time: 0.095s, 1349.37/s  (0.098s, 1304.92/s)  LR: 5.479e-04  Data: 0.007 (0.008)
2024-04-17 15:59:07,953 - train - INFO - Train: 12 [ 400/781 ( 51%)]  Loss:  3.261594 (3.6425)  Time: 0.104s, 1235.06/s  (0.098s, 1311.96/s)  LR: 5.479e-04  Data: 0.008 (0.008)
2024-04-17 15:59:12,778 - train - INFO - Train: 12 [ 450/781 ( 58%)]  Loss:  3.886970 (3.6407)  Time: 0.104s, 1231.17/s  (0.097s, 1313.62/s)  LR: 5.479e-04  Data: 0.006 (0.008)
2024-04-17 15:59:17,648 - train - INFO - Train: 12 [ 500/781 ( 64%)]  Loss:  3.708710 (3.6346)  Time: 0.087s, 1472.55/s  (0.097s, 1313.70/s)  LR: 5.479e-04  Data: 0.008 (0.008)
2024-04-17 15:59:22,364 - train - INFO - Train: 12 [ 550/781 ( 71%)]  Loss:  3.867604 (3.6313)  Time: 0.090s, 1425.90/s  (0.097s, 1317.55/s)  LR: 5.479e-04  Data: 0.008 (0.008)
2024-04-17 15:59:27,120 - train - INFO - Train: 12 [ 600/781 ( 77%)]  Loss:  3.017972 (3.6364)  Time: 0.089s, 1440.47/s  (0.097s, 1319.87/s)  LR: 5.479e-04  Data: 0.008 (0.008)
2024-04-17 15:59:31,939 - train - INFO - Train: 12 [ 650/781 ( 83%)]  Loss:  3.484093 (3.6326)  Time: 0.095s, 1344.79/s  (0.097s, 1320.53/s)  LR: 5.479e-04  Data: 0.007 (0.008)
2024-04-17 15:59:36,659 - train - INFO - Train: 12 [ 700/781 ( 90%)]  Loss:  3.857048 (3.6326)  Time: 0.107s, 1194.42/s  (0.097s, 1323.03/s)  LR: 5.479e-04  Data: 0.008 (0.008)
2024-04-17 15:59:41,312 - train - INFO - Train: 12 [ 750/781 ( 96%)]  Loss:  3.557370 (3.6358)  Time: 0.100s, 1284.93/s  (0.096s, 1326.43/s)  LR: 5.479e-04  Data: 0.008 (0.008)
2024-04-17 15:59:44,183 - train - INFO - Train: 12 [ 780/781 (100%)]  Loss:  3.456010 (3.6398)  Time: 0.113s, 1134.40/s  (0.096s, 1326.86/s)  LR: 5.479e-04  Data: 0.000 (0.008)
2024-04-17 15:59:44,310 - train - INFO - Test: [   0/78]  Time: 0.124 (0.124)  Loss:  1.4258 (1.4258)  Acc@1: 70.3125 (70.3125)  Acc@5: 85.1562 (85.1562)
2024-04-17 15:59:45,586 - train - INFO - Test: [  50/78]  Time: 0.027 (0.027)  Loss:  2.0859 (2.0526)  Acc@1: 53.1250 (52.7267)  Acc@5: 75.7812 (78.3548)
2024-04-17 15:59:46,302 - train - INFO - Test: [  78/78]  Time: 0.023 (0.027)  Loss:  2.4590 (2.0688)  Acc@1: 37.5000 (52.7400)  Acc@5: 81.2500 (77.8300)
2024-04-17 15:59:46,608 - train - INFO - Train: 13 [   0/781 (  0%)]  Loss:  3.761812 (3.7618)  Time: 0.226s,  567.34/s  (0.226s,  567.34/s)  LR: 5.475e-04  Data: 0.128 (0.128)
2024-04-17 15:59:51,285 - train - INFO - Train: 13 [  50/781 (  6%)]  Loss:  3.280992 (3.5686)  Time: 0.089s, 1434.70/s  (0.096s, 1331.71/s)  LR: 5.475e-04  Data: 0.007 (0.009)
2024-04-17 15:59:56,078 - train - INFO - Train: 13 [ 100/781 ( 13%)]  Loss:  3.591735 (3.5957)  Time: 0.094s, 1364.45/s  (0.096s, 1333.73/s)  LR: 5.475e-04  Data: 0.008 (0.008)
2024-04-17 16:00:00,992 - train - INFO - Train: 13 [ 150/781 ( 19%)]  Loss:  2.910903 (3.5825)  Time: 0.104s, 1225.96/s  (0.097s, 1323.31/s)  LR: 5.475e-04  Data: 0.008 (0.008)
2024-04-17 16:00:05,529 - train - INFO - Train: 13 [ 200/781 ( 26%)]  Loss:  3.283929 (3.5708)  Time: 0.084s, 1522.59/s  (0.095s, 1344.05/s)  LR: 5.475e-04  Data: 0.006 (0.008)
2024-04-17 16:00:10,231 - train - INFO - Train: 13 [ 250/781 ( 32%)]  Loss:  3.704237 (3.5767)  Time: 0.097s, 1319.99/s  (0.095s, 1347.48/s)  LR: 5.475e-04  Data: 0.008 (0.008)
2024-04-17 16:00:14,959 - train - INFO - Train: 13 [ 300/781 ( 38%)]  Loss:  4.001536 (3.6003)  Time: 0.092s, 1390.44/s  (0.095s, 1348.59/s)  LR: 5.475e-04  Data: 0.007 (0.008)
2024-04-17 16:00:19,596 - train - INFO - Train: 13 [ 350/781 ( 45%)]  Loss:  2.959667 (3.5944)  Time: 0.084s, 1532.88/s  (0.095s, 1353.08/s)  LR: 5.475e-04  Data: 0.006 (0.008)
2024-04-17 16:00:24,354 - train - INFO - Train: 13 [ 400/781 ( 51%)]  Loss:  3.121501 (3.5890)  Time: 0.111s, 1154.96/s  (0.095s, 1352.13/s)  LR: 5.475e-04  Data: 0.009 (0.007)
2024-04-17 16:00:29,085 - train - INFO - Train: 13 [ 450/781 ( 58%)]  Loss:  3.652329 (3.5918)  Time: 0.090s, 1415.97/s  (0.095s, 1352.26/s)  LR: 5.475e-04  Data: 0.007 (0.007)
2024-04-17 16:00:34,083 - train - INFO - Train: 13 [ 500/781 ( 64%)]  Loss:  3.989004 (3.6000)  Time: 0.095s, 1352.68/s  (0.095s, 1344.78/s)  LR: 5.475e-04  Data: 0.004 (0.007)
2024-04-17 16:00:39,115 - train - INFO - Train: 13 [ 550/781 ( 71%)]  Loss:  4.018091 (3.6082)  Time: 0.094s, 1357.60/s  (0.096s, 1337.88/s)  LR: 5.475e-04  Data: 0.009 (0.007)
2024-04-17 16:00:44,082 - train - INFO - Train: 13 [ 600/781 ( 77%)]  Loss:  3.312838 (3.6077)  Time: 0.085s, 1500.21/s  (0.096s, 1333.66/s)  LR: 5.475e-04  Data: 0.006 (0.007)
2024-04-17 16:00:48,726 - train - INFO - Train: 13 [ 650/781 ( 83%)]  Loss:  3.583697 (3.6077)  Time: 0.090s, 1419.47/s  (0.096s, 1337.01/s)  LR: 5.475e-04  Data: 0.007 (0.007)
2024-04-17 16:00:53,647 - train - INFO - Train: 13 [ 700/781 ( 90%)]  Loss:  3.799390 (3.6091)  Time: 0.105s, 1213.31/s  (0.096s, 1334.36/s)  LR: 5.475e-04  Data: 0.007 (0.007)
2024-04-17 16:00:58,334 - train - INFO - Train: 13 [ 750/781 ( 96%)]  Loss:  3.314480 (3.6063)  Time: 0.102s, 1250.16/s  (0.096s, 1336.43/s)  LR: 5.475e-04  Data: 0.008 (0.007)
2024-04-17 16:01:01,146 - train - INFO - Train: 13 [ 780/781 (100%)]  Loss:  3.662723 (3.6084)  Time: 0.079s, 1622.69/s  (0.096s, 1337.54/s)  LR: 5.475e-04  Data: 0.000 (0.007)
2024-04-17 16:01:01,272 - train - INFO - Test: [   0/78]  Time: 0.123 (0.123)  Loss:  1.1484 (1.1484)  Acc@1: 76.5625 (76.5625)  Acc@5: 90.6250 (90.6250)
2024-04-17 16:01:02,564 - train - INFO - Test: [  50/78]  Time: 0.025 (0.028)  Loss:  1.8916 (2.0377)  Acc@1: 57.8125 (52.6348)  Acc@5: 78.9062 (77.9871)
2024-04-17 16:01:03,280 - train - INFO - Test: [  78/78]  Time: 0.023 (0.027)  Loss:  2.3457 (2.0271)  Acc@1: 37.5000 (52.8000)  Acc@5: 87.5000 (78.3100)
2024-04-17 16:01:03,590 - train - INFO - Train: 14 [   0/781 (  0%)]  Loss:  3.648029 (3.6480)  Time: 0.228s,  561.26/s  (0.228s,  561.26/s)  LR: 5.471e-04  Data: 0.129 (0.129)
2024-04-17 16:01:08,244 - train - INFO - Train: 14 [  50/781 (  6%)]  Loss:  3.751658 (3.6114)  Time: 0.108s, 1185.53/s  (0.096s, 1337.57/s)  LR: 5.471e-04  Data: 0.009 (0.009)
2024-04-17 16:01:13,184 - train - INFO - Train: 14 [ 100/781 ( 13%)]  Loss:  4.072857 (3.6508)  Time: 0.084s, 1523.60/s  (0.097s, 1316.68/s)  LR: 5.471e-04  Data: 0.006 (0.008)
2024-04-17 16:01:17,905 - train - INFO - Train: 14 [ 150/781 ( 19%)]  Loss:  3.135267 (3.6748)  Time: 0.090s, 1418.49/s  (0.096s, 1329.49/s)  LR: 5.471e-04  Data: 0.008 (0.008)
2024-04-17 16:01:22,575 - train - INFO - Train: 14 [ 200/781 ( 26%)]  Loss:  3.937918 (3.6754)  Time: 0.101s, 1273.18/s  (0.096s, 1339.57/s)  LR: 5.471e-04  Data: 0.006 (0.008)
2024-04-17 16:01:27,503 - train - INFO - Train: 14 [ 250/781 ( 32%)]  Loss:  3.141472 (3.6475)  Time: 0.091s, 1408.25/s  (0.096s, 1331.29/s)  LR: 5.471e-04  Data: 0.006 (0.008)
2024-04-17 16:01:32,223 - train - INFO - Train: 14 [ 300/781 ( 38%)]  Loss:  3.959320 (3.6537)  Time: 0.100s, 1281.84/s  (0.096s, 1335.41/s)  LR: 5.471e-04  Data: 0.007 (0.008)
2024-04-17 16:01:37,098 - train - INFO - Train: 14 [ 350/781 ( 45%)]  Loss:  4.123477 (3.6454)  Time: 0.088s, 1452.38/s  (0.096s, 1332.20/s)  LR: 5.471e-04  Data: 0.006 (0.008)
2024-04-17 16:01:41,759 - train - INFO - Train: 14 [ 400/781 ( 51%)]  Loss:  3.253378 (3.6409)  Time: 0.098s, 1311.91/s  (0.096s, 1337.21/s)  LR: 5.471e-04  Data: 0.006 (0.008)
2024-04-17 16:01:46,801 - train - INFO - Train: 14 [ 450/781 ( 58%)]  Loss:  3.158758 (3.6285)  Time: 0.106s, 1205.28/s  (0.096s, 1329.36/s)  LR: 5.471e-04  Data: 0.007 (0.008)
2024-04-17 16:01:51,647 - train - INFO - Train: 14 [ 500/781 ( 64%)]  Loss:  3.229391 (3.6259)  Time: 0.100s, 1277.96/s  (0.096s, 1328.55/s)  LR: 5.471e-04  Data: 0.005 (0.008)
2024-04-17 16:01:56,556 - train - INFO - Train: 14 [ 550/781 ( 71%)]  Loss:  3.582652 (3.6232)  Time: 0.089s, 1443.62/s  (0.097s, 1326.27/s)  LR: 5.471e-04  Data: 0.007 (0.008)
2024-04-17 16:02:01,694 - train - INFO - Train: 14 [ 600/781 ( 77%)]  Loss:  4.100731 (3.6226)  Time: 0.108s, 1180.47/s  (0.097s, 1319.20/s)  LR: 5.471e-04  Data: 0.008 (0.008)
2024-04-17 16:02:06,681 - train - INFO - Train: 14 [ 650/781 ( 83%)]  Loss:  3.674845 (3.6150)  Time: 0.095s, 1352.94/s  (0.097s, 1316.42/s)  LR: 5.471e-04  Data: 0.006 (0.008)
2024-04-17 16:02:11,533 - train - INFO - Train: 14 [ 700/781 ( 90%)]  Loss:  4.025543 (3.6164)  Time: 0.082s, 1558.15/s  (0.097s, 1316.62/s)  LR: 5.471e-04  Data: 0.004 (0.008)
2024-04-17 16:02:16,882 - train - INFO - Train: 14 [ 750/781 ( 96%)]  Loss:  3.022681 (3.6151)  Time: 0.100s, 1276.21/s  (0.098s, 1307.92/s)  LR: 5.471e-04  Data: 0.009 (0.008)
2024-04-17 16:02:19,605 - train - INFO - Train: 14 [ 780/781 (100%)]  Loss:  3.915033 (3.6180)  Time: 0.087s, 1465.40/s  (0.098s, 1311.59/s)  LR: 5.471e-04  Data: 0.000 (0.008)
2024-04-17 16:02:19,723 - train - INFO - Test: [   0/78]  Time: 0.116 (0.116)  Loss:  1.2012 (1.2012)  Acc@1: 77.3438 (77.3438)  Acc@5: 91.4062 (91.4062)
2024-04-17 16:02:21,098 - train - INFO - Test: [  50/78]  Time: 0.026 (0.029)  Loss:  2.2988 (2.0448)  Acc@1: 50.7812 (53.1097)  Acc@5: 69.5312 (78.8143)
2024-04-17 16:02:21,814 - train - INFO - Test: [  78/78]  Time: 0.024 (0.028)  Loss:  2.1797 (2.0483)  Acc@1: 43.7500 (53.4500)  Acc@5: 87.5000 (78.6900)
2024-04-17 16:02:22,113 - train - INFO - Train: 15 [   0/781 (  0%)]  Loss:  4.043458 (4.0435)  Time: 0.218s,  586.20/s  (0.218s,  586.20/s)  LR: 5.467e-04  Data: 0.119 (0.119)
2024-04-17 16:02:26,750 - train - INFO - Train: 15 [  50/781 (  6%)]  Loss:  3.690256 (3.5327)  Time: 0.109s, 1174.39/s  (0.095s, 1344.61/s)  LR: 5.467e-04  Data: 0.009 (0.009)
2024-04-17 16:02:31,577 - train - INFO - Train: 15 [ 100/781 ( 13%)]  Loss:  3.511621 (3.5829)  Time: 0.093s, 1383.20/s  (0.096s, 1335.52/s)  LR: 5.467e-04  Data: 0.007 (0.008)
2024-04-17 16:02:36,488 - train - INFO - Train: 15 [ 150/781 ( 19%)]  Loss:  4.192896 (3.5811)  Time: 0.089s, 1438.57/s  (0.097s, 1324.77/s)  LR: 5.467e-04  Data: 0.008 (0.008)
2024-04-17 16:02:41,144 - train - INFO - Train: 15 [ 200/781 ( 26%)]  Loss:  3.415784 (3.5680)  Time: 0.092s, 1391.94/s  (0.096s, 1336.90/s)  LR: 5.467e-04  Data: 0.007 (0.008)
2024-04-17 16:02:45,890 - train - INFO - Train: 15 [ 250/781 ( 32%)]  Loss:  3.782284 (3.5852)  Time: 0.092s, 1397.32/s  (0.096s, 1339.30/s)  LR: 5.467e-04  Data: 0.008 (0.008)
2024-04-17 16:02:50,413 - train - INFO - Train: 15 [ 300/781 ( 38%)]  Loss:  3.238462 (3.5808)  Time: 0.087s, 1477.69/s  (0.095s, 1351.36/s)  LR: 5.467e-04  Data: 0.009 (0.008)
2024-04-17 16:02:55,213 - train - INFO - Train: 15 [ 350/781 ( 45%)]  Loss:  3.429520 (3.5961)  Time: 0.102s, 1260.82/s  (0.095s, 1348.83/s)  LR: 5.467e-04  Data: 0.009 (0.008)
2024-04-17 16:02:59,899 - train - INFO - Train: 15 [ 400/781 ( 51%)]  Loss:  3.703243 (3.5809)  Time: 0.108s, 1181.36/s  (0.095s, 1350.96/s)  LR: 5.467e-04  Data: 0.008 (0.008)
2024-04-17 16:03:04,661 - train - INFO - Train: 15 [ 450/781 ( 58%)]  Loss:  3.273244 (3.5852)  Time: 0.101s, 1265.14/s  (0.095s, 1350.22/s)  LR: 5.467e-04  Data: 0.011 (0.008)
2024-04-17 16:03:09,703 - train - INFO - Train: 15 [ 500/781 ( 64%)]  Loss:  3.431459 (3.5863)  Time: 0.083s, 1546.08/s  (0.095s, 1341.72/s)  LR: 5.467e-04  Data: 0.005 (0.008)
2024-04-17 16:03:14,444 - train - INFO - Train: 15 [ 550/781 ( 71%)]  Loss:  4.009500 (3.5902)  Time: 0.106s, 1207.30/s  (0.095s, 1342.52/s)  LR: 5.467e-04  Data: 0.007 (0.008)
2024-04-17 16:03:19,257 - train - INFO - Train: 15 [ 600/781 ( 77%)]  Loss:  3.092967 (3.5920)  Time: 0.090s, 1427.19/s  (0.095s, 1341.47/s)  LR: 5.467e-04  Data: 0.008 (0.008)
2024-04-17 16:03:24,077 - train - INFO - Train: 15 [ 650/781 ( 83%)]  Loss:  3.450705 (3.5855)  Time: 0.084s, 1526.80/s  (0.095s, 1340.46/s)  LR: 5.467e-04  Data: 0.005 (0.008)
2024-04-17 16:03:29,102 - train - INFO - Train: 15 [ 700/781 ( 90%)]  Loss:  2.890528 (3.5881)  Time: 0.091s, 1405.75/s  (0.096s, 1335.48/s)  LR: 5.467e-04  Data: 0.008 (0.008)
2024-04-17 16:03:34,160 - train - INFO - Train: 15 [ 750/781 ( 96%)]  Loss:  3.784136 (3.5864)  Time: 0.121s, 1054.59/s  (0.096s, 1330.60/s)  LR: 5.467e-04  Data: 0.007 (0.008)
