2024-04-02 20:35:23,421 - train - INFO - Training with a single process on 1 GPUs.
2024-04-02 20:35:26,656 - train - INFO - Model vit_7_4_32 created, param count:3716931
2024-04-02 20:35:26,673 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-04-02 20:35:26,673 - train - INFO - Scheduled epochs: 160
2024-04-02 20:35:27,893 - train - INFO - Verifying teacher model
2024-04-02 20:35:28,323 - train - INFO - Test: [   0/39]  Time: 0.429 (0.429)  Loss:  0.3433 (0.3433)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-02 20:35:28,692 - train - INFO - Test: [  39/39]  Time: 0.057 (0.020)  Loss:  0.3740 (0.3449)  Acc@1: 93.7500 (93.5400)  Acc@5: 100.0000 (99.7600)
2024-04-02 20:35:28,693 - train - INFO - Verifying initial model
2024-04-02 20:35:29,031 - train - INFO - Test: [   0/39]  Time: 0.338 (0.338)  Loss:  2.0332 (2.0332)  Acc@1: 27.7344 (27.7344)  Acc@5: 71.4844 (71.4844)
2024-04-02 20:35:38,875 - train - INFO - Test: [  39/39]  Time: 0.250 (0.255)  Loss:  1.8789 (2.0274)  Acc@1: 37.5000 (28.2900)  Acc@5: 81.2500 (73.7800)
2024-04-02 20:35:40,132 - train - INFO - Train: 0 [   0/195 (  0%)]  Loss:  2.307119 (2.3071)  Time: 1.254s,  204.22/s  (1.254s,  204.22/s)  LR: 1.000e-05  Data: 0.220 (0.220)
2024-04-02 20:36:23,237 - train - INFO - Train: 0 [  50/195 ( 26%)]  Loss:  2.243143 (2.2792)  Time: 0.875s,  292.46/s  (0.870s,  294.34/s)  LR: 1.000e-05  Data: 0.010 (0.014)
2024-04-02 20:37:06,301 - train - INFO - Train: 0 [ 100/195 ( 52%)]  Loss:  2.269072 (2.2641)  Time: 0.840s,  304.88/s  (0.866s,  295.77/s)  LR: 1.000e-05  Data: 0.009 (0.012)
2024-04-02 20:37:49,822 - train - INFO - Train: 0 [ 150/195 ( 77%)]  Loss:  2.250834 (2.2506)  Time: 0.875s,  292.55/s  (0.867s,  295.22/s)  LR: 1.000e-05  Data: 0.010 (0.011)
2024-04-02 20:38:27,379 - train - INFO - Train: 0 [ 194/195 (100%)]  Loss:  2.192079 (2.2422)  Time: 0.862s,  296.84/s  (0.864s,  296.27/s)  LR: 1.000e-05  Data: 0.000 (0.011)
2024-04-02 20:38:27,380 - train - INFO - True
2024-04-02 20:38:27,419 - train - INFO - alphas:tensor([0.5008, 0.4992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,419 - train - INFO - True
2024-04-02 20:38:27,420 - train - INFO - alphas:tensor([0.5008, 0.4992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,420 - train - INFO - True
2024-04-02 20:38:27,420 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,420 - train - INFO - True
2024-04-02 20:38:27,421 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,421 - train - INFO - True
2024-04-02 20:38:27,422 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,422 - train - INFO - True
2024-04-02 20:38:27,422 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,423 - train - INFO - True
2024-04-02 20:38:27,423 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,423 - train - INFO - True
2024-04-02 20:38:27,424 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,424 - train - INFO - True
2024-04-02 20:38:27,425 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,425 - train - INFO - True
2024-04-02 20:38:27,425 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,425 - train - INFO - True
2024-04-02 20:38:27,426 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,426 - train - INFO - True
2024-04-02 20:38:27,427 - train - INFO - alphas:tensor([0.5011, 0.4989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,427 - train - INFO - True
2024-04-02 20:38:27,427 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,427 - train - INFO - True
2024-04-02 20:38:27,428 - train - INFO - alphas:tensor([0.5011, 0.4989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,428 - train - INFO - True
2024-04-02 20:38:27,429 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,429 - train - INFO - True
2024-04-02 20:38:27,429 - train - INFO - alphas:tensor([0.5006, 0.4994], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,430 - train - INFO - True
2024-04-02 20:38:27,430 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,430 - train - INFO - True
2024-04-02 20:38:27,431 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,431 - train - INFO - True
2024-04-02 20:38:27,432 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,432 - train - INFO - True
2024-04-02 20:38:27,432 - train - INFO - alphas:tensor([0.4994, 0.5006], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,432 - train - INFO - True
2024-04-02 20:38:27,433 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,433 - train - INFO - True
2024-04-02 20:38:27,434 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,434 - train - INFO - True
2024-04-02 20:38:27,434 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,435 - train - INFO - True
2024-04-02 20:38:27,435 - train - INFO - alphas:tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,435 - train - INFO - True
2024-04-02 20:38:27,436 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,436 - train - INFO - True
2024-04-02 20:38:27,437 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,437 - train - INFO - True
2024-04-02 20:38:27,437 - train - INFO - alphas:tensor([0.5005, 0.4995], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,437 - train - INFO - True
2024-04-02 20:38:27,438 - train - INFO - alphas:tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,438 - train - INFO - True
2024-04-02 20:38:27,439 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,439 - train - INFO - avg block size:1.5172413793103448
2024-04-02 20:38:27,783 - train - INFO - Test: [   0/39]  Time: 0.342 (0.342)  Loss:  1.8203 (1.8203)  Acc@1: 51.1719 (51.1719)  Acc@5: 89.8438 (89.8438)
2024-04-02 20:38:37,599 - train - INFO - Test: [  39/39]  Time: 0.250 (0.254)  Loss:  1.7236 (1.8016)  Acc@1: 56.2500 (48.1300)  Acc@5: 93.7500 (91.1600)
2024-04-02 20:38:38,645 - train - INFO - Train: 1 [   0/195 (  0%)]  Loss:  2.194058 (2.1941)  Time: 0.974s,  262.88/s  (0.974s,  262.88/s)  LR: 6.400e-05  Data: 0.137 (0.137)
2024-04-02 20:39:21,312 - train - INFO - Train: 1 [  50/195 ( 26%)]  Loss:  2.201029 (2.1635)  Time: 0.868s,  295.10/s  (0.856s,  299.18/s)  LR: 6.400e-05  Data: 0.011 (0.013)
2024-04-02 20:40:04,838 - train - INFO - Train: 1 [ 100/195 ( 52%)]  Loss:  2.188852 (2.1200)  Time: 0.847s,  302.25/s  (0.863s,  296.64/s)  LR: 6.400e-05  Data: 0.011 (0.011)
2024-04-02 20:40:53,463 - train - INFO - Train: 1 [ 150/195 ( 77%)]  Loss:  2.057493 (2.0833)  Time: 1.091s,  234.73/s  (0.899s,  284.68/s)  LR: 6.400e-05  Data: 0.010 (0.010)
2024-04-02 20:41:40,272 - train - INFO - Train: 1 [ 194/195 (100%)]  Loss:  1.811355 (2.0649)  Time: 1.058s,  241.88/s  (0.936s,  273.39/s)  LR: 6.400e-05  Data: 0.000 (0.009)
2024-04-02 20:41:40,273 - train - INFO - True
2024-04-02 20:41:40,274 - train - INFO - alphas:tensor([0.5075, 0.4925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,274 - train - INFO - True
2024-04-02 20:41:40,275 - train - INFO - alphas:tensor([0.5071, 0.4929], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,276 - train - INFO - True
2024-04-02 20:41:40,276 - train - INFO - alphas:tensor([0.5089, 0.4911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,276 - train - INFO - True
2024-04-02 20:41:40,277 - train - INFO - alphas:tensor([0.5101, 0.4899], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,277 - train - INFO - True
2024-04-02 20:41:40,278 - train - INFO - alphas:tensor([0.5091, 0.4909], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,278 - train - INFO - True
2024-04-02 20:41:40,279 - train - INFO - alphas:tensor([0.5086, 0.4914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,279 - train - INFO - True
2024-04-02 20:41:40,279 - train - INFO - alphas:tensor([0.5080, 0.4920], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,280 - train - INFO - True
2024-04-02 20:41:40,280 - train - INFO - alphas:tensor([0.5081, 0.4919], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,280 - train - INFO - True
2024-04-02 20:41:40,281 - train - INFO - alphas:tensor([0.5084, 0.4916], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,281 - train - INFO - True
2024-04-02 20:41:40,282 - train - INFO - alphas:tensor([0.5077, 0.4923], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,282 - train - INFO - True
2024-04-02 20:41:40,283 - train - INFO - alphas:tensor([0.5075, 0.4925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,283 - train - INFO - True
2024-04-02 20:41:40,283 - train - INFO - alphas:tensor([0.5081, 0.4919], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,283 - train - INFO - True
2024-04-02 20:41:40,284 - train - INFO - alphas:tensor([0.5076, 0.4924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,284 - train - INFO - True
2024-04-02 20:41:40,285 - train - INFO - alphas:tensor([0.5070, 0.4930], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,285 - train - INFO - True
2024-04-02 20:41:40,286 - train - INFO - alphas:tensor([0.5078, 0.4922], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,286 - train - INFO - True
2024-04-02 20:41:40,286 - train - INFO - alphas:tensor([0.5084, 0.4916], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,287 - train - INFO - True
2024-04-02 20:41:40,287 - train - INFO - alphas:tensor([0.5076, 0.4924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,287 - train - INFO - True
2024-04-02 20:41:40,288 - train - INFO - alphas:tensor([0.5065, 0.4935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,288 - train - INFO - True
2024-04-02 20:41:40,289 - train - INFO - alphas:tensor([0.5058, 0.4942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,289 - train - INFO - True
2024-04-02 20:41:40,290 - train - INFO - alphas:tensor([0.5043, 0.4957], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,290 - train - INFO - True
2024-04-02 20:41:40,290 - train - INFO - alphas:tensor([0.5065, 0.4935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,290 - train - INFO - True
2024-04-02 20:41:40,291 - train - INFO - alphas:tensor([0.5058, 0.4942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,291 - train - INFO - True
2024-04-02 20:41:40,292 - train - INFO - alphas:tensor([0.5049, 0.4951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,292 - train - INFO - True
2024-04-02 20:41:40,293 - train - INFO - alphas:tensor([0.5065, 0.4935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,293 - train - INFO - True
2024-04-02 20:41:40,294 - train - INFO - alphas:tensor([0.5064, 0.4936], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,294 - train - INFO - True
2024-04-02 20:41:40,295 - train - INFO - alphas:tensor([0.5052, 0.4948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,295 - train - INFO - True
2024-04-02 20:41:40,296 - train - INFO - alphas:tensor([0.5050, 0.4950], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,296 - train - INFO - True
2024-04-02 20:41:40,297 - train - INFO - alphas:tensor([0.5057, 0.4943], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,297 - train - INFO - True
2024-04-02 20:41:40,298 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,298 - train - INFO - avg block size:1.0
2024-04-02 20:41:40,782 - train - INFO - Test: [   0/39]  Time: 0.480 (0.480)  Loss:  1.1689 (1.1689)  Acc@1: 66.0156 (66.0156)  Acc@5: 98.0469 (98.0469)
2024-04-02 20:42:02,283 - train - INFO - Test: [  39/39]  Time: 0.642 (0.550)  Loss:  1.1289 (1.1307)  Acc@1: 62.5000 (67.4300)  Acc@5: 100.0000 (97.3900)
2024-04-02 20:42:03,539 - train - INFO - Train: 2 [   0/195 (  0%)]  Loss:  2.025479 (2.0255)  Time: 1.181s,  216.69/s  (1.181s,  216.69/s)  LR: 1.180e-04  Data: 0.124 (0.124)
2024-04-02 20:42:52,375 - train - INFO - Train: 2 [  50/195 ( 26%)]  Loss:  2.143815 (1.9549)  Time: 1.067s,  240.00/s  (0.981s,  261.03/s)  LR: 1.180e-04  Data: 0.005 (0.009)
2024-04-02 20:43:49,186 - train - INFO - Train: 2 [ 100/195 ( 52%)]  Loss:  2.069757 (1.9302)  Time: 1.270s,  201.62/s  (1.058s,  242.04/s)  LR: 1.180e-04  Data: 0.005 (0.008)
2024-04-02 20:45:05,604 - train - INFO - Train: 2 [ 150/195 ( 77%)]  Loss:  1.777966 (1.9159)  Time: 1.618s,  158.23/s  (1.214s,  210.95/s)  LR: 1.180e-04  Data: 0.005 (0.008)
2024-04-02 20:46:15,925 - train - INFO - Train: 2 [ 194/195 (100%)]  Loss:  1.987849 (1.9019)  Time: 1.537s,  166.59/s  (1.300s,  196.88/s)  LR: 1.180e-04  Data: 0.000 (0.007)
2024-04-02 20:46:15,926 - train - INFO - True
2024-04-02 20:46:15,927 - train - INFO - alphas:tensor([0.5196, 0.4804], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,927 - train - INFO - True
2024-04-02 20:46:15,928 - train - INFO - alphas:tensor([0.5172, 0.4828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,929 - train - INFO - True
2024-04-02 20:46:15,930 - train - INFO - alphas:tensor([0.5236, 0.4764], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,930 - train - INFO - True
2024-04-02 20:46:15,931 - train - INFO - alphas:tensor([0.5251, 0.4749], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,931 - train - INFO - True
2024-04-02 20:46:15,932 - train - INFO - alphas:tensor([0.5218, 0.4782], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,932 - train - INFO - True
2024-04-02 20:46:15,933 - train - INFO - alphas:tensor([0.5204, 0.4796], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,933 - train - INFO - True
2024-04-02 20:46:15,934 - train - INFO - alphas:tensor([0.5201, 0.4799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,934 - train - INFO - True
2024-04-02 20:46:15,935 - train - INFO - alphas:tensor([0.5202, 0.4798], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,935 - train - INFO - True
2024-04-02 20:46:15,936 - train - INFO - alphas:tensor([0.5231, 0.4769], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,936 - train - INFO - True
2024-04-02 20:46:15,937 - train - INFO - alphas:tensor([0.5219, 0.4781], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,937 - train - INFO - True
2024-04-02 20:46:15,938 - train - INFO - alphas:tensor([0.5182, 0.4818], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,938 - train - INFO - True
2024-04-02 20:46:15,939 - train - INFO - alphas:tensor([0.5196, 0.4804], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,940 - train - INFO - True
2024-04-02 20:46:15,941 - train - INFO - alphas:tensor([0.5177, 0.4823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,941 - train - INFO - True
2024-04-02 20:46:15,942 - train - INFO - alphas:tensor([0.5164, 0.4836], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,943 - train - INFO - True
2024-04-02 20:46:15,944 - train - INFO - alphas:tensor([0.5190, 0.4810], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,945 - train - INFO - True
2024-04-02 20:46:15,946 - train - INFO - alphas:tensor([0.5220, 0.4780], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,946 - train - INFO - True
2024-04-02 20:46:15,948 - train - INFO - alphas:tensor([0.5151, 0.4849], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,949 - train - INFO - True
2024-04-02 20:46:15,950 - train - INFO - alphas:tensor([0.5138, 0.4862], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,950 - train - INFO - True
2024-04-02 20:46:15,951 - train - INFO - alphas:tensor([0.5139, 0.4861], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,951 - train - INFO - True
2024-04-02 20:46:15,952 - train - INFO - alphas:tensor([0.5155, 0.4845], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,954 - train - INFO - True
2024-04-02 20:46:15,955 - train - INFO - alphas:tensor([0.5124, 0.4876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,955 - train - INFO - True
2024-04-02 20:46:15,957 - train - INFO - alphas:tensor([0.5126, 0.4874], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,957 - train - INFO - True
2024-04-02 20:46:15,958 - train - INFO - alphas:tensor([0.5118, 0.4882], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,958 - train - INFO - True
2024-04-02 20:46:15,959 - train - INFO - alphas:tensor([0.5133, 0.4867], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,959 - train - INFO - True
2024-04-02 20:46:15,970 - train - INFO - alphas:tensor([0.5109, 0.4891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,970 - train - INFO - True
2024-04-02 20:46:15,971 - train - INFO - alphas:tensor([0.5095, 0.4905], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,971 - train - INFO - True
2024-04-02 20:46:15,972 - train - INFO - alphas:tensor([0.5116, 0.4884], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,972 - train - INFO - True
2024-04-02 20:46:15,973 - train - INFO - alphas:tensor([0.5085, 0.4915], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,973 - train - INFO - True
2024-04-02 20:46:15,974 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,976 - train - INFO - avg block size:1.0
2024-04-02 20:46:16,926 - train - INFO - Test: [   0/39]  Time: 0.945 (0.945)  Loss:  0.9048 (0.9048)  Acc@1: 76.5625 (76.5625)  Acc@5: 98.4375 (98.4375)
2024-04-02 20:46:51,631 - train - INFO - Test: [  39/39]  Time: 0.875 (0.891)  Loss:  0.9932 (0.8627)  Acc@1: 68.7500 (76.2300)  Acc@5: 100.0000 (98.4500)
2024-04-02 20:46:53,637 - train - INFO - Train: 3 [   0/195 (  0%)]  Loss:  1.805281 (1.8053)  Time: 1.898s,  134.87/s  (1.898s,  134.87/s)  LR: 1.720e-04  Data: 0.226 (0.226)
2024-04-02 20:48:13,636 - train - INFO - Train: 3 [  50/195 ( 26%)]  Loss:  1.902879 (1.8514)  Time: 1.488s,  171.99/s  (1.606s,  159.42/s)  LR: 1.720e-04  Data: 0.006 (0.012)
2024-04-02 20:49:34,130 - train - INFO - Train: 3 [ 100/195 ( 52%)]  Loss:  1.819241 (1.8213)  Time: 1.492s,  171.56/s  (1.608s,  159.22/s)  LR: 1.720e-04  Data: 0.006 (0.010)
2024-04-02 20:51:02,952 - train - INFO - Train: 3 [ 150/195 ( 77%)]  Loss:  1.953846 (1.8178)  Time: 1.799s,  142.34/s  (1.664s,  153.88/s)  LR: 1.720e-04  Data: 0.007 (0.010)
2024-04-02 20:52:26,014 - train - INFO - Train: 3 [ 194/195 (100%)]  Loss:  1.638349 (1.8136)  Time: 2.050s,  124.90/s  (1.714s,  149.34/s)  LR: 1.720e-04  Data: 0.000 (0.010)
2024-04-02 20:52:26,020 - train - INFO - True
2024-04-02 20:52:26,021 - train - INFO - alphas:tensor([0.5323, 0.4677], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,021 - train - INFO - tau:0.99
2024-04-02 20:52:26,021 - train - INFO - True
2024-04-02 20:52:26,022 - train - INFO - alphas:tensor([0.5263, 0.4737], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,022 - train - INFO - tau:0.99
2024-04-02 20:52:26,022 - train - INFO - True
2024-04-02 20:52:26,023 - train - INFO - alphas:tensor([0.5414, 0.4586], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,023 - train - INFO - tau:0.99
2024-04-02 20:52:26,024 - train - INFO - True
2024-04-02 20:52:26,024 - train - INFO - alphas:tensor([0.5433, 0.4567], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,024 - train - INFO - tau:0.99
2024-04-02 20:52:26,025 - train - INFO - True
2024-04-02 20:52:26,032 - train - INFO - alphas:tensor([0.5366, 0.4634], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,032 - train - INFO - tau:0.99
2024-04-02 20:52:26,032 - train - INFO - True
2024-04-02 20:52:26,033 - train - INFO - alphas:tensor([0.5350, 0.4650], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,034 - train - INFO - tau:0.99
2024-04-02 20:52:26,034 - train - INFO - True
2024-04-02 20:52:26,035 - train - INFO - alphas:tensor([0.5342, 0.4658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,035 - train - INFO - tau:0.99
2024-04-02 20:52:26,035 - train - INFO - True
2024-04-02 20:52:26,036 - train - INFO - alphas:tensor([0.5341, 0.4659], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,036 - train - INFO - tau:0.99
2024-04-02 20:52:26,037 - train - INFO - True
2024-04-02 20:52:26,037 - train - INFO - alphas:tensor([0.5415, 0.4585], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,038 - train - INFO - tau:0.99
2024-04-02 20:52:26,038 - train - INFO - True
2024-04-02 20:52:26,039 - train - INFO - alphas:tensor([0.5421, 0.4579], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,039 - train - INFO - tau:0.99
2024-04-02 20:52:26,039 - train - INFO - True
2024-04-02 20:52:26,040 - train - INFO - alphas:tensor([0.5320, 0.4680], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,040 - train - INFO - tau:0.99
2024-04-02 20:52:26,041 - train - INFO - True
2024-04-02 20:52:26,041 - train - INFO - alphas:tensor([0.5342, 0.4658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,042 - train - INFO - tau:0.99
2024-04-02 20:52:26,042 - train - INFO - True
2024-04-02 20:52:26,043 - train - INFO - alphas:tensor([0.5321, 0.4679], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,043 - train - INFO - tau:0.99
2024-04-02 20:52:26,043 - train - INFO - True
2024-04-02 20:52:26,044 - train - INFO - alphas:tensor([0.5315, 0.4685], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,044 - train - INFO - tau:0.99
2024-04-02 20:52:26,044 - train - INFO - True
2024-04-02 20:52:26,045 - train - INFO - alphas:tensor([0.5333, 0.4667], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,045 - train - INFO - tau:0.99
2024-04-02 20:52:26,046 - train - INFO - True
2024-04-02 20:52:26,047 - train - INFO - alphas:tensor([0.5384, 0.4616], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,047 - train - INFO - tau:0.99
2024-04-02 20:52:26,047 - train - INFO - True
2024-04-02 20:52:26,048 - train - INFO - alphas:tensor([0.5242, 0.4758], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,049 - train - INFO - tau:0.99
2024-04-02 20:52:26,049 - train - INFO - True
2024-04-02 20:52:26,050 - train - INFO - alphas:tensor([0.5229, 0.4771], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,050 - train - INFO - tau:0.99
2024-04-02 20:52:26,050 - train - INFO - True
2024-04-02 20:52:26,051 - train - INFO - alphas:tensor([0.5260, 0.4740], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,051 - train - INFO - tau:0.99
2024-04-02 20:52:26,052 - train - INFO - True
2024-04-02 20:52:26,052 - train - INFO - alphas:tensor([0.5318, 0.4682], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,053 - train - INFO - tau:0.99
2024-04-02 20:52:26,053 - train - INFO - True
2024-04-02 20:52:26,054 - train - INFO - alphas:tensor([0.5179, 0.4821], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,054 - train - INFO - tau:0.99
2024-04-02 20:52:26,054 - train - INFO - True
2024-04-02 20:52:26,055 - train - INFO - alphas:tensor([0.5198, 0.4802], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,055 - train - INFO - tau:0.99
2024-04-02 20:52:26,056 - train - INFO - True
2024-04-02 20:52:26,056 - train - INFO - alphas:tensor([0.5217, 0.4783], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,057 - train - INFO - tau:0.99
2024-04-02 20:52:26,057 - train - INFO - True
2024-04-02 20:52:26,058 - train - INFO - alphas:tensor([0.5229, 0.4771], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,058 - train - INFO - tau:0.99
2024-04-02 20:52:26,058 - train - INFO - True
2024-04-02 20:52:26,059 - train - INFO - alphas:tensor([0.5163, 0.4837], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,060 - train - INFO - tau:0.99
2024-04-02 20:52:26,060 - train - INFO - True
2024-04-02 20:52:26,061 - train - INFO - alphas:tensor([0.5151, 0.4849], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,061 - train - INFO - tau:0.99
2024-04-02 20:52:26,061 - train - INFO - True
2024-04-02 20:52:26,062 - train - INFO - alphas:tensor([0.5230, 0.4770], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,062 - train - INFO - tau:0.99
2024-04-02 20:52:26,062 - train - INFO - True
2024-04-02 20:52:26,063 - train - INFO - alphas:tensor([0.5140, 0.4860], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,064 - train - INFO - tau:0.99
2024-04-02 20:52:26,064 - train - INFO - True
2024-04-02 20:52:26,065 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,065 - train - INFO - tau:0.99
2024-04-02 20:52:26,065 - train - INFO - avg block size:1.0
2024-04-02 20:52:27,189 - train - INFO - Test: [   0/39]  Time: 1.121 (1.121)  Loss:  0.7344 (0.7344)  Acc@1: 82.4219 (82.4219)  Acc@5: 98.4375 (98.4375)
2024-04-02 20:53:10,198 - train - INFO - Test: [  39/39]  Time: 1.103 (1.103)  Loss:  0.8428 (0.7001)  Acc@1: 68.7500 (81.4200)  Acc@5: 100.0000 (98.8600)
2024-04-02 20:53:12,775 - train - INFO - Train: 4 [   0/195 (  0%)]  Loss:  1.431711 (1.4317)  Time: 2.493s,  102.70/s  (2.493s,  102.70/s)  LR: 2.260e-04  Data: 0.214 (0.214)
2024-04-02 20:54:51,871 - train - INFO - Train: 4 [  50/195 ( 26%)]  Loss:  1.748157 (1.7377)  Time: 2.260s,  113.27/s  (1.992s,  128.52/s)  LR: 2.260e-04  Data: 0.010 (0.013)
2024-04-02 20:56:38,947 - train - INFO - Train: 4 [ 100/195 ( 52%)]  Loss:  1.778219 (1.7107)  Time: 2.385s,  107.34/s  (2.066s,  123.92/s)  LR: 2.260e-04  Data: 0.014 (0.011)
2024-04-02 20:58:18,023 - train - INFO - Train: 4 [ 150/195 ( 77%)]  Loss:  1.660895 (1.7186)  Time: 2.077s,  123.27/s  (2.038s,  125.62/s)  LR: 2.260e-04  Data: 0.006 (0.011)
2024-04-02 20:59:46,029 - train - INFO - Train: 4 [ 194/195 (100%)]  Loss:  1.433296 (1.7073)  Time: 1.816s,  140.94/s  (2.029s,  126.14/s)  LR: 2.260e-04  Data: 0.000 (0.011)
2024-04-02 20:59:46,030 - train - INFO - True
2024-04-02 20:59:46,032 - train - INFO - alphas:tensor([0.5434, 0.4566], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,032 - train - INFO - tau:0.9801
2024-04-02 20:59:46,033 - train - INFO - True
2024-04-02 20:59:46,035 - train - INFO - alphas:tensor([0.5345, 0.4655], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,035 - train - INFO - tau:0.9801
2024-04-02 20:59:46,035 - train - INFO - True
2024-04-02 20:59:46,036 - train - INFO - alphas:tensor([0.5627, 0.4373], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,036 - train - INFO - tau:0.9801
2024-04-02 20:59:46,037 - train - INFO - True
2024-04-02 20:59:46,038 - train - INFO - alphas:tensor([0.5657, 0.4343], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,038 - train - INFO - tau:0.9801
2024-04-02 20:59:46,038 - train - INFO - True
2024-04-02 20:59:46,039 - train - INFO - alphas:tensor([0.5526, 0.4474], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,039 - train - INFO - tau:0.9801
2024-04-02 20:59:46,039 - train - INFO - True
2024-04-02 20:59:46,040 - train - INFO - alphas:tensor([0.5519, 0.4481], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,041 - train - INFO - tau:0.9801
2024-04-02 20:59:46,041 - train - INFO - True
2024-04-02 20:59:46,042 - train - INFO - alphas:tensor([0.5518, 0.4482], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,042 - train - INFO - tau:0.9801
2024-04-02 20:59:46,042 - train - INFO - True
2024-04-02 20:59:46,043 - train - INFO - alphas:tensor([0.5509, 0.4491], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,043 - train - INFO - tau:0.9801
2024-04-02 20:59:46,043 - train - INFO - True
2024-04-02 20:59:46,044 - train - INFO - alphas:tensor([0.5591, 0.4409], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,044 - train - INFO - tau:0.9801
2024-04-02 20:59:46,044 - train - INFO - True
2024-04-02 20:59:46,046 - train - INFO - alphas:tensor([0.5629, 0.4371], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,046 - train - INFO - tau:0.9801
2024-04-02 20:59:46,046 - train - INFO - True
2024-04-02 20:59:46,056 - train - INFO - alphas:tensor([0.5505, 0.4495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,093 - train - INFO - tau:0.9801
2024-04-02 20:59:46,093 - train - INFO - True
2024-04-02 20:59:46,094 - train - INFO - alphas:tensor([0.5535, 0.4465], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,094 - train - INFO - tau:0.9801
2024-04-02 20:59:46,094 - train - INFO - True
2024-04-02 20:59:46,095 - train - INFO - alphas:tensor([0.5490, 0.4510], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,099 - train - INFO - tau:0.9801
2024-04-02 20:59:46,100 - train - INFO - True
2024-04-02 20:59:46,101 - train - INFO - alphas:tensor([0.5510, 0.4490], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,101 - train - INFO - tau:0.9801
2024-04-02 20:59:46,110 - train - INFO - True
2024-04-02 20:59:46,111 - train - INFO - alphas:tensor([0.5527, 0.4473], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,111 - train - INFO - tau:0.9801
2024-04-02 20:59:46,111 - train - INFO - True
2024-04-02 20:59:46,112 - train - INFO - alphas:tensor([0.5600, 0.4400], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,113 - train - INFO - tau:0.9801
2024-04-02 20:59:46,113 - train - INFO - True
2024-04-02 20:59:46,114 - train - INFO - alphas:tensor([0.5358, 0.4642], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,114 - train - INFO - tau:0.9801
2024-04-02 20:59:46,114 - train - INFO - True
2024-04-02 20:59:46,115 - train - INFO - alphas:tensor([0.5351, 0.4649], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,120 - train - INFO - tau:0.9801
2024-04-02 20:59:46,120 - train - INFO - True
2024-04-02 20:59:46,121 - train - INFO - alphas:tensor([0.5421, 0.4579], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,121 - train - INFO - tau:0.9801
2024-04-02 20:59:46,130 - train - INFO - True
2024-04-02 20:59:46,131 - train - INFO - alphas:tensor([0.5522, 0.4478], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,131 - train - INFO - tau:0.9801
2024-04-02 20:59:46,132 - train - INFO - True
2024-04-02 20:59:46,132 - train - INFO - alphas:tensor([0.5259, 0.4741], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,133 - train - INFO - tau:0.9801
2024-04-02 20:59:46,133 - train - INFO - True
2024-04-02 20:59:46,134 - train - INFO - alphas:tensor([0.5296, 0.4704], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,135 - train - INFO - tau:0.9801
2024-04-02 20:59:46,136 - train - INFO - True
2024-04-02 20:59:46,136 - train - INFO - alphas:tensor([0.5357, 0.4643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,137 - train - INFO - tau:0.9801
2024-04-02 20:59:46,137 - train - INFO - True
2024-04-02 20:59:46,138 - train - INFO - alphas:tensor([0.5371, 0.4629], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,145 - train - INFO - tau:0.9801
2024-04-02 20:59:46,150 - train - INFO - True
2024-04-02 20:59:46,151 - train - INFO - alphas:tensor([0.5232, 0.4768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,151 - train - INFO - tau:0.9801
2024-04-02 20:59:46,151 - train - INFO - True
2024-04-02 20:59:46,152 - train - INFO - alphas:tensor([0.5227, 0.4773], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,152 - train - INFO - tau:0.9801
2024-04-02 20:59:46,152 - train - INFO - True
2024-04-02 20:59:46,153 - train - INFO - alphas:tensor([0.5389, 0.4611], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,153 - train - INFO - tau:0.9801
2024-04-02 20:59:46,153 - train - INFO - True
2024-04-02 20:59:46,154 - train - INFO - alphas:tensor([0.5230, 0.4770], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,154 - train - INFO - tau:0.9801
2024-04-02 20:59:46,155 - train - INFO - True
2024-04-02 20:59:46,155 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,156 - train - INFO - tau:0.9801
2024-04-02 20:59:46,156 - train - INFO - avg block size:1.0
2024-04-02 20:59:47,365 - train - INFO - Test: [   0/39]  Time: 1.205 (1.205)  Loss:  0.6475 (0.6475)  Acc@1: 82.8125 (82.8125)  Acc@5: 98.8281 (98.8281)
2024-04-02 21:00:29,707 - train - INFO - Test: [  39/39]  Time: 1.034 (1.089)  Loss:  0.6758 (0.5846)  Acc@1: 81.2500 (85.8500)  Acc@5: 100.0000 (99.1900)
2024-04-02 21:00:31,912 - train - INFO - Train: 5 [   0/195 (  0%)]  Loss:  1.902684 (1.9027)  Time: 2.092s,  122.36/s  (2.092s,  122.36/s)  LR: 2.800e-04  Data: 0.225 (0.225)
2024-04-02 21:02:10,068 - train - INFO - Train: 5 [  50/195 ( 26%)]  Loss:  1.375885 (1.7294)  Time: 1.941s,  131.87/s  (1.966s,  130.24/s)  LR: 2.800e-04  Data: 0.005 (0.014)
2024-04-02 21:03:49,572 - train - INFO - Train: 5 [ 100/195 ( 52%)]  Loss:  1.544680 (1.6743)  Time: 2.226s,  114.99/s  (1.978s,  129.44/s)  LR: 2.800e-04  Data: 0.020 (0.012)
2024-04-02 21:05:28,002 - train - INFO - Train: 5 [ 150/195 ( 77%)]  Loss:  1.554915 (1.6526)  Time: 1.872s,  136.76/s  (1.975s,  129.64/s)  LR: 2.800e-04  Data: 0.017 (0.011)
2024-04-02 21:06:52,900 - train - INFO - Train: 5 [ 194/195 (100%)]  Loss:  1.806862 (1.6462)  Time: 1.749s,  146.36/s  (1.964s,  130.32/s)  LR: 2.800e-04  Data: 0.000 (0.010)
2024-04-02 21:06:52,905 - train - INFO - True
2024-04-02 21:06:52,907 - train - INFO - alphas:tensor([0.5473, 0.4527], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,911 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,912 - train - INFO - True
2024-04-02 21:06:52,912 - train - INFO - alphas:tensor([0.5389, 0.4611], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,913 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,913 - train - INFO - True
2024-04-02 21:06:52,914 - train - INFO - alphas:tensor([0.5829, 0.4171], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,914 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,914 - train - INFO - True
2024-04-02 21:06:52,920 - train - INFO - alphas:tensor([0.5876, 0.4124], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,920 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,920 - train - INFO - True
2024-04-02 21:06:52,921 - train - INFO - alphas:tensor([0.5689, 0.4311], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,921 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,922 - train - INFO - True
2024-04-02 21:06:52,922 - train - INFO - alphas:tensor([0.5692, 0.4308], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,923 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,923 - train - INFO - True
2024-04-02 21:06:52,924 - train - INFO - alphas:tensor([0.5723, 0.4277], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,928 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,929 - train - INFO - True
2024-04-02 21:06:52,930 - train - INFO - alphas:tensor([0.5703, 0.4297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,934 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,935 - train - INFO - True
2024-04-02 21:06:52,935 - train - INFO - alphas:tensor([0.5738, 0.4262], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,936 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,936 - train - INFO - True
2024-04-02 21:06:52,937 - train - INFO - alphas:tensor([0.5821, 0.4179], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,937 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,937 - train - INFO - True
2024-04-02 21:06:52,938 - train - INFO - alphas:tensor([0.5710, 0.4290], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,938 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,939 - train - INFO - True
2024-04-02 21:06:52,940 - train - INFO - alphas:tensor([0.5754, 0.4246], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,940 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,940 - train - INFO - True
2024-04-02 21:06:52,941 - train - INFO - alphas:tensor([0.5645, 0.4355], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,950 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,950 - train - INFO - True
2024-04-02 21:06:52,951 - train - INFO - alphas:tensor([0.5702, 0.4298], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,951 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,952 - train - INFO - True
2024-04-02 21:06:52,953 - train - INFO - alphas:tensor([0.5738, 0.4262], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,953 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,953 - train - INFO - True
2024-04-02 21:06:52,954 - train - INFO - alphas:tensor([0.5839, 0.4161], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,954 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,954 - train - INFO - True
2024-04-02 21:06:52,955 - train - INFO - alphas:tensor([0.5486, 0.4514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,956 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,956 - train - INFO - True
2024-04-02 21:06:52,957 - train - INFO - alphas:tensor([0.5486, 0.4514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,966 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,966 - train - INFO - True
2024-04-02 21:06:52,967 - train - INFO - alphas:tensor([0.5597, 0.4403], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,967 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,967 - train - INFO - True
2024-04-02 21:06:52,968 - train - INFO - alphas:tensor([0.5733, 0.4267], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,969 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,969 - train - INFO - True
2024-04-02 21:06:52,970 - train - INFO - alphas:tensor([0.5350, 0.4650], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,970 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,970 - train - INFO - True
2024-04-02 21:06:52,971 - train - INFO - alphas:tensor([0.5401, 0.4599], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,971 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,971 - train - INFO - True
2024-04-02 21:06:52,972 - train - INFO - alphas:tensor([0.5519, 0.4481], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,972 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,972 - train - INFO - True
2024-04-02 21:06:52,973 - train - INFO - alphas:tensor([0.5547, 0.4453], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,974 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,974 - train - INFO - True
2024-04-02 21:06:52,975 - train - INFO - alphas:tensor([0.5311, 0.4689], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,975 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,975 - train - INFO - True
2024-04-02 21:06:52,976 - train - INFO - alphas:tensor([0.5313, 0.4687], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,977 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,977 - train - INFO - True
2024-04-02 21:06:52,978 - train - INFO - alphas:tensor([0.5546, 0.4454], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,978 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,978 - train - INFO - True
2024-04-02 21:06:52,984 - train - INFO - alphas:tensor([0.5324, 0.4676], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,984 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,984 - train - INFO - True
2024-04-02 21:06:52,985 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,985 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,985 - train - INFO - avg block size:1.0
2024-04-02 21:06:54,136 - train - INFO - Test: [   0/39]  Time: 1.147 (1.147)  Loss:  0.5698 (0.5698)  Acc@1: 85.9375 (85.9375)  Acc@5: 100.0000 (100.0000)
2024-04-02 21:07:36,410 - train - INFO - Test: [  39/39]  Time: 1.129 (1.086)  Loss:  0.5259 (0.5291)  Acc@1: 81.2500 (88.2900)  Acc@5: 100.0000 (99.5400)
2024-04-02 21:07:38,684 - train - INFO - Train: 6 [   0/195 (  0%)]  Loss:  1.708569 (1.7086)  Time: 2.136s,  119.84/s  (2.136s,  119.84/s)  LR: 3.340e-04  Data: 0.200 (0.200)
2024-04-02 21:09:16,897 - train - INFO - Train: 6 [  50/195 ( 26%)]  Loss:  1.767722 (1.6013)  Time: 2.256s,  113.46/s  (1.968s,  130.11/s)  LR: 3.340e-04  Data: 0.005 (0.012)
2024-04-02 21:10:44,828 - train - INFO - Train: 6 [ 100/195 ( 52%)]  Loss:  1.398860 (1.5932)  Time: 1.241s,  206.28/s  (1.864s,  137.33/s)  LR: 3.340e-04  Data: 0.005 (0.010)
2024-04-02 21:11:47,572 - train - INFO - Train: 6 [ 150/195 ( 77%)]  Loss:  1.477973 (1.5853)  Time: 1.242s,  206.09/s  (1.662s,  154.00/s)  LR: 3.340e-04  Data: 0.007 (0.009)
2024-04-02 21:12:33,082 - train - INFO - Train: 6 [ 194/195 (100%)]  Loss:  1.268204 (1.5870)  Time: 1.035s,  247.29/s  (1.521s,  168.35/s)  LR: 3.340e-04  Data: 0.000 (0.008)
2024-04-02 21:12:33,082 - train - INFO - True
2024-04-02 21:12:33,083 - train - INFO - alphas:tensor([0.5452, 0.4548], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,084 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,084 - train - INFO - True
2024-04-02 21:12:33,084 - train - INFO - alphas:tensor([0.5392, 0.4608], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,084 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,085 - train - INFO - True
2024-04-02 21:12:33,085 - train - INFO - alphas:tensor([0.6000, 0.4000], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,085 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,085 - train - INFO - True
2024-04-02 21:12:33,086 - train - INFO - alphas:tensor([0.6056, 0.3944], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,086 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,086 - train - INFO - True
2024-04-02 21:12:33,087 - train - INFO - alphas:tensor([0.5777, 0.4223], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,087 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,087 - train - INFO - True
2024-04-02 21:12:33,088 - train - INFO - alphas:tensor([0.5818, 0.4182], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,088 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,089 - train - INFO - True
2024-04-02 21:12:33,089 - train - INFO - alphas:tensor([0.5930, 0.4070], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,089 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,089 - train - INFO - True
2024-04-02 21:12:33,090 - train - INFO - alphas:tensor([0.5898, 0.4102], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,090 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,090 - train - INFO - True
2024-04-02 21:12:33,091 - train - INFO - alphas:tensor([0.5841, 0.4159], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,091 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,091 - train - INFO - True
2024-04-02 21:12:33,092 - train - INFO - alphas:tensor([0.5986, 0.4014], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,092 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,092 - train - INFO - True
2024-04-02 21:12:33,093 - train - INFO - alphas:tensor([0.5917, 0.4083], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,093 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,093 - train - INFO - True
2024-04-02 21:12:33,093 - train - INFO - alphas:tensor([0.5970, 0.4030], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,094 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,094 - train - INFO - True
2024-04-02 21:12:33,094 - train - INFO - alphas:tensor([0.5781, 0.4219], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,094 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,095 - train - INFO - True
2024-04-02 21:12:33,095 - train - INFO - alphas:tensor([0.5885, 0.4115], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,095 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,095 - train - INFO - True
2024-04-02 21:12:33,096 - train - INFO - alphas:tensor([0.5946, 0.4054], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,096 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,096 - train - INFO - True
2024-04-02 21:12:33,097 - train - INFO - alphas:tensor([0.6069, 0.3931], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,097 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,097 - train - INFO - True
2024-04-02 21:12:33,098 - train - INFO - alphas:tensor([0.5608, 0.4392], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,098 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,098 - train - INFO - True
2024-04-02 21:12:33,099 - train - INFO - alphas:tensor([0.5626, 0.4374], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,099 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,099 - train - INFO - True
2024-04-02 21:12:33,100 - train - INFO - alphas:tensor([0.5783, 0.4217], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,100 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,100 - train - INFO - True
2024-04-02 21:12:33,101 - train - INFO - alphas:tensor([0.5947, 0.4053], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,101 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,101 - train - INFO - True
2024-04-02 21:12:33,102 - train - INFO - alphas:tensor([0.5441, 0.4559], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,102 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,102 - train - INFO - True
2024-04-02 21:12:33,103 - train - INFO - alphas:tensor([0.5510, 0.4490], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,103 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,103 - train - INFO - True
2024-04-02 21:12:33,104 - train - INFO - alphas:tensor([0.5693, 0.4307], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,104 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,104 - train - INFO - True
2024-04-02 21:12:33,105 - train - INFO - alphas:tensor([0.5750, 0.4250], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,105 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,105 - train - INFO - True
2024-04-02 21:12:33,106 - train - INFO - alphas:tensor([0.5412, 0.4588], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,106 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,106 - train - INFO - True
2024-04-02 21:12:33,107 - train - INFO - alphas:tensor([0.5408, 0.4592], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,107 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,107 - train - INFO - True
2024-04-02 21:12:33,108 - train - INFO - alphas:tensor([0.5694, 0.4306], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,108 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,108 - train - INFO - True
2024-04-02 21:12:33,109 - train - INFO - alphas:tensor([0.5412, 0.4588], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,109 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,109 - train - INFO - True
2024-04-02 21:12:33,110 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,110 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,110 - train - INFO - avg block size:1.0
2024-04-02 21:12:33,110 - train - INFO - lasso_alpha:1.1000000000000001e-05
2024-04-02 21:12:33,573 - train - INFO - Test: [   0/39]  Time: 0.460 (0.460)  Loss:  0.5088 (0.5088)  Acc@1: 86.3281 (86.3281)  Acc@5: 99.6094 (99.6094)
2024-04-02 21:12:48,906 - train - INFO - Test: [  39/39]  Time: 0.388 (0.395)  Loss:  0.3831 (0.4729)  Acc@1: 93.7500 (88.9100)  Acc@5: 100.0000 (99.5500)
2024-04-02 21:12:50,160 - train - INFO - Train: 7 [   0/195 (  0%)]  Loss:  1.757668 (1.7577)  Time: 1.168s,  219.27/s  (1.168s,  219.27/s)  LR: 3.880e-04  Data: 0.130 (0.130)
2024-04-02 21:13:41,670 - train - INFO - Train: 7 [  50/195 ( 26%)]  Loss:  1.631794 (1.6218)  Time: 1.038s,  246.52/s  (1.033s,  247.85/s)  LR: 3.880e-04  Data: 0.005 (0.008)
2024-04-02 21:14:33,970 - train - INFO - Train: 7 [ 100/195 ( 52%)]  Loss:  1.822347 (1.6108)  Time: 1.029s,  248.70/s  (1.039s,  246.30/s)  LR: 3.880e-04  Data: 0.005 (0.007)
2024-04-02 21:15:36,114 - train - INFO - Train: 7 [ 150/195 ( 77%)]  Loss:  1.376630 (1.6024)  Time: 1.282s,  199.62/s  (1.107s,  231.31/s)  LR: 3.880e-04  Data: 0.005 (0.007)
2024-04-02 21:16:30,575 - train - INFO - Train: 7 [ 194/195 (100%)]  Loss:  1.597976 (1.5996)  Time: 1.294s,  197.81/s  (1.136s,  225.29/s)  LR: 3.880e-04  Data: 0.000 (0.007)
2024-04-02 21:16:30,576 - train - INFO - True
2024-04-02 21:16:30,577 - train - INFO - alphas:tensor([0.5431, 0.4569], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,577 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,577 - train - INFO - True
2024-04-02 21:16:30,578 - train - INFO - alphas:tensor([0.5399, 0.4601], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,578 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,578 - train - INFO - True
2024-04-02 21:16:30,579 - train - INFO - alphas:tensor([0.6144, 0.3856], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,579 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,579 - train - INFO - True
2024-04-02 21:16:30,580 - train - INFO - alphas:tensor([0.6200, 0.3800], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,580 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,580 - train - INFO - True
2024-04-02 21:16:30,583 - train - INFO - alphas:tensor([0.5824, 0.4176], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,584 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,584 - train - INFO - True
2024-04-02 21:16:30,584 - train - INFO - alphas:tensor([0.5922, 0.4078], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,584 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,584 - train - INFO - True
2024-04-02 21:16:30,585 - train - INFO - alphas:tensor([0.6132, 0.3868], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,585 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,585 - train - INFO - True
2024-04-02 21:16:30,586 - train - INFO - alphas:tensor([0.6089, 0.3911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,586 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,586 - train - INFO - True
2024-04-02 21:16:30,587 - train - INFO - alphas:tensor([0.5908, 0.4092], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,587 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,587 - train - INFO - True
2024-04-02 21:16:30,588 - train - INFO - alphas:tensor([0.6116, 0.3884], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,588 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,588 - train - INFO - True
2024-04-02 21:16:30,589 - train - INFO - alphas:tensor([0.6117, 0.3883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,589 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,589 - train - INFO - True
2024-04-02 21:16:30,590 - train - INFO - alphas:tensor([0.6183, 0.3817], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,590 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,590 - train - INFO - True
2024-04-02 21:16:30,591 - train - INFO - alphas:tensor([0.5891, 0.4109], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,591 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,591 - train - INFO - True
2024-04-02 21:16:30,591 - train - INFO - alphas:tensor([0.6044, 0.3956], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,592 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,592 - train - INFO - True
2024-04-02 21:16:30,593 - train - INFO - alphas:tensor([0.6138, 0.3862], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,593 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,593 - train - INFO - True
2024-04-02 21:16:30,594 - train - INFO - alphas:tensor([0.6274, 0.3726], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,594 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,594 - train - INFO - True
2024-04-02 21:16:30,595 - train - INFO - alphas:tensor([0.5715, 0.4285], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,595 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,595 - train - INFO - True
2024-04-02 21:16:30,596 - train - INFO - alphas:tensor([0.5757, 0.4243], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,596 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,596 - train - INFO - True
2024-04-02 21:16:30,596 - train - INFO - alphas:tensor([0.5948, 0.4052], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,597 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,597 - train - INFO - True
2024-04-02 21:16:30,598 - train - INFO - alphas:tensor([0.6130, 0.3870], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,598 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,598 - train - INFO - True
2024-04-02 21:16:30,599 - train - INFO - alphas:tensor([0.5520, 0.4480], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,599 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,600 - train - INFO - True
2024-04-02 21:16:30,600 - train - INFO - alphas:tensor([0.5613, 0.4387], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,600 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,600 - train - INFO - True
2024-04-02 21:16:30,601 - train - INFO - alphas:tensor([0.5860, 0.4140], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,601 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,601 - train - INFO - True
2024-04-02 21:16:30,602 - train - INFO - alphas:tensor([0.5933, 0.4067], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,602 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,602 - train - INFO - True
2024-04-02 21:16:30,603 - train - INFO - alphas:tensor([0.5505, 0.4495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,603 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,603 - train - INFO - True
2024-04-02 21:16:30,604 - train - INFO - alphas:tensor([0.5496, 0.4504], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,604 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,604 - train - INFO - True
2024-04-02 21:16:30,604 - train - INFO - alphas:tensor([0.5812, 0.4188], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,605 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,605 - train - INFO - True
2024-04-02 21:16:30,605 - train - INFO - alphas:tensor([0.5472, 0.4528], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,605 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,606 - train - INFO - True
2024-04-02 21:16:30,608 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,622 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,622 - train - INFO - avg block size:1.0
2024-04-02 21:16:31,307 - train - INFO - Test: [   0/39]  Time: 0.682 (0.682)  Loss:  0.4822 (0.4822)  Acc@1: 86.7188 (86.7188)  Acc@5: 99.2188 (99.2188)
2024-04-02 21:16:56,113 - train - INFO - Test: [  39/39]  Time: 0.653 (0.637)  Loss:  0.4639 (0.4523)  Acc@1: 87.5000 (89.3900)  Acc@5: 100.0000 (99.5800)
2024-04-02 21:16:57,580 - train - INFO - Train: 8 [   0/195 (  0%)]  Loss:  1.743913 (1.7439)  Time: 1.383s,  185.09/s  (1.383s,  185.09/s)  LR: 4.420e-04  Data: 0.144 (0.144)
2024-04-02 21:18:02,004 - train - INFO - Train: 8 [  50/195 ( 26%)]  Loss:  1.374280 (1.5842)  Time: 1.220s,  209.87/s  (1.290s,  198.40/s)  LR: 4.420e-04  Data: 0.008 (0.011)
2024-04-02 21:19:03,516 - train - INFO - Train: 8 [ 100/195 ( 52%)]  Loss:  1.240020 (1.6149)  Time: 1.325s,  193.25/s  (1.261s,  203.08/s)  LR: 4.420e-04  Data: 0.018 (0.009)
2024-04-02 21:20:09,382 - train - INFO - Train: 8 [ 150/195 ( 77%)]  Loss:  1.735475 (1.5895)  Time: 1.590s,  161.04/s  (1.279s,  200.10/s)  LR: 4.420e-04  Data: 0.005 (0.008)
2024-04-02 21:21:18,706 - train - INFO - Train: 8 [ 194/195 (100%)]  Loss:  1.825789 (1.5983)  Time: 1.538s,  166.41/s  (1.346s,  190.17/s)  LR: 4.420e-04  Data: 0.000 (0.009)
2024-04-02 21:21:18,706 - train - INFO - True
2024-04-02 21:21:18,709 - train - INFO - alphas:tensor([0.5371, 0.4629], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,709 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,709 - train - INFO - True
2024-04-02 21:21:18,711 - train - INFO - alphas:tensor([0.5379, 0.4621], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,711 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,712 - train - INFO - True
2024-04-02 21:21:18,713 - train - INFO - alphas:tensor([0.6269, 0.3731], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,714 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,714 - train - INFO - True
2024-04-02 21:21:18,719 - train - INFO - alphas:tensor([0.6323, 0.3677], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,720 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,720 - train - INFO - True
2024-04-02 21:21:18,721 - train - INFO - alphas:tensor([0.5847, 0.4153], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,721 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,721 - train - INFO - True
2024-04-02 21:21:18,722 - train - INFO - alphas:tensor([0.6012, 0.3988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,723 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,723 - train - INFO - True
2024-04-02 21:21:18,724 - train - INFO - alphas:tensor([0.6323, 0.3677], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,725 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,725 - train - INFO - True
2024-04-02 21:21:18,726 - train - INFO - alphas:tensor([0.6265, 0.3735], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,726 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,726 - train - INFO - True
2024-04-02 21:21:18,727 - train - INFO - alphas:tensor([0.5973, 0.4027], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,727 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,727 - train - INFO - True
2024-04-02 21:21:18,729 - train - INFO - alphas:tensor([0.6233, 0.3767], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,729 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,729 - train - INFO - True
2024-04-02 21:21:18,731 - train - INFO - alphas:tensor([0.6303, 0.3697], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,731 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,731 - train - INFO - True
2024-04-02 21:21:18,732 - train - INFO - alphas:tensor([0.6376, 0.3624], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,732 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,733 - train - INFO - True
2024-04-02 21:21:18,734 - train - INFO - alphas:tensor([0.5958, 0.4042], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,734 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,734 - train - INFO - True
2024-04-02 21:21:18,735 - train - INFO - alphas:tensor([0.6166, 0.3834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,735 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,735 - train - INFO - True
2024-04-02 21:21:18,736 - train - INFO - alphas:tensor([0.6323, 0.3677], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,737 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,737 - train - INFO - True
2024-04-02 21:21:18,738 - train - INFO - alphas:tensor([0.6466, 0.3534], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,739 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,739 - train - INFO - True
2024-04-02 21:21:18,741 - train - INFO - alphas:tensor([0.5800, 0.4200], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,741 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,741 - train - INFO - True
2024-04-02 21:21:18,743 - train - INFO - alphas:tensor([0.5872, 0.4128], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,743 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,743 - train - INFO - True
2024-04-02 21:21:18,745 - train - INFO - alphas:tensor([0.6107, 0.3893], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,745 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,745 - train - INFO - True
2024-04-02 21:21:18,746 - train - INFO - alphas:tensor([0.6298, 0.3702], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,746 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,746 - train - INFO - True
2024-04-02 21:21:18,747 - train - INFO - alphas:tensor([0.5603, 0.4397], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,747 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,747 - train - INFO - True
2024-04-02 21:21:18,748 - train - INFO - alphas:tensor([0.5711, 0.4289], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,748 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,749 - train - INFO - True
2024-04-02 21:21:18,749 - train - INFO - alphas:tensor([0.6018, 0.3982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,750 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,750 - train - INFO - True
2024-04-02 21:21:18,751 - train - INFO - alphas:tensor([0.6094, 0.3906], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,752 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,752 - train - INFO - True
2024-04-02 21:21:18,754 - train - INFO - alphas:tensor([0.5567, 0.4433], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,754 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,754 - train - INFO - True
2024-04-02 21:21:18,755 - train - INFO - alphas:tensor([0.5565, 0.4435], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,755 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,756 - train - INFO - True
2024-04-02 21:21:18,757 - train - INFO - alphas:tensor([0.5888, 0.4112], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,757 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,757 - train - INFO - True
2024-04-02 21:21:18,759 - train - INFO - alphas:tensor([0.5496, 0.4504], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,759 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,759 - train - INFO - True
2024-04-02 21:21:18,760 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,760 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,760 - train - INFO - avg block size:1.0
2024-04-02 21:21:18,761 - train - INFO - lasso_alpha:1.2100000000000003e-05
2024-04-02 21:21:19,664 - train - INFO - Test: [   0/39]  Time: 0.900 (0.900)  Loss:  0.4636 (0.4636)  Acc@1: 89.4531 (89.4531)  Acc@5: 100.0000 (100.0000)
2024-04-02 21:21:55,482 - train - INFO - Test: [  39/39]  Time: 0.926 (0.918)  Loss:  0.4312 (0.4433)  Acc@1: 81.2500 (90.3600)  Acc@5: 100.0000 (99.6300)
2024-04-02 21:21:57,288 - train - INFO - Train: 9 [   0/195 (  0%)]  Loss:  1.198707 (1.1987)  Time: 1.720s,  148.80/s  (1.720s,  148.80/s)  LR: 4.960e-04  Data: 0.192 (0.192)
2024-04-02 21:23:29,857 - train - INFO - Train: 9 [  50/195 ( 26%)]  Loss:  1.399732 (1.5651)  Time: 1.734s,  147.67/s  (1.849s,  138.47/s)  LR: 4.960e-04  Data: 0.016 (0.014)
2024-04-02 21:25:27,733 - train - INFO - Train: 9 [ 100/195 ( 52%)]  Loss:  1.397795 (1.5344)  Time: 2.584s,   99.08/s  (2.101s,  121.87/s)  LR: 4.960e-04  Data: 0.005 (0.013)
2024-04-02 21:27:46,229 - train - INFO - Train: 9 [ 150/195 ( 77%)]  Loss:  1.501621 (1.5594)  Time: 3.227s,   79.33/s  (2.322s,  110.24/s)  LR: 4.960e-04  Data: 0.010 (0.013)
