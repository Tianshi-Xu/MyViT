2024-04-02 20:35:23,421 - train - INFO - Training with a single process on 1 GPUs.
2024-04-02 20:35:26,656 - train - INFO - Model vit_7_4_32 created, param count:3716931
2024-04-02 20:35:26,673 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-04-02 20:35:26,673 - train - INFO - Scheduled epochs: 160
2024-04-02 20:35:27,893 - train - INFO - Verifying teacher model
2024-04-02 20:35:28,323 - train - INFO - Test: [   0/39]  Time: 0.429 (0.429)  Loss:  0.3433 (0.3433)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-02 20:35:28,692 - train - INFO - Test: [  39/39]  Time: 0.057 (0.020)  Loss:  0.3740 (0.3449)  Acc@1: 93.7500 (93.5400)  Acc@5: 100.0000 (99.7600)
2024-04-02 20:35:28,693 - train - INFO - Verifying initial model
2024-04-02 20:35:29,031 - train - INFO - Test: [   0/39]  Time: 0.338 (0.338)  Loss:  2.0332 (2.0332)  Acc@1: 27.7344 (27.7344)  Acc@5: 71.4844 (71.4844)
2024-04-02 20:35:38,875 - train - INFO - Test: [  39/39]  Time: 0.250 (0.255)  Loss:  1.8789 (2.0274)  Acc@1: 37.5000 (28.2900)  Acc@5: 81.2500 (73.7800)
2024-04-02 20:35:40,132 - train - INFO - Train: 0 [   0/195 (  0%)]  Loss:  2.307119 (2.3071)  Time: 1.254s,  204.22/s  (1.254s,  204.22/s)  LR: 1.000e-05  Data: 0.220 (0.220)
2024-04-02 20:36:23,237 - train - INFO - Train: 0 [  50/195 ( 26%)]  Loss:  2.243143 (2.2792)  Time: 0.875s,  292.46/s  (0.870s,  294.34/s)  LR: 1.000e-05  Data: 0.010 (0.014)
2024-04-02 20:37:06,301 - train - INFO - Train: 0 [ 100/195 ( 52%)]  Loss:  2.269072 (2.2641)  Time: 0.840s,  304.88/s  (0.866s,  295.77/s)  LR: 1.000e-05  Data: 0.009 (0.012)
2024-04-02 20:37:49,822 - train - INFO - Train: 0 [ 150/195 ( 77%)]  Loss:  2.250834 (2.2506)  Time: 0.875s,  292.55/s  (0.867s,  295.22/s)  LR: 1.000e-05  Data: 0.010 (0.011)
2024-04-02 20:38:27,379 - train - INFO - Train: 0 [ 194/195 (100%)]  Loss:  2.192079 (2.2422)  Time: 0.862s,  296.84/s  (0.864s,  296.27/s)  LR: 1.000e-05  Data: 0.000 (0.011)
2024-04-02 20:38:27,380 - train - INFO - True
2024-04-02 20:38:27,419 - train - INFO - alphas:tensor([0.5008, 0.4992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,419 - train - INFO - True
2024-04-02 20:38:27,420 - train - INFO - alphas:tensor([0.5008, 0.4992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,420 - train - INFO - True
2024-04-02 20:38:27,420 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,420 - train - INFO - True
2024-04-02 20:38:27,421 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,421 - train - INFO - True
2024-04-02 20:38:27,422 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,422 - train - INFO - True
2024-04-02 20:38:27,422 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,423 - train - INFO - True
2024-04-02 20:38:27,423 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,423 - train - INFO - True
2024-04-02 20:38:27,424 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,424 - train - INFO - True
2024-04-02 20:38:27,425 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,425 - train - INFO - True
2024-04-02 20:38:27,425 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,425 - train - INFO - True
2024-04-02 20:38:27,426 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,426 - train - INFO - True
2024-04-02 20:38:27,427 - train - INFO - alphas:tensor([0.5011, 0.4989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,427 - train - INFO - True
2024-04-02 20:38:27,427 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,427 - train - INFO - True
2024-04-02 20:38:27,428 - train - INFO - alphas:tensor([0.5011, 0.4989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,428 - train - INFO - True
2024-04-02 20:38:27,429 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,429 - train - INFO - True
2024-04-02 20:38:27,429 - train - INFO - alphas:tensor([0.5006, 0.4994], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,430 - train - INFO - True
2024-04-02 20:38:27,430 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,430 - train - INFO - True
2024-04-02 20:38:27,431 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,431 - train - INFO - True
2024-04-02 20:38:27,432 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,432 - train - INFO - True
2024-04-02 20:38:27,432 - train - INFO - alphas:tensor([0.4994, 0.5006], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,432 - train - INFO - True
2024-04-02 20:38:27,433 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,433 - train - INFO - True
2024-04-02 20:38:27,434 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,434 - train - INFO - True
2024-04-02 20:38:27,434 - train - INFO - alphas:tensor([0.5009, 0.4991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,435 - train - INFO - True
2024-04-02 20:38:27,435 - train - INFO - alphas:tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,435 - train - INFO - True
2024-04-02 20:38:27,436 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,436 - train - INFO - True
2024-04-02 20:38:27,437 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,437 - train - INFO - True
2024-04-02 20:38:27,437 - train - INFO - alphas:tensor([0.5005, 0.4995], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,437 - train - INFO - True
2024-04-02 20:38:27,438 - train - INFO - alphas:tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,438 - train - INFO - True
2024-04-02 20:38:27,439 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:38:27,439 - train - INFO - avg block size:1.5172413793103448
2024-04-02 20:38:27,783 - train - INFO - Test: [   0/39]  Time: 0.342 (0.342)  Loss:  1.8203 (1.8203)  Acc@1: 51.1719 (51.1719)  Acc@5: 89.8438 (89.8438)
2024-04-02 20:38:37,599 - train - INFO - Test: [  39/39]  Time: 0.250 (0.254)  Loss:  1.7236 (1.8016)  Acc@1: 56.2500 (48.1300)  Acc@5: 93.7500 (91.1600)
2024-04-02 20:38:38,645 - train - INFO - Train: 1 [   0/195 (  0%)]  Loss:  2.194058 (2.1941)  Time: 0.974s,  262.88/s  (0.974s,  262.88/s)  LR: 6.400e-05  Data: 0.137 (0.137)
2024-04-02 20:39:21,312 - train - INFO - Train: 1 [  50/195 ( 26%)]  Loss:  2.201029 (2.1635)  Time: 0.868s,  295.10/s  (0.856s,  299.18/s)  LR: 6.400e-05  Data: 0.011 (0.013)
2024-04-02 20:40:04,838 - train - INFO - Train: 1 [ 100/195 ( 52%)]  Loss:  2.188852 (2.1200)  Time: 0.847s,  302.25/s  (0.863s,  296.64/s)  LR: 6.400e-05  Data: 0.011 (0.011)
2024-04-02 20:40:53,463 - train - INFO - Train: 1 [ 150/195 ( 77%)]  Loss:  2.057493 (2.0833)  Time: 1.091s,  234.73/s  (0.899s,  284.68/s)  LR: 6.400e-05  Data: 0.010 (0.010)
2024-04-02 20:41:40,272 - train - INFO - Train: 1 [ 194/195 (100%)]  Loss:  1.811355 (2.0649)  Time: 1.058s,  241.88/s  (0.936s,  273.39/s)  LR: 6.400e-05  Data: 0.000 (0.009)
2024-04-02 20:41:40,273 - train - INFO - True
2024-04-02 20:41:40,274 - train - INFO - alphas:tensor([0.5075, 0.4925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,274 - train - INFO - True
2024-04-02 20:41:40,275 - train - INFO - alphas:tensor([0.5071, 0.4929], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,276 - train - INFO - True
2024-04-02 20:41:40,276 - train - INFO - alphas:tensor([0.5089, 0.4911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,276 - train - INFO - True
2024-04-02 20:41:40,277 - train - INFO - alphas:tensor([0.5101, 0.4899], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,277 - train - INFO - True
2024-04-02 20:41:40,278 - train - INFO - alphas:tensor([0.5091, 0.4909], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,278 - train - INFO - True
2024-04-02 20:41:40,279 - train - INFO - alphas:tensor([0.5086, 0.4914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,279 - train - INFO - True
2024-04-02 20:41:40,279 - train - INFO - alphas:tensor([0.5080, 0.4920], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,280 - train - INFO - True
2024-04-02 20:41:40,280 - train - INFO - alphas:tensor([0.5081, 0.4919], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,280 - train - INFO - True
2024-04-02 20:41:40,281 - train - INFO - alphas:tensor([0.5084, 0.4916], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,281 - train - INFO - True
2024-04-02 20:41:40,282 - train - INFO - alphas:tensor([0.5077, 0.4923], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,282 - train - INFO - True
2024-04-02 20:41:40,283 - train - INFO - alphas:tensor([0.5075, 0.4925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,283 - train - INFO - True
2024-04-02 20:41:40,283 - train - INFO - alphas:tensor([0.5081, 0.4919], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,283 - train - INFO - True
2024-04-02 20:41:40,284 - train - INFO - alphas:tensor([0.5076, 0.4924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,284 - train - INFO - True
2024-04-02 20:41:40,285 - train - INFO - alphas:tensor([0.5070, 0.4930], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,285 - train - INFO - True
2024-04-02 20:41:40,286 - train - INFO - alphas:tensor([0.5078, 0.4922], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,286 - train - INFO - True
2024-04-02 20:41:40,286 - train - INFO - alphas:tensor([0.5084, 0.4916], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,287 - train - INFO - True
2024-04-02 20:41:40,287 - train - INFO - alphas:tensor([0.5076, 0.4924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,287 - train - INFO - True
2024-04-02 20:41:40,288 - train - INFO - alphas:tensor([0.5065, 0.4935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,288 - train - INFO - True
2024-04-02 20:41:40,289 - train - INFO - alphas:tensor([0.5058, 0.4942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,289 - train - INFO - True
2024-04-02 20:41:40,290 - train - INFO - alphas:tensor([0.5043, 0.4957], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,290 - train - INFO - True
2024-04-02 20:41:40,290 - train - INFO - alphas:tensor([0.5065, 0.4935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,290 - train - INFO - True
2024-04-02 20:41:40,291 - train - INFO - alphas:tensor([0.5058, 0.4942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,291 - train - INFO - True
2024-04-02 20:41:40,292 - train - INFO - alphas:tensor([0.5049, 0.4951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,292 - train - INFO - True
2024-04-02 20:41:40,293 - train - INFO - alphas:tensor([0.5065, 0.4935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,293 - train - INFO - True
2024-04-02 20:41:40,294 - train - INFO - alphas:tensor([0.5064, 0.4936], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,294 - train - INFO - True
2024-04-02 20:41:40,295 - train - INFO - alphas:tensor([0.5052, 0.4948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,295 - train - INFO - True
2024-04-02 20:41:40,296 - train - INFO - alphas:tensor([0.5050, 0.4950], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,296 - train - INFO - True
2024-04-02 20:41:40,297 - train - INFO - alphas:tensor([0.5057, 0.4943], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,297 - train - INFO - True
2024-04-02 20:41:40,298 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:41:40,298 - train - INFO - avg block size:1.0
2024-04-02 20:41:40,782 - train - INFO - Test: [   0/39]  Time: 0.480 (0.480)  Loss:  1.1689 (1.1689)  Acc@1: 66.0156 (66.0156)  Acc@5: 98.0469 (98.0469)
2024-04-02 20:42:02,283 - train - INFO - Test: [  39/39]  Time: 0.642 (0.550)  Loss:  1.1289 (1.1307)  Acc@1: 62.5000 (67.4300)  Acc@5: 100.0000 (97.3900)
2024-04-02 20:42:03,539 - train - INFO - Train: 2 [   0/195 (  0%)]  Loss:  2.025479 (2.0255)  Time: 1.181s,  216.69/s  (1.181s,  216.69/s)  LR: 1.180e-04  Data: 0.124 (0.124)
2024-04-02 20:42:52,375 - train - INFO - Train: 2 [  50/195 ( 26%)]  Loss:  2.143815 (1.9549)  Time: 1.067s,  240.00/s  (0.981s,  261.03/s)  LR: 1.180e-04  Data: 0.005 (0.009)
2024-04-02 20:43:49,186 - train - INFO - Train: 2 [ 100/195 ( 52%)]  Loss:  2.069757 (1.9302)  Time: 1.270s,  201.62/s  (1.058s,  242.04/s)  LR: 1.180e-04  Data: 0.005 (0.008)
2024-04-02 20:45:05,604 - train - INFO - Train: 2 [ 150/195 ( 77%)]  Loss:  1.777966 (1.9159)  Time: 1.618s,  158.23/s  (1.214s,  210.95/s)  LR: 1.180e-04  Data: 0.005 (0.008)
2024-04-02 20:46:15,925 - train - INFO - Train: 2 [ 194/195 (100%)]  Loss:  1.987849 (1.9019)  Time: 1.537s,  166.59/s  (1.300s,  196.88/s)  LR: 1.180e-04  Data: 0.000 (0.007)
2024-04-02 20:46:15,926 - train - INFO - True
2024-04-02 20:46:15,927 - train - INFO - alphas:tensor([0.5196, 0.4804], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,927 - train - INFO - True
2024-04-02 20:46:15,928 - train - INFO - alphas:tensor([0.5172, 0.4828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,929 - train - INFO - True
2024-04-02 20:46:15,930 - train - INFO - alphas:tensor([0.5236, 0.4764], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,930 - train - INFO - True
2024-04-02 20:46:15,931 - train - INFO - alphas:tensor([0.5251, 0.4749], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,931 - train - INFO - True
2024-04-02 20:46:15,932 - train - INFO - alphas:tensor([0.5218, 0.4782], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,932 - train - INFO - True
2024-04-02 20:46:15,933 - train - INFO - alphas:tensor([0.5204, 0.4796], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,933 - train - INFO - True
2024-04-02 20:46:15,934 - train - INFO - alphas:tensor([0.5201, 0.4799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,934 - train - INFO - True
2024-04-02 20:46:15,935 - train - INFO - alphas:tensor([0.5202, 0.4798], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,935 - train - INFO - True
2024-04-02 20:46:15,936 - train - INFO - alphas:tensor([0.5231, 0.4769], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,936 - train - INFO - True
2024-04-02 20:46:15,937 - train - INFO - alphas:tensor([0.5219, 0.4781], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,937 - train - INFO - True
2024-04-02 20:46:15,938 - train - INFO - alphas:tensor([0.5182, 0.4818], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,938 - train - INFO - True
2024-04-02 20:46:15,939 - train - INFO - alphas:tensor([0.5196, 0.4804], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,940 - train - INFO - True
2024-04-02 20:46:15,941 - train - INFO - alphas:tensor([0.5177, 0.4823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,941 - train - INFO - True
2024-04-02 20:46:15,942 - train - INFO - alphas:tensor([0.5164, 0.4836], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,943 - train - INFO - True
2024-04-02 20:46:15,944 - train - INFO - alphas:tensor([0.5190, 0.4810], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,945 - train - INFO - True
2024-04-02 20:46:15,946 - train - INFO - alphas:tensor([0.5220, 0.4780], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,946 - train - INFO - True
2024-04-02 20:46:15,948 - train - INFO - alphas:tensor([0.5151, 0.4849], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,949 - train - INFO - True
2024-04-02 20:46:15,950 - train - INFO - alphas:tensor([0.5138, 0.4862], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,950 - train - INFO - True
2024-04-02 20:46:15,951 - train - INFO - alphas:tensor([0.5139, 0.4861], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,951 - train - INFO - True
2024-04-02 20:46:15,952 - train - INFO - alphas:tensor([0.5155, 0.4845], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,954 - train - INFO - True
2024-04-02 20:46:15,955 - train - INFO - alphas:tensor([0.5124, 0.4876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,955 - train - INFO - True
2024-04-02 20:46:15,957 - train - INFO - alphas:tensor([0.5126, 0.4874], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,957 - train - INFO - True
2024-04-02 20:46:15,958 - train - INFO - alphas:tensor([0.5118, 0.4882], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,958 - train - INFO - True
2024-04-02 20:46:15,959 - train - INFO - alphas:tensor([0.5133, 0.4867], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,959 - train - INFO - True
2024-04-02 20:46:15,970 - train - INFO - alphas:tensor([0.5109, 0.4891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,970 - train - INFO - True
2024-04-02 20:46:15,971 - train - INFO - alphas:tensor([0.5095, 0.4905], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,971 - train - INFO - True
2024-04-02 20:46:15,972 - train - INFO - alphas:tensor([0.5116, 0.4884], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,972 - train - INFO - True
2024-04-02 20:46:15,973 - train - INFO - alphas:tensor([0.5085, 0.4915], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,973 - train - INFO - True
2024-04-02 20:46:15,974 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:46:15,976 - train - INFO - avg block size:1.0
2024-04-02 20:46:16,926 - train - INFO - Test: [   0/39]  Time: 0.945 (0.945)  Loss:  0.9048 (0.9048)  Acc@1: 76.5625 (76.5625)  Acc@5: 98.4375 (98.4375)
2024-04-02 20:46:51,631 - train - INFO - Test: [  39/39]  Time: 0.875 (0.891)  Loss:  0.9932 (0.8627)  Acc@1: 68.7500 (76.2300)  Acc@5: 100.0000 (98.4500)
2024-04-02 20:46:53,637 - train - INFO - Train: 3 [   0/195 (  0%)]  Loss:  1.805281 (1.8053)  Time: 1.898s,  134.87/s  (1.898s,  134.87/s)  LR: 1.720e-04  Data: 0.226 (0.226)
2024-04-02 20:48:13,636 - train - INFO - Train: 3 [  50/195 ( 26%)]  Loss:  1.902879 (1.8514)  Time: 1.488s,  171.99/s  (1.606s,  159.42/s)  LR: 1.720e-04  Data: 0.006 (0.012)
2024-04-02 20:49:34,130 - train - INFO - Train: 3 [ 100/195 ( 52%)]  Loss:  1.819241 (1.8213)  Time: 1.492s,  171.56/s  (1.608s,  159.22/s)  LR: 1.720e-04  Data: 0.006 (0.010)
2024-04-02 20:51:02,952 - train - INFO - Train: 3 [ 150/195 ( 77%)]  Loss:  1.953846 (1.8178)  Time: 1.799s,  142.34/s  (1.664s,  153.88/s)  LR: 1.720e-04  Data: 0.007 (0.010)
2024-04-02 20:52:26,014 - train - INFO - Train: 3 [ 194/195 (100%)]  Loss:  1.638349 (1.8136)  Time: 2.050s,  124.90/s  (1.714s,  149.34/s)  LR: 1.720e-04  Data: 0.000 (0.010)
2024-04-02 20:52:26,020 - train - INFO - True
2024-04-02 20:52:26,021 - train - INFO - alphas:tensor([0.5323, 0.4677], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,021 - train - INFO - tau:0.99
2024-04-02 20:52:26,021 - train - INFO - True
2024-04-02 20:52:26,022 - train - INFO - alphas:tensor([0.5263, 0.4737], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,022 - train - INFO - tau:0.99
2024-04-02 20:52:26,022 - train - INFO - True
2024-04-02 20:52:26,023 - train - INFO - alphas:tensor([0.5414, 0.4586], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,023 - train - INFO - tau:0.99
2024-04-02 20:52:26,024 - train - INFO - True
2024-04-02 20:52:26,024 - train - INFO - alphas:tensor([0.5433, 0.4567], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,024 - train - INFO - tau:0.99
2024-04-02 20:52:26,025 - train - INFO - True
2024-04-02 20:52:26,032 - train - INFO - alphas:tensor([0.5366, 0.4634], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,032 - train - INFO - tau:0.99
2024-04-02 20:52:26,032 - train - INFO - True
2024-04-02 20:52:26,033 - train - INFO - alphas:tensor([0.5350, 0.4650], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,034 - train - INFO - tau:0.99
2024-04-02 20:52:26,034 - train - INFO - True
2024-04-02 20:52:26,035 - train - INFO - alphas:tensor([0.5342, 0.4658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,035 - train - INFO - tau:0.99
2024-04-02 20:52:26,035 - train - INFO - True
2024-04-02 20:52:26,036 - train - INFO - alphas:tensor([0.5341, 0.4659], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,036 - train - INFO - tau:0.99
2024-04-02 20:52:26,037 - train - INFO - True
2024-04-02 20:52:26,037 - train - INFO - alphas:tensor([0.5415, 0.4585], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,038 - train - INFO - tau:0.99
2024-04-02 20:52:26,038 - train - INFO - True
2024-04-02 20:52:26,039 - train - INFO - alphas:tensor([0.5421, 0.4579], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,039 - train - INFO - tau:0.99
2024-04-02 20:52:26,039 - train - INFO - True
2024-04-02 20:52:26,040 - train - INFO - alphas:tensor([0.5320, 0.4680], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,040 - train - INFO - tau:0.99
2024-04-02 20:52:26,041 - train - INFO - True
2024-04-02 20:52:26,041 - train - INFO - alphas:tensor([0.5342, 0.4658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,042 - train - INFO - tau:0.99
2024-04-02 20:52:26,042 - train - INFO - True
2024-04-02 20:52:26,043 - train - INFO - alphas:tensor([0.5321, 0.4679], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,043 - train - INFO - tau:0.99
2024-04-02 20:52:26,043 - train - INFO - True
2024-04-02 20:52:26,044 - train - INFO - alphas:tensor([0.5315, 0.4685], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,044 - train - INFO - tau:0.99
2024-04-02 20:52:26,044 - train - INFO - True
2024-04-02 20:52:26,045 - train - INFO - alphas:tensor([0.5333, 0.4667], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,045 - train - INFO - tau:0.99
2024-04-02 20:52:26,046 - train - INFO - True
2024-04-02 20:52:26,047 - train - INFO - alphas:tensor([0.5384, 0.4616], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,047 - train - INFO - tau:0.99
2024-04-02 20:52:26,047 - train - INFO - True
2024-04-02 20:52:26,048 - train - INFO - alphas:tensor([0.5242, 0.4758], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,049 - train - INFO - tau:0.99
2024-04-02 20:52:26,049 - train - INFO - True
2024-04-02 20:52:26,050 - train - INFO - alphas:tensor([0.5229, 0.4771], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,050 - train - INFO - tau:0.99
2024-04-02 20:52:26,050 - train - INFO - True
2024-04-02 20:52:26,051 - train - INFO - alphas:tensor([0.5260, 0.4740], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,051 - train - INFO - tau:0.99
2024-04-02 20:52:26,052 - train - INFO - True
2024-04-02 20:52:26,052 - train - INFO - alphas:tensor([0.5318, 0.4682], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,053 - train - INFO - tau:0.99
2024-04-02 20:52:26,053 - train - INFO - True
2024-04-02 20:52:26,054 - train - INFO - alphas:tensor([0.5179, 0.4821], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,054 - train - INFO - tau:0.99
2024-04-02 20:52:26,054 - train - INFO - True
2024-04-02 20:52:26,055 - train - INFO - alphas:tensor([0.5198, 0.4802], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,055 - train - INFO - tau:0.99
2024-04-02 20:52:26,056 - train - INFO - True
2024-04-02 20:52:26,056 - train - INFO - alphas:tensor([0.5217, 0.4783], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,057 - train - INFO - tau:0.99
2024-04-02 20:52:26,057 - train - INFO - True
2024-04-02 20:52:26,058 - train - INFO - alphas:tensor([0.5229, 0.4771], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,058 - train - INFO - tau:0.99
2024-04-02 20:52:26,058 - train - INFO - True
2024-04-02 20:52:26,059 - train - INFO - alphas:tensor([0.5163, 0.4837], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,060 - train - INFO - tau:0.99
2024-04-02 20:52:26,060 - train - INFO - True
2024-04-02 20:52:26,061 - train - INFO - alphas:tensor([0.5151, 0.4849], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,061 - train - INFO - tau:0.99
2024-04-02 20:52:26,061 - train - INFO - True
2024-04-02 20:52:26,062 - train - INFO - alphas:tensor([0.5230, 0.4770], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,062 - train - INFO - tau:0.99
2024-04-02 20:52:26,062 - train - INFO - True
2024-04-02 20:52:26,063 - train - INFO - alphas:tensor([0.5140, 0.4860], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,064 - train - INFO - tau:0.99
2024-04-02 20:52:26,064 - train - INFO - True
2024-04-02 20:52:26,065 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:52:26,065 - train - INFO - tau:0.99
2024-04-02 20:52:26,065 - train - INFO - avg block size:1.0
2024-04-02 20:52:27,189 - train - INFO - Test: [   0/39]  Time: 1.121 (1.121)  Loss:  0.7344 (0.7344)  Acc@1: 82.4219 (82.4219)  Acc@5: 98.4375 (98.4375)
2024-04-02 20:53:10,198 - train - INFO - Test: [  39/39]  Time: 1.103 (1.103)  Loss:  0.8428 (0.7001)  Acc@1: 68.7500 (81.4200)  Acc@5: 100.0000 (98.8600)
2024-04-02 20:53:12,775 - train - INFO - Train: 4 [   0/195 (  0%)]  Loss:  1.431711 (1.4317)  Time: 2.493s,  102.70/s  (2.493s,  102.70/s)  LR: 2.260e-04  Data: 0.214 (0.214)
2024-04-02 20:54:51,871 - train - INFO - Train: 4 [  50/195 ( 26%)]  Loss:  1.748157 (1.7377)  Time: 2.260s,  113.27/s  (1.992s,  128.52/s)  LR: 2.260e-04  Data: 0.010 (0.013)
2024-04-02 20:56:38,947 - train - INFO - Train: 4 [ 100/195 ( 52%)]  Loss:  1.778219 (1.7107)  Time: 2.385s,  107.34/s  (2.066s,  123.92/s)  LR: 2.260e-04  Data: 0.014 (0.011)
2024-04-02 20:58:18,023 - train - INFO - Train: 4 [ 150/195 ( 77%)]  Loss:  1.660895 (1.7186)  Time: 2.077s,  123.27/s  (2.038s,  125.62/s)  LR: 2.260e-04  Data: 0.006 (0.011)
2024-04-02 20:59:46,029 - train - INFO - Train: 4 [ 194/195 (100%)]  Loss:  1.433296 (1.7073)  Time: 1.816s,  140.94/s  (2.029s,  126.14/s)  LR: 2.260e-04  Data: 0.000 (0.011)
2024-04-02 20:59:46,030 - train - INFO - True
2024-04-02 20:59:46,032 - train - INFO - alphas:tensor([0.5434, 0.4566], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,032 - train - INFO - tau:0.9801
2024-04-02 20:59:46,033 - train - INFO - True
2024-04-02 20:59:46,035 - train - INFO - alphas:tensor([0.5345, 0.4655], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,035 - train - INFO - tau:0.9801
2024-04-02 20:59:46,035 - train - INFO - True
2024-04-02 20:59:46,036 - train - INFO - alphas:tensor([0.5627, 0.4373], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,036 - train - INFO - tau:0.9801
2024-04-02 20:59:46,037 - train - INFO - True
2024-04-02 20:59:46,038 - train - INFO - alphas:tensor([0.5657, 0.4343], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,038 - train - INFO - tau:0.9801
2024-04-02 20:59:46,038 - train - INFO - True
2024-04-02 20:59:46,039 - train - INFO - alphas:tensor([0.5526, 0.4474], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,039 - train - INFO - tau:0.9801
2024-04-02 20:59:46,039 - train - INFO - True
2024-04-02 20:59:46,040 - train - INFO - alphas:tensor([0.5519, 0.4481], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,041 - train - INFO - tau:0.9801
2024-04-02 20:59:46,041 - train - INFO - True
2024-04-02 20:59:46,042 - train - INFO - alphas:tensor([0.5518, 0.4482], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,042 - train - INFO - tau:0.9801
2024-04-02 20:59:46,042 - train - INFO - True
2024-04-02 20:59:46,043 - train - INFO - alphas:tensor([0.5509, 0.4491], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,043 - train - INFO - tau:0.9801
2024-04-02 20:59:46,043 - train - INFO - True
2024-04-02 20:59:46,044 - train - INFO - alphas:tensor([0.5591, 0.4409], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,044 - train - INFO - tau:0.9801
2024-04-02 20:59:46,044 - train - INFO - True
2024-04-02 20:59:46,046 - train - INFO - alphas:tensor([0.5629, 0.4371], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,046 - train - INFO - tau:0.9801
2024-04-02 20:59:46,046 - train - INFO - True
2024-04-02 20:59:46,056 - train - INFO - alphas:tensor([0.5505, 0.4495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,093 - train - INFO - tau:0.9801
2024-04-02 20:59:46,093 - train - INFO - True
2024-04-02 20:59:46,094 - train - INFO - alphas:tensor([0.5535, 0.4465], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,094 - train - INFO - tau:0.9801
2024-04-02 20:59:46,094 - train - INFO - True
2024-04-02 20:59:46,095 - train - INFO - alphas:tensor([0.5490, 0.4510], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,099 - train - INFO - tau:0.9801
2024-04-02 20:59:46,100 - train - INFO - True
2024-04-02 20:59:46,101 - train - INFO - alphas:tensor([0.5510, 0.4490], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,101 - train - INFO - tau:0.9801
2024-04-02 20:59:46,110 - train - INFO - True
2024-04-02 20:59:46,111 - train - INFO - alphas:tensor([0.5527, 0.4473], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,111 - train - INFO - tau:0.9801
2024-04-02 20:59:46,111 - train - INFO - True
2024-04-02 20:59:46,112 - train - INFO - alphas:tensor([0.5600, 0.4400], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,113 - train - INFO - tau:0.9801
2024-04-02 20:59:46,113 - train - INFO - True
2024-04-02 20:59:46,114 - train - INFO - alphas:tensor([0.5358, 0.4642], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,114 - train - INFO - tau:0.9801
2024-04-02 20:59:46,114 - train - INFO - True
2024-04-02 20:59:46,115 - train - INFO - alphas:tensor([0.5351, 0.4649], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,120 - train - INFO - tau:0.9801
2024-04-02 20:59:46,120 - train - INFO - True
2024-04-02 20:59:46,121 - train - INFO - alphas:tensor([0.5421, 0.4579], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,121 - train - INFO - tau:0.9801
2024-04-02 20:59:46,130 - train - INFO - True
2024-04-02 20:59:46,131 - train - INFO - alphas:tensor([0.5522, 0.4478], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,131 - train - INFO - tau:0.9801
2024-04-02 20:59:46,132 - train - INFO - True
2024-04-02 20:59:46,132 - train - INFO - alphas:tensor([0.5259, 0.4741], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,133 - train - INFO - tau:0.9801
2024-04-02 20:59:46,133 - train - INFO - True
2024-04-02 20:59:46,134 - train - INFO - alphas:tensor([0.5296, 0.4704], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,135 - train - INFO - tau:0.9801
2024-04-02 20:59:46,136 - train - INFO - True
2024-04-02 20:59:46,136 - train - INFO - alphas:tensor([0.5357, 0.4643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,137 - train - INFO - tau:0.9801
2024-04-02 20:59:46,137 - train - INFO - True
2024-04-02 20:59:46,138 - train - INFO - alphas:tensor([0.5371, 0.4629], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,145 - train - INFO - tau:0.9801
2024-04-02 20:59:46,150 - train - INFO - True
2024-04-02 20:59:46,151 - train - INFO - alphas:tensor([0.5232, 0.4768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,151 - train - INFO - tau:0.9801
2024-04-02 20:59:46,151 - train - INFO - True
2024-04-02 20:59:46,152 - train - INFO - alphas:tensor([0.5227, 0.4773], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,152 - train - INFO - tau:0.9801
2024-04-02 20:59:46,152 - train - INFO - True
2024-04-02 20:59:46,153 - train - INFO - alphas:tensor([0.5389, 0.4611], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,153 - train - INFO - tau:0.9801
2024-04-02 20:59:46,153 - train - INFO - True
2024-04-02 20:59:46,154 - train - INFO - alphas:tensor([0.5230, 0.4770], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,154 - train - INFO - tau:0.9801
2024-04-02 20:59:46,155 - train - INFO - True
2024-04-02 20:59:46,155 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 20:59:46,156 - train - INFO - tau:0.9801
2024-04-02 20:59:46,156 - train - INFO - avg block size:1.0
2024-04-02 20:59:47,365 - train - INFO - Test: [   0/39]  Time: 1.205 (1.205)  Loss:  0.6475 (0.6475)  Acc@1: 82.8125 (82.8125)  Acc@5: 98.8281 (98.8281)
2024-04-02 21:00:29,707 - train - INFO - Test: [  39/39]  Time: 1.034 (1.089)  Loss:  0.6758 (0.5846)  Acc@1: 81.2500 (85.8500)  Acc@5: 100.0000 (99.1900)
2024-04-02 21:00:31,912 - train - INFO - Train: 5 [   0/195 (  0%)]  Loss:  1.902684 (1.9027)  Time: 2.092s,  122.36/s  (2.092s,  122.36/s)  LR: 2.800e-04  Data: 0.225 (0.225)
2024-04-02 21:02:10,068 - train - INFO - Train: 5 [  50/195 ( 26%)]  Loss:  1.375885 (1.7294)  Time: 1.941s,  131.87/s  (1.966s,  130.24/s)  LR: 2.800e-04  Data: 0.005 (0.014)
2024-04-02 21:03:49,572 - train - INFO - Train: 5 [ 100/195 ( 52%)]  Loss:  1.544680 (1.6743)  Time: 2.226s,  114.99/s  (1.978s,  129.44/s)  LR: 2.800e-04  Data: 0.020 (0.012)
2024-04-02 21:05:28,002 - train - INFO - Train: 5 [ 150/195 ( 77%)]  Loss:  1.554915 (1.6526)  Time: 1.872s,  136.76/s  (1.975s,  129.64/s)  LR: 2.800e-04  Data: 0.017 (0.011)
2024-04-02 21:06:52,900 - train - INFO - Train: 5 [ 194/195 (100%)]  Loss:  1.806862 (1.6462)  Time: 1.749s,  146.36/s  (1.964s,  130.32/s)  LR: 2.800e-04  Data: 0.000 (0.010)
2024-04-02 21:06:52,905 - train - INFO - True
2024-04-02 21:06:52,907 - train - INFO - alphas:tensor([0.5473, 0.4527], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,911 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,912 - train - INFO - True
2024-04-02 21:06:52,912 - train - INFO - alphas:tensor([0.5389, 0.4611], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,913 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,913 - train - INFO - True
2024-04-02 21:06:52,914 - train - INFO - alphas:tensor([0.5829, 0.4171], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,914 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,914 - train - INFO - True
2024-04-02 21:06:52,920 - train - INFO - alphas:tensor([0.5876, 0.4124], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,920 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,920 - train - INFO - True
2024-04-02 21:06:52,921 - train - INFO - alphas:tensor([0.5689, 0.4311], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,921 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,922 - train - INFO - True
2024-04-02 21:06:52,922 - train - INFO - alphas:tensor([0.5692, 0.4308], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,923 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,923 - train - INFO - True
2024-04-02 21:06:52,924 - train - INFO - alphas:tensor([0.5723, 0.4277], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,928 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,929 - train - INFO - True
2024-04-02 21:06:52,930 - train - INFO - alphas:tensor([0.5703, 0.4297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,934 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,935 - train - INFO - True
2024-04-02 21:06:52,935 - train - INFO - alphas:tensor([0.5738, 0.4262], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,936 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,936 - train - INFO - True
2024-04-02 21:06:52,937 - train - INFO - alphas:tensor([0.5821, 0.4179], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,937 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,937 - train - INFO - True
2024-04-02 21:06:52,938 - train - INFO - alphas:tensor([0.5710, 0.4290], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,938 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,939 - train - INFO - True
2024-04-02 21:06:52,940 - train - INFO - alphas:tensor([0.5754, 0.4246], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,940 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,940 - train - INFO - True
2024-04-02 21:06:52,941 - train - INFO - alphas:tensor([0.5645, 0.4355], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,950 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,950 - train - INFO - True
2024-04-02 21:06:52,951 - train - INFO - alphas:tensor([0.5702, 0.4298], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,951 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,952 - train - INFO - True
2024-04-02 21:06:52,953 - train - INFO - alphas:tensor([0.5738, 0.4262], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,953 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,953 - train - INFO - True
2024-04-02 21:06:52,954 - train - INFO - alphas:tensor([0.5839, 0.4161], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,954 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,954 - train - INFO - True
2024-04-02 21:06:52,955 - train - INFO - alphas:tensor([0.5486, 0.4514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,956 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,956 - train - INFO - True
2024-04-02 21:06:52,957 - train - INFO - alphas:tensor([0.5486, 0.4514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,966 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,966 - train - INFO - True
2024-04-02 21:06:52,967 - train - INFO - alphas:tensor([0.5597, 0.4403], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,967 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,967 - train - INFO - True
2024-04-02 21:06:52,968 - train - INFO - alphas:tensor([0.5733, 0.4267], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,969 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,969 - train - INFO - True
2024-04-02 21:06:52,970 - train - INFO - alphas:tensor([0.5350, 0.4650], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,970 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,970 - train - INFO - True
2024-04-02 21:06:52,971 - train - INFO - alphas:tensor([0.5401, 0.4599], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,971 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,971 - train - INFO - True
2024-04-02 21:06:52,972 - train - INFO - alphas:tensor([0.5519, 0.4481], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,972 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,972 - train - INFO - True
2024-04-02 21:06:52,973 - train - INFO - alphas:tensor([0.5547, 0.4453], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,974 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,974 - train - INFO - True
2024-04-02 21:06:52,975 - train - INFO - alphas:tensor([0.5311, 0.4689], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,975 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,975 - train - INFO - True
2024-04-02 21:06:52,976 - train - INFO - alphas:tensor([0.5313, 0.4687], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,977 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,977 - train - INFO - True
2024-04-02 21:06:52,978 - train - INFO - alphas:tensor([0.5546, 0.4454], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,978 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,978 - train - INFO - True
2024-04-02 21:06:52,984 - train - INFO - alphas:tensor([0.5324, 0.4676], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,984 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,984 - train - INFO - True
2024-04-02 21:06:52,985 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:06:52,985 - train - INFO - tau:0.9702989999999999
2024-04-02 21:06:52,985 - train - INFO - avg block size:1.0
2024-04-02 21:06:54,136 - train - INFO - Test: [   0/39]  Time: 1.147 (1.147)  Loss:  0.5698 (0.5698)  Acc@1: 85.9375 (85.9375)  Acc@5: 100.0000 (100.0000)
2024-04-02 21:07:36,410 - train - INFO - Test: [  39/39]  Time: 1.129 (1.086)  Loss:  0.5259 (0.5291)  Acc@1: 81.2500 (88.2900)  Acc@5: 100.0000 (99.5400)
2024-04-02 21:07:38,684 - train - INFO - Train: 6 [   0/195 (  0%)]  Loss:  1.708569 (1.7086)  Time: 2.136s,  119.84/s  (2.136s,  119.84/s)  LR: 3.340e-04  Data: 0.200 (0.200)
2024-04-02 21:09:16,897 - train - INFO - Train: 6 [  50/195 ( 26%)]  Loss:  1.767722 (1.6013)  Time: 2.256s,  113.46/s  (1.968s,  130.11/s)  LR: 3.340e-04  Data: 0.005 (0.012)
2024-04-02 21:10:44,828 - train - INFO - Train: 6 [ 100/195 ( 52%)]  Loss:  1.398860 (1.5932)  Time: 1.241s,  206.28/s  (1.864s,  137.33/s)  LR: 3.340e-04  Data: 0.005 (0.010)
2024-04-02 21:11:47,572 - train - INFO - Train: 6 [ 150/195 ( 77%)]  Loss:  1.477973 (1.5853)  Time: 1.242s,  206.09/s  (1.662s,  154.00/s)  LR: 3.340e-04  Data: 0.007 (0.009)
2024-04-02 21:12:33,082 - train - INFO - Train: 6 [ 194/195 (100%)]  Loss:  1.268204 (1.5870)  Time: 1.035s,  247.29/s  (1.521s,  168.35/s)  LR: 3.340e-04  Data: 0.000 (0.008)
2024-04-02 21:12:33,082 - train - INFO - True
2024-04-02 21:12:33,083 - train - INFO - alphas:tensor([0.5452, 0.4548], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,084 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,084 - train - INFO - True
2024-04-02 21:12:33,084 - train - INFO - alphas:tensor([0.5392, 0.4608], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,084 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,085 - train - INFO - True
2024-04-02 21:12:33,085 - train - INFO - alphas:tensor([0.6000, 0.4000], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,085 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,085 - train - INFO - True
2024-04-02 21:12:33,086 - train - INFO - alphas:tensor([0.6056, 0.3944], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,086 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,086 - train - INFO - True
2024-04-02 21:12:33,087 - train - INFO - alphas:tensor([0.5777, 0.4223], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,087 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,087 - train - INFO - True
2024-04-02 21:12:33,088 - train - INFO - alphas:tensor([0.5818, 0.4182], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,088 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,089 - train - INFO - True
2024-04-02 21:12:33,089 - train - INFO - alphas:tensor([0.5930, 0.4070], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,089 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,089 - train - INFO - True
2024-04-02 21:12:33,090 - train - INFO - alphas:tensor([0.5898, 0.4102], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,090 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,090 - train - INFO - True
2024-04-02 21:12:33,091 - train - INFO - alphas:tensor([0.5841, 0.4159], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,091 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,091 - train - INFO - True
2024-04-02 21:12:33,092 - train - INFO - alphas:tensor([0.5986, 0.4014], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,092 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,092 - train - INFO - True
2024-04-02 21:12:33,093 - train - INFO - alphas:tensor([0.5917, 0.4083], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,093 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,093 - train - INFO - True
2024-04-02 21:12:33,093 - train - INFO - alphas:tensor([0.5970, 0.4030], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,094 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,094 - train - INFO - True
2024-04-02 21:12:33,094 - train - INFO - alphas:tensor([0.5781, 0.4219], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,094 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,095 - train - INFO - True
2024-04-02 21:12:33,095 - train - INFO - alphas:tensor([0.5885, 0.4115], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,095 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,095 - train - INFO - True
2024-04-02 21:12:33,096 - train - INFO - alphas:tensor([0.5946, 0.4054], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,096 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,096 - train - INFO - True
2024-04-02 21:12:33,097 - train - INFO - alphas:tensor([0.6069, 0.3931], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,097 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,097 - train - INFO - True
2024-04-02 21:12:33,098 - train - INFO - alphas:tensor([0.5608, 0.4392], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,098 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,098 - train - INFO - True
2024-04-02 21:12:33,099 - train - INFO - alphas:tensor([0.5626, 0.4374], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,099 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,099 - train - INFO - True
2024-04-02 21:12:33,100 - train - INFO - alphas:tensor([0.5783, 0.4217], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,100 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,100 - train - INFO - True
2024-04-02 21:12:33,101 - train - INFO - alphas:tensor([0.5947, 0.4053], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,101 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,101 - train - INFO - True
2024-04-02 21:12:33,102 - train - INFO - alphas:tensor([0.5441, 0.4559], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,102 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,102 - train - INFO - True
2024-04-02 21:12:33,103 - train - INFO - alphas:tensor([0.5510, 0.4490], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,103 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,103 - train - INFO - True
2024-04-02 21:12:33,104 - train - INFO - alphas:tensor([0.5693, 0.4307], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,104 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,104 - train - INFO - True
2024-04-02 21:12:33,105 - train - INFO - alphas:tensor([0.5750, 0.4250], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,105 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,105 - train - INFO - True
2024-04-02 21:12:33,106 - train - INFO - alphas:tensor([0.5412, 0.4588], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,106 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,106 - train - INFO - True
2024-04-02 21:12:33,107 - train - INFO - alphas:tensor([0.5408, 0.4592], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,107 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,107 - train - INFO - True
2024-04-02 21:12:33,108 - train - INFO - alphas:tensor([0.5694, 0.4306], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,108 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,108 - train - INFO - True
2024-04-02 21:12:33,109 - train - INFO - alphas:tensor([0.5412, 0.4588], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,109 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,109 - train - INFO - True
2024-04-02 21:12:33,110 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:12:33,110 - train - INFO - tau:0.96059601
2024-04-02 21:12:33,110 - train - INFO - avg block size:1.0
2024-04-02 21:12:33,110 - train - INFO - lasso_alpha:1.1000000000000001e-05
2024-04-02 21:12:33,573 - train - INFO - Test: [   0/39]  Time: 0.460 (0.460)  Loss:  0.5088 (0.5088)  Acc@1: 86.3281 (86.3281)  Acc@5: 99.6094 (99.6094)
2024-04-02 21:12:48,906 - train - INFO - Test: [  39/39]  Time: 0.388 (0.395)  Loss:  0.3831 (0.4729)  Acc@1: 93.7500 (88.9100)  Acc@5: 100.0000 (99.5500)
2024-04-02 21:12:50,160 - train - INFO - Train: 7 [   0/195 (  0%)]  Loss:  1.757668 (1.7577)  Time: 1.168s,  219.27/s  (1.168s,  219.27/s)  LR: 3.880e-04  Data: 0.130 (0.130)
2024-04-02 21:13:41,670 - train - INFO - Train: 7 [  50/195 ( 26%)]  Loss:  1.631794 (1.6218)  Time: 1.038s,  246.52/s  (1.033s,  247.85/s)  LR: 3.880e-04  Data: 0.005 (0.008)
2024-04-02 21:14:33,970 - train - INFO - Train: 7 [ 100/195 ( 52%)]  Loss:  1.822347 (1.6108)  Time: 1.029s,  248.70/s  (1.039s,  246.30/s)  LR: 3.880e-04  Data: 0.005 (0.007)
2024-04-02 21:15:36,114 - train - INFO - Train: 7 [ 150/195 ( 77%)]  Loss:  1.376630 (1.6024)  Time: 1.282s,  199.62/s  (1.107s,  231.31/s)  LR: 3.880e-04  Data: 0.005 (0.007)
2024-04-02 21:16:30,575 - train - INFO - Train: 7 [ 194/195 (100%)]  Loss:  1.597976 (1.5996)  Time: 1.294s,  197.81/s  (1.136s,  225.29/s)  LR: 3.880e-04  Data: 0.000 (0.007)
2024-04-02 21:16:30,576 - train - INFO - True
2024-04-02 21:16:30,577 - train - INFO - alphas:tensor([0.5431, 0.4569], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,577 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,577 - train - INFO - True
2024-04-02 21:16:30,578 - train - INFO - alphas:tensor([0.5399, 0.4601], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,578 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,578 - train - INFO - True
2024-04-02 21:16:30,579 - train - INFO - alphas:tensor([0.6144, 0.3856], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,579 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,579 - train - INFO - True
2024-04-02 21:16:30,580 - train - INFO - alphas:tensor([0.6200, 0.3800], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,580 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,580 - train - INFO - True
2024-04-02 21:16:30,583 - train - INFO - alphas:tensor([0.5824, 0.4176], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,584 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,584 - train - INFO - True
2024-04-02 21:16:30,584 - train - INFO - alphas:tensor([0.5922, 0.4078], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,584 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,584 - train - INFO - True
2024-04-02 21:16:30,585 - train - INFO - alphas:tensor([0.6132, 0.3868], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,585 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,585 - train - INFO - True
2024-04-02 21:16:30,586 - train - INFO - alphas:tensor([0.6089, 0.3911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,586 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,586 - train - INFO - True
2024-04-02 21:16:30,587 - train - INFO - alphas:tensor([0.5908, 0.4092], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,587 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,587 - train - INFO - True
2024-04-02 21:16:30,588 - train - INFO - alphas:tensor([0.6116, 0.3884], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,588 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,588 - train - INFO - True
2024-04-02 21:16:30,589 - train - INFO - alphas:tensor([0.6117, 0.3883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,589 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,589 - train - INFO - True
2024-04-02 21:16:30,590 - train - INFO - alphas:tensor([0.6183, 0.3817], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,590 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,590 - train - INFO - True
2024-04-02 21:16:30,591 - train - INFO - alphas:tensor([0.5891, 0.4109], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,591 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,591 - train - INFO - True
2024-04-02 21:16:30,591 - train - INFO - alphas:tensor([0.6044, 0.3956], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,592 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,592 - train - INFO - True
2024-04-02 21:16:30,593 - train - INFO - alphas:tensor([0.6138, 0.3862], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,593 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,593 - train - INFO - True
2024-04-02 21:16:30,594 - train - INFO - alphas:tensor([0.6274, 0.3726], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,594 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,594 - train - INFO - True
2024-04-02 21:16:30,595 - train - INFO - alphas:tensor([0.5715, 0.4285], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,595 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,595 - train - INFO - True
2024-04-02 21:16:30,596 - train - INFO - alphas:tensor([0.5757, 0.4243], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,596 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,596 - train - INFO - True
2024-04-02 21:16:30,596 - train - INFO - alphas:tensor([0.5948, 0.4052], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,597 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,597 - train - INFO - True
2024-04-02 21:16:30,598 - train - INFO - alphas:tensor([0.6130, 0.3870], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,598 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,598 - train - INFO - True
2024-04-02 21:16:30,599 - train - INFO - alphas:tensor([0.5520, 0.4480], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,599 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,600 - train - INFO - True
2024-04-02 21:16:30,600 - train - INFO - alphas:tensor([0.5613, 0.4387], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,600 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,600 - train - INFO - True
2024-04-02 21:16:30,601 - train - INFO - alphas:tensor([0.5860, 0.4140], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,601 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,601 - train - INFO - True
2024-04-02 21:16:30,602 - train - INFO - alphas:tensor([0.5933, 0.4067], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,602 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,602 - train - INFO - True
2024-04-02 21:16:30,603 - train - INFO - alphas:tensor([0.5505, 0.4495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,603 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,603 - train - INFO - True
2024-04-02 21:16:30,604 - train - INFO - alphas:tensor([0.5496, 0.4504], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,604 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,604 - train - INFO - True
2024-04-02 21:16:30,604 - train - INFO - alphas:tensor([0.5812, 0.4188], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,605 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,605 - train - INFO - True
2024-04-02 21:16:30,605 - train - INFO - alphas:tensor([0.5472, 0.4528], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,605 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,606 - train - INFO - True
2024-04-02 21:16:30,608 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:16:30,622 - train - INFO - tau:0.9509900498999999
2024-04-02 21:16:30,622 - train - INFO - avg block size:1.0
2024-04-02 21:16:31,307 - train - INFO - Test: [   0/39]  Time: 0.682 (0.682)  Loss:  0.4822 (0.4822)  Acc@1: 86.7188 (86.7188)  Acc@5: 99.2188 (99.2188)
2024-04-02 21:16:56,113 - train - INFO - Test: [  39/39]  Time: 0.653 (0.637)  Loss:  0.4639 (0.4523)  Acc@1: 87.5000 (89.3900)  Acc@5: 100.0000 (99.5800)
2024-04-02 21:16:57,580 - train - INFO - Train: 8 [   0/195 (  0%)]  Loss:  1.743913 (1.7439)  Time: 1.383s,  185.09/s  (1.383s,  185.09/s)  LR: 4.420e-04  Data: 0.144 (0.144)
2024-04-02 21:18:02,004 - train - INFO - Train: 8 [  50/195 ( 26%)]  Loss:  1.374280 (1.5842)  Time: 1.220s,  209.87/s  (1.290s,  198.40/s)  LR: 4.420e-04  Data: 0.008 (0.011)
2024-04-02 21:19:03,516 - train - INFO - Train: 8 [ 100/195 ( 52%)]  Loss:  1.240020 (1.6149)  Time: 1.325s,  193.25/s  (1.261s,  203.08/s)  LR: 4.420e-04  Data: 0.018 (0.009)
2024-04-02 21:20:09,382 - train - INFO - Train: 8 [ 150/195 ( 77%)]  Loss:  1.735475 (1.5895)  Time: 1.590s,  161.04/s  (1.279s,  200.10/s)  LR: 4.420e-04  Data: 0.005 (0.008)
2024-04-02 21:21:18,706 - train - INFO - Train: 8 [ 194/195 (100%)]  Loss:  1.825789 (1.5983)  Time: 1.538s,  166.41/s  (1.346s,  190.17/s)  LR: 4.420e-04  Data: 0.000 (0.009)
2024-04-02 21:21:18,706 - train - INFO - True
2024-04-02 21:21:18,709 - train - INFO - alphas:tensor([0.5371, 0.4629], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,709 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,709 - train - INFO - True
2024-04-02 21:21:18,711 - train - INFO - alphas:tensor([0.5379, 0.4621], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,711 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,712 - train - INFO - True
2024-04-02 21:21:18,713 - train - INFO - alphas:tensor([0.6269, 0.3731], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,714 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,714 - train - INFO - True
2024-04-02 21:21:18,719 - train - INFO - alphas:tensor([0.6323, 0.3677], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,720 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,720 - train - INFO - True
2024-04-02 21:21:18,721 - train - INFO - alphas:tensor([0.5847, 0.4153], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,721 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,721 - train - INFO - True
2024-04-02 21:21:18,722 - train - INFO - alphas:tensor([0.6012, 0.3988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,723 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,723 - train - INFO - True
2024-04-02 21:21:18,724 - train - INFO - alphas:tensor([0.6323, 0.3677], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,725 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,725 - train - INFO - True
2024-04-02 21:21:18,726 - train - INFO - alphas:tensor([0.6265, 0.3735], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,726 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,726 - train - INFO - True
2024-04-02 21:21:18,727 - train - INFO - alphas:tensor([0.5973, 0.4027], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,727 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,727 - train - INFO - True
2024-04-02 21:21:18,729 - train - INFO - alphas:tensor([0.6233, 0.3767], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,729 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,729 - train - INFO - True
2024-04-02 21:21:18,731 - train - INFO - alphas:tensor([0.6303, 0.3697], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,731 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,731 - train - INFO - True
2024-04-02 21:21:18,732 - train - INFO - alphas:tensor([0.6376, 0.3624], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,732 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,733 - train - INFO - True
2024-04-02 21:21:18,734 - train - INFO - alphas:tensor([0.5958, 0.4042], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,734 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,734 - train - INFO - True
2024-04-02 21:21:18,735 - train - INFO - alphas:tensor([0.6166, 0.3834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,735 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,735 - train - INFO - True
2024-04-02 21:21:18,736 - train - INFO - alphas:tensor([0.6323, 0.3677], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,737 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,737 - train - INFO - True
2024-04-02 21:21:18,738 - train - INFO - alphas:tensor([0.6466, 0.3534], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,739 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,739 - train - INFO - True
2024-04-02 21:21:18,741 - train - INFO - alphas:tensor([0.5800, 0.4200], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,741 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,741 - train - INFO - True
2024-04-02 21:21:18,743 - train - INFO - alphas:tensor([0.5872, 0.4128], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,743 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,743 - train - INFO - True
2024-04-02 21:21:18,745 - train - INFO - alphas:tensor([0.6107, 0.3893], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,745 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,745 - train - INFO - True
2024-04-02 21:21:18,746 - train - INFO - alphas:tensor([0.6298, 0.3702], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,746 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,746 - train - INFO - True
2024-04-02 21:21:18,747 - train - INFO - alphas:tensor([0.5603, 0.4397], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,747 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,747 - train - INFO - True
2024-04-02 21:21:18,748 - train - INFO - alphas:tensor([0.5711, 0.4289], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,748 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,749 - train - INFO - True
2024-04-02 21:21:18,749 - train - INFO - alphas:tensor([0.6018, 0.3982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,750 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,750 - train - INFO - True
2024-04-02 21:21:18,751 - train - INFO - alphas:tensor([0.6094, 0.3906], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,752 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,752 - train - INFO - True
2024-04-02 21:21:18,754 - train - INFO - alphas:tensor([0.5567, 0.4433], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,754 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,754 - train - INFO - True
2024-04-02 21:21:18,755 - train - INFO - alphas:tensor([0.5565, 0.4435], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,755 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,756 - train - INFO - True
2024-04-02 21:21:18,757 - train - INFO - alphas:tensor([0.5888, 0.4112], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,757 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,757 - train - INFO - True
2024-04-02 21:21:18,759 - train - INFO - alphas:tensor([0.5496, 0.4504], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,759 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,759 - train - INFO - True
2024-04-02 21:21:18,760 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:21:18,760 - train - INFO - tau:0.9414801494009999
2024-04-02 21:21:18,760 - train - INFO - avg block size:1.0
2024-04-02 21:21:18,761 - train - INFO - lasso_alpha:1.2100000000000003e-05
2024-04-02 21:21:19,664 - train - INFO - Test: [   0/39]  Time: 0.900 (0.900)  Loss:  0.4636 (0.4636)  Acc@1: 89.4531 (89.4531)  Acc@5: 100.0000 (100.0000)
2024-04-02 21:21:55,482 - train - INFO - Test: [  39/39]  Time: 0.926 (0.918)  Loss:  0.4312 (0.4433)  Acc@1: 81.2500 (90.3600)  Acc@5: 100.0000 (99.6300)
2024-04-02 21:21:57,288 - train - INFO - Train: 9 [   0/195 (  0%)]  Loss:  1.198707 (1.1987)  Time: 1.720s,  148.80/s  (1.720s,  148.80/s)  LR: 4.960e-04  Data: 0.192 (0.192)
2024-04-02 21:23:29,857 - train - INFO - Train: 9 [  50/195 ( 26%)]  Loss:  1.399732 (1.5651)  Time: 1.734s,  147.67/s  (1.849s,  138.47/s)  LR: 4.960e-04  Data: 0.016 (0.014)
2024-04-02 21:25:27,733 - train - INFO - Train: 9 [ 100/195 ( 52%)]  Loss:  1.397795 (1.5344)  Time: 2.584s,   99.08/s  (2.101s,  121.87/s)  LR: 4.960e-04  Data: 0.005 (0.013)
2024-04-02 21:27:46,229 - train - INFO - Train: 9 [ 150/195 ( 77%)]  Loss:  1.501621 (1.5594)  Time: 3.227s,   79.33/s  (2.322s,  110.24/s)  LR: 4.960e-04  Data: 0.010 (0.013)
2024-04-02 21:29:50,544 - train - INFO - Train: 9 [ 194/195 (100%)]  Loss:  1.346987 (1.5785)  Time: 2.663s,   96.14/s  (2.436s,  105.10/s)  LR: 4.960e-04  Data: 0.000 (0.014)
2024-04-02 21:29:50,545 - train - INFO - True
2024-04-02 21:29:50,547 - train - INFO - alphas:tensor([0.5289, 0.4711], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,547 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,547 - train - INFO - True
2024-04-02 21:29:50,548 - train - INFO - alphas:tensor([0.5344, 0.4656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,548 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,549 - train - INFO - True
2024-04-02 21:29:50,550 - train - INFO - alphas:tensor([0.6366, 0.3634], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,550 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,550 - train - INFO - True
2024-04-02 21:29:50,551 - train - INFO - alphas:tensor([0.6421, 0.3579], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,552 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,552 - train - INFO - True
2024-04-02 21:29:50,567 - train - INFO - alphas:tensor([0.5843, 0.4157], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,568 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,568 - train - INFO - True
2024-04-02 21:29:50,582 - train - INFO - alphas:tensor([0.6066, 0.3934], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,582 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,583 - train - INFO - True
2024-04-02 21:29:50,586 - train - INFO - alphas:tensor([0.6499, 0.3501], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,586 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,586 - train - INFO - True
2024-04-02 21:29:50,592 - train - INFO - alphas:tensor([0.6429, 0.3571], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,593 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,593 - train - INFO - True
2024-04-02 21:29:50,594 - train - INFO - alphas:tensor([0.6000, 0.4000], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,594 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,594 - train - INFO - True
2024-04-02 21:29:50,595 - train - INFO - alphas:tensor([0.6322, 0.3678], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,595 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,596 - train - INFO - True
2024-04-02 21:29:50,597 - train - INFO - alphas:tensor([0.6463, 0.3537], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,597 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,597 - train - INFO - True
2024-04-02 21:29:50,599 - train - INFO - alphas:tensor([0.6536, 0.3464], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,599 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,599 - train - INFO - True
2024-04-02 21:29:50,601 - train - INFO - alphas:tensor([0.6002, 0.3998], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,601 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,601 - train - INFO - True
2024-04-02 21:29:50,603 - train - INFO - alphas:tensor([0.6262, 0.3738], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,603 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,603 - train - INFO - True
2024-04-02 21:29:50,605 - train - INFO - alphas:tensor([0.6481, 0.3519], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,606 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,606 - train - INFO - True
2024-04-02 21:29:50,612 - train - INFO - alphas:tensor([0.6621, 0.3379], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,612 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,613 - train - INFO - True
2024-04-02 21:29:50,614 - train - INFO - alphas:tensor([0.5859, 0.4141], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,614 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,615 - train - INFO - True
2024-04-02 21:29:50,616 - train - INFO - alphas:tensor([0.5966, 0.4034], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,617 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,617 - train - INFO - True
2024-04-02 21:29:50,619 - train - INFO - alphas:tensor([0.6246, 0.3754], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,619 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,619 - train - INFO - True
2024-04-02 21:29:50,621 - train - INFO - alphas:tensor([0.6427, 0.3573], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,621 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,621 - train - INFO - True
2024-04-02 21:29:50,623 - train - INFO - alphas:tensor([0.5660, 0.4340], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,623 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,623 - train - INFO - True
2024-04-02 21:29:50,624 - train - INFO - alphas:tensor([0.5793, 0.4207], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,624 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,625 - train - INFO - True
2024-04-02 21:29:50,631 - train - INFO - alphas:tensor([0.6157, 0.3843], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,631 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,631 - train - INFO - True
2024-04-02 21:29:50,633 - train - INFO - alphas:tensor([0.6205, 0.3795], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,633 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,633 - train - INFO - True
2024-04-02 21:29:50,635 - train - INFO - alphas:tensor([0.5593, 0.4407], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,635 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,635 - train - INFO - True
2024-04-02 21:29:50,637 - train - INFO - alphas:tensor([0.5616, 0.4384], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,637 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,637 - train - INFO - True
2024-04-02 21:29:50,639 - train - INFO - alphas:tensor([0.5943, 0.4057], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,639 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,639 - train - INFO - True
2024-04-02 21:29:50,641 - train - INFO - alphas:tensor([0.5498, 0.4502], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,641 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,641 - train - INFO - True
2024-04-02 21:29:50,643 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:29:50,643 - train - INFO - tau:0.9320653479069899
2024-04-02 21:29:50,643 - train - INFO - avg block size:1.0
2024-04-02 21:29:52,285 - train - INFO - Test: [   0/39]  Time: 1.638 (1.638)  Loss:  0.4436 (0.4436)  Acc@1: 90.2344 (90.2344)  Acc@5: 99.2188 (99.2188)
2024-04-02 21:30:55,480 - train - INFO - Test: [  39/39]  Time: 1.641 (1.621)  Loss:  0.3677 (0.4287)  Acc@1: 87.5000 (90.2400)  Acc@5: 100.0000 (99.7000)
2024-04-02 21:30:58,667 - train - INFO - Train: 10 [   0/195 (  0%)]  Loss:  1.426113 (1.4261)  Time: 2.992s,   85.56/s  (2.992s,   85.56/s)  LR: 5.441e-04  Data: 0.404 (0.404)
2024-04-02 21:33:16,486 - train - INFO - Train: 10 [  50/195 ( 26%)]  Loss:  1.300385 (1.5841)  Time: 2.509s,  102.04/s  (2.761s,   92.72/s)  LR: 5.441e-04  Data: 0.005 (0.022)
2024-04-02 21:35:34,250 - train - INFO - Train: 10 [ 100/195 ( 52%)]  Loss:  1.517599 (1.5797)  Time: 2.613s,   97.96/s  (2.758s,   92.82/s)  LR: 5.441e-04  Data: 0.018 (0.017)
2024-04-02 21:37:53,041 - train - INFO - Train: 10 [ 150/195 ( 77%)]  Loss:  1.755305 (1.5877)  Time: 2.894s,   88.47/s  (2.764s,   92.62/s)  LR: 5.441e-04  Data: 0.014 (0.017)
2024-04-02 21:39:54,950 - train - INFO - Train: 10 [ 194/195 (100%)]  Loss:  1.469695 (1.5882)  Time: 2.658s,   96.30/s  (2.765s,   92.57/s)  LR: 5.441e-04  Data: 0.000 (0.017)
2024-04-02 21:39:54,955 - train - INFO - True
2024-04-02 21:39:54,956 - train - INFO - alphas:tensor([0.5218, 0.4782], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,957 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,957 - train - INFO - True
2024-04-02 21:39:54,958 - train - INFO - alphas:tensor([0.5320, 0.4680], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,958 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,959 - train - INFO - True
2024-04-02 21:39:54,959 - train - INFO - alphas:tensor([0.6457, 0.3543], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,960 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,960 - train - INFO - True
2024-04-02 21:39:54,961 - train - INFO - alphas:tensor([0.6511, 0.3489], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,961 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,961 - train - INFO - True
2024-04-02 21:39:54,963 - train - INFO - alphas:tensor([0.5813, 0.4187], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,963 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,963 - train - INFO - True
2024-04-02 21:39:54,965 - train - INFO - alphas:tensor([0.6119, 0.3881], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,965 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,965 - train - INFO - True
2024-04-02 21:39:54,967 - train - INFO - alphas:tensor([0.6658, 0.3342], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,968 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,968 - train - INFO - True
2024-04-02 21:39:54,970 - train - INFO - alphas:tensor([0.6581, 0.3419], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,970 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,970 - train - INFO - True
2024-04-02 21:39:54,972 - train - INFO - alphas:tensor([0.6011, 0.3989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,972 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,973 - train - INFO - True
2024-04-02 21:39:54,974 - train - INFO - alphas:tensor([0.6404, 0.3596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,975 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,979 - train - INFO - True
2024-04-02 21:39:54,980 - train - INFO - alphas:tensor([0.6614, 0.3386], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,980 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,981 - train - INFO - True
2024-04-02 21:39:54,981 - train - INFO - alphas:tensor([0.6692, 0.3308], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,982 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,982 - train - INFO - True
2024-04-02 21:39:54,983 - train - INFO - alphas:tensor([0.6034, 0.3966], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,983 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,983 - train - INFO - True
2024-04-02 21:39:54,984 - train - INFO - alphas:tensor([0.6336, 0.3664], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,985 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,985 - train - INFO - True
2024-04-02 21:39:54,986 - train - INFO - alphas:tensor([0.6622, 0.3378], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,986 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,986 - train - INFO - True
2024-04-02 21:39:54,987 - train - INFO - alphas:tensor([0.6745, 0.3255], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,987 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,988 - train - INFO - True
2024-04-02 21:39:54,989 - train - INFO - alphas:tensor([0.5898, 0.4102], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,990 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,990 - train - INFO - True
2024-04-02 21:39:54,992 - train - INFO - alphas:tensor([0.6033, 0.3967], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,992 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,992 - train - INFO - True
2024-04-02 21:39:54,993 - train - INFO - alphas:tensor([0.6378, 0.3622], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,993 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,993 - train - INFO - True
2024-04-02 21:39:54,994 - train - INFO - alphas:tensor([0.6532, 0.3468], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,995 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,995 - train - INFO - True
2024-04-02 21:39:54,996 - train - INFO - alphas:tensor([0.5703, 0.4297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,996 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,996 - train - INFO - True
2024-04-02 21:39:54,997 - train - INFO - alphas:tensor([0.5855, 0.4145], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:54,997 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:54,998 - train - INFO - True
2024-04-02 21:39:54,999 - train - INFO - alphas:tensor([0.6261, 0.3739], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:55,000 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:55,000 - train - INFO - True
2024-04-02 21:39:55,001 - train - INFO - alphas:tensor([0.6240, 0.3760], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:55,001 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:55,001 - train - INFO - True
2024-04-02 21:39:55,003 - train - INFO - alphas:tensor([0.5578, 0.4422], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:55,003 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:55,003 - train - INFO - True
2024-04-02 21:39:55,005 - train - INFO - alphas:tensor([0.5631, 0.4369], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:55,005 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:55,005 - train - INFO - True
2024-04-02 21:39:55,007 - train - INFO - alphas:tensor([0.5952, 0.4048], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:55,007 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:55,007 - train - INFO - True
2024-04-02 21:39:55,009 - train - INFO - alphas:tensor([0.5459, 0.4541], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:55,009 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:55,009 - train - INFO - True
2024-04-02 21:39:55,011 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:39:55,011 - train - INFO - tau:0.92274469442792
2024-04-02 21:39:55,011 - train - INFO - avg block size:1.0
2024-04-02 21:39:55,011 - train - INFO - lasso_alpha:1.3310000000000005e-05
2024-04-02 21:39:56,706 - train - INFO - Test: [   0/39]  Time: 1.691 (1.691)  Loss:  0.4397 (0.4397)  Acc@1: 91.4062 (91.4062)  Acc@5: 100.0000 (100.0000)
2024-04-02 21:41:01,421 - train - INFO - Test: [  39/39]  Time: 1.627 (1.660)  Loss:  0.3806 (0.4301)  Acc@1: 87.5000 (90.9400)  Acc@5: 100.0000 (99.6300)
2024-04-02 21:41:04,523 - train - INFO - Train: 11 [   0/195 (  0%)]  Loss:  1.333089 (1.3331)  Time: 2.951s,   86.74/s  (2.951s,   86.74/s)  LR: 5.429e-04  Data: 0.458 (0.458)
2024-04-02 21:43:25,291 - train - INFO - Train: 11 [  50/195 ( 26%)]  Loss:  1.520467 (1.6025)  Time: 2.973s,   86.11/s  (2.818s,   90.84/s)  LR: 5.429e-04  Data: 0.005 (0.021)
2024-04-02 21:45:44,612 - train - INFO - Train: 11 [ 100/195 ( 52%)]  Loss:  1.491228 (1.5725)  Time: 2.529s,  101.21/s  (2.802s,   91.35/s)  LR: 5.429e-04  Data: 0.006 (0.017)
2024-04-02 21:48:03,722 - train - INFO - Train: 11 [ 150/195 ( 77%)]  Loss:  1.833512 (1.5723)  Time: 2.692s,   95.08/s  (2.796s,   91.57/s)  LR: 5.429e-04  Data: 0.014 (0.016)
2024-04-02 21:50:04,616 - train - INFO - Train: 11 [ 194/195 (100%)]  Loss:  1.282152 (1.5810)  Time: 2.760s,   92.75/s  (2.785s,   91.93/s)  LR: 5.429e-04  Data: 0.000 (0.015)
2024-04-02 21:50:04,617 - train - INFO - True
2024-04-02 21:50:04,619 - train - INFO - alphas:tensor([0.5110, 0.4890], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,620 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,620 - train - INFO - True
2024-04-02 21:50:04,621 - train - INFO - alphas:tensor([0.5270, 0.4730], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,622 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,622 - train - INFO - True
2024-04-02 21:50:04,623 - train - INFO - alphas:tensor([0.6528, 0.3472], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,624 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,624 - train - INFO - True
2024-04-02 21:50:04,625 - train - INFO - alphas:tensor([0.6582, 0.3418], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,625 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,625 - train - INFO - True
2024-04-02 21:50:04,626 - train - INFO - alphas:tensor([0.5769, 0.4231], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,627 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,627 - train - INFO - True
2024-04-02 21:50:04,628 - train - INFO - alphas:tensor([0.6150, 0.3850], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,628 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,628 - train - INFO - True
2024-04-02 21:50:04,629 - train - INFO - alphas:tensor([0.6777, 0.3223], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,629 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,630 - train - INFO - True
2024-04-02 21:50:04,631 - train - INFO - alphas:tensor([0.6684, 0.3316], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,631 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,631 - train - INFO - True
2024-04-02 21:50:04,632 - train - INFO - alphas:tensor([0.5992, 0.4008], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,632 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,633 - train - INFO - True
2024-04-02 21:50:04,634 - train - INFO - alphas:tensor([0.6450, 0.3550], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,634 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,635 - train - INFO - True
2024-04-02 21:50:04,636 - train - INFO - alphas:tensor([0.6736, 0.3264], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,636 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,637 - train - INFO - True
2024-04-02 21:50:04,638 - train - INFO - alphas:tensor([0.6807, 0.3193], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,638 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,638 - train - INFO - True
2024-04-02 21:50:04,640 - train - INFO - alphas:tensor([0.6016, 0.3984], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,640 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,640 - train - INFO - True
2024-04-02 21:50:04,642 - train - INFO - alphas:tensor([0.6367, 0.3633], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,642 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,642 - train - INFO - True
2024-04-02 21:50:04,644 - train - INFO - alphas:tensor([0.6730, 0.3270], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,645 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,645 - train - INFO - True
2024-04-02 21:50:04,647 - train - INFO - alphas:tensor([0.6835, 0.3165], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,647 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,647 - train - INFO - True
2024-04-02 21:50:04,649 - train - INFO - alphas:tensor([0.5915, 0.4085], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,649 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,649 - train - INFO - True
2024-04-02 21:50:04,651 - train - INFO - alphas:tensor([0.6082, 0.3918], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,651 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,651 - train - INFO - True
2024-04-02 21:50:04,653 - train - INFO - alphas:tensor([0.6471, 0.3529], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,654 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,654 - train - INFO - True
2024-04-02 21:50:04,655 - train - INFO - alphas:tensor([0.6571, 0.3429], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,656 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,656 - train - INFO - True
2024-04-02 21:50:04,657 - train - INFO - alphas:tensor([0.5718, 0.4282], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,657 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,657 - train - INFO - True
2024-04-02 21:50:04,658 - train - INFO - alphas:tensor([0.5906, 0.4094], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,658 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,659 - train - INFO - True
2024-04-02 21:50:04,660 - train - INFO - alphas:tensor([0.6346, 0.3654], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,660 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,660 - train - INFO - True
2024-04-02 21:50:04,661 - train - INFO - alphas:tensor([0.6270, 0.3730], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,661 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,662 - train - INFO - True
2024-04-02 21:50:04,662 - train - INFO - alphas:tensor([0.5567, 0.4433], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,663 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,663 - train - INFO - True
2024-04-02 21:50:04,664 - train - INFO - alphas:tensor([0.5655, 0.4345], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,664 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,664 - train - INFO - True
2024-04-02 21:50:04,666 - train - INFO - alphas:tensor([0.5933, 0.4067], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,666 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,666 - train - INFO - True
2024-04-02 21:50:04,668 - train - INFO - alphas:tensor([0.5399, 0.4601], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,668 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,668 - train - INFO - True
2024-04-02 21:50:04,670 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 21:50:04,670 - train - INFO - tau:0.9135172474836407
2024-04-02 21:50:04,671 - train - INFO - avg block size:1.0
2024-04-02 21:50:06,415 - train - INFO - Test: [   0/39]  Time: 1.742 (1.742)  Loss:  0.4355 (0.4355)  Acc@1: 89.4531 (89.4531)  Acc@5: 99.6094 (99.6094)
2024-04-02 21:51:09,428 - train - INFO - Test: [  39/39]  Time: 1.642 (1.618)  Loss:  0.3906 (0.4212)  Acc@1: 87.5000 (90.8600)  Acc@5: 100.0000 (99.5900)
2024-04-02 21:51:12,774 - train - INFO - Train: 12 [   0/195 (  0%)]  Loss:  1.661198 (1.6612)  Time: 3.220s,   79.50/s  (3.220s,   79.50/s)  LR: 5.415e-04  Data: 0.325 (0.325)
2024-04-02 21:53:33,451 - train - INFO - Train: 12 [  50/195 ( 26%)]  Loss:  1.280714 (1.5333)  Time: 2.482s,  103.16/s  (2.821s,   90.74/s)  LR: 5.415e-04  Data: 0.020 (0.019)
2024-04-02 21:55:51,882 - train - INFO - Train: 12 [ 100/195 ( 52%)]  Loss:  1.617236 (1.5397)  Time: 2.817s,   90.87/s  (2.795s,   91.59/s)  LR: 5.415e-04  Data: 0.019 (0.017)
2024-04-02 21:58:07,792 - train - INFO - Train: 12 [ 150/195 ( 77%)]  Loss:  1.819089 (1.5448)  Time: 2.616s,   97.86/s  (2.770s,   92.43/s)  LR: 5.415e-04  Data: 0.019 (0.016)
2024-04-02 22:00:12,998 - train - INFO - Train: 12 [ 194/195 (100%)]  Loss:  1.760001 (1.5407)  Time: 2.542s,  100.69/s  (2.787s,   91.86/s)  LR: 5.415e-04  Data: 0.000 (0.015)
2024-04-02 22:00:12,999 - train - INFO - True
2024-04-02 22:00:13,006 - train - INFO - alphas:tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,006 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,006 - train - INFO - True
2024-04-02 22:00:13,008 - train - INFO - alphas:tensor([0.5210, 0.4790], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,008 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,008 - train - INFO - True
2024-04-02 22:00:13,010 - train - INFO - alphas:tensor([0.6585, 0.3415], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,010 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,011 - train - INFO - True
2024-04-02 22:00:13,016 - train - INFO - alphas:tensor([0.6643, 0.3357], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,017 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,017 - train - INFO - True
2024-04-02 22:00:13,018 - train - INFO - alphas:tensor([0.5710, 0.4290], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,019 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,019 - train - INFO - True
2024-04-02 22:00:13,020 - train - INFO - alphas:tensor([0.6171, 0.3829], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,021 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,022 - train - INFO - True
2024-04-02 22:00:13,027 - train - INFO - alphas:tensor([0.6900, 0.3100], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,027 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,027 - train - INFO - True
2024-04-02 22:00:13,028 - train - INFO - alphas:tensor([0.6793, 0.3207], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,029 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,029 - train - INFO - True
2024-04-02 22:00:13,030 - train - INFO - alphas:tensor([0.6004, 0.3996], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,031 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,031 - train - INFO - True
2024-04-02 22:00:13,032 - train - INFO - alphas:tensor([0.6516, 0.3484], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,033 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,033 - train - INFO - True
2024-04-02 22:00:13,034 - train - INFO - alphas:tensor([0.6836, 0.3164], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,035 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,035 - train - INFO - True
2024-04-02 22:00:13,041 - train - INFO - alphas:tensor([0.6898, 0.3102], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,041 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,041 - train - INFO - True
2024-04-02 22:00:13,045 - train - INFO - alphas:tensor([0.6030, 0.3970], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,045 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,046 - train - INFO - True
2024-04-02 22:00:13,046 - train - INFO - alphas:tensor([0.6425, 0.3575], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,047 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,047 - train - INFO - True
2024-04-02 22:00:13,048 - train - INFO - alphas:tensor([0.6820, 0.3180], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,048 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,048 - train - INFO - True
2024-04-02 22:00:13,049 - train - INFO - alphas:tensor([0.6900, 0.3100], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,049 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,050 - train - INFO - True
2024-04-02 22:00:13,051 - train - INFO - alphas:tensor([0.5916, 0.4084], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,051 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,052 - train - INFO - True
2024-04-02 22:00:13,066 - train - INFO - alphas:tensor([0.6120, 0.3880], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,066 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,066 - train - INFO - True
2024-04-02 22:00:13,070 - train - INFO - alphas:tensor([0.6555, 0.3445], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,071 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,071 - train - INFO - True
2024-04-02 22:00:13,072 - train - INFO - alphas:tensor([0.6599, 0.3401], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,072 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,072 - train - INFO - True
2024-04-02 22:00:13,073 - train - INFO - alphas:tensor([0.5721, 0.4279], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,073 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,074 - train - INFO - True
2024-04-02 22:00:13,080 - train - INFO - alphas:tensor([0.5938, 0.4062], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,081 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,081 - train - INFO - True
2024-04-02 22:00:13,082 - train - INFO - alphas:tensor([0.6423, 0.3577], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,083 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,083 - train - INFO - True
2024-04-02 22:00:13,084 - train - INFO - alphas:tensor([0.6279, 0.3721], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,085 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,085 - train - INFO - True
2024-04-02 22:00:13,086 - train - INFO - alphas:tensor([0.5520, 0.4480], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,086 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,086 - train - INFO - True
2024-04-02 22:00:13,087 - train - INFO - alphas:tensor([0.5655, 0.4345], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,088 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,088 - train - INFO - True
2024-04-02 22:00:13,089 - train - INFO - alphas:tensor([0.5895, 0.4105], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,089 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,089 - train - INFO - True
2024-04-02 22:00:13,090 - train - INFO - alphas:tensor([0.5317, 0.4683], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,090 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,091 - train - INFO - True
2024-04-02 22:00:13,091 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:00:13,092 - train - INFO - tau:0.9043820750088043
2024-04-02 22:00:13,092 - train - INFO - avg block size:1.0
2024-04-02 22:00:13,092 - train - INFO - lasso_alpha:1.4641000000000006e-05
2024-04-02 22:00:14,817 - train - INFO - Test: [   0/39]  Time: 1.721 (1.721)  Loss:  0.4158 (0.4158)  Acc@1: 90.2344 (90.2344)  Acc@5: 99.2188 (99.2188)
2024-04-02 22:01:17,901 - train - INFO - Test: [  39/39]  Time: 1.651 (1.620)  Loss:  0.3777 (0.4106)  Acc@1: 81.2500 (90.9600)  Acc@5: 100.0000 (99.6600)
2024-04-02 22:01:21,302 - train - INFO - Train: 13 [   0/195 (  0%)]  Loss:  1.773422 (1.7734)  Time: 3.085s,   82.98/s  (3.085s,   82.98/s)  LR: 5.401e-04  Data: 0.227 (0.227)
2024-04-02 22:03:39,556 - train - INFO - Train: 13 [  50/195 ( 26%)]  Loss:  1.844962 (1.6284)  Time: 2.956s,   86.60/s  (2.771s,   92.38/s)  LR: 5.401e-04  Data: 0.010 (0.018)
2024-04-02 22:05:58,456 - train - INFO - Train: 13 [ 100/195 ( 52%)]  Loss:  1.885687 (1.6003)  Time: 2.641s,   96.92/s  (2.775s,   92.27/s)  LR: 5.401e-04  Data: 0.015 (0.015)
2024-04-02 22:08:16,102 - train - INFO - Train: 13 [ 150/195 ( 77%)]  Loss:  1.537503 (1.5981)  Time: 2.699s,   94.85/s  (2.767s,   92.51/s)  LR: 5.401e-04  Data: 0.023 (0.014)
2024-04-02 22:10:16,296 - train - INFO - Train: 13 [ 194/195 (100%)]  Loss:  1.859215 (1.5918)  Time: 2.512s,  101.92/s  (2.759s,   92.78/s)  LR: 5.401e-04  Data: 0.000 (0.014)
2024-04-02 22:10:16,297 - train - INFO - True
2024-04-02 22:10:16,298 - train - INFO - alphas:tensor([0.4886, 0.5114], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,300 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,300 - train - INFO - True
2024-04-02 22:10:16,314 - train - INFO - alphas:tensor([0.5131, 0.4869], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,315 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,315 - train - INFO - True
2024-04-02 22:10:16,316 - train - INFO - alphas:tensor([0.6626, 0.3374], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,321 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,321 - train - INFO - True
2024-04-02 22:10:16,322 - train - INFO - alphas:tensor([0.6682, 0.3318], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,322 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,322 - train - INFO - True
2024-04-02 22:10:16,323 - train - INFO - alphas:tensor([0.5667, 0.4333], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,328 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,328 - train - INFO - True
2024-04-02 22:10:16,329 - train - INFO - alphas:tensor([0.6188, 0.3812], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,329 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,330 - train - INFO - True
2024-04-02 22:10:16,331 - train - INFO - alphas:tensor([0.6972, 0.3028], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,335 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,336 - train - INFO - True
2024-04-02 22:10:16,336 - train - INFO - alphas:tensor([0.6852, 0.3148], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,341 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,350 - train - INFO - True
2024-04-02 22:10:16,355 - train - INFO - alphas:tensor([0.5967, 0.4033], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,356 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,356 - train - INFO - True
2024-04-02 22:10:16,357 - train - INFO - alphas:tensor([0.6547, 0.3453], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,357 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,357 - train - INFO - True
2024-04-02 22:10:16,358 - train - INFO - alphas:tensor([0.6919, 0.3081], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,359 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,359 - train - INFO - True
2024-04-02 22:10:16,360 - train - INFO - alphas:tensor([0.6960, 0.3040], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,360 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,360 - train - INFO - True
2024-04-02 22:10:16,361 - train - INFO - alphas:tensor([0.5989, 0.4011], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,374 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,379 - train - INFO - True
2024-04-02 22:10:16,380 - train - INFO - alphas:tensor([0.6446, 0.3554], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,380 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,380 - train - INFO - True
2024-04-02 22:10:16,381 - train - INFO - alphas:tensor([0.6894, 0.3106], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,381 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,382 - train - INFO - True
2024-04-02 22:10:16,382 - train - INFO - alphas:tensor([0.6939, 0.3061], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,383 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,383 - train - INFO - True
2024-04-02 22:10:16,384 - train - INFO - alphas:tensor([0.5891, 0.4109], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,396 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,397 - train - INFO - True
2024-04-02 22:10:16,398 - train - INFO - alphas:tensor([0.6131, 0.3869], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,398 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,398 - train - INFO - True
2024-04-02 22:10:16,399 - train - INFO - alphas:tensor([0.6620, 0.3380], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,399 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,400 - train - INFO - True
2024-04-02 22:10:16,401 - train - INFO - alphas:tensor([0.6590, 0.3410], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,412 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,412 - train - INFO - True
2024-04-02 22:10:16,417 - train - INFO - alphas:tensor([0.5703, 0.4297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,420 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,420 - train - INFO - True
2024-04-02 22:10:16,421 - train - INFO - alphas:tensor([0.5958, 0.4042], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,421 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,422 - train - INFO - True
2024-04-02 22:10:16,422 - train - INFO - alphas:tensor([0.6470, 0.3530], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,427 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,427 - train - INFO - True
2024-04-02 22:10:16,428 - train - INFO - alphas:tensor([0.6236, 0.3764], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,429 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,429 - train - INFO - True
2024-04-02 22:10:16,438 - train - INFO - alphas:tensor([0.5482, 0.4518], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,439 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,443 - train - INFO - True
2024-04-02 22:10:16,444 - train - INFO - alphas:tensor([0.5661, 0.4339], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,445 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,445 - train - INFO - True
2024-04-02 22:10:16,446 - train - INFO - alphas:tensor([0.5818, 0.4182], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,446 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,446 - train - INFO - True
2024-04-02 22:10:16,447 - train - INFO - alphas:tensor([0.5189, 0.4811], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,452 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,452 - train - INFO - True
2024-04-02 22:10:16,453 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:10:16,453 - train - INFO - tau:0.8953382542587163
2024-04-02 22:10:16,453 - train - INFO - avg block size:1.5172413793103448
2024-04-02 22:10:18,042 - train - INFO - Test: [   0/39]  Time: 1.585 (1.585)  Loss:  0.4380 (0.4380)  Acc@1: 88.6719 (88.6719)  Acc@5: 99.6094 (99.6094)
2024-04-02 22:11:20,197 - train - INFO - Test: [  39/39]  Time: 1.608 (1.594)  Loss:  0.3821 (0.4317)  Acc@1: 93.7500 (90.2400)  Acc@5: 100.0000 (99.6600)
2024-04-02 22:11:23,638 - train - INFO - Train: 14 [   0/195 (  0%)]  Loss:  1.694371 (1.6944)  Time: 3.224s,   79.40/s  (3.224s,   79.40/s)  LR: 5.385e-04  Data: 0.188 (0.188)
2024-04-02 22:13:41,014 - train - INFO - Train: 14 [  50/195 ( 26%)]  Loss:  1.758152 (1.5958)  Time: 2.990s,   85.63/s  (2.757s,   92.86/s)  LR: 5.385e-04  Data: 0.027 (0.018)
2024-04-02 22:15:57,701 - train - INFO - Train: 14 [ 100/195 ( 52%)]  Loss:  1.268898 (1.5932)  Time: 2.495s,  102.62/s  (2.745s,   93.25/s)  LR: 5.385e-04  Data: 0.006 (0.015)
2024-04-02 22:18:13,081 - train - INFO - Train: 14 [ 150/195 ( 77%)]  Loss:  1.305174 (1.5878)  Time: 2.508s,  102.06/s  (2.733s,   93.67/s)  LR: 5.385e-04  Data: 0.037 (0.014)
2024-04-02 22:20:14,782 - train - INFO - Train: 14 [ 194/195 (100%)]  Loss:  1.731850 (1.5892)  Time: 2.598s,   98.55/s  (2.740s,   93.42/s)  LR: 5.385e-04  Data: 0.000 (0.014)
2024-04-02 22:20:14,783 - train - INFO - True
2024-04-02 22:20:14,784 - train - INFO - alphas:tensor([0.4766, 0.5234], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,784 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,785 - train - INFO - True
2024-04-02 22:20:14,790 - train - INFO - alphas:tensor([0.5049, 0.4951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,790 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,791 - train - INFO - True
2024-04-02 22:20:14,792 - train - INFO - alphas:tensor([0.6671, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,792 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,792 - train - INFO - True
2024-04-02 22:20:14,793 - train - INFO - alphas:tensor([0.6727, 0.3273], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,793 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,793 - train - INFO - True
2024-04-02 22:20:14,794 - train - INFO - alphas:tensor([0.5603, 0.4397], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,799 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,799 - train - INFO - True
2024-04-02 22:20:14,800 - train - INFO - alphas:tensor([0.6199, 0.3801], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,801 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,801 - train - INFO - True
2024-04-02 22:20:14,803 - train - INFO - alphas:tensor([0.7044, 0.2956], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,803 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,803 - train - INFO - True
2024-04-02 22:20:14,804 - train - INFO - alphas:tensor([0.6912, 0.3088], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,804 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,805 - train - INFO - True
2024-04-02 22:20:14,805 - train - INFO - alphas:tensor([0.5916, 0.4084], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,806 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,806 - train - INFO - True
2024-04-02 22:20:14,807 - train - INFO - alphas:tensor([0.6555, 0.3445], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,807 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,807 - train - INFO - True
2024-04-02 22:20:14,808 - train - INFO - alphas:tensor([0.6986, 0.3014], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,808 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,809 - train - INFO - True
2024-04-02 22:20:14,810 - train - INFO - alphas:tensor([0.7018, 0.2982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,810 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,810 - train - INFO - True
2024-04-02 22:20:14,811 - train - INFO - alphas:tensor([0.5952, 0.4048], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,811 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,811 - train - INFO - True
2024-04-02 22:20:14,812 - train - INFO - alphas:tensor([0.6456, 0.3544], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,813 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,813 - train - INFO - True
2024-04-02 22:20:14,814 - train - INFO - alphas:tensor([0.6958, 0.3042], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,814 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,814 - train - INFO - True
2024-04-02 22:20:14,815 - train - INFO - alphas:tensor([0.6957, 0.3043], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,815 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,816 - train - INFO - True
2024-04-02 22:20:14,825 - train - INFO - alphas:tensor([0.5862, 0.4138], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,826 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,826 - train - INFO - True
2024-04-02 22:20:14,827 - train - INFO - alphas:tensor([0.6139, 0.3861], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,827 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,827 - train - INFO - True
2024-04-02 22:20:14,828 - train - INFO - alphas:tensor([0.6680, 0.3320], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,828 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,829 - train - INFO - True
2024-04-02 22:20:14,829 - train - INFO - alphas:tensor([0.6565, 0.3435], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,830 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,830 - train - INFO - True
2024-04-02 22:20:14,831 - train - INFO - alphas:tensor([0.5655, 0.4345], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,831 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,831 - train - INFO - True
2024-04-02 22:20:14,832 - train - INFO - alphas:tensor([0.5961, 0.4039], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,833 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,833 - train - INFO - True
2024-04-02 22:20:14,834 - train - INFO - alphas:tensor([0.6502, 0.3498], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,834 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,834 - train - INFO - True
2024-04-02 22:20:14,835 - train - INFO - alphas:tensor([0.6166, 0.3834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,835 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,836 - train - INFO - True
2024-04-02 22:20:14,836 - train - INFO - alphas:tensor([0.5404, 0.4596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,837 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,837 - train - INFO - True
2024-04-02 22:20:14,838 - train - INFO - alphas:tensor([0.5639, 0.4361], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,838 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,838 - train - INFO - True
2024-04-02 22:20:14,839 - train - INFO - alphas:tensor([0.5750, 0.4250], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,840 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,840 - train - INFO - True
2024-04-02 22:20:14,841 - train - INFO - alphas:tensor([0.5070, 0.4930], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,841 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,841 - train - INFO - True
2024-04-02 22:20:14,842 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:20:14,842 - train - INFO - tau:0.8863848717161291
2024-04-02 22:20:14,843 - train - INFO - avg block size:1.5172413793103448
2024-04-02 22:20:14,843 - train - INFO - lasso_alpha:1.610510000000001e-05
2024-04-02 22:20:16,384 - train - INFO - Test: [   0/39]  Time: 1.538 (1.538)  Loss:  0.4451 (0.4451)  Acc@1: 89.0625 (89.0625)  Acc@5: 99.6094 (99.6094)
2024-04-02 22:21:17,784 - train - INFO - Test: [  39/39]  Time: 1.589 (1.573)  Loss:  0.5205 (0.4156)  Acc@1: 81.2500 (90.4000)  Acc@5: 100.0000 (99.6200)
2024-04-02 22:21:20,871 - train - INFO - Train: 15 [   0/195 (  0%)]  Loss:  1.767470 (1.7675)  Time: 2.880s,   88.90/s  (2.880s,   88.90/s)  LR: 5.368e-04  Data: 0.372 (0.372)
2024-04-02 22:23:40,584 - train - INFO - Train: 15 [  50/195 ( 26%)]  Loss:  1.536661 (1.6289)  Time: 3.065s,   83.52/s  (2.796s,   91.56/s)  LR: 5.368e-04  Data: 0.015 (0.019)
2024-04-02 22:25:52,334 - train - INFO - Train: 15 [ 100/195 ( 52%)]  Loss:  1.524407 (1.6380)  Time: 2.414s,  106.06/s  (2.716s,   94.25/s)  LR: 5.368e-04  Data: 0.005 (0.016)
2024-04-02 22:28:11,879 - train - INFO - Train: 15 [ 150/195 ( 77%)]  Loss:  1.780100 (1.6244)  Time: 2.515s,  101.81/s  (2.741s,   93.40/s)  LR: 5.368e-04  Data: 0.037 (0.015)
2024-04-02 22:30:10,208 - train - INFO - Train: 15 [ 194/195 (100%)]  Loss:  1.473513 (1.6081)  Time: 2.913s,   87.89/s  (2.729s,   93.80/s)  LR: 5.368e-04  Data: 0.000 (0.015)
2024-04-02 22:30:10,209 - train - INFO - True
2024-04-02 22:30:10,212 - train - INFO - alphas:tensor([0.4640, 0.5360], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,212 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,212 - train - INFO - True
2024-04-02 22:30:10,213 - train - INFO - alphas:tensor([0.4969, 0.5031], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,213 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,214 - train - INFO - True
2024-04-02 22:30:10,214 - train - INFO - alphas:tensor([0.6697, 0.3303], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,215 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,215 - train - INFO - True
2024-04-02 22:30:10,216 - train - INFO - alphas:tensor([0.6751, 0.3249], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,216 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,216 - train - INFO - True
2024-04-02 22:30:10,217 - train - INFO - alphas:tensor([0.5507, 0.4493], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,217 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,218 - train - INFO - True
2024-04-02 22:30:10,219 - train - INFO - alphas:tensor([0.6183, 0.3817], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,220 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,220 - train - INFO - True
2024-04-02 22:30:10,221 - train - INFO - alphas:tensor([0.7096, 0.2904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,221 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,222 - train - INFO - True
2024-04-02 22:30:10,222 - train - INFO - alphas:tensor([0.6948, 0.3052], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,223 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,223 - train - INFO - True
2024-04-02 22:30:10,224 - train - INFO - alphas:tensor([0.5878, 0.4122], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,224 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,224 - train - INFO - True
2024-04-02 22:30:10,225 - train - INFO - alphas:tensor([0.6569, 0.3431], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,225 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,226 - train - INFO - True
2024-04-02 22:30:10,227 - train - INFO - alphas:tensor([0.7037, 0.2963], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,227 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,227 - train - INFO - True
2024-04-02 22:30:10,228 - train - INFO - alphas:tensor([0.7038, 0.2962], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,228 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,228 - train - INFO - True
2024-04-02 22:30:10,229 - train - INFO - alphas:tensor([0.5904, 0.4096], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,230 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,230 - train - INFO - True
2024-04-02 22:30:10,231 - train - INFO - alphas:tensor([0.6455, 0.3545], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,231 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,231 - train - INFO - True
2024-04-02 22:30:10,232 - train - INFO - alphas:tensor([0.6999, 0.3001], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,232 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,233 - train - INFO - True
2024-04-02 22:30:10,233 - train - INFO - alphas:tensor([0.6944, 0.3056], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,234 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,234 - train - INFO - True
2024-04-02 22:30:10,235 - train - INFO - alphas:tensor([0.5812, 0.4188], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,235 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,235 - train - INFO - True
2024-04-02 22:30:10,236 - train - INFO - alphas:tensor([0.6126, 0.3874], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,236 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,237 - train - INFO - True
2024-04-02 22:30:10,237 - train - INFO - alphas:tensor([0.6703, 0.3297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,238 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,238 - train - INFO - True
2024-04-02 22:30:10,239 - train - INFO - alphas:tensor([0.6487, 0.3513], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,239 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,239 - train - INFO - True
2024-04-02 22:30:10,240 - train - INFO - alphas:tensor([0.5610, 0.4390], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,241 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,241 - train - INFO - True
2024-04-02 22:30:10,242 - train - INFO - alphas:tensor([0.5959, 0.4041], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,242 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,242 - train - INFO - True
2024-04-02 22:30:10,243 - train - INFO - alphas:tensor([0.6507, 0.3493], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,243 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,243 - train - INFO - True
2024-04-02 22:30:10,244 - train - INFO - alphas:tensor([0.6044, 0.3956], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,245 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,245 - train - INFO - True
2024-04-02 22:30:10,246 - train - INFO - alphas:tensor([0.5327, 0.4673], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,246 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,246 - train - INFO - True
2024-04-02 22:30:10,247 - train - INFO - alphas:tensor([0.5621, 0.4379], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,247 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,247 - train - INFO - True
2024-04-02 22:30:10,248 - train - INFO - alphas:tensor([0.5650, 0.4350], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,248 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,249 - train - INFO - True
2024-04-02 22:30:10,249 - train - INFO - alphas:tensor([0.4917, 0.5083], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,250 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,250 - train - INFO - True
2024-04-02 22:30:10,251 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:30:10,251 - train - INFO - tau:0.8775210229989678
2024-04-02 22:30:10,251 - train - INFO - avg block size:2.5517241379310347
2024-04-02 22:30:11,911 - train - INFO - Test: [   0/39]  Time: 1.657 (1.657)  Loss:  0.4165 (0.4165)  Acc@1: 90.6250 (90.6250)  Acc@5: 99.6094 (99.6094)
2024-04-02 22:31:13,508 - train - INFO - Test: [  39/39]  Time: 1.586 (1.581)  Loss:  0.4226 (0.3964)  Acc@1: 87.5000 (91.2000)  Acc@5: 100.0000 (99.6900)
2024-04-02 22:31:16,813 - train - INFO - Train: 16 [   0/195 (  0%)]  Loss:  1.701166 (1.7012)  Time: 3.112s,   82.26/s  (3.112s,   82.26/s)  LR: 5.350e-04  Data: 0.294 (0.294)
2024-04-02 22:33:35,233 - train - INFO - Train: 16 [  50/195 ( 26%)]  Loss:  1.468157 (1.6121)  Time: 3.215s,   79.62/s  (2.775s,   92.25/s)  LR: 5.350e-04  Data: 0.046 (0.019)
2024-04-02 22:35:53,146 - train - INFO - Train: 16 [ 100/195 ( 52%)]  Loss:  1.792327 (1.6115)  Time: 3.125s,   81.91/s  (2.766s,   92.54/s)  LR: 5.350e-04  Data: 0.017 (0.017)
2024-04-02 22:38:11,042 - train - INFO - Train: 16 [ 150/195 ( 77%)]  Loss:  1.415510 (1.6100)  Time: 2.592s,   98.75/s  (2.764s,   92.63/s)  LR: 5.350e-04  Data: 0.011 (0.016)
2024-04-02 22:40:09,001 - train - INFO - Train: 16 [ 194/195 (100%)]  Loss:  1.770059 (1.6098)  Time: 2.446s,  104.66/s  (2.745s,   93.26/s)  LR: 5.350e-04  Data: 0.000 (0.015)
2024-04-02 22:40:09,001 - train - INFO - True
2024-04-02 22:40:09,003 - train - INFO - alphas:tensor([0.4504, 0.5496], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,003 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,003 - train - INFO - True
2024-04-02 22:40:09,008 - train - INFO - alphas:tensor([0.4879, 0.5121], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,008 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,009 - train - INFO - True
2024-04-02 22:40:09,009 - train - INFO - alphas:tensor([0.6719, 0.3281], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,010 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,014 - train - INFO - True
2024-04-02 22:40:09,015 - train - INFO - alphas:tensor([0.6758, 0.3242], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,016 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,016 - train - INFO - True
2024-04-02 22:40:09,017 - train - INFO - alphas:tensor([0.5455, 0.4545], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,017 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,017 - train - INFO - True
2024-04-02 22:40:09,018 - train - INFO - alphas:tensor([0.6185, 0.3815], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,018 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,019 - train - INFO - True
2024-04-02 22:40:09,019 - train - INFO - alphas:tensor([0.7140, 0.2860], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,020 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,020 - train - INFO - True
2024-04-02 22:40:09,021 - train - INFO - alphas:tensor([0.6962, 0.3038], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,021 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,022 - train - INFO - True
2024-04-02 22:40:09,023 - train - INFO - alphas:tensor([0.5832, 0.4168], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,023 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,023 - train - INFO - True
2024-04-02 22:40:09,024 - train - INFO - alphas:tensor([0.6576, 0.3424], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,024 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,025 - train - INFO - True
2024-04-02 22:40:09,025 - train - INFO - alphas:tensor([0.7084, 0.2916], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,030 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,030 - train - INFO - True
2024-04-02 22:40:09,031 - train - INFO - alphas:tensor([0.7055, 0.2945], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,032 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,032 - train - INFO - True
2024-04-02 22:40:09,033 - train - INFO - alphas:tensor([0.5873, 0.4127], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,033 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,033 - train - INFO - True
2024-04-02 22:40:09,040 - train - INFO - alphas:tensor([0.6474, 0.3526], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,040 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,040 - train - INFO - True
2024-04-02 22:40:09,041 - train - INFO - alphas:tensor([0.7028, 0.2972], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,041 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,042 - train - INFO - True
2024-04-02 22:40:09,042 - train - INFO - alphas:tensor([0.6915, 0.3085], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,043 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,043 - train - INFO - True
2024-04-02 22:40:09,044 - train - INFO - alphas:tensor([0.5767, 0.4233], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,044 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,044 - train - INFO - True
2024-04-02 22:40:09,045 - train - INFO - alphas:tensor([0.6126, 0.3874], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,045 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,046 - train - INFO - True
2024-04-02 22:40:09,047 - train - INFO - alphas:tensor([0.6724, 0.3276], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,047 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,048 - train - INFO - True
2024-04-02 22:40:09,048 - train - INFO - alphas:tensor([0.6383, 0.3617], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,049 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,049 - train - INFO - True
2024-04-02 22:40:09,050 - train - INFO - alphas:tensor([0.5551, 0.4449], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,050 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,050 - train - INFO - True
2024-04-02 22:40:09,051 - train - INFO - alphas:tensor([0.5934, 0.4066], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,052 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,052 - train - INFO - True
2024-04-02 22:40:09,057 - train - INFO - alphas:tensor([0.6504, 0.3496], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,057 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,058 - train - INFO - True
2024-04-02 22:40:09,058 - train - INFO - alphas:tensor([0.5913, 0.4087], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,059 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,059 - train - INFO - True
2024-04-02 22:40:09,060 - train - INFO - alphas:tensor([0.5250, 0.4750], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,060 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,060 - train - INFO - True
2024-04-02 22:40:09,061 - train - INFO - alphas:tensor([0.5592, 0.4408], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,061 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,062 - train - INFO - True
2024-04-02 22:40:09,063 - train - INFO - alphas:tensor([0.5540, 0.4460], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,063 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,063 - train - INFO - True
2024-04-02 22:40:09,064 - train - INFO - alphas:tensor([0.4751, 0.5249], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,064 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,065 - train - INFO - True
2024-04-02 22:40:09,065 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:40:09,066 - train - INFO - tau:0.8687458127689781
2024-04-02 22:40:09,066 - train - INFO - avg block size:2.5517241379310347
2024-04-02 22:40:09,066 - train - INFO - lasso_alpha:1.771561000000001e-05
2024-04-02 22:40:10,769 - train - INFO - Test: [   0/39]  Time: 1.690 (1.690)  Loss:  0.4409 (0.4409)  Acc@1: 89.8438 (89.8438)  Acc@5: 99.2188 (99.2188)
2024-04-02 22:41:12,950 - train - INFO - Test: [  39/39]  Time: 1.553 (1.597)  Loss:  0.4016 (0.4077)  Acc@1: 87.5000 (90.8100)  Acc@5: 100.0000 (99.6700)
2024-04-02 22:41:16,463 - train - INFO - Train: 17 [   0/195 (  0%)]  Loss:  1.846723 (1.8467)  Time: 3.331s,   76.86/s  (3.331s,   76.86/s)  LR: 5.331e-04  Data: 0.238 (0.238)
2024-04-02 22:43:33,852 - train - INFO - Train: 17 [  50/195 ( 26%)]  Loss:  1.467550 (1.5987)  Time: 2.632s,   97.25/s  (2.759s,   92.79/s)  LR: 5.331e-04  Data: 0.018 (0.018)
2024-04-02 22:45:49,516 - train - INFO - Train: 17 [ 100/195 ( 52%)]  Loss:  1.850568 (1.6165)  Time: 2.516s,  101.75/s  (2.736s,   93.56/s)  LR: 5.331e-04  Data: 0.019 (0.015)
2024-04-02 22:48:05,899 - train - INFO - Train: 17 [ 150/195 ( 77%)]  Loss:  1.582229 (1.6138)  Time: 2.630s,   97.35/s  (2.733s,   93.66/s)  LR: 5.331e-04  Data: 0.014 (0.015)
2024-04-02 22:50:05,964 - train - INFO - Train: 17 [ 194/195 (100%)]  Loss:  1.733277 (1.6077)  Time: 2.729s,   93.79/s  (2.732s,   93.69/s)  LR: 5.331e-04  Data: 0.000 (0.014)
2024-04-02 22:50:05,965 - train - INFO - True
2024-04-02 22:50:05,967 - train - INFO - alphas:tensor([0.4384, 0.5616], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:05,967 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:05,968 - train - INFO - True
2024-04-02 22:50:05,968 - train - INFO - alphas:tensor([0.4786, 0.5214], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:05,969 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:05,969 - train - INFO - True
2024-04-02 22:50:05,970 - train - INFO - alphas:tensor([0.6738, 0.3262], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:05,970 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:05,970 - train - INFO - True
2024-04-02 22:50:05,971 - train - INFO - alphas:tensor([0.6774, 0.3226], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:05,972 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:05,972 - train - INFO - True
2024-04-02 22:50:05,973 - train - INFO - alphas:tensor([0.5346, 0.4654], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:05,973 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:05,973 - train - INFO - True
2024-04-02 22:50:05,974 - train - INFO - alphas:tensor([0.6145, 0.3855], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:05,974 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:05,975 - train - INFO - True
2024-04-02 22:50:05,976 - train - INFO - alphas:tensor([0.7161, 0.2839], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:05,976 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:05,976 - train - INFO - True
2024-04-02 22:50:05,977 - train - INFO - alphas:tensor([0.6968, 0.3032], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:05,978 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:05,978 - train - INFO - True
2024-04-02 22:50:05,987 - train - INFO - alphas:tensor([0.5764, 0.4236], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:05,988 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:05,988 - train - INFO - True
2024-04-02 22:50:05,989 - train - INFO - alphas:tensor([0.6559, 0.3441], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:05,989 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:05,989 - train - INFO - True
2024-04-02 22:50:05,990 - train - INFO - alphas:tensor([0.7123, 0.2877], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:05,991 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:05,991 - train - INFO - True
2024-04-02 22:50:06,001 - train - INFO - alphas:tensor([0.7058, 0.2942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,001 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,001 - train - INFO - True
2024-04-02 22:50:06,002 - train - INFO - alphas:tensor([0.5808, 0.4192], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,002 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,003 - train - INFO - True
2024-04-02 22:50:06,004 - train - INFO - alphas:tensor([0.6465, 0.3535], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,004 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,004 - train - INFO - True
2024-04-02 22:50:06,005 - train - INFO - alphas:tensor([0.7043, 0.2957], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,005 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,006 - train - INFO - True
2024-04-02 22:50:06,007 - train - INFO - alphas:tensor([0.6855, 0.3145], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,007 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,007 - train - INFO - True
2024-04-02 22:50:06,008 - train - INFO - alphas:tensor([0.5701, 0.4299], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,008 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,009 - train - INFO - True
2024-04-02 22:50:06,010 - train - INFO - alphas:tensor([0.6089, 0.3911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,010 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,011 - train - INFO - True
2024-04-02 22:50:06,012 - train - INFO - alphas:tensor([0.6730, 0.3270], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,012 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,012 - train - INFO - True
2024-04-02 22:50:06,013 - train - INFO - alphas:tensor([0.6262, 0.3738], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,014 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,014 - train - INFO - True
2024-04-02 22:50:06,015 - train - INFO - alphas:tensor([0.5486, 0.4514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,015 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,015 - train - INFO - True
2024-04-02 22:50:06,016 - train - INFO - alphas:tensor([0.5900, 0.4100], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,016 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,016 - train - INFO - True
2024-04-02 22:50:06,017 - train - INFO - alphas:tensor([0.6487, 0.3513], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,017 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,017 - train - INFO - True
2024-04-02 22:50:06,018 - train - INFO - alphas:tensor([0.5733, 0.4267], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,018 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,019 - train - INFO - True
2024-04-02 22:50:06,028 - train - INFO - alphas:tensor([0.5148, 0.4852], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,029 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,029 - train - INFO - True
2024-04-02 22:50:06,030 - train - INFO - alphas:tensor([0.5544, 0.4456], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,030 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,030 - train - INFO - True
2024-04-02 22:50:06,031 - train - INFO - alphas:tensor([0.5384, 0.4616], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,031 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,032 - train - INFO - True
2024-04-02 22:50:06,032 - train - INFO - alphas:tensor([0.4535, 0.5465], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,033 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,033 - train - INFO - True
2024-04-02 22:50:06,034 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 22:50:06,034 - train - INFO - tau:0.8600583546412883
2024-04-02 22:50:06,034 - train - INFO - avg block size:2.5517241379310347
2024-04-02 22:50:07,538 - train - INFO - Test: [   0/39]  Time: 1.501 (1.501)  Loss:  0.4072 (0.4072)  Acc@1: 91.4062 (91.4062)  Acc@5: 99.6094 (99.6094)
2024-04-02 22:51:10,365 - train - INFO - Test: [  39/39]  Time: 1.611 (1.608)  Loss:  0.4436 (0.3950)  Acc@1: 81.2500 (91.5200)  Acc@5: 100.0000 (99.6800)
2024-04-02 22:51:13,566 - train - INFO - Train: 18 [   0/195 (  0%)]  Loss:  1.831334 (1.8313)  Time: 2.980s,   85.89/s  (2.980s,   85.89/s)  LR: 5.310e-04  Data: 0.283 (0.283)
2024-04-02 22:53:29,942 - train - INFO - Train: 18 [  50/195 ( 26%)]  Loss:  1.753422 (1.6575)  Time: 2.845s,   89.98/s  (2.732s,   93.69/s)  LR: 5.310e-04  Data: 0.014 (0.017)
2024-04-02 22:55:49,344 - train - INFO - Train: 18 [ 100/195 ( 52%)]  Loss:  1.880768 (1.6185)  Time: 2.247s,  113.94/s  (2.760s,   92.76/s)  LR: 5.310e-04  Data: 0.019 (0.014)
2024-04-02 22:58:05,483 - train - INFO - Train: 18 [ 150/195 ( 77%)]  Loss:  1.629862 (1.6234)  Time: 3.129s,   81.80/s  (2.748s,   93.17/s)  LR: 5.310e-04  Data: 0.016 (0.013)
2024-04-02 23:00:04,711 - train - INFO - Train: 18 [ 194/195 (100%)]  Loss:  1.506645 (1.6231)  Time: 2.569s,   99.64/s  (2.739s,   93.47/s)  LR: 5.310e-04  Data: 0.000 (0.013)
2024-04-02 23:00:04,712 - train - INFO - True
2024-04-02 23:00:04,713 - train - INFO - alphas:tensor([0.4235, 0.5765], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,713 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,713 - train - INFO - True
2024-04-02 23:00:04,714 - train - INFO - alphas:tensor([0.4668, 0.5332], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,714 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,714 - train - INFO - True
2024-04-02 23:00:04,715 - train - INFO - alphas:tensor([0.6748, 0.3252], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,715 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,715 - train - INFO - True
2024-04-02 23:00:04,716 - train - INFO - alphas:tensor([0.6779, 0.3221], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,716 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,716 - train - INFO - True
2024-04-02 23:00:04,717 - train - INFO - alphas:tensor([0.5249, 0.4751], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,717 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,717 - train - INFO - True
2024-04-02 23:00:04,718 - train - INFO - alphas:tensor([0.6103, 0.3897], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,718 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,718 - train - INFO - True
2024-04-02 23:00:04,718 - train - INFO - alphas:tensor([0.7194, 0.2806], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,719 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,719 - train - INFO - True
2024-04-02 23:00:04,720 - train - INFO - alphas:tensor([0.6975, 0.3025], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,720 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,720 - train - INFO - True
2024-04-02 23:00:04,721 - train - INFO - alphas:tensor([0.5699, 0.4301], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,721 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,722 - train - INFO - True
2024-04-02 23:00:04,722 - train - INFO - alphas:tensor([0.6551, 0.3449], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,723 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,723 - train - INFO - True
2024-04-02 23:00:04,724 - train - INFO - alphas:tensor([0.7145, 0.2855], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,724 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,724 - train - INFO - True
2024-04-02 23:00:04,725 - train - INFO - alphas:tensor([0.7036, 0.2964], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,725 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,725 - train - INFO - True
2024-04-02 23:00:04,726 - train - INFO - alphas:tensor([0.5761, 0.4239], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,726 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,726 - train - INFO - True
2024-04-02 23:00:04,727 - train - INFO - alphas:tensor([0.6456, 0.3544], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,727 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,727 - train - INFO - True
2024-04-02 23:00:04,728 - train - INFO - alphas:tensor([0.7068, 0.2932], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,728 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,729 - train - INFO - True
2024-04-02 23:00:04,729 - train - INFO - alphas:tensor([0.6794, 0.3206], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,730 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,730 - train - INFO - True
2024-04-02 23:00:04,731 - train - INFO - alphas:tensor([0.5645, 0.4355], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,731 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,731 - train - INFO - True
2024-04-02 23:00:04,732 - train - INFO - alphas:tensor([0.6046, 0.3954], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,732 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,732 - train - INFO - True
2024-04-02 23:00:04,742 - train - INFO - alphas:tensor([0.6729, 0.3271], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,742 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,742 - train - INFO - True
2024-04-02 23:00:04,743 - train - INFO - alphas:tensor([0.6118, 0.3882], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,743 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,744 - train - INFO - True
2024-04-02 23:00:04,744 - train - INFO - alphas:tensor([0.5411, 0.4589], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,745 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,745 - train - INFO - True
2024-04-02 23:00:04,746 - train - INFO - alphas:tensor([0.5864, 0.4136], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,746 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,746 - train - INFO - True
2024-04-02 23:00:04,747 - train - INFO - alphas:tensor([0.6467, 0.3533], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,747 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,748 - train - INFO - True
2024-04-02 23:00:04,749 - train - INFO - alphas:tensor([0.5590, 0.4410], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,749 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,749 - train - INFO - True
2024-04-02 23:00:04,750 - train - INFO - alphas:tensor([0.5056, 0.4944], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,750 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,750 - train - INFO - True
2024-04-02 23:00:04,751 - train - INFO - alphas:tensor([0.5495, 0.4505], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,751 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,752 - train - INFO - True
2024-04-02 23:00:04,761 - train - INFO - alphas:tensor([0.5244, 0.4756], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,762 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,762 - train - INFO - True
2024-04-02 23:00:04,763 - train - INFO - alphas:tensor([0.4337, 0.5663], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,763 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,763 - train - INFO - True
2024-04-02 23:00:04,764 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:00:04,764 - train - INFO - tau:0.8514577710948754
2024-04-02 23:00:04,764 - train - INFO - avg block size:2.5517241379310347
2024-04-02 23:00:04,765 - train - INFO - lasso_alpha:1.9487171000000013e-05
2024-04-02 23:00:06,406 - train - INFO - Test: [   0/39]  Time: 1.638 (1.638)  Loss:  0.4458 (0.4458)  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)
2024-04-02 23:01:08,563 - train - INFO - Test: [  39/39]  Time: 1.718 (1.595)  Loss:  0.4038 (0.4002)  Acc@1: 87.5000 (91.4000)  Acc@5: 100.0000 (99.6900)
2024-04-02 23:01:11,785 - train - INFO - Train: 19 [   0/195 (  0%)]  Loss:  1.300632 (1.3006)  Time: 2.946s,   86.89/s  (2.946s,   86.89/s)  LR: 5.289e-04  Data: 0.328 (0.328)
2024-04-02 23:03:25,658 - train - INFO - Train: 19 [  50/195 ( 26%)]  Loss:  1.385471 (1.6119)  Time: 2.447s,  104.62/s  (2.683s,   95.43/s)  LR: 5.289e-04  Data: 0.029 (0.016)
2024-04-02 23:05:43,679 - train - INFO - Train: 19 [ 100/195 ( 52%)]  Loss:  1.822739 (1.6151)  Time: 2.510s,  101.97/s  (2.721s,   94.08/s)  LR: 5.289e-04  Data: 0.009 (0.015)
2024-04-02 23:08:03,648 - train - INFO - Train: 19 [ 150/195 ( 77%)]  Loss:  1.796377 (1.6126)  Time: 2.991s,   85.60/s  (2.747s,   93.19/s)  LR: 5.289e-04  Data: 0.016 (0.014)
2024-04-02 23:10:05,146 - train - INFO - Train: 19 [ 194/195 (100%)]  Loss:  1.841414 (1.6100)  Time: 2.610s,   98.09/s  (2.750s,   93.08/s)  LR: 5.289e-04  Data: 0.000 (0.014)
2024-04-02 23:10:05,146 - train - INFO - True
2024-04-02 23:10:05,147 - train - INFO - alphas:tensor([0.4096, 0.5904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,148 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,148 - train - INFO - True
2024-04-02 23:10:05,148 - train - INFO - alphas:tensor([0.4573, 0.5427], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,148 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,149 - train - INFO - True
2024-04-02 23:10:05,149 - train - INFO - alphas:tensor([0.6732, 0.3268], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,149 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,149 - train - INFO - True
2024-04-02 23:10:05,150 - train - INFO - alphas:tensor([0.6754, 0.3246], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,150 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,150 - train - INFO - True
2024-04-02 23:10:05,151 - train - INFO - alphas:tensor([0.5116, 0.4884], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,151 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,151 - train - INFO - True
2024-04-02 23:10:05,152 - train - INFO - alphas:tensor([0.6036, 0.3964], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,156 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,156 - train - INFO - True
2024-04-02 23:10:05,157 - train - INFO - alphas:tensor([0.7185, 0.2815], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,157 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,157 - train - INFO - True
2024-04-02 23:10:05,158 - train - INFO - alphas:tensor([0.6928, 0.3072], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,158 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,159 - train - INFO - True
2024-04-02 23:10:05,159 - train - INFO - alphas:tensor([0.5606, 0.4394], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,160 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,164 - train - INFO - True
2024-04-02 23:10:05,165 - train - INFO - alphas:tensor([0.6515, 0.3485], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,165 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,165 - train - INFO - True
2024-04-02 23:10:05,166 - train - INFO - alphas:tensor([0.7156, 0.2844], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,167 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,167 - train - INFO - True
2024-04-02 23:10:05,168 - train - INFO - alphas:tensor([0.6999, 0.3001], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,168 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,168 - train - INFO - True
2024-04-02 23:10:05,169 - train - INFO - alphas:tensor([0.5692, 0.4308], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,169 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,170 - train - INFO - True
2024-04-02 23:10:05,170 - train - INFO - alphas:tensor([0.6419, 0.3581], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,175 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,175 - train - INFO - True
2024-04-02 23:10:05,176 - train - INFO - alphas:tensor([0.7056, 0.2944], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,177 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,177 - train - INFO - True
2024-04-02 23:10:05,178 - train - INFO - alphas:tensor([0.6679, 0.3321], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,178 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,178 - train - INFO - True
2024-04-02 23:10:05,179 - train - INFO - alphas:tensor([0.5557, 0.4443], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,179 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,180 - train - INFO - True
2024-04-02 23:10:05,180 - train - INFO - alphas:tensor([0.5976, 0.4024], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,181 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,181 - train - INFO - True
2024-04-02 23:10:05,182 - train - INFO - alphas:tensor([0.6700, 0.3300], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,182 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,182 - train - INFO - True
2024-04-02 23:10:05,183 - train - INFO - alphas:tensor([0.5902, 0.4098], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,184 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,184 - train - INFO - True
2024-04-02 23:10:05,185 - train - INFO - alphas:tensor([0.5308, 0.4692], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,185 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,185 - train - INFO - True
2024-04-02 23:10:05,190 - train - INFO - alphas:tensor([0.5790, 0.4210], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,191 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,191 - train - INFO - True
2024-04-02 23:10:05,192 - train - INFO - alphas:tensor([0.6437, 0.3563], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,192 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,192 - train - INFO - True
2024-04-02 23:10:05,193 - train - INFO - alphas:tensor([0.5395, 0.4605], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,194 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,194 - train - INFO - True
2024-04-02 23:10:05,195 - train - INFO - alphas:tensor([0.4926, 0.5074], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,195 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,195 - train - INFO - True
2024-04-02 23:10:05,196 - train - INFO - alphas:tensor([0.5413, 0.4587], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,196 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,197 - train - INFO - True
2024-04-02 23:10:05,197 - train - INFO - alphas:tensor([0.5055, 0.4945], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,198 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,198 - train - INFO - True
2024-04-02 23:10:05,203 - train - INFO - alphas:tensor([0.4083, 0.5917], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,204 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,204 - train - INFO - True
2024-04-02 23:10:05,205 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:10:05,205 - train - INFO - tau:0.8429431933839266
2024-04-02 23:10:05,205 - train - INFO - avg block size:3.0689655172413794
2024-04-02 23:10:06,791 - train - INFO - Test: [   0/39]  Time: 1.579 (1.579)  Loss:  0.4263 (0.4263)  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)
2024-04-02 23:11:10,225 - train - INFO - Test: [  39/39]  Time: 1.564 (1.625)  Loss:  0.3987 (0.4160)  Acc@1: 87.5000 (91.0900)  Acc@5: 100.0000 (99.6800)
2024-04-02 23:11:13,224 - train - INFO - Train: 20 [   0/195 (  0%)]  Loss:  1.497244 (1.4972)  Time: 2.741s,   93.39/s  (2.741s,   93.39/s)  LR: 5.267e-04  Data: 0.305 (0.305)
2024-04-02 23:13:34,169 - train - INFO - Train: 20 [  50/195 ( 26%)]  Loss:  1.858501 (1.6371)  Time: 3.024s,   84.67/s  (2.817s,   90.87/s)  LR: 5.267e-04  Data: 0.006 (0.019)
2024-04-02 23:15:48,489 - train - INFO - Train: 20 [ 100/195 ( 52%)]  Loss:  1.489218 (1.6039)  Time: 2.747s,   93.21/s  (2.753s,   93.01/s)  LR: 5.267e-04  Data: 0.005 (0.016)
2024-04-02 23:18:02,772 - train - INFO - Train: 20 [ 150/195 ( 77%)]  Loss:  1.365920 (1.6064)  Time: 2.470s,  103.64/s  (2.730s,   93.76/s)  LR: 5.267e-04  Data: 0.006 (0.015)
2024-04-02 23:19:58,792 - train - INFO - Train: 20 [ 194/195 (100%)]  Loss:  1.720960 (1.6133)  Time: 2.444s,  104.74/s  (2.709s,   94.49/s)  LR: 5.267e-04  Data: 0.000 (0.015)
2024-04-02 23:19:58,793 - train - INFO - True
2024-04-02 23:19:58,794 - train - INFO - alphas:tensor([0.3949, 0.6051], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,794 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,794 - train - INFO - True
2024-04-02 23:19:58,795 - train - INFO - alphas:tensor([0.4481, 0.5519], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,795 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,795 - train - INFO - True
2024-04-02 23:19:58,796 - train - INFO - alphas:tensor([0.6740, 0.3260], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,796 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,796 - train - INFO - True
2024-04-02 23:19:58,797 - train - INFO - alphas:tensor([0.6753, 0.3247], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,797 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,797 - train - INFO - True
2024-04-02 23:19:58,802 - train - INFO - alphas:tensor([0.5037, 0.4963], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,802 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,802 - train - INFO - True
2024-04-02 23:19:58,803 - train - INFO - alphas:tensor([0.6042, 0.3958], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,804 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,804 - train - INFO - True
2024-04-02 23:19:58,805 - train - INFO - alphas:tensor([0.7195, 0.2805], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,805 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,805 - train - INFO - True
2024-04-02 23:19:58,806 - train - INFO - alphas:tensor([0.6905, 0.3095], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,807 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,807 - train - INFO - True
2024-04-02 23:19:58,808 - train - INFO - alphas:tensor([0.5550, 0.4450], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,808 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,808 - train - INFO - True
2024-04-02 23:19:58,809 - train - INFO - alphas:tensor([0.6493, 0.3507], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,810 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,810 - train - INFO - True
2024-04-02 23:19:58,811 - train - INFO - alphas:tensor([0.7181, 0.2819], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,811 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,811 - train - INFO - True
2024-04-02 23:19:58,812 - train - INFO - alphas:tensor([0.6971, 0.3029], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,812 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,813 - train - INFO - True
2024-04-02 23:19:58,814 - train - INFO - alphas:tensor([0.5631, 0.4369], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,814 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,814 - train - INFO - True
2024-04-02 23:19:58,815 - train - INFO - alphas:tensor([0.6397, 0.3603], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,815 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,815 - train - INFO - True
2024-04-02 23:19:58,816 - train - INFO - alphas:tensor([0.7052, 0.2948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,817 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,817 - train - INFO - True
2024-04-02 23:19:58,818 - train - INFO - alphas:tensor([0.6592, 0.3408], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,818 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,818 - train - INFO - True
2024-04-02 23:19:58,819 - train - INFO - alphas:tensor([0.5494, 0.4506], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,819 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,820 - train - INFO - True
2024-04-02 23:19:58,820 - train - INFO - alphas:tensor([0.5940, 0.4060], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,821 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,821 - train - INFO - True
2024-04-02 23:19:58,822 - train - INFO - alphas:tensor([0.6694, 0.3306], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,822 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,823 - train - INFO - True
2024-04-02 23:19:58,823 - train - INFO - alphas:tensor([0.5769, 0.4231], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,824 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,824 - train - INFO - True
2024-04-02 23:19:58,825 - train - INFO - alphas:tensor([0.5241, 0.4759], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,825 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,825 - train - INFO - True
2024-04-02 23:19:58,826 - train - INFO - alphas:tensor([0.5752, 0.4248], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,827 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,827 - train - INFO - True
2024-04-02 23:19:58,832 - train - INFO - alphas:tensor([0.6389, 0.3611], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,832 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,833 - train - INFO - True
2024-04-02 23:19:58,833 - train - INFO - alphas:tensor([0.5209, 0.4791], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,834 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,834 - train - INFO - True
2024-04-02 23:19:58,835 - train - INFO - alphas:tensor([0.4837, 0.5163], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,835 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,835 - train - INFO - True
2024-04-02 23:19:58,836 - train - INFO - alphas:tensor([0.5346, 0.4654], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,837 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,837 - train - INFO - True
2024-04-02 23:19:58,838 - train - INFO - alphas:tensor([0.4914, 0.5086], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,838 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,838 - train - INFO - True
2024-04-02 23:19:58,839 - train - INFO - alphas:tensor([0.3886, 0.6114], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,840 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,840 - train - INFO - True
2024-04-02 23:19:58,841 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:19:58,841 - train - INFO - tau:0.8345137614500874
2024-04-02 23:19:58,841 - train - INFO - avg block size:3.586206896551724
2024-04-02 23:19:58,842 - train - INFO - lasso_alpha:2.1435888100000015e-05
2024-04-02 23:20:00,426 - train - INFO - Test: [   0/39]  Time: 1.581 (1.581)  Loss:  0.4280 (0.4280)  Acc@1: 89.4531 (89.4531)  Acc@5: 100.0000 (100.0000)
2024-04-02 23:21:01,523 - train - INFO - Test: [  39/39]  Time: 1.528 (1.567)  Loss:  0.4417 (0.4061)  Acc@1: 87.5000 (91.1800)  Acc@5: 100.0000 (99.6900)
2024-04-02 23:21:05,075 - train - INFO - Train: 21 [   0/195 (  0%)]  Loss:  1.282232 (1.2822)  Time: 3.312s,   77.29/s  (3.312s,   77.29/s)  LR: 5.243e-04  Data: 0.340 (0.340)
2024-04-02 23:23:23,272 - train - INFO - Train: 21 [  50/195 ( 26%)]  Loss:  1.828555 (1.6484)  Time: 2.505s,  102.19/s  (2.775s,   92.26/s)  LR: 5.243e-04  Data: 0.007 (0.019)
2024-04-02 23:25:40,389 - train - INFO - Train: 21 [ 100/195 ( 52%)]  Loss:  1.372947 (1.6483)  Time: 3.122s,   82.01/s  (2.759s,   92.80/s)  LR: 5.243e-04  Data: 0.021 (0.016)
2024-04-02 23:27:54,499 - train - INFO - Train: 21 [ 150/195 ( 77%)]  Loss:  1.879376 (1.6489)  Time: 2.741s,   93.39/s  (2.733s,   93.66/s)  LR: 5.243e-04  Data: 0.021 (0.015)
2024-04-02 23:29:55,588 - train - INFO - Train: 21 [ 194/195 (100%)]  Loss:  1.862895 (1.6541)  Time: 2.989s,   85.66/s  (2.738s,   93.52/s)  LR: 5.243e-04  Data: 0.000 (0.015)
2024-04-02 23:29:55,592 - train - INFO - True
2024-04-02 23:29:55,594 - train - INFO - alphas:tensor([0.3789, 0.6211], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,594 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,594 - train - INFO - True
2024-04-02 23:29:55,595 - train - INFO - alphas:tensor([0.4339, 0.5661], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,595 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,595 - train - INFO - True
2024-04-02 23:29:55,596 - train - INFO - alphas:tensor([0.6739, 0.3261], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,596 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,596 - train - INFO - True
2024-04-02 23:29:55,597 - train - INFO - alphas:tensor([0.6724, 0.3276], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,597 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,597 - train - INFO - True
2024-04-02 23:29:55,597 - train - INFO - alphas:tensor([0.4934, 0.5066], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,598 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,598 - train - INFO - True
2024-04-02 23:29:55,598 - train - INFO - alphas:tensor([0.5972, 0.4028], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,598 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,598 - train - INFO - True
2024-04-02 23:29:55,599 - train - INFO - alphas:tensor([0.7171, 0.2829], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,599 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,600 - train - INFO - True
2024-04-02 23:29:55,600 - train - INFO - alphas:tensor([0.6837, 0.3163], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,612 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,612 - train - INFO - True
2024-04-02 23:29:55,613 - train - INFO - alphas:tensor([0.5461, 0.4539], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,614 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,614 - train - INFO - True
2024-04-02 23:29:55,615 - train - INFO - alphas:tensor([0.6449, 0.3551], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,615 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,615 - train - INFO - True
2024-04-02 23:29:55,616 - train - INFO - alphas:tensor([0.7169, 0.2831], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,616 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,616 - train - INFO - True
2024-04-02 23:29:55,617 - train - INFO - alphas:tensor([0.6875, 0.3125], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,617 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,618 - train - INFO - True
2024-04-02 23:29:55,618 - train - INFO - alphas:tensor([0.5544, 0.4456], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,619 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,619 - train - INFO - True
2024-04-02 23:29:55,620 - train - INFO - alphas:tensor([0.6348, 0.3652], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,620 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,620 - train - INFO - True
2024-04-02 23:29:55,630 - train - INFO - alphas:tensor([0.7032, 0.2968], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,630 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,631 - train - INFO - True
2024-04-02 23:29:55,631 - train - INFO - alphas:tensor([0.6421, 0.3579], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,632 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,632 - train - INFO - True
2024-04-02 23:29:55,633 - train - INFO - alphas:tensor([0.5397, 0.4603], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,633 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,633 - train - INFO - True
2024-04-02 23:29:55,634 - train - INFO - alphas:tensor([0.5853, 0.4147], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,634 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,635 - train - INFO - True
2024-04-02 23:29:55,636 - train - INFO - alphas:tensor([0.6648, 0.3352], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,636 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,636 - train - INFO - True
2024-04-02 23:29:55,637 - train - INFO - alphas:tensor([0.5550, 0.4450], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,637 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,638 - train - INFO - True
2024-04-02 23:29:55,638 - train - INFO - alphas:tensor([0.5120, 0.4880], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,639 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,639 - train - INFO - True
2024-04-02 23:29:55,640 - train - INFO - alphas:tensor([0.5657, 0.4343], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,640 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,640 - train - INFO - True
2024-04-02 23:29:55,641 - train - INFO - alphas:tensor([0.6328, 0.3672], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,641 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,642 - train - INFO - True
2024-04-02 23:29:55,643 - train - INFO - alphas:tensor([0.5003, 0.4997], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,643 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,643 - train - INFO - True
2024-04-02 23:29:55,644 - train - INFO - alphas:tensor([0.4696, 0.5304], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,644 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,644 - train - INFO - True
2024-04-02 23:29:55,645 - train - INFO - alphas:tensor([0.5253, 0.4747], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,645 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,646 - train - INFO - True
2024-04-02 23:29:55,647 - train - INFO - alphas:tensor([0.4700, 0.5300], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,647 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,647 - train - INFO - True
2024-04-02 23:29:55,648 - train - INFO - alphas:tensor([0.3621, 0.6379], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,648 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,648 - train - INFO - True
2024-04-02 23:29:55,649 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:29:55,650 - train - INFO - tau:0.8261686238355865
2024-04-02 23:29:55,650 - train - INFO - avg block size:4.103448275862069
2024-04-02 23:29:57,235 - train - INFO - Test: [   0/39]  Time: 1.582 (1.582)  Loss:  0.3789 (0.3789)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-04-02 23:30:59,686 - train - INFO - Test: [  39/39]  Time: 1.573 (1.601)  Loss:  0.4368 (0.3813)  Acc@1: 87.5000 (91.5300)  Acc@5: 100.0000 (99.7100)
2024-04-02 23:31:03,019 - train - INFO - Train: 22 [   0/195 (  0%)]  Loss:  1.417181 (1.4172)  Time: 3.226s,   79.36/s  (3.226s,   79.36/s)  LR: 5.218e-04  Data: 0.216 (0.216)
2024-04-02 23:33:15,498 - train - INFO - Train: 22 [  50/195 ( 26%)]  Loss:  1.399300 (1.6032)  Time: 2.446s,  104.65/s  (2.661s,   96.21/s)  LR: 5.218e-04  Data: 0.024 (0.017)
2024-04-02 23:35:32,394 - train - INFO - Train: 22 [ 100/195 ( 52%)]  Loss:  1.642232 (1.6113)  Time: 3.086s,   82.95/s  (2.699s,   94.85/s)  LR: 5.218e-04  Data: 0.019 (0.015)
2024-04-02 23:37:48,535 - train - INFO - Train: 22 [ 150/195 ( 77%)]  Loss:  1.470118 (1.6195)  Time: 3.153s,   81.19/s  (2.707s,   94.58/s)  LR: 5.218e-04  Data: 0.023 (0.015)
2024-04-02 23:39:50,666 - train - INFO - Train: 22 [ 194/195 (100%)]  Loss:  1.704924 (1.6110)  Time: 2.497s,  102.54/s  (2.722s,   94.04/s)  LR: 5.218e-04  Data: 0.000 (0.015)
2024-04-02 23:39:50,667 - train - INFO - True
2024-04-02 23:39:50,669 - train - INFO - alphas:tensor([0.3640, 0.6360], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,669 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,669 - train - INFO - True
2024-04-02 23:39:50,670 - train - INFO - alphas:tensor([0.4231, 0.5769], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,670 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,671 - train - INFO - True
2024-04-02 23:39:50,671 - train - INFO - alphas:tensor([0.6713, 0.3287], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,672 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,672 - train - INFO - True
2024-04-02 23:39:50,673 - train - INFO - alphas:tensor([0.6688, 0.3312], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,674 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,674 - train - INFO - True
2024-04-02 23:39:50,675 - train - INFO - alphas:tensor([0.4840, 0.5160], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,675 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,675 - train - INFO - True
2024-04-02 23:39:50,676 - train - INFO - alphas:tensor([0.5901, 0.4099], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,676 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,677 - train - INFO - True
2024-04-02 23:39:50,678 - train - INFO - alphas:tensor([0.7160, 0.2840], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,678 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,678 - train - INFO - True
2024-04-02 23:39:50,679 - train - INFO - alphas:tensor([0.6787, 0.3213], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,680 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,680 - train - INFO - True
2024-04-02 23:39:50,681 - train - INFO - alphas:tensor([0.5402, 0.4598], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,681 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,681 - train - INFO - True
2024-04-02 23:39:50,682 - train - INFO - alphas:tensor([0.6434, 0.3566], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,682 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,683 - train - INFO - True
2024-04-02 23:39:50,684 - train - INFO - alphas:tensor([0.7158, 0.2842], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,684 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,684 - train - INFO - True
2024-04-02 23:39:50,685 - train - INFO - alphas:tensor([0.6789, 0.3211], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,685 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,685 - train - INFO - True
2024-04-02 23:39:50,686 - train - INFO - alphas:tensor([0.5486, 0.4514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,687 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,687 - train - INFO - True
2024-04-02 23:39:50,688 - train - INFO - alphas:tensor([0.6333, 0.3667], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,688 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,688 - train - INFO - True
2024-04-02 23:39:50,689 - train - INFO - alphas:tensor([0.7003, 0.2997], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,689 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,690 - train - INFO - True
2024-04-02 23:39:50,691 - train - INFO - alphas:tensor([0.6276, 0.3724], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,691 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,691 - train - INFO - True
2024-04-02 23:39:50,692 - train - INFO - alphas:tensor([0.5319, 0.4681], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,693 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,693 - train - INFO - True
2024-04-02 23:39:50,694 - train - INFO - alphas:tensor([0.5794, 0.4206], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,694 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,694 - train - INFO - True
2024-04-02 23:39:50,695 - train - INFO - alphas:tensor([0.6613, 0.3387], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,695 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,696 - train - INFO - True
2024-04-02 23:39:50,697 - train - INFO - alphas:tensor([0.5372, 0.4628], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,697 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,697 - train - INFO - True
2024-04-02 23:39:50,698 - train - INFO - alphas:tensor([0.5003, 0.4997], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,698 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,698 - train - INFO - True
2024-04-02 23:39:50,699 - train - INFO - alphas:tensor([0.5565, 0.4435], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,700 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,700 - train - INFO - True
2024-04-02 23:39:50,701 - train - INFO - alphas:tensor([0.6258, 0.3742], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,701 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,701 - train - INFO - True
2024-04-02 23:39:50,702 - train - INFO - alphas:tensor([0.4819, 0.5181], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,702 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,703 - train - INFO - True
2024-04-02 23:39:50,704 - train - INFO - alphas:tensor([0.4588, 0.5412], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,704 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,704 - train - INFO - True
2024-04-02 23:39:50,705 - train - INFO - alphas:tensor([0.5174, 0.4826], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,705 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,706 - train - INFO - True
2024-04-02 23:39:50,706 - train - INFO - alphas:tensor([0.4539, 0.5461], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,707 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,707 - train - INFO - True
2024-04-02 23:39:50,708 - train - INFO - alphas:tensor([0.3403, 0.6597], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,708 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,708 - train - INFO - True
2024-04-02 23:39:50,709 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:39:50,709 - train - INFO - tau:0.8179069375972307
2024-04-02 23:39:50,710 - train - INFO - avg block size:4.620689655172414
2024-04-02 23:39:50,710 - train - INFO - lasso_alpha:2.357947691000002e-05
2024-04-02 23:39:52,350 - train - INFO - Test: [   0/39]  Time: 1.637 (1.637)  Loss:  0.3926 (0.3926)  Acc@1: 91.7969 (91.7969)  Acc@5: 100.0000 (100.0000)
2024-04-02 23:40:54,795 - train - INFO - Test: [  39/39]  Time: 1.635 (1.602)  Loss:  0.3289 (0.3896)  Acc@1: 81.2500 (91.7200)  Acc@5: 100.0000 (99.7100)
2024-04-02 23:40:57,684 - train - INFO - Train: 23 [   0/195 (  0%)]  Loss:  1.491752 (1.4918)  Time: 2.748s,   93.14/s  (2.748s,   93.14/s)  LR: 5.193e-04  Data: 0.344 (0.344)
2024-04-02 23:43:14,636 - train - INFO - Train: 23 [  50/195 ( 26%)]  Loss:  1.799088 (1.6433)  Time: 2.697s,   94.91/s  (2.739s,   93.46/s)  LR: 5.193e-04  Data: 0.010 (0.018)
2024-04-02 23:45:29,768 - train - INFO - Train: 23 [ 100/195 ( 52%)]  Loss:  1.770987 (1.6483)  Time: 2.632s,   97.28/s  (2.721s,   94.08/s)  LR: 5.193e-04  Data: 0.014 (0.017)
2024-04-02 23:47:45,803 - train - INFO - Train: 23 [ 150/195 ( 77%)]  Loss:  1.742515 (1.6452)  Time: 2.802s,   91.37/s  (2.721s,   94.09/s)  LR: 5.193e-04  Data: 0.006 (0.015)
2024-04-02 23:49:44,883 - train - INFO - Train: 23 [ 194/195 (100%)]  Loss:  1.765627 (1.6448)  Time: 2.454s,  104.31/s  (2.718s,   94.20/s)  LR: 5.193e-04  Data: 0.000 (0.015)
2024-04-02 23:49:44,884 - train - INFO - True
2024-04-02 23:49:44,885 - train - INFO - alphas:tensor([0.3484, 0.6516], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,885 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,890 - train - INFO - True
2024-04-02 23:49:44,890 - train - INFO - alphas:tensor([0.4099, 0.5901], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,895 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,895 - train - INFO - True
2024-04-02 23:49:44,896 - train - INFO - alphas:tensor([0.6690, 0.3310], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,896 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,896 - train - INFO - True
2024-04-02 23:49:44,896 - train - INFO - alphas:tensor([0.6638, 0.3362], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,896 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,897 - train - INFO - True
2024-04-02 23:49:44,897 - train - INFO - alphas:tensor([0.4719, 0.5281], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,897 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,897 - train - INFO - True
2024-04-02 23:49:44,898 - train - INFO - alphas:tensor([0.5817, 0.4183], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,898 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,898 - train - INFO - True
2024-04-02 23:49:44,899 - train - INFO - alphas:tensor([0.7128, 0.2872], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,900 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,900 - train - INFO - True
2024-04-02 23:49:44,901 - train - INFO - alphas:tensor([0.6704, 0.3296], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,901 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,901 - train - INFO - True
2024-04-02 23:49:44,902 - train - INFO - alphas:tensor([0.5288, 0.4712], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,907 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,907 - train - INFO - True
2024-04-02 23:49:44,907 - train - INFO - alphas:tensor([0.6364, 0.3636], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,912 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,912 - train - INFO - True
2024-04-02 23:49:44,913 - train - INFO - alphas:tensor([0.7147, 0.2853], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,917 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,917 - train - INFO - True
2024-04-02 23:49:44,918 - train - INFO - alphas:tensor([0.6698, 0.3302], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,918 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,918 - train - INFO - True
2024-04-02 23:49:44,919 - train - INFO - alphas:tensor([0.5387, 0.4613], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,919 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,919 - train - INFO - True
2024-04-02 23:49:44,919 - train - INFO - alphas:tensor([0.6258, 0.3742], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,919 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,920 - train - INFO - True
2024-04-02 23:49:44,920 - train - INFO - alphas:tensor([0.6960, 0.3040], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,934 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,934 - train - INFO - True
2024-04-02 23:49:44,935 - train - INFO - alphas:tensor([0.6125, 0.3875], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,949 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,953 - train - INFO - True
2024-04-02 23:49:44,954 - train - INFO - alphas:tensor([0.5190, 0.4810], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,954 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,954 - train - INFO - True
2024-04-02 23:49:44,955 - train - INFO - alphas:tensor([0.5679, 0.4321], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,955 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,955 - train - INFO - True
2024-04-02 23:49:44,956 - train - INFO - alphas:tensor([0.6547, 0.3453], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,956 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,956 - train - INFO - True
2024-04-02 23:49:44,956 - train - INFO - alphas:tensor([0.5151, 0.4849], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,971 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,971 - train - INFO - True
2024-04-02 23:49:44,972 - train - INFO - alphas:tensor([0.4918, 0.5082], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,972 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,972 - train - INFO - True
2024-04-02 23:49:44,973 - train - INFO - alphas:tensor([0.5486, 0.4514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,973 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,973 - train - INFO - True
2024-04-02 23:49:44,974 - train - INFO - alphas:tensor([0.6177, 0.3823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,974 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,974 - train - INFO - True
2024-04-02 23:49:44,975 - train - INFO - alphas:tensor([0.4625, 0.5375], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,975 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,975 - train - INFO - True
2024-04-02 23:49:44,976 - train - INFO - alphas:tensor([0.4453, 0.5547], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,976 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,976 - train - INFO - True
2024-04-02 23:49:44,977 - train - INFO - alphas:tensor([0.5034, 0.4966], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,977 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,977 - train - INFO - True
2024-04-02 23:49:44,977 - train - INFO - alphas:tensor([0.4320, 0.5680], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,977 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,978 - train - INFO - True
2024-04-02 23:49:44,978 - train - INFO - alphas:tensor([0.3145, 0.6855], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,978 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,978 - train - INFO - True
2024-04-02 23:49:44,979 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:49:44,979 - train - INFO - tau:0.8097278682212583
2024-04-02 23:49:44,979 - train - INFO - avg block size:5.137931034482759
2024-04-02 23:49:46,666 - train - INFO - Test: [   0/39]  Time: 1.680 (1.680)  Loss:  0.3945 (0.3945)  Acc@1: 92.1875 (92.1875)  Acc@5: 99.6094 (99.6094)
2024-04-02 23:50:49,042 - train - INFO - Test: [  39/39]  Time: 1.648 (1.601)  Loss:  0.4819 (0.4068)  Acc@1: 87.5000 (91.0400)  Acc@5: 100.0000 (99.6700)
2024-04-02 23:50:52,583 - train - INFO - Train: 24 [   0/195 (  0%)]  Loss:  1.823073 (1.8231)  Time: 3.268s,   78.34/s  (3.268s,   78.34/s)  LR: 5.166e-04  Data: 0.278 (0.278)
2024-04-02 23:53:10,124 - train - INFO - Train: 24 [  50/195 ( 26%)]  Loss:  1.540258 (1.6652)  Time: 2.715s,   94.27/s  (2.761s,   92.73/s)  LR: 5.166e-04  Data: 0.014 (0.018)
2024-04-02 23:55:26,065 - train - INFO - Train: 24 [ 100/195 ( 52%)]  Loss:  1.848292 (1.6582)  Time: 2.492s,  102.73/s  (2.740s,   93.43/s)  LR: 5.166e-04  Data: 0.014 (0.015)
2024-04-02 23:57:46,273 - train - INFO - Train: 24 [ 150/195 ( 77%)]  Loss:  1.668101 (1.6447)  Time: 2.591s,   98.80/s  (2.761s,   92.71/s)  LR: 5.166e-04  Data: 0.009 (0.014)
2024-04-02 23:59:50,294 - train - INFO - Train: 24 [ 194/195 (100%)]  Loss:  1.311197 (1.6352)  Time: 2.758s,   92.83/s  (2.774s,   92.28/s)  LR: 5.166e-04  Data: 0.000 (0.013)
2024-04-02 23:59:50,295 - train - INFO - True
2024-04-02 23:59:50,296 - train - INFO - alphas:tensor([0.3342, 0.6658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,296 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,296 - train - INFO - True
2024-04-02 23:59:50,297 - train - INFO - alphas:tensor([0.3998, 0.6002], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,297 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,297 - train - INFO - True
2024-04-02 23:59:50,297 - train - INFO - alphas:tensor([0.6676, 0.3324], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,297 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,298 - train - INFO - True
2024-04-02 23:59:50,298 - train - INFO - alphas:tensor([0.6601, 0.3399], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,298 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,298 - train - INFO - True
2024-04-02 23:59:50,299 - train - INFO - alphas:tensor([0.4627, 0.5373], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,299 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,299 - train - INFO - True
2024-04-02 23:59:50,300 - train - INFO - alphas:tensor([0.5763, 0.4237], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,300 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,300 - train - INFO - True
2024-04-02 23:59:50,301 - train - INFO - alphas:tensor([0.7096, 0.2904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,301 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,301 - train - INFO - True
2024-04-02 23:59:50,301 - train - INFO - alphas:tensor([0.6626, 0.3374], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,302 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,302 - train - INFO - True
2024-04-02 23:59:50,302 - train - INFO - alphas:tensor([0.5201, 0.4799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,311 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,311 - train - INFO - True
2024-04-02 23:59:50,312 - train - INFO - alphas:tensor([0.6325, 0.3675], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,312 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,312 - train - INFO - True
2024-04-02 23:59:50,313 - train - INFO - alphas:tensor([0.7125, 0.2875], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,313 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,313 - train - INFO - True
2024-04-02 23:59:50,314 - train - INFO - alphas:tensor([0.6597, 0.3403], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,314 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,314 - train - INFO - True
2024-04-02 23:59:50,315 - train - INFO - alphas:tensor([0.5330, 0.4670], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,315 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,315 - train - INFO - True
2024-04-02 23:59:50,315 - train - INFO - alphas:tensor([0.6243, 0.3757], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,315 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,316 - train - INFO - True
2024-04-02 23:59:50,316 - train - INFO - alphas:tensor([0.6923, 0.3077], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,316 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,316 - train - INFO - True
2024-04-02 23:59:50,317 - train - INFO - alphas:tensor([0.5975, 0.4025], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,317 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,317 - train - INFO - True
2024-04-02 23:59:50,318 - train - INFO - alphas:tensor([0.5123, 0.4877], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,318 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,318 - train - INFO - True
2024-04-02 23:59:50,319 - train - INFO - alphas:tensor([0.5622, 0.4378], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,319 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,319 - train - INFO - True
2024-04-02 23:59:50,319 - train - INFO - alphas:tensor([0.6487, 0.3513], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,320 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,320 - train - INFO - True
2024-04-02 23:59:50,321 - train - INFO - alphas:tensor([0.5002, 0.4998], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,321 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,321 - train - INFO - True
2024-04-02 23:59:50,321 - train - INFO - alphas:tensor([0.4802, 0.5198], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,321 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,322 - train - INFO - True
2024-04-02 23:59:50,322 - train - INFO - alphas:tensor([0.5394, 0.4606], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,322 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,322 - train - INFO - True
2024-04-02 23:59:50,323 - train - INFO - alphas:tensor([0.6082, 0.3918], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,323 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,323 - train - INFO - True
2024-04-02 23:59:50,324 - train - INFO - alphas:tensor([0.4455, 0.5545], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,324 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,324 - train - INFO - True
2024-04-02 23:59:50,325 - train - INFO - alphas:tensor([0.4351, 0.5649], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,325 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,325 - train - INFO - True
2024-04-02 23:59:50,325 - train - INFO - alphas:tensor([0.4888, 0.5112], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,325 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,326 - train - INFO - True
2024-04-02 23:59:50,326 - train - INFO - alphas:tensor([0.4145, 0.5855], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,326 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,326 - train - INFO - True
2024-04-02 23:59:50,327 - train - INFO - alphas:tensor([0.2924, 0.7076], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,327 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,327 - train - INFO - True
2024-04-02 23:59:50,328 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-02 23:59:50,328 - train - INFO - tau:0.8016305895390458
2024-04-02 23:59:50,328 - train - INFO - avg block size:5.655172413793103
2024-04-02 23:59:50,328 - train - INFO - lasso_alpha:2.5937424601000023e-05
2024-04-02 23:59:51,929 - train - INFO - Test: [   0/39]  Time: 1.598 (1.598)  Loss:  0.4104 (0.4104)  Acc@1: 90.2344 (90.2344)  Acc@5: 100.0000 (100.0000)
2024-04-03 00:00:56,588 - train - INFO - Test: [  39/39]  Time: 1.870 (1.656)  Loss:  0.4958 (0.4078)  Acc@1: 81.2500 (91.0300)  Acc@5: 100.0000 (99.6700)
2024-04-03 00:01:00,668 - train - INFO - Train: 25 [   0/195 (  0%)]  Loss:  1.467647 (1.4676)  Time: 3.739s,   68.47/s  (3.739s,   68.47/s)  LR: 5.138e-04  Data: 0.493 (0.493)
2024-04-03 00:03:18,055 - train - INFO - Train: 25 [  50/195 ( 26%)]  Loss:  1.846342 (1.6862)  Time: 2.821s,   90.76/s  (2.767s,   92.51/s)  LR: 5.138e-04  Data: 0.014 (0.024)
2024-04-03 00:05:37,867 - train - INFO - Train: 25 [ 100/195 ( 52%)]  Loss:  1.535692 (1.6438)  Time: 2.269s,  112.84/s  (2.782s,   92.04/s)  LR: 5.138e-04  Data: 0.018 (0.018)
2024-04-03 00:07:56,547 - train - INFO - Train: 25 [ 150/195 ( 77%)]  Loss:  1.836263 (1.6453)  Time: 2.481s,  103.17/s  (2.779s,   92.12/s)  LR: 5.138e-04  Data: 0.032 (0.017)
2024-04-03 00:09:59,593 - train - INFO - Train: 25 [ 194/195 (100%)]  Loss:  1.679380 (1.6497)  Time: 3.138s,   81.58/s  (2.783s,   91.99/s)  LR: 5.138e-04  Data: 0.000 (0.016)
2024-04-03 00:09:59,594 - train - INFO - True
2024-04-03 00:09:59,595 - train - INFO - alphas:tensor([0.3183, 0.6817], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,595 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,595 - train - INFO - True
2024-04-03 00:09:59,596 - train - INFO - alphas:tensor([0.3857, 0.6143], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,596 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,596 - train - INFO - True
2024-04-03 00:09:59,596 - train - INFO - alphas:tensor([0.6662, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,597 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,597 - train - INFO - True
2024-04-03 00:09:59,602 - train - INFO - alphas:tensor([0.6568, 0.3432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,602 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,602 - train - INFO - True
2024-04-03 00:09:59,603 - train - INFO - alphas:tensor([0.4522, 0.5478], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,603 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,603 - train - INFO - True
2024-04-03 00:09:59,603 - train - INFO - alphas:tensor([0.5686, 0.4314], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,603 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,604 - train - INFO - True
2024-04-03 00:09:59,604 - train - INFO - alphas:tensor([0.7056, 0.2944], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,627 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,627 - train - INFO - True
2024-04-03 00:09:59,628 - train - INFO - alphas:tensor([0.6523, 0.3477], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,636 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,636 - train - INFO - True
2024-04-03 00:09:59,650 - train - INFO - alphas:tensor([0.5117, 0.4883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,650 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,650 - train - INFO - True
2024-04-03 00:09:59,651 - train - INFO - alphas:tensor([0.6269, 0.3731], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,651 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,651 - train - INFO - True
2024-04-03 00:09:59,652 - train - INFO - alphas:tensor([0.7080, 0.2920], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,652 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,652 - train - INFO - True
2024-04-03 00:09:59,653 - train - INFO - alphas:tensor([0.6445, 0.3555], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,654 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,654 - train - INFO - True
2024-04-03 00:09:59,655 - train - INFO - alphas:tensor([0.5226, 0.4774], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,655 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,655 - train - INFO - True
2024-04-03 00:09:59,656 - train - INFO - alphas:tensor([0.6158, 0.3842], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,660 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,661 - train - INFO - True
2024-04-03 00:09:59,661 - train - INFO - alphas:tensor([0.6879, 0.3121], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,661 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,661 - train - INFO - True
2024-04-03 00:09:59,662 - train - INFO - alphas:tensor([0.5818, 0.4182], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,662 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,662 - train - INFO - True
2024-04-03 00:09:59,663 - train - INFO - alphas:tensor([0.5005, 0.4995], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,663 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,663 - train - INFO - True
2024-04-03 00:09:59,664 - train - INFO - alphas:tensor([0.5509, 0.4491], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,686 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,686 - train - INFO - True
2024-04-03 00:09:59,687 - train - INFO - alphas:tensor([0.6405, 0.3595], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,687 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,687 - train - INFO - True
2024-04-03 00:09:59,687 - train - INFO - alphas:tensor([0.4812, 0.5188], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,688 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,688 - train - INFO - True
2024-04-03 00:09:59,706 - train - INFO - alphas:tensor([0.4658, 0.5342], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,719 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,719 - train - INFO - True
2024-04-03 00:09:59,720 - train - INFO - alphas:tensor([0.5268, 0.4732], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,720 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,720 - train - INFO - True
2024-04-03 00:09:59,721 - train - INFO - alphas:tensor([0.5994, 0.4006], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,725 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,725 - train - INFO - True
2024-04-03 00:09:59,726 - train - INFO - alphas:tensor([0.4281, 0.5719], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,726 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,726 - train - INFO - True
2024-04-03 00:09:59,727 - train - INFO - alphas:tensor([0.4202, 0.5798], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,727 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,727 - train - INFO - True
2024-04-03 00:09:59,728 - train - INFO - alphas:tensor([0.4736, 0.5264], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,728 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,728 - train - INFO - True
2024-04-03 00:09:59,729 - train - INFO - alphas:tensor([0.3916, 0.6084], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,729 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,729 - train - INFO - True
2024-04-03 00:09:59,729 - train - INFO - alphas:tensor([0.2672, 0.7328], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,729 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,736 - train - INFO - True
2024-04-03 00:09:59,737 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:09:59,737 - train - INFO - tau:0.7936142836436553
2024-04-03 00:09:59,737 - train - INFO - avg block size:6.172413793103448
2024-04-03 00:10:01,304 - train - INFO - Test: [   0/39]  Time: 1.564 (1.564)  Loss:  0.3823 (0.3823)  Acc@1: 91.4062 (91.4062)  Acc@5: 99.6094 (99.6094)
2024-04-03 00:11:04,602 - train - INFO - Test: [  39/39]  Time: 1.679 (1.622)  Loss:  0.3906 (0.3851)  Acc@1: 87.5000 (91.5900)  Acc@5: 100.0000 (99.7400)
2024-04-03 00:11:07,986 - train - INFO - Train: 26 [   0/195 (  0%)]  Loss:  1.800297 (1.8003)  Time: 3.171s,   80.73/s  (3.171s,   80.73/s)  LR: 5.109e-04  Data: 0.461 (0.461)
2024-04-03 00:13:30,265 - train - INFO - Train: 26 [  50/195 ( 26%)]  Loss:  1.863750 (1.6287)  Time: 3.287s,   77.87/s  (2.852s,   89.76/s)  LR: 5.109e-04  Data: 0.023 (0.021)
2024-04-03 00:15:52,628 - train - INFO - Train: 26 [ 100/195 ( 52%)]  Loss:  1.808504 (1.6206)  Time: 2.866s,   89.32/s  (2.850s,   89.84/s)  LR: 5.109e-04  Data: 0.018 (0.018)
2024-04-03 00:18:12,398 - train - INFO - Train: 26 [ 150/195 ( 77%)]  Loss:  1.345010 (1.6235)  Time: 2.637s,   97.07/s  (2.832s,   90.41/s)  LR: 5.109e-04  Data: 0.007 (0.017)
2024-04-03 00:20:14,842 - train - INFO - Train: 26 [ 194/195 (100%)]  Loss:  1.826912 (1.6177)  Time: 2.621s,   97.66/s  (2.821s,   90.76/s)  LR: 5.109e-04  Data: 0.000 (0.015)
2024-04-03 00:20:14,842 - train - INFO - True
2024-04-03 00:20:14,844 - train - INFO - alphas:tensor([0.3033, 0.6967], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,844 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,844 - train - INFO - True
2024-04-03 00:20:14,846 - train - INFO - alphas:tensor([0.3714, 0.6286], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,846 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,846 - train - INFO - True
2024-04-03 00:20:14,852 - train - INFO - alphas:tensor([0.6656, 0.3344], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,852 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,852 - train - INFO - True
2024-04-03 00:20:14,854 - train - INFO - alphas:tensor([0.6543, 0.3457], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,854 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,854 - train - INFO - True
2024-04-03 00:20:14,855 - train - INFO - alphas:tensor([0.4390, 0.5610], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,856 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,856 - train - INFO - True
2024-04-03 00:20:14,857 - train - INFO - alphas:tensor([0.5597, 0.4403], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,857 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,857 - train - INFO - True
2024-04-03 00:20:14,859 - train - INFO - alphas:tensor([0.7027, 0.2973], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,859 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,859 - train - INFO - True
2024-04-03 00:20:14,860 - train - INFO - alphas:tensor([0.6445, 0.3555], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,860 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,860 - train - INFO - True
2024-04-03 00:20:14,862 - train - INFO - alphas:tensor([0.5035, 0.4965], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,862 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,862 - train - INFO - True
2024-04-03 00:20:14,863 - train - INFO - alphas:tensor([0.6204, 0.3796], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,864 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,864 - train - INFO - True
2024-04-03 00:20:14,865 - train - INFO - alphas:tensor([0.7060, 0.2940], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,865 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,865 - train - INFO - True
2024-04-03 00:20:14,866 - train - INFO - alphas:tensor([0.6335, 0.3665], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,867 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,867 - train - INFO - True
2024-04-03 00:20:14,868 - train - INFO - alphas:tensor([0.5133, 0.4867], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,868 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,868 - train - INFO - True
2024-04-03 00:20:14,874 - train - INFO - alphas:tensor([0.6094, 0.3906], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,874 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,874 - train - INFO - True
2024-04-03 00:20:14,876 - train - INFO - alphas:tensor([0.6828, 0.3172], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,876 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,876 - train - INFO - True
2024-04-03 00:20:14,877 - train - INFO - alphas:tensor([0.5659, 0.4341], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,877 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,877 - train - INFO - True
2024-04-03 00:20:14,879 - train - INFO - alphas:tensor([0.4917, 0.5083], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,879 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,879 - train - INFO - True
2024-04-03 00:20:14,880 - train - INFO - alphas:tensor([0.5445, 0.4555], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,880 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,880 - train - INFO - True
2024-04-03 00:20:14,882 - train - INFO - alphas:tensor([0.6326, 0.3674], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,882 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,882 - train - INFO - True
2024-04-03 00:20:14,883 - train - INFO - alphas:tensor([0.4654, 0.5346], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,884 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,884 - train - INFO - True
2024-04-03 00:20:14,884 - train - INFO - alphas:tensor([0.4544, 0.5456], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,884 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,884 - train - INFO - True
2024-04-03 00:20:14,885 - train - INFO - alphas:tensor([0.5167, 0.4833], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,885 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,885 - train - INFO - True
2024-04-03 00:20:14,886 - train - INFO - alphas:tensor([0.5919, 0.4081], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,886 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,886 - train - INFO - True
2024-04-03 00:20:14,887 - train - INFO - alphas:tensor([0.4162, 0.5838], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,887 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,887 - train - INFO - True
2024-04-03 00:20:14,887 - train - INFO - alphas:tensor([0.4078, 0.5922], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,888 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,888 - train - INFO - True
2024-04-03 00:20:14,888 - train - INFO - alphas:tensor([0.4595, 0.5405], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,888 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,888 - train - INFO - True
2024-04-03 00:20:14,889 - train - INFO - alphas:tensor([0.3739, 0.6261], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,889 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,889 - train - INFO - True
2024-04-03 00:20:14,890 - train - INFO - alphas:tensor([0.2459, 0.7541], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,890 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,890 - train - INFO - True
2024-04-03 00:20:14,891 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:20:14,891 - train - INFO - tau:0.7856781408072188
2024-04-03 00:20:14,891 - train - INFO - avg block size:6.689655172413793
2024-04-03 00:20:14,891 - train - INFO - lasso_alpha:2.8531167061100026e-05
2024-04-03 00:20:16,655 - train - INFO - Test: [   0/39]  Time: 1.761 (1.761)  Loss:  0.4182 (0.4182)  Acc@1: 89.8438 (89.8438)  Acc@5: 99.6094 (99.6094)
2024-04-03 00:21:21,608 - train - INFO - Test: [  39/39]  Time: 1.685 (1.668)  Loss:  0.4575 (0.3916)  Acc@1: 81.2500 (91.3400)  Acc@5: 100.0000 (99.7600)
2024-04-03 00:21:24,700 - train - INFO - Train: 27 [   0/195 (  0%)]  Loss:  1.810830 (1.8108)  Time: 2.893s,   88.49/s  (2.893s,   88.49/s)  LR: 5.080e-04  Data: 0.193 (0.193)
2024-04-03 00:23:44,203 - train - INFO - Train: 27 [  50/195 ( 26%)]  Loss:  1.956486 (1.6856)  Time: 2.629s,   97.36/s  (2.792s,   91.69/s)  LR: 5.080e-04  Data: 0.006 (0.017)
2024-04-03 00:26:06,372 - train - INFO - Train: 27 [ 100/195 ( 52%)]  Loss:  1.806659 (1.6594)  Time: 2.533s,  101.06/s  (2.817s,   90.86/s)  LR: 5.080e-04  Data: 0.010 (0.016)
2024-04-03 00:28:27,918 - train - INFO - Train: 27 [ 150/195 ( 77%)]  Loss:  1.528276 (1.6541)  Time: 2.478s,  103.30/s  (2.822s,   90.72/s)  LR: 5.080e-04  Data: 0.006 (0.016)
2024-04-03 00:30:32,699 - train - INFO - Train: 27 [ 194/195 (100%)]  Loss:  1.897023 (1.6579)  Time: 2.773s,   92.33/s  (2.825s,   90.62/s)  LR: 5.080e-04  Data: 0.000 (0.016)
2024-04-03 00:30:32,700 - train - INFO - True
2024-04-03 00:30:32,702 - train - INFO - alphas:tensor([0.2871, 0.7129], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,702 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,702 - train - INFO - True
2024-04-03 00:30:32,703 - train - INFO - alphas:tensor([0.3579, 0.6421], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,703 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,703 - train - INFO - True
2024-04-03 00:30:32,703 - train - INFO - alphas:tensor([0.6614, 0.3386], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,703 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,704 - train - INFO - True
2024-04-03 00:30:32,704 - train - INFO - alphas:tensor([0.6471, 0.3529], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,704 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,704 - train - INFO - True
2024-04-03 00:30:32,705 - train - INFO - alphas:tensor([0.4296, 0.5704], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,709 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,710 - train - INFO - True
2024-04-03 00:30:32,711 - train - INFO - alphas:tensor([0.5498, 0.4502], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,711 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,712 - train - INFO - True
2024-04-03 00:30:32,713 - train - INFO - alphas:tensor([0.6971, 0.3029], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,713 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,713 - train - INFO - True
2024-04-03 00:30:32,714 - train - INFO - alphas:tensor([0.6325, 0.3675], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,714 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,714 - train - INFO - True
2024-04-03 00:30:32,715 - train - INFO - alphas:tensor([0.4924, 0.5076], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,715 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,715 - train - INFO - True
2024-04-03 00:30:32,716 - train - INFO - alphas:tensor([0.6137, 0.3863], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,716 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,716 - train - INFO - True
2024-04-03 00:30:32,716 - train - INFO - alphas:tensor([0.7008, 0.2992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,717 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,717 - train - INFO - True
2024-04-03 00:30:32,717 - train - INFO - alphas:tensor([0.6184, 0.3816], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,717 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,717 - train - INFO - True
2024-04-03 00:30:32,718 - train - INFO - alphas:tensor([0.5048, 0.4952], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,718 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,718 - train - INFO - True
2024-04-03 00:30:32,719 - train - INFO - alphas:tensor([0.6035, 0.3965], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,719 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,719 - train - INFO - True
2024-04-03 00:30:32,720 - train - INFO - alphas:tensor([0.6766, 0.3234], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,720 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,720 - train - INFO - True
2024-04-03 00:30:32,721 - train - INFO - alphas:tensor([0.5482, 0.4518], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,721 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,721 - train - INFO - True
2024-04-03 00:30:32,721 - train - INFO - alphas:tensor([0.4807, 0.5193], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,721 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,722 - train - INFO - True
2024-04-03 00:30:32,722 - train - INFO - alphas:tensor([0.5336, 0.4664], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,722 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,722 - train - INFO - True
2024-04-03 00:30:32,727 - train - INFO - alphas:tensor([0.6240, 0.3760], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,728 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,728 - train - INFO - True
2024-04-03 00:30:32,728 - train - INFO - alphas:tensor([0.4489, 0.5511], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,728 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,728 - train - INFO - True
2024-04-03 00:30:32,729 - train - INFO - alphas:tensor([0.4429, 0.5571], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,729 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,729 - train - INFO - True
2024-04-03 00:30:32,730 - train - INFO - alphas:tensor([0.5018, 0.4982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,730 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,730 - train - INFO - True
2024-04-03 00:30:32,731 - train - INFO - alphas:tensor([0.5806, 0.4194], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,731 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,731 - train - INFO - True
2024-04-03 00:30:32,731 - train - INFO - alphas:tensor([0.4005, 0.5995], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,732 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,732 - train - INFO - True
2024-04-03 00:30:32,733 - train - INFO - alphas:tensor([0.3948, 0.6052], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,733 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,733 - train - INFO - True
2024-04-03 00:30:32,734 - train - INFO - alphas:tensor([0.4437, 0.5563], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,734 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,734 - train - INFO - True
2024-04-03 00:30:32,740 - train - INFO - alphas:tensor([0.3546, 0.6454], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,740 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,740 - train - INFO - True
2024-04-03 00:30:32,740 - train - INFO - alphas:tensor([0.2232, 0.7768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,740 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,741 - train - INFO - True
2024-04-03 00:30:32,741 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:30:32,741 - train - INFO - tau:0.7778213593991465
2024-04-03 00:30:32,741 - train - INFO - avg block size:7.206896551724138
2024-04-03 00:30:34,283 - train - INFO - Test: [   0/39]  Time: 1.539 (1.539)  Loss:  0.4111 (0.4111)  Acc@1: 89.4531 (89.4531)  Acc@5: 99.2188 (99.2188)
2024-04-03 00:31:38,586 - train - INFO - Test: [  39/39]  Time: 1.650 (1.646)  Loss:  0.4634 (0.3928)  Acc@1: 81.2500 (91.1500)  Acc@5: 100.0000 (99.6400)
2024-04-03 00:31:41,525 - train - INFO - Train: 28 [   0/195 (  0%)]  Loss:  1.803209 (1.8032)  Time: 2.749s,   93.11/s  (2.749s,   93.11/s)  LR: 5.049e-04  Data: 0.343 (0.343)
2024-04-03 00:34:00,496 - train - INFO - Train: 28 [  50/195 ( 26%)]  Loss:  1.863539 (1.6853)  Time: 2.604s,   98.32/s  (2.779s,   92.13/s)  LR: 5.049e-04  Data: 0.005 (0.021)
2024-04-03 00:36:20,466 - train - INFO - Train: 28 [ 100/195 ( 52%)]  Loss:  1.771478 (1.6659)  Time: 3.060s,   83.66/s  (2.789s,   91.79/s)  LR: 5.049e-04  Data: 0.021 (0.019)
2024-04-03 00:38:42,801 - train - INFO - Train: 28 [ 150/195 ( 77%)]  Loss:  1.360278 (1.6685)  Time: 3.250s,   78.78/s  (2.808s,   91.17/s)  LR: 5.049e-04  Data: 0.021 (0.018)
2024-04-03 00:40:46,463 - train - INFO - Train: 28 [ 194/195 (100%)]  Loss:  1.816888 (1.6675)  Time: 3.227s,   79.33/s  (2.809s,   91.15/s)  LR: 5.049e-04  Data: 0.000 (0.017)
2024-04-03 00:40:46,464 - train - INFO - True
2024-04-03 00:40:46,465 - train - INFO - alphas:tensor([0.2736, 0.7264], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,465 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,465 - train - INFO - True
2024-04-03 00:40:46,466 - train - INFO - alphas:tensor([0.3448, 0.6552], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,466 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,466 - train - INFO - True
2024-04-03 00:40:46,468 - train - INFO - alphas:tensor([0.6569, 0.3431], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,468 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,468 - train - INFO - True
2024-04-03 00:40:46,469 - train - INFO - alphas:tensor([0.6404, 0.3596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,469 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,469 - train - INFO - True
2024-04-03 00:40:46,471 - train - INFO - alphas:tensor([0.4173, 0.5827], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,471 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,471 - train - INFO - True
2024-04-03 00:40:46,473 - train - INFO - alphas:tensor([0.5398, 0.4602], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,473 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,473 - train - INFO - True
2024-04-03 00:40:46,474 - train - INFO - alphas:tensor([0.6912, 0.3088], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,474 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,475 - train - INFO - True
2024-04-03 00:40:46,485 - train - INFO - alphas:tensor([0.6195, 0.3805], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,485 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,485 - train - INFO - True
2024-04-03 00:40:46,486 - train - INFO - alphas:tensor([0.4828, 0.5172], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,486 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,486 - train - INFO - True
2024-04-03 00:40:46,488 - train - INFO - alphas:tensor([0.6074, 0.3926], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,488 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,488 - train - INFO - True
2024-04-03 00:40:46,488 - train - INFO - alphas:tensor([0.6975, 0.3025], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,489 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,489 - train - INFO - True
2024-04-03 00:40:46,489 - train - INFO - alphas:tensor([0.6054, 0.3946], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,489 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,489 - train - INFO - True
2024-04-03 00:40:46,490 - train - INFO - alphas:tensor([0.4947, 0.5053], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,490 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,490 - train - INFO - True
2024-04-03 00:40:46,491 - train - INFO - alphas:tensor([0.5954, 0.4046], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,491 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,491 - train - INFO - True
2024-04-03 00:40:46,492 - train - INFO - alphas:tensor([0.6721, 0.3279], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,492 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,492 - train - INFO - True
2024-04-03 00:40:46,493 - train - INFO - alphas:tensor([0.5378, 0.4622], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,493 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,493 - train - INFO - True
2024-04-03 00:40:46,495 - train - INFO - alphas:tensor([0.4716, 0.5284], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,495 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,495 - train - INFO - True
2024-04-03 00:40:46,496 - train - INFO - alphas:tensor([0.5242, 0.4758], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,496 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,497 - train - INFO - True
2024-04-03 00:40:46,498 - train - INFO - alphas:tensor([0.6136, 0.3864], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,498 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,498 - train - INFO - True
2024-04-03 00:40:46,499 - train - INFO - alphas:tensor([0.4341, 0.5659], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,500 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,500 - train - INFO - True
2024-04-03 00:40:46,501 - train - INFO - alphas:tensor([0.4318, 0.5682], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,501 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,501 - train - INFO - True
2024-04-03 00:40:46,502 - train - INFO - alphas:tensor([0.4911, 0.5089], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,503 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,503 - train - INFO - True
2024-04-03 00:40:46,504 - train - INFO - alphas:tensor([0.5710, 0.4290], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,504 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,504 - train - INFO - True
2024-04-03 00:40:46,505 - train - INFO - alphas:tensor([0.3852, 0.6148], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,505 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,506 - train - INFO - True
2024-04-03 00:40:46,508 - train - INFO - alphas:tensor([0.3819, 0.6181], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,508 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,508 - train - INFO - True
2024-04-03 00:40:46,520 - train - INFO - alphas:tensor([0.4268, 0.5732], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,520 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,520 - train - INFO - True
2024-04-03 00:40:46,521 - train - INFO - alphas:tensor([0.3351, 0.6649], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,521 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,521 - train - INFO - True
2024-04-03 00:40:46,538 - train - INFO - alphas:tensor([0.2024, 0.7976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,538 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,538 - train - INFO - True
2024-04-03 00:40:46,557 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:40:46,557 - train - INFO - tau:0.7700431458051551
2024-04-03 00:40:46,557 - train - INFO - avg block size:8.241379310344827
2024-04-03 00:40:48,173 - train - INFO - Test: [   0/39]  Time: 1.604 (1.604)  Loss:  0.4004 (0.4004)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-04-03 00:41:53,212 - train - INFO - Test: [  39/39]  Time: 1.673 (1.666)  Loss:  0.3984 (0.4064)  Acc@1: 81.2500 (90.9800)  Acc@5: 100.0000 (99.7100)
2024-04-03 00:41:56,871 - train - INFO - Train: 29 [   0/195 (  0%)]  Loss:  1.885513 (1.8855)  Time: 3.313s,   77.26/s  (3.313s,   77.26/s)  LR: 5.017e-04  Data: 0.312 (0.312)
2024-04-03 00:44:13,802 - train - INFO - Train: 29 [  50/195 ( 26%)]  Loss:  1.749446 (1.6827)  Time: 2.408s,  106.33/s  (2.750s,   93.10/s)  LR: 5.017e-04  Data: 0.010 (0.017)
2024-04-03 00:46:27,500 - train - INFO - Train: 29 [ 100/195 ( 52%)]  Loss:  1.325398 (1.6682)  Time: 2.839s,   90.17/s  (2.712s,   94.39/s)  LR: 5.017e-04  Data: 0.016 (0.016)
2024-04-03 00:48:45,818 - train - INFO - Train: 29 [ 150/195 ( 77%)]  Loss:  1.801755 (1.6507)  Time: 3.026s,   84.61/s  (2.730s,   93.77/s)  LR: 5.017e-04  Data: 0.010 (0.015)
2024-04-03 00:50:46,090 - train - INFO - Train: 29 [ 194/195 (100%)]  Loss:  1.730999 (1.6532)  Time: 2.956s,   86.60/s  (2.731s,   93.74/s)  LR: 5.017e-04  Data: 0.000 (0.014)
2024-04-03 00:50:46,091 - train - INFO - True
2024-04-03 00:50:46,101 - train - INFO - alphas:tensor([0.2583, 0.7417], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,102 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,102 - train - INFO - True
2024-04-03 00:50:46,103 - train - INFO - alphas:tensor([0.3324, 0.6676], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,103 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,103 - train - INFO - True
2024-04-03 00:50:46,105 - train - INFO - alphas:tensor([0.6562, 0.3438], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,105 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,105 - train - INFO - True
2024-04-03 00:50:46,107 - train - INFO - alphas:tensor([0.6370, 0.3630], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,108 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,108 - train - INFO - True
2024-04-03 00:50:46,121 - train - INFO - alphas:tensor([0.4076, 0.5924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,121 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,121 - train - INFO - True
2024-04-03 00:50:46,136 - train - INFO - alphas:tensor([0.5349, 0.4651], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,136 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,136 - train - INFO - True
2024-04-03 00:50:46,143 - train - INFO - alphas:tensor([0.6895, 0.3105], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,143 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,147 - train - INFO - True
2024-04-03 00:50:46,149 - train - INFO - alphas:tensor([0.6142, 0.3858], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,149 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,149 - train - INFO - True
2024-04-03 00:50:46,150 - train - INFO - alphas:tensor([0.4762, 0.5238], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,150 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,150 - train - INFO - True
2024-04-03 00:50:46,151 - train - INFO - alphas:tensor([0.6009, 0.3991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,151 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,152 - train - INFO - True
2024-04-03 00:50:46,157 - train - INFO - alphas:tensor([0.6937, 0.3063], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,157 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,157 - train - INFO - True
2024-04-03 00:50:46,159 - train - INFO - alphas:tensor([0.5955, 0.4045], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,159 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,159 - train - INFO - True
2024-04-03 00:50:46,160 - train - INFO - alphas:tensor([0.4861, 0.5139], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,160 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,160 - train - INFO - True
2024-04-03 00:50:46,162 - train - INFO - alphas:tensor([0.5905, 0.4095], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,162 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,162 - train - INFO - True
2024-04-03 00:50:46,168 - train - INFO - alphas:tensor([0.6674, 0.3326], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,168 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,168 - train - INFO - True
2024-04-03 00:50:46,169 - train - INFO - alphas:tensor([0.5318, 0.4682], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,169 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,169 - train - INFO - True
2024-04-03 00:50:46,175 - train - INFO - alphas:tensor([0.4613, 0.5387], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,175 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,175 - train - INFO - True
2024-04-03 00:50:46,177 - train - INFO - alphas:tensor([0.5133, 0.4867], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,177 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,177 - train - INFO - True
2024-04-03 00:50:46,178 - train - INFO - alphas:tensor([0.6066, 0.3934], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,178 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,178 - train - INFO - True
2024-04-03 00:50:46,180 - train - INFO - alphas:tensor([0.4254, 0.5746], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,180 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,180 - train - INFO - True
2024-04-03 00:50:46,181 - train - INFO - alphas:tensor([0.4235, 0.5765], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,181 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,182 - train - INFO - True
2024-04-03 00:50:46,183 - train - INFO - alphas:tensor([0.4836, 0.5164], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,183 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,183 - train - INFO - True
2024-04-03 00:50:46,184 - train - INFO - alphas:tensor([0.5618, 0.4382], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,184 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,185 - train - INFO - True
2024-04-03 00:50:46,195 - train - INFO - alphas:tensor([0.3744, 0.6256], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,195 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,195 - train - INFO - True
2024-04-03 00:50:46,196 - train - INFO - alphas:tensor([0.3705, 0.6295], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,196 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,196 - train - INFO - True
2024-04-03 00:50:46,198 - train - INFO - alphas:tensor([0.4131, 0.5869], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,198 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,198 - train - INFO - True
2024-04-03 00:50:46,199 - train - INFO - alphas:tensor([0.3196, 0.6804], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,199 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,199 - train - INFO - True
2024-04-03 00:50:46,201 - train - INFO - alphas:tensor([0.1852, 0.8148], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,201 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,201 - train - INFO - True
2024-04-03 00:50:46,204 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 00:50:46,204 - train - INFO - tau:0.7623427143471035
2024-04-03 00:50:46,204 - train - INFO - avg block size:8.241379310344827
2024-04-03 00:50:47,937 - train - INFO - Test: [   0/39]  Time: 1.730 (1.730)  Loss:  0.4126 (0.4126)  Acc@1: 92.5781 (92.5781)  Acc@5: 99.6094 (99.6094)
2024-04-03 00:51:52,043 - train - INFO - Test: [  39/39]  Time: 1.601 (1.646)  Loss:  0.5010 (0.4083)  Acc@1: 87.5000 (91.7300)  Acc@5: 100.0000 (99.6600)
2024-04-03 00:51:55,762 - train - INFO - Train: 30 [   0/195 (  0%)]  Loss:  1.888349 (1.8883)  Time: 3.529s,   72.55/s  (3.529s,   72.55/s)  LR: 4.984e-04  Data: 0.376 (0.376)
2024-04-03 00:54:16,988 - train - INFO - Train: 30 [  50/195 ( 26%)]  Loss:  1.496453 (1.6141)  Time: 2.450s,  104.47/s  (2.838s,   90.19/s)  LR: 4.984e-04  Data: 0.015 (0.022)
2024-04-03 00:56:36,281 - train - INFO - Train: 30 [ 100/195 ( 52%)]  Loss:  1.801877 (1.6349)  Time: 2.714s,   94.32/s  (2.812s,   91.03/s)  LR: 4.984e-04  Data: 0.027 (0.018)
2024-04-03 00:58:55,475 - train - INFO - Train: 30 [ 150/195 ( 77%)]  Loss:  1.888493 (1.6413)  Time: 2.902s,   88.22/s  (2.803s,   91.33/s)  LR: 4.984e-04  Data: 0.005 (0.016)
2024-04-03 01:00:51,921 - train - INFO - Train: 30 [ 194/195 (100%)]  Loss:  1.654110 (1.6437)  Time: 2.510s,  101.98/s  (2.768s,   92.50/s)  LR: 4.984e-04  Data: 0.000 (0.015)
2024-04-03 01:00:51,931 - train - INFO - True
2024-04-03 01:00:51,934 - train - INFO - alphas:tensor([0.2453, 0.7547], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,934 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,934 - train - INFO - True
2024-04-03 01:00:51,935 - train - INFO - alphas:tensor([0.3211, 0.6789], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,935 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,935 - train - INFO - True
2024-04-03 01:00:51,936 - train - INFO - alphas:tensor([0.6520, 0.3480], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,936 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,936 - train - INFO - True
2024-04-03 01:00:51,937 - train - INFO - alphas:tensor([0.6302, 0.3698], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,944 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,944 - train - INFO - True
2024-04-03 01:00:51,945 - train - INFO - alphas:tensor([0.3993, 0.6007], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,945 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,945 - train - INFO - True
2024-04-03 01:00:51,946 - train - INFO - alphas:tensor([0.5256, 0.4744], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,946 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,946 - train - INFO - True
2024-04-03 01:00:51,947 - train - INFO - alphas:tensor([0.6855, 0.3145], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,948 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,953 - train - INFO - True
2024-04-03 01:00:51,954 - train - INFO - alphas:tensor([0.6051, 0.3949], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,954 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,954 - train - INFO - True
2024-04-03 01:00:51,954 - train - INFO - alphas:tensor([0.4691, 0.5309], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,959 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,959 - train - INFO - True
2024-04-03 01:00:51,960 - train - INFO - alphas:tensor([0.5963, 0.4037], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,960 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,960 - train - INFO - True
2024-04-03 01:00:51,961 - train - INFO - alphas:tensor([0.6916, 0.3084], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,961 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,961 - train - INFO - True
2024-04-03 01:00:51,961 - train - INFO - alphas:tensor([0.5897, 0.4103], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,961 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,962 - train - INFO - True
2024-04-03 01:00:51,972 - train - INFO - alphas:tensor([0.4796, 0.5204], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,972 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,972 - train - INFO - True
2024-04-03 01:00:51,973 - train - INFO - alphas:tensor([0.5834, 0.4166], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,977 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,977 - train - INFO - True
2024-04-03 01:00:51,983 - train - INFO - alphas:tensor([0.6599, 0.3401], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,983 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,983 - train - INFO - True
2024-04-03 01:00:51,989 - train - INFO - alphas:tensor([0.5194, 0.4806], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:51,990 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:51,990 - train - INFO - True
2024-04-03 01:00:51,990 - train - INFO - alphas:tensor([0.4560, 0.5440], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:52,003 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:52,003 - train - INFO - True
2024-04-03 01:00:52,003 - train - INFO - alphas:tensor([0.5079, 0.4921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:52,003 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:52,004 - train - INFO - True
2024-04-03 01:00:52,004 - train - INFO - alphas:tensor([0.5985, 0.4015], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:52,004 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:52,004 - train - INFO - True
2024-04-03 01:00:52,005 - train - INFO - alphas:tensor([0.4146, 0.5854], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:52,005 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:52,005 - train - INFO - True
2024-04-03 01:00:52,006 - train - INFO - alphas:tensor([0.4142, 0.5858], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:52,007 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:52,007 - train - INFO - True
2024-04-03 01:00:52,008 - train - INFO - alphas:tensor([0.4713, 0.5287], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:52,012 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:52,012 - train - INFO - True
2024-04-03 01:00:52,013 - train - INFO - alphas:tensor([0.5555, 0.4445], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:52,013 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:52,013 - train - INFO - True
2024-04-03 01:00:52,014 - train - INFO - alphas:tensor([0.3651, 0.6349], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:52,014 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:52,014 - train - INFO - True
2024-04-03 01:00:52,015 - train - INFO - alphas:tensor([0.3588, 0.6412], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:52,015 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:52,015 - train - INFO - True
2024-04-03 01:00:52,015 - train - INFO - alphas:tensor([0.3975, 0.6025], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:52,015 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:52,016 - train - INFO - True
2024-04-03 01:00:52,016 - train - INFO - alphas:tensor([0.3065, 0.6935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:52,016 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:52,016 - train - INFO - True
2024-04-03 01:00:52,017 - train - INFO - alphas:tensor([0.1690, 0.8310], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:52,017 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:52,017 - train - INFO - True
2024-04-03 01:00:52,018 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:00:52,018 - train - INFO - tau:0.7547192872036325
2024-04-03 01:00:52,018 - train - INFO - avg block size:8.241379310344827
2024-04-03 01:00:53,699 - train - INFO - Test: [   0/39]  Time: 1.660 (1.660)  Loss:  0.4238 (0.4238)  Acc@1: 92.1875 (92.1875)  Acc@5: 99.2188 (99.2188)
2024-04-03 01:01:57,120 - train - INFO - Test: [  39/39]  Time: 1.620 (1.627)  Loss:  0.4434 (0.4197)  Acc@1: 81.2500 (90.9900)  Acc@5: 100.0000 (99.5900)
2024-04-03 01:02:00,269 - train - INFO - Train: 31 [   0/195 (  0%)]  Loss:  1.441426 (1.4414)  Time: 2.914s,   87.84/s  (2.914s,   87.84/s)  LR: 4.951e-04  Data: 0.269 (0.269)
2024-04-03 01:04:13,953 - train - INFO - Train: 31 [  50/195 ( 26%)]  Loss:  1.879183 (1.6426)  Time: 2.694s,   95.02/s  (2.678s,   95.58/s)  LR: 4.951e-04  Data: 0.025 (0.017)
2024-04-03 01:06:27,341 - train - INFO - Train: 31 [ 100/195 ( 52%)]  Loss:  1.825748 (1.6361)  Time: 3.026s,   84.59/s  (2.673s,   95.77/s)  LR: 4.951e-04  Data: 0.023 (0.015)
2024-04-03 01:08:46,911 - train - INFO - Train: 31 [ 150/195 ( 77%)]  Loss:  1.786858 (1.6372)  Time: 3.026s,   84.59/s  (2.712s,   94.39/s)  LR: 4.951e-04  Data: 0.006 (0.015)
2024-04-03 01:10:45,885 - train - INFO - Train: 31 [ 194/195 (100%)]  Loss:  1.487131 (1.6345)  Time: 2.496s,  102.56/s  (2.710s,   94.45/s)  LR: 4.951e-04  Data: 0.000 (0.014)
2024-04-03 01:10:45,886 - train - INFO - True
2024-04-03 01:10:45,887 - train - INFO - alphas:tensor([0.2339, 0.7661], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,887 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,887 - train - INFO - True
2024-04-03 01:10:45,888 - train - INFO - alphas:tensor([0.3086, 0.6914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,888 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,888 - train - INFO - True
2024-04-03 01:10:45,888 - train - INFO - alphas:tensor([0.6511, 0.3489], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,889 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,889 - train - INFO - True
2024-04-03 01:10:45,889 - train - INFO - alphas:tensor([0.6265, 0.3735], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,889 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,889 - train - INFO - True
2024-04-03 01:10:45,890 - train - INFO - alphas:tensor([0.3885, 0.6115], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,890 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,890 - train - INFO - True
2024-04-03 01:10:45,891 - train - INFO - alphas:tensor([0.5185, 0.4815], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,891 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,891 - train - INFO - True
2024-04-03 01:10:45,896 - train - INFO - alphas:tensor([0.6831, 0.3169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,896 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,896 - train - INFO - True
2024-04-03 01:10:45,897 - train - INFO - alphas:tensor([0.6006, 0.3994], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,897 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,897 - train - INFO - True
2024-04-03 01:10:45,898 - train - INFO - alphas:tensor([0.4618, 0.5382], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,898 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,898 - train - INFO - True
2024-04-03 01:10:45,899 - train - INFO - alphas:tensor([0.5897, 0.4103], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,899 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,899 - train - INFO - True
2024-04-03 01:10:45,900 - train - INFO - alphas:tensor([0.6898, 0.3102], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,900 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,900 - train - INFO - True
2024-04-03 01:10:45,901 - train - INFO - alphas:tensor([0.5830, 0.4170], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,901 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,901 - train - INFO - True
2024-04-03 01:10:45,901 - train - INFO - alphas:tensor([0.4732, 0.5268], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,901 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,901 - train - INFO - True
2024-04-03 01:10:45,902 - train - INFO - alphas:tensor([0.5767, 0.4233], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,902 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,902 - train - INFO - True
2024-04-03 01:10:45,903 - train - INFO - alphas:tensor([0.6594, 0.3406], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,903 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,903 - train - INFO - True
2024-04-03 01:10:45,904 - train - INFO - alphas:tensor([0.5153, 0.4847], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,904 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,904 - train - INFO - True
2024-04-03 01:10:45,905 - train - INFO - alphas:tensor([0.4465, 0.5535], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,905 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,905 - train - INFO - True
2024-04-03 01:10:45,905 - train - INFO - alphas:tensor([0.4980, 0.5020], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,905 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,905 - train - INFO - True
2024-04-03 01:10:45,906 - train - INFO - alphas:tensor([0.5916, 0.4084], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,906 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,906 - train - INFO - True
2024-04-03 01:10:45,907 - train - INFO - alphas:tensor([0.4058, 0.5942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,907 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,907 - train - INFO - True
2024-04-03 01:10:45,908 - train - INFO - alphas:tensor([0.4040, 0.5960], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,908 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,908 - train - INFO - True
2024-04-03 01:10:45,909 - train - INFO - alphas:tensor([0.4595, 0.5405], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,909 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,909 - train - INFO - True
2024-04-03 01:10:45,909 - train - INFO - alphas:tensor([0.5491, 0.4509], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,909 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,910 - train - INFO - True
2024-04-03 01:10:45,910 - train - INFO - alphas:tensor([0.3571, 0.6429], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,910 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,910 - train - INFO - True
2024-04-03 01:10:45,911 - train - INFO - alphas:tensor([0.3488, 0.6512], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,911 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,911 - train - INFO - True
2024-04-03 01:10:45,912 - train - INFO - alphas:tensor([0.3843, 0.6157], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,916 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,916 - train - INFO - True
2024-04-03 01:10:45,917 - train - INFO - alphas:tensor([0.2937, 0.7063], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,917 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,917 - train - INFO - True
2024-04-03 01:10:45,918 - train - INFO - alphas:tensor([0.1545, 0.8455], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,918 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,918 - train - INFO - True
2024-04-03 01:10:45,919 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:10:45,919 - train - INFO - tau:0.7471720943315961
2024-04-03 01:10:45,919 - train - INFO - avg block size:8.758620689655173
2024-04-03 01:10:47,537 - train - INFO - Test: [   0/39]  Time: 1.616 (1.616)  Loss:  0.4121 (0.4121)  Acc@1: 91.4062 (91.4062)  Acc@5: 100.0000 (100.0000)
2024-04-03 01:11:50,097 - train - INFO - Test: [  39/39]  Time: 1.622 (1.604)  Loss:  0.5420 (0.3959)  Acc@1: 81.2500 (91.4300)  Acc@5: 100.0000 (99.6900)
2024-04-03 01:11:53,937 - train - INFO - Train: 32 [   0/195 (  0%)]  Loss:  1.875294 (1.8753)  Time: 3.668s,   69.79/s  (3.668s,   69.79/s)  LR: 4.916e-04  Data: 0.256 (0.256)
2024-04-03 01:14:12,230 - train - INFO - Train: 32 [  50/195 ( 26%)]  Loss:  1.586626 (1.6695)  Time: 2.907s,   88.07/s  (2.784s,   91.97/s)  LR: 4.916e-04  Data: 0.014 (0.019)
2024-04-03 01:16:28,108 - train - INFO - Train: 32 [ 100/195 ( 52%)]  Loss:  1.858059 (1.6905)  Time: 2.914s,   87.86/s  (2.751s,   93.06/s)  LR: 4.916e-04  Data: 0.009 (0.016)
2024-04-03 01:18:46,120 - train - INFO - Train: 32 [ 150/195 ( 77%)]  Loss:  1.337577 (1.6704)  Time: 3.008s,   85.11/s  (2.754s,   92.96/s)  LR: 4.916e-04  Data: 0.010 (0.015)
2024-04-03 01:20:44,710 - train - INFO - Train: 32 [ 194/195 (100%)]  Loss:  1.339925 (1.6695)  Time: 2.770s,   92.42/s  (2.741s,   93.41/s)  LR: 4.916e-04  Data: 0.000 (0.015)
2024-04-03 01:20:44,710 - train - INFO - True
2024-04-03 01:20:44,716 - train - INFO - alphas:tensor([0.2235, 0.7765], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,716 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,716 - train - INFO - True
2024-04-03 01:20:44,717 - train - INFO - alphas:tensor([0.2986, 0.7014], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,717 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,717 - train - INFO - True
2024-04-03 01:20:44,718 - train - INFO - alphas:tensor([0.6485, 0.3515], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,718 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,718 - train - INFO - True
2024-04-03 01:20:44,719 - train - INFO - alphas:tensor([0.6220, 0.3780], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,719 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,719 - train - INFO - True
2024-04-03 01:20:44,720 - train - INFO - alphas:tensor([0.3811, 0.6189], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,720 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,720 - train - INFO - True
2024-04-03 01:20:44,721 - train - INFO - alphas:tensor([0.5101, 0.4899], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,721 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,721 - train - INFO - True
2024-04-03 01:20:44,721 - train - INFO - alphas:tensor([0.6797, 0.3203], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,721 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,721 - train - INFO - True
2024-04-03 01:20:44,722 - train - INFO - alphas:tensor([0.5936, 0.4064], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,727 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,727 - train - INFO - True
2024-04-03 01:20:44,727 - train - INFO - alphas:tensor([0.4531, 0.5469], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,728 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,728 - train - INFO - True
2024-04-03 01:20:44,729 - train - INFO - alphas:tensor([0.5808, 0.4192], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,729 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,729 - train - INFO - True
2024-04-03 01:20:44,729 - train - INFO - alphas:tensor([0.6866, 0.3134], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,730 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,730 - train - INFO - True
2024-04-03 01:20:44,730 - train - INFO - alphas:tensor([0.5778, 0.4222], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,735 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,735 - train - INFO - True
2024-04-03 01:20:44,735 - train - INFO - alphas:tensor([0.4659, 0.5341], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,736 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,736 - train - INFO - True
2024-04-03 01:20:44,736 - train - INFO - alphas:tensor([0.5721, 0.4279], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,736 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,736 - train - INFO - True
2024-04-03 01:20:44,737 - train - INFO - alphas:tensor([0.6528, 0.3472], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,737 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,737 - train - INFO - True
2024-04-03 01:20:44,738 - train - INFO - alphas:tensor([0.5030, 0.4970], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,738 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,738 - train - INFO - True
2024-04-03 01:20:44,739 - train - INFO - alphas:tensor([0.4372, 0.5628], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,739 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,739 - train - INFO - True
2024-04-03 01:20:44,739 - train - INFO - alphas:tensor([0.4891, 0.5109], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,740 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,740 - train - INFO - True
2024-04-03 01:20:44,740 - train - INFO - alphas:tensor([0.5864, 0.4136], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,740 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,740 - train - INFO - True
2024-04-03 01:20:44,741 - train - INFO - alphas:tensor([0.4018, 0.5982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,741 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,741 - train - INFO - True
2024-04-03 01:20:44,742 - train - INFO - alphas:tensor([0.3952, 0.6048], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,742 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,742 - train - INFO - True
2024-04-03 01:20:44,743 - train - INFO - alphas:tensor([0.4529, 0.5471], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,743 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,743 - train - INFO - True
2024-04-03 01:20:44,743 - train - INFO - alphas:tensor([0.5410, 0.4590], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,744 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,744 - train - INFO - True
2024-04-03 01:20:44,744 - train - INFO - alphas:tensor([0.3499, 0.6501], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,744 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,744 - train - INFO - True
2024-04-03 01:20:44,745 - train - INFO - alphas:tensor([0.3421, 0.6579], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,745 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,745 - train - INFO - True
2024-04-03 01:20:44,746 - train - INFO - alphas:tensor([0.3705, 0.6296], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,746 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,746 - train - INFO - True
2024-04-03 01:20:44,747 - train - INFO - alphas:tensor([0.2802, 0.7198], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,747 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,747 - train - INFO - True
2024-04-03 01:20:44,748 - train - INFO - alphas:tensor([0.1391, 0.8609], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,748 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,748 - train - INFO - True
2024-04-03 01:20:44,748 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:20:44,748 - train - INFO - tau:0.7397003733882802
2024-04-03 01:20:44,748 - train - INFO - avg block size:8.758620689655173
2024-04-03 01:20:46,428 - train - INFO - Test: [   0/39]  Time: 1.677 (1.677)  Loss:  0.4507 (0.4507)  Acc@1: 88.6719 (88.6719)  Acc@5: 99.6094 (99.6094)
2024-04-03 01:21:48,763 - train - INFO - Test: [  39/39]  Time: 1.568 (1.600)  Loss:  0.4277 (0.4112)  Acc@1: 81.2500 (91.1600)  Acc@5: 100.0000 (99.7300)
2024-04-03 01:21:51,933 - train - INFO - Train: 33 [   0/195 (  0%)]  Loss:  1.705806 (1.7058)  Time: 2.946s,   86.89/s  (2.946s,   86.89/s)  LR: 4.880e-04  Data: 0.271 (0.271)
2024-04-03 01:24:09,081 - train - INFO - Train: 33 [  50/195 ( 26%)]  Loss:  1.840202 (1.6232)  Time: 2.877s,   88.99/s  (2.747s,   93.19/s)  LR: 4.880e-04  Data: 0.018 (0.018)
2024-04-03 01:26:26,266 - train - INFO - Train: 33 [ 100/195 ( 52%)]  Loss:  1.729609 (1.6338)  Time: 2.828s,   90.52/s  (2.745s,   93.25/s)  LR: 4.880e-04  Data: 0.014 (0.015)
2024-04-03 01:28:33,891 - train - INFO - Train: 33 [ 150/195 ( 77%)]  Loss:  1.730418 (1.6440)  Time: 2.485s,  103.00/s  (2.681s,   95.47/s)  LR: 4.880e-04  Data: 0.024 (0.014)
2024-04-03 01:30:15,842 - train - INFO - Train: 33 [ 194/195 (100%)]  Loss:  1.756256 (1.6380)  Time: 2.319s,  110.40/s  (2.599s,   98.49/s)  LR: 4.880e-04  Data: 0.000 (0.013)
2024-04-03 01:30:15,843 - train - INFO - True
2024-04-03 01:30:15,845 - train - INFO - alphas:tensor([0.2117, 0.7883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,845 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,845 - train - INFO - True
2024-04-03 01:30:15,850 - train - INFO - alphas:tensor([0.2871, 0.7129], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,850 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,851 - train - INFO - True
2024-04-03 01:30:15,851 - train - INFO - alphas:tensor([0.6457, 0.3543], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,851 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,851 - train - INFO - True
2024-04-03 01:30:15,852 - train - INFO - alphas:tensor([0.6166, 0.3834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,852 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,852 - train - INFO - True
2024-04-03 01:30:15,853 - train - INFO - alphas:tensor([0.3750, 0.6250], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,853 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,853 - train - INFO - True
2024-04-03 01:30:15,854 - train - INFO - alphas:tensor([0.5039, 0.4961], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,854 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,854 - train - INFO - True
2024-04-03 01:30:15,854 - train - INFO - alphas:tensor([0.6768, 0.3232], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,854 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,855 - train - INFO - True
2024-04-03 01:30:15,855 - train - INFO - alphas:tensor([0.5871, 0.4129], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,856 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,856 - train - INFO - True
2024-04-03 01:30:15,856 - train - INFO - alphas:tensor([0.4487, 0.5513], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,856 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,857 - train - INFO - True
2024-04-03 01:30:15,857 - train - INFO - alphas:tensor([0.5760, 0.4240], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,857 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,857 - train - INFO - True
2024-04-03 01:30:15,858 - train - INFO - alphas:tensor([0.6830, 0.3170], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,858 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,858 - train - INFO - True
2024-04-03 01:30:15,859 - train - INFO - alphas:tensor([0.5684, 0.4316], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,859 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,859 - train - INFO - True
2024-04-03 01:30:15,860 - train - INFO - alphas:tensor([0.4595, 0.5405], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,860 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,860 - train - INFO - True
2024-04-03 01:30:15,860 - train - INFO - alphas:tensor([0.5655, 0.4345], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,861 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,861 - train - INFO - True
2024-04-03 01:30:15,861 - train - INFO - alphas:tensor([0.6490, 0.3510], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,861 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,861 - train - INFO - True
2024-04-03 01:30:15,862 - train - INFO - alphas:tensor([0.4974, 0.5026], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,862 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,862 - train - INFO - True
2024-04-03 01:30:15,863 - train - INFO - alphas:tensor([0.4305, 0.5695], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,863 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,863 - train - INFO - True
2024-04-03 01:30:15,864 - train - INFO - alphas:tensor([0.4808, 0.5192], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,864 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,864 - train - INFO - True
2024-04-03 01:30:15,865 - train - INFO - alphas:tensor([0.5770, 0.4230], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,865 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,865 - train - INFO - True
2024-04-03 01:30:15,865 - train - INFO - alphas:tensor([0.3896, 0.6104], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,866 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,866 - train - INFO - True
2024-04-03 01:30:15,866 - train - INFO - alphas:tensor([0.3892, 0.6108], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,866 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,866 - train - INFO - True
2024-04-03 01:30:15,867 - train - INFO - alphas:tensor([0.4457, 0.5543], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,867 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,867 - train - INFO - True
2024-04-03 01:30:15,868 - train - INFO - alphas:tensor([0.5340, 0.4660], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,868 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,868 - train - INFO - True
2024-04-03 01:30:15,870 - train - INFO - alphas:tensor([0.3423, 0.6577], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,870 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,870 - train - INFO - True
2024-04-03 01:30:15,872 - train - INFO - alphas:tensor([0.3327, 0.6673], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,872 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,872 - train - INFO - True
2024-04-03 01:30:15,873 - train - INFO - alphas:tensor([0.3577, 0.6423], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,873 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,873 - train - INFO - True
2024-04-03 01:30:15,874 - train - INFO - alphas:tensor([0.2679, 0.7321], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,874 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,874 - train - INFO - True
2024-04-03 01:30:15,875 - train - INFO - alphas:tensor([0.1255, 0.8745], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,875 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,875 - train - INFO - True
2024-04-03 01:30:15,875 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:30:15,876 - train - INFO - tau:0.7323033696543974
2024-04-03 01:30:15,876 - train - INFO - avg block size:9.275862068965518
2024-04-03 01:30:17,259 - train - INFO - Test: [   0/39]  Time: 1.376 (1.376)  Loss:  0.4282 (0.4282)  Acc@1: 88.2812 (88.2812)  Acc@5: 99.6094 (99.6094)
2024-04-03 01:31:09,295 - train - INFO - Test: [  39/39]  Time: 1.350 (1.335)  Loss:  0.4673 (0.4148)  Acc@1: 87.5000 (91.3000)  Acc@5: 100.0000 (99.7000)
2024-04-03 01:31:12,007 - train - INFO - Train: 34 [   0/195 (  0%)]  Loss:  1.974588 (1.9746)  Time: 2.507s,  102.11/s  (2.507s,  102.11/s)  LR: 4.844e-04  Data: 0.392 (0.392)
2024-04-03 01:33:08,782 - train - INFO - Train: 34 [  50/195 ( 26%)]  Loss:  1.738531 (1.6873)  Time: 2.286s,  112.00/s  (2.339s,  109.46/s)  LR: 4.844e-04  Data: 0.005 (0.018)
2024-04-03 01:35:02,282 - train - INFO - Train: 34 [ 100/195 ( 52%)]  Loss:  1.736243 (1.6580)  Time: 2.448s,  104.59/s  (2.305s,  111.07/s)  LR: 4.844e-04  Data: 0.011 (0.014)
2024-04-03 01:37:01,009 - train - INFO - Train: 34 [ 150/195 ( 77%)]  Loss:  1.880710 (1.6692)  Time: 2.163s,  118.37/s  (2.328s,  109.97/s)  LR: 4.844e-04  Data: 0.006 (0.013)
2024-04-03 01:38:46,858 - train - INFO - Train: 34 [ 194/195 (100%)]  Loss:  1.364341 (1.6579)  Time: 2.112s,  121.22/s  (2.345s,  109.15/s)  LR: 4.844e-04  Data: 0.000 (0.013)
2024-04-03 01:38:46,859 - train - INFO - True
2024-04-03 01:38:46,860 - train - INFO - alphas:tensor([0.2015, 0.7985], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,860 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,860 - train - INFO - True
2024-04-03 01:38:46,861 - train - INFO - alphas:tensor([0.2774, 0.7226], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,861 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,861 - train - INFO - True
2024-04-03 01:38:46,862 - train - INFO - alphas:tensor([0.6432, 0.3568], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,862 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,862 - train - INFO - True
2024-04-03 01:38:46,863 - train - INFO - alphas:tensor([0.6124, 0.3876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,863 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,863 - train - INFO - True
2024-04-03 01:38:46,868 - train - INFO - alphas:tensor([0.3655, 0.6345], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,868 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,868 - train - INFO - True
2024-04-03 01:38:46,869 - train - INFO - alphas:tensor([0.4956, 0.5044], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,869 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,869 - train - INFO - True
2024-04-03 01:38:46,870 - train - INFO - alphas:tensor([0.6732, 0.3268], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,870 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,870 - train - INFO - True
2024-04-03 01:38:46,870 - train - INFO - alphas:tensor([0.5833, 0.4167], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,870 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,871 - train - INFO - True
2024-04-03 01:38:46,871 - train - INFO - alphas:tensor([0.4399, 0.5601], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,871 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,871 - train - INFO - True
2024-04-03 01:38:46,872 - train - INFO - alphas:tensor([0.5694, 0.4306], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,872 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,872 - train - INFO - True
2024-04-03 01:38:46,873 - train - INFO - alphas:tensor([0.6808, 0.3192], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,873 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,873 - train - INFO - True
2024-04-03 01:38:46,874 - train - INFO - alphas:tensor([0.5658, 0.4342], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,874 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,874 - train - INFO - True
2024-04-03 01:38:46,874 - train - INFO - alphas:tensor([0.4534, 0.5466], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,875 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,875 - train - INFO - True
2024-04-03 01:38:46,875 - train - INFO - alphas:tensor([0.5611, 0.4389], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,880 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,880 - train - INFO - True
2024-04-03 01:38:46,880 - train - INFO - alphas:tensor([0.6449, 0.3551], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,881 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,881 - train - INFO - True
2024-04-03 01:38:46,881 - train - INFO - alphas:tensor([0.4895, 0.5105], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,881 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,881 - train - INFO - True
2024-04-03 01:38:46,882 - train - INFO - alphas:tensor([0.4233, 0.5767], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,882 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,882 - train - INFO - True
2024-04-03 01:38:46,883 - train - INFO - alphas:tensor([0.4737, 0.5263], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,883 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,883 - train - INFO - True
2024-04-03 01:38:46,884 - train - INFO - alphas:tensor([0.5706, 0.4294], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,884 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,884 - train - INFO - True
2024-04-03 01:38:46,885 - train - INFO - alphas:tensor([0.3840, 0.6160], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,885 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,885 - train - INFO - True
2024-04-03 01:38:46,885 - train - INFO - alphas:tensor([0.3798, 0.6202], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,885 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,886 - train - INFO - True
2024-04-03 01:38:46,886 - train - INFO - alphas:tensor([0.4349, 0.5651], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,886 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,886 - train - INFO - True
2024-04-03 01:38:46,887 - train - INFO - alphas:tensor([0.5287, 0.4713], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,887 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,887 - train - INFO - True
2024-04-03 01:38:46,888 - train - INFO - alphas:tensor([0.3349, 0.6651], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,888 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,888 - train - INFO - True
2024-04-03 01:38:46,889 - train - INFO - alphas:tensor([0.3227, 0.6773], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,889 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,889 - train - INFO - True
2024-04-03 01:38:46,889 - train - INFO - alphas:tensor([0.3449, 0.6551], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,890 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,890 - train - INFO - True
2024-04-03 01:38:46,890 - train - INFO - alphas:tensor([0.2571, 0.7429], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,890 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,890 - train - INFO - True
2024-04-03 01:38:46,891 - train - INFO - alphas:tensor([0.1124, 0.8876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,891 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,891 - train - INFO - True
2024-04-03 01:38:46,892 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:38:46,892 - train - INFO - tau:0.7249803359578534
2024-04-03 01:38:46,892 - train - INFO - avg block size:9.793103448275861
2024-04-03 01:38:48,254 - train - INFO - Test: [   0/39]  Time: 1.359 (1.359)  Loss:  0.3933 (0.3933)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.2188 (99.2188)
2024-04-03 01:39:40,756 - train - INFO - Test: [  39/39]  Time: 1.367 (1.347)  Loss:  0.5093 (0.3995)  Acc@1: 87.5000 (91.1500)  Acc@5: 100.0000 (99.6900)
2024-04-03 01:39:43,540 - train - INFO - Train: 35 [   0/195 (  0%)]  Loss:  1.740532 (1.7405)  Time: 2.583s,   99.09/s  (2.583s,   99.09/s)  LR: 4.806e-04  Data: 0.237 (0.237)
2024-04-03 01:41:43,906 - train - INFO - Train: 35 [  50/195 ( 26%)]  Loss:  1.819945 (1.6323)  Time: 2.368s,  108.12/s  (2.411s,  106.19/s)  LR: 4.806e-04  Data: 0.035 (0.015)
2024-04-03 01:43:39,334 - train - INFO - Train: 35 [ 100/195 ( 52%)]  Loss:  1.551538 (1.6302)  Time: 2.230s,  114.79/s  (2.360s,  108.47/s)  LR: 4.806e-04  Data: 0.005 (0.014)
2024-04-03 01:45:36,912 - train - INFO - Train: 35 [ 150/195 ( 77%)]  Loss:  1.487328 (1.6480)  Time: 2.532s,  101.11/s  (2.357s,  108.60/s)  LR: 4.806e-04  Data: 0.014 (0.013)
2024-04-03 01:47:20,932 - train - INFO - Train: 35 [ 194/195 (100%)]  Loss:  1.304696 (1.6334)  Time: 2.366s,  108.20/s  (2.359s,  108.53/s)  LR: 4.806e-04  Data: 0.000 (0.012)
2024-04-03 01:47:20,933 - train - INFO - True
2024-04-03 01:47:20,935 - train - INFO - alphas:tensor([0.1923, 0.8077], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,935 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,935 - train - INFO - True
2024-04-03 01:47:20,936 - train - INFO - alphas:tensor([0.2681, 0.7319], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,936 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,936 - train - INFO - True
2024-04-03 01:47:20,937 - train - INFO - alphas:tensor([0.6417, 0.3583], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,937 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,937 - train - INFO - True
2024-04-03 01:47:20,937 - train - INFO - alphas:tensor([0.6099, 0.3901], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,937 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,938 - train - INFO - True
2024-04-03 01:47:20,938 - train - INFO - alphas:tensor([0.3589, 0.6411], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,938 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,938 - train - INFO - True
2024-04-03 01:47:20,939 - train - INFO - alphas:tensor([0.4861, 0.5139], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,939 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,939 - train - INFO - True
2024-04-03 01:47:20,940 - train - INFO - alphas:tensor([0.6701, 0.3299], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,940 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,940 - train - INFO - True
2024-04-03 01:47:20,941 - train - INFO - alphas:tensor([0.5769, 0.4231], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,941 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,941 - train - INFO - True
2024-04-03 01:47:20,942 - train - INFO - alphas:tensor([0.4374, 0.5626], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,942 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,942 - train - INFO - True
2024-04-03 01:47:20,943 - train - INFO - alphas:tensor([0.5667, 0.4333], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,943 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,943 - train - INFO - True
2024-04-03 01:47:20,944 - train - INFO - alphas:tensor([0.6780, 0.3220], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,944 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,944 - train - INFO - True
2024-04-03 01:47:20,944 - train - INFO - alphas:tensor([0.5592, 0.4408], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,944 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,945 - train - INFO - True
2024-04-03 01:47:20,945 - train - INFO - alphas:tensor([0.4471, 0.5529], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,945 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,945 - train - INFO - True
2024-04-03 01:47:20,946 - train - INFO - alphas:tensor([0.5569, 0.4431], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,946 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,946 - train - INFO - True
2024-04-03 01:47:20,947 - train - INFO - alphas:tensor([0.6418, 0.3582], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,947 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,947 - train - INFO - True
2024-04-03 01:47:20,948 - train - INFO - alphas:tensor([0.4857, 0.5143], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,948 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,948 - train - INFO - True
2024-04-03 01:47:20,948 - train - INFO - alphas:tensor([0.4196, 0.5804], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,949 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,949 - train - INFO - True
2024-04-03 01:47:20,949 - train - INFO - alphas:tensor([0.4662, 0.5338], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,949 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,949 - train - INFO - True
2024-04-03 01:47:20,950 - train - INFO - alphas:tensor([0.5654, 0.4346], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,950 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,950 - train - INFO - True
2024-04-03 01:47:20,951 - train - INFO - alphas:tensor([0.3779, 0.6221], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,951 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,951 - train - INFO - True
2024-04-03 01:47:20,952 - train - INFO - alphas:tensor([0.3729, 0.6271], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,952 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,952 - train - INFO - True
2024-04-03 01:47:20,953 - train - INFO - alphas:tensor([0.4288, 0.5712], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,953 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,953 - train - INFO - True
2024-04-03 01:47:20,953 - train - INFO - alphas:tensor([0.5231, 0.4769], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,953 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,954 - train - INFO - True
2024-04-03 01:47:20,954 - train - INFO - alphas:tensor([0.3293, 0.6707], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,954 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,954 - train - INFO - True
2024-04-03 01:47:20,955 - train - INFO - alphas:tensor([0.3146, 0.6854], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,955 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,955 - train - INFO - True
2024-04-03 01:47:20,956 - train - INFO - alphas:tensor([0.3335, 0.6665], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,956 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,956 - train - INFO - True
2024-04-03 01:47:20,957 - train - INFO - alphas:tensor([0.2458, 0.7542], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,957 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,957 - train - INFO - True
2024-04-03 01:47:20,957 - train - INFO - alphas:tensor([0.1009, 0.8991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,958 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,958 - train - INFO - True
2024-04-03 01:47:20,958 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:47:20,959 - train - INFO - tau:0.7177305325982748
2024-04-03 01:47:20,959 - train - INFO - avg block size:9.793103448275861
2024-04-03 01:47:22,342 - train - INFO - Test: [   0/39]  Time: 1.381 (1.381)  Loss:  0.3987 (0.3987)  Acc@1: 92.1875 (92.1875)  Acc@5: 99.6094 (99.6094)
2024-04-03 01:48:14,987 - train - INFO - Test: [  39/39]  Time: 1.335 (1.351)  Loss:  0.4180 (0.3977)  Acc@1: 81.2500 (91.5900)  Acc@5: 100.0000 (99.7200)
2024-04-03 01:48:17,849 - train - INFO - Train: 36 [   0/195 (  0%)]  Loss:  1.808541 (1.8085)  Time: 2.666s,   96.04/s  (2.666s,   96.04/s)  LR: 4.768e-04  Data: 0.265 (0.265)
2024-04-03 01:50:13,778 - train - INFO - Train: 36 [  50/195 ( 26%)]  Loss:  1.663376 (1.6962)  Time: 2.063s,  124.12/s  (2.325s,  110.09/s)  LR: 4.768e-04  Data: 0.010 (0.015)
2024-04-03 01:52:11,965 - train - INFO - Train: 36 [ 100/195 ( 52%)]  Loss:  1.825011 (1.6457)  Time: 2.556s,  100.16/s  (2.344s,  109.20/s)  LR: 4.768e-04  Data: 0.008 (0.013)
2024-04-03 01:54:11,675 - train - INFO - Train: 36 [ 150/195 ( 77%)]  Loss:  1.744337 (1.6468)  Time: 2.434s,  105.17/s  (2.361s,  108.44/s)  LR: 4.768e-04  Data: 0.011 (0.012)
2024-04-03 01:55:55,942 - train - INFO - Train: 36 [ 194/195 (100%)]  Loss:  1.512352 (1.6365)  Time: 2.188s,  116.98/s  (2.363s,  108.34/s)  LR: 4.768e-04  Data: 0.000 (0.012)
2024-04-03 01:55:55,942 - train - INFO - True
2024-04-03 01:55:55,943 - train - INFO - alphas:tensor([0.1834, 0.8166], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,943 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,943 - train - INFO - True
2024-04-03 01:55:55,944 - train - INFO - alphas:tensor([0.2595, 0.7405], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,944 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,944 - train - INFO - True
2024-04-03 01:55:55,945 - train - INFO - alphas:tensor([0.6395, 0.3605], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,945 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,945 - train - INFO - True
2024-04-03 01:55:55,946 - train - INFO - alphas:tensor([0.6068, 0.3932], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,946 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,950 - train - INFO - True
2024-04-03 01:55:55,951 - train - INFO - alphas:tensor([0.3527, 0.6473], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,951 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,951 - train - INFO - True
2024-04-03 01:55:55,952 - train - INFO - alphas:tensor([0.4823, 0.5177], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,952 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,952 - train - INFO - True
2024-04-03 01:55:55,953 - train - INFO - alphas:tensor([0.6682, 0.3318], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,953 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,953 - train - INFO - True
2024-04-03 01:55:55,958 - train - INFO - alphas:tensor([0.5719, 0.4281], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,959 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,959 - train - INFO - True
2024-04-03 01:55:55,959 - train - INFO - alphas:tensor([0.4294, 0.5706], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,959 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,959 - train - INFO - True
2024-04-03 01:55:55,960 - train - INFO - alphas:tensor([0.5607, 0.4393], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,960 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,960 - train - INFO - True
2024-04-03 01:55:55,961 - train - INFO - alphas:tensor([0.6758, 0.3242], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,961 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,961 - train - INFO - True
2024-04-03 01:55:55,962 - train - INFO - alphas:tensor([0.5562, 0.4438], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,962 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,962 - train - INFO - True
2024-04-03 01:55:55,963 - train - INFO - alphas:tensor([0.4429, 0.5571], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,963 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,963 - train - INFO - True
2024-04-03 01:55:55,963 - train - INFO - alphas:tensor([0.5509, 0.4491], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,963 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,964 - train - INFO - True
2024-04-03 01:55:55,964 - train - INFO - alphas:tensor([0.6387, 0.3613], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,964 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,964 - train - INFO - True
2024-04-03 01:55:55,965 - train - INFO - alphas:tensor([0.4826, 0.5174], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,965 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,965 - train - INFO - True
2024-04-03 01:55:55,966 - train - INFO - alphas:tensor([0.4137, 0.5863], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,966 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,966 - train - INFO - True
2024-04-03 01:55:55,976 - train - INFO - alphas:tensor([0.4633, 0.5367], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,976 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,976 - train - INFO - True
2024-04-03 01:55:55,976 - train - INFO - alphas:tensor([0.5600, 0.4400], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,976 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,977 - train - INFO - True
2024-04-03 01:55:55,977 - train - INFO - alphas:tensor([0.3732, 0.6268], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,985 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,985 - train - INFO - True
2024-04-03 01:55:55,986 - train - INFO - alphas:tensor([0.3690, 0.6310], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,986 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,986 - train - INFO - True
2024-04-03 01:55:55,987 - train - INFO - alphas:tensor([0.4221, 0.5779], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,987 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,987 - train - INFO - True
2024-04-03 01:55:55,988 - train - INFO - alphas:tensor([0.5172, 0.4828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,988 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,988 - train - INFO - True
2024-04-03 01:55:55,989 - train - INFO - alphas:tensor([0.3228, 0.6772], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,989 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,989 - train - INFO - True
2024-04-03 01:55:55,990 - train - INFO - alphas:tensor([0.3073, 0.6927], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,990 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,991 - train - INFO - True
2024-04-03 01:55:55,991 - train - INFO - alphas:tensor([0.3215, 0.6785], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,991 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,991 - train - INFO - True
2024-04-03 01:55:55,992 - train - INFO - alphas:tensor([0.2353, 0.7647], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,992 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,992 - train - INFO - True
2024-04-03 01:55:55,993 - train - INFO - alphas:tensor([0.0899, 0.9101], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:55,993 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:55,993 - train - INFO - True
2024-04-03 01:55:56,007 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 01:55:56,007 - train - INFO - tau:0.7105532272722921
2024-04-03 01:55:56,007 - train - INFO - avg block size:9.793103448275861
2024-04-03 01:55:57,337 - train - INFO - Test: [   0/39]  Time: 1.327 (1.327)  Loss:  0.4260 (0.4260)  Acc@1: 89.0625 (89.0625)  Acc@5: 100.0000 (100.0000)
2024-04-03 01:56:49,804 - train - INFO - Test: [  39/39]  Time: 1.337 (1.345)  Loss:  0.4775 (0.4023)  Acc@1: 81.2500 (91.5400)  Acc@5: 100.0000 (99.6900)
2024-04-03 01:56:52,882 - train - INFO - Train: 37 [   0/195 (  0%)]  Loss:  1.884491 (1.8845)  Time: 2.906s,   88.09/s  (2.906s,   88.09/s)  LR: 4.729e-04  Data: 0.268 (0.268)
2024-04-03 01:58:53,530 - train - INFO - Train: 37 [  50/195 ( 26%)]  Loss:  1.820141 (1.6738)  Time: 2.319s,  110.39/s  (2.423s,  105.67/s)  LR: 4.729e-04  Data: 0.005 (0.016)
2024-04-03 02:00:53,101 - train - INFO - Train: 37 [ 100/195 ( 52%)]  Loss:  1.592090 (1.6310)  Time: 2.323s,  110.18/s  (2.407s,  106.35/s)  LR: 4.729e-04  Data: 0.009 (0.014)
2024-04-03 02:02:49,837 - train - INFO - Train: 37 [ 150/195 ( 77%)]  Loss:  1.776064 (1.6280)  Time: 1.986s,  128.92/s  (2.383s,  107.42/s)  LR: 4.729e-04  Data: 0.005 (0.012)
2024-04-03 02:04:33,742 - train - INFO - Train: 37 [ 194/195 (100%)]  Loss:  1.670620 (1.6272)  Time: 2.332s,  109.77/s  (2.378s,  107.64/s)  LR: 4.729e-04  Data: 0.000 (0.012)
2024-04-03 02:04:33,742 - train - INFO - True
2024-04-03 02:04:33,748 - train - INFO - alphas:tensor([0.1741, 0.8259], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,748 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,748 - train - INFO - True
2024-04-03 02:04:33,749 - train - INFO - alphas:tensor([0.2493, 0.7507], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,749 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,749 - train - INFO - True
2024-04-03 02:04:33,749 - train - INFO - alphas:tensor([0.6368, 0.3632], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,749 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,750 - train - INFO - True
2024-04-03 02:04:33,750 - train - INFO - alphas:tensor([0.6029, 0.3971], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,750 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,750 - train - INFO - True
2024-04-03 02:04:33,751 - train - INFO - alphas:tensor([0.3468, 0.6532], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,751 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,751 - train - INFO - True
2024-04-03 02:04:33,756 - train - INFO - alphas:tensor([0.4744, 0.5256], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,756 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,756 - train - INFO - True
2024-04-03 02:04:33,757 - train - INFO - alphas:tensor([0.6660, 0.3340], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,757 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,757 - train - INFO - True
2024-04-03 02:04:33,758 - train - INFO - alphas:tensor([0.5695, 0.4305], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,758 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,758 - train - INFO - True
2024-04-03 02:04:33,759 - train - INFO - alphas:tensor([0.4239, 0.5761], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,759 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,759 - train - INFO - True
2024-04-03 02:04:33,760 - train - INFO - alphas:tensor([0.5565, 0.4435], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,760 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,760 - train - INFO - True
2024-04-03 02:04:33,765 - train - INFO - alphas:tensor([0.6727, 0.3273], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,765 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,765 - train - INFO - True
2024-04-03 02:04:33,766 - train - INFO - alphas:tensor([0.5494, 0.4506], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,766 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,766 - train - INFO - True
2024-04-03 02:04:33,767 - train - INFO - alphas:tensor([0.4349, 0.5651], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,767 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,767 - train - INFO - True
2024-04-03 02:04:33,768 - train - INFO - alphas:tensor([0.5438, 0.4562], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,768 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,768 - train - INFO - True
2024-04-03 02:04:33,768 - train - INFO - alphas:tensor([0.6342, 0.3658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,769 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,769 - train - INFO - True
2024-04-03 02:04:33,769 - train - INFO - alphas:tensor([0.4789, 0.5211], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,769 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,769 - train - INFO - True
2024-04-03 02:04:33,774 - train - INFO - alphas:tensor([0.4092, 0.5908], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,775 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,775 - train - INFO - True
2024-04-03 02:04:33,775 - train - INFO - alphas:tensor([0.4577, 0.5423], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,775 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,775 - train - INFO - True
2024-04-03 02:04:33,776 - train - INFO - alphas:tensor([0.5557, 0.4443], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,776 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,776 - train - INFO - True
2024-04-03 02:04:33,777 - train - INFO - alphas:tensor([0.3715, 0.6285], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,777 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,777 - train - INFO - True
2024-04-03 02:04:33,778 - train - INFO - alphas:tensor([0.3599, 0.6401], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,778 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,778 - train - INFO - True
2024-04-03 02:04:33,779 - train - INFO - alphas:tensor([0.4138, 0.5862], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,779 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,779 - train - INFO - True
2024-04-03 02:04:33,779 - train - INFO - alphas:tensor([0.5119, 0.4881], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,779 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,779 - train - INFO - True
2024-04-03 02:04:33,780 - train - INFO - alphas:tensor([0.3179, 0.6821], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,780 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,780 - train - INFO - True
2024-04-03 02:04:33,781 - train - INFO - alphas:tensor([0.3018, 0.6982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,781 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,781 - train - INFO - True
2024-04-03 02:04:33,782 - train - INFO - alphas:tensor([0.3131, 0.6869], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,782 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,782 - train - INFO - True
2024-04-03 02:04:33,783 - train - INFO - alphas:tensor([0.2277, 0.7723], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,783 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,783 - train - INFO - True
2024-04-03 02:04:33,792 - train - INFO - alphas:tensor([0.0804, 0.9196], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,792 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,792 - train - INFO - True
2024-04-03 02:04:33,793 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:04:33,793 - train - INFO - tau:0.7034476949995692
2024-04-03 02:04:33,793 - train - INFO - avg block size:9.793103448275861
2024-04-03 02:04:35,161 - train - INFO - Test: [   0/39]  Time: 1.366 (1.366)  Loss:  0.4314 (0.4314)  Acc@1: 91.4062 (91.4062)  Acc@5: 99.6094 (99.6094)
2024-04-03 02:05:27,884 - train - INFO - Test: [  39/39]  Time: 1.337 (1.352)  Loss:  0.4312 (0.4039)  Acc@1: 87.5000 (91.5000)  Acc@5: 100.0000 (99.7200)
2024-04-03 02:05:30,428 - train - INFO - Train: 38 [   0/195 (  0%)]  Loss:  1.607942 (1.6079)  Time: 2.385s,  107.35/s  (2.385s,  107.35/s)  LR: 4.689e-04  Data: 0.282 (0.282)
2024-04-03 02:07:26,978 - train - INFO - Train: 38 [  50/195 ( 26%)]  Loss:  1.534713 (1.5692)  Time: 2.290s,  111.80/s  (2.332s,  109.78/s)  LR: 4.689e-04  Data: 0.005 (0.016)
2024-04-03 02:09:23,973 - train - INFO - Train: 38 [ 100/195 ( 52%)]  Loss:  1.795102 (1.5988)  Time: 2.557s,  100.14/s  (2.336s,  109.59/s)  LR: 4.689e-04  Data: 0.005 (0.014)
2024-04-03 02:11:21,666 - train - INFO - Train: 38 [ 150/195 ( 77%)]  Loss:  1.337198 (1.6152)  Time: 2.454s,  104.31/s  (2.342s,  109.32/s)  LR: 4.689e-04  Data: 0.015 (0.014)
2024-04-03 02:13:04,332 - train - INFO - Train: 38 [ 194/195 (100%)]  Loss:  1.505012 (1.6270)  Time: 2.142s,  119.53/s  (2.340s,  109.41/s)  LR: 4.689e-04  Data: 0.000 (0.013)
2024-04-03 02:13:04,332 - train - INFO - True
2024-04-03 02:13:04,333 - train - INFO - alphas:tensor([0.1652, 0.8348], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,333 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,333 - train - INFO - True
2024-04-03 02:13:04,334 - train - INFO - alphas:tensor([0.2417, 0.7583], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,334 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,334 - train - INFO - True
2024-04-03 02:13:04,335 - train - INFO - alphas:tensor([0.6344, 0.3656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,335 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,335 - train - INFO - True
2024-04-03 02:13:04,336 - train - INFO - alphas:tensor([0.5994, 0.4006], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,336 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,336 - train - INFO - True
2024-04-03 02:13:04,337 - train - INFO - alphas:tensor([0.3397, 0.6603], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,337 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,337 - train - INFO - True
2024-04-03 02:13:04,337 - train - INFO - alphas:tensor([0.4686, 0.5314], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,342 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,342 - train - INFO - True
2024-04-03 02:13:04,343 - train - INFO - alphas:tensor([0.6604, 0.3396], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,343 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,343 - train - INFO - True
2024-04-03 02:13:04,343 - train - INFO - alphas:tensor([0.5643, 0.4357], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,343 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,344 - train - INFO - True
2024-04-03 02:13:04,344 - train - INFO - alphas:tensor([0.4190, 0.5810], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,345 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,345 - train - INFO - True
2024-04-03 02:13:04,345 - train - INFO - alphas:tensor([0.5542, 0.4458], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,345 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,346 - train - INFO - True
2024-04-03 02:13:04,346 - train - INFO - alphas:tensor([0.6697, 0.3303], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,346 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,346 - train - INFO - True
2024-04-03 02:13:04,347 - train - INFO - alphas:tensor([0.5454, 0.4546], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,347 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,347 - train - INFO - True
2024-04-03 02:13:04,348 - train - INFO - alphas:tensor([0.4305, 0.5695], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,348 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,348 - train - INFO - True
2024-04-03 02:13:04,349 - train - INFO - alphas:tensor([0.5403, 0.4597], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,349 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,349 - train - INFO - True
2024-04-03 02:13:04,349 - train - INFO - alphas:tensor([0.6297, 0.3703], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,350 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,350 - train - INFO - True
2024-04-03 02:13:04,350 - train - INFO - alphas:tensor([0.4754, 0.5246], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,350 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,350 - train - INFO - True
2024-04-03 02:13:04,351 - train - INFO - alphas:tensor([0.4025, 0.5975], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,351 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,351 - train - INFO - True
2024-04-03 02:13:04,352 - train - INFO - alphas:tensor([0.4518, 0.5482], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,352 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,352 - train - INFO - True
2024-04-03 02:13:04,353 - train - INFO - alphas:tensor([0.5510, 0.4490], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,353 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,353 - train - INFO - True
2024-04-03 02:13:04,353 - train - INFO - alphas:tensor([0.3674, 0.6326], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,354 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,354 - train - INFO - True
2024-04-03 02:13:04,354 - train - INFO - alphas:tensor([0.3536, 0.6464], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,354 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,354 - train - INFO - True
2024-04-03 02:13:04,355 - train - INFO - alphas:tensor([0.4053, 0.5947], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,355 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,355 - train - INFO - True
2024-04-03 02:13:04,356 - train - INFO - alphas:tensor([0.5058, 0.4942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,356 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,356 - train - INFO - True
2024-04-03 02:13:04,357 - train - INFO - alphas:tensor([0.3099, 0.6901], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,357 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,357 - train - INFO - True
2024-04-03 02:13:04,358 - train - INFO - alphas:tensor([0.2963, 0.7037], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,358 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,358 - train - INFO - True
2024-04-03 02:13:04,358 - train - INFO - alphas:tensor([0.3025, 0.6975], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,358 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,358 - train - INFO - True
2024-04-03 02:13:04,359 - train - INFO - alphas:tensor([0.2186, 0.7814], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,359 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,359 - train - INFO - True
2024-04-03 02:13:04,364 - train - INFO - alphas:tensor([0.0718, 0.9282], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,364 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,365 - train - INFO - True
2024-04-03 02:13:04,365 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:13:04,365 - train - INFO - tau:0.6964132180495735
2024-04-03 02:13:04,365 - train - INFO - avg block size:9.793103448275861
2024-04-03 02:13:05,729 - train - INFO - Test: [   0/39]  Time: 1.361 (1.361)  Loss:  0.4050 (0.4050)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.6094 (99.6094)
2024-04-03 02:13:57,814 - train - INFO - Test: [  39/39]  Time: 1.347 (1.336)  Loss:  0.4761 (0.3946)  Acc@1: 81.2500 (91.6000)  Acc@5: 100.0000 (99.7100)
2024-04-03 02:14:00,489 - train - INFO - Train: 39 [   0/195 (  0%)]  Loss:  1.874439 (1.8744)  Time: 2.482s,  103.16/s  (2.482s,  103.16/s)  LR: 4.648e-04  Data: 0.380 (0.380)
2024-04-03 02:15:58,388 - train - INFO - Train: 39 [  50/195 ( 26%)]  Loss:  1.627859 (1.6384)  Time: 2.333s,  109.73/s  (2.360s,  108.46/s)  LR: 4.648e-04  Data: 0.010 (0.018)
2024-04-03 02:17:58,120 - train - INFO - Train: 39 [ 100/195 ( 52%)]  Loss:  1.417389 (1.6280)  Time: 2.518s,  101.66/s  (2.377s,  107.68/s)  LR: 4.648e-04  Data: 0.010 (0.014)
2024-04-03 02:19:55,302 - train - INFO - Train: 39 [ 150/195 ( 77%)]  Loss:  1.390800 (1.6149)  Time: 2.270s,  112.78/s  (2.366s,  108.19/s)  LR: 4.648e-04  Data: 0.010 (0.013)
2024-04-03 02:21:38,764 - train - INFO - Train: 39 [ 194/195 (100%)]  Loss:  1.935550 (1.6193)  Time: 2.471s,  103.60/s  (2.363s,  108.34/s)  LR: 4.648e-04  Data: 0.000 (0.012)
2024-04-03 02:21:38,765 - train - INFO - True
2024-04-03 02:21:38,770 - train - INFO - alphas:tensor([0.1572, 0.8428], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,770 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,771 - train - INFO - True
2024-04-03 02:21:38,771 - train - INFO - alphas:tensor([0.2333, 0.7667], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,771 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,771 - train - INFO - True
2024-04-03 02:21:38,772 - train - INFO - alphas:tensor([0.6355, 0.3645], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,772 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,772 - train - INFO - True
2024-04-03 02:21:38,773 - train - INFO - alphas:tensor([0.5986, 0.4014], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,773 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,773 - train - INFO - True
2024-04-03 02:21:38,774 - train - INFO - alphas:tensor([0.3314, 0.6686], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,774 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,774 - train - INFO - True
2024-04-03 02:21:38,774 - train - INFO - alphas:tensor([0.4608, 0.5392], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,775 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,775 - train - INFO - True
2024-04-03 02:21:38,775 - train - INFO - alphas:tensor([0.6597, 0.3403], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,775 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,775 - train - INFO - True
2024-04-03 02:21:38,776 - train - INFO - alphas:tensor([0.5625, 0.4375], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,776 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,776 - train - INFO - True
2024-04-03 02:21:38,777 - train - INFO - alphas:tensor([0.4140, 0.5860], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,777 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,777 - train - INFO - True
2024-04-03 02:21:38,787 - train - INFO - alphas:tensor([0.5500, 0.4500], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,787 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,787 - train - INFO - True
2024-04-03 02:21:38,788 - train - INFO - alphas:tensor([0.6686, 0.3314], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,788 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,788 - train - INFO - True
2024-04-03 02:21:38,789 - train - INFO - alphas:tensor([0.5419, 0.4581], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,789 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,789 - train - INFO - True
2024-04-03 02:21:38,789 - train - INFO - alphas:tensor([0.4265, 0.5735], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,789 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,789 - train - INFO - True
2024-04-03 02:21:38,790 - train - INFO - alphas:tensor([0.5341, 0.4659], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,790 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,790 - train - INFO - True
2024-04-03 02:21:38,791 - train - INFO - alphas:tensor([0.6245, 0.3755], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,791 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,791 - train - INFO - True
2024-04-03 02:21:38,796 - train - INFO - alphas:tensor([0.4707, 0.5293], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,796 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,796 - train - INFO - True
2024-04-03 02:21:38,797 - train - INFO - alphas:tensor([0.3969, 0.6031], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,797 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,797 - train - INFO - True
2024-04-03 02:21:38,798 - train - INFO - alphas:tensor([0.4483, 0.5517], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,798 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,798 - train - INFO - True
2024-04-03 02:21:38,799 - train - INFO - alphas:tensor([0.5444, 0.4556], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,799 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,799 - train - INFO - True
2024-04-03 02:21:38,799 - train - INFO - alphas:tensor([0.3606, 0.6394], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,799 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,799 - train - INFO - True
2024-04-03 02:21:38,805 - train - INFO - alphas:tensor([0.3495, 0.6505], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,805 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,805 - train - INFO - True
2024-04-03 02:21:38,805 - train - INFO - alphas:tensor([0.4027, 0.5973], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,805 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,806 - train - INFO - True
2024-04-03 02:21:38,806 - train - INFO - alphas:tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,806 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,806 - train - INFO - True
2024-04-03 02:21:38,807 - train - INFO - alphas:tensor([0.3019, 0.6981], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,807 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,807 - train - INFO - True
2024-04-03 02:21:38,808 - train - INFO - alphas:tensor([0.2887, 0.7113], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,808 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,808 - train - INFO - True
2024-04-03 02:21:38,809 - train - INFO - alphas:tensor([0.2916, 0.7084], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,809 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,809 - train - INFO - True
2024-04-03 02:21:38,809 - train - INFO - alphas:tensor([0.2096, 0.7904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,810 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,810 - train - INFO - True
2024-04-03 02:21:38,810 - train - INFO - alphas:tensor([0.0638, 0.9362], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,810 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,810 - train - INFO - True
2024-04-03 02:21:38,811 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:21:38,811 - train - INFO - tau:0.6894490858690777
2024-04-03 02:21:38,811 - train - INFO - avg block size:10.310344827586206
2024-04-03 02:21:40,164 - train - INFO - Test: [   0/39]  Time: 1.350 (1.350)  Loss:  0.3950 (0.3950)  Acc@1: 89.4531 (89.4531)  Acc@5: 100.0000 (100.0000)
2024-04-03 02:22:32,391 - train - INFO - Test: [  39/39]  Time: 1.353 (1.339)  Loss:  0.4351 (0.3804)  Acc@1: 81.2500 (91.3200)  Acc@5: 100.0000 (99.7400)
2024-04-03 02:22:34,916 - train - INFO - Train: 40 [   0/195 (  0%)]  Loss:  1.563190 (1.5632)  Time: 2.337s,  109.54/s  (2.337s,  109.54/s)  LR: 4.607e-04  Data: 0.197 (0.197)
2024-04-03 02:24:33,241 - train - INFO - Train: 40 [  50/195 ( 26%)]  Loss:  1.879048 (1.6286)  Time: 2.306s,  111.00/s  (2.366s,  108.20/s)  LR: 4.607e-04  Data: 0.010 (0.014)
2024-04-03 02:26:28,347 - train - INFO - Train: 40 [ 100/195 ( 52%)]  Loss:  1.717716 (1.6282)  Time: 1.997s,  128.19/s  (2.334s,  109.67/s)  LR: 4.607e-04  Data: 0.015 (0.012)
2024-04-03 02:28:26,153 - train - INFO - Train: 40 [ 150/195 ( 77%)]  Loss:  1.297651 (1.6249)  Time: 2.242s,  114.21/s  (2.342s,  109.33/s)  LR: 4.607e-04  Data: 0.009 (0.012)
2024-04-03 02:30:09,596 - train - INFO - Train: 40 [ 194/195 (100%)]  Loss:  1.819160 (1.6355)  Time: 2.159s,  118.55/s  (2.344s,  109.23/s)  LR: 4.607e-04  Data: 0.000 (0.011)
2024-04-03 02:30:09,597 - train - INFO - True
2024-04-03 02:30:09,598 - train - INFO - alphas:tensor([0.1494, 0.8506], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,598 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,598 - train - INFO - True
2024-04-03 02:30:09,599 - train - INFO - alphas:tensor([0.2261, 0.7739], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,599 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,599 - train - INFO - True
2024-04-03 02:30:09,600 - train - INFO - alphas:tensor([0.6309, 0.3691], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,600 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,600 - train - INFO - True
2024-04-03 02:30:09,601 - train - INFO - alphas:tensor([0.5931, 0.4069], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,601 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,601 - train - INFO - True
2024-04-03 02:30:09,601 - train - INFO - alphas:tensor([0.3277, 0.6723], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,602 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,602 - train - INFO - True
2024-04-03 02:30:09,602 - train - INFO - alphas:tensor([0.4541, 0.5459], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,602 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,602 - train - INFO - True
2024-04-03 02:30:09,603 - train - INFO - alphas:tensor([0.6563, 0.3437], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,603 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,603 - train - INFO - True
2024-04-03 02:30:09,604 - train - INFO - alphas:tensor([0.5573, 0.4427], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,604 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,604 - train - INFO - True
2024-04-03 02:30:09,605 - train - INFO - alphas:tensor([0.4086, 0.5914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,605 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,605 - train - INFO - True
2024-04-03 02:30:09,606 - train - INFO - alphas:tensor([0.5436, 0.4564], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,606 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,606 - train - INFO - True
2024-04-03 02:30:09,607 - train - INFO - alphas:tensor([0.6659, 0.3341], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,607 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,607 - train - INFO - True
2024-04-03 02:30:09,608 - train - INFO - alphas:tensor([0.5402, 0.4598], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,608 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,608 - train - INFO - True
2024-04-03 02:30:09,608 - train - INFO - alphas:tensor([0.4229, 0.5771], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,609 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,609 - train - INFO - True
2024-04-03 02:30:09,609 - train - INFO - alphas:tensor([0.5291, 0.4709], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,609 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,609 - train - INFO - True
2024-04-03 02:30:09,610 - train - INFO - alphas:tensor([0.6237, 0.3763], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,610 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,610 - train - INFO - True
2024-04-03 02:30:09,611 - train - INFO - alphas:tensor([0.4717, 0.5283], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,611 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,611 - train - INFO - True
2024-04-03 02:30:09,612 - train - INFO - alphas:tensor([0.3924, 0.6076], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,612 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,612 - train - INFO - True
2024-04-03 02:30:09,613 - train - INFO - alphas:tensor([0.4429, 0.5571], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,613 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,613 - train - INFO - True
2024-04-03 02:30:09,613 - train - INFO - alphas:tensor([0.5373, 0.4627], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,614 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,614 - train - INFO - True
2024-04-03 02:30:09,614 - train - INFO - alphas:tensor([0.3535, 0.6465], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,614 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,614 - train - INFO - True
2024-04-03 02:30:09,615 - train - INFO - alphas:tensor([0.3431, 0.6569], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,615 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,615 - train - INFO - True
2024-04-03 02:30:09,616 - train - INFO - alphas:tensor([0.3948, 0.6052], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,616 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,616 - train - INFO - True
2024-04-03 02:30:09,617 - train - INFO - alphas:tensor([0.4941, 0.5059], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,617 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,617 - train - INFO - True
2024-04-03 02:30:09,618 - train - INFO - alphas:tensor([0.2962, 0.7038], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,618 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,618 - train - INFO - True
2024-04-03 02:30:09,618 - train - INFO - alphas:tensor([0.2818, 0.7182], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,619 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,619 - train - INFO - True
2024-04-03 02:30:09,619 - train - INFO - alphas:tensor([0.2810, 0.7190], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,619 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,619 - train - INFO - True
2024-04-03 02:30:09,620 - train - INFO - alphas:tensor([0.2022, 0.7978], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,620 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,620 - train - INFO - True
2024-04-03 02:30:09,621 - train - INFO - alphas:tensor([0.0564, 0.9436], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,621 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,621 - train - INFO - True
2024-04-03 02:30:09,622 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:30:09,622 - train - INFO - tau:0.682554595010387
2024-04-03 02:30:09,622 - train - INFO - avg block size:10.310344827586206
2024-04-03 02:30:10,933 - train - INFO - Test: [   0/39]  Time: 1.308 (1.308)  Loss:  0.4370 (0.4370)  Acc@1: 88.2812 (88.2812)  Acc@5: 99.6094 (99.6094)
2024-04-03 02:31:03,982 - train - INFO - Test: [  39/39]  Time: 1.367 (1.359)  Loss:  0.4175 (0.4064)  Acc@1: 87.5000 (91.3000)  Acc@5: 100.0000 (99.6900)
2024-04-03 02:31:06,802 - train - INFO - Train: 41 [   0/195 (  0%)]  Loss:  1.788403 (1.7884)  Time: 2.636s,   97.13/s  (2.636s,   97.13/s)  LR: 4.564e-04  Data: 0.365 (0.365)
2024-04-03 02:33:05,421 - train - INFO - Train: 41 [  50/195 ( 26%)]  Loss:  1.629459 (1.6229)  Time: 2.462s,  103.96/s  (2.378s,  107.67/s)  LR: 4.564e-04  Data: 0.005 (0.016)
2024-04-03 02:35:03,907 - train - INFO - Train: 41 [ 100/195 ( 52%)]  Loss:  1.474805 (1.6475)  Time: 2.139s,  119.70/s  (2.374s,  107.85/s)  LR: 4.564e-04  Data: 0.010 (0.013)
2024-04-03 02:37:02,199 - train - INFO - Train: 41 [ 150/195 ( 77%)]  Loss:  1.339063 (1.6190)  Time: 2.497s,  102.53/s  (2.371s,  107.97/s)  LR: 4.564e-04  Data: 0.005 (0.013)
2024-04-03 02:38:44,879 - train - INFO - Train: 41 [ 194/195 (100%)]  Loss:  1.873318 (1.6134)  Time: 2.444s,  104.75/s  (2.363s,  108.36/s)  LR: 4.564e-04  Data: 0.000 (0.013)
2024-04-03 02:38:44,880 - train - INFO - True
2024-04-03 02:38:44,883 - train - INFO - alphas:tensor([0.1421, 0.8579], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,883 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,884 - train - INFO - True
2024-04-03 02:38:44,884 - train - INFO - alphas:tensor([0.2173, 0.7827], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,884 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,884 - train - INFO - True
2024-04-03 02:38:44,885 - train - INFO - alphas:tensor([0.6286, 0.3714], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,885 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,885 - train - INFO - True
2024-04-03 02:38:44,886 - train - INFO - alphas:tensor([0.5905, 0.4095], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,886 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,886 - train - INFO - True
2024-04-03 02:38:44,887 - train - INFO - alphas:tensor([0.3199, 0.6801], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,888 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,888 - train - INFO - True
2024-04-03 02:38:44,890 - train - INFO - alphas:tensor([0.4490, 0.5510], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,890 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,890 - train - INFO - True
2024-04-03 02:38:44,892 - train - INFO - alphas:tensor([0.6551, 0.3449], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,892 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,892 - train - INFO - True
2024-04-03 02:38:44,898 - train - INFO - alphas:tensor([0.5545, 0.4455], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,899 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,899 - train - INFO - True
2024-04-03 02:38:44,900 - train - INFO - alphas:tensor([0.4039, 0.5961], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,900 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,900 - train - INFO - True
2024-04-03 02:38:44,902 - train - INFO - alphas:tensor([0.5416, 0.4584], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,902 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,902 - train - INFO - True
2024-04-03 02:38:44,903 - train - INFO - alphas:tensor([0.6620, 0.3380], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,903 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,903 - train - INFO - True
2024-04-03 02:38:44,903 - train - INFO - alphas:tensor([0.5356, 0.4644], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,903 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,904 - train - INFO - True
2024-04-03 02:38:44,904 - train - INFO - alphas:tensor([0.4164, 0.5836], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,904 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,904 - train - INFO - True
2024-04-03 02:38:44,905 - train - INFO - alphas:tensor([0.5249, 0.4751], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,905 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,905 - train - INFO - True
2024-04-03 02:38:44,906 - train - INFO - alphas:tensor([0.6213, 0.3787], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,906 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,906 - train - INFO - True
2024-04-03 02:38:44,907 - train - INFO - alphas:tensor([0.4670, 0.5330], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,908 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,908 - train - INFO - True
2024-04-03 02:38:44,913 - train - INFO - alphas:tensor([0.3879, 0.6121], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,913 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,913 - train - INFO - True
2024-04-03 02:38:44,914 - train - INFO - alphas:tensor([0.4395, 0.5605], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,914 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,914 - train - INFO - True
2024-04-03 02:38:44,915 - train - INFO - alphas:tensor([0.5339, 0.4661], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,915 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,915 - train - INFO - True
2024-04-03 02:38:44,915 - train - INFO - alphas:tensor([0.3485, 0.6515], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,915 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,916 - train - INFO - True
2024-04-03 02:38:44,916 - train - INFO - alphas:tensor([0.3393, 0.6607], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,916 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,916 - train - INFO - True
2024-04-03 02:38:44,917 - train - INFO - alphas:tensor([0.3916, 0.6084], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,917 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,917 - train - INFO - True
2024-04-03 02:38:44,919 - train - INFO - alphas:tensor([0.4905, 0.5095], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,919 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,919 - train - INFO - True
2024-04-03 02:38:44,921 - train - INFO - alphas:tensor([0.2903, 0.7097], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,921 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,921 - train - INFO - True
2024-04-03 02:38:44,927 - train - INFO - alphas:tensor([0.2763, 0.7237], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,927 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,927 - train - INFO - True
2024-04-03 02:38:44,928 - train - INFO - alphas:tensor([0.2725, 0.7275], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,928 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,928 - train - INFO - True
2024-04-03 02:38:44,929 - train - INFO - alphas:tensor([0.1956, 0.8044], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,929 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,929 - train - INFO - True
2024-04-03 02:38:44,930 - train - INFO - alphas:tensor([0.0497, 0.9503], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,930 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,930 - train - INFO - True
2024-04-03 02:38:44,931 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:38:44,931 - train - INFO - tau:0.6757290490602831
2024-04-03 02:38:44,931 - train - INFO - avg block size:10.310344827586206
2024-04-03 02:38:46,394 - train - INFO - Test: [   0/39]  Time: 1.460 (1.460)  Loss:  0.3794 (0.3794)  Acc@1: 91.4062 (91.4062)  Acc@5: 100.0000 (100.0000)
2024-04-03 02:39:38,457 - train - INFO - Test: [  39/39]  Time: 1.361 (1.338)  Loss:  0.3928 (0.3773)  Acc@1: 87.5000 (91.5300)  Acc@5: 100.0000 (99.7100)
2024-04-03 02:39:41,326 - train - INFO - Train: 42 [   0/195 (  0%)]  Loss:  1.489901 (1.4899)  Time: 2.724s,   93.96/s  (2.724s,   93.96/s)  LR: 4.521e-04  Data: 0.297 (0.297)
2024-04-03 02:41:38,777 - train - INFO - Train: 42 [  50/195 ( 26%)]  Loss:  1.516377 (1.6207)  Time: 2.535s,  100.97/s  (2.356s,  108.64/s)  LR: 4.521e-04  Data: 0.006 (0.015)
2024-04-03 02:43:34,819 - train - INFO - Train: 42 [ 100/195 ( 52%)]  Loss:  1.822332 (1.6197)  Time: 2.528s,  101.26/s  (2.339s,  109.47/s)  LR: 4.521e-04  Data: 0.014 (0.013)
2024-04-03 02:45:30,955 - train - INFO - Train: 42 [ 150/195 ( 77%)]  Loss:  1.866201 (1.6119)  Time: 2.119s,  120.82/s  (2.333s,  109.71/s)  LR: 4.521e-04  Data: 0.009 (0.012)
2024-04-03 02:47:13,452 - train - INFO - Train: 42 [ 194/195 (100%)]  Loss:  1.720799 (1.6176)  Time: 2.131s,  120.11/s  (2.332s,  109.75/s)  LR: 4.521e-04  Data: 0.000 (0.012)
2024-04-03 02:47:13,457 - train - INFO - True
2024-04-03 02:47:13,458 - train - INFO - alphas:tensor([0.1357, 0.8643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,458 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,458 - train - INFO - True
2024-04-03 02:47:13,459 - train - INFO - alphas:tensor([0.2124, 0.7876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,459 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,459 - train - INFO - True
2024-04-03 02:47:13,460 - train - INFO - alphas:tensor([0.6271, 0.3729], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,460 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,460 - train - INFO - True
2024-04-03 02:47:13,460 - train - INFO - alphas:tensor([0.5874, 0.4126], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,461 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,461 - train - INFO - True
2024-04-03 02:47:13,461 - train - INFO - alphas:tensor([0.3170, 0.6830], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,461 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,461 - train - INFO - True
2024-04-03 02:47:13,462 - train - INFO - alphas:tensor([0.4476, 0.5524], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,462 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,463 - train - INFO - True
2024-04-03 02:47:13,463 - train - INFO - alphas:tensor([0.6514, 0.3486], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,463 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,463 - train - INFO - True
2024-04-03 02:47:13,464 - train - INFO - alphas:tensor([0.5514, 0.4486], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,464 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,464 - train - INFO - True
2024-04-03 02:47:13,465 - train - INFO - alphas:tensor([0.3988, 0.6012], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,465 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,465 - train - INFO - True
2024-04-03 02:47:13,470 - train - INFO - alphas:tensor([0.5362, 0.4638], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,470 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,470 - train - INFO - True
2024-04-03 02:47:13,471 - train - INFO - alphas:tensor([0.6597, 0.3403], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,471 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,471 - train - INFO - True
2024-04-03 02:47:13,472 - train - INFO - alphas:tensor([0.5335, 0.4665], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,472 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,472 - train - INFO - True
2024-04-03 02:47:13,473 - train - INFO - alphas:tensor([0.4122, 0.5878], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,473 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,473 - train - INFO - True
2024-04-03 02:47:13,473 - train - INFO - alphas:tensor([0.5219, 0.4781], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,473 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,474 - train - INFO - True
2024-04-03 02:47:13,474 - train - INFO - alphas:tensor([0.6155, 0.3845], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,474 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,474 - train - INFO - True
2024-04-03 02:47:13,475 - train - INFO - alphas:tensor([0.4592, 0.5408], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,475 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,475 - train - INFO - True
2024-04-03 02:47:13,476 - train - INFO - alphas:tensor([0.3830, 0.6170], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,476 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,476 - train - INFO - True
2024-04-03 02:47:13,477 - train - INFO - alphas:tensor([0.4344, 0.5656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,477 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,477 - train - INFO - True
2024-04-03 02:47:13,477 - train - INFO - alphas:tensor([0.5308, 0.4692], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,477 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,478 - train - INFO - True
2024-04-03 02:47:13,478 - train - INFO - alphas:tensor([0.3453, 0.6547], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,478 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,478 - train - INFO - True
2024-04-03 02:47:13,479 - train - INFO - alphas:tensor([0.3334, 0.6666], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,479 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,479 - train - INFO - True
2024-04-03 02:47:13,480 - train - INFO - alphas:tensor([0.3846, 0.6154], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,480 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,480 - train - INFO - True
2024-04-03 02:47:13,481 - train - INFO - alphas:tensor([0.4872, 0.5128], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,481 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,481 - train - INFO - True
2024-04-03 02:47:13,481 - train - INFO - alphas:tensor([0.2874, 0.7126], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,482 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,482 - train - INFO - True
2024-04-03 02:47:13,482 - train - INFO - alphas:tensor([0.2706, 0.7294], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,482 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,482 - train - INFO - True
2024-04-03 02:47:13,483 - train - INFO - alphas:tensor([0.2636, 0.7364], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,483 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,483 - train - INFO - True
2024-04-03 02:47:13,484 - train - INFO - alphas:tensor([0.1895, 0.8105], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,484 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,484 - train - INFO - True
2024-04-03 02:47:13,485 - train - INFO - alphas:tensor([0.0441, 0.9559], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,485 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,485 - train - INFO - True
2024-04-03 02:47:13,485 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:47:13,486 - train - INFO - tau:0.6689717585696803
2024-04-03 02:47:13,486 - train - INFO - avg block size:10.310344827586206
2024-04-03 02:47:14,844 - train - INFO - Test: [   0/39]  Time: 1.351 (1.351)  Loss:  0.3931 (0.3931)  Acc@1: 91.0156 (91.0156)  Acc@5: 100.0000 (100.0000)
2024-04-03 02:48:07,663 - train - INFO - Test: [  39/39]  Time: 1.369 (1.354)  Loss:  0.4180 (0.3852)  Acc@1: 81.2500 (91.6000)  Acc@5: 100.0000 (99.6900)
2024-04-03 02:48:10,530 - train - INFO - Train: 43 [   0/195 (  0%)]  Loss:  1.427525 (1.4275)  Time: 2.670s,   95.89/s  (2.670s,   95.89/s)  LR: 4.477e-04  Data: 0.365 (0.365)
2024-04-03 02:50:08,070 - train - INFO - Train: 43 [  50/195 ( 26%)]  Loss:  1.687299 (1.6135)  Time: 2.173s,  117.82/s  (2.357s,  108.62/s)  LR: 4.477e-04  Data: 0.005 (0.018)
2024-04-03 02:52:04,116 - train - INFO - Train: 43 [ 100/195 ( 52%)]  Loss:  1.575752 (1.6049)  Time: 1.991s,  128.59/s  (2.339s,  109.45/s)  LR: 4.477e-04  Data: 0.006 (0.014)
2024-04-03 02:54:03,250 - train - INFO - Train: 43 [ 150/195 ( 77%)]  Loss:  1.231030 (1.6128)  Time: 2.582s,   99.14/s  (2.353s,  108.77/s)  LR: 4.477e-04  Data: 0.018 (0.013)
2024-04-03 02:55:48,739 - train - INFO - Train: 43 [ 194/195 (100%)]  Loss:  1.539868 (1.5983)  Time: 2.712s,   94.41/s  (2.363s,  108.32/s)  LR: 4.477e-04  Data: 0.000 (0.013)
2024-04-03 02:55:48,740 - train - INFO - True
2024-04-03 02:55:48,745 - train - INFO - alphas:tensor([0.1292, 0.8708], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,745 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,745 - train - INFO - True
2024-04-03 02:55:48,746 - train - INFO - alphas:tensor([0.2055, 0.7945], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,746 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,746 - train - INFO - True
2024-04-03 02:55:48,747 - train - INFO - alphas:tensor([0.6253, 0.3747], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,747 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,747 - train - INFO - True
2024-04-03 02:55:48,748 - train - INFO - alphas:tensor([0.5844, 0.4156], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,748 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,748 - train - INFO - True
2024-04-03 02:55:48,748 - train - INFO - alphas:tensor([0.3108, 0.6892], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,749 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,749 - train - INFO - True
2024-04-03 02:55:48,758 - train - INFO - alphas:tensor([0.4407, 0.5593], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,758 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,758 - train - INFO - True
2024-04-03 02:55:48,759 - train - INFO - alphas:tensor([0.6484, 0.3516], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,759 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,759 - train - INFO - True
2024-04-03 02:55:48,760 - train - INFO - alphas:tensor([0.5471, 0.4529], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,760 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,760 - train - INFO - True
2024-04-03 02:55:48,761 - train - INFO - alphas:tensor([0.3946, 0.6054], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,761 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,761 - train - INFO - True
2024-04-03 02:55:48,761 - train - INFO - alphas:tensor([0.5357, 0.4643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,761 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,762 - train - INFO - True
2024-04-03 02:55:48,762 - train - INFO - alphas:tensor([0.6554, 0.3446], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,762 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,762 - train - INFO - True
2024-04-03 02:55:48,763 - train - INFO - alphas:tensor([0.5269, 0.4731], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,763 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,763 - train - INFO - True
2024-04-03 02:55:48,764 - train - INFO - alphas:tensor([0.4079, 0.5921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,764 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,764 - train - INFO - True
2024-04-03 02:55:48,769 - train - INFO - alphas:tensor([0.5168, 0.4832], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,769 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,769 - train - INFO - True
2024-04-03 02:55:48,770 - train - INFO - alphas:tensor([0.6131, 0.3869], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,770 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,770 - train - INFO - True
2024-04-03 02:55:48,771 - train - INFO - alphas:tensor([0.4572, 0.5428], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,771 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,771 - train - INFO - True
2024-04-03 02:55:48,776 - train - INFO - alphas:tensor([0.3795, 0.6205], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,776 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,776 - train - INFO - True
2024-04-03 02:55:48,777 - train - INFO - alphas:tensor([0.4326, 0.5674], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,777 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,777 - train - INFO - True
2024-04-03 02:55:48,782 - train - INFO - alphas:tensor([0.5260, 0.4740], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,782 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,782 - train - INFO - True
2024-04-03 02:55:48,787 - train - INFO - alphas:tensor([0.3406, 0.6594], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,787 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,787 - train - INFO - True
2024-04-03 02:55:48,788 - train - INFO - alphas:tensor([0.3271, 0.6729], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,788 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,788 - train - INFO - True
2024-04-03 02:55:48,789 - train - INFO - alphas:tensor([0.3785, 0.6215], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,789 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,789 - train - INFO - True
2024-04-03 02:55:48,790 - train - INFO - alphas:tensor([0.4824, 0.5176], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,790 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,790 - train - INFO - True
2024-04-03 02:55:48,790 - train - INFO - alphas:tensor([0.2820, 0.7180], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,790 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,791 - train - INFO - True
2024-04-03 02:55:48,800 - train - INFO - alphas:tensor([0.2635, 0.7365], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,800 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,800 - train - INFO - True
2024-04-03 02:55:48,801 - train - INFO - alphas:tensor([0.2517, 0.7483], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,801 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,801 - train - INFO - True
2024-04-03 02:55:48,802 - train - INFO - alphas:tensor([0.1826, 0.8174], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,802 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,802 - train - INFO - True
2024-04-03 02:55:48,811 - train - INFO - alphas:tensor([0.0387, 0.9613], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,812 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,812 - train - INFO - True
2024-04-03 02:55:48,812 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 02:55:48,812 - train - INFO - tau:0.6622820409839835
2024-04-03 02:55:48,812 - train - INFO - avg block size:10.310344827586206
2024-04-03 02:55:50,271 - train - INFO - Test: [   0/39]  Time: 1.456 (1.456)  Loss:  0.3865 (0.3865)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.6094 (99.6094)
2024-04-03 02:56:43,371 - train - INFO - Test: [  39/39]  Time: 1.339 (1.364)  Loss:  0.5117 (0.3822)  Acc@1: 81.2500 (91.4600)  Acc@5: 100.0000 (99.6800)
2024-04-03 02:56:46,225 - train - INFO - Train: 44 [   0/195 (  0%)]  Loss:  1.341484 (1.3415)  Time: 2.661s,   96.22/s  (2.661s,   96.22/s)  LR: 4.432e-04  Data: 0.231 (0.231)
2024-04-03 02:58:43,896 - train - INFO - Train: 44 [  50/195 ( 26%)]  Loss:  1.819235 (1.6514)  Time: 2.848s,   89.90/s  (2.359s,  108.50/s)  LR: 4.432e-04  Data: 0.006 (0.015)
2024-04-03 03:00:40,201 - train - INFO - Train: 44 [ 100/195 ( 52%)]  Loss:  1.879835 (1.6277)  Time: 2.256s,  113.47/s  (2.343s,  109.27/s)  LR: 4.432e-04  Data: 0.014 (0.013)
2024-04-03 03:02:38,713 - train - INFO - Train: 44 [ 150/195 ( 77%)]  Loss:  1.706800 (1.6185)  Time: 2.648s,   96.66/s  (2.352s,  108.85/s)  LR: 4.432e-04  Data: 0.006 (0.012)
2024-04-03 03:04:21,380 - train - INFO - Train: 44 [ 194/195 (100%)]  Loss:  1.445563 (1.6120)  Time: 2.110s,  121.35/s  (2.348s,  109.04/s)  LR: 4.432e-04  Data: 0.000 (0.012)
2024-04-03 03:04:21,381 - train - INFO - True
2024-04-03 03:04:21,382 - train - INFO - alphas:tensor([0.1225, 0.8775], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,382 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,382 - train - INFO - True
2024-04-03 03:04:21,383 - train - INFO - alphas:tensor([0.2003, 0.7997], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,383 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,383 - train - INFO - True
2024-04-03 03:04:21,384 - train - INFO - alphas:tensor([0.6250, 0.3750], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,384 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,384 - train - INFO - True
2024-04-03 03:04:21,384 - train - INFO - alphas:tensor([0.5826, 0.4174], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,385 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,385 - train - INFO - True
2024-04-03 03:04:21,385 - train - INFO - alphas:tensor([0.3060, 0.6940], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,385 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,385 - train - INFO - True
2024-04-03 03:04:21,386 - train - INFO - alphas:tensor([0.4333, 0.5667], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,386 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,386 - train - INFO - True
2024-04-03 03:04:21,387 - train - INFO - alphas:tensor([0.6460, 0.3540], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,387 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,387 - train - INFO - True
2024-04-03 03:04:21,388 - train - INFO - alphas:tensor([0.5460, 0.4540], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,388 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,388 - train - INFO - True
2024-04-03 03:04:21,389 - train - INFO - alphas:tensor([0.3927, 0.6073], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,399 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,399 - train - INFO - True
2024-04-03 03:04:21,400 - train - INFO - alphas:tensor([0.5319, 0.4681], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,400 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,400 - train - INFO - True
2024-04-03 03:04:21,401 - train - INFO - alphas:tensor([0.6526, 0.3474], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,405 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,405 - train - INFO - True
2024-04-03 03:04:21,406 - train - INFO - alphas:tensor([0.5235, 0.4765], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,406 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,406 - train - INFO - True
2024-04-03 03:04:21,407 - train - INFO - alphas:tensor([0.4056, 0.5944], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,407 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,407 - train - INFO - True
2024-04-03 03:04:21,408 - train - INFO - alphas:tensor([0.5152, 0.4848], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,408 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,408 - train - INFO - True
2024-04-03 03:04:21,417 - train - INFO - alphas:tensor([0.6092, 0.3908], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,417 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,417 - train - INFO - True
2024-04-03 03:04:21,418 - train - INFO - alphas:tensor([0.4546, 0.5454], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,418 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,418 - train - INFO - True
2024-04-03 03:04:21,419 - train - INFO - alphas:tensor([0.3735, 0.6265], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,423 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,423 - train - INFO - True
2024-04-03 03:04:21,424 - train - INFO - alphas:tensor([0.4265, 0.5735], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,424 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,424 - train - INFO - True
2024-04-03 03:04:21,425 - train - INFO - alphas:tensor([0.5221, 0.4779], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,425 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,425 - train - INFO - True
2024-04-03 03:04:21,426 - train - INFO - alphas:tensor([0.3368, 0.6632], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,426 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,426 - train - INFO - True
2024-04-03 03:04:21,427 - train - INFO - alphas:tensor([0.3229, 0.6771], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,427 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,427 - train - INFO - True
2024-04-03 03:04:21,427 - train - INFO - alphas:tensor([0.3761, 0.6239], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,427 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,428 - train - INFO - True
2024-04-03 03:04:21,428 - train - INFO - alphas:tensor([0.4788, 0.5212], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,428 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,428 - train - INFO - True
2024-04-03 03:04:21,429 - train - INFO - alphas:tensor([0.2780, 0.7220], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,429 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,429 - train - INFO - True
2024-04-03 03:04:21,430 - train - INFO - alphas:tensor([0.2593, 0.7407], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,430 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,430 - train - INFO - True
2024-04-03 03:04:21,431 - train - INFO - alphas:tensor([0.2446, 0.7554], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,435 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,435 - train - INFO - True
2024-04-03 03:04:21,436 - train - INFO - alphas:tensor([0.1764, 0.8236], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,450 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,451 - train - INFO - True
2024-04-03 03:04:21,451 - train - INFO - alphas:tensor([0.0341, 0.9659], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,451 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,451 - train - INFO - True
2024-04-03 03:04:21,452 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:04:21,452 - train - INFO - tau:0.6556592205741436
2024-04-03 03:04:21,452 - train - INFO - avg block size:10.310344827586206
2024-04-03 03:04:22,823 - train - INFO - Test: [   0/39]  Time: 1.368 (1.368)  Loss:  0.4119 (0.4119)  Acc@1: 90.2344 (90.2344)  Acc@5: 99.6094 (99.6094)
2024-04-03 03:05:15,094 - train - INFO - Test: [  39/39]  Time: 1.352 (1.341)  Loss:  0.4839 (0.3953)  Acc@1: 87.5000 (91.5400)  Acc@5: 100.0000 (99.6500)
2024-04-03 03:05:17,965 - train - INFO - Train: 45 [   0/195 (  0%)]  Loss:  1.805256 (1.8053)  Time: 2.689s,   95.20/s  (2.689s,   95.20/s)  LR: 4.387e-04  Data: 0.193 (0.193)
2024-04-03 03:07:16,302 - train - INFO - Train: 45 [  50/195 ( 26%)]  Loss:  1.864865 (1.6638)  Time: 2.754s,   92.95/s  (2.373s,  107.88/s)  LR: 4.387e-04  Data: 0.007 (0.014)
2024-04-03 03:09:14,489 - train - INFO - Train: 45 [ 100/195 ( 52%)]  Loss:  1.786059 (1.6633)  Time: 2.239s,  114.35/s  (2.368s,  108.09/s)  LR: 4.387e-04  Data: 0.009 (0.013)
2024-04-03 03:11:09,544 - train - INFO - Train: 45 [ 150/195 ( 77%)]  Loss:  1.823943 (1.6486)  Time: 2.223s,  115.14/s  (2.346s,  109.12/s)  LR: 4.387e-04  Data: 0.017 (0.012)
2024-04-03 03:12:53,168 - train - INFO - Train: 45 [ 194/195 (100%)]  Loss:  1.508987 (1.6381)  Time: 2.344s,  109.21/s  (2.348s,  109.02/s)  LR: 4.387e-04  Data: 0.000 (0.012)
2024-04-03 03:12:53,169 - train - INFO - True
2024-04-03 03:12:53,170 - train - INFO - alphas:tensor([0.1155, 0.8845], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,170 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,170 - train - INFO - True
2024-04-03 03:12:53,171 - train - INFO - alphas:tensor([0.1937, 0.8063], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,171 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,171 - train - INFO - True
2024-04-03 03:12:53,172 - train - INFO - alphas:tensor([0.6222, 0.3778], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,172 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,172 - train - INFO - True
2024-04-03 03:12:53,173 - train - INFO - alphas:tensor([0.5777, 0.4223], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,173 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,173 - train - INFO - True
2024-04-03 03:12:53,174 - train - INFO - alphas:tensor([0.3016, 0.6984], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,174 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,174 - train - INFO - True
2024-04-03 03:12:53,175 - train - INFO - alphas:tensor([0.4266, 0.5734], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,175 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,175 - train - INFO - True
2024-04-03 03:12:53,176 - train - INFO - alphas:tensor([0.6441, 0.3559], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,176 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,176 - train - INFO - True
2024-04-03 03:12:53,176 - train - INFO - alphas:tensor([0.5423, 0.4577], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,177 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,177 - train - INFO - True
2024-04-03 03:12:53,178 - train - INFO - alphas:tensor([0.3865, 0.6135], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,178 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,178 - train - INFO - True
2024-04-03 03:12:53,178 - train - INFO - alphas:tensor([0.5268, 0.4732], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,179 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,179 - train - INFO - True
2024-04-03 03:12:53,179 - train - INFO - alphas:tensor([0.6510, 0.3490], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,179 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,179 - train - INFO - True
2024-04-03 03:12:53,180 - train - INFO - alphas:tensor([0.5229, 0.4771], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,180 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,180 - train - INFO - True
2024-04-03 03:12:53,181 - train - INFO - alphas:tensor([0.4003, 0.5997], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,181 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,181 - train - INFO - True
2024-04-03 03:12:53,182 - train - INFO - alphas:tensor([0.5103, 0.4897], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,182 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,182 - train - INFO - True
2024-04-03 03:12:53,183 - train - INFO - alphas:tensor([0.6041, 0.3959], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,183 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,183 - train - INFO - True
2024-04-03 03:12:53,183 - train - INFO - alphas:tensor([0.4464, 0.5536], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,184 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,184 - train - INFO - True
2024-04-03 03:12:53,184 - train - INFO - alphas:tensor([0.3694, 0.6306], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,184 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,184 - train - INFO - True
2024-04-03 03:12:53,185 - train - INFO - alphas:tensor([0.4237, 0.5763], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,185 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,185 - train - INFO - True
2024-04-03 03:12:53,186 - train - INFO - alphas:tensor([0.5155, 0.4845], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,186 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,186 - train - INFO - True
2024-04-03 03:12:53,187 - train - INFO - alphas:tensor([0.3275, 0.6725], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,187 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,187 - train - INFO - True
2024-04-03 03:12:53,187 - train - INFO - alphas:tensor([0.3175, 0.6825], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,188 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,188 - train - INFO - True
2024-04-03 03:12:53,188 - train - INFO - alphas:tensor([0.3700, 0.6300], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,188 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,188 - train - INFO - True
2024-04-03 03:12:53,189 - train - INFO - alphas:tensor([0.4743, 0.5257], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,189 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,189 - train - INFO - True
2024-04-03 03:12:53,190 - train - INFO - alphas:tensor([0.2719, 0.7281], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,190 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,190 - train - INFO - True
2024-04-03 03:12:53,191 - train - INFO - alphas:tensor([0.2536, 0.7464], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,191 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,191 - train - INFO - True
2024-04-03 03:12:53,192 - train - INFO - alphas:tensor([0.2335, 0.7665], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,192 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,192 - train - INFO - True
2024-04-03 03:12:53,192 - train - INFO - alphas:tensor([0.1672, 0.8328], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,193 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,193 - train - INFO - True
2024-04-03 03:12:53,193 - train - INFO - alphas:tensor([0.0298, 0.9702], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,193 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,193 - train - INFO - True
2024-04-03 03:12:53,194 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:12:53,194 - train - INFO - tau:0.6491026283684022
2024-04-03 03:12:53,194 - train - INFO - avg block size:10.310344827586206
2024-04-03 03:12:54,555 - train - INFO - Test: [   0/39]  Time: 1.358 (1.358)  Loss:  0.4060 (0.4060)  Acc@1: 91.4062 (91.4062)  Acc@5: 99.6094 (99.6094)
2024-04-03 03:13:47,520 - train - INFO - Test: [  39/39]  Time: 1.327 (1.358)  Loss:  0.4673 (0.3990)  Acc@1: 87.5000 (91.5200)  Acc@5: 100.0000 (99.6200)
2024-04-03 03:13:50,342 - train - INFO - Train: 46 [   0/195 (  0%)]  Loss:  1.878874 (1.8789)  Time: 2.632s,   97.26/s  (2.632s,   97.26/s)  LR: 4.341e-04  Data: 0.346 (0.346)
2024-04-03 03:15:50,946 - train - INFO - Train: 46 [  50/195 ( 26%)]  Loss:  1.738725 (1.6199)  Time: 2.356s,  108.66/s  (2.416s,  105.95/s)  LR: 4.341e-04  Data: 0.005 (0.018)
2024-04-03 03:17:49,208 - train - INFO - Train: 46 [ 100/195 ( 52%)]  Loss:  1.417109 (1.6117)  Time: 2.594s,   98.69/s  (2.391s,  107.07/s)  LR: 4.341e-04  Data: 0.018 (0.015)
2024-04-03 03:19:47,322 - train - INFO - Train: 46 [ 150/195 ( 77%)]  Loss:  1.340084 (1.6002)  Time: 2.477s,  103.34/s  (2.381s,  107.50/s)  LR: 4.341e-04  Data: 0.005 (0.013)
2024-04-03 03:21:31,037 - train - INFO - Train: 46 [ 194/195 (100%)]  Loss:  1.868433 (1.6066)  Time: 2.382s,  107.49/s  (2.376s,  107.74/s)  LR: 4.341e-04  Data: 0.000 (0.013)
2024-04-03 03:21:31,037 - train - INFO - True
2024-04-03 03:21:31,039 - train - INFO - alphas:tensor([0.1103, 0.8897], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,040 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,040 - train - INFO - True
2024-04-03 03:21:31,040 - train - INFO - alphas:tensor([0.1894, 0.8106], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,041 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,041 - train - INFO - True
2024-04-03 03:21:31,041 - train - INFO - alphas:tensor([0.6201, 0.3799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,046 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,046 - train - INFO - True
2024-04-03 03:21:31,047 - train - INFO - alphas:tensor([0.5742, 0.4258], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,047 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,047 - train - INFO - True
2024-04-03 03:21:31,048 - train - INFO - alphas:tensor([0.2964, 0.7036], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,048 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,048 - train - INFO - True
2024-04-03 03:21:31,049 - train - INFO - alphas:tensor([0.4200, 0.5800], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,049 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,049 - train - INFO - True
2024-04-03 03:21:31,049 - train - INFO - alphas:tensor([0.6427, 0.3573], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,049 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,050 - train - INFO - True
2024-04-03 03:21:31,050 - train - INFO - alphas:tensor([0.5405, 0.4595], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,050 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,050 - train - INFO - True
2024-04-03 03:21:31,051 - train - INFO - alphas:tensor([0.3819, 0.6181], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,055 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,055 - train - INFO - True
2024-04-03 03:21:31,056 - train - INFO - alphas:tensor([0.5195, 0.4805], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,057 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,057 - train - INFO - True
2024-04-03 03:21:31,057 - train - INFO - alphas:tensor([0.6488, 0.3512], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,057 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,057 - train - INFO - True
2024-04-03 03:21:31,058 - train - INFO - alphas:tensor([0.5194, 0.4806], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,058 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,058 - train - INFO - True
2024-04-03 03:21:31,059 - train - INFO - alphas:tensor([0.3949, 0.6051], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,059 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,059 - train - INFO - True
2024-04-03 03:21:31,082 - train - INFO - alphas:tensor([0.5071, 0.4929], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,082 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,082 - train - INFO - True
2024-04-03 03:21:31,083 - train - INFO - alphas:tensor([0.6027, 0.3973], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,083 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,083 - train - INFO - True
2024-04-03 03:21:31,083 - train - INFO - alphas:tensor([0.4479, 0.5521], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,083 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,084 - train - INFO - True
2024-04-03 03:21:31,084 - train - INFO - alphas:tensor([0.3641, 0.6359], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,084 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,084 - train - INFO - True
2024-04-03 03:21:31,085 - train - INFO - alphas:tensor([0.4161, 0.5839], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,085 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,085 - train - INFO - True
2024-04-03 03:21:31,086 - train - INFO - alphas:tensor([0.5112, 0.4888], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,086 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,086 - train - INFO - True
2024-04-03 03:21:31,119 - train - INFO - alphas:tensor([0.3246, 0.6754], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,119 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,119 - train - INFO - True
2024-04-03 03:21:31,120 - train - INFO - alphas:tensor([0.3134, 0.6866], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,120 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,120 - train - INFO - True
2024-04-03 03:21:31,120 - train - INFO - alphas:tensor([0.3656, 0.6344], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,121 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,121 - train - INFO - True
2024-04-03 03:21:31,121 - train - INFO - alphas:tensor([0.4698, 0.5302], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,121 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,121 - train - INFO - True
2024-04-03 03:21:31,122 - train - INFO - alphas:tensor([0.2674, 0.7326], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,122 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,122 - train - INFO - True
2024-04-03 03:21:31,132 - train - INFO - alphas:tensor([0.2515, 0.7485], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,132 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,132 - train - INFO - True
2024-04-03 03:21:31,133 - train - INFO - alphas:tensor([0.2257, 0.7743], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,133 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,133 - train - INFO - True
2024-04-03 03:21:31,138 - train - INFO - alphas:tensor([0.1620, 0.8380], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,138 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,138 - train - INFO - True
2024-04-03 03:21:31,139 - train - INFO - alphas:tensor([0.0262, 0.9738], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,139 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,139 - train - INFO - True
2024-04-03 03:21:31,139 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:21:31,139 - train - INFO - tau:0.6426116020847181
2024-04-03 03:21:31,148 - train - INFO - avg block size:10.310344827586206
2024-04-03 03:21:32,512 - train - INFO - Test: [   0/39]  Time: 1.361 (1.361)  Loss:  0.4326 (0.4326)  Acc@1: 89.8438 (89.8438)  Acc@5: 100.0000 (100.0000)
2024-04-03 03:22:25,391 - train - INFO - Test: [  39/39]  Time: 1.330 (1.356)  Loss:  0.3765 (0.3998)  Acc@1: 81.2500 (91.7800)  Acc@5: 100.0000 (99.7700)
2024-04-03 03:22:28,069 - train - INFO - Train: 47 [   0/195 (  0%)]  Loss:  1.725473 (1.7255)  Time: 2.456s,  104.25/s  (2.456s,  104.25/s)  LR: 4.294e-04  Data: 0.338 (0.338)
2024-04-03 03:24:24,862 - train - INFO - Train: 47 [  50/195 ( 26%)]  Loss:  1.297113 (1.5609)  Time: 2.204s,  116.13/s  (2.338s,  109.49/s)  LR: 4.294e-04  Data: 0.019 (0.018)
2024-04-03 03:26:26,174 - train - INFO - Train: 47 [ 100/195 ( 52%)]  Loss:  1.830019 (1.5751)  Time: 2.070s,  123.65/s  (2.382s,  107.48/s)  LR: 4.294e-04  Data: 0.005 (0.014)
2024-04-03 03:28:25,144 - train - INFO - Train: 47 [ 150/195 ( 77%)]  Loss:  1.615524 (1.5940)  Time: 2.250s,  113.78/s  (2.381s,  107.52/s)  LR: 4.294e-04  Data: 0.005 (0.012)
2024-04-03 03:30:08,022 - train - INFO - Train: 47 [ 194/195 (100%)]  Loss:  1.492490 (1.6025)  Time: 2.313s,  110.66/s  (2.371s,  107.96/s)  LR: 4.294e-04  Data: 0.000 (0.012)
2024-04-03 03:30:08,023 - train - INFO - True
2024-04-03 03:30:08,024 - train - INFO - alphas:tensor([0.1044, 0.8956], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,024 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,024 - train - INFO - True
2024-04-03 03:30:08,025 - train - INFO - alphas:tensor([0.1843, 0.8157], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,025 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,025 - train - INFO - True
2024-04-03 03:30:08,026 - train - INFO - alphas:tensor([0.6199, 0.3801], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,026 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,026 - train - INFO - True
2024-04-03 03:30:08,027 - train - INFO - alphas:tensor([0.5733, 0.4267], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,027 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,027 - train - INFO - True
2024-04-03 03:30:08,027 - train - INFO - alphas:tensor([0.2937, 0.7063], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,028 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,028 - train - INFO - True
2024-04-03 03:30:08,028 - train - INFO - alphas:tensor([0.4163, 0.5837], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,028 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,028 - train - INFO - True
2024-04-03 03:30:08,029 - train - INFO - alphas:tensor([0.6388, 0.3612], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,029 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,029 - train - INFO - True
2024-04-03 03:30:08,030 - train - INFO - alphas:tensor([0.5364, 0.4636], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,030 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,030 - train - INFO - True
2024-04-03 03:30:08,031 - train - INFO - alphas:tensor([0.3783, 0.6217], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,031 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,031 - train - INFO - True
2024-04-03 03:30:08,032 - train - INFO - alphas:tensor([0.5182, 0.4818], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,032 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,032 - train - INFO - True
2024-04-03 03:30:08,033 - train - INFO - alphas:tensor([0.6461, 0.3539], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,033 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,033 - train - INFO - True
2024-04-03 03:30:08,034 - train - INFO - alphas:tensor([0.5185, 0.4815], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,034 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,034 - train - INFO - True
2024-04-03 03:30:08,034 - train - INFO - alphas:tensor([0.3922, 0.6078], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,035 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,035 - train - INFO - True
2024-04-03 03:30:08,035 - train - INFO - alphas:tensor([0.5049, 0.4951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,035 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,035 - train - INFO - True
2024-04-03 03:30:08,036 - train - INFO - alphas:tensor([0.5997, 0.4003], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,036 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,036 - train - INFO - True
2024-04-03 03:30:08,037 - train - INFO - alphas:tensor([0.4437, 0.5563], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,037 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,037 - train - INFO - True
2024-04-03 03:30:08,038 - train - INFO - alphas:tensor([0.3596, 0.6404], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,038 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,038 - train - INFO - True
2024-04-03 03:30:08,039 - train - INFO - alphas:tensor([0.4118, 0.5882], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,039 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,039 - train - INFO - True
2024-04-03 03:30:08,039 - train - INFO - alphas:tensor([0.5106, 0.4894], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,040 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,040 - train - INFO - True
2024-04-03 03:30:08,040 - train - INFO - alphas:tensor([0.3269, 0.6731], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,040 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,040 - train - INFO - True
2024-04-03 03:30:08,041 - train - INFO - alphas:tensor([0.3079, 0.6921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,041 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,041 - train - INFO - True
2024-04-03 03:30:08,042 - train - INFO - alphas:tensor([0.3603, 0.6397], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,042 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,042 - train - INFO - True
2024-04-03 03:30:08,043 - train - INFO - alphas:tensor([0.4648, 0.5352], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,043 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,043 - train - INFO - True
2024-04-03 03:30:08,044 - train - INFO - alphas:tensor([0.2620, 0.7380], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,044 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,044 - train - INFO - True
2024-04-03 03:30:08,044 - train - INFO - alphas:tensor([0.2437, 0.7563], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,045 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,045 - train - INFO - True
2024-04-03 03:30:08,045 - train - INFO - alphas:tensor([0.2176, 0.7824], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,045 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,045 - train - INFO - True
2024-04-03 03:30:08,046 - train - INFO - alphas:tensor([0.1567, 0.8433], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,046 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,046 - train - INFO - True
2024-04-03 03:30:08,047 - train - INFO - alphas:tensor([0.0230, 0.9770], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,047 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,047 - train - INFO - True
2024-04-03 03:30:08,048 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:30:08,048 - train - INFO - tau:0.6361854860638709
2024-04-03 03:30:08,048 - train - INFO - avg block size:10.310344827586206
2024-04-03 03:30:09,428 - train - INFO - Test: [   0/39]  Time: 1.377 (1.377)  Loss:  0.3914 (0.3914)  Acc@1: 91.0156 (91.0156)  Acc@5: 100.0000 (100.0000)
2024-04-03 03:31:02,118 - train - INFO - Test: [  39/39]  Time: 1.335 (1.352)  Loss:  0.3401 (0.3834)  Acc@1: 93.7500 (91.6500)  Acc@5: 100.0000 (99.6700)
2024-04-03 03:31:04,495 - train - INFO - Train: 48 [   0/195 (  0%)]  Loss:  1.406322 (1.4063)  Time: 2.261s,  113.23/s  (2.261s,  113.23/s)  LR: 4.247e-04  Data: 0.164 (0.164)
2024-04-03 03:33:02,045 - train - INFO - Train: 48 [  50/195 ( 26%)]  Loss:  1.610940 (1.6094)  Time: 2.465s,  103.85/s  (2.349s,  108.97/s)  LR: 4.247e-04  Data: 0.022 (0.014)
2024-04-03 03:34:59,547 - train - INFO - Train: 48 [ 100/195 ( 52%)]  Loss:  1.445871 (1.6308)  Time: 2.200s,  116.35/s  (2.350s,  108.95/s)  LR: 4.247e-04  Data: 0.010 (0.012)
2024-04-03 03:36:58,276 - train - INFO - Train: 48 [ 150/195 ( 77%)]  Loss:  1.761640 (1.6192)  Time: 2.201s,  116.31/s  (2.358s,  108.57/s)  LR: 4.247e-04  Data: 0.021 (0.011)
2024-04-03 03:38:39,994 - train - INFO - Train: 48 [ 194/195 (100%)]  Loss:  1.799445 (1.6198)  Time: 2.035s,  125.81/s  (2.347s,  109.05/s)  LR: 4.247e-04  Data: 0.000 (0.011)
2024-04-03 03:38:39,994 - train - INFO - True
2024-04-03 03:38:39,996 - train - INFO - alphas:tensor([0.0989, 0.9011], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:39,996 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:39,996 - train - INFO - True
2024-04-03 03:38:39,997 - train - INFO - alphas:tensor([0.1804, 0.8196], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:39,997 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:39,997 - train - INFO - True
2024-04-03 03:38:39,998 - train - INFO - alphas:tensor([0.6180, 0.3820], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:39,998 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:39,998 - train - INFO - True
2024-04-03 03:38:39,998 - train - INFO - alphas:tensor([0.5697, 0.4303], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:39,998 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:39,999 - train - INFO - True
2024-04-03 03:38:39,999 - train - INFO - alphas:tensor([0.2882, 0.7118], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:39,999 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:39,999 - train - INFO - True
2024-04-03 03:38:40,000 - train - INFO - alphas:tensor([0.4123, 0.5877], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,000 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,000 - train - INFO - True
2024-04-03 03:38:40,001 - train - INFO - alphas:tensor([0.6344, 0.3656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,001 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,001 - train - INFO - True
2024-04-03 03:38:40,002 - train - INFO - alphas:tensor([0.5311, 0.4689], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,002 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,002 - train - INFO - True
2024-04-03 03:38:40,003 - train - INFO - alphas:tensor([0.3740, 0.6260], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,003 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,003 - train - INFO - True
2024-04-03 03:38:40,004 - train - INFO - alphas:tensor([0.5147, 0.4853], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,004 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,004 - train - INFO - True
2024-04-03 03:38:40,004 - train - INFO - alphas:tensor([0.6436, 0.3564], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,004 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,005 - train - INFO - True
2024-04-03 03:38:40,005 - train - INFO - alphas:tensor([0.5150, 0.4850], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,005 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,005 - train - INFO - True
2024-04-03 03:38:40,006 - train - INFO - alphas:tensor([0.3878, 0.6122], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,006 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,006 - train - INFO - True
2024-04-03 03:38:40,007 - train - INFO - alphas:tensor([0.4986, 0.5014], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,007 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,007 - train - INFO - True
2024-04-03 03:38:40,008 - train - INFO - alphas:tensor([0.5956, 0.4044], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,008 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,008 - train - INFO - True
2024-04-03 03:38:40,008 - train - INFO - alphas:tensor([0.4423, 0.5577], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,009 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,009 - train - INFO - True
2024-04-03 03:38:40,009 - train - INFO - alphas:tensor([0.3563, 0.6437], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,009 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,009 - train - INFO - True
2024-04-03 03:38:40,010 - train - INFO - alphas:tensor([0.4130, 0.5870], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,010 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,010 - train - INFO - True
2024-04-03 03:38:40,011 - train - INFO - alphas:tensor([0.5090, 0.4910], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,011 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,011 - train - INFO - True
2024-04-03 03:38:40,012 - train - INFO - alphas:tensor([0.3237, 0.6763], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,012 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,012 - train - INFO - True
2024-04-03 03:38:40,012 - train - INFO - alphas:tensor([0.3050, 0.6950], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,012 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,013 - train - INFO - True
2024-04-03 03:38:40,013 - train - INFO - alphas:tensor([0.3563, 0.6437], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,013 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,013 - train - INFO - True
2024-04-03 03:38:40,014 - train - INFO - alphas:tensor([0.4607, 0.5393], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,014 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,014 - train - INFO - True
2024-04-03 03:38:40,015 - train - INFO - alphas:tensor([0.2575, 0.7425], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,015 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,015 - train - INFO - True
2024-04-03 03:38:40,016 - train - INFO - alphas:tensor([0.2406, 0.7594], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,016 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,016 - train - INFO - True
2024-04-03 03:38:40,016 - train - INFO - alphas:tensor([0.2103, 0.7897], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,016 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,017 - train - INFO - True
2024-04-03 03:38:40,017 - train - INFO - alphas:tensor([0.1516, 0.8484], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,017 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,017 - train - INFO - True
2024-04-03 03:38:40,018 - train - INFO - alphas:tensor([0.0201, 0.9799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,019 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,019 - train - INFO - True
2024-04-03 03:38:40,019 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:38:40,019 - train - INFO - tau:0.6298236312032323
2024-04-03 03:38:40,019 - train - INFO - avg block size:10.827586206896552
2024-04-03 03:38:41,384 - train - INFO - Test: [   0/39]  Time: 1.361 (1.361)  Loss:  0.4009 (0.4009)  Acc@1: 91.0156 (91.0156)  Acc@5: 100.0000 (100.0000)
2024-04-03 03:39:34,126 - train - INFO - Test: [  39/39]  Time: 1.304 (1.353)  Loss:  0.4170 (0.3784)  Acc@1: 87.5000 (91.9200)  Acc@5: 100.0000 (99.6900)
2024-04-03 03:39:36,650 - train - INFO - Train: 49 [   0/195 (  0%)]  Loss:  1.837476 (1.8375)  Time: 2.375s,  107.79/s  (2.375s,  107.79/s)  LR: 4.199e-04  Data: 0.213 (0.213)
2024-04-03 03:41:35,345 - train - INFO - Train: 49 [  50/195 ( 26%)]  Loss:  1.306296 (1.6021)  Time: 2.109s,  121.39/s  (2.374s,  107.84/s)  LR: 4.199e-04  Data: 0.007 (0.015)
2024-04-03 03:43:31,643 - train - INFO - Train: 49 [ 100/195 ( 52%)]  Loss:  1.710585 (1.5995)  Time: 2.381s,  107.50/s  (2.350s,  108.93/s)  LR: 4.199e-04  Data: 0.006 (0.013)
2024-04-03 03:45:29,200 - train - INFO - Train: 49 [ 150/195 ( 77%)]  Loss:  1.634530 (1.6047)  Time: 2.394s,  106.95/s  (2.350s,  108.92/s)  LR: 4.199e-04  Data: 0.028 (0.013)
2024-04-03 03:47:14,230 - train - INFO - Train: 49 [ 194/195 (100%)]  Loss:  1.556152 (1.6068)  Time: 2.598s,   98.53/s  (2.359s,  108.54/s)  LR: 4.199e-04  Data: 0.000 (0.012)
2024-04-03 03:47:14,231 - train - INFO - True
2024-04-03 03:47:14,232 - train - INFO - alphas:tensor([0.0940, 0.9060], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,233 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,233 - train - INFO - True
2024-04-03 03:47:14,233 - train - INFO - alphas:tensor([0.1757, 0.8243], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,234 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,234 - train - INFO - True
2024-04-03 03:47:14,234 - train - INFO - alphas:tensor([0.6172, 0.3828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,234 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,234 - train - INFO - True
2024-04-03 03:47:14,235 - train - INFO - alphas:tensor([0.5685, 0.4315], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,235 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,235 - train - INFO - True
2024-04-03 03:47:14,236 - train - INFO - alphas:tensor([0.2834, 0.7166], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,236 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,236 - train - INFO - True
2024-04-03 03:47:14,246 - train - INFO - alphas:tensor([0.4090, 0.5910], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,246 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,246 - train - INFO - True
2024-04-03 03:47:14,246 - train - INFO - alphas:tensor([0.6326, 0.3674], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,246 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,247 - train - INFO - True
2024-04-03 03:47:14,247 - train - INFO - alphas:tensor([0.5300, 0.4700], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,252 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,252 - train - INFO - True
2024-04-03 03:47:14,252 - train - INFO - alphas:tensor([0.3727, 0.6273], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,253 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,253 - train - INFO - True
2024-04-03 03:47:14,253 - train - INFO - alphas:tensor([0.5135, 0.4865], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,253 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,253 - train - INFO - True
2024-04-03 03:47:14,254 - train - INFO - alphas:tensor([0.6432, 0.3568], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,254 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,254 - train - INFO - True
2024-04-03 03:47:14,255 - train - INFO - alphas:tensor([0.5143, 0.4857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,255 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,255 - train - INFO - True
2024-04-03 03:47:14,256 - train - INFO - alphas:tensor([0.3854, 0.6146], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,256 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,256 - train - INFO - True
2024-04-03 03:47:14,257 - train - INFO - alphas:tensor([0.4992, 0.5008], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,257 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,257 - train - INFO - True
2024-04-03 03:47:14,257 - train - INFO - alphas:tensor([0.5927, 0.4073], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,258 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,258 - train - INFO - True
2024-04-03 03:47:14,258 - train - INFO - alphas:tensor([0.4377, 0.5623], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,258 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,258 - train - INFO - True
2024-04-03 03:47:14,272 - train - INFO - alphas:tensor([0.3523, 0.6477], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,272 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,272 - train - INFO - True
2024-04-03 03:47:14,273 - train - INFO - alphas:tensor([0.4098, 0.5902], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,273 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,273 - train - INFO - True
2024-04-03 03:47:14,274 - train - INFO - alphas:tensor([0.5058, 0.4942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,274 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,274 - train - INFO - True
2024-04-03 03:47:14,275 - train - INFO - alphas:tensor([0.3209, 0.6791], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,275 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,275 - train - INFO - True
2024-04-03 03:47:14,276 - train - INFO - alphas:tensor([0.3005, 0.6995], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,276 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,276 - train - INFO - True
2024-04-03 03:47:14,290 - train - INFO - alphas:tensor([0.3539, 0.6461], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,290 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,290 - train - INFO - True
2024-04-03 03:47:14,290 - train - INFO - alphas:tensor([0.4592, 0.5408], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,291 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,291 - train - INFO - True
2024-04-03 03:47:14,291 - train - INFO - alphas:tensor([0.2548, 0.7452], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,291 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,291 - train - INFO - True
2024-04-03 03:47:14,292 - train - INFO - alphas:tensor([0.2382, 0.7618], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,292 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,292 - train - INFO - True
2024-04-03 03:47:14,293 - train - INFO - alphas:tensor([0.2048, 0.7952], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,293 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,293 - train - INFO - True
2024-04-03 03:47:14,294 - train - INFO - alphas:tensor([0.1467, 0.8533], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,294 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,294 - train - INFO - True
2024-04-03 03:47:14,295 - train - INFO - alphas:tensor([0.0177, 0.9823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,295 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,295 - train - INFO - True
2024-04-03 03:47:14,300 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:47:14,300 - train - INFO - tau:0.6235253948912
2024-04-03 03:47:14,300 - train - INFO - avg block size:10.827586206896552
2024-04-03 03:47:15,739 - train - INFO - Test: [   0/39]  Time: 1.435 (1.435)  Loss:  0.3809 (0.3809)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.6094 (99.6094)
2024-04-03 03:48:08,642 - train - INFO - Test: [  39/39]  Time: 1.338 (1.358)  Loss:  0.4453 (0.3814)  Acc@1: 81.2500 (91.7500)  Acc@5: 100.0000 (99.7400)
2024-04-03 03:48:11,607 - train - INFO - Train: 50 [   0/195 (  0%)]  Loss:  1.632275 (1.6323)  Time: 2.764s,   92.62/s  (2.764s,   92.62/s)  LR: 4.150e-04  Data: 0.373 (0.373)
2024-04-03 03:50:08,901 - train - INFO - Train: 50 [  50/195 ( 26%)]  Loss:  1.386562 (1.5858)  Time: 2.357s,  108.63/s  (2.354s,  108.75/s)  LR: 4.150e-04  Data: 0.015 (0.020)
2024-04-03 03:52:06,961 - train - INFO - Train: 50 [ 100/195 ( 52%)]  Loss:  1.656581 (1.5932)  Time: 2.222s,  115.20/s  (2.358s,  108.59/s)  LR: 4.150e-04  Data: 0.006 (0.015)
2024-04-03 03:54:07,175 - train - INFO - Train: 50 [ 150/195 ( 77%)]  Loss:  1.540065 (1.5925)  Time: 2.378s,  107.63/s  (2.373s,  107.88/s)  LR: 4.150e-04  Data: 0.024 (0.014)
2024-04-03 03:55:52,350 - train - INFO - Train: 50 [ 194/195 (100%)]  Loss:  1.364844 (1.5803)  Time: 2.294s,  111.59/s  (2.377s,  107.70/s)  LR: 4.150e-04  Data: 0.000 (0.013)
2024-04-03 03:55:52,352 - train - INFO - True
2024-04-03 03:55:52,353 - train - INFO - alphas:tensor([0.0889, 0.9111], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,353 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,353 - train - INFO - True
2024-04-03 03:55:52,354 - train - INFO - alphas:tensor([0.1716, 0.8284], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,354 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,354 - train - INFO - True
2024-04-03 03:55:52,359 - train - INFO - alphas:tensor([0.6143, 0.3857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,359 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,359 - train - INFO - True
2024-04-03 03:55:52,360 - train - INFO - alphas:tensor([0.5649, 0.4351], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,360 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,360 - train - INFO - True
2024-04-03 03:55:52,361 - train - INFO - alphas:tensor([0.2825, 0.7175], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,361 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,361 - train - INFO - True
2024-04-03 03:55:52,362 - train - INFO - alphas:tensor([0.4070, 0.5930], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,362 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,362 - train - INFO - True
2024-04-03 03:55:52,362 - train - INFO - alphas:tensor([0.6325, 0.3675], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,362 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,363 - train - INFO - True
2024-04-03 03:55:52,363 - train - INFO - alphas:tensor([0.5314, 0.4686], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,363 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,363 - train - INFO - True
2024-04-03 03:55:52,364 - train - INFO - alphas:tensor([0.3674, 0.6326], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,364 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,364 - train - INFO - True
2024-04-03 03:55:52,365 - train - INFO - alphas:tensor([0.5086, 0.4914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,365 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,365 - train - INFO - True
2024-04-03 03:55:52,366 - train - INFO - alphas:tensor([0.6409, 0.3591], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,366 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,366 - train - INFO - True
2024-04-03 03:55:52,367 - train - INFO - alphas:tensor([0.5122, 0.4878], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,367 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,367 - train - INFO - True
2024-04-03 03:55:52,367 - train - INFO - alphas:tensor([0.3827, 0.6173], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,367 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,368 - train - INFO - True
2024-04-03 03:55:52,368 - train - INFO - alphas:tensor([0.4982, 0.5018], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,368 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,368 - train - INFO - True
2024-04-03 03:55:52,369 - train - INFO - alphas:tensor([0.5915, 0.4085], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,369 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,369 - train - INFO - True
2024-04-03 03:55:52,370 - train - INFO - alphas:tensor([0.4386, 0.5614], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,370 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,370 - train - INFO - True
2024-04-03 03:55:52,375 - train - INFO - alphas:tensor([0.3491, 0.6509], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,376 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,376 - train - INFO - True
2024-04-03 03:55:52,376 - train - INFO - alphas:tensor([0.4075, 0.5925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,376 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,377 - train - INFO - True
2024-04-03 03:55:52,377 - train - INFO - alphas:tensor([0.5024, 0.4976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,377 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,377 - train - INFO - True
2024-04-03 03:55:52,378 - train - INFO - alphas:tensor([0.3179, 0.6821], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,378 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,378 - train - INFO - True
2024-04-03 03:55:52,379 - train - INFO - alphas:tensor([0.2985, 0.7015], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,379 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,379 - train - INFO - True
2024-04-03 03:55:52,380 - train - INFO - alphas:tensor([0.3505, 0.6495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,380 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,380 - train - INFO - True
2024-04-03 03:55:52,380 - train - INFO - alphas:tensor([0.4561, 0.5439], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,381 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,381 - train - INFO - True
2024-04-03 03:55:52,381 - train - INFO - alphas:tensor([0.2506, 0.7494], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,381 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,381 - train - INFO - True
2024-04-03 03:55:52,382 - train - INFO - alphas:tensor([0.2332, 0.7668], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,382 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,382 - train - INFO - True
2024-04-03 03:55:52,383 - train - INFO - alphas:tensor([0.1980, 0.8020], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,383 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,383 - train - INFO - True
2024-04-03 03:55:52,384 - train - INFO - alphas:tensor([0.1432, 0.8568], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,384 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,384 - train - INFO - True
2024-04-03 03:55:52,385 - train - INFO - alphas:tensor([0.0155, 0.9845], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,385 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,385 - train - INFO - True
2024-04-03 03:55:52,386 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 03:55:52,386 - train - INFO - tau:0.617290140942288
2024-04-03 03:55:52,386 - train - INFO - avg block size:10.827586206896552
2024-04-03 03:55:53,737 - train - INFO - Test: [   0/39]  Time: 1.348 (1.348)  Loss:  0.3777 (0.3777)  Acc@1: 91.4062 (91.4062)  Acc@5: 99.6094 (99.6094)
2024-04-03 03:56:46,629 - train - INFO - Test: [  39/39]  Time: 1.345 (1.356)  Loss:  0.3328 (0.3790)  Acc@1: 87.5000 (91.5000)  Acc@5: 100.0000 (99.7200)
2024-04-03 03:56:49,533 - train - INFO - Train: 51 [   0/195 (  0%)]  Loss:  1.431981 (1.4320)  Time: 2.707s,   94.57/s  (2.707s,   94.57/s)  LR: 4.101e-04  Data: 0.292 (0.292)
2024-04-03 03:58:47,598 - train - INFO - Train: 51 [  50/195 ( 26%)]  Loss:  1.728359 (1.5703)  Time: 2.312s,  110.73/s  (2.368s,  108.10/s)  LR: 4.101e-04  Data: 0.005 (0.017)
2024-04-03 04:00:45,818 - train - INFO - Train: 51 [ 100/195 ( 52%)]  Loss:  1.633271 (1.5934)  Time: 2.013s,  127.16/s  (2.366s,  108.19/s)  LR: 4.101e-04  Data: 0.006 (0.014)
2024-04-03 04:02:43,143 - train - INFO - Train: 51 [ 150/195 ( 77%)]  Loss:  1.802784 (1.5746)  Time: 2.538s,  100.87/s  (2.360s,  108.49/s)  LR: 4.101e-04  Data: 0.006 (0.013)
2024-04-03 04:04:28,307 - train - INFO - Train: 51 [ 194/195 (100%)]  Loss:  1.768541 (1.5854)  Time: 2.272s,  112.67/s  (2.367s,  108.17/s)  LR: 4.101e-04  Data: 0.000 (0.013)
2024-04-03 04:04:28,308 - train - INFO - True
2024-04-03 04:04:28,309 - train - INFO - alphas:tensor([0.0846, 0.9154], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,309 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,309 - train - INFO - True
2024-04-03 04:04:28,314 - train - INFO - alphas:tensor([0.1690, 0.8310], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,314 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,314 - train - INFO - True
2024-04-03 04:04:28,315 - train - INFO - alphas:tensor([0.6130, 0.3870], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,315 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,315 - train - INFO - True
2024-04-03 04:04:28,316 - train - INFO - alphas:tensor([0.5637, 0.4363], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,316 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,316 - train - INFO - True
2024-04-03 04:04:28,316 - train - INFO - alphas:tensor([0.2754, 0.7246], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,317 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,317 - train - INFO - True
2024-04-03 04:04:28,317 - train - INFO - alphas:tensor([0.3993, 0.6007], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,317 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,317 - train - INFO - True
2024-04-03 04:04:28,318 - train - INFO - alphas:tensor([0.6277, 0.3723], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,318 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,318 - train - INFO - True
2024-04-03 04:04:28,319 - train - INFO - alphas:tensor([0.5250, 0.4750], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,319 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,319 - train - INFO - True
2024-04-03 04:04:28,320 - train - INFO - alphas:tensor([0.3646, 0.6354], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,320 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,320 - train - INFO - True
2024-04-03 04:04:28,321 - train - INFO - alphas:tensor([0.5063, 0.4937], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,321 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,321 - train - INFO - True
2024-04-03 04:04:28,322 - train - INFO - alphas:tensor([0.6361, 0.3639], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,322 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,322 - train - INFO - True
2024-04-03 04:04:28,323 - train - INFO - alphas:tensor([0.5042, 0.4958], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,323 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,323 - train - INFO - True
2024-04-03 04:04:28,324 - train - INFO - alphas:tensor([0.3784, 0.6216], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,324 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,324 - train - INFO - True
2024-04-03 04:04:28,325 - train - INFO - alphas:tensor([0.4950, 0.5050], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,325 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,325 - train - INFO - True
2024-04-03 04:04:28,326 - train - INFO - alphas:tensor([0.5890, 0.4110], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,326 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,326 - train - INFO - True
2024-04-03 04:04:28,327 - train - INFO - alphas:tensor([0.4361, 0.5639], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,327 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,327 - train - INFO - True
2024-04-03 04:04:28,332 - train - INFO - alphas:tensor([0.3452, 0.6548], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,332 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,332 - train - INFO - True
2024-04-03 04:04:28,333 - train - INFO - alphas:tensor([0.4018, 0.5982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,333 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,333 - train - INFO - True
2024-04-03 04:04:28,333 - train - INFO - alphas:tensor([0.4981, 0.5019], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,334 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,334 - train - INFO - True
2024-04-03 04:04:28,334 - train - INFO - alphas:tensor([0.3116, 0.6884], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,334 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,334 - train - INFO - True
2024-04-03 04:04:28,335 - train - INFO - alphas:tensor([0.2943, 0.7057], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,335 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,335 - train - INFO - True
2024-04-03 04:04:28,336 - train - INFO - alphas:tensor([0.3454, 0.6546], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,336 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,336 - train - INFO - True
2024-04-03 04:04:28,337 - train - INFO - alphas:tensor([0.4518, 0.5482], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,337 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,337 - train - INFO - True
2024-04-03 04:04:28,338 - train - INFO - alphas:tensor([0.2477, 0.7523], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,338 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,338 - train - INFO - True
2024-04-03 04:04:28,338 - train - INFO - alphas:tensor([0.2290, 0.7710], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,338 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,339 - train - INFO - True
2024-04-03 04:04:28,339 - train - INFO - alphas:tensor([0.1920, 0.8080], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,339 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,339 - train - INFO - True
2024-04-03 04:04:28,340 - train - INFO - alphas:tensor([0.1378, 0.8622], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,340 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,340 - train - INFO - True
2024-04-03 04:04:28,341 - train - INFO - alphas:tensor([0.0136, 0.9864], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,341 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,341 - train - INFO - True
2024-04-03 04:04:28,342 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:04:28,342 - train - INFO - tau:0.6111172395328651
2024-04-03 04:04:28,342 - train - INFO - avg block size:11.344827586206897
2024-04-03 04:04:29,775 - train - INFO - Test: [   0/39]  Time: 1.431 (1.431)  Loss:  0.3787 (0.3787)  Acc@1: 92.5781 (92.5781)  Acc@5: 99.6094 (99.6094)
2024-04-03 04:05:22,463 - train - INFO - Test: [  39/39]  Time: 1.345 (1.353)  Loss:  0.4260 (0.3688)  Acc@1: 87.5000 (92.0800)  Acc@5: 100.0000 (99.7300)
2024-04-03 04:05:25,537 - train - INFO - Train: 52 [   0/195 (  0%)]  Loss:  1.301277 (1.3013)  Time: 2.854s,   89.70/s  (2.854s,   89.70/s)  LR: 4.051e-04  Data: 0.212 (0.212)
2024-04-03 04:07:25,651 - train - INFO - Train: 52 [  50/195 ( 26%)]  Loss:  1.730973 (1.5800)  Time: 2.335s,  109.65/s  (2.411s,  106.18/s)  LR: 4.051e-04  Data: 0.006 (0.014)
2024-04-03 04:09:21,866 - train - INFO - Train: 52 [ 100/195 ( 52%)]  Loss:  1.829216 (1.5769)  Time: 2.135s,  119.89/s  (2.368s,  108.11/s)  LR: 4.051e-04  Data: 0.010 (0.012)
2024-04-03 04:11:18,533 - train - INFO - Train: 52 [ 150/195 ( 77%)]  Loss:  1.442400 (1.5964)  Time: 2.460s,  104.09/s  (2.357s,  108.63/s)  LR: 4.051e-04  Data: 0.005 (0.012)
2024-04-03 04:13:03,898 - train - INFO - Train: 52 [ 194/195 (100%)]  Loss:  1.739830 (1.5968)  Time: 2.686s,   95.31/s  (2.365s,  108.24/s)  LR: 4.051e-04  Data: 0.000 (0.011)
2024-04-03 04:13:03,898 - train - INFO - True
2024-04-03 04:13:03,899 - train - INFO - alphas:tensor([0.0798, 0.9202], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,899 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,899 - train - INFO - True
2024-04-03 04:13:03,900 - train - INFO - alphas:tensor([0.1644, 0.8356], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,900 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,900 - train - INFO - True
2024-04-03 04:13:03,901 - train - INFO - alphas:tensor([0.6118, 0.3882], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,901 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,901 - train - INFO - True
2024-04-03 04:13:03,902 - train - INFO - alphas:tensor([0.5618, 0.4382], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,902 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,902 - train - INFO - True
2024-04-03 04:13:03,903 - train - INFO - alphas:tensor([0.2726, 0.7274], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,907 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,907 - train - INFO - True
2024-04-03 04:13:03,908 - train - INFO - alphas:tensor([0.3973, 0.6027], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,908 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,908 - train - INFO - True
2024-04-03 04:13:03,909 - train - INFO - alphas:tensor([0.6266, 0.3734], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,909 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,909 - train - INFO - True
2024-04-03 04:13:03,910 - train - INFO - alphas:tensor([0.5227, 0.4773], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,914 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,914 - train - INFO - True
2024-04-03 04:13:03,915 - train - INFO - alphas:tensor([0.3623, 0.6377], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,915 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,915 - train - INFO - True
2024-04-03 04:13:03,916 - train - INFO - alphas:tensor([0.5046, 0.4954], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,916 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,916 - train - INFO - True
2024-04-03 04:13:03,917 - train - INFO - alphas:tensor([0.6326, 0.3674], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,921 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,921 - train - INFO - True
2024-04-03 04:13:03,922 - train - INFO - alphas:tensor([0.5003, 0.4997], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,922 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,922 - train - INFO - True
2024-04-03 04:13:03,923 - train - INFO - alphas:tensor([0.3736, 0.6264], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,923 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,923 - train - INFO - True
2024-04-03 04:13:03,923 - train - INFO - alphas:tensor([0.4882, 0.5118], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,926 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,926 - train - INFO - True
2024-04-03 04:13:03,945 - train - INFO - alphas:tensor([0.5856, 0.4144], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,945 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,945 - train - INFO - True
2024-04-03 04:13:03,950 - train - INFO - alphas:tensor([0.4306, 0.5694], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,958 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,958 - train - INFO - True
2024-04-03 04:13:03,959 - train - INFO - alphas:tensor([0.3425, 0.6575], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,959 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,959 - train - INFO - True
2024-04-03 04:13:03,960 - train - INFO - alphas:tensor([0.3995, 0.6005], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,960 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,960 - train - INFO - True
2024-04-03 04:13:03,961 - train - INFO - alphas:tensor([0.4945, 0.5055], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,961 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,961 - train - INFO - True
2024-04-03 04:13:03,975 - train - INFO - alphas:tensor([0.3114, 0.6886], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,975 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,975 - train - INFO - True
2024-04-03 04:13:03,976 - train - INFO - alphas:tensor([0.2911, 0.7089], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,976 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,976 - train - INFO - True
2024-04-03 04:13:03,977 - train - INFO - alphas:tensor([0.3420, 0.6580], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,977 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,977 - train - INFO - True
2024-04-03 04:13:03,977 - train - INFO - alphas:tensor([0.4479, 0.5521], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,977 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,978 - train - INFO - True
2024-04-03 04:13:03,978 - train - INFO - alphas:tensor([0.2430, 0.7570], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,978 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,978 - train - INFO - True
2024-04-03 04:13:03,992 - train - INFO - alphas:tensor([0.2244, 0.7756], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,992 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,992 - train - INFO - True
2024-04-03 04:13:03,993 - train - INFO - alphas:tensor([0.1866, 0.8134], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,995 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,995 - train - INFO - True
2024-04-03 04:13:03,995 - train - INFO - alphas:tensor([0.1329, 0.8671], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,995 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,995 - train - INFO - True
2024-04-03 04:13:03,996 - train - INFO - alphas:tensor([0.0119, 0.9881], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:03,996 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:03,996 - train - INFO - True
2024-04-03 04:13:03,997 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:13:04,006 - train - INFO - tau:0.6050060671375365
2024-04-03 04:13:04,006 - train - INFO - avg block size:11.344827586206897
2024-04-03 04:13:05,360 - train - INFO - Test: [   0/39]  Time: 1.347 (1.347)  Loss:  0.3789 (0.3789)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.6094 (99.6094)
2024-04-03 04:13:57,688 - train - INFO - Test: [  39/39]  Time: 1.310 (1.342)  Loss:  0.3572 (0.3687)  Acc@1: 87.5000 (91.7400)  Acc@5: 100.0000 (99.6600)
2024-04-03 04:14:00,659 - train - INFO - Train: 53 [   0/195 (  0%)]  Loss:  1.834969 (1.8350)  Time: 2.752s,   93.03/s  (2.752s,   93.03/s)  LR: 4.001e-04  Data: 0.319 (0.319)
2024-04-03 04:15:59,528 - train - INFO - Train: 53 [  50/195 ( 26%)]  Loss:  1.788775 (1.5865)  Time: 2.173s,  117.78/s  (2.385s,  107.35/s)  LR: 4.001e-04  Data: 0.005 (0.016)
2024-04-03 04:17:56,751 - train - INFO - Train: 53 [ 100/195 ( 52%)]  Loss:  1.721789 (1.5770)  Time: 2.293s,  111.65/s  (2.365s,  108.26/s)  LR: 4.001e-04  Data: 0.018 (0.013)
2024-04-03 04:19:54,523 - train - INFO - Train: 53 [ 150/195 ( 77%)]  Loss:  1.265269 (1.5915)  Time: 2.324s,  110.16/s  (2.362s,  108.40/s)  LR: 4.001e-04  Data: 0.023 (0.012)
2024-04-03 04:21:38,194 - train - INFO - Train: 53 [ 194/195 (100%)]  Loss:  1.809070 (1.5980)  Time: 1.936s,  132.20/s  (2.360s,  108.46/s)  LR: 4.001e-04  Data: 0.000 (0.012)
2024-04-03 04:21:38,194 - train - INFO - True
2024-04-03 04:21:38,195 - train - INFO - alphas:tensor([0.0755, 0.9245], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,196 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,196 - train - INFO - True
2024-04-03 04:21:38,196 - train - INFO - alphas:tensor([0.1611, 0.8389], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,197 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,197 - train - INFO - True
2024-04-03 04:21:38,197 - train - INFO - alphas:tensor([0.6108, 0.3892], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,197 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,197 - train - INFO - True
2024-04-03 04:21:38,198 - train - INFO - alphas:tensor([0.5596, 0.4404], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,198 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,198 - train - INFO - True
2024-04-03 04:21:38,199 - train - INFO - alphas:tensor([0.2679, 0.7321], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,199 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,199 - train - INFO - True
2024-04-03 04:21:38,200 - train - INFO - alphas:tensor([0.3945, 0.6055], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,200 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,200 - train - INFO - True
2024-04-03 04:21:38,200 - train - INFO - alphas:tensor([0.6242, 0.3758], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,201 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,201 - train - INFO - True
2024-04-03 04:21:38,201 - train - INFO - alphas:tensor([0.5224, 0.4776], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,201 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,201 - train - INFO - True
2024-04-03 04:21:38,202 - train - INFO - alphas:tensor([0.3604, 0.6396], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,202 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,203 - train - INFO - True
2024-04-03 04:21:38,203 - train - INFO - alphas:tensor([0.5026, 0.4974], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,203 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,203 - train - INFO - True
2024-04-03 04:21:38,204 - train - INFO - alphas:tensor([0.6307, 0.3693], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,204 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,204 - train - INFO - True
2024-04-03 04:21:38,205 - train - INFO - alphas:tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,205 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,205 - train - INFO - True
2024-04-03 04:21:38,206 - train - INFO - alphas:tensor([0.3708, 0.6292], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,206 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,206 - train - INFO - True
2024-04-03 04:21:38,206 - train - INFO - alphas:tensor([0.4843, 0.5157], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,207 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,207 - train - INFO - True
2024-04-03 04:21:38,207 - train - INFO - alphas:tensor([0.5828, 0.4172], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,207 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,207 - train - INFO - True
2024-04-03 04:21:38,208 - train - INFO - alphas:tensor([0.4311, 0.5689], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,208 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,208 - train - INFO - True
2024-04-03 04:21:38,209 - train - INFO - alphas:tensor([0.3371, 0.6629], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,209 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,209 - train - INFO - True
2024-04-03 04:21:38,210 - train - INFO - alphas:tensor([0.3948, 0.6052], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,210 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,210 - train - INFO - True
2024-04-03 04:21:38,210 - train - INFO - alphas:tensor([0.4894, 0.5106], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,211 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,211 - train - INFO - True
2024-04-03 04:21:38,211 - train - INFO - alphas:tensor([0.3067, 0.6933], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,211 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,211 - train - INFO - True
2024-04-03 04:21:38,212 - train - INFO - alphas:tensor([0.2874, 0.7126], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,212 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,212 - train - INFO - True
2024-04-03 04:21:38,213 - train - INFO - alphas:tensor([0.3376, 0.6624], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,213 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,213 - train - INFO - True
2024-04-03 04:21:38,214 - train - INFO - alphas:tensor([0.4433, 0.5567], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,214 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,214 - train - INFO - True
2024-04-03 04:21:38,215 - train - INFO - alphas:tensor([0.2371, 0.7629], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,215 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,215 - train - INFO - True
2024-04-03 04:21:38,215 - train - INFO - alphas:tensor([0.2209, 0.7791], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,215 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,216 - train - INFO - True
2024-04-03 04:21:38,216 - train - INFO - alphas:tensor([0.1791, 0.8209], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,216 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,216 - train - INFO - True
2024-04-03 04:21:38,217 - train - INFO - alphas:tensor([0.1293, 0.8707], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,217 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,217 - train - INFO - True
2024-04-03 04:21:38,218 - train - INFO - alphas:tensor([0.0105, 0.9895], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,218 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,218 - train - INFO - True
2024-04-03 04:21:38,218 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:21:38,219 - train - INFO - tau:0.5989560064661611
2024-04-03 04:21:38,219 - train - INFO - avg block size:11.862068965517242
2024-04-03 04:21:39,588 - train - INFO - Test: [   0/39]  Time: 1.367 (1.367)  Loss:  0.4075 (0.4075)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.6094 (99.6094)
2024-04-03 04:22:31,809 - train - INFO - Test: [  39/39]  Time: 1.313 (1.340)  Loss:  0.4736 (0.4018)  Acc@1: 81.2500 (91.5100)  Acc@5: 100.0000 (99.6800)
2024-04-03 04:22:34,523 - train - INFO - Train: 54 [   0/195 (  0%)]  Loss:  1.582888 (1.5829)  Time: 2.579s,   99.26/s  (2.579s,   99.26/s)  LR: 3.950e-04  Data: 0.205 (0.205)
2024-04-03 04:24:32,636 - train - INFO - Train: 54 [  50/195 ( 26%)]  Loss:  1.777128 (1.6016)  Time: 2.463s,  103.93/s  (2.366s,  108.19/s)  LR: 3.950e-04  Data: 0.005 (0.013)
2024-04-03 04:26:30,971 - train - INFO - Train: 54 [ 100/195 ( 52%)]  Loss:  1.288895 (1.6089)  Time: 2.386s,  107.30/s  (2.366s,  108.18/s)  LR: 3.950e-04  Data: 0.014 (0.012)
2024-04-03 04:28:29,290 - train - INFO - Train: 54 [ 150/195 ( 77%)]  Loss:  1.730051 (1.5923)  Time: 2.262s,  113.17/s  (2.366s,  108.18/s)  LR: 3.950e-04  Data: 0.005 (0.012)
2024-04-03 04:30:13,904 - train - INFO - Train: 54 [ 194/195 (100%)]  Loss:  1.212297 (1.5970)  Time: 2.459s,  104.09/s  (2.369s,  108.07/s)  LR: 3.950e-04  Data: 0.000 (0.011)
2024-04-03 04:30:13,904 - train - INFO - True
2024-04-03 04:30:13,906 - train - INFO - alphas:tensor([0.0715, 0.9285], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,906 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,906 - train - INFO - True
2024-04-03 04:30:13,907 - train - INFO - alphas:tensor([0.1581, 0.8419], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,907 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,907 - train - INFO - True
2024-04-03 04:30:13,907 - train - INFO - alphas:tensor([0.6093, 0.3907], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,907 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,908 - train - INFO - True
2024-04-03 04:30:13,908 - train - INFO - alphas:tensor([0.5566, 0.4434], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,908 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,908 - train - INFO - True
2024-04-03 04:30:13,909 - train - INFO - alphas:tensor([0.2657, 0.7343], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,910 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,910 - train - INFO - True
2024-04-03 04:30:13,910 - train - INFO - alphas:tensor([0.3891, 0.6109], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,910 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,910 - train - INFO - True
2024-04-03 04:30:13,911 - train - INFO - alphas:tensor([0.6228, 0.3772], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,912 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,912 - train - INFO - True
2024-04-03 04:30:13,912 - train - INFO - alphas:tensor([0.5198, 0.4802], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,912 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,913 - train - INFO - True
2024-04-03 04:30:13,913 - train - INFO - alphas:tensor([0.3557, 0.6443], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,913 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,913 - train - INFO - True
2024-04-03 04:30:13,914 - train - INFO - alphas:tensor([0.5004, 0.4996], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,914 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,914 - train - INFO - True
2024-04-03 04:30:13,915 - train - INFO - alphas:tensor([0.6296, 0.3704], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,915 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,915 - train - INFO - True
2024-04-03 04:30:13,916 - train - INFO - alphas:tensor([0.4991, 0.5009], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,916 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,916 - train - INFO - True
2024-04-03 04:30:13,916 - train - INFO - alphas:tensor([0.3683, 0.6317], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,917 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,917 - train - INFO - True
2024-04-03 04:30:13,917 - train - INFO - alphas:tensor([0.4827, 0.5173], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,917 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,917 - train - INFO - True
2024-04-03 04:30:13,918 - train - INFO - alphas:tensor([0.5801, 0.4199], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,918 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,918 - train - INFO - True
2024-04-03 04:30:13,919 - train - INFO - alphas:tensor([0.4280, 0.5720], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,919 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,919 - train - INFO - True
2024-04-03 04:30:13,920 - train - INFO - alphas:tensor([0.3374, 0.6626], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,920 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,920 - train - INFO - True
2024-04-03 04:30:13,921 - train - INFO - alphas:tensor([0.3931, 0.6069], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,921 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,921 - train - INFO - True
2024-04-03 04:30:13,921 - train - INFO - alphas:tensor([0.4860, 0.5140], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,921 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,922 - train - INFO - True
2024-04-03 04:30:13,922 - train - INFO - alphas:tensor([0.3040, 0.6960], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,922 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,922 - train - INFO - True
2024-04-03 04:30:13,923 - train - INFO - alphas:tensor([0.2826, 0.7174], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,923 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,923 - train - INFO - True
2024-04-03 04:30:13,924 - train - INFO - alphas:tensor([0.3347, 0.6653], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,924 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,924 - train - INFO - True
2024-04-03 04:30:13,925 - train - INFO - alphas:tensor([0.4416, 0.5584], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,925 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,925 - train - INFO - True
2024-04-03 04:30:13,925 - train - INFO - alphas:tensor([0.2348, 0.7652], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,926 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,926 - train - INFO - True
2024-04-03 04:30:13,926 - train - INFO - alphas:tensor([0.2171, 0.7829], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,926 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,926 - train - INFO - True
2024-04-03 04:30:13,927 - train - INFO - alphas:tensor([0.1723, 0.8277], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,927 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,927 - train - INFO - True
2024-04-03 04:30:13,928 - train - INFO - alphas:tensor([0.1249, 0.8751], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,928 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,928 - train - INFO - True
2024-04-03 04:30:13,929 - train - INFO - alphas:tensor([0.0092, 0.9908], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,929 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,929 - train - INFO - True
2024-04-03 04:30:13,929 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:30:13,930 - train - INFO - tau:0.5929664464014994
2024-04-03 04:30:13,930 - train - INFO - avg block size:11.862068965517242
2024-04-03 04:30:15,239 - train - INFO - Test: [   0/39]  Time: 1.306 (1.306)  Loss:  0.3923 (0.3923)  Acc@1: 89.4531 (89.4531)  Acc@5: 99.6094 (99.6094)
2024-04-03 04:31:08,114 - train - INFO - Test: [  39/39]  Time: 1.331 (1.355)  Loss:  0.3665 (0.3868)  Acc@1: 87.5000 (91.7300)  Acc@5: 100.0000 (99.7000)
2024-04-03 04:31:10,739 - train - INFO - Train: 55 [   0/195 (  0%)]  Loss:  1.325472 (1.3255)  Time: 2.358s,  108.56/s  (2.358s,  108.56/s)  LR: 3.898e-04  Data: 0.271 (0.271)
2024-04-03 04:33:08,326 - train - INFO - Train: 55 [  50/195 ( 26%)]  Loss:  1.298895 (1.6246)  Time: 2.149s,  119.12/s  (2.352s,  108.85/s)  LR: 3.898e-04  Data: 0.016 (0.015)
2024-04-03 04:35:08,268 - train - INFO - Train: 55 [ 100/195 ( 52%)]  Loss:  1.518056 (1.6175)  Time: 2.749s,   93.12/s  (2.375s,  107.78/s)  LR: 3.898e-04  Data: 0.018 (0.014)
2024-04-03 04:37:06,443 - train - INFO - Train: 55 [ 150/195 ( 77%)]  Loss:  1.211044 (1.6044)  Time: 2.761s,   92.71/s  (2.371s,  107.96/s)  LR: 3.898e-04  Data: 0.024 (0.013)
2024-04-03 04:38:53,589 - train - INFO - Train: 55 [ 194/195 (100%)]  Loss:  1.615954 (1.6100)  Time: 2.418s,  105.88/s  (2.386s,  107.31/s)  LR: 3.898e-04  Data: 0.000 (0.013)
2024-04-03 04:38:53,590 - train - INFO - True
2024-04-03 04:38:53,591 - train - INFO - alphas:tensor([0.0674, 0.9326], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,592 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,592 - train - INFO - True
2024-04-03 04:38:53,593 - train - INFO - alphas:tensor([0.1544, 0.8456], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,593 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,593 - train - INFO - True
2024-04-03 04:38:53,594 - train - INFO - alphas:tensor([0.6079, 0.3921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,594 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,594 - train - INFO - True
2024-04-03 04:38:53,599 - train - INFO - alphas:tensor([0.5546, 0.4454], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,599 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,599 - train - INFO - True
2024-04-03 04:38:53,600 - train - INFO - alphas:tensor([0.2611, 0.7389], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,600 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,600 - train - INFO - True
2024-04-03 04:38:53,601 - train - INFO - alphas:tensor([0.3847, 0.6153], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,601 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,601 - train - INFO - True
2024-04-03 04:38:53,602 - train - INFO - alphas:tensor([0.6214, 0.3786], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,602 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,602 - train - INFO - True
2024-04-03 04:38:53,603 - train - INFO - alphas:tensor([0.5172, 0.4828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,603 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,603 - train - INFO - True
2024-04-03 04:38:53,604 - train - INFO - alphas:tensor([0.3538, 0.6462], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,604 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,604 - train - INFO - True
2024-04-03 04:38:53,605 - train - INFO - alphas:tensor([0.4961, 0.5039], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,605 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,605 - train - INFO - True
2024-04-03 04:38:53,606 - train - INFO - alphas:tensor([0.6274, 0.3726], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,606 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,606 - train - INFO - True
2024-04-03 04:38:53,612 - train - INFO - alphas:tensor([0.4967, 0.5033], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,612 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,612 - train - INFO - True
2024-04-03 04:38:53,612 - train - INFO - alphas:tensor([0.3660, 0.6340], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,613 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,613 - train - INFO - True
2024-04-03 04:38:53,613 - train - INFO - alphas:tensor([0.4813, 0.5187], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,614 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,614 - train - INFO - True
2024-04-03 04:38:53,614 - train - INFO - alphas:tensor([0.5771, 0.4229], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,615 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,615 - train - INFO - True
2024-04-03 04:38:53,615 - train - INFO - alphas:tensor([0.4260, 0.5740], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,615 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,616 - train - INFO - True
2024-04-03 04:38:53,616 - train - INFO - alphas:tensor([0.3349, 0.6651], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,616 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,617 - train - INFO - True
2024-04-03 04:38:53,617 - train - INFO - alphas:tensor([0.3907, 0.6093], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,617 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,617 - train - INFO - True
2024-04-03 04:38:53,618 - train - INFO - alphas:tensor([0.4820, 0.5180], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,618 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,618 - train - INFO - True
2024-04-03 04:38:53,619 - train - INFO - alphas:tensor([0.2994, 0.7006], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,619 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,619 - train - INFO - True
2024-04-03 04:38:53,620 - train - INFO - alphas:tensor([0.2810, 0.7190], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,620 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,620 - train - INFO - True
2024-04-03 04:38:53,621 - train - INFO - alphas:tensor([0.3317, 0.6683], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,621 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,621 - train - INFO - True
2024-04-03 04:38:53,622 - train - INFO - alphas:tensor([0.4368, 0.5632], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,622 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,622 - train - INFO - True
2024-04-03 04:38:53,628 - train - INFO - alphas:tensor([0.2316, 0.7684], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,628 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,628 - train - INFO - True
2024-04-03 04:38:53,629 - train - INFO - alphas:tensor([0.2144, 0.7856], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,629 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,629 - train - INFO - True
2024-04-03 04:38:53,630 - train - INFO - alphas:tensor([0.1676, 0.8324], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,630 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,630 - train - INFO - True
2024-04-03 04:38:53,631 - train - INFO - alphas:tensor([0.1213, 0.8787], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,631 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,631 - train - INFO - True
2024-04-03 04:38:53,632 - train - INFO - alphas:tensor([0.0081, 0.9919], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,632 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,632 - train - INFO - True
2024-04-03 04:38:53,633 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:38:53,633 - train - INFO - tau:0.5870367819374844
2024-04-03 04:38:53,633 - train - INFO - avg block size:12.379310344827585
2024-04-03 04:38:55,003 - train - INFO - Test: [   0/39]  Time: 1.362 (1.362)  Loss:  0.3875 (0.3875)  Acc@1: 91.0156 (91.0156)  Acc@5: 100.0000 (100.0000)
2024-04-03 04:39:48,225 - train - INFO - Test: [  39/39]  Time: 1.358 (1.365)  Loss:  0.4246 (0.3759)  Acc@1: 81.2500 (91.8600)  Acc@5: 100.0000 (99.7200)
2024-04-03 04:39:51,122 - train - INFO - Train: 56 [   0/195 (  0%)]  Loss:  1.822976 (1.8230)  Time: 2.629s,   97.39/s  (2.629s,   97.39/s)  LR: 3.846e-04  Data: 0.292 (0.292)
2024-04-03 04:41:49,485 - train - INFO - Train: 56 [  50/195 ( 26%)]  Loss:  1.271593 (1.5862)  Time: 2.495s,  102.59/s  (2.372s,  107.91/s)  LR: 3.846e-04  Data: 0.006 (0.016)
2024-04-03 04:43:43,955 - train - INFO - Train: 56 [ 100/195 ( 52%)]  Loss:  1.641481 (1.6034)  Time: 2.503s,  102.26/s  (2.331s,  109.81/s)  LR: 3.846e-04  Data: 0.012 (0.013)
2024-04-03 04:45:45,390 - train - INFO - Train: 56 [ 150/195 ( 77%)]  Loss:  1.815224 (1.6006)  Time: 2.242s,  114.19/s  (2.363s,  108.31/s)  LR: 3.846e-04  Data: 0.008 (0.012)
2024-04-03 04:47:29,012 - train - INFO - Train: 56 [ 194/195 (100%)]  Loss:  1.812680 (1.6065)  Time: 2.265s,  113.02/s  (2.362s,  108.40/s)  LR: 3.846e-04  Data: 0.000 (0.012)
2024-04-03 04:47:29,013 - train - INFO - True
2024-04-03 04:47:29,014 - train - INFO - alphas:tensor([0.0637, 0.9363], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,014 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,014 - train - INFO - True
2024-04-03 04:47:29,015 - train - INFO - alphas:tensor([0.1516, 0.8484], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,015 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,015 - train - INFO - True
2024-04-03 04:47:29,015 - train - INFO - alphas:tensor([0.6067, 0.3933], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,015 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,016 - train - INFO - True
2024-04-03 04:47:29,021 - train - INFO - alphas:tensor([0.5519, 0.4481], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,021 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,021 - train - INFO - True
2024-04-03 04:47:29,021 - train - INFO - alphas:tensor([0.2574, 0.7426], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,022 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,022 - train - INFO - True
2024-04-03 04:47:29,022 - train - INFO - alphas:tensor([0.3803, 0.6197], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,022 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,022 - train - INFO - True
2024-04-03 04:47:29,024 - train - INFO - alphas:tensor([0.6180, 0.3820], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,024 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,024 - train - INFO - True
2024-04-03 04:47:29,024 - train - INFO - alphas:tensor([0.5136, 0.4864], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,037 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,037 - train - INFO - True
2024-04-03 04:47:29,038 - train - INFO - alphas:tensor([0.3478, 0.6522], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,038 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,038 - train - INFO - True
2024-04-03 04:47:29,039 - train - INFO - alphas:tensor([0.4902, 0.5098], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,039 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,039 - train - INFO - True
2024-04-03 04:47:29,040 - train - INFO - alphas:tensor([0.6250, 0.3750], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,040 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,040 - train - INFO - True
2024-04-03 04:47:29,040 - train - INFO - alphas:tensor([0.4951, 0.5049], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,040 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,041 - train - INFO - True
2024-04-03 04:47:29,041 - train - INFO - alphas:tensor([0.3633, 0.6367], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,041 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,041 - train - INFO - True
2024-04-03 04:47:29,042 - train - INFO - alphas:tensor([0.4783, 0.5217], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,042 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,042 - train - INFO - True
2024-04-03 04:47:29,043 - train - INFO - alphas:tensor([0.5748, 0.4252], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,043 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,043 - train - INFO - True
2024-04-03 04:47:29,044 - train - INFO - alphas:tensor([0.4223, 0.5777], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,044 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,044 - train - INFO - True
2024-04-03 04:47:29,049 - train - INFO - alphas:tensor([0.3324, 0.6676], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,049 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,049 - train - INFO - True
2024-04-03 04:47:29,050 - train - INFO - alphas:tensor([0.3884, 0.6116], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,062 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,062 - train - INFO - True
2024-04-03 04:47:29,063 - train - INFO - alphas:tensor([0.4778, 0.5222], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,063 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,063 - train - INFO - True
2024-04-03 04:47:29,064 - train - INFO - alphas:tensor([0.2969, 0.7031], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,064 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,064 - train - INFO - True
2024-04-03 04:47:29,065 - train - INFO - alphas:tensor([0.2781, 0.7219], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,065 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,065 - train - INFO - True
2024-04-03 04:47:29,065 - train - INFO - alphas:tensor([0.3276, 0.6724], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,066 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,066 - train - INFO - True
2024-04-03 04:47:29,071 - train - INFO - alphas:tensor([0.4344, 0.5656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,071 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,071 - train - INFO - True
2024-04-03 04:47:29,071 - train - INFO - alphas:tensor([0.2276, 0.7724], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,072 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,072 - train - INFO - True
2024-04-03 04:47:29,072 - train - INFO - alphas:tensor([0.2110, 0.7890], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,072 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,072 - train - INFO - True
2024-04-03 04:47:29,073 - train - INFO - alphas:tensor([0.1608, 0.8392], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,073 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,073 - train - INFO - True
2024-04-03 04:47:29,074 - train - INFO - alphas:tensor([0.1169, 0.8831], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,074 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,074 - train - INFO - True
2024-04-03 04:47:29,075 - train - INFO - alphas:tensor([0.0071, 0.9929], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,075 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,075 - train - INFO - True
2024-04-03 04:47:29,075 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:47:29,076 - train - INFO - tau:0.5811664141181095
2024-04-03 04:47:29,076 - train - INFO - avg block size:12.379310344827585
2024-04-03 04:47:30,380 - train - INFO - Test: [   0/39]  Time: 1.302 (1.302)  Loss:  0.4148 (0.4148)  Acc@1: 90.6250 (90.6250)  Acc@5: 99.6094 (99.6094)
2024-04-03 04:48:22,582 - train - INFO - Test: [  39/39]  Time: 1.317 (1.337)  Loss:  0.3381 (0.3998)  Acc@1: 93.7500 (91.3700)  Acc@5: 100.0000 (99.6400)
2024-04-03 04:48:25,126 - train - INFO - Train: 57 [   0/195 (  0%)]  Loss:  1.793465 (1.7935)  Time: 2.410s,  106.23/s  (2.410s,  106.23/s)  LR: 3.794e-04  Data: 0.286 (0.286)
2024-04-03 04:50:23,289 - train - INFO - Train: 57 [  50/195 ( 26%)]  Loss:  1.272386 (1.6296)  Time: 2.166s,  118.18/s  (2.364s,  108.29/s)  LR: 3.794e-04  Data: 0.005 (0.016)
2024-04-03 04:52:19,349 - train - INFO - Train: 57 [ 100/195 ( 52%)]  Loss:  1.257083 (1.6385)  Time: 2.760s,   92.76/s  (2.343s,  109.27/s)  LR: 3.794e-04  Data: 0.014 (0.013)
2024-04-03 04:54:14,922 - train - INFO - Train: 57 [ 150/195 ( 77%)]  Loss:  1.679646 (1.6240)  Time: 2.636s,   97.11/s  (2.332s,  109.76/s)  LR: 3.794e-04  Data: 0.010 (0.013)
2024-04-03 04:55:59,925 - train - INFO - Train: 57 [ 194/195 (100%)]  Loss:  1.666992 (1.6185)  Time: 2.487s,  102.93/s  (2.345s,  109.19/s)  LR: 3.794e-04  Data: 0.000 (0.012)
2024-04-03 04:55:59,925 - train - INFO - True
2024-04-03 04:55:59,926 - train - INFO - alphas:tensor([0.0599, 0.9401], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,927 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,927 - train - INFO - True
2024-04-03 04:55:59,927 - train - INFO - alphas:tensor([0.1495, 0.8505], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,928 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,932 - train - INFO - True
2024-04-03 04:55:59,933 - train - INFO - alphas:tensor([0.6049, 0.3951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,933 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,933 - train - INFO - True
2024-04-03 04:55:59,934 - train - INFO - alphas:tensor([0.5478, 0.4522], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,934 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,934 - train - INFO - True
2024-04-03 04:55:59,935 - train - INFO - alphas:tensor([0.2546, 0.7454], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,935 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,935 - train - INFO - True
2024-04-03 04:55:59,936 - train - INFO - alphas:tensor([0.3780, 0.6220], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,936 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,936 - train - INFO - True
2024-04-03 04:55:59,936 - train - INFO - alphas:tensor([0.6157, 0.3843], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,937 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,937 - train - INFO - True
2024-04-03 04:55:59,937 - train - INFO - alphas:tensor([0.5115, 0.4885], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,937 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,937 - train - INFO - True
2024-04-03 04:55:59,938 - train - INFO - alphas:tensor([0.3448, 0.6552], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,938 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,938 - train - INFO - True
2024-04-03 04:55:59,939 - train - INFO - alphas:tensor([0.4866, 0.5134], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,939 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,939 - train - INFO - True
2024-04-03 04:55:59,940 - train - INFO - alphas:tensor([0.6235, 0.3765], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,940 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,940 - train - INFO - True
2024-04-03 04:55:59,941 - train - INFO - alphas:tensor([0.4911, 0.5089], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,941 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,941 - train - INFO - True
2024-04-03 04:55:59,942 - train - INFO - alphas:tensor([0.3595, 0.6405], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,942 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,942 - train - INFO - True
2024-04-03 04:55:59,943 - train - INFO - alphas:tensor([0.4759, 0.5241], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,947 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,947 - train - INFO - True
2024-04-03 04:55:59,966 - train - INFO - alphas:tensor([0.5713, 0.4287], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,967 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,967 - train - INFO - True
2024-04-03 04:55:59,967 - train - INFO - alphas:tensor([0.4199, 0.5801], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,982 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,982 - train - INFO - True
2024-04-03 04:55:59,983 - train - INFO - alphas:tensor([0.3294, 0.6706], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,983 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,983 - train - INFO - True
2024-04-03 04:55:59,984 - train - INFO - alphas:tensor([0.3863, 0.6137], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,986 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,986 - train - INFO - True
2024-04-03 04:55:59,986 - train - INFO - alphas:tensor([0.4769, 0.5231], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,986 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,986 - train - INFO - True
2024-04-03 04:55:59,987 - train - INFO - alphas:tensor([0.2979, 0.7021], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,987 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,987 - train - INFO - True
2024-04-03 04:55:59,988 - train - INFO - alphas:tensor([0.2755, 0.7245], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,988 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,988 - train - INFO - True
2024-04-03 04:55:59,989 - train - INFO - alphas:tensor([0.3268, 0.6732], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,989 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,989 - train - INFO - True
2024-04-03 04:55:59,990 - train - INFO - alphas:tensor([0.4339, 0.5661], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,990 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,990 - train - INFO - True
2024-04-03 04:55:59,990 - train - INFO - alphas:tensor([0.2276, 0.7724], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:55:59,991 - train - INFO - tau:0.5753547499769285
2024-04-03 04:55:59,991 - train - INFO - True
2024-04-03 04:56:00,009 - train - INFO - alphas:tensor([0.2075, 0.7925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:56:00,009 - train - INFO - tau:0.5753547499769285
2024-04-03 04:56:00,009 - train - INFO - True
2024-04-03 04:56:00,010 - train - INFO - alphas:tensor([0.1554, 0.8446], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:56:00,010 - train - INFO - tau:0.5753547499769285
2024-04-03 04:56:00,010 - train - INFO - True
2024-04-03 04:56:00,011 - train - INFO - alphas:tensor([0.1136, 0.8864], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:56:00,011 - train - INFO - tau:0.5753547499769285
2024-04-03 04:56:00,011 - train - INFO - True
2024-04-03 04:56:00,011 - train - INFO - alphas:tensor([0.0063, 0.9937], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:56:00,012 - train - INFO - tau:0.5753547499769285
2024-04-03 04:56:00,012 - train - INFO - True
2024-04-03 04:56:00,012 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 04:56:00,012 - train - INFO - tau:0.5753547499769285
2024-04-03 04:56:00,012 - train - INFO - avg block size:12.379310344827585
2024-04-03 04:56:01,431 - train - INFO - Test: [   0/39]  Time: 1.404 (1.404)  Loss:  0.4070 (0.4070)  Acc@1: 90.6250 (90.6250)  Acc@5: 99.2188 (99.2188)
2024-04-03 04:56:53,745 - train - INFO - Test: [  39/39]  Time: 1.302 (1.343)  Loss:  0.3708 (0.3817)  Acc@1: 87.5000 (91.7900)  Acc@5: 100.0000 (99.6900)
2024-04-03 04:56:56,560 - train - INFO - Train: 58 [   0/195 (  0%)]  Loss:  1.804377 (1.8044)  Time: 2.626s,   97.50/s  (2.626s,   97.50/s)  LR: 3.741e-04  Data: 0.154 (0.154)
2024-04-03 04:58:54,361 - train - INFO - Train: 58 [  50/195 ( 26%)]  Loss:  1.366299 (1.6167)  Time: 2.269s,  112.80/s  (2.361s,  108.42/s)  LR: 3.741e-04  Data: 0.005 (0.011)
2024-04-03 05:00:52,962 - train - INFO - Train: 58 [ 100/195 ( 52%)]  Loss:  1.812709 (1.6090)  Time: 2.373s,  107.88/s  (2.367s,  108.17/s)  LR: 3.741e-04  Data: 0.014 (0.011)
2024-04-03 05:02:51,083 - train - INFO - Train: 58 [ 150/195 ( 77%)]  Loss:  1.643204 (1.6068)  Time: 2.264s,  113.08/s  (2.365s,  108.24/s)  LR: 3.741e-04  Data: 0.014 (0.011)
2024-04-03 05:04:34,126 - train - INFO - Train: 58 [ 194/195 (100%)]  Loss:  1.512414 (1.6068)  Time: 2.171s,  117.92/s  (2.360s,  108.48/s)  LR: 3.741e-04  Data: 0.000 (0.011)
2024-04-03 05:04:34,127 - train - INFO - True
2024-04-03 05:04:34,129 - train - INFO - alphas:tensor([0.0565, 0.9435], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,129 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,129 - train - INFO - True
2024-04-03 05:04:34,130 - train - INFO - alphas:tensor([0.1471, 0.8529], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,130 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,130 - train - INFO - True
2024-04-03 05:04:34,131 - train - INFO - alphas:tensor([0.6032, 0.3968], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,131 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,131 - train - INFO - True
2024-04-03 05:04:34,132 - train - INFO - alphas:tensor([0.5463, 0.4537], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,132 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,132 - train - INFO - True
2024-04-03 05:04:34,133 - train - INFO - alphas:tensor([0.2507, 0.7493], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,133 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,133 - train - INFO - True
2024-04-03 05:04:34,134 - train - INFO - alphas:tensor([0.3703, 0.6297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,134 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,135 - train - INFO - True
2024-04-03 05:04:34,135 - train - INFO - alphas:tensor([0.6161, 0.3839], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,135 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,136 - train - INFO - True
2024-04-03 05:04:34,136 - train - INFO - alphas:tensor([0.5129, 0.4871], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,136 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,137 - train - INFO - True
2024-04-03 05:04:34,137 - train - INFO - alphas:tensor([0.3449, 0.6551], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,137 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,138 - train - INFO - True
2024-04-03 05:04:34,139 - train - INFO - alphas:tensor([0.4878, 0.5122], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,139 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,139 - train - INFO - True
2024-04-03 05:04:34,140 - train - INFO - alphas:tensor([0.6222, 0.3778], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,140 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,140 - train - INFO - True
2024-04-03 05:04:34,141 - train - INFO - alphas:tensor([0.4903, 0.5097], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,141 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,141 - train - INFO - True
2024-04-03 05:04:34,142 - train - INFO - alphas:tensor([0.3590, 0.6410], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,142 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,142 - train - INFO - True
2024-04-03 05:04:34,143 - train - INFO - alphas:tensor([0.4749, 0.5251], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,143 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,143 - train - INFO - True
2024-04-03 05:04:34,144 - train - INFO - alphas:tensor([0.5682, 0.4318], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,144 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,144 - train - INFO - True
2024-04-03 05:04:34,145 - train - INFO - alphas:tensor([0.4174, 0.5826], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,145 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,145 - train - INFO - True
2024-04-03 05:04:34,145 - train - INFO - alphas:tensor([0.3269, 0.6731], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,146 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,146 - train - INFO - True
2024-04-03 05:04:34,146 - train - INFO - alphas:tensor([0.3841, 0.6159], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,146 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,146 - train - INFO - True
2024-04-03 05:04:34,147 - train - INFO - alphas:tensor([0.4734, 0.5266], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,147 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,147 - train - INFO - True
2024-04-03 05:04:34,148 - train - INFO - alphas:tensor([0.2941, 0.7059], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,148 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,148 - train - INFO - True
2024-04-03 05:04:34,149 - train - INFO - alphas:tensor([0.2728, 0.7272], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,149 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,149 - train - INFO - True
2024-04-03 05:04:34,150 - train - INFO - alphas:tensor([0.3230, 0.6770], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,150 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,150 - train - INFO - True
2024-04-03 05:04:34,150 - train - INFO - alphas:tensor([0.4273, 0.5727], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,150 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,151 - train - INFO - True
2024-04-03 05:04:34,151 - train - INFO - alphas:tensor([0.2223, 0.7777], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,151 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,151 - train - INFO - True
2024-04-03 05:04:34,152 - train - INFO - alphas:tensor([0.2048, 0.7952], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,152 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,152 - train - INFO - True
2024-04-03 05:04:34,153 - train - INFO - alphas:tensor([0.1486, 0.8514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,153 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,153 - train - INFO - True
2024-04-03 05:04:34,154 - train - INFO - alphas:tensor([0.1109, 0.8891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,154 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,154 - train - INFO - True
2024-04-03 05:04:34,154 - train - INFO - alphas:tensor([0.0055, 0.9945], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,155 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,155 - train - INFO - True
2024-04-03 05:04:34,155 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:04:34,155 - train - INFO - tau:0.5696012024771592
2024-04-03 05:04:34,155 - train - INFO - avg block size:12.379310344827585
2024-04-03 05:04:35,579 - train - INFO - Test: [   0/39]  Time: 1.419 (1.419)  Loss:  0.3933 (0.3933)  Acc@1: 91.0156 (91.0156)  Acc@5: 100.0000 (100.0000)
2024-04-03 05:05:27,927 - train - INFO - Test: [  39/39]  Time: 1.366 (1.344)  Loss:  0.4744 (0.3815)  Acc@1: 81.2500 (92.3100)  Acc@5: 100.0000 (99.7400)
2024-04-03 05:05:30,528 - train - INFO - Train: 59 [   0/195 (  0%)]  Loss:  1.804979 (1.8050)  Time: 2.445s,  104.69/s  (2.445s,  104.69/s)  LR: 3.688e-04  Data: 0.199 (0.199)
2024-04-03 05:07:29,639 - train - INFO - Train: 59 [  50/195 ( 26%)]  Loss:  1.756073 (1.6215)  Time: 2.304s,  111.11/s  (2.383s,  107.41/s)  LR: 3.688e-04  Data: 0.014 (0.015)
2024-04-03 05:09:29,319 - train - INFO - Train: 59 [ 100/195 ( 52%)]  Loss:  1.753397 (1.6150)  Time: 2.208s,  115.95/s  (2.388s,  107.18/s)  LR: 3.688e-04  Data: 0.010 (0.012)
2024-04-03 05:11:23,715 - train - INFO - Train: 59 [ 150/195 ( 77%)]  Loss:  1.211929 (1.5947)  Time: 2.650s,   96.59/s  (2.355s,  108.70/s)  LR: 3.688e-04  Data: 0.005 (0.011)
2024-04-03 05:13:09,145 - train - INFO - Train: 59 [ 194/195 (100%)]  Loss:  1.394541 (1.5950)  Time: 2.163s,  118.37/s  (2.364s,  108.27/s)  LR: 3.688e-04  Data: 0.000 (0.011)
2024-04-03 05:13:09,146 - train - INFO - True
2024-04-03 05:13:09,148 - train - INFO - alphas:tensor([0.0536, 0.9464], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,148 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,148 - train - INFO - True
2024-04-03 05:13:09,149 - train - INFO - alphas:tensor([0.1439, 0.8561], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,149 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,149 - train - INFO - True
2024-04-03 05:13:09,150 - train - INFO - alphas:tensor([0.6023, 0.3977], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,150 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,150 - train - INFO - True
2024-04-03 05:13:09,151 - train - INFO - alphas:tensor([0.5447, 0.4553], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,151 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,151 - train - INFO - True
2024-04-03 05:13:09,151 - train - INFO - alphas:tensor([0.2489, 0.7511], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,152 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,152 - train - INFO - True
2024-04-03 05:13:09,152 - train - INFO - alphas:tensor([0.3693, 0.6307], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,154 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,154 - train - INFO - True
2024-04-03 05:13:09,155 - train - INFO - alphas:tensor([0.6143, 0.3857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,155 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,155 - train - INFO - True
2024-04-03 05:13:09,155 - train - INFO - alphas:tensor([0.5082, 0.4918], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,156 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,156 - train - INFO - True
2024-04-03 05:13:09,156 - train - INFO - alphas:tensor([0.3418, 0.6582], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,178 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,178 - train - INFO - True
2024-04-03 05:13:09,179 - train - INFO - alphas:tensor([0.4846, 0.5154], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,183 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,183 - train - INFO - True
2024-04-03 05:13:09,184 - train - INFO - alphas:tensor([0.6201, 0.3799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,191 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,191 - train - INFO - True
2024-04-03 05:13:09,192 - train - INFO - alphas:tensor([0.4901, 0.5099], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,192 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,192 - train - INFO - True
2024-04-03 05:13:09,192 - train - INFO - alphas:tensor([0.3542, 0.6458], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,193 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,193 - train - INFO - True
2024-04-03 05:13:09,193 - train - INFO - alphas:tensor([0.4704, 0.5296], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,195 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,195 - train - INFO - True
2024-04-03 05:13:09,210 - train - INFO - alphas:tensor([0.5663, 0.4337], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,210 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,214 - train - INFO - True
2024-04-03 05:13:09,219 - train - INFO - alphas:tensor([0.4148, 0.5852], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,219 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,219 - train - INFO - True
2024-04-03 05:13:09,220 - train - INFO - alphas:tensor([0.3224, 0.6776], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,220 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,220 - train - INFO - True
2024-04-03 05:13:09,221 - train - INFO - alphas:tensor([0.3805, 0.6195], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,221 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,221 - train - INFO - True
2024-04-03 05:13:09,221 - train - INFO - alphas:tensor([0.4703, 0.5297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,221 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,222 - train - INFO - True
2024-04-03 05:13:09,222 - train - INFO - alphas:tensor([0.2886, 0.7114], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,227 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,227 - train - INFO - True
2024-04-03 05:13:09,227 - train - INFO - alphas:tensor([0.2683, 0.7317], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,228 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,228 - train - INFO - True
2024-04-03 05:13:09,228 - train - INFO - alphas:tensor([0.3182, 0.6818], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,228 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,228 - train - INFO - True
2024-04-03 05:13:09,229 - train - INFO - alphas:tensor([0.4246, 0.5754], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,229 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,229 - train - INFO - True
2024-04-03 05:13:09,230 - train - INFO - alphas:tensor([0.2184, 0.7816], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,230 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,230 - train - INFO - True
2024-04-03 05:13:09,231 - train - INFO - alphas:tensor([0.2024, 0.7976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,231 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,231 - train - INFO - True
2024-04-03 05:13:09,232 - train - INFO - alphas:tensor([0.1444, 0.8556], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,245 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,245 - train - INFO - True
2024-04-03 05:13:09,246 - train - INFO - alphas:tensor([0.1076, 0.8924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,246 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,246 - train - INFO - True
2024-04-03 05:13:09,246 - train - INFO - alphas:tensor([0.0049, 0.9951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,247 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,247 - train - INFO - True
2024-04-03 05:13:09,247 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:13:09,247 - train - INFO - tau:0.5639051904523876
2024-04-03 05:13:09,247 - train - INFO - avg block size:12.379310344827585
2024-04-03 05:13:10,638 - train - INFO - Test: [   0/39]  Time: 1.388 (1.388)  Loss:  0.3857 (0.3857)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-04-03 05:14:03,197 - train - INFO - Test: [  39/39]  Time: 1.308 (1.349)  Loss:  0.4180 (0.3787)  Acc@1: 87.5000 (91.8900)  Acc@5: 100.0000 (99.7100)
2024-04-03 05:14:05,715 - train - INFO - Train: 60 [   0/195 (  0%)]  Loss:  1.726915 (1.7269)  Time: 2.423s,  105.66/s  (2.423s,  105.66/s)  LR: 3.634e-04  Data: 0.310 (0.310)
2024-04-03 05:16:04,412 - train - INFO - Train: 60 [  50/195 ( 26%)]  Loss:  1.208170 (1.6175)  Time: 2.434s,  105.16/s  (2.375s,  107.80/s)  LR: 3.634e-04  Data: 0.013 (0.017)
2024-04-03 05:18:02,610 - train - INFO - Train: 60 [ 100/195 ( 52%)]  Loss:  1.841904 (1.5908)  Time: 2.262s,  113.20/s  (2.369s,  108.04/s)  LR: 3.634e-04  Data: 0.006 (0.013)
2024-04-03 05:19:58,960 - train - INFO - Train: 60 [ 150/195 ( 77%)]  Loss:  1.859622 (1.5875)  Time: 2.149s,  119.14/s  (2.355s,  108.69/s)  LR: 3.634e-04  Data: 0.005 (0.013)
2024-04-03 05:21:43,780 - train - INFO - Train: 60 [ 194/195 (100%)]  Loss:  1.284501 (1.5963)  Time: 2.349s,  109.00/s  (2.361s,  108.41/s)  LR: 3.634e-04  Data: 0.000 (0.012)
2024-04-03 05:21:43,780 - train - INFO - True
2024-04-03 05:21:43,781 - train - INFO - alphas:tensor([0.0502, 0.9498], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,782 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,782 - train - INFO - True
2024-04-03 05:21:43,782 - train - INFO - alphas:tensor([0.1419, 0.8581], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,782 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,783 - train - INFO - True
2024-04-03 05:21:43,783 - train - INFO - alphas:tensor([0.6014, 0.3986], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,783 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,783 - train - INFO - True
2024-04-03 05:21:43,784 - train - INFO - alphas:tensor([0.5433, 0.4567], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,784 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,784 - train - INFO - True
2024-04-03 05:21:43,785 - train - INFO - alphas:tensor([0.2461, 0.7539], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,785 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,785 - train - INFO - True
2024-04-03 05:21:43,786 - train - INFO - alphas:tensor([0.3665, 0.6335], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,786 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,786 - train - INFO - True
2024-04-03 05:21:43,786 - train - INFO - alphas:tensor([0.6130, 0.3870], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,787 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,787 - train - INFO - True
2024-04-03 05:21:43,787 - train - INFO - alphas:tensor([0.5065, 0.4935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,788 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,788 - train - INFO - True
2024-04-03 05:21:43,788 - train - INFO - alphas:tensor([0.3379, 0.6621], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,789 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,789 - train - INFO - True
2024-04-03 05:21:43,789 - train - INFO - alphas:tensor([0.4789, 0.5211], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,789 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,789 - train - INFO - True
2024-04-03 05:21:43,790 - train - INFO - alphas:tensor([0.6177, 0.3823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,790 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,790 - train - INFO - True
2024-04-03 05:21:43,791 - train - INFO - alphas:tensor([0.4874, 0.5126], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,791 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,791 - train - INFO - True
2024-04-03 05:21:43,792 - train - INFO - alphas:tensor([0.3535, 0.6465], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,792 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,792 - train - INFO - True
2024-04-03 05:21:43,793 - train - INFO - alphas:tensor([0.4672, 0.5328], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,793 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,793 - train - INFO - True
2024-04-03 05:21:43,793 - train - INFO - alphas:tensor([0.5629, 0.4371], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,794 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,794 - train - INFO - True
2024-04-03 05:21:43,794 - train - INFO - alphas:tensor([0.4123, 0.5877], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,794 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,794 - train - INFO - True
2024-04-03 05:21:43,795 - train - INFO - alphas:tensor([0.3172, 0.6828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,795 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,795 - train - INFO - True
2024-04-03 05:21:43,796 - train - INFO - alphas:tensor([0.3763, 0.6237], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,796 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,796 - train - INFO - True
2024-04-03 05:21:43,797 - train - INFO - alphas:tensor([0.4659, 0.5341], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,797 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,797 - train - INFO - True
2024-04-03 05:21:43,798 - train - INFO - alphas:tensor([0.2867, 0.7133], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,798 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,798 - train - INFO - True
2024-04-03 05:21:43,798 - train - INFO - alphas:tensor([0.2658, 0.7342], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,798 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,799 - train - INFO - True
2024-04-03 05:21:43,799 - train - INFO - alphas:tensor([0.3169, 0.6831], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,799 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,799 - train - INFO - True
2024-04-03 05:21:43,800 - train - INFO - alphas:tensor([0.4213, 0.5787], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,800 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,800 - train - INFO - True
2024-04-03 05:21:43,801 - train - INFO - alphas:tensor([0.2143, 0.7857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,801 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,801 - train - INFO - True
2024-04-03 05:21:43,802 - train - INFO - alphas:tensor([0.1990, 0.8010], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,802 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,802 - train - INFO - True
2024-04-03 05:21:43,802 - train - INFO - alphas:tensor([0.1382, 0.8618], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,803 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,803 - train - INFO - True
2024-04-03 05:21:43,804 - train - INFO - alphas:tensor([0.1049, 0.8951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,804 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,804 - train - INFO - True
2024-04-03 05:21:43,804 - train - INFO - alphas:tensor([0.0043, 0.9957], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,805 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,805 - train - INFO - True
2024-04-03 05:21:43,805 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:21:43,805 - train - INFO - tau:0.5582661385478638
2024-04-03 05:21:43,805 - train - INFO - avg block size:12.379310344827585
2024-04-03 05:21:45,166 - train - INFO - Test: [   0/39]  Time: 1.358 (1.358)  Loss:  0.3794 (0.3794)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.2188 (99.2188)
2024-04-03 05:22:38,268 - train - INFO - Test: [  39/39]  Time: 1.390 (1.362)  Loss:  0.3916 (0.3767)  Acc@1: 87.5000 (92.1500)  Acc@5: 100.0000 (99.6900)
2024-04-03 05:22:40,933 - train - INFO - Train: 61 [   0/195 (  0%)]  Loss:  1.784649 (1.7846)  Time: 2.449s,  104.53/s  (2.449s,  104.53/s)  LR: 3.580e-04  Data: 0.292 (0.292)
2024-04-03 05:24:37,453 - train - INFO - Train: 61 [  50/195 ( 26%)]  Loss:  1.526673 (1.6011)  Time: 2.441s,  104.86/s  (2.333s,  109.74/s)  LR: 3.580e-04  Data: 0.014 (0.016)
2024-04-03 05:26:34,549 - train - INFO - Train: 61 [ 100/195 ( 52%)]  Loss:  1.331414 (1.5899)  Time: 2.457s,  104.21/s  (2.337s,  109.53/s)  LR: 3.580e-04  Data: 0.011 (0.013)
2024-04-03 05:28:32,094 - train - INFO - Train: 61 [ 150/195 ( 77%)]  Loss:  1.795472 (1.5957)  Time: 2.347s,  109.08/s  (2.342s,  109.32/s)  LR: 3.580e-04  Data: 0.005 (0.013)
2024-04-03 05:30:15,012 - train - INFO - Train: 61 [ 194/195 (100%)]  Loss:  1.586748 (1.5952)  Time: 2.387s,  107.23/s  (2.341s,  109.35/s)  LR: 3.580e-04  Data: 0.000 (0.012)
2024-04-03 05:30:15,023 - train - INFO - True
2024-04-03 05:30:15,024 - train - INFO - alphas:tensor([0.0472, 0.9528], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,024 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,024 - train - INFO - True
2024-04-03 05:30:15,025 - train - INFO - alphas:tensor([0.1393, 0.8607], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,025 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,025 - train - INFO - True
2024-04-03 05:30:15,026 - train - INFO - alphas:tensor([0.6000, 0.4000], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,026 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,026 - train - INFO - True
2024-04-03 05:30:15,027 - train - INFO - alphas:tensor([0.5409, 0.4591], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,027 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,027 - train - INFO - True
2024-04-03 05:30:15,028 - train - INFO - alphas:tensor([0.2422, 0.7578], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,028 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,028 - train - INFO - True
2024-04-03 05:30:15,028 - train - INFO - alphas:tensor([0.3625, 0.6375], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,028 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,029 - train - INFO - True
2024-04-03 05:30:15,029 - train - INFO - alphas:tensor([0.6103, 0.3897], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,029 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,029 - train - INFO - True
2024-04-03 05:30:15,030 - train - INFO - alphas:tensor([0.5048, 0.4952], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,030 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,030 - train - INFO - True
2024-04-03 05:30:15,031 - train - INFO - alphas:tensor([0.3361, 0.6639], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,031 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,031 - train - INFO - True
2024-04-03 05:30:15,032 - train - INFO - alphas:tensor([0.4767, 0.5233], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,032 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,032 - train - INFO - True
2024-04-03 05:30:15,033 - train - INFO - alphas:tensor([0.6166, 0.3834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,033 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,033 - train - INFO - True
2024-04-03 05:30:15,034 - train - INFO - alphas:tensor([0.4872, 0.5128], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,034 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,034 - train - INFO - True
2024-04-03 05:30:15,034 - train - INFO - alphas:tensor([0.3513, 0.6487], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,034 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,035 - train - INFO - True
2024-04-03 05:30:15,035 - train - INFO - alphas:tensor([0.4673, 0.5327], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,035 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,035 - train - INFO - True
2024-04-03 05:30:15,036 - train - INFO - alphas:tensor([0.5623, 0.4377], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,036 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,036 - train - INFO - True
2024-04-03 05:30:15,037 - train - INFO - alphas:tensor([0.4117, 0.5883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,037 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,037 - train - INFO - True
2024-04-03 05:30:15,038 - train - INFO - alphas:tensor([0.3175, 0.6825], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,038 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,038 - train - INFO - True
2024-04-03 05:30:15,038 - train - INFO - alphas:tensor([0.3747, 0.6253], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,039 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,039 - train - INFO - True
2024-04-03 05:30:15,039 - train - INFO - alphas:tensor([0.4655, 0.5345], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,039 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,039 - train - INFO - True
2024-04-03 05:30:15,040 - train - INFO - alphas:tensor([0.2842, 0.7158], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,040 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,040 - train - INFO - True
2024-04-03 05:30:15,041 - train - INFO - alphas:tensor([0.2631, 0.7369], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,041 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,041 - train - INFO - True
2024-04-03 05:30:15,042 - train - INFO - alphas:tensor([0.3148, 0.6852], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,042 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,042 - train - INFO - True
2024-04-03 05:30:15,042 - train - INFO - alphas:tensor([0.4205, 0.5795], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,043 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,043 - train - INFO - True
2024-04-03 05:30:15,043 - train - INFO - alphas:tensor([0.2127, 0.7873], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,043 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,043 - train - INFO - True
2024-04-03 05:30:15,044 - train - INFO - alphas:tensor([0.1956, 0.8044], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,044 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,044 - train - INFO - True
2024-04-03 05:30:15,045 - train - INFO - alphas:tensor([0.1338, 0.8662], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,045 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,045 - train - INFO - True
2024-04-03 05:30:15,046 - train - INFO - alphas:tensor([0.1008, 0.8992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,046 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,046 - train - INFO - True
2024-04-03 05:30:15,046 - train - INFO - alphas:tensor([0.0038, 0.9962], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,047 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,047 - train - INFO - True
2024-04-03 05:30:15,047 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:30:15,047 - train - INFO - tau:0.5526834771623851
2024-04-03 05:30:15,047 - train - INFO - avg block size:12.379310344827585
2024-04-03 05:30:16,436 - train - INFO - Test: [   0/39]  Time: 1.386 (1.386)  Loss:  0.3740 (0.3740)  Acc@1: 91.4062 (91.4062)  Acc@5: 99.6094 (99.6094)
2024-04-03 05:31:08,854 - train - INFO - Test: [  39/39]  Time: 1.384 (1.345)  Loss:  0.3501 (0.3731)  Acc@1: 93.7500 (91.9600)  Acc@5: 100.0000 (99.7300)
2024-04-03 05:31:11,508 - train - INFO - Train: 62 [   0/195 (  0%)]  Loss:  1.368893 (1.3689)  Time: 2.457s,  104.19/s  (2.457s,  104.19/s)  LR: 3.526e-04  Data: 0.306 (0.306)
2024-04-03 05:33:09,185 - train - INFO - Train: 62 [  50/195 ( 26%)]  Loss:  1.248476 (1.5635)  Time: 2.128s,  120.29/s  (2.356s,  108.68/s)  LR: 3.526e-04  Data: 0.010 (0.015)
2024-04-03 05:35:04,959 - train - INFO - Train: 62 [ 100/195 ( 52%)]  Loss:  1.446435 (1.5882)  Time: 2.251s,  113.75/s  (2.336s,  109.60/s)  LR: 3.526e-04  Data: 0.014 (0.013)
2024-04-03 05:37:03,963 - train - INFO - Train: 62 [ 150/195 ( 77%)]  Loss:  1.787507 (1.6004)  Time: 2.646s,   96.74/s  (2.350s,  108.92/s)  LR: 3.526e-04  Data: 0.010 (0.012)
2024-04-03 05:38:49,210 - train - INFO - Train: 62 [ 194/195 (100%)]  Loss:  1.377558 (1.5974)  Time: 2.337s,  109.54/s  (2.360s,  108.49/s)  LR: 3.526e-04  Data: 0.000 (0.012)
2024-04-03 05:38:49,215 - train - INFO - True
2024-04-03 05:38:49,217 - train - INFO - alphas:tensor([0.0443, 0.9557], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,217 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,217 - train - INFO - True
2024-04-03 05:38:49,218 - train - INFO - alphas:tensor([0.1366, 0.8634], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,218 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,218 - train - INFO - True
2024-04-03 05:38:49,219 - train - INFO - alphas:tensor([0.5986, 0.4014], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,219 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,219 - train - INFO - True
2024-04-03 05:38:49,220 - train - INFO - alphas:tensor([0.5392, 0.4608], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,220 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,220 - train - INFO - True
2024-04-03 05:38:49,220 - train - INFO - alphas:tensor([0.2403, 0.7597], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,221 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,221 - train - INFO - True
2024-04-03 05:38:49,221 - train - INFO - alphas:tensor([0.3607, 0.6393], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,221 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,222 - train - INFO - True
2024-04-03 05:38:49,223 - train - INFO - alphas:tensor([0.6087, 0.3913], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,223 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,223 - train - INFO - True
2024-04-03 05:38:49,223 - train - INFO - alphas:tensor([0.5020, 0.4980], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,223 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,224 - train - INFO - True
2024-04-03 05:38:49,224 - train - INFO - alphas:tensor([0.3331, 0.6669], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,224 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,224 - train - INFO - True
2024-04-03 05:38:49,225 - train - INFO - alphas:tensor([0.4757, 0.5243], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,225 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,225 - train - INFO - True
2024-04-03 05:38:49,226 - train - INFO - alphas:tensor([0.6139, 0.3861], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,226 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,226 - train - INFO - True
2024-04-03 05:38:49,227 - train - INFO - alphas:tensor([0.4819, 0.5181], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,227 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,227 - train - INFO - True
2024-04-03 05:38:49,228 - train - INFO - alphas:tensor([0.3465, 0.6535], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,228 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,228 - train - INFO - True
2024-04-03 05:38:49,228 - train - INFO - alphas:tensor([0.4629, 0.5371], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,228 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,229 - train - INFO - True
2024-04-03 05:38:49,234 - train - INFO - alphas:tensor([0.5587, 0.4413], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,234 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,234 - train - INFO - True
2024-04-03 05:38:49,235 - train - INFO - alphas:tensor([0.4067, 0.5933], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,235 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,235 - train - INFO - True
2024-04-03 05:38:49,235 - train - INFO - alphas:tensor([0.3152, 0.6848], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,236 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,236 - train - INFO - True
2024-04-03 05:38:49,236 - train - INFO - alphas:tensor([0.3730, 0.6270], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,236 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,236 - train - INFO - True
2024-04-03 05:38:49,237 - train - INFO - alphas:tensor([0.4627, 0.5373], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,237 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,237 - train - INFO - True
2024-04-03 05:38:49,238 - train - INFO - alphas:tensor([0.2820, 0.7180], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,238 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,238 - train - INFO - True
2024-04-03 05:38:49,239 - train - INFO - alphas:tensor([0.2607, 0.7393], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,239 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,239 - train - INFO - True
2024-04-03 05:38:49,240 - train - INFO - alphas:tensor([0.3105, 0.6895], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,240 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,240 - train - INFO - True
2024-04-03 05:38:49,240 - train - INFO - alphas:tensor([0.4177, 0.5823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,241 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,241 - train - INFO - True
2024-04-03 05:38:49,241 - train - INFO - alphas:tensor([0.2097, 0.7903], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,241 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,241 - train - INFO - True
2024-04-03 05:38:49,242 - train - INFO - alphas:tensor([0.1939, 0.8061], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,242 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,242 - train - INFO - True
2024-04-03 05:38:49,247 - train - INFO - alphas:tensor([0.1294, 0.8706], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,247 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,247 - train - INFO - True
2024-04-03 05:38:49,248 - train - INFO - alphas:tensor([0.0974, 0.9026], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,248 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,248 - train - INFO - True
2024-04-03 05:38:49,249 - train - INFO - alphas:tensor([0.0033, 0.9967], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,249 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,249 - train - INFO - True
2024-04-03 05:38:49,250 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:38:49,250 - train - INFO - tau:0.5471566423907612
2024-04-03 05:38:49,250 - train - INFO - avg block size:12.379310344827585
2024-04-03 05:38:50,644 - train - INFO - Test: [   0/39]  Time: 1.391 (1.391)  Loss:  0.3967 (0.3967)  Acc@1: 91.7969 (91.7969)  Acc@5: 100.0000 (100.0000)
2024-04-03 05:39:42,983 - train - INFO - Test: [  39/39]  Time: 1.337 (1.343)  Loss:  0.4258 (0.3857)  Acc@1: 87.5000 (91.9100)  Acc@5: 100.0000 (99.6700)
2024-04-03 05:39:46,072 - train - INFO - Train: 63 [   0/195 (  0%)]  Loss:  1.821667 (1.8217)  Time: 2.890s,   88.57/s  (2.890s,   88.57/s)  LR: 3.471e-04  Data: 0.356 (0.356)
2024-04-03 05:41:46,048 - train - INFO - Train: 63 [  50/195 ( 26%)]  Loss:  1.756198 (1.5971)  Time: 2.466s,  103.80/s  (2.409s,  106.26/s)  LR: 3.471e-04  Data: 0.023 (0.018)
2024-04-03 05:43:44,682 - train - INFO - Train: 63 [ 100/195 ( 52%)]  Loss:  1.605929 (1.6039)  Time: 2.548s,  100.48/s  (2.391s,  107.06/s)  LR: 3.471e-04  Data: 0.014 (0.015)
2024-04-03 05:45:43,394 - train - INFO - Train: 63 [ 150/195 ( 77%)]  Loss:  1.612621 (1.5921)  Time: 2.421s,  105.73/s  (2.385s,  107.32/s)  LR: 3.471e-04  Data: 0.005 (0.013)
2024-04-03 05:47:29,954 - train - INFO - Train: 63 [ 194/195 (100%)]  Loss:  1.805393 (1.5926)  Time: 2.428s,  105.43/s  (2.394s,  106.95/s)  LR: 3.471e-04  Data: 0.000 (0.013)
2024-04-03 05:47:29,955 - train - INFO - True
2024-04-03 05:47:29,956 - train - INFO - alphas:tensor([0.0417, 0.9583], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,956 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,956 - train - INFO - True
2024-04-03 05:47:29,957 - train - INFO - alphas:tensor([0.1344, 0.8656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,957 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,958 - train - INFO - True
2024-04-03 05:47:29,958 - train - INFO - alphas:tensor([0.5978, 0.4022], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,958 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,959 - train - INFO - True
2024-04-03 05:47:29,959 - train - INFO - alphas:tensor([0.5374, 0.4626], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,959 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,959 - train - INFO - True
2024-04-03 05:47:29,965 - train - INFO - alphas:tensor([0.2360, 0.7640], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,965 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,965 - train - INFO - True
2024-04-03 05:47:29,966 - train - INFO - alphas:tensor([0.3573, 0.6427], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,966 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,966 - train - INFO - True
2024-04-03 05:47:29,967 - train - INFO - alphas:tensor([0.6058, 0.3942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,967 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,967 - train - INFO - True
2024-04-03 05:47:29,968 - train - INFO - alphas:tensor([0.5012, 0.4988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,968 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,968 - train - INFO - True
2024-04-03 05:47:29,969 - train - INFO - alphas:tensor([0.3303, 0.6697], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,969 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,969 - train - INFO - True
2024-04-03 05:47:29,970 - train - INFO - alphas:tensor([0.4728, 0.5272], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,970 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,970 - train - INFO - True
2024-04-03 05:47:29,971 - train - INFO - alphas:tensor([0.6121, 0.3879], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,971 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,971 - train - INFO - True
2024-04-03 05:47:29,972 - train - INFO - alphas:tensor([0.4799, 0.5201], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,972 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,972 - train - INFO - True
2024-04-03 05:47:29,973 - train - INFO - alphas:tensor([0.3465, 0.6535], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,973 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,973 - train - INFO - True
2024-04-03 05:47:29,974 - train - INFO - alphas:tensor([0.4627, 0.5373], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,974 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,974 - train - INFO - True
2024-04-03 05:47:29,975 - train - INFO - alphas:tensor([0.5581, 0.4419], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,975 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,975 - train - INFO - True
2024-04-03 05:47:29,976 - train - INFO - alphas:tensor([0.4077, 0.5923], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,976 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,976 - train - INFO - True
2024-04-03 05:47:29,977 - train - INFO - alphas:tensor([0.3118, 0.6882], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,977 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,977 - train - INFO - True
2024-04-03 05:47:29,978 - train - INFO - alphas:tensor([0.3703, 0.6297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,978 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,978 - train - INFO - True
2024-04-03 05:47:29,979 - train - INFO - alphas:tensor([0.4618, 0.5382], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,979 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,979 - train - INFO - True
2024-04-03 05:47:29,980 - train - INFO - alphas:tensor([0.2808, 0.7192], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,980 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,980 - train - INFO - True
2024-04-03 05:47:29,981 - train - INFO - alphas:tensor([0.2600, 0.7400], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,981 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,981 - train - INFO - True
2024-04-03 05:47:29,982 - train - INFO - alphas:tensor([0.3076, 0.6924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,982 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,982 - train - INFO - True
2024-04-03 05:47:29,983 - train - INFO - alphas:tensor([0.4156, 0.5844], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,983 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,983 - train - INFO - True
2024-04-03 05:47:29,984 - train - INFO - alphas:tensor([0.2078, 0.7922], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,984 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,984 - train - INFO - True
2024-04-03 05:47:29,985 - train - INFO - alphas:tensor([0.1925, 0.8075], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,985 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,985 - train - INFO - True
2024-04-03 05:47:29,986 - train - INFO - alphas:tensor([0.1252, 0.8748], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,986 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,986 - train - INFO - True
2024-04-03 05:47:29,987 - train - INFO - alphas:tensor([0.0943, 0.9057], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,987 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,987 - train - INFO - True
2024-04-03 05:47:29,988 - train - INFO - alphas:tensor([0.0029, 0.9971], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,988 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,988 - train - INFO - True
2024-04-03 05:47:29,989 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:47:29,989 - train - INFO - tau:0.5416850759668536
2024-04-03 05:47:29,989 - train - INFO - avg block size:12.379310344827585
2024-04-03 05:47:31,327 - train - INFO - Test: [   0/39]  Time: 1.335 (1.335)  Loss:  0.3767 (0.3767)  Acc@1: 92.9688 (92.9688)  Acc@5: 99.6094 (99.6094)
2024-04-03 05:48:23,714 - train - INFO - Test: [  39/39]  Time: 1.374 (1.343)  Loss:  0.4265 (0.3718)  Acc@1: 87.5000 (92.2600)  Acc@5: 100.0000 (99.7400)
2024-04-03 05:48:26,388 - train - INFO - Train: 64 [   0/195 (  0%)]  Loss:  1.771272 (1.7713)  Time: 2.470s,  103.66/s  (2.470s,  103.66/s)  LR: 3.417e-04  Data: 0.232 (0.232)
2024-04-03 05:50:24,418 - train - INFO - Train: 64 [  50/195 ( 26%)]  Loss:  1.903565 (1.5743)  Time: 2.442s,  104.84/s  (2.363s,  108.35/s)  LR: 3.417e-04  Data: 0.018 (0.016)
2024-04-03 05:52:22,837 - train - INFO - Train: 64 [ 100/195 ( 52%)]  Loss:  1.738889 (1.5759)  Time: 2.667s,   96.00/s  (2.366s,  108.22/s)  LR: 3.417e-04  Data: 0.006 (0.014)
2024-04-03 05:54:22,353 - train - INFO - Train: 64 [ 150/195 ( 77%)]  Loss:  1.175444 (1.5869)  Time: 2.348s,  109.03/s  (2.374s,  107.85/s)  LR: 3.417e-04  Data: 0.014 (0.013)
2024-04-03 05:55:49,859 - train - INFO - Train: 64 [ 194/195 (100%)]  Loss:  1.431283 (1.5802)  Time: 1.772s,  144.45/s  (2.287s,  111.94/s)  LR: 3.417e-04  Data: 0.000 (0.012)
2024-04-03 05:55:49,860 - train - INFO - True
2024-04-03 05:55:49,861 - train - INFO - alphas:tensor([0.0390, 0.9610], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,861 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,861 - train - INFO - True
2024-04-03 05:55:49,862 - train - INFO - alphas:tensor([0.1321, 0.8679], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,862 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,862 - train - INFO - True
2024-04-03 05:55:49,863 - train - INFO - alphas:tensor([0.5966, 0.4034], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,863 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,864 - train - INFO - True
2024-04-03 05:55:49,865 - train - INFO - alphas:tensor([0.5361, 0.4639], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,865 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,865 - train - INFO - True
2024-04-03 05:55:49,865 - train - INFO - alphas:tensor([0.2339, 0.7661], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,865 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,866 - train - INFO - True
2024-04-03 05:55:49,866 - train - INFO - alphas:tensor([0.3539, 0.6461], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,866 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,867 - train - INFO - True
2024-04-03 05:55:49,876 - train - INFO - alphas:tensor([0.6061, 0.3939], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,876 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,876 - train - INFO - True
2024-04-03 05:55:49,877 - train - INFO - alphas:tensor([0.5015, 0.4985], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,877 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,877 - train - INFO - True
2024-04-03 05:55:49,878 - train - INFO - alphas:tensor([0.3300, 0.6700], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,878 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,878 - train - INFO - True
2024-04-03 05:55:49,879 - train - INFO - alphas:tensor([0.4720, 0.5280], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,879 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,879 - train - INFO - True
2024-04-03 05:55:49,879 - train - INFO - alphas:tensor([0.6113, 0.3887], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,879 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,880 - train - INFO - True
2024-04-03 05:55:49,893 - train - INFO - alphas:tensor([0.4796, 0.5204], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,893 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,893 - train - INFO - True
2024-04-03 05:55:49,894 - train - INFO - alphas:tensor([0.3434, 0.6566], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,894 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,894 - train - INFO - True
2024-04-03 05:55:49,899 - train - INFO - alphas:tensor([0.4599, 0.5401], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,899 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,899 - train - INFO - True
2024-04-03 05:55:49,900 - train - INFO - alphas:tensor([0.5568, 0.4432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,900 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,900 - train - INFO - True
2024-04-03 05:55:49,901 - train - INFO - alphas:tensor([0.4061, 0.5939], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,901 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,901 - train - INFO - True
2024-04-03 05:55:49,901 - train - INFO - alphas:tensor([0.3102, 0.6898], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,902 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,902 - train - INFO - True
2024-04-03 05:55:49,907 - train - INFO - alphas:tensor([0.3674, 0.6326], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,907 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,907 - train - INFO - True
2024-04-03 05:55:49,907 - train - INFO - alphas:tensor([0.4592, 0.5408], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,908 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,908 - train - INFO - True
2024-04-03 05:55:49,908 - train - INFO - alphas:tensor([0.2771, 0.7229], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,908 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,908 - train - INFO - True
2024-04-03 05:55:49,909 - train - INFO - alphas:tensor([0.2574, 0.7426], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,909 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,909 - train - INFO - True
2024-04-03 05:55:49,910 - train - INFO - alphas:tensor([0.3050, 0.6950], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,910 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,910 - train - INFO - True
2024-04-03 05:55:49,924 - train - INFO - alphas:tensor([0.4119, 0.5881], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,924 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,924 - train - INFO - True
2024-04-03 05:55:49,925 - train - INFO - alphas:tensor([0.2032, 0.7968], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,925 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,925 - train - INFO - True
2024-04-03 05:55:49,926 - train - INFO - alphas:tensor([0.1902, 0.8098], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,926 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,926 - train - INFO - True
2024-04-03 05:55:49,926 - train - INFO - alphas:tensor([0.1205, 0.8795], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,927 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,927 - train - INFO - True
2024-04-03 05:55:49,927 - train - INFO - alphas:tensor([0.0920, 0.9080], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,927 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,927 - train - INFO - True
2024-04-03 05:55:49,928 - train - INFO - alphas:tensor([0.0026, 0.9974], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,928 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,928 - train - INFO - True
2024-04-03 05:55:49,929 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 05:55:49,929 - train - INFO - tau:0.536268225207185
2024-04-03 05:55:49,929 - train - INFO - avg block size:12.379310344827585
2024-04-03 05:55:51,107 - train - INFO - Test: [   0/39]  Time: 1.166 (1.166)  Loss:  0.4062 (0.4062)  Acc@1: 90.6250 (90.6250)  Acc@5: 99.2188 (99.2188)
2024-04-03 05:56:34,618 - train - INFO - Test: [  39/39]  Time: 1.051 (1.117)  Loss:  0.3728 (0.3924)  Acc@1: 87.5000 (91.8300)  Acc@5: 100.0000 (99.6900)
2024-04-03 05:56:37,064 - train - INFO - Train: 65 [   0/195 (  0%)]  Loss:  1.611660 (1.6117)  Time: 2.238s,  114.40/s  (2.238s,  114.40/s)  LR: 3.361e-04  Data: 0.180 (0.180)
2024-04-03 05:58:17,658 - train - INFO - Train: 65 [  50/195 ( 26%)]  Loss:  1.405386 (1.5629)  Time: 2.077s,  123.25/s  (2.016s,  126.97/s)  LR: 3.361e-04  Data: 0.008 (0.012)
2024-04-03 05:59:57,471 - train - INFO - Train: 65 [ 100/195 ( 52%)]  Loss:  1.681464 (1.5739)  Time: 1.715s,  149.24/s  (2.006s,  127.60/s)  LR: 3.361e-04  Data: 0.005 (0.011)
2024-04-03 06:01:35,561 - train - INFO - Train: 65 [ 150/195 ( 77%)]  Loss:  1.668486 (1.5876)  Time: 1.844s,  138.80/s  (1.992s,  128.54/s)  LR: 3.361e-04  Data: 0.014 (0.010)
2024-04-03 06:03:01,096 - train - INFO - Train: 65 [ 194/195 (100%)]  Loss:  1.532720 (1.5823)  Time: 2.133s,  120.01/s  (1.981s,  129.24/s)  LR: 3.361e-04  Data: 0.000 (0.010)
2024-04-03 06:03:01,101 - train - INFO - True
2024-04-03 06:03:01,102 - train - INFO - alphas:tensor([0.0365, 0.9635], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,103 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,103 - train - INFO - True
2024-04-03 06:03:01,103 - train - INFO - alphas:tensor([0.1307, 0.8693], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,103 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,103 - train - INFO - True
2024-04-03 06:03:01,104 - train - INFO - alphas:tensor([0.5938, 0.4062], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,104 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,104 - train - INFO - True
2024-04-03 06:03:01,105 - train - INFO - alphas:tensor([0.5326, 0.4674], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,105 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,105 - train - INFO - True
2024-04-03 06:03:01,106 - train - INFO - alphas:tensor([0.2324, 0.7676], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,110 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,110 - train - INFO - True
2024-04-03 06:03:01,111 - train - INFO - alphas:tensor([0.3520, 0.6480], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,111 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,111 - train - INFO - True
2024-04-03 06:03:01,112 - train - INFO - alphas:tensor([0.6035, 0.3965], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,112 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,112 - train - INFO - True
2024-04-03 06:03:01,113 - train - INFO - alphas:tensor([0.4973, 0.5027], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,113 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,113 - train - INFO - True
2024-04-03 06:03:01,114 - train - INFO - alphas:tensor([0.3273, 0.6727], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,114 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,114 - train - INFO - True
2024-04-03 06:03:01,114 - train - INFO - alphas:tensor([0.4709, 0.5291], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,114 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,115 - train - INFO - True
2024-04-03 06:03:01,124 - train - INFO - alphas:tensor([0.6094, 0.3906], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,124 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,124 - train - INFO - True
2024-04-03 06:03:01,125 - train - INFO - alphas:tensor([0.4781, 0.5219], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,125 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,125 - train - INFO - True
2024-04-03 06:03:01,126 - train - INFO - alphas:tensor([0.3397, 0.6603], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,126 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,126 - train - INFO - True
2024-04-03 06:03:01,126 - train - INFO - alphas:tensor([0.4566, 0.5434], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,127 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,127 - train - INFO - True
2024-04-03 06:03:01,127 - train - INFO - alphas:tensor([0.5536, 0.4464], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,127 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,127 - train - INFO - True
2024-04-03 06:03:01,128 - train - INFO - alphas:tensor([0.4032, 0.5968], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,128 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,128 - train - INFO - True
2024-04-03 06:03:01,129 - train - INFO - alphas:tensor([0.3084, 0.6916], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,129 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,129 - train - INFO - True
2024-04-03 06:03:01,130 - train - INFO - alphas:tensor([0.3674, 0.6326], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,130 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,130 - train - INFO - True
2024-04-03 06:03:01,131 - train - INFO - alphas:tensor([0.4561, 0.5439], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,131 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,131 - train - INFO - True
2024-04-03 06:03:01,131 - train - INFO - alphas:tensor([0.2761, 0.7239], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,140 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,140 - train - INFO - True
2024-04-03 06:03:01,141 - train - INFO - alphas:tensor([0.2553, 0.7447], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,141 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,141 - train - INFO - True
2024-04-03 06:03:01,142 - train - INFO - alphas:tensor([0.3041, 0.6959], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,142 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,142 - train - INFO - True
2024-04-03 06:03:01,143 - train - INFO - alphas:tensor([0.4093, 0.5907], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,143 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,143 - train - INFO - True
2024-04-03 06:03:01,144 - train - INFO - alphas:tensor([0.1999, 0.8001], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,144 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,144 - train - INFO - True
2024-04-03 06:03:01,144 - train - INFO - alphas:tensor([0.1881, 0.8119], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,145 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,145 - train - INFO - True
2024-04-03 06:03:01,145 - train - INFO - alphas:tensor([0.1164, 0.8836], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,145 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,145 - train - INFO - True
2024-04-03 06:03:01,155 - train - INFO - alphas:tensor([0.0890, 0.9110], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,155 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,155 - train - INFO - True
2024-04-03 06:03:01,156 - train - INFO - alphas:tensor([0.0023, 0.9977], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,156 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,156 - train - INFO - True
2024-04-03 06:03:01,157 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:03:01,157 - train - INFO - tau:0.5309055429551132
2024-04-03 06:03:01,157 - train - INFO - avg block size:12.89655172413793
2024-04-03 06:03:02,336 - train - INFO - Test: [   0/39]  Time: 1.176 (1.176)  Loss:  0.3965 (0.3965)  Acc@1: 92.1875 (92.1875)  Acc@5: 99.2188 (99.2188)
2024-04-03 06:03:46,167 - train - INFO - Test: [  39/39]  Time: 1.132 (1.125)  Loss:  0.4268 (0.3687)  Acc@1: 87.5000 (92.2400)  Acc@5: 100.0000 (99.7100)
2024-04-03 06:03:48,491 - train - INFO - Train: 66 [   0/195 (  0%)]  Loss:  1.700595 (1.7006)  Time: 2.079s,  123.17/s  (2.079s,  123.17/s)  LR: 3.306e-04  Data: 0.199 (0.199)
2024-04-03 06:05:26,635 - train - INFO - Train: 66 [  50/195 ( 26%)]  Loss:  1.711795 (1.6002)  Time: 2.157s,  118.70/s  (1.965s,  130.27/s)  LR: 3.306e-04  Data: 0.014 (0.013)
2024-04-03 06:07:03,925 - train - INFO - Train: 66 [ 100/195 ( 52%)]  Loss:  1.298725 (1.5818)  Time: 1.788s,  143.19/s  (1.956s,  130.91/s)  LR: 3.306e-04  Data: 0.013 (0.011)
2024-04-03 06:08:43,631 - train - INFO - Train: 66 [ 150/195 ( 77%)]  Loss:  1.714630 (1.5911)  Time: 2.005s,  127.66/s  (1.968s,  130.06/s)  LR: 3.306e-04  Data: 0.005 (0.011)
2024-04-03 06:10:11,169 - train - INFO - Train: 66 [ 194/195 (100%)]  Loss:  1.682746 (1.5783)  Time: 1.950s,  131.31/s  (1.973s,  129.75/s)  LR: 3.306e-04  Data: 0.000 (0.010)
2024-04-03 06:10:11,169 - train - INFO - True
2024-04-03 06:10:11,170 - train - INFO - alphas:tensor([0.0342, 0.9658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,171 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,171 - train - INFO - True
2024-04-03 06:10:11,171 - train - INFO - alphas:tensor([0.1289, 0.8711], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,172 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,172 - train - INFO - True
2024-04-03 06:10:11,172 - train - INFO - alphas:tensor([0.5938, 0.4062], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,172 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,172 - train - INFO - True
2024-04-03 06:10:11,173 - train - INFO - alphas:tensor([0.5320, 0.4680], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,173 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,173 - train - INFO - True
2024-04-03 06:10:11,174 - train - INFO - alphas:tensor([0.2290, 0.7710], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,174 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,174 - train - INFO - True
2024-04-03 06:10:11,175 - train - INFO - alphas:tensor([0.3492, 0.6508], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,175 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,175 - train - INFO - True
2024-04-03 06:10:11,176 - train - INFO - alphas:tensor([0.6010, 0.3990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,176 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,176 - train - INFO - True
2024-04-03 06:10:11,177 - train - INFO - alphas:tensor([0.4955, 0.5045], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,177 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,177 - train - INFO - True
2024-04-03 06:10:11,177 - train - INFO - alphas:tensor([0.3251, 0.6749], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,177 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,178 - train - INFO - True
2024-04-03 06:10:11,178 - train - INFO - alphas:tensor([0.4667, 0.5333], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,178 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,178 - train - INFO - True
2024-04-03 06:10:11,179 - train - INFO - alphas:tensor([0.6077, 0.3923], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,179 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,179 - train - INFO - True
2024-04-03 06:10:11,180 - train - INFO - alphas:tensor([0.4767, 0.5233], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,180 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,180 - train - INFO - True
2024-04-03 06:10:11,181 - train - INFO - alphas:tensor([0.3401, 0.6599], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,181 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,181 - train - INFO - True
2024-04-03 06:10:11,181 - train - INFO - alphas:tensor([0.4564, 0.5436], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,182 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,182 - train - INFO - True
2024-04-03 06:10:11,182 - train - INFO - alphas:tensor([0.5526, 0.4474], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,182 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,182 - train - INFO - True
2024-04-03 06:10:11,183 - train - INFO - alphas:tensor([0.4024, 0.5976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,183 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,183 - train - INFO - True
2024-04-03 06:10:11,184 - train - INFO - alphas:tensor([0.3070, 0.6930], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,184 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,184 - train - INFO - True
2024-04-03 06:10:11,185 - train - INFO - alphas:tensor([0.3644, 0.6356], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,185 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,185 - train - INFO - True
2024-04-03 06:10:11,186 - train - INFO - alphas:tensor([0.4505, 0.5495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,186 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,186 - train - INFO - True
2024-04-03 06:10:11,187 - train - INFO - alphas:tensor([0.2717, 0.7283], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,187 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,187 - train - INFO - True
2024-04-03 06:10:11,188 - train - INFO - alphas:tensor([0.2523, 0.7477], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,188 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,188 - train - INFO - True
2024-04-03 06:10:11,189 - train - INFO - alphas:tensor([0.3014, 0.6986], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,193 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,193 - train - INFO - True
2024-04-03 06:10:11,194 - train - INFO - alphas:tensor([0.4065, 0.5935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,194 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,194 - train - INFO - True
2024-04-03 06:10:11,199 - train - INFO - alphas:tensor([0.1980, 0.8020], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,199 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,199 - train - INFO - True
2024-04-03 06:10:11,200 - train - INFO - alphas:tensor([0.1850, 0.8150], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,200 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,200 - train - INFO - True
2024-04-03 06:10:11,201 - train - INFO - alphas:tensor([0.1112, 0.8888], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,201 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,201 - train - INFO - True
2024-04-03 06:10:11,202 - train - INFO - alphas:tensor([0.0863, 0.9137], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,202 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,202 - train - INFO - True
2024-04-03 06:10:11,203 - train - INFO - alphas:tensor([0.0020, 0.9980], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,203 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,203 - train - INFO - True
2024-04-03 06:10:11,203 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:10:11,203 - train - INFO - tau:0.525596487525562
2024-04-03 06:10:11,204 - train - INFO - avg block size:12.89655172413793
2024-04-03 06:10:12,359 - train - INFO - Test: [   0/39]  Time: 1.152 (1.152)  Loss:  0.3887 (0.3887)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.2188 (99.2188)
2024-04-03 06:10:56,049 - train - INFO - Test: [  39/39]  Time: 1.119 (1.121)  Loss:  0.4463 (0.3840)  Acc@1: 87.5000 (92.0800)  Acc@5: 100.0000 (99.6800)
2024-04-03 06:10:58,549 - train - INFO - Train: 67 [   0/195 (  0%)]  Loss:  1.694679 (1.6947)  Time: 2.388s,  107.20/s  (2.388s,  107.20/s)  LR: 3.250e-04  Data: 0.221 (0.221)
2024-04-03 06:12:37,120 - train - INFO - Train: 67 [  50/195 ( 26%)]  Loss:  1.488969 (1.5971)  Time: 1.944s,  131.69/s  (1.980s,  129.32/s)  LR: 3.250e-04  Data: 0.013 (0.014)
2024-04-03 06:14:15,513 - train - INFO - Train: 67 [ 100/195 ( 52%)]  Loss:  1.783960 (1.5964)  Time: 1.974s,  129.69/s  (1.974s,  129.70/s)  LR: 3.250e-04  Data: 0.012 (0.011)
2024-04-03 06:15:53,665 - train - INFO - Train: 67 [ 150/195 ( 77%)]  Loss:  1.770966 (1.5869)  Time: 1.857s,  137.87/s  (1.970s,  129.94/s)  LR: 3.250e-04  Data: 0.005 (0.011)
2024-04-03 06:17:21,038 - train - INFO - Train: 67 [ 194/195 (100%)]  Loss:  1.708583 (1.5867)  Time: 1.782s,  143.67/s  (1.974s,  129.70/s)  LR: 3.250e-04  Data: 0.000 (0.011)
2024-04-03 06:17:21,039 - train - INFO - True
2024-04-03 06:17:21,041 - train - INFO - alphas:tensor([0.0319, 0.9681], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,041 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,041 - train - INFO - True
2024-04-03 06:17:21,046 - train - INFO - alphas:tensor([0.1268, 0.8732], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,047 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,047 - train - INFO - True
2024-04-03 06:17:21,047 - train - INFO - alphas:tensor([0.5915, 0.4085], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,048 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,048 - train - INFO - True
2024-04-03 06:17:21,048 - train - INFO - alphas:tensor([0.5290, 0.4710], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,048 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,048 - train - INFO - True
2024-04-03 06:17:21,049 - train - INFO - alphas:tensor([0.2256, 0.7744], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,049 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,049 - train - INFO - True
2024-04-03 06:17:21,050 - train - INFO - alphas:tensor([0.3461, 0.6539], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,050 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,050 - train - INFO - True
2024-04-03 06:17:21,051 - train - INFO - alphas:tensor([0.6004, 0.3996], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,051 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,051 - train - INFO - True
2024-04-03 06:17:21,052 - train - INFO - alphas:tensor([0.4938, 0.5062], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,052 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,052 - train - INFO - True
2024-04-03 06:17:21,053 - train - INFO - alphas:tensor([0.3219, 0.6781], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,057 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,057 - train - INFO - True
2024-04-03 06:17:21,058 - train - INFO - alphas:tensor([0.4657, 0.5343], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,058 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,058 - train - INFO - True
2024-04-03 06:17:21,059 - train - INFO - alphas:tensor([0.6075, 0.3925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,059 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,059 - train - INFO - True
2024-04-03 06:17:21,060 - train - INFO - alphas:tensor([0.4786, 0.5214], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,060 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,060 - train - INFO - True
2024-04-03 06:17:21,060 - train - INFO - alphas:tensor([0.3351, 0.6649], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,061 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,061 - train - INFO - True
2024-04-03 06:17:21,061 - train - INFO - alphas:tensor([0.4517, 0.5483], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,061 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,061 - train - INFO - True
2024-04-03 06:17:21,062 - train - INFO - alphas:tensor([0.5503, 0.4497], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,062 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,062 - train - INFO - True
2024-04-03 06:17:21,063 - train - INFO - alphas:tensor([0.4014, 0.5986], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,063 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,063 - train - INFO - True
2024-04-03 06:17:21,064 - train - INFO - alphas:tensor([0.3034, 0.6966], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,064 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,064 - train - INFO - True
2024-04-03 06:17:21,065 - train - INFO - alphas:tensor([0.3629, 0.6371], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,065 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,065 - train - INFO - True
2024-04-03 06:17:21,065 - train - INFO - alphas:tensor([0.4503, 0.5497], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,065 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,066 - train - INFO - True
2024-04-03 06:17:21,066 - train - INFO - alphas:tensor([0.2727, 0.7273], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,066 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,066 - train - INFO - True
2024-04-03 06:17:21,067 - train - INFO - alphas:tensor([0.2497, 0.7503], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,067 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,067 - train - INFO - True
2024-04-03 06:17:21,072 - train - INFO - alphas:tensor([0.2964, 0.7036], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,072 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,072 - train - INFO - True
2024-04-03 06:17:21,073 - train - INFO - alphas:tensor([0.4060, 0.5940], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,073 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,073 - train - INFO - True
2024-04-03 06:17:21,074 - train - INFO - alphas:tensor([0.1973, 0.8027], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,074 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,074 - train - INFO - True
2024-04-03 06:17:21,075 - train - INFO - alphas:tensor([0.1815, 0.8185], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,075 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,075 - train - INFO - True
2024-04-03 06:17:21,075 - train - INFO - alphas:tensor([0.1072, 0.8928], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,076 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,076 - train - INFO - True
2024-04-03 06:17:21,076 - train - INFO - alphas:tensor([0.0835, 0.9165], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,076 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,076 - train - INFO - True
2024-04-03 06:17:21,077 - train - INFO - alphas:tensor([0.0018, 0.9982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,077 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,077 - train - INFO - True
2024-04-03 06:17:21,078 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:17:21,078 - train - INFO - tau:0.5203405226503064
2024-04-03 06:17:21,078 - train - INFO - avg block size:12.89655172413793
2024-04-03 06:17:22,173 - train - INFO - Test: [   0/39]  Time: 1.091 (1.091)  Loss:  0.3760 (0.3760)  Acc@1: 91.0156 (91.0156)  Acc@5: 100.0000 (100.0000)
2024-04-03 06:18:05,560 - train - INFO - Test: [  39/39]  Time: 1.135 (1.112)  Loss:  0.4846 (0.3773)  Acc@1: 87.5000 (91.6700)  Acc@5: 100.0000 (99.7200)
2024-04-03 06:18:07,754 - train - INFO - Train: 68 [   0/195 (  0%)]  Loss:  1.423209 (1.4232)  Time: 2.079s,  123.12/s  (2.079s,  123.12/s)  LR: 3.194e-04  Data: 0.234 (0.234)
2024-04-03 06:19:49,164 - train - INFO - Train: 68 [  50/195 ( 26%)]  Loss:  1.475208 (1.5910)  Time: 2.226s,  115.01/s  (2.029s,  126.16/s)  LR: 3.194e-04  Data: 0.006 (0.014)
2024-04-03 06:21:27,221 - train - INFO - Train: 68 [ 100/195 ( 52%)]  Loss:  1.454707 (1.5939)  Time: 2.191s,  116.83/s  (1.995s,  128.29/s)  LR: 3.194e-04  Data: 0.007 (0.011)
2024-04-03 06:23:07,447 - train - INFO - Train: 68 [ 150/195 ( 77%)]  Loss:  1.308365 (1.5621)  Time: 1.761s,  145.36/s  (1.998s,  128.10/s)  LR: 3.194e-04  Data: 0.005 (0.011)
2024-04-03 06:24:32,703 - train - INFO - Train: 68 [ 194/195 (100%)]  Loss:  1.680688 (1.5625)  Time: 1.894s,  135.18/s  (1.985s,  128.99/s)  LR: 3.194e-04  Data: 0.000 (0.010)
2024-04-03 06:24:32,703 - train - INFO - True
2024-04-03 06:24:32,704 - train - INFO - alphas:tensor([0.0301, 0.9699], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,704 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,705 - train - INFO - True
2024-04-03 06:24:32,705 - train - INFO - alphas:tensor([0.1256, 0.8744], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,705 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,705 - train - INFO - True
2024-04-03 06:24:32,706 - train - INFO - alphas:tensor([0.5916, 0.4084], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,706 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,706 - train - INFO - True
2024-04-03 06:24:32,707 - train - INFO - alphas:tensor([0.5284, 0.4716], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,707 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,707 - train - INFO - True
2024-04-03 06:24:32,708 - train - INFO - alphas:tensor([0.2227, 0.7773], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,708 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,708 - train - INFO - True
2024-04-03 06:24:32,709 - train - INFO - alphas:tensor([0.3434, 0.6566], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,709 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,709 - train - INFO - True
2024-04-03 06:24:32,710 - train - INFO - alphas:tensor([0.5993, 0.4007], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,710 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,710 - train - INFO - True
2024-04-03 06:24:32,711 - train - INFO - alphas:tensor([0.4927, 0.5073], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,711 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,711 - train - INFO - True
2024-04-03 06:24:32,711 - train - INFO - alphas:tensor([0.3205, 0.6795], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,712 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,712 - train - INFO - True
2024-04-03 06:24:32,713 - train - INFO - alphas:tensor([0.4640, 0.5360], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,713 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,713 - train - INFO - True
2024-04-03 06:24:32,714 - train - INFO - alphas:tensor([0.6046, 0.3954], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,714 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,714 - train - INFO - True
2024-04-03 06:24:32,714 - train - INFO - alphas:tensor([0.4746, 0.5254], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,714 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,715 - train - INFO - True
2024-04-03 06:24:32,715 - train - INFO - alphas:tensor([0.3356, 0.6644], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,715 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,715 - train - INFO - True
2024-04-03 06:24:32,716 - train - INFO - alphas:tensor([0.4517, 0.5483], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,716 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,716 - train - INFO - True
2024-04-03 06:24:32,717 - train - INFO - alphas:tensor([0.5489, 0.4511], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,717 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,717 - train - INFO - True
2024-04-03 06:24:32,718 - train - INFO - alphas:tensor([0.4004, 0.5996], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,718 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,718 - train - INFO - True
2024-04-03 06:24:32,718 - train - INFO - alphas:tensor([0.3036, 0.6964], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,719 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,719 - train - INFO - True
2024-04-03 06:24:32,719 - train - INFO - alphas:tensor([0.3641, 0.6359], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,719 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,719 - train - INFO - True
2024-04-03 06:24:32,720 - train - INFO - alphas:tensor([0.4485, 0.5515], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,720 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,720 - train - INFO - True
2024-04-03 06:24:32,721 - train - INFO - alphas:tensor([0.2706, 0.7294], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,721 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,721 - train - INFO - True
2024-04-03 06:24:32,722 - train - INFO - alphas:tensor([0.2485, 0.7515], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,722 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,722 - train - INFO - True
2024-04-03 06:24:32,723 - train - INFO - alphas:tensor([0.2963, 0.7037], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,723 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,723 - train - INFO - True
2024-04-03 06:24:32,723 - train - INFO - alphas:tensor([0.4033, 0.5967], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,723 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,724 - train - INFO - True
2024-04-03 06:24:32,724 - train - INFO - alphas:tensor([0.1957, 0.8043], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,724 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,724 - train - INFO - True
2024-04-03 06:24:32,725 - train - INFO - alphas:tensor([0.1799, 0.8201], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,725 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,725 - train - INFO - True
2024-04-03 06:24:32,726 - train - INFO - alphas:tensor([0.1044, 0.8956], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,726 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,726 - train - INFO - True
2024-04-03 06:24:32,727 - train - INFO - alphas:tensor([0.0820, 0.9180], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,727 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,727 - train - INFO - True
2024-04-03 06:24:32,728 - train - INFO - alphas:tensor([0.0016, 0.9984], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,728 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,728 - train - INFO - True
2024-04-03 06:24:32,728 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:24:32,728 - train - INFO - tau:0.5151371174238033
2024-04-03 06:24:32,728 - train - INFO - avg block size:12.89655172413793
2024-04-03 06:24:33,883 - train - INFO - Test: [   0/39]  Time: 1.153 (1.153)  Loss:  0.3755 (0.3755)  Acc@1: 91.4062 (91.4062)  Acc@5: 99.2188 (99.2188)
2024-04-03 06:25:18,094 - train - INFO - Test: [  39/39]  Time: 1.144 (1.134)  Loss:  0.4397 (0.3640)  Acc@1: 87.5000 (91.8200)  Acc@5: 100.0000 (99.7200)
2024-04-03 06:25:20,408 - train - INFO - Train: 69 [   0/195 (  0%)]  Loss:  1.782166 (1.7822)  Time: 2.114s,  121.12/s  (2.114s,  121.12/s)  LR: 3.138e-04  Data: 0.142 (0.142)
2024-04-03 06:27:00,025 - train - INFO - Train: 69 [  50/195 ( 26%)]  Loss:  1.565236 (1.5609)  Time: 1.956s,  130.91/s  (1.995s,  128.34/s)  LR: 3.138e-04  Data: 0.005 (0.012)
2024-04-03 06:28:38,671 - train - INFO - Train: 69 [ 100/195 ( 52%)]  Loss:  1.831424 (1.5916)  Time: 2.000s,  128.01/s  (1.984s,  129.04/s)  LR: 3.138e-04  Data: 0.005 (0.010)
2024-04-03 06:30:18,233 - train - INFO - Train: 69 [ 150/195 ( 77%)]  Loss:  1.785672 (1.5913)  Time: 2.180s,  117.44/s  (1.986s,  128.88/s)  LR: 3.138e-04  Data: 0.005 (0.010)
2024-04-03 06:31:44,416 - train - INFO - Train: 69 [ 194/195 (100%)]  Loss:  1.704926 (1.5864)  Time: 1.701s,  150.51/s  (1.980s,  129.29/s)  LR: 3.138e-04  Data: 0.000 (0.010)
2024-04-03 06:31:44,416 - train - INFO - True
2024-04-03 06:31:44,418 - train - INFO - alphas:tensor([0.0279, 0.9721], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,418 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,418 - train - INFO - True
2024-04-03 06:31:44,419 - train - INFO - alphas:tensor([0.1228, 0.8772], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,419 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,419 - train - INFO - True
2024-04-03 06:31:44,420 - train - INFO - alphas:tensor([0.5900, 0.4100], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,420 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,420 - train - INFO - True
2024-04-03 06:31:44,420 - train - INFO - alphas:tensor([0.5267, 0.4733], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,420 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,421 - train - INFO - True
2024-04-03 06:31:44,421 - train - INFO - alphas:tensor([0.2207, 0.7793], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,421 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,421 - train - INFO - True
2024-04-03 06:31:44,422 - train - INFO - alphas:tensor([0.3381, 0.6619], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,422 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,422 - train - INFO - True
2024-04-03 06:31:44,423 - train - INFO - alphas:tensor([0.5973, 0.4027], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,423 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,423 - train - INFO - True
2024-04-03 06:31:44,424 - train - INFO - alphas:tensor([0.4923, 0.5077], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,424 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,424 - train - INFO - True
2024-04-03 06:31:44,424 - train - INFO - alphas:tensor([0.3178, 0.6822], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,425 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,425 - train - INFO - True
2024-04-03 06:31:44,426 - train - INFO - alphas:tensor([0.4620, 0.5380], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,426 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,426 - train - INFO - True
2024-04-03 06:31:44,426 - train - INFO - alphas:tensor([0.6022, 0.3978], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,426 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,427 - train - INFO - True
2024-04-03 06:31:44,427 - train - INFO - alphas:tensor([0.4705, 0.5295], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,427 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,427 - train - INFO - True
2024-04-03 06:31:44,428 - train - INFO - alphas:tensor([0.3336, 0.6664], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,428 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,428 - train - INFO - True
2024-04-03 06:31:44,429 - train - INFO - alphas:tensor([0.4506, 0.5494], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,429 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,429 - train - INFO - True
2024-04-03 06:31:44,430 - train - INFO - alphas:tensor([0.5479, 0.4521], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,430 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,430 - train - INFO - True
2024-04-03 06:31:44,430 - train - INFO - alphas:tensor([0.3987, 0.6013], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,430 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,431 - train - INFO - True
2024-04-03 06:31:44,431 - train - INFO - alphas:tensor([0.3010, 0.6990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,431 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,431 - train - INFO - True
2024-04-03 06:31:44,432 - train - INFO - alphas:tensor([0.3627, 0.6373], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,432 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,432 - train - INFO - True
2024-04-03 06:31:44,433 - train - INFO - alphas:tensor([0.4461, 0.5539], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,433 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,433 - train - INFO - True
2024-04-03 06:31:44,434 - train - INFO - alphas:tensor([0.2681, 0.7319], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,434 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,434 - train - INFO - True
2024-04-03 06:31:44,434 - train - INFO - alphas:tensor([0.2448, 0.7552], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,435 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,435 - train - INFO - True
2024-04-03 06:31:44,435 - train - INFO - alphas:tensor([0.2947, 0.7053], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,435 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,435 - train - INFO - True
2024-04-03 06:31:44,436 - train - INFO - alphas:tensor([0.4007, 0.5993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,436 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,436 - train - INFO - True
2024-04-03 06:31:44,437 - train - INFO - alphas:tensor([0.1922, 0.8078], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,437 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,437 - train - INFO - True
2024-04-03 06:31:44,438 - train - INFO - alphas:tensor([0.1778, 0.8222], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,438 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,438 - train - INFO - True
2024-04-03 06:31:44,438 - train - INFO - alphas:tensor([0.0997, 0.9003], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,439 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,439 - train - INFO - True
2024-04-03 06:31:44,439 - train - INFO - alphas:tensor([0.0796, 0.9204], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,439 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,439 - train - INFO - True
2024-04-03 06:31:44,440 - train - INFO - alphas:tensor([0.0014, 0.9986], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,440 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,440 - train - INFO - True
2024-04-03 06:31:44,441 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:31:44,441 - train - INFO - tau:0.5099857462495653
2024-04-03 06:31:44,441 - train - INFO - avg block size:12.89655172413793
2024-04-03 06:31:45,624 - train - INFO - Test: [   0/39]  Time: 1.181 (1.181)  Loss:  0.3762 (0.3762)  Acc@1: 92.5781 (92.5781)  Acc@5: 99.2188 (99.2188)
2024-04-03 06:32:28,974 - train - INFO - Test: [  39/39]  Time: 1.132 (1.113)  Loss:  0.3767 (0.3823)  Acc@1: 87.5000 (91.9500)  Acc@5: 100.0000 (99.6800)
2024-04-03 06:32:31,249 - train - INFO - Train: 70 [   0/195 (  0%)]  Loss:  1.446179 (1.4462)  Time: 2.055s,  124.58/s  (2.055s,  124.58/s)  LR: 3.082e-04  Data: 0.167 (0.167)
2024-04-03 06:34:11,489 - train - INFO - Train: 70 [  50/195 ( 26%)]  Loss:  1.778352 (1.5673)  Time: 1.970s,  129.93/s  (2.006s,  127.63/s)  LR: 3.082e-04  Data: 0.006 (0.011)
2024-04-03 06:35:50,078 - train - INFO - Train: 70 [ 100/195 ( 52%)]  Loss:  1.259550 (1.5432)  Time: 2.038s,  125.62/s  (1.989s,  128.71/s)  LR: 3.082e-04  Data: 0.018 (0.010)
2024-04-03 06:37:27,294 - train - INFO - Train: 70 [ 150/195 ( 77%)]  Loss:  1.451667 (1.5417)  Time: 2.021s,  126.67/s  (1.974s,  129.68/s)  LR: 3.082e-04  Data: 0.010 (0.010)
2024-04-03 06:38:56,408 - train - INFO - Train: 70 [ 194/195 (100%)]  Loss:  1.690367 (1.5483)  Time: 1.796s,  142.54/s  (1.986s,  128.92/s)  LR: 3.082e-04  Data: 0.000 (0.010)
2024-04-03 06:38:56,408 - train - INFO - True
2024-04-03 06:38:56,410 - train - INFO - alphas:tensor([0.0261, 0.9739], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,410 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,410 - train - INFO - True
2024-04-03 06:38:56,411 - train - INFO - alphas:tensor([0.1221, 0.8779], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,411 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,411 - train - INFO - True
2024-04-03 06:38:56,411 - train - INFO - alphas:tensor([0.5904, 0.4096], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,411 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,412 - train - INFO - True
2024-04-03 06:38:56,412 - train - INFO - alphas:tensor([0.5271, 0.4729], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,412 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,412 - train - INFO - True
2024-04-03 06:38:56,413 - train - INFO - alphas:tensor([0.2177, 0.7823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,413 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,413 - train - INFO - True
2024-04-03 06:38:56,414 - train - INFO - alphas:tensor([0.3360, 0.6640], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,414 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,414 - train - INFO - True
2024-04-03 06:38:56,415 - train - INFO - alphas:tensor([0.5976, 0.4024], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,415 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,416 - train - INFO - True
2024-04-03 06:38:56,416 - train - INFO - alphas:tensor([0.4920, 0.5080], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,416 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,417 - train - INFO - True
2024-04-03 06:38:56,417 - train - INFO - alphas:tensor([0.3162, 0.6838], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,417 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,417 - train - INFO - True
2024-04-03 06:38:56,418 - train - INFO - alphas:tensor([0.4627, 0.5373], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,418 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,418 - train - INFO - True
2024-04-03 06:38:56,419 - train - INFO - alphas:tensor([0.6005, 0.3995], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,419 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,419 - train - INFO - True
2024-04-03 06:38:56,420 - train - INFO - alphas:tensor([0.4698, 0.5302], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,420 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,420 - train - INFO - True
2024-04-03 06:38:56,420 - train - INFO - alphas:tensor([0.3297, 0.6703], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,421 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,421 - train - INFO - True
2024-04-03 06:38:56,421 - train - INFO - alphas:tensor([0.4507, 0.5493], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,421 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,421 - train - INFO - True
2024-04-03 06:38:56,422 - train - INFO - alphas:tensor([0.5457, 0.4543], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,422 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,422 - train - INFO - True
2024-04-03 06:38:56,423 - train - INFO - alphas:tensor([0.3959, 0.6041], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,423 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,423 - train - INFO - True
2024-04-03 06:38:56,424 - train - INFO - alphas:tensor([0.2984, 0.7016], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,424 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,424 - train - INFO - True
2024-04-03 06:38:56,425 - train - INFO - alphas:tensor([0.3603, 0.6397], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,425 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,425 - train - INFO - True
2024-04-03 06:38:56,425 - train - INFO - alphas:tensor([0.4427, 0.5573], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,425 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,425 - train - INFO - True
2024-04-03 06:38:56,426 - train - INFO - alphas:tensor([0.2657, 0.7344], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,426 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,426 - train - INFO - True
2024-04-03 06:38:56,427 - train - INFO - alphas:tensor([0.2430, 0.7570], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,427 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,427 - train - INFO - True
2024-04-03 06:38:56,428 - train - INFO - alphas:tensor([0.2931, 0.7069], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,428 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,428 - train - INFO - True
2024-04-03 06:38:56,429 - train - INFO - alphas:tensor([0.3985, 0.6015], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,429 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,429 - train - INFO - True
2024-04-03 06:38:56,429 - train - INFO - alphas:tensor([0.1896, 0.8104], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,430 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,430 - train - INFO - True
2024-04-03 06:38:56,430 - train - INFO - alphas:tensor([0.1754, 0.8246], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,430 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,430 - train - INFO - True
2024-04-03 06:38:56,431 - train - INFO - alphas:tensor([0.0953, 0.9047], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,431 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,431 - train - INFO - True
2024-04-03 06:38:56,432 - train - INFO - alphas:tensor([0.0782, 0.9218], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,432 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,432 - train - INFO - True
2024-04-03 06:38:56,433 - train - INFO - alphas:tensor([0.0012, 0.9988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,433 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,433 - train - INFO - True
2024-04-03 06:38:56,433 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:38:56,434 - train - INFO - tau:0.5048858887870696
2024-04-03 06:38:56,434 - train - INFO - avg block size:12.89655172413793
2024-04-03 06:38:57,572 - train - INFO - Test: [   0/39]  Time: 1.136 (1.136)  Loss:  0.3840 (0.3840)  Acc@1: 92.1875 (92.1875)  Acc@5: 99.6094 (99.6094)
2024-04-03 06:39:41,138 - train - INFO - Test: [  39/39]  Time: 1.130 (1.118)  Loss:  0.5581 (0.3797)  Acc@1: 81.2500 (91.9100)  Acc@5: 100.0000 (99.7400)
2024-04-03 06:39:43,707 - train - INFO - Train: 71 [   0/195 (  0%)]  Loss:  1.522383 (1.5224)  Time: 2.452s,  104.42/s  (2.452s,  104.42/s)  LR: 3.026e-04  Data: 0.318 (0.318)
2024-04-03 06:41:24,310 - train - INFO - Train: 71 [  50/195 ( 26%)]  Loss:  1.351071 (1.5746)  Time: 2.092s,  122.40/s  (2.021s,  126.69/s)  LR: 3.026e-04  Data: 0.006 (0.015)
2024-04-03 06:43:01,903 - train - INFO - Train: 71 [ 100/195 ( 52%)]  Loss:  1.804782 (1.5964)  Time: 1.780s,  143.85/s  (1.987s,  128.87/s)  LR: 3.026e-04  Data: 0.005 (0.012)
2024-04-03 06:44:41,162 - train - INFO - Train: 71 [ 150/195 ( 77%)]  Loss:  1.758209 (1.5919)  Time: 2.092s,  122.40/s  (1.986s,  128.90/s)  LR: 3.026e-04  Data: 0.009 (0.011)
2024-04-03 06:46:12,150 - train - INFO - Train: 71 [ 194/195 (100%)]  Loss:  1.543024 (1.5873)  Time: 1.999s,  128.05/s  (2.005s,  127.71/s)  LR: 3.026e-04  Data: 0.000 (0.010)
2024-04-03 06:46:12,151 - train - INFO - True
2024-04-03 06:46:12,152 - train - INFO - alphas:tensor([0.0242, 0.9758], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,152 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,152 - train - INFO - True
2024-04-03 06:46:12,153 - train - INFO - alphas:tensor([0.1200, 0.8800], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,153 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,153 - train - INFO - True
2024-04-03 06:46:12,153 - train - INFO - alphas:tensor([0.5902, 0.4098], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,154 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,154 - train - INFO - True
2024-04-03 06:46:12,154 - train - INFO - alphas:tensor([0.5252, 0.4748], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,154 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,154 - train - INFO - True
2024-04-03 06:46:12,155 - train - INFO - alphas:tensor([0.2161, 0.7839], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,155 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,155 - train - INFO - True
2024-04-03 06:46:12,156 - train - INFO - alphas:tensor([0.3351, 0.6649], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,156 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,156 - train - INFO - True
2024-04-03 06:46:12,157 - train - INFO - alphas:tensor([0.5943, 0.4057], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,157 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,157 - train - INFO - True
2024-04-03 06:46:12,157 - train - INFO - alphas:tensor([0.4872, 0.5128], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,158 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,158 - train - INFO - True
2024-04-03 06:46:12,158 - train - INFO - alphas:tensor([0.3133, 0.6867], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,159 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,159 - train - INFO - True
2024-04-03 06:46:12,159 - train - INFO - alphas:tensor([0.4600, 0.5400], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,160 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,160 - train - INFO - True
2024-04-03 06:46:12,160 - train - INFO - alphas:tensor([0.6002, 0.3998], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,160 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,160 - train - INFO - True
2024-04-03 06:46:12,161 - train - INFO - alphas:tensor([0.4687, 0.5313], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,161 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,161 - train - INFO - True
2024-04-03 06:46:12,162 - train - INFO - alphas:tensor([0.3277, 0.6723], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,162 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,162 - train - INFO - True
2024-04-03 06:46:12,163 - train - INFO - alphas:tensor([0.4478, 0.5522], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,163 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,163 - train - INFO - True
2024-04-03 06:46:12,164 - train - INFO - alphas:tensor([0.5428, 0.4572], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,164 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,164 - train - INFO - True
2024-04-03 06:46:12,165 - train - INFO - alphas:tensor([0.3925, 0.6075], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,165 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,165 - train - INFO - True
2024-04-03 06:46:12,166 - train - INFO - alphas:tensor([0.2974, 0.7026], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,166 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,166 - train - INFO - True
2024-04-03 06:46:12,166 - train - INFO - alphas:tensor([0.3596, 0.6404], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,166 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,166 - train - INFO - True
2024-04-03 06:46:12,167 - train - INFO - alphas:tensor([0.4420, 0.5580], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,167 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,167 - train - INFO - True
2024-04-03 06:46:12,168 - train - INFO - alphas:tensor([0.2680, 0.7320], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,168 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,168 - train - INFO - True
2024-04-03 06:46:12,169 - train - INFO - alphas:tensor([0.2413, 0.7587], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,169 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,169 - train - INFO - True
2024-04-03 06:46:12,170 - train - INFO - alphas:tensor([0.2916, 0.7084], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,170 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,170 - train - INFO - True
2024-04-03 06:46:12,170 - train - INFO - alphas:tensor([0.3987, 0.6013], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,170 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,171 - train - INFO - True
2024-04-03 06:46:12,171 - train - INFO - alphas:tensor([0.1888, 0.8112], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,171 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,171 - train - INFO - True
2024-04-03 06:46:12,172 - train - INFO - alphas:tensor([0.1725, 0.8275], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,172 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,172 - train - INFO - True
2024-04-03 06:46:12,173 - train - INFO - alphas:tensor([0.0912, 0.9088], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,173 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,173 - train - INFO - True
2024-04-03 06:46:12,174 - train - INFO - alphas:tensor([0.0750, 0.9250], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,174 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,174 - train - INFO - True
2024-04-03 06:46:12,174 - train - INFO - alphas:tensor([0.0011, 0.9989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,174 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,175 - train - INFO - True
2024-04-03 06:46:12,175 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:46:12,175 - train - INFO - tau:0.4998370298991989
2024-04-03 06:46:12,175 - train - INFO - avg block size:12.89655172413793
2024-04-03 06:46:13,323 - train - INFO - Test: [   0/39]  Time: 1.145 (1.145)  Loss:  0.3945 (0.3945)  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)
2024-04-03 06:46:57,223 - train - INFO - Test: [  39/39]  Time: 1.125 (1.126)  Loss:  0.3857 (0.3914)  Acc@1: 87.5000 (91.9800)  Acc@5: 100.0000 (99.6900)
2024-04-03 06:46:59,547 - train - INFO - Train: 72 [   0/195 (  0%)]  Loss:  1.587427 (1.5874)  Time: 2.158s,  118.64/s  (2.158s,  118.64/s)  LR: 2.970e-04  Data: 0.167 (0.167)
2024-04-03 06:48:36,564 - train - INFO - Train: 72 [  50/195 ( 26%)]  Loss:  1.743294 (1.5837)  Time: 1.930s,  132.65/s  (1.945s,  131.65/s)  LR: 2.970e-04  Data: 0.018 (0.012)
2024-04-03 06:50:15,973 - train - INFO - Train: 72 [ 100/195 ( 52%)]  Loss:  1.670840 (1.6060)  Time: 2.000s,  128.02/s  (1.966s,  130.21/s)  LR: 2.970e-04  Data: 0.018 (0.011)
2024-04-03 06:51:56,045 - train - INFO - Train: 72 [ 150/195 ( 77%)]  Loss:  1.460307 (1.5839)  Time: 2.238s,  114.38/s  (1.978s,  129.44/s)  LR: 2.970e-04  Data: 0.005 (0.010)
2024-04-03 06:53:24,279 - train - INFO - Train: 72 [ 194/195 (100%)]  Loss:  1.195835 (1.5848)  Time: 1.974s,  129.65/s  (1.984s,  129.03/s)  LR: 2.970e-04  Data: 0.000 (0.010)
2024-04-03 06:53:24,279 - train - INFO - True
2024-04-03 06:53:24,281 - train - INFO - alphas:tensor([0.0226, 0.9774], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,281 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,281 - train - INFO - True
2024-04-03 06:53:24,281 - train - INFO - alphas:tensor([0.1186, 0.8814], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,282 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,282 - train - INFO - True
2024-04-03 06:53:24,282 - train - INFO - alphas:tensor([0.5869, 0.4131], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,282 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,282 - train - INFO - True
2024-04-03 06:53:24,283 - train - INFO - alphas:tensor([0.5220, 0.4780], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,283 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,283 - train - INFO - True
2024-04-03 06:53:24,284 - train - INFO - alphas:tensor([0.2140, 0.7860], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,284 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,284 - train - INFO - True
2024-04-03 06:53:24,285 - train - INFO - alphas:tensor([0.3305, 0.6695], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,285 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,285 - train - INFO - True
2024-04-03 06:53:24,286 - train - INFO - alphas:tensor([0.5928, 0.4072], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,286 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,286 - train - INFO - True
2024-04-03 06:53:24,287 - train - INFO - alphas:tensor([0.4855, 0.5145], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,287 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,287 - train - INFO - True
2024-04-03 06:53:24,288 - train - INFO - alphas:tensor([0.3125, 0.6875], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,288 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,288 - train - INFO - True
2024-04-03 06:53:24,289 - train - INFO - alphas:tensor([0.4567, 0.5433], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,289 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,289 - train - INFO - True
2024-04-03 06:53:24,294 - train - INFO - alphas:tensor([0.5979, 0.4021], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,294 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,294 - train - INFO - True
2024-04-03 06:53:24,295 - train - INFO - alphas:tensor([0.4671, 0.5329], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,303 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,303 - train - INFO - True
2024-04-03 06:53:24,303 - train - INFO - alphas:tensor([0.3251, 0.6749], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,303 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,304 - train - INFO - True
2024-04-03 06:53:24,304 - train - INFO - alphas:tensor([0.4457, 0.5543], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,307 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,307 - train - INFO - True
2024-04-03 06:53:24,308 - train - INFO - alphas:tensor([0.5420, 0.4580], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,308 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,308 - train - INFO - True
2024-04-03 06:53:24,309 - train - INFO - alphas:tensor([0.3948, 0.6052], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,309 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,309 - train - INFO - True
2024-04-03 06:53:24,310 - train - INFO - alphas:tensor([0.2937, 0.7063], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,310 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,310 - train - INFO - True
2024-04-03 06:53:24,311 - train - INFO - alphas:tensor([0.3558, 0.6442], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,311 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,311 - train - INFO - True
2024-04-03 06:53:24,321 - train - INFO - alphas:tensor([0.4404, 0.5596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,321 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,321 - train - INFO - True
2024-04-03 06:53:24,322 - train - INFO - alphas:tensor([0.2656, 0.7344], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,322 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,322 - train - INFO - True
2024-04-03 06:53:24,323 - train - INFO - alphas:tensor([0.2404, 0.7596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,323 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,323 - train - INFO - True
2024-04-03 06:53:24,323 - train - INFO - alphas:tensor([0.2892, 0.7108], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,323 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,324 - train - INFO - True
2024-04-03 06:53:24,324 - train - INFO - alphas:tensor([0.3963, 0.6037], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,341 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,341 - train - INFO - True
2024-04-03 06:53:24,342 - train - INFO - alphas:tensor([0.1870, 0.8130], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,342 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,342 - train - INFO - True
2024-04-03 06:53:24,343 - train - INFO - alphas:tensor([0.1724, 0.8276], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,343 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,343 - train - INFO - True
2024-04-03 06:53:24,344 - train - INFO - alphas:tensor([0.0878, 0.9122], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,344 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,344 - train - INFO - True
2024-04-03 06:53:24,345 - train - INFO - alphas:tensor([0.0728, 0.9272], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,345 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,345 - train - INFO - True
2024-04-03 06:53:24,345 - train - INFO - alphas:tensor([9.5267e-04, 9.9905e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,346 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,346 - train - INFO - True
2024-04-03 06:53:24,346 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 06:53:24,346 - train - INFO - tau:0.49483865960020695
2024-04-03 06:53:24,346 - train - INFO - avg block size:12.89655172413793
2024-04-03 06:53:25,505 - train - INFO - Test: [   0/39]  Time: 1.153 (1.153)  Loss:  0.3738 (0.3738)  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)
2024-04-03 06:54:09,116 - train - INFO - Test: [  39/39]  Time: 1.136 (1.119)  Loss:  0.4868 (0.3675)  Acc@1: 81.2500 (92.0600)  Acc@5: 100.0000 (99.7400)
2024-04-03 06:54:11,353 - train - INFO - Train: 73 [   0/195 (  0%)]  Loss:  1.818648 (1.8186)  Time: 2.146s,  119.28/s  (2.146s,  119.28/s)  LR: 2.913e-04  Data: 0.202 (0.202)
2024-04-03 06:55:49,621 - train - INFO - Train: 73 [  50/195 ( 26%)]  Loss:  1.701636 (1.6168)  Time: 1.861s,  137.58/s  (1.969s,  130.02/s)  LR: 2.913e-04  Data: 0.018 (0.013)
2024-04-03 06:57:27,795 - train - INFO - Train: 73 [ 100/195 ( 52%)]  Loss:  1.884127 (1.6056)  Time: 2.053s,  124.67/s  (1.966s,  130.20/s)  LR: 2.913e-04  Data: 0.014 (0.011)
2024-04-03 06:59:07,482 - train - INFO - Train: 73 [ 150/195 ( 77%)]  Loss:  1.522754 (1.5971)  Time: 2.000s,  127.98/s  (1.975s,  129.60/s)  LR: 2.913e-04  Data: 0.005 (0.010)
2024-04-03 07:00:34,382 - train - INFO - Train: 73 [ 194/195 (100%)]  Loss:  1.321295 (1.5986)  Time: 1.736s,  147.44/s  (1.975s,  129.61/s)  LR: 2.913e-04  Data: 0.000 (0.010)
2024-04-03 07:00:34,382 - train - INFO - True
2024-04-03 07:00:34,384 - train - INFO - alphas:tensor([0.0209, 0.9791], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,384 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,384 - train - INFO - True
2024-04-03 07:00:34,385 - train - INFO - alphas:tensor([0.1166, 0.8834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,385 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,385 - train - INFO - True
2024-04-03 07:00:34,386 - train - INFO - alphas:tensor([0.5867, 0.4133], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,386 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,386 - train - INFO - True
2024-04-03 07:00:34,386 - train - INFO - alphas:tensor([0.5211, 0.4789], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,386 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,387 - train - INFO - True
2024-04-03 07:00:34,387 - train - INFO - alphas:tensor([0.2124, 0.7876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,387 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,387 - train - INFO - True
2024-04-03 07:00:34,388 - train - INFO - alphas:tensor([0.3284, 0.6716], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,388 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,388 - train - INFO - True
2024-04-03 07:00:34,389 - train - INFO - alphas:tensor([0.5922, 0.4078], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,389 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,389 - train - INFO - True
2024-04-03 07:00:34,390 - train - INFO - alphas:tensor([0.4844, 0.5156], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,390 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,390 - train - INFO - True
2024-04-03 07:00:34,390 - train - INFO - alphas:tensor([0.3111, 0.6889], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,391 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,391 - train - INFO - True
2024-04-03 07:00:34,391 - train - INFO - alphas:tensor([0.4562, 0.5438], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,391 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,391 - train - INFO - True
2024-04-03 07:00:34,392 - train - INFO - alphas:tensor([0.5965, 0.4035], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,392 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,392 - train - INFO - True
2024-04-03 07:00:34,393 - train - INFO - alphas:tensor([0.4644, 0.5356], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,393 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,393 - train - INFO - True
2024-04-03 07:00:34,394 - train - INFO - alphas:tensor([0.3243, 0.6757], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,394 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,394 - train - INFO - True
2024-04-03 07:00:34,394 - train - INFO - alphas:tensor([0.4452, 0.5548], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,395 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,395 - train - INFO - True
2024-04-03 07:00:34,395 - train - INFO - alphas:tensor([0.5408, 0.4592], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,395 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,395 - train - INFO - True
2024-04-03 07:00:34,396 - train - INFO - alphas:tensor([0.3930, 0.6070], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,396 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,396 - train - INFO - True
2024-04-03 07:00:34,397 - train - INFO - alphas:tensor([0.2933, 0.7067], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,397 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,397 - train - INFO - True
2024-04-03 07:00:34,398 - train - INFO - alphas:tensor([0.3555, 0.6445], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,398 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,398 - train - INFO - True
2024-04-03 07:00:34,399 - train - INFO - alphas:tensor([0.4379, 0.5621], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,399 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,399 - train - INFO - True
2024-04-03 07:00:34,400 - train - INFO - alphas:tensor([0.2625, 0.7375], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,400 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,400 - train - INFO - True
2024-04-03 07:00:34,401 - train - INFO - alphas:tensor([0.2373, 0.7627], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,401 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,401 - train - INFO - True
2024-04-03 07:00:34,402 - train - INFO - alphas:tensor([0.2857, 0.7143], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,402 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,402 - train - INFO - True
2024-04-03 07:00:34,403 - train - INFO - alphas:tensor([0.3909, 0.6091], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,403 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,403 - train - INFO - True
2024-04-03 07:00:34,403 - train - INFO - alphas:tensor([0.1825, 0.8175], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,403 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,404 - train - INFO - True
2024-04-03 07:00:34,404 - train - INFO - alphas:tensor([0.1708, 0.8292], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,404 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,404 - train - INFO - True
2024-04-03 07:00:34,405 - train - INFO - alphas:tensor([0.0844, 0.9156], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,405 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,405 - train - INFO - True
2024-04-03 07:00:34,406 - train - INFO - alphas:tensor([0.0704, 0.9296], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,406 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,406 - train - INFO - True
2024-04-03 07:00:34,407 - train - INFO - alphas:tensor([8.4168e-04, 9.9916e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,407 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,407 - train - INFO - True
2024-04-03 07:00:34,407 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:00:34,407 - train - INFO - tau:0.4898902730042049
2024-04-03 07:00:34,408 - train - INFO - avg block size:12.89655172413793
2024-04-03 07:00:35,532 - train - INFO - Test: [   0/39]  Time: 1.122 (1.122)  Loss:  0.3865 (0.3865)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.2188 (99.2188)
2024-04-03 07:01:19,671 - train - INFO - Test: [  39/39]  Time: 1.114 (1.132)  Loss:  0.5063 (0.3804)  Acc@1: 81.2500 (91.7800)  Acc@5: 100.0000 (99.7100)
2024-04-03 07:01:22,101 - train - INFO - Train: 74 [   0/195 (  0%)]  Loss:  1.513294 (1.5133)  Time: 2.257s,  113.42/s  (2.257s,  113.42/s)  LR: 2.857e-04  Data: 0.254 (0.254)
2024-04-03 07:03:00,894 - train - INFO - Train: 74 [  50/195 ( 26%)]  Loss:  1.547554 (1.5734)  Time: 2.153s,  118.89/s  (1.981s,  129.20/s)  LR: 2.857e-04  Data: 0.008 (0.013)
2024-04-03 07:04:40,988 - train - INFO - Train: 74 [ 100/195 ( 52%)]  Loss:  1.284543 (1.5569)  Time: 2.007s,  127.57/s  (1.992s,  128.55/s)  LR: 2.857e-04  Data: 0.013 (0.012)
2024-04-03 07:06:18,965 - train - INFO - Train: 74 [ 150/195 ( 77%)]  Loss:  1.649850 (1.5811)  Time: 1.922s,  133.23/s  (1.981s,  129.23/s)  LR: 2.857e-04  Data: 0.005 (0.011)
2024-04-03 07:07:45,860 - train - INFO - Train: 74 [ 194/195 (100%)]  Loss:  1.461666 (1.5795)  Time: 1.881s,  136.09/s  (1.980s,  129.32/s)  LR: 2.857e-04  Data: 0.000 (0.011)
2024-04-03 07:07:45,861 - train - INFO - True
2024-04-03 07:07:45,862 - train - INFO - alphas:tensor([0.0194, 0.9806], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,862 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,862 - train - INFO - True
2024-04-03 07:07:45,863 - train - INFO - alphas:tensor([0.1154, 0.8846], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,863 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,863 - train - INFO - True
2024-04-03 07:07:45,864 - train - INFO - alphas:tensor([0.5854, 0.4146], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,864 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,864 - train - INFO - True
2024-04-03 07:07:45,865 - train - INFO - alphas:tensor([0.5176, 0.4824], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,865 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,865 - train - INFO - True
2024-04-03 07:07:45,866 - train - INFO - alphas:tensor([0.2109, 0.7891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,866 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,866 - train - INFO - True
2024-04-03 07:07:45,867 - train - INFO - alphas:tensor([0.3261, 0.6739], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,867 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,867 - train - INFO - True
2024-04-03 07:07:45,867 - train - INFO - alphas:tensor([0.5904, 0.4096], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,867 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,868 - train - INFO - True
2024-04-03 07:07:45,868 - train - INFO - alphas:tensor([0.4834, 0.5166], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,869 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,869 - train - INFO - True
2024-04-03 07:07:45,869 - train - INFO - alphas:tensor([0.3072, 0.6928], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,870 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,870 - train - INFO - True
2024-04-03 07:07:45,870 - train - INFO - alphas:tensor([0.4506, 0.5494], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,870 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,870 - train - INFO - True
2024-04-03 07:07:45,871 - train - INFO - alphas:tensor([0.5977, 0.4023], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,871 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,871 - train - INFO - True
2024-04-03 07:07:45,872 - train - INFO - alphas:tensor([0.4659, 0.5341], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,872 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,872 - train - INFO - True
2024-04-03 07:07:45,873 - train - INFO - alphas:tensor([0.3237, 0.6763], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,873 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,873 - train - INFO - True
2024-04-03 07:07:45,874 - train - INFO - alphas:tensor([0.4437, 0.5563], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,874 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,874 - train - INFO - True
2024-04-03 07:07:45,874 - train - INFO - alphas:tensor([0.5406, 0.4594], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,875 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,875 - train - INFO - True
2024-04-03 07:07:45,875 - train - INFO - alphas:tensor([0.3915, 0.6085], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,875 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,876 - train - INFO - True
2024-04-03 07:07:45,876 - train - INFO - alphas:tensor([0.2915, 0.7085], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,876 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,876 - train - INFO - True
2024-04-03 07:07:45,877 - train - INFO - alphas:tensor([0.3547, 0.6453], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,877 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,877 - train - INFO - True
2024-04-03 07:07:45,878 - train - INFO - alphas:tensor([0.4377, 0.5623], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,878 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,878 - train - INFO - True
2024-04-03 07:07:45,879 - train - INFO - alphas:tensor([0.2627, 0.7373], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,879 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,879 - train - INFO - True
2024-04-03 07:07:45,879 - train - INFO - alphas:tensor([0.2354, 0.7646], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,880 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,880 - train - INFO - True
2024-04-03 07:07:45,880 - train - INFO - alphas:tensor([0.2835, 0.7165], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,880 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,880 - train - INFO - True
2024-04-03 07:07:45,881 - train - INFO - alphas:tensor([0.3886, 0.6114], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,881 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,881 - train - INFO - True
2024-04-03 07:07:45,882 - train - INFO - alphas:tensor([0.1790, 0.8210], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,882 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,882 - train - INFO - True
2024-04-03 07:07:45,883 - train - INFO - alphas:tensor([0.1677, 0.8323], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,883 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,883 - train - INFO - True
2024-04-03 07:07:45,884 - train - INFO - alphas:tensor([0.0799, 0.9201], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,884 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,884 - train - INFO - True
2024-04-03 07:07:45,884 - train - INFO - alphas:tensor([0.0691, 0.9309], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,885 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,885 - train - INFO - True
2024-04-03 07:07:45,885 - train - INFO - alphas:tensor([7.4495e-04, 9.9926e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,885 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,885 - train - INFO - True
2024-04-03 07:07:45,886 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:07:45,886 - train - INFO - tau:0.48499137027416284
2024-04-03 07:07:45,886 - train - INFO - avg block size:12.89655172413793
2024-04-03 07:07:47,094 - train - INFO - Test: [   0/39]  Time: 1.206 (1.206)  Loss:  0.3650 (0.3650)  Acc@1: 92.9688 (92.9688)  Acc@5: 99.6094 (99.6094)
2024-04-03 07:08:30,710 - train - INFO - Test: [  39/39]  Time: 1.143 (1.121)  Loss:  0.3350 (0.3768)  Acc@1: 87.5000 (92.1400)  Acc@5: 100.0000 (99.6500)
2024-04-03 07:08:32,873 - train - INFO - Train: 75 [   0/195 (  0%)]  Loss:  1.751802 (1.7518)  Time: 2.034s,  125.86/s  (2.034s,  125.86/s)  LR: 2.800e-04  Data: 0.226 (0.226)
2024-04-03 07:10:12,236 - train - INFO - Train: 75 [  50/195 ( 26%)]  Loss:  1.535733 (1.5378)  Time: 2.117s,  120.91/s  (1.988s,  128.76/s)  LR: 2.800e-04  Data: 0.014 (0.013)
2024-04-03 07:11:50,340 - train - INFO - Train: 75 [ 100/195 ( 52%)]  Loss:  1.578175 (1.5684)  Time: 2.012s,  127.23/s  (1.975s,  129.61/s)  LR: 2.800e-04  Data: 0.018 (0.011)
2024-04-03 07:13:27,423 - train - INFO - Train: 75 [ 150/195 ( 77%)]  Loss:  1.729306 (1.5732)  Time: 1.953s,  131.11/s  (1.964s,  130.34/s)  LR: 2.800e-04  Data: 0.027 (0.011)
2024-04-03 07:14:54,411 - train - INFO - Train: 75 [ 194/195 (100%)]  Loss:  1.421587 (1.5701)  Time: 2.017s,  126.93/s  (1.967s,  130.15/s)  LR: 2.800e-04  Data: 0.000 (0.010)
2024-04-03 07:14:54,416 - train - INFO - True
2024-04-03 07:14:54,418 - train - INFO - alphas:tensor([0.0180, 0.9820], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,421 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,421 - train - INFO - True
2024-04-03 07:14:54,422 - train - INFO - alphas:tensor([0.1136, 0.8864], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,423 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,423 - train - INFO - True
2024-04-03 07:14:54,423 - train - INFO - alphas:tensor([0.5851, 0.4149], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,423 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,424 - train - INFO - True
2024-04-03 07:14:54,424 - train - INFO - alphas:tensor([0.5167, 0.4833], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,424 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,424 - train - INFO - True
2024-04-03 07:14:54,425 - train - INFO - alphas:tensor([0.2092, 0.7908], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,425 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,425 - train - INFO - True
2024-04-03 07:14:54,426 - train - INFO - alphas:tensor([0.3245, 0.6755], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,430 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,430 - train - INFO - True
2024-04-03 07:14:54,432 - train - INFO - alphas:tensor([0.5917, 0.4083], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,436 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,436 - train - INFO - True
2024-04-03 07:14:54,437 - train - INFO - alphas:tensor([0.4831, 0.5169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,437 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,437 - train - INFO - True
2024-04-03 07:14:54,438 - train - INFO - alphas:tensor([0.3074, 0.6926], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,438 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,438 - train - INFO - True
2024-04-03 07:14:54,439 - train - INFO - alphas:tensor([0.4509, 0.5491], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,439 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,439 - train - INFO - True
2024-04-03 07:14:54,439 - train - INFO - alphas:tensor([0.5946, 0.4054], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,439 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,439 - train - INFO - True
2024-04-03 07:14:54,440 - train - INFO - alphas:tensor([0.4629, 0.5371], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,440 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,440 - train - INFO - True
2024-04-03 07:14:54,441 - train - INFO - alphas:tensor([0.3204, 0.6796], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,441 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,441 - train - INFO - True
2024-04-03 07:14:54,442 - train - INFO - alphas:tensor([0.4412, 0.5588], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,442 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,442 - train - INFO - True
2024-04-03 07:14:54,443 - train - INFO - alphas:tensor([0.5389, 0.4611], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,443 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,443 - train - INFO - True
2024-04-03 07:14:54,452 - train - INFO - alphas:tensor([0.3894, 0.6106], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,452 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,452 - train - INFO - True
2024-04-03 07:14:54,453 - train - INFO - alphas:tensor([0.2883, 0.7117], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,453 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,453 - train - INFO - True
2024-04-03 07:14:54,454 - train - INFO - alphas:tensor([0.3514, 0.6486], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,454 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,454 - train - INFO - True
2024-04-03 07:14:54,455 - train - INFO - alphas:tensor([0.4350, 0.5650], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,455 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,455 - train - INFO - True
2024-04-03 07:14:54,456 - train - INFO - alphas:tensor([0.2606, 0.7394], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,456 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,456 - train - INFO - True
2024-04-03 07:14:54,456 - train - INFO - alphas:tensor([0.2338, 0.7662], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,456 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,457 - train - INFO - True
2024-04-03 07:14:54,457 - train - INFO - alphas:tensor([0.2847, 0.7153], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,457 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,457 - train - INFO - True
2024-04-03 07:14:54,458 - train - INFO - alphas:tensor([0.3878, 0.6122], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,458 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,458 - train - INFO - True
2024-04-03 07:14:54,459 - train - INFO - alphas:tensor([0.1779, 0.8221], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,459 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,459 - train - INFO - True
2024-04-03 07:14:54,460 - train - INFO - alphas:tensor([0.1665, 0.8335], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,460 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,460 - train - INFO - True
2024-04-03 07:14:54,460 - train - INFO - alphas:tensor([0.0776, 0.9224], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,461 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,461 - train - INFO - True
2024-04-03 07:14:54,461 - train - INFO - alphas:tensor([0.0681, 0.9319], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,461 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,461 - train - INFO - True
2024-04-03 07:14:54,466 - train - INFO - alphas:tensor([6.5891e-04, 9.9934e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,467 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,467 - train - INFO - True
2024-04-03 07:14:54,467 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:14:54,467 - train - INFO - tau:0.4801414565714212
2024-04-03 07:14:54,467 - train - INFO - avg block size:12.89655172413793
2024-04-03 07:14:55,585 - train - INFO - Test: [   0/39]  Time: 1.115 (1.115)  Loss:  0.3835 (0.3835)  Acc@1: 91.0156 (91.0156)  Acc@5: 100.0000 (100.0000)
2024-04-03 07:15:38,893 - train - INFO - Test: [  39/39]  Time: 1.087 (1.111)  Loss:  0.4329 (0.3744)  Acc@1: 87.5000 (92.1500)  Acc@5: 100.0000 (99.7800)
2024-04-03 07:15:41,263 - train - INFO - Train: 76 [   0/195 (  0%)]  Loss:  1.258474 (1.2585)  Time: 2.142s,  119.53/s  (2.142s,  119.53/s)  LR: 2.743e-04  Data: 0.195 (0.195)
2024-04-03 07:17:19,974 - train - INFO - Train: 76 [  50/195 ( 26%)]  Loss:  1.378251 (1.5319)  Time: 1.880s,  136.15/s  (1.977s,  129.46/s)  LR: 2.743e-04  Data: 0.010 (0.014)
2024-04-03 07:19:00,377 - train - INFO - Train: 76 [ 100/195 ( 52%)]  Loss:  1.706203 (1.5471)  Time: 2.147s,  119.26/s  (1.993s,  128.48/s)  LR: 2.743e-04  Data: 0.005 (0.012)
2024-04-03 07:20:41,563 - train - INFO - Train: 76 [ 150/195 ( 77%)]  Loss:  1.461970 (1.5512)  Time: 1.875s,  136.51/s  (2.003s,  127.81/s)  LR: 2.743e-04  Data: 0.020 (0.011)
2024-04-03 07:22:07,452 - train - INFO - Train: 76 [ 194/195 (100%)]  Loss:  1.263192 (1.5511)  Time: 1.919s,  133.39/s  (1.991s,  128.55/s)  LR: 2.743e-04  Data: 0.000 (0.010)
2024-04-03 07:22:07,452 - train - INFO - True
2024-04-03 07:22:07,453 - train - INFO - alphas:tensor([0.0167, 0.9833], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,453 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,454 - train - INFO - True
2024-04-03 07:22:07,454 - train - INFO - alphas:tensor([0.1118, 0.8882], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,459 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,459 - train - INFO - True
2024-04-03 07:22:07,459 - train - INFO - alphas:tensor([0.5856, 0.4144], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,460 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,460 - train - INFO - True
2024-04-03 07:22:07,460 - train - INFO - alphas:tensor([0.5167, 0.4833], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,460 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,460 - train - INFO - True
2024-04-03 07:22:07,461 - train - INFO - alphas:tensor([0.2060, 0.7940], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,461 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,461 - train - INFO - True
2024-04-03 07:22:07,462 - train - INFO - alphas:tensor([0.3206, 0.6794], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,462 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,462 - train - INFO - True
2024-04-03 07:22:07,463 - train - INFO - alphas:tensor([0.5896, 0.4104], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,463 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,463 - train - INFO - True
2024-04-03 07:22:07,463 - train - INFO - alphas:tensor([0.4822, 0.5178], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,464 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,464 - train - INFO - True
2024-04-03 07:22:07,464 - train - INFO - alphas:tensor([0.3075, 0.6925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,464 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,464 - train - INFO - True
2024-04-03 07:22:07,465 - train - INFO - alphas:tensor([0.4507, 0.5493], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,465 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,465 - train - INFO - True
2024-04-03 07:22:07,466 - train - INFO - alphas:tensor([0.5949, 0.4051], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,466 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,466 - train - INFO - True
2024-04-03 07:22:07,467 - train - INFO - alphas:tensor([0.4645, 0.5355], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,467 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,467 - train - INFO - True
2024-04-03 07:22:07,467 - train - INFO - alphas:tensor([0.3199, 0.6801], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,468 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,468 - train - INFO - True
2024-04-03 07:22:07,468 - train - INFO - alphas:tensor([0.4406, 0.5594], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,468 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,468 - train - INFO - True
2024-04-03 07:22:07,469 - train - INFO - alphas:tensor([0.5369, 0.4631], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,469 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,469 - train - INFO - True
2024-04-03 07:22:07,470 - train - INFO - alphas:tensor([0.3885, 0.6115], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,470 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,470 - train - INFO - True
2024-04-03 07:22:07,471 - train - INFO - alphas:tensor([0.2864, 0.7136], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,471 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,471 - train - INFO - True
2024-04-03 07:22:07,471 - train - INFO - alphas:tensor([0.3505, 0.6495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,472 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,472 - train - INFO - True
2024-04-03 07:22:07,477 - train - INFO - alphas:tensor([0.4324, 0.5676], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,477 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,477 - train - INFO - True
2024-04-03 07:22:07,477 - train - INFO - alphas:tensor([0.2590, 0.7410], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,478 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,478 - train - INFO - True
2024-04-03 07:22:07,478 - train - INFO - alphas:tensor([0.2325, 0.7675], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,478 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,478 - train - INFO - True
2024-04-03 07:22:07,479 - train - INFO - alphas:tensor([0.2828, 0.7172], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,479 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,479 - train - INFO - True
2024-04-03 07:22:07,480 - train - INFO - alphas:tensor([0.3857, 0.6143], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,480 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,480 - train - INFO - True
2024-04-03 07:22:07,481 - train - INFO - alphas:tensor([0.1750, 0.8250], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,481 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,481 - train - INFO - True
2024-04-03 07:22:07,482 - train - INFO - alphas:tensor([0.1641, 0.8359], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,482 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,482 - train - INFO - True
2024-04-03 07:22:07,482 - train - INFO - alphas:tensor([0.0742, 0.9258], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,482 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,482 - train - INFO - True
2024-04-03 07:22:07,483 - train - INFO - alphas:tensor([0.0656, 0.9344], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,483 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,483 - train - INFO - True
2024-04-03 07:22:07,484 - train - INFO - alphas:tensor([5.8270e-04, 9.9942e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,484 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,484 - train - INFO - True
2024-04-03 07:22:07,485 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:22:07,485 - train - INFO - tau:0.475340042005707
2024-04-03 07:22:07,485 - train - INFO - avg block size:12.89655172413793
2024-04-03 07:22:08,657 - train - INFO - Test: [   0/39]  Time: 1.170 (1.170)  Loss:  0.3728 (0.3728)  Acc@1: 90.6250 (90.6250)  Acc@5: 99.6094 (99.6094)
2024-04-03 07:22:51,974 - train - INFO - Test: [  39/39]  Time: 1.064 (1.112)  Loss:  0.4597 (0.3572)  Acc@1: 81.2500 (92.2100)  Acc@5: 100.0000 (99.7100)
2024-04-03 07:22:54,300 - train - INFO - Train: 77 [   0/195 (  0%)]  Loss:  1.753053 (1.7531)  Time: 2.171s,  117.93/s  (2.171s,  117.93/s)  LR: 2.687e-04  Data: 0.317 (0.317)
2024-04-03 07:24:32,353 - train - INFO - Train: 77 [  50/195 ( 26%)]  Loss:  1.505883 (1.5145)  Time: 2.176s,  117.66/s  (1.965s,  130.27/s)  LR: 2.687e-04  Data: 0.014 (0.014)
2024-04-03 07:26:12,329 - train - INFO - Train: 77 [ 100/195 ( 52%)]  Loss:  1.319988 (1.5061)  Time: 1.947s,  131.50/s  (1.982s,  129.15/s)  LR: 2.687e-04  Data: 0.005 (0.012)
2024-04-03 07:27:53,453 - train - INFO - Train: 77 [ 150/195 ( 77%)]  Loss:  1.516875 (1.5434)  Time: 2.119s,  120.83/s  (1.996s,  128.29/s)  LR: 2.687e-04  Data: 0.018 (0.012)
2024-04-03 07:29:20,101 - train - INFO - Train: 77 [ 194/195 (100%)]  Loss:  1.780065 (1.5523)  Time: 1.870s,  136.93/s  (1.990s,  128.67/s)  LR: 2.687e-04  Data: 0.000 (0.011)
2024-04-03 07:29:20,102 - train - INFO - True
2024-04-03 07:29:20,103 - train - INFO - alphas:tensor([0.0155, 0.9845], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,103 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,103 - train - INFO - True
2024-04-03 07:29:20,104 - train - INFO - alphas:tensor([0.1116, 0.8884], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,105 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,105 - train - INFO - True
2024-04-03 07:29:20,105 - train - INFO - alphas:tensor([0.5858, 0.4142], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,105 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,106 - train - INFO - True
2024-04-03 07:29:20,106 - train - INFO - alphas:tensor([0.5166, 0.4834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,106 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,106 - train - INFO - True
2024-04-03 07:29:20,107 - train - INFO - alphas:tensor([0.2044, 0.7956], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,107 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,107 - train - INFO - True
2024-04-03 07:29:20,110 - train - INFO - alphas:tensor([0.3198, 0.6802], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,110 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,110 - train - INFO - True
2024-04-03 07:29:20,111 - train - INFO - alphas:tensor([0.5886, 0.4114], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,111 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,111 - train - INFO - True
2024-04-03 07:29:20,112 - train - INFO - alphas:tensor([0.4789, 0.5211], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,112 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,112 - train - INFO - True
2024-04-03 07:29:20,122 - train - INFO - alphas:tensor([0.3040, 0.6960], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,122 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,122 - train - INFO - True
2024-04-03 07:29:20,123 - train - INFO - alphas:tensor([0.4472, 0.5528], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,123 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,123 - train - INFO - True
2024-04-03 07:29:20,124 - train - INFO - alphas:tensor([0.5922, 0.4078], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,124 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,124 - train - INFO - True
2024-04-03 07:29:20,125 - train - INFO - alphas:tensor([0.4601, 0.5399], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,125 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,125 - train - INFO - True
2024-04-03 07:29:20,126 - train - INFO - alphas:tensor([0.3192, 0.6808], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,131 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,131 - train - INFO - True
2024-04-03 07:29:20,132 - train - INFO - alphas:tensor([0.4420, 0.5580], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,132 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,132 - train - INFO - True
2024-04-03 07:29:20,132 - train - INFO - alphas:tensor([0.5353, 0.4647], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,133 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,133 - train - INFO - True
2024-04-03 07:29:20,138 - train - INFO - alphas:tensor([0.3853, 0.6147], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,138 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,138 - train - INFO - True
2024-04-03 07:29:20,139 - train - INFO - alphas:tensor([0.2855, 0.7145], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,139 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,139 - train - INFO - True
2024-04-03 07:29:20,140 - train - INFO - alphas:tensor([0.3490, 0.6510], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,140 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,140 - train - INFO - True
2024-04-03 07:29:20,141 - train - INFO - alphas:tensor([0.4330, 0.5670], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,141 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,141 - train - INFO - True
2024-04-03 07:29:20,142 - train - INFO - alphas:tensor([0.2579, 0.7421], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,142 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,142 - train - INFO - True
2024-04-03 07:29:20,143 - train - INFO - alphas:tensor([0.2309, 0.7691], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,147 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,147 - train - INFO - True
2024-04-03 07:29:20,148 - train - INFO - alphas:tensor([0.2770, 0.7230], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,148 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,148 - train - INFO - True
2024-04-03 07:29:20,149 - train - INFO - alphas:tensor([0.3849, 0.6151], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,149 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,149 - train - INFO - True
2024-04-03 07:29:20,150 - train - INFO - alphas:tensor([0.1739, 0.8261], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,150 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,150 - train - INFO - True
2024-04-03 07:29:20,151 - train - INFO - alphas:tensor([0.1635, 0.8365], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,151 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,151 - train - INFO - True
2024-04-03 07:29:20,156 - train - INFO - alphas:tensor([0.0717, 0.9283], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,156 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,157 - train - INFO - True
2024-04-03 07:29:20,157 - train - INFO - alphas:tensor([0.0628, 0.9372], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,157 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,158 - train - INFO - True
2024-04-03 07:29:20,158 - train - INFO - alphas:tensor([5.1531e-04, 9.9948e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,158 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,158 - train - INFO - True
2024-04-03 07:29:20,159 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:29:20,159 - train - INFO - tau:0.47058664158564995
2024-04-03 07:29:20,159 - train - INFO - avg block size:12.89655172413793
2024-04-03 07:29:21,327 - train - INFO - Test: [   0/39]  Time: 1.155 (1.155)  Loss:  0.3503 (0.3503)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-03 07:30:04,853 - train - INFO - Test: [  39/39]  Time: 1.143 (1.117)  Loss:  0.4897 (0.3639)  Acc@1: 81.2500 (92.4800)  Acc@5: 100.0000 (99.8000)
2024-04-03 07:30:07,163 - train - INFO - Train: 78 [   0/195 (  0%)]  Loss:  1.792695 (1.7927)  Time: 2.098s,  122.02/s  (2.098s,  122.02/s)  LR: 2.630e-04  Data: 0.186 (0.186)
2024-04-03 07:31:46,930 - train - INFO - Train: 78 [  50/195 ( 26%)]  Loss:  1.360283 (1.5927)  Time: 2.002s,  127.87/s  (1.997s,  128.17/s)  LR: 2.630e-04  Data: 0.005 (0.013)
2024-04-03 07:33:24,526 - train - INFO - Train: 78 [ 100/195 ( 52%)]  Loss:  1.377900 (1.5773)  Time: 1.799s,  142.30/s  (1.975s,  129.63/s)  LR: 2.630e-04  Data: 0.006 (0.011)
2024-04-03 07:35:01,082 - train - INFO - Train: 78 [ 150/195 ( 77%)]  Loss:  1.314547 (1.5684)  Time: 1.822s,  140.47/s  (1.960s,  130.59/s)  LR: 2.630e-04  Data: 0.013 (0.010)
2024-04-03 07:36:28,412 - train - INFO - Train: 78 [ 194/195 (100%)]  Loss:  1.499812 (1.5619)  Time: 1.973s,  129.74/s  (1.966s,  130.22/s)  LR: 2.630e-04  Data: 0.000 (0.010)
2024-04-03 07:36:28,413 - train - INFO - True
2024-04-03 07:36:28,415 - train - INFO - alphas:tensor([0.0143, 0.9857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,415 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,415 - train - INFO - True
2024-04-03 07:36:28,416 - train - INFO - alphas:tensor([0.1102, 0.8898], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,416 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,416 - train - INFO - True
2024-04-03 07:36:28,417 - train - INFO - alphas:tensor([0.5841, 0.4159], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,417 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,421 - train - INFO - True
2024-04-03 07:36:28,422 - train - INFO - alphas:tensor([0.5144, 0.4856], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,422 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,422 - train - INFO - True
2024-04-03 07:36:28,423 - train - INFO - alphas:tensor([0.2024, 0.7976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,423 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,423 - train - INFO - True
2024-04-03 07:36:28,424 - train - INFO - alphas:tensor([0.3172, 0.6828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,424 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,424 - train - INFO - True
2024-04-03 07:36:28,424 - train - INFO - alphas:tensor([0.5878, 0.4122], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,424 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,425 - train - INFO - True
2024-04-03 07:36:28,425 - train - INFO - alphas:tensor([0.4804, 0.5196], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,426 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,426 - train - INFO - True
2024-04-03 07:36:28,426 - train - INFO - alphas:tensor([0.3031, 0.6969], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,427 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,427 - train - INFO - True
2024-04-03 07:36:28,427 - train - INFO - alphas:tensor([0.4472, 0.5528], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,427 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,427 - train - INFO - True
2024-04-03 07:36:28,428 - train - INFO - alphas:tensor([0.5911, 0.4089], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,428 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,428 - train - INFO - True
2024-04-03 07:36:28,429 - train - INFO - alphas:tensor([0.4583, 0.5417], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,429 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,429 - train - INFO - True
2024-04-03 07:36:28,430 - train - INFO - alphas:tensor([0.3168, 0.6832], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,430 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,430 - train - INFO - True
2024-04-03 07:36:28,431 - train - INFO - alphas:tensor([0.4400, 0.5600], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,431 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,431 - train - INFO - True
2024-04-03 07:36:28,431 - train - INFO - alphas:tensor([0.5348, 0.4652], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,431 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,431 - train - INFO - True
2024-04-03 07:36:28,432 - train - INFO - alphas:tensor([0.3843, 0.6157], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,432 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,432 - train - INFO - True
2024-04-03 07:36:28,433 - train - INFO - alphas:tensor([0.2830, 0.7170], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,433 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,433 - train - INFO - True
2024-04-03 07:36:28,434 - train - INFO - alphas:tensor([0.3464, 0.6536], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,434 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,438 - train - INFO - True
2024-04-03 07:36:28,439 - train - INFO - alphas:tensor([0.4337, 0.5663], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,439 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,439 - train - INFO - True
2024-04-03 07:36:28,440 - train - INFO - alphas:tensor([0.2568, 0.7432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,440 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,440 - train - INFO - True
2024-04-03 07:36:28,441 - train - INFO - alphas:tensor([0.2308, 0.7692], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,441 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,441 - train - INFO - True
2024-04-03 07:36:28,441 - train - INFO - alphas:tensor([0.2763, 0.7237], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,442 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,442 - train - INFO - True
2024-04-03 07:36:28,442 - train - INFO - alphas:tensor([0.3848, 0.6152], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,442 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,442 - train - INFO - True
2024-04-03 07:36:28,443 - train - INFO - alphas:tensor([0.1727, 0.8273], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,443 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,443 - train - INFO - True
2024-04-03 07:36:28,444 - train - INFO - alphas:tensor([0.1616, 0.8384], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,444 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,444 - train - INFO - True
2024-04-03 07:36:28,445 - train - INFO - alphas:tensor([0.0689, 0.9311], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,445 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,445 - train - INFO - True
2024-04-03 07:36:28,446 - train - INFO - alphas:tensor([0.0619, 0.9381], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,446 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,446 - train - INFO - True
2024-04-03 07:36:28,446 - train - INFO - alphas:tensor([4.5619e-04, 9.9954e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,446 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,446 - train - INFO - True
2024-04-03 07:36:28,447 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:36:28,447 - train - INFO - tau:0.4658807751697934
2024-04-03 07:36:28,447 - train - INFO - avg block size:12.89655172413793
2024-04-03 07:36:29,547 - train - INFO - Test: [   0/39]  Time: 1.097 (1.097)  Loss:  0.3643 (0.3643)  Acc@1: 91.0156 (91.0156)  Acc@5: 100.0000 (100.0000)
2024-04-03 07:37:13,726 - train - INFO - Test: [  39/39]  Time: 1.150 (1.132)  Loss:  0.4177 (0.3627)  Acc@1: 87.5000 (92.1900)  Acc@5: 100.0000 (99.7500)
2024-04-03 07:37:16,424 - train - INFO - Train: 79 [   0/195 (  0%)]  Loss:  1.465564 (1.4656)  Time: 2.529s,  101.22/s  (2.529s,  101.22/s)  LR: 2.574e-04  Data: 0.167 (0.167)
2024-04-03 07:38:56,326 - train - INFO - Train: 79 [  50/195 ( 26%)]  Loss:  1.724583 (1.5571)  Time: 1.869s,  136.97/s  (2.008s,  127.47/s)  LR: 2.574e-04  Data: 0.005 (0.012)
2024-04-03 07:40:36,037 - train - INFO - Train: 79 [ 100/195 ( 52%)]  Loss:  1.693950 (1.5562)  Time: 2.068s,  123.76/s  (2.001s,  127.91/s)  LR: 2.574e-04  Data: 0.005 (0.010)
2024-04-03 07:42:15,663 - train - INFO - Train: 79 [ 150/195 ( 77%)]  Loss:  1.465198 (1.5503)  Time: 1.918s,  133.50/s  (1.998s,  128.10/s)  LR: 2.574e-04  Data: 0.021 (0.010)
2024-04-03 07:43:41,282 - train - INFO - Train: 79 [ 194/195 (100%)]  Loss:  1.657904 (1.5592)  Time: 1.817s,  140.89/s  (1.987s,  128.87/s)  LR: 2.574e-04  Data: 0.000 (0.010)
2024-04-03 07:43:41,283 - train - INFO - True
2024-04-03 07:43:41,284 - train - INFO - alphas:tensor([0.0133, 0.9867], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,284 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,284 - train - INFO - True
2024-04-03 07:43:41,285 - train - INFO - alphas:tensor([0.1090, 0.8910], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,285 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,285 - train - INFO - True
2024-04-03 07:43:41,286 - train - INFO - alphas:tensor([0.5835, 0.4165], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,286 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,286 - train - INFO - True
2024-04-03 07:43:41,286 - train - INFO - alphas:tensor([0.5128, 0.4872], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,286 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,287 - train - INFO - True
2024-04-03 07:43:41,287 - train - INFO - alphas:tensor([0.2007, 0.7993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,287 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,287 - train - INFO - True
2024-04-03 07:43:41,288 - train - INFO - alphas:tensor([0.3142, 0.6858], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,288 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,288 - train - INFO - True
2024-04-03 07:43:41,289 - train - INFO - alphas:tensor([0.5865, 0.4135], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,290 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,290 - train - INFO - True
2024-04-03 07:43:41,290 - train - INFO - alphas:tensor([0.4782, 0.5218], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,290 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,291 - train - INFO - True
2024-04-03 07:43:41,291 - train - INFO - alphas:tensor([0.3018, 0.6982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,291 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,291 - train - INFO - True
2024-04-03 07:43:41,292 - train - INFO - alphas:tensor([0.4465, 0.5535], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,292 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,292 - train - INFO - True
2024-04-03 07:43:41,293 - train - INFO - alphas:tensor([0.5909, 0.4091], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,293 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,293 - train - INFO - True
2024-04-03 07:43:41,294 - train - INFO - alphas:tensor([0.4575, 0.5425], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,294 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,294 - train - INFO - True
2024-04-03 07:43:41,295 - train - INFO - alphas:tensor([0.3163, 0.6837], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,295 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,295 - train - INFO - True
2024-04-03 07:43:41,296 - train - INFO - alphas:tensor([0.4403, 0.5597], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,296 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,296 - train - INFO - True
2024-04-03 07:43:41,296 - train - INFO - alphas:tensor([0.5344, 0.4656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,297 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,297 - train - INFO - True
2024-04-03 07:43:41,297 - train - INFO - alphas:tensor([0.3850, 0.6150], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,297 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,297 - train - INFO - True
2024-04-03 07:43:41,298 - train - INFO - alphas:tensor([0.2836, 0.7164], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,298 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,298 - train - INFO - True
2024-04-03 07:43:41,299 - train - INFO - alphas:tensor([0.3468, 0.6532], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,299 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,299 - train - INFO - True
2024-04-03 07:43:41,300 - train - INFO - alphas:tensor([0.4317, 0.5683], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,300 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,300 - train - INFO - True
2024-04-03 07:43:41,300 - train - INFO - alphas:tensor([0.2548, 0.7452], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,301 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,301 - train - INFO - True
2024-04-03 07:43:41,301 - train - INFO - alphas:tensor([0.2273, 0.7727], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,301 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,301 - train - INFO - True
2024-04-03 07:43:41,302 - train - INFO - alphas:tensor([0.2748, 0.7252], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,302 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,302 - train - INFO - True
2024-04-03 07:43:41,303 - train - INFO - alphas:tensor([0.3814, 0.6186], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,303 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,303 - train - INFO - True
2024-04-03 07:43:41,304 - train - INFO - alphas:tensor([0.1701, 0.8299], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,304 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,304 - train - INFO - True
2024-04-03 07:43:41,304 - train - INFO - alphas:tensor([0.1587, 0.8413], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,305 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,305 - train - INFO - True
2024-04-03 07:43:41,305 - train - INFO - alphas:tensor([0.0656, 0.9344], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,305 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,305 - train - INFO - True
2024-04-03 07:43:41,306 - train - INFO - alphas:tensor([0.0597, 0.9403], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,306 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,306 - train - INFO - True
2024-04-03 07:43:41,307 - train - INFO - alphas:tensor([4.0331e-04, 9.9960e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,307 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,307 - train - INFO - True
2024-04-03 07:43:41,308 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:43:41,308 - train - INFO - tau:0.4612219674180955
2024-04-03 07:43:41,308 - train - INFO - avg block size:12.89655172413793
2024-04-03 07:43:42,480 - train - INFO - Test: [   0/39]  Time: 1.169 (1.169)  Loss:  0.3638 (0.3638)  Acc@1: 91.4062 (91.4062)  Acc@5: 100.0000 (100.0000)
2024-04-03 07:44:26,266 - train - INFO - Test: [  39/39]  Time: 1.066 (1.124)  Loss:  0.4106 (0.3601)  Acc@1: 87.5000 (92.3700)  Acc@5: 100.0000 (99.7200)
2024-04-03 07:44:28,688 - train - INFO - Train: 80 [   0/195 (  0%)]  Loss:  1.823691 (1.8237)  Time: 2.261s,  113.21/s  (2.261s,  113.21/s)  LR: 2.518e-04  Data: 0.254 (0.254)
2024-04-03 07:46:10,364 - train - INFO - Train: 80 [  50/195 ( 26%)]  Loss:  1.840359 (1.5381)  Time: 1.789s,  143.10/s  (2.038s,  125.61/s)  LR: 2.518e-04  Data: 0.016 (0.014)
2024-04-03 07:47:49,884 - train - INFO - Train: 80 [ 100/195 ( 52%)]  Loss:  1.293696 (1.5172)  Time: 1.927s,  132.85/s  (2.014s,  127.08/s)  LR: 2.518e-04  Data: 0.010 (0.011)
2024-04-03 07:49:28,555 - train - INFO - Train: 80 [ 150/195 ( 77%)]  Loss:  1.628369 (1.5281)  Time: 1.864s,  137.31/s  (2.001s,  127.95/s)  LR: 2.518e-04  Data: 0.006 (0.010)
2024-04-03 07:50:55,626 - train - INFO - Train: 80 [ 194/195 (100%)]  Loss:  1.207147 (1.5316)  Time: 1.986s,  128.92/s  (1.996s,  128.26/s)  LR: 2.518e-04  Data: 0.000 (0.010)
2024-04-03 07:50:55,627 - train - INFO - True
2024-04-03 07:50:55,628 - train - INFO - alphas:tensor([0.0123, 0.9877], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,628 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,628 - train - INFO - True
2024-04-03 07:50:55,634 - train - INFO - alphas:tensor([0.1082, 0.8918], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,634 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,634 - train - INFO - True
2024-04-03 07:50:55,634 - train - INFO - alphas:tensor([0.5821, 0.4179], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,635 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,635 - train - INFO - True
2024-04-03 07:50:55,635 - train - INFO - alphas:tensor([0.5114, 0.4886], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,635 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,636 - train - INFO - True
2024-04-03 07:50:55,636 - train - INFO - alphas:tensor([0.1998, 0.8002], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,636 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,636 - train - INFO - True
2024-04-03 07:50:55,637 - train - INFO - alphas:tensor([0.3143, 0.6857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,637 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,637 - train - INFO - True
2024-04-03 07:50:55,638 - train - INFO - alphas:tensor([0.5868, 0.4132], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,638 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,638 - train - INFO - True
2024-04-03 07:50:55,639 - train - INFO - alphas:tensor([0.4780, 0.5220], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,639 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,639 - train - INFO - True
2024-04-03 07:50:55,639 - train - INFO - alphas:tensor([0.3002, 0.6998], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,640 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,640 - train - INFO - True
2024-04-03 07:50:55,640 - train - INFO - alphas:tensor([0.4456, 0.5544], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,640 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,640 - train - INFO - True
2024-04-03 07:50:55,641 - train - INFO - alphas:tensor([0.5904, 0.4096], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,641 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,641 - train - INFO - True
2024-04-03 07:50:55,646 - train - INFO - alphas:tensor([0.4578, 0.5422], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,646 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,646 - train - INFO - True
2024-04-03 07:50:55,647 - train - INFO - alphas:tensor([0.3139, 0.6861], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,647 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,647 - train - INFO - True
2024-04-03 07:50:55,648 - train - INFO - alphas:tensor([0.4381, 0.5619], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,648 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,648 - train - INFO - True
2024-04-03 07:50:55,649 - train - INFO - alphas:tensor([0.5333, 0.4667], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,649 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,649 - train - INFO - True
2024-04-03 07:50:55,650 - train - INFO - alphas:tensor([0.3864, 0.6136], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,650 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,650 - train - INFO - True
2024-04-03 07:50:55,650 - train - INFO - alphas:tensor([0.2812, 0.7188], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,650 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,651 - train - INFO - True
2024-04-03 07:50:55,651 - train - INFO - alphas:tensor([0.3451, 0.6549], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,651 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,651 - train - INFO - True
2024-04-03 07:50:55,652 - train - INFO - alphas:tensor([0.4319, 0.5681], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,652 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,652 - train - INFO - True
2024-04-03 07:50:55,653 - train - INFO - alphas:tensor([0.2544, 0.7456], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,653 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,653 - train - INFO - True
2024-04-03 07:50:55,654 - train - INFO - alphas:tensor([0.2254, 0.7746], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,654 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,654 - train - INFO - True
2024-04-03 07:50:55,654 - train - INFO - alphas:tensor([0.2741, 0.7259], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,655 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,655 - train - INFO - True
2024-04-03 07:50:55,655 - train - INFO - alphas:tensor([0.3794, 0.6206], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,655 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,655 - train - INFO - True
2024-04-03 07:50:55,656 - train - INFO - alphas:tensor([0.1671, 0.8329], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,656 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,656 - train - INFO - True
2024-04-03 07:50:55,657 - train - INFO - alphas:tensor([0.1588, 0.8412], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,657 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,657 - train - INFO - True
2024-04-03 07:50:55,658 - train - INFO - alphas:tensor([0.0632, 0.9368], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,658 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,658 - train - INFO - True
2024-04-03 07:50:55,659 - train - INFO - alphas:tensor([0.0583, 0.9417], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,659 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,659 - train - INFO - True
2024-04-03 07:50:55,659 - train - INFO - alphas:tensor([3.5709e-04, 9.9964e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,659 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,659 - train - INFO - True
2024-04-03 07:50:55,660 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:50:55,660 - train - INFO - tau:0.45660974774391455
2024-04-03 07:50:55,660 - train - INFO - avg block size:12.89655172413793
2024-04-03 07:50:56,762 - train - INFO - Test: [   0/39]  Time: 1.099 (1.099)  Loss:  0.3772 (0.3772)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-04-03 07:51:40,475 - train - INFO - Test: [  39/39]  Time: 1.074 (1.120)  Loss:  0.3984 (0.3795)  Acc@1: 93.7500 (92.2500)  Acc@5: 100.0000 (99.7300)
2024-04-03 07:51:42,997 - train - INFO - Train: 81 [   0/195 (  0%)]  Loss:  1.755356 (1.7554)  Time: 2.379s,  107.63/s  (2.379s,  107.63/s)  LR: 2.462e-04  Data: 0.244 (0.244)
2024-04-03 07:53:19,902 - train - INFO - Train: 81 [  50/195 ( 26%)]  Loss:  1.328710 (1.5590)  Time: 1.898s,  134.85/s  (1.947s,  131.51/s)  LR: 2.462e-04  Data: 0.011 (0.015)
2024-04-03 07:54:59,344 - train - INFO - Train: 81 [ 100/195 ( 52%)]  Loss:  1.786540 (1.5770)  Time: 2.332s,  109.80/s  (1.968s,  130.11/s)  LR: 2.462e-04  Data: 0.014 (0.012)
2024-04-03 07:56:40,691 - train - INFO - Train: 81 [ 150/195 ( 77%)]  Loss:  1.735646 (1.5720)  Time: 1.941s,  131.92/s  (1.987s,  128.83/s)  LR: 2.462e-04  Data: 0.015 (0.012)
2024-04-03 07:58:07,506 - train - INFO - Train: 81 [ 194/195 (100%)]  Loss:  1.739519 (1.5756)  Time: 1.910s,  134.03/s  (1.984s,  129.03/s)  LR: 2.462e-04  Data: 0.000 (0.011)
2024-04-03 07:58:07,506 - train - INFO - True
2024-04-03 07:58:07,508 - train - INFO - alphas:tensor([0.0114, 0.9886], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,508 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,508 - train - INFO - True
2024-04-03 07:58:07,509 - train - INFO - alphas:tensor([0.1073, 0.8927], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,509 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,509 - train - INFO - True
2024-04-03 07:58:07,510 - train - INFO - alphas:tensor([0.5816, 0.4184], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,510 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,510 - train - INFO - True
2024-04-03 07:58:07,511 - train - INFO - alphas:tensor([0.5101, 0.4899], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,511 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,511 - train - INFO - True
2024-04-03 07:58:07,511 - train - INFO - alphas:tensor([0.1951, 0.8049], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,511 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,511 - train - INFO - True
2024-04-03 07:58:07,512 - train - INFO - alphas:tensor([0.3101, 0.6899], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,512 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,512 - train - INFO - True
2024-04-03 07:58:07,513 - train - INFO - alphas:tensor([0.5859, 0.4141], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,513 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,513 - train - INFO - True
2024-04-03 07:58:07,514 - train - INFO - alphas:tensor([0.4745, 0.5255], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,514 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,514 - train - INFO - True
2024-04-03 07:58:07,515 - train - INFO - alphas:tensor([0.2987, 0.7013], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,515 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,515 - train - INFO - True
2024-04-03 07:58:07,516 - train - INFO - alphas:tensor([0.4450, 0.5550], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,516 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,516 - train - INFO - True
2024-04-03 07:58:07,517 - train - INFO - alphas:tensor([0.5891, 0.4109], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,517 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,517 - train - INFO - True
2024-04-03 07:58:07,517 - train - INFO - alphas:tensor([0.4564, 0.5436], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,518 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,518 - train - INFO - True
2024-04-03 07:58:07,518 - train - INFO - alphas:tensor([0.3129, 0.6871], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,518 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,518 - train - INFO - True
2024-04-03 07:58:07,519 - train - INFO - alphas:tensor([0.4373, 0.5627], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,519 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,519 - train - INFO - True
2024-04-03 07:58:07,520 - train - INFO - alphas:tensor([0.5300, 0.4700], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,520 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,520 - train - INFO - True
2024-04-03 07:58:07,521 - train - INFO - alphas:tensor([0.3824, 0.6176], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,521 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,521 - train - INFO - True
2024-04-03 07:58:07,521 - train - INFO - alphas:tensor([0.2793, 0.7207], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,522 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,522 - train - INFO - True
2024-04-03 07:58:07,522 - train - INFO - alphas:tensor([0.3440, 0.6560], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,522 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,522 - train - INFO - True
2024-04-03 07:58:07,523 - train - INFO - alphas:tensor([0.4298, 0.5702], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,523 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,523 - train - INFO - True
2024-04-03 07:58:07,524 - train - INFO - alphas:tensor([0.2532, 0.7468], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,524 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,524 - train - INFO - True
2024-04-03 07:58:07,525 - train - INFO - alphas:tensor([0.2255, 0.7745], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,525 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,525 - train - INFO - True
2024-04-03 07:58:07,525 - train - INFO - alphas:tensor([0.2743, 0.7257], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,526 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,526 - train - INFO - True
2024-04-03 07:58:07,526 - train - INFO - alphas:tensor([0.3782, 0.6218], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,526 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,526 - train - INFO - True
2024-04-03 07:58:07,527 - train - INFO - alphas:tensor([0.1668, 0.8332], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,527 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,527 - train - INFO - True
2024-04-03 07:58:07,528 - train - INFO - alphas:tensor([0.1569, 0.8431], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,528 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,528 - train - INFO - True
2024-04-03 07:58:07,529 - train - INFO - alphas:tensor([0.0602, 0.9398], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,529 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,529 - train - INFO - True
2024-04-03 07:58:07,529 - train - INFO - alphas:tensor([0.0567, 0.9433], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,530 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,530 - train - INFO - True
2024-04-03 07:58:07,530 - train - INFO - alphas:tensor([3.1597e-04, 9.9968e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,530 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,530 - train - INFO - True
2024-04-03 07:58:07,531 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 07:58:07,531 - train - INFO - tau:0.4520436502664754
2024-04-03 07:58:07,532 - train - INFO - avg block size:12.89655172413793
2024-04-03 07:58:08,685 - train - INFO - Test: [   0/39]  Time: 1.151 (1.151)  Loss:  0.3718 (0.3718)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-04-03 07:58:53,044 - train - INFO - Test: [  39/39]  Time: 1.147 (1.138)  Loss:  0.4849 (0.3702)  Acc@1: 81.2500 (92.2000)  Acc@5: 100.0000 (99.7600)
2024-04-03 07:58:55,288 - train - INFO - Train: 82 [   0/195 (  0%)]  Loss:  1.576609 (1.5766)  Time: 2.111s,  121.29/s  (2.111s,  121.29/s)  LR: 2.406e-04  Data: 0.195 (0.195)
2024-04-03 08:00:34,082 - train - INFO - Train: 82 [  50/195 ( 26%)]  Loss:  1.420359 (1.5320)  Time: 1.714s,  149.37/s  (1.979s,  129.39/s)  LR: 2.406e-04  Data: 0.019 (0.014)
2024-04-03 08:02:11,875 - train - INFO - Train: 82 [ 100/195 ( 52%)]  Loss:  1.823925 (1.5175)  Time: 1.881s,  136.09/s  (1.967s,  130.13/s)  LR: 2.406e-04  Data: 0.009 (0.011)
2024-04-03 08:03:49,849 - train - INFO - Train: 82 [ 150/195 ( 77%)]  Loss:  1.846167 (1.5421)  Time: 1.724s,  148.52/s  (1.965s,  130.30/s)  LR: 2.406e-04  Data: 0.010 (0.011)
2024-04-03 08:05:16,924 - train - INFO - Train: 82 [ 194/195 (100%)]  Loss:  1.287541 (1.5525)  Time: 1.904s,  134.44/s  (1.968s,  130.09/s)  LR: 2.406e-04  Data: 0.000 (0.010)
2024-04-03 08:05:16,925 - train - INFO - True
2024-04-03 08:05:16,926 - train - INFO - alphas:tensor([0.0105, 0.9895], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,926 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,926 - train - INFO - True
2024-04-03 08:05:16,927 - train - INFO - alphas:tensor([0.1064, 0.8936], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,927 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,927 - train - INFO - True
2024-04-03 08:05:16,928 - train - INFO - alphas:tensor([0.5799, 0.4201], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,928 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,928 - train - INFO - True
2024-04-03 08:05:16,929 - train - INFO - alphas:tensor([0.5076, 0.4924], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,929 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,929 - train - INFO - True
2024-04-03 08:05:16,929 - train - INFO - alphas:tensor([0.1947, 0.8053], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,930 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,930 - train - INFO - True
2024-04-03 08:05:16,931 - train - INFO - alphas:tensor([0.3096, 0.6904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,931 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,931 - train - INFO - True
2024-04-03 08:05:16,932 - train - INFO - alphas:tensor([0.5847, 0.4153], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,932 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,932 - train - INFO - True
2024-04-03 08:05:16,933 - train - INFO - alphas:tensor([0.4731, 0.5269], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,933 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,933 - train - INFO - True
2024-04-03 08:05:16,934 - train - INFO - alphas:tensor([0.2972, 0.7028], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,934 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,934 - train - INFO - True
2024-04-03 08:05:16,935 - train - INFO - alphas:tensor([0.4430, 0.5570], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,935 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,935 - train - INFO - True
2024-04-03 08:05:16,936 - train - INFO - alphas:tensor([0.5881, 0.4119], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,936 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,936 - train - INFO - True
2024-04-03 08:05:16,936 - train - INFO - alphas:tensor([0.4532, 0.5468], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,936 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,937 - train - INFO - True
2024-04-03 08:05:16,937 - train - INFO - alphas:tensor([0.3103, 0.6897], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,937 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,937 - train - INFO - True
2024-04-03 08:05:16,938 - train - INFO - alphas:tensor([0.4350, 0.5650], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,938 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,938 - train - INFO - True
2024-04-03 08:05:16,939 - train - INFO - alphas:tensor([0.5277, 0.4723], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,939 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,939 - train - INFO - True
2024-04-03 08:05:16,940 - train - INFO - alphas:tensor([0.3786, 0.6214], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,940 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,940 - train - INFO - True
2024-04-03 08:05:16,940 - train - INFO - alphas:tensor([0.2790, 0.7210], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,941 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,941 - train - INFO - True
2024-04-03 08:05:16,941 - train - INFO - alphas:tensor([0.3446, 0.6554], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,941 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,941 - train - INFO - True
2024-04-03 08:05:16,942 - train - INFO - alphas:tensor([0.4265, 0.5735], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,942 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,942 - train - INFO - True
2024-04-03 08:05:16,943 - train - INFO - alphas:tensor([0.2493, 0.7507], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,943 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,943 - train - INFO - True
2024-04-03 08:05:16,944 - train - INFO - alphas:tensor([0.2232, 0.7768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,944 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,944 - train - INFO - True
2024-04-03 08:05:16,945 - train - INFO - alphas:tensor([0.2717, 0.7283], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,945 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,945 - train - INFO - True
2024-04-03 08:05:16,945 - train - INFO - alphas:tensor([0.3794, 0.6206], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,945 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,946 - train - INFO - True
2024-04-03 08:05:16,946 - train - INFO - alphas:tensor([0.1650, 0.8350], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,946 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,946 - train - INFO - True
2024-04-03 08:05:16,947 - train - INFO - alphas:tensor([0.1560, 0.8440], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,947 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,947 - train - INFO - True
2024-04-03 08:05:16,948 - train - INFO - alphas:tensor([0.0573, 0.9427], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,948 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,948 - train - INFO - True
2024-04-03 08:05:16,949 - train - INFO - alphas:tensor([0.0552, 0.9448], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,949 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,949 - train - INFO - True
2024-04-03 08:05:16,949 - train - INFO - alphas:tensor([2.7956e-04, 9.9972e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,949 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,950 - train - INFO - True
2024-04-03 08:05:16,950 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:05:16,950 - train - INFO - tau:0.44752321376381066
2024-04-03 08:05:16,950 - train - INFO - avg block size:12.89655172413793
2024-04-03 08:05:18,042 - train - INFO - Test: [   0/39]  Time: 1.089 (1.089)  Loss:  0.3752 (0.3752)  Acc@1: 91.7969 (91.7969)  Acc@5: 100.0000 (100.0000)
2024-04-03 08:06:01,378 - train - INFO - Test: [  39/39]  Time: 1.132 (1.111)  Loss:  0.5049 (0.3817)  Acc@1: 81.2500 (92.0800)  Acc@5: 100.0000 (99.7600)
2024-04-03 08:06:03,881 - train - INFO - Train: 83 [   0/195 (  0%)]  Loss:  1.718857 (1.7189)  Time: 2.334s,  109.69/s  (2.334s,  109.69/s)  LR: 2.350e-04  Data: 0.146 (0.146)
2024-04-03 08:07:43,788 - train - INFO - Train: 83 [  50/195 ( 26%)]  Loss:  1.544811 (1.5754)  Time: 2.123s,  120.61/s  (2.005s,  127.70/s)  LR: 2.350e-04  Data: 0.006 (0.012)
2024-04-03 08:09:21,675 - train - INFO - Train: 83 [ 100/195 ( 52%)]  Loss:  1.782659 (1.5658)  Time: 2.129s,  120.25/s  (1.981s,  129.20/s)  LR: 2.350e-04  Data: 0.008 (0.010)
2024-04-03 08:10:59,691 - train - INFO - Train: 83 [ 150/195 ( 77%)]  Loss:  1.413568 (1.5775)  Time: 1.991s,  128.56/s  (1.974s,  129.66/s)  LR: 2.350e-04  Data: 0.008 (0.010)
2024-04-03 08:12:26,204 - train - INFO - Train: 83 [ 194/195 (100%)]  Loss:  1.346867 (1.5788)  Time: 1.919s,  133.37/s  (1.973s,  129.78/s)  LR: 2.350e-04  Data: 0.000 (0.010)
2024-04-03 08:12:26,213 - train - INFO - True
2024-04-03 08:12:26,215 - train - INFO - alphas:tensor([0.0096, 0.9904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,215 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,215 - train - INFO - True
2024-04-03 08:12:26,216 - train - INFO - alphas:tensor([0.1042, 0.8958], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,216 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,216 - train - INFO - True
2024-04-03 08:12:26,217 - train - INFO - alphas:tensor([0.5806, 0.4194], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,217 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,217 - train - INFO - True
2024-04-03 08:12:26,218 - train - INFO - alphas:tensor([0.5079, 0.4921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,218 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,218 - train - INFO - True
2024-04-03 08:12:26,219 - train - INFO - alphas:tensor([0.1919, 0.8081], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,219 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,219 - train - INFO - True
2024-04-03 08:12:26,220 - train - INFO - alphas:tensor([0.3081, 0.6919], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,220 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,220 - train - INFO - True
2024-04-03 08:12:26,220 - train - INFO - alphas:tensor([0.5820, 0.4180], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,221 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,221 - train - INFO - True
2024-04-03 08:12:26,221 - train - INFO - alphas:tensor([0.4697, 0.5303], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,222 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,222 - train - INFO - True
2024-04-03 08:12:26,223 - train - INFO - alphas:tensor([0.2955, 0.7045], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,223 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,223 - train - INFO - True
2024-04-03 08:12:26,224 - train - INFO - alphas:tensor([0.4431, 0.5569], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,224 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,224 - train - INFO - True
2024-04-03 08:12:26,233 - train - INFO - alphas:tensor([0.5860, 0.4140], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,234 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,234 - train - INFO - True
2024-04-03 08:12:26,234 - train - INFO - alphas:tensor([0.4501, 0.5499], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,235 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,235 - train - INFO - True
2024-04-03 08:12:26,235 - train - INFO - alphas:tensor([0.3092, 0.6908], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,236 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,236 - train - INFO - True
2024-04-03 08:12:26,236 - train - INFO - alphas:tensor([0.4347, 0.5653], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,236 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,237 - train - INFO - True
2024-04-03 08:12:26,237 - train - INFO - alphas:tensor([0.5263, 0.4737], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,237 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,237 - train - INFO - True
2024-04-03 08:12:26,243 - train - INFO - alphas:tensor([0.3757, 0.6243], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,243 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,243 - train - INFO - True
2024-04-03 08:12:26,244 - train - INFO - alphas:tensor([0.2770, 0.7230], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,244 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,244 - train - INFO - True
2024-04-03 08:12:26,245 - train - INFO - alphas:tensor([0.3428, 0.6572], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,245 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,245 - train - INFO - True
2024-04-03 08:12:26,246 - train - INFO - alphas:tensor([0.4243, 0.5757], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,246 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,246 - train - INFO - True
2024-04-03 08:12:26,246 - train - INFO - alphas:tensor([0.2466, 0.7534], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,251 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,251 - train - INFO - True
2024-04-03 08:12:26,256 - train - INFO - alphas:tensor([0.2215, 0.7785], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,256 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,256 - train - INFO - True
2024-04-03 08:12:26,257 - train - INFO - alphas:tensor([0.2690, 0.7310], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,257 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,257 - train - INFO - True
2024-04-03 08:12:26,258 - train - INFO - alphas:tensor([0.3784, 0.6216], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,258 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,258 - train - INFO - True
2024-04-03 08:12:26,259 - train - INFO - alphas:tensor([0.1632, 0.8368], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,259 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,259 - train - INFO - True
2024-04-03 08:12:26,260 - train - INFO - alphas:tensor([0.1534, 0.8466], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,260 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,260 - train - INFO - True
2024-04-03 08:12:26,278 - train - INFO - alphas:tensor([0.0550, 0.9450], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,283 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,283 - train - INFO - True
2024-04-03 08:12:26,283 - train - INFO - alphas:tensor([0.0537, 0.9463], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,283 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,283 - train - INFO - True
2024-04-03 08:12:26,284 - train - INFO - alphas:tensor([2.4722e-04, 9.9975e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,284 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,284 - train - INFO - True
2024-04-03 08:12:26,285 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:12:26,285 - train - INFO - tau:0.44304798162617254
2024-04-03 08:12:26,285 - train - INFO - avg block size:12.89655172413793
2024-04-03 08:12:27,504 - train - INFO - Test: [   0/39]  Time: 1.216 (1.216)  Loss:  0.3784 (0.3784)  Acc@1: 92.1875 (92.1875)  Acc@5: 100.0000 (100.0000)
2024-04-03 08:13:12,035 - train - INFO - Test: [  39/39]  Time: 1.164 (1.144)  Loss:  0.4749 (0.3638)  Acc@1: 81.2500 (92.4600)  Acc@5: 100.0000 (99.7300)
2024-04-03 08:13:14,252 - train - INFO - Train: 84 [   0/195 (  0%)]  Loss:  1.237501 (1.2375)  Time: 1.962s,  130.51/s  (1.962s,  130.51/s)  LR: 2.294e-04  Data: 0.244 (0.244)
2024-04-03 08:14:52,128 - train - INFO - Train: 84 [  50/195 ( 26%)]  Loss:  1.545478 (1.5300)  Time: 1.858s,  137.76/s  (1.958s,  130.77/s)  LR: 2.294e-04  Data: 0.010 (0.013)
2024-04-03 08:16:32,171 - train - INFO - Train: 84 [ 100/195 ( 52%)]  Loss:  1.247146 (1.5422)  Time: 1.869s,  137.00/s  (1.979s,  129.36/s)  LR: 2.294e-04  Data: 0.006 (0.011)
2024-04-03 08:18:11,655 - train - INFO - Train: 84 [ 150/195 ( 77%)]  Loss:  1.404789 (1.5515)  Time: 1.854s,  138.12/s  (1.983s,  129.13/s)  LR: 2.294e-04  Data: 0.009 (0.010)
2024-04-03 08:19:40,076 - train - INFO - Train: 84 [ 194/195 (100%)]  Loss:  1.521898 (1.5545)  Time: 2.073s,  123.46/s  (1.989s,  128.73/s)  LR: 2.294e-04  Data: 0.000 (0.010)
2024-04-03 08:19:40,077 - train - INFO - True
2024-04-03 08:19:40,079 - train - INFO - alphas:tensor([0.0089, 0.9911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,079 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,079 - train - INFO - True
2024-04-03 08:19:40,080 - train - INFO - alphas:tensor([0.1042, 0.8958], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,080 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,080 - train - INFO - True
2024-04-03 08:19:40,081 - train - INFO - alphas:tensor([0.5782, 0.4218], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,081 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,081 - train - INFO - True
2024-04-03 08:19:40,082 - train - INFO - alphas:tensor([0.5052, 0.4948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,082 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,082 - train - INFO - True
2024-04-03 08:19:40,083 - train - INFO - alphas:tensor([0.1905, 0.8095], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,083 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,083 - train - INFO - True
2024-04-03 08:19:40,083 - train - INFO - alphas:tensor([0.3067, 0.6933], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,084 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,084 - train - INFO - True
2024-04-03 08:19:40,084 - train - INFO - alphas:tensor([0.5806, 0.4194], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,084 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,084 - train - INFO - True
2024-04-03 08:19:40,085 - train - INFO - alphas:tensor([0.4690, 0.5310], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,085 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,085 - train - INFO - True
2024-04-03 08:19:40,086 - train - INFO - alphas:tensor([0.2936, 0.7064], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,086 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,086 - train - INFO - True
2024-04-03 08:19:40,087 - train - INFO - alphas:tensor([0.4418, 0.5582], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,087 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,087 - train - INFO - True
2024-04-03 08:19:40,088 - train - INFO - alphas:tensor([0.5846, 0.4154], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,088 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,088 - train - INFO - True
2024-04-03 08:19:40,088 - train - INFO - alphas:tensor([0.4476, 0.5524], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,088 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,089 - train - INFO - True
2024-04-03 08:19:40,089 - train - INFO - alphas:tensor([0.3086, 0.6914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,089 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,089 - train - INFO - True
2024-04-03 08:19:40,090 - train - INFO - alphas:tensor([0.4337, 0.5663], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,090 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,090 - train - INFO - True
2024-04-03 08:19:40,091 - train - INFO - alphas:tensor([0.5253, 0.4747], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,091 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,091 - train - INFO - True
2024-04-03 08:19:40,092 - train - INFO - alphas:tensor([0.3763, 0.6237], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,092 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,092 - train - INFO - True
2024-04-03 08:19:40,096 - train - INFO - alphas:tensor([0.2758, 0.7242], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,097 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,097 - train - INFO - True
2024-04-03 08:19:40,098 - train - INFO - alphas:tensor([0.3400, 0.6600], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,098 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,098 - train - INFO - True
2024-04-03 08:19:40,099 - train - INFO - alphas:tensor([0.4231, 0.5769], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,099 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,099 - train - INFO - True
2024-04-03 08:19:40,100 - train - INFO - alphas:tensor([0.2471, 0.7529], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,100 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,100 - train - INFO - True
2024-04-03 08:19:40,100 - train - INFO - alphas:tensor([0.2197, 0.7803], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,101 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,101 - train - INFO - True
2024-04-03 08:19:40,101 - train - INFO - alphas:tensor([0.2669, 0.7331], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,101 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,101 - train - INFO - True
2024-04-03 08:19:40,102 - train - INFO - alphas:tensor([0.3761, 0.6239], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,102 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,102 - train - INFO - True
2024-04-03 08:19:40,103 - train - INFO - alphas:tensor([0.1603, 0.8397], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,103 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,103 - train - INFO - True
2024-04-03 08:19:40,104 - train - INFO - alphas:tensor([0.1520, 0.8480], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,104 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,104 - train - INFO - True
2024-04-03 08:19:40,104 - train - INFO - alphas:tensor([0.0523, 0.9477], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,105 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,105 - train - INFO - True
2024-04-03 08:19:40,114 - train - INFO - alphas:tensor([0.0517, 0.9483], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,114 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,114 - train - INFO - True
2024-04-03 08:19:40,115 - train - INFO - alphas:tensor([2.1856e-04, 9.9978e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,115 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,115 - train - INFO - True
2024-04-03 08:19:40,116 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:19:40,116 - train - INFO - tau:0.4386175018099108
2024-04-03 08:19:40,116 - train - INFO - avg block size:12.89655172413793
2024-04-03 08:19:41,216 - train - INFO - Test: [   0/39]  Time: 1.097 (1.097)  Loss:  0.3779 (0.3779)  Acc@1: 92.9688 (92.9688)  Acc@5: 99.6094 (99.6094)
2024-04-03 08:20:24,780 - train - INFO - Test: [  39/39]  Time: 1.098 (1.117)  Loss:  0.3767 (0.3711)  Acc@1: 81.2500 (92.2200)  Acc@5: 100.0000 (99.7300)
2024-04-03 08:20:27,154 - train - INFO - Train: 85 [   0/195 (  0%)]  Loss:  1.709842 (1.7098)  Time: 2.190s,  116.89/s  (2.190s,  116.89/s)  LR: 2.239e-04  Data: 0.147 (0.147)
2024-04-03 08:22:07,642 - train - INFO - Train: 85 [  50/195 ( 26%)]  Loss:  1.733203 (1.5538)  Time: 2.414s,  106.05/s  (2.013s,  127.16/s)  LR: 2.239e-04  Data: 0.005 (0.012)
2024-04-03 08:23:46,626 - train - INFO - Train: 85 [ 100/195 ( 52%)]  Loss:  1.764101 (1.5409)  Time: 1.827s,  140.11/s  (1.997s,  128.22/s)  LR: 2.239e-04  Data: 0.010 (0.011)
2024-04-03 08:25:28,355 - train - INFO - Train: 85 [ 150/195 ( 77%)]  Loss:  1.713236 (1.5492)  Time: 2.131s,  120.13/s  (2.009s,  127.41/s)  LR: 2.239e-04  Data: 0.010 (0.010)
2024-04-03 08:26:56,599 - train - INFO - Train: 85 [ 194/195 (100%)]  Loss:  1.847249 (1.5574)  Time: 2.116s,  120.96/s  (2.008s,  127.47/s)  LR: 2.239e-04  Data: 0.000 (0.010)
2024-04-03 08:26:56,604 - train - INFO - True
2024-04-03 08:26:56,605 - train - INFO - alphas:tensor([0.0082, 0.9918], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,605 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,605 - train - INFO - True
2024-04-03 08:26:56,606 - train - INFO - alphas:tensor([0.1030, 0.8970], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,606 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,606 - train - INFO - True
2024-04-03 08:26:56,607 - train - INFO - alphas:tensor([0.5774, 0.4226], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,607 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,607 - train - INFO - True
2024-04-03 08:26:56,608 - train - INFO - alphas:tensor([0.5032, 0.4968], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,608 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,608 - train - INFO - True
2024-04-03 08:26:56,609 - train - INFO - alphas:tensor([0.1897, 0.8103], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,609 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,609 - train - INFO - True
2024-04-03 08:26:56,610 - train - INFO - alphas:tensor([0.3047, 0.6953], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,610 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,610 - train - INFO - True
2024-04-03 08:26:56,616 - train - INFO - alphas:tensor([0.5802, 0.4198], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,616 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,616 - train - INFO - True
2024-04-03 08:26:56,617 - train - INFO - alphas:tensor([0.4681, 0.5319], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,617 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,617 - train - INFO - True
2024-04-03 08:26:56,617 - train - INFO - alphas:tensor([0.2919, 0.7081], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,618 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,618 - train - INFO - True
2024-04-03 08:26:56,618 - train - INFO - alphas:tensor([0.4404, 0.5596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,619 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,619 - train - INFO - True
2024-04-03 08:26:56,619 - train - INFO - alphas:tensor([0.5845, 0.4155], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,624 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,624 - train - INFO - True
2024-04-03 08:26:56,625 - train - INFO - alphas:tensor([0.4497, 0.5503], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,625 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,625 - train - INFO - True
2024-04-03 08:26:56,626 - train - INFO - alphas:tensor([0.3060, 0.6940], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,626 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,626 - train - INFO - True
2024-04-03 08:26:56,627 - train - INFO - alphas:tensor([0.4323, 0.5677], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,627 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,627 - train - INFO - True
2024-04-03 08:26:56,628 - train - INFO - alphas:tensor([0.5264, 0.4736], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,628 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,628 - train - INFO - True
2024-04-03 08:26:56,629 - train - INFO - alphas:tensor([0.3776, 0.6224], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,629 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,629 - train - INFO - True
2024-04-03 08:26:56,630 - train - INFO - alphas:tensor([0.2733, 0.7267], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,630 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,630 - train - INFO - True
2024-04-03 08:26:56,631 - train - INFO - alphas:tensor([0.3373, 0.6627], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,631 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,631 - train - INFO - True
2024-04-03 08:26:56,632 - train - INFO - alphas:tensor([0.4201, 0.5799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,632 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,632 - train - INFO - True
2024-04-03 08:26:56,632 - train - INFO - alphas:tensor([0.2442, 0.7558], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,634 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,634 - train - INFO - True
2024-04-03 08:26:56,635 - train - INFO - alphas:tensor([0.2189, 0.7811], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,635 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,635 - train - INFO - True
2024-04-03 08:26:56,636 - train - INFO - alphas:tensor([0.2646, 0.7354], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,636 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,636 - train - INFO - True
2024-04-03 08:26:56,645 - train - INFO - alphas:tensor([0.3739, 0.6261], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,645 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,646 - train - INFO - True
2024-04-03 08:26:56,651 - train - INFO - alphas:tensor([0.1586, 0.8414], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,651 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,651 - train - INFO - True
2024-04-03 08:26:56,651 - train - INFO - alphas:tensor([0.1512, 0.8488], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,655 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,655 - train - INFO - True
2024-04-03 08:26:56,655 - train - INFO - alphas:tensor([0.0499, 0.9501], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,655 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,655 - train - INFO - True
2024-04-03 08:26:56,656 - train - INFO - alphas:tensor([0.0500, 0.9500], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,656 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,656 - train - INFO - True
2024-04-03 08:26:56,657 - train - INFO - alphas:tensor([1.9323e-04, 9.9981e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,657 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,657 - train - INFO - True
2024-04-03 08:26:56,658 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:26:56,658 - train - INFO - tau:0.4342313267918117
2024-04-03 08:26:56,658 - train - INFO - avg block size:12.89655172413793
2024-04-03 08:26:57,798 - train - INFO - Test: [   0/39]  Time: 1.128 (1.128)  Loss:  0.3779 (0.3779)  Acc@1: 92.1875 (92.1875)  Acc@5: 99.6094 (99.6094)
2024-04-03 08:27:41,943 - train - INFO - Test: [  39/39]  Time: 1.088 (1.132)  Loss:  0.3970 (0.3689)  Acc@1: 87.5000 (92.1300)  Acc@5: 100.0000 (99.7700)
2024-04-03 08:27:44,156 - train - INFO - Train: 86 [   0/195 (  0%)]  Loss:  1.256200 (1.2562)  Time: 2.019s,  126.77/s  (2.019s,  126.77/s)  LR: 2.183e-04  Data: 0.145 (0.145)
2024-04-03 08:29:23,789 - train - INFO - Train: 86 [  50/195 ( 26%)]  Loss:  1.391268 (1.5456)  Time: 2.219s,  115.37/s  (1.993s,  128.44/s)  LR: 2.183e-04  Data: 0.005 (0.012)
2024-04-03 08:31:02,789 - train - INFO - Train: 86 [ 100/195 ( 52%)]  Loss:  1.704731 (1.5645)  Time: 2.039s,  125.56/s  (1.987s,  128.86/s)  LR: 2.183e-04  Data: 0.017 (0.010)
2024-04-03 08:32:41,844 - train - INFO - Train: 86 [ 150/195 ( 77%)]  Loss:  1.246978 (1.5584)  Time: 1.950s,  131.26/s  (1.985s,  128.98/s)  LR: 2.183e-04  Data: 0.022 (0.010)
2024-04-03 08:34:09,032 - train - INFO - Train: 86 [ 194/195 (100%)]  Loss:  1.791368 (1.5617)  Time: 2.140s,  119.64/s  (1.984s,  129.03/s)  LR: 2.183e-04  Data: 0.000 (0.010)
2024-04-03 08:34:09,033 - train - INFO - True
2024-04-03 08:34:09,034 - train - INFO - alphas:tensor([0.0075, 0.9925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,039 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,039 - train - INFO - True
2024-04-03 08:34:09,039 - train - INFO - alphas:tensor([0.1018, 0.8982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,039 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,040 - train - INFO - True
2024-04-03 08:34:09,040 - train - INFO - alphas:tensor([0.5774, 0.4226], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,040 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,040 - train - INFO - True
2024-04-03 08:34:09,041 - train - INFO - alphas:tensor([0.5024, 0.4976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,041 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,041 - train - INFO - True
2024-04-03 08:34:09,042 - train - INFO - alphas:tensor([0.1881, 0.8119], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,042 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,042 - train - INFO - True
2024-04-03 08:34:09,043 - train - INFO - alphas:tensor([0.3022, 0.6978], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,043 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,043 - train - INFO - True
2024-04-03 08:34:09,044 - train - INFO - alphas:tensor([0.5784, 0.4216], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,044 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,044 - train - INFO - True
2024-04-03 08:34:09,045 - train - INFO - alphas:tensor([0.4655, 0.5345], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,045 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,045 - train - INFO - True
2024-04-03 08:34:09,046 - train - INFO - alphas:tensor([0.2907, 0.7093], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,046 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,046 - train - INFO - True
2024-04-03 08:34:09,046 - train - INFO - alphas:tensor([0.4387, 0.5613], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,046 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,047 - train - INFO - True
2024-04-03 08:34:09,047 - train - INFO - alphas:tensor([0.5835, 0.4165], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,047 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,047 - train - INFO - True
2024-04-03 08:34:09,048 - train - INFO - alphas:tensor([0.4465, 0.5535], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,048 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,048 - train - INFO - True
2024-04-03 08:34:09,049 - train - INFO - alphas:tensor([0.3065, 0.6935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,049 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,049 - train - INFO - True
2024-04-03 08:34:09,050 - train - INFO - alphas:tensor([0.4330, 0.5670], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,050 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,050 - train - INFO - True
2024-04-03 08:34:09,051 - train - INFO - alphas:tensor([0.5251, 0.4749], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,051 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,051 - train - INFO - True
2024-04-03 08:34:09,051 - train - INFO - alphas:tensor([0.3738, 0.6262], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,051 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,051 - train - INFO - True
2024-04-03 08:34:09,052 - train - INFO - alphas:tensor([0.2722, 0.7278], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,052 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,052 - train - INFO - True
2024-04-03 08:34:09,053 - train - INFO - alphas:tensor([0.3368, 0.6632], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,053 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,053 - train - INFO - True
2024-04-03 08:34:09,054 - train - INFO - alphas:tensor([0.4180, 0.5820], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,054 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,054 - train - INFO - True
2024-04-03 08:34:09,055 - train - INFO - alphas:tensor([0.2416, 0.7584], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,067 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,067 - train - INFO - True
2024-04-03 08:34:09,068 - train - INFO - alphas:tensor([0.2187, 0.7813], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,092 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,092 - train - INFO - True
2024-04-03 08:34:09,097 - train - INFO - alphas:tensor([0.2661, 0.7339], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,097 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,097 - train - INFO - True
2024-04-03 08:34:09,098 - train - INFO - alphas:tensor([0.3710, 0.6290], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,098 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,098 - train - INFO - True
2024-04-03 08:34:09,099 - train - INFO - alphas:tensor([0.1553, 0.8447], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,099 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,099 - train - INFO - True
2024-04-03 08:34:09,100 - train - INFO - alphas:tensor([0.1492, 0.8508], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,100 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,100 - train - INFO - True
2024-04-03 08:34:09,101 - train - INFO - alphas:tensor([0.0478, 0.9522], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,101 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,109 - train - INFO - True
2024-04-03 08:34:09,119 - train - INFO - alphas:tensor([0.0484, 0.9516], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,119 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,119 - train - INFO - True
2024-04-03 08:34:09,124 - train - INFO - alphas:tensor([1.7091e-04, 9.9983e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,124 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,124 - train - INFO - True
2024-04-03 08:34:09,125 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:34:09,125 - train - INFO - tau:0.4298890135238936
2024-04-03 08:34:09,125 - train - INFO - avg block size:12.89655172413793
2024-04-03 08:34:10,260 - train - INFO - Test: [   0/39]  Time: 1.113 (1.113)  Loss:  0.3718 (0.3718)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-03 08:34:54,576 - train - INFO - Test: [  39/39]  Time: 1.098 (1.136)  Loss:  0.4062 (0.3602)  Acc@1: 87.5000 (92.5000)  Acc@5: 100.0000 (99.7200)
2024-04-03 08:34:57,273 - train - INFO - Train: 87 [   0/195 (  0%)]  Loss:  1.815058 (1.8151)  Time: 2.542s,  100.70/s  (2.542s,  100.70/s)  LR: 2.129e-04  Data: 0.285 (0.285)
2024-04-03 08:36:33,820 - train - INFO - Train: 87 [  50/195 ( 26%)]  Loss:  1.476056 (1.5040)  Time: 1.874s,  136.62/s  (1.943s,  131.76/s)  LR: 2.129e-04  Data: 0.005 (0.014)
2024-04-03 08:38:13,178 - train - INFO - Train: 87 [ 100/195 ( 52%)]  Loss:  1.791614 (1.5357)  Time: 2.117s,  120.94/s  (1.965s,  130.29/s)  LR: 2.129e-04  Data: 0.005 (0.012)
2024-04-03 08:39:53,296 - train - INFO - Train: 87 [ 150/195 ( 77%)]  Loss:  1.533540 (1.5525)  Time: 1.854s,  138.08/s  (1.977s,  129.48/s)  LR: 2.129e-04  Data: 0.005 (0.011)
2024-04-03 08:41:19,379 - train - INFO - Train: 87 [ 194/195 (100%)]  Loss:  1.446328 (1.5661)  Time: 1.835s,  139.52/s  (1.973s,  129.78/s)  LR: 2.129e-04  Data: 0.000 (0.010)
2024-04-03 08:41:19,380 - train - INFO - True
2024-04-03 08:41:19,381 - train - INFO - alphas:tensor([0.0069, 0.9931], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,381 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,381 - train - INFO - True
2024-04-03 08:41:19,382 - train - INFO - alphas:tensor([0.1000, 0.9000], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,382 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,382 - train - INFO - True
2024-04-03 08:41:19,383 - train - INFO - alphas:tensor([0.5772, 0.4228], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,383 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,383 - train - INFO - True
2024-04-03 08:41:19,384 - train - INFO - alphas:tensor([0.5016, 0.4984], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,384 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,384 - train - INFO - True
2024-04-03 08:41:19,385 - train - INFO - alphas:tensor([0.1857, 0.8143], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,385 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,385 - train - INFO - True
2024-04-03 08:41:19,386 - train - INFO - alphas:tensor([0.3004, 0.6996], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,386 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,386 - train - INFO - True
2024-04-03 08:41:19,387 - train - INFO - alphas:tensor([0.5789, 0.4211], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,387 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,387 - train - INFO - True
2024-04-03 08:41:19,388 - train - INFO - alphas:tensor([0.4643, 0.5357], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,388 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,388 - train - INFO - True
2024-04-03 08:41:19,388 - train - INFO - alphas:tensor([0.2891, 0.7109], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,389 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,389 - train - INFO - True
2024-04-03 08:41:19,389 - train - INFO - alphas:tensor([0.4368, 0.5632], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,389 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,389 - train - INFO - True
2024-04-03 08:41:19,390 - train - INFO - alphas:tensor([0.5831, 0.4169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,390 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,390 - train - INFO - True
2024-04-03 08:41:19,391 - train - INFO - alphas:tensor([0.4477, 0.5523], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,391 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,391 - train - INFO - True
2024-04-03 08:41:19,392 - train - INFO - alphas:tensor([0.3055, 0.6945], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,392 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,392 - train - INFO - True
2024-04-03 08:41:19,393 - train - INFO - alphas:tensor([0.4312, 0.5688], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,393 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,393 - train - INFO - True
2024-04-03 08:41:19,393 - train - INFO - alphas:tensor([0.5237, 0.4763], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,393 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,394 - train - INFO - True
2024-04-03 08:41:19,394 - train - INFO - alphas:tensor([0.3751, 0.6249], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,394 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,394 - train - INFO - True
2024-04-03 08:41:19,395 - train - INFO - alphas:tensor([0.2705, 0.7295], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,395 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,395 - train - INFO - True
2024-04-03 08:41:19,396 - train - INFO - alphas:tensor([0.3342, 0.6658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,396 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,396 - train - INFO - True
2024-04-03 08:41:19,397 - train - INFO - alphas:tensor([0.4173, 0.5827], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,397 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,397 - train - INFO - True
2024-04-03 08:41:19,397 - train - INFO - alphas:tensor([0.2402, 0.7598], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,398 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,398 - train - INFO - True
2024-04-03 08:41:19,398 - train - INFO - alphas:tensor([0.2157, 0.7843], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,398 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,398 - train - INFO - True
2024-04-03 08:41:19,399 - train - INFO - alphas:tensor([0.2633, 0.7367], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,399 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,399 - train - INFO - True
2024-04-03 08:41:19,400 - train - INFO - alphas:tensor([0.3697, 0.6303], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,400 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,400 - train - INFO - True
2024-04-03 08:41:19,401 - train - INFO - alphas:tensor([0.1547, 0.8453], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,401 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,401 - train - INFO - True
2024-04-03 08:41:19,402 - train - INFO - alphas:tensor([0.1486, 0.8514], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,402 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,402 - train - INFO - True
2024-04-03 08:41:19,402 - train - INFO - alphas:tensor([0.0457, 0.9543], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,402 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,403 - train - INFO - True
2024-04-03 08:41:19,403 - train - INFO - alphas:tensor([0.0466, 0.9534], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,403 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,403 - train - INFO - True
2024-04-03 08:41:19,404 - train - INFO - alphas:tensor([1.5116e-04, 9.9985e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,404 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,404 - train - INFO - True
2024-04-03 08:41:19,405 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:41:19,405 - train - INFO - tau:0.42559012338865465
2024-04-03 08:41:19,405 - train - INFO - avg block size:12.89655172413793
2024-04-03 08:41:20,536 - train - INFO - Test: [   0/39]  Time: 1.128 (1.128)  Loss:  0.3645 (0.3645)  Acc@1: 93.7500 (93.7500)  Acc@5: 99.6094 (99.6094)
2024-04-03 08:42:04,397 - train - INFO - Test: [  39/39]  Time: 1.126 (1.125)  Loss:  0.3943 (0.3685)  Acc@1: 87.5000 (92.4900)  Acc@5: 100.0000 (99.7300)
2024-04-03 08:42:06,716 - train - INFO - Train: 88 [   0/195 (  0%)]  Loss:  1.847224 (1.8472)  Time: 2.135s,  119.88/s  (2.135s,  119.88/s)  LR: 2.074e-04  Data: 0.223 (0.223)
2024-04-03 08:43:45,428 - train - INFO - Train: 88 [  50/195 ( 26%)]  Loss:  1.712934 (1.5879)  Time: 1.867s,  137.13/s  (1.977s,  129.46/s)  LR: 2.074e-04  Data: 0.005 (0.014)
2024-04-03 08:45:25,474 - train - INFO - Train: 88 [ 100/195 ( 52%)]  Loss:  1.381111 (1.5843)  Time: 2.295s,  111.56/s  (1.989s,  128.71/s)  LR: 2.074e-04  Data: 0.005 (0.012)
2024-04-03 08:47:03,537 - train - INFO - Train: 88 [ 150/195 ( 77%)]  Loss:  1.462738 (1.5654)  Time: 1.989s,  128.69/s  (1.980s,  129.31/s)  LR: 2.074e-04  Data: 0.005 (0.011)
2024-04-03 08:48:31,017 - train - INFO - Train: 88 [ 194/195 (100%)]  Loss:  1.313893 (1.5691)  Time: 1.834s,  139.55/s  (1.982s,  129.18/s)  LR: 2.074e-04  Data: 0.000 (0.010)
2024-04-03 08:48:31,018 - train - INFO - True
2024-04-03 08:48:31,020 - train - INFO - alphas:tensor([0.0064, 0.9936], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,020 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,020 - train - INFO - True
2024-04-03 08:48:31,021 - train - INFO - alphas:tensor([0.0988, 0.9012], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,021 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,021 - train - INFO - True
2024-04-03 08:48:31,022 - train - INFO - alphas:tensor([0.5762, 0.4238], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,022 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,022 - train - INFO - True
2024-04-03 08:48:31,023 - train - INFO - alphas:tensor([0.5005, 0.4995], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,023 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,023 - train - INFO - True
2024-04-03 08:48:31,024 - train - INFO - alphas:tensor([0.1844, 0.8156], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,024 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,024 - train - INFO - True
2024-04-03 08:48:31,025 - train - INFO - alphas:tensor([0.3004, 0.6996], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,025 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,025 - train - INFO - True
2024-04-03 08:48:31,028 - train - INFO - alphas:tensor([0.5786, 0.4214], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,028 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,028 - train - INFO - True
2024-04-03 08:48:31,029 - train - INFO - alphas:tensor([0.4642, 0.5358], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,029 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,029 - train - INFO - True
2024-04-03 08:48:31,030 - train - INFO - alphas:tensor([0.2855, 0.7145], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,034 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,035 - train - INFO - True
2024-04-03 08:48:31,035 - train - INFO - alphas:tensor([0.4330, 0.5670], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,035 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,040 - train - INFO - True
2024-04-03 08:48:31,040 - train - INFO - alphas:tensor([0.5834, 0.4166], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,041 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,041 - train - INFO - True
2024-04-03 08:48:31,041 - train - INFO - alphas:tensor([0.4469, 0.5531], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,041 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,041 - train - INFO - True
2024-04-03 08:48:31,042 - train - INFO - alphas:tensor([0.3033, 0.6967], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,042 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,042 - train - INFO - True
2024-04-03 08:48:31,043 - train - INFO - alphas:tensor([0.4294, 0.5706], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,043 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,043 - train - INFO - True
2024-04-03 08:48:31,044 - train - INFO - alphas:tensor([0.5213, 0.4787], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,044 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,044 - train - INFO - True
2024-04-03 08:48:31,045 - train - INFO - alphas:tensor([0.3719, 0.6281], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,045 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,045 - train - INFO - True
2024-04-03 08:48:31,045 - train - INFO - alphas:tensor([0.2706, 0.7294], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,045 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,046 - train - INFO - True
2024-04-03 08:48:31,046 - train - INFO - alphas:tensor([0.3347, 0.6653], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,046 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,046 - train - INFO - True
2024-04-03 08:48:31,056 - train - INFO - alphas:tensor([0.4148, 0.5852], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,056 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,056 - train - INFO - True
2024-04-03 08:48:31,057 - train - INFO - alphas:tensor([0.2381, 0.7619], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,057 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,057 - train - INFO - True
2024-04-03 08:48:31,058 - train - INFO - alphas:tensor([0.2152, 0.7848], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,058 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,058 - train - INFO - True
2024-04-03 08:48:31,058 - train - INFO - alphas:tensor([0.2627, 0.7373], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,058 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,059 - train - INFO - True
2024-04-03 08:48:31,059 - train - INFO - alphas:tensor([0.3682, 0.6318], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,059 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,059 - train - INFO - True
2024-04-03 08:48:31,060 - train - INFO - alphas:tensor([0.1531, 0.8469], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,060 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,060 - train - INFO - True
2024-04-03 08:48:31,061 - train - INFO - alphas:tensor([0.1476, 0.8524], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,061 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,061 - train - INFO - True
2024-04-03 08:48:31,062 - train - INFO - alphas:tensor([0.0436, 0.9564], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,062 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,062 - train - INFO - True
2024-04-03 08:48:31,072 - train - INFO - alphas:tensor([0.0442, 0.9558], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,072 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,072 - train - INFO - True
2024-04-03 08:48:31,073 - train - INFO - alphas:tensor([1.3365e-04, 9.9987e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,073 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,073 - train - INFO - True
2024-04-03 08:48:31,073 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:48:31,073 - train - INFO - tau:0.4213342221547681
2024-04-03 08:48:31,074 - train - INFO - avg block size:12.89655172413793
2024-04-03 08:48:32,206 - train - INFO - Test: [   0/39]  Time: 1.130 (1.130)  Loss:  0.3738 (0.3738)  Acc@1: 91.7969 (91.7969)  Acc@5: 99.6094 (99.6094)
2024-04-03 08:49:16,246 - train - INFO - Test: [  39/39]  Time: 1.115 (1.129)  Loss:  0.3582 (0.3591)  Acc@1: 87.5000 (92.3200)  Acc@5: 100.0000 (99.7400)
2024-04-03 08:49:18,565 - train - INFO - Train: 89 [   0/195 (  0%)]  Loss:  1.498594 (1.4986)  Time: 2.197s,  116.50/s  (2.197s,  116.50/s)  LR: 2.020e-04  Data: 0.240 (0.240)
2024-04-03 08:50:56,773 - train - INFO - Train: 89 [  50/195 ( 26%)]  Loss:  1.806499 (1.5495)  Time: 1.958s,  130.74/s  (1.969s,  130.03/s)  LR: 2.020e-04  Data: 0.014 (0.015)
2024-04-03 08:52:36,471 - train - INFO - Train: 89 [ 100/195 ( 52%)]  Loss:  1.864306 (1.5467)  Time: 2.311s,  110.76/s  (1.981s,  129.22/s)  LR: 2.020e-04  Data: 0.005 (0.012)
2024-04-03 08:54:14,912 - train - INFO - Train: 89 [ 150/195 ( 77%)]  Loss:  1.807639 (1.5441)  Time: 1.760s,  145.44/s  (1.977s,  129.48/s)  LR: 2.020e-04  Data: 0.005 (0.011)
2024-04-03 08:55:43,443 - train - INFO - Train: 89 [ 194/195 (100%)]  Loss:  1.745199 (1.5526)  Time: 1.804s,  141.92/s  (1.985s,  128.97/s)  LR: 2.020e-04  Data: 0.000 (0.010)
2024-04-03 08:55:43,443 - train - INFO - True
2024-04-03 08:55:43,444 - train - INFO - alphas:tensor([0.0058, 0.9942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,445 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,445 - train - INFO - True
2024-04-03 08:55:43,445 - train - INFO - alphas:tensor([0.0970, 0.9030], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,446 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,446 - train - INFO - True
2024-04-03 08:55:43,446 - train - INFO - alphas:tensor([0.5761, 0.4239], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,446 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,446 - train - INFO - True
2024-04-03 08:55:43,447 - train - INFO - alphas:tensor([0.4996, 0.5004], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,447 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,447 - train - INFO - True
2024-04-03 08:55:43,448 - train - INFO - alphas:tensor([0.1831, 0.8169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,448 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,448 - train - INFO - True
2024-04-03 08:55:43,449 - train - INFO - alphas:tensor([0.2991, 0.7009], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,449 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,449 - train - INFO - True
2024-04-03 08:55:43,450 - train - INFO - alphas:tensor([0.5762, 0.4238], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,450 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,450 - train - INFO - True
2024-04-03 08:55:43,450 - train - INFO - alphas:tensor([0.4615, 0.5385], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,451 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,451 - train - INFO - True
2024-04-03 08:55:43,452 - train - INFO - alphas:tensor([0.2863, 0.7137], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,452 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,452 - train - INFO - True
2024-04-03 08:55:43,452 - train - INFO - alphas:tensor([0.4342, 0.5658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,453 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,453 - train - INFO - True
2024-04-03 08:55:43,453 - train - INFO - alphas:tensor([0.5809, 0.4191], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,453 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,453 - train - INFO - True
2024-04-03 08:55:43,454 - train - INFO - alphas:tensor([0.4458, 0.5542], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,454 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,454 - train - INFO - True
2024-04-03 08:55:43,455 - train - INFO - alphas:tensor([0.3023, 0.6977], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,455 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,455 - train - INFO - True
2024-04-03 08:55:43,456 - train - INFO - alphas:tensor([0.4277, 0.5723], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,456 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,456 - train - INFO - True
2024-04-03 08:55:43,456 - train - INFO - alphas:tensor([0.5207, 0.4793], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,457 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,457 - train - INFO - True
2024-04-03 08:55:43,457 - train - INFO - alphas:tensor([0.3721, 0.6279], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,457 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,457 - train - INFO - True
2024-04-03 08:55:43,458 - train - INFO - alphas:tensor([0.2696, 0.7304], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,458 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,458 - train - INFO - True
2024-04-03 08:55:43,459 - train - INFO - alphas:tensor([0.3335, 0.6665], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,459 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,459 - train - INFO - True
2024-04-03 08:55:43,460 - train - INFO - alphas:tensor([0.4172, 0.5828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,460 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,460 - train - INFO - True
2024-04-03 08:55:43,460 - train - INFO - alphas:tensor([0.2404, 0.7596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,461 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,461 - train - INFO - True
2024-04-03 08:55:43,461 - train - INFO - alphas:tensor([0.2143, 0.7857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,461 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,461 - train - INFO - True
2024-04-03 08:55:43,462 - train - INFO - alphas:tensor([0.2614, 0.7386], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,462 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,462 - train - INFO - True
2024-04-03 08:55:43,463 - train - INFO - alphas:tensor([0.3665, 0.6335], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,463 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,463 - train - INFO - True
2024-04-03 08:55:43,464 - train - INFO - alphas:tensor([0.1523, 0.8477], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,464 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,464 - train - INFO - True
2024-04-03 08:55:43,464 - train - INFO - alphas:tensor([0.1465, 0.8535], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,465 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,465 - train - INFO - True
2024-04-03 08:55:43,465 - train - INFO - alphas:tensor([0.0417, 0.9583], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,465 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,465 - train - INFO - True
2024-04-03 08:55:43,466 - train - INFO - alphas:tensor([0.0432, 0.9568], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,466 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,466 - train - INFO - True
2024-04-03 08:55:43,467 - train - INFO - alphas:tensor([1.1821e-04, 9.9988e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,467 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,467 - train - INFO - True
2024-04-03 08:55:43,468 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 08:55:43,468 - train - INFO - tau:0.41712087993322045
2024-04-03 08:55:43,468 - train - INFO - avg block size:13.413793103448276
2024-04-03 08:55:44,752 - train - INFO - Test: [   0/39]  Time: 1.281 (1.281)  Loss:  0.3691 (0.3691)  Acc@1: 91.0156 (91.0156)  Acc@5: 99.6094 (99.6094)
2024-04-03 08:56:29,201 - train - INFO - Test: [  39/39]  Time: 1.135 (1.143)  Loss:  0.3235 (0.3586)  Acc@1: 93.7500 (92.2200)  Acc@5: 100.0000 (99.7300)
2024-04-03 08:56:31,586 - train - INFO - Train: 90 [   0/195 (  0%)]  Loss:  1.411276 (1.4113)  Time: 2.178s,  117.56/s  (2.178s,  117.56/s)  LR: 1.966e-04  Data: 0.153 (0.153)
2024-04-03 08:58:11,544 - train - INFO - Train: 90 [  50/195 ( 26%)]  Loss:  1.685489 (1.5430)  Time: 1.728s,  148.16/s  (2.003s,  127.83/s)  LR: 1.966e-04  Data: 0.008 (0.012)
2024-04-03 08:59:49,984 - train - INFO - Train: 90 [ 100/195 ( 52%)]  Loss:  1.274113 (1.5476)  Time: 1.963s,  130.44/s  (1.986s,  128.91/s)  LR: 1.966e-04  Data: 0.008 (0.011)
2024-04-03 09:01:30,208 - train - INFO - Train: 90 [ 150/195 ( 77%)]  Loss:  1.459152 (1.5484)  Time: 2.379s,  107.59/s  (1.992s,  128.51/s)  LR: 1.966e-04  Data: 0.009 (0.011)
2024-04-03 09:02:58,063 - train - INFO - Train: 90 [ 194/195 (100%)]  Loss:  1.709543 (1.5438)  Time: 1.936s,  132.26/s  (1.993s,  128.44/s)  LR: 1.966e-04  Data: 0.000 (0.010)
2024-04-03 09:02:58,064 - train - INFO - True
2024-04-03 09:02:58,065 - train - INFO - alphas:tensor([0.0054, 0.9946], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,065 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,065 - train - INFO - True
2024-04-03 09:02:58,066 - train - INFO - alphas:tensor([0.0962, 0.9038], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,066 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,066 - train - INFO - True
2024-04-03 09:02:58,067 - train - INFO - alphas:tensor([0.5752, 0.4248], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,067 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,067 - train - INFO - True
2024-04-03 09:02:58,068 - train - INFO - alphas:tensor([0.4982, 0.5018], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,068 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,068 - train - INFO - True
2024-04-03 09:02:58,069 - train - INFO - alphas:tensor([0.1812, 0.8188], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,073 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,073 - train - INFO - True
2024-04-03 09:02:58,074 - train - INFO - alphas:tensor([0.2959, 0.7041], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,074 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,074 - train - INFO - True
2024-04-03 09:02:58,075 - train - INFO - alphas:tensor([0.5746, 0.4254], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,079 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,079 - train - INFO - True
2024-04-03 09:02:58,080 - train - INFO - alphas:tensor([0.4605, 0.5395], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,080 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,080 - train - INFO - True
2024-04-03 09:02:58,081 - train - INFO - alphas:tensor([0.2852, 0.7148], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,081 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,081 - train - INFO - True
2024-04-03 09:02:58,082 - train - INFO - alphas:tensor([0.4323, 0.5677], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,082 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,082 - train - INFO - True
2024-04-03 09:02:58,087 - train - INFO - alphas:tensor([0.5803, 0.4197], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,087 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,087 - train - INFO - True
2024-04-03 09:02:58,088 - train - INFO - alphas:tensor([0.4468, 0.5532], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,092 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,092 - train - INFO - True
2024-04-03 09:02:58,093 - train - INFO - alphas:tensor([0.3004, 0.6996], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,093 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,093 - train - INFO - True
2024-04-03 09:02:58,094 - train - INFO - alphas:tensor([0.4257, 0.5743], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,094 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,094 - train - INFO - True
2024-04-03 09:02:58,095 - train - INFO - alphas:tensor([0.5197, 0.4803], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,095 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,095 - train - INFO - True
2024-04-03 09:02:58,095 - train - INFO - alphas:tensor([0.3707, 0.6293], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,095 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,096 - train - INFO - True
2024-04-03 09:02:58,096 - train - INFO - alphas:tensor([0.2692, 0.7308], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,096 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,096 - train - INFO - True
2024-04-03 09:02:58,097 - train - INFO - alphas:tensor([0.3339, 0.6661], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,106 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,106 - train - INFO - True
2024-04-03 09:02:58,107 - train - INFO - alphas:tensor([0.4163, 0.5837], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,107 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,107 - train - INFO - True
2024-04-03 09:02:58,107 - train - INFO - alphas:tensor([0.2407, 0.7593], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,108 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,108 - train - INFO - True
2024-04-03 09:02:58,108 - train - INFO - alphas:tensor([0.2128, 0.7872], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,108 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,108 - train - INFO - True
2024-04-03 09:02:58,109 - train - INFO - alphas:tensor([0.2600, 0.7400], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,109 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,109 - train - INFO - True
2024-04-03 09:02:58,110 - train - INFO - alphas:tensor([0.3654, 0.6346], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,114 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,114 - train - INFO - True
2024-04-03 09:02:58,115 - train - INFO - alphas:tensor([0.1513, 0.8487], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,115 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,115 - train - INFO - True
2024-04-03 09:02:58,116 - train - INFO - alphas:tensor([0.1453, 0.8547], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,116 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,116 - train - INFO - True
2024-04-03 09:02:58,117 - train - INFO - alphas:tensor([0.0395, 0.9605], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,121 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,121 - train - INFO - True
2024-04-03 09:02:58,122 - train - INFO - alphas:tensor([0.0419, 0.9581], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,122 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,122 - train - INFO - True
2024-04-03 09:02:58,123 - train - INFO - alphas:tensor([1.0450e-04, 9.9990e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,123 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,123 - train - INFO - True
2024-04-03 09:02:58,124 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:02:58,128 - train - INFO - tau:0.41294967113388825
2024-04-03 09:02:58,128 - train - INFO - avg block size:13.413793103448276
2024-04-03 09:02:59,274 - train - INFO - Test: [   0/39]  Time: 1.143 (1.143)  Loss:  0.3530 (0.3530)  Acc@1: 92.9688 (92.9688)  Acc@5: 99.2188 (99.2188)
2024-04-03 09:03:43,299 - train - INFO - Test: [  39/39]  Time: 1.173 (1.129)  Loss:  0.3745 (0.3580)  Acc@1: 87.5000 (92.1900)  Acc@5: 100.0000 (99.7200)
2024-04-03 09:03:45,671 - train - INFO - Train: 91 [   0/195 (  0%)]  Loss:  1.768968 (1.7690)  Time: 2.222s,  115.20/s  (2.222s,  115.20/s)  LR: 1.912e-04  Data: 0.337 (0.337)
2024-04-03 09:05:25,180 - train - INFO - Train: 91 [  50/195 ( 26%)]  Loss:  1.482117 (1.5516)  Time: 1.971s,  129.88/s  (1.995s,  128.34/s)  LR: 1.912e-04  Data: 0.009 (0.016)
2024-04-03 09:07:05,789 - train - INFO - Train: 91 [ 100/195 ( 52%)]  Loss:  1.795129 (1.5361)  Time: 1.829s,  139.95/s  (2.003s,  127.79/s)  LR: 1.912e-04  Data: 0.005 (0.013)
2024-04-03 09:08:43,225 - train - INFO - Train: 91 [ 150/195 ( 77%)]  Loss:  1.577099 (1.5484)  Time: 2.090s,  122.47/s  (1.985s,  128.95/s)  LR: 1.912e-04  Data: 0.011 (0.012)
2024-04-03 09:10:09,560 - train - INFO - Train: 91 [ 194/195 (100%)]  Loss:  1.603276 (1.5610)  Time: 1.798s,  142.39/s  (1.980s,  129.29/s)  LR: 1.912e-04  Data: 0.000 (0.011)
2024-04-03 09:10:09,560 - train - INFO - True
2024-04-03 09:10:09,561 - train - INFO - alphas:tensor([0.0049, 0.9951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,562 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,562 - train - INFO - True
2024-04-03 09:10:09,563 - train - INFO - alphas:tensor([0.0945, 0.9055], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,563 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,563 - train - INFO - True
2024-04-03 09:10:09,564 - train - INFO - alphas:tensor([0.5748, 0.4252], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,564 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,564 - train - INFO - True
2024-04-03 09:10:09,564 - train - INFO - alphas:tensor([0.4966, 0.5034], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,564 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,565 - train - INFO - True
2024-04-03 09:10:09,565 - train - INFO - alphas:tensor([0.1801, 0.8199], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,565 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,565 - train - INFO - True
2024-04-03 09:10:09,566 - train - INFO - alphas:tensor([0.2952, 0.7048], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,566 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,566 - train - INFO - True
2024-04-03 09:10:09,567 - train - INFO - alphas:tensor([0.5746, 0.4254], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,567 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,567 - train - INFO - True
2024-04-03 09:10:09,568 - train - INFO - alphas:tensor([0.4609, 0.5391], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,568 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,568 - train - INFO - True
2024-04-03 09:10:09,568 - train - INFO - alphas:tensor([0.2834, 0.7166], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,569 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,569 - train - INFO - True
2024-04-03 09:10:09,569 - train - INFO - alphas:tensor([0.4309, 0.5691], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,569 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,569 - train - INFO - True
2024-04-03 09:10:09,570 - train - INFO - alphas:tensor([0.5795, 0.4205], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,570 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,570 - train - INFO - True
2024-04-03 09:10:09,571 - train - INFO - alphas:tensor([0.4444, 0.5556], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,571 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,571 - train - INFO - True
2024-04-03 09:10:09,572 - train - INFO - alphas:tensor([0.3000, 0.7000], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,572 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,572 - train - INFO - True
2024-04-03 09:10:09,572 - train - INFO - alphas:tensor([0.4251, 0.5749], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,573 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,573 - train - INFO - True
2024-04-03 09:10:09,573 - train - INFO - alphas:tensor([0.5199, 0.4801], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,573 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,573 - train - INFO - True
2024-04-03 09:10:09,574 - train - INFO - alphas:tensor([0.3721, 0.6279], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,574 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,574 - train - INFO - True
2024-04-03 09:10:09,575 - train - INFO - alphas:tensor([0.2668, 0.7332], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,575 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,575 - train - INFO - True
2024-04-03 09:10:09,576 - train - INFO - alphas:tensor([0.3320, 0.6680], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,576 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,576 - train - INFO - True
2024-04-03 09:10:09,577 - train - INFO - alphas:tensor([0.4165, 0.5835], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,577 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,577 - train - INFO - True
2024-04-03 09:10:09,577 - train - INFO - alphas:tensor([0.2406, 0.7594], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,577 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,578 - train - INFO - True
2024-04-03 09:10:09,578 - train - INFO - alphas:tensor([0.2124, 0.7876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,578 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,578 - train - INFO - True
2024-04-03 09:10:09,579 - train - INFO - alphas:tensor([0.2588, 0.7412], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,579 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,579 - train - INFO - True
2024-04-03 09:10:09,580 - train - INFO - alphas:tensor([0.3637, 0.6363], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,580 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,580 - train - INFO - True
2024-04-03 09:10:09,581 - train - INFO - alphas:tensor([0.1490, 0.8510], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,581 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,581 - train - INFO - True
2024-04-03 09:10:09,581 - train - INFO - alphas:tensor([0.1446, 0.8554], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,581 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,582 - train - INFO - True
2024-04-03 09:10:09,582 - train - INFO - alphas:tensor([0.0376, 0.9624], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,582 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,582 - train - INFO - True
2024-04-03 09:10:09,583 - train - INFO - alphas:tensor([0.0403, 0.9597], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,583 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,583 - train - INFO - True
2024-04-03 09:10:09,584 - train - INFO - alphas:tensor([9.2368e-05, 9.9991e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,584 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,584 - train - INFO - True
2024-04-03 09:10:09,585 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:10:09,585 - train - INFO - tau:0.40882017442254937
2024-04-03 09:10:09,585 - train - INFO - avg block size:13.413793103448276
2024-04-03 09:10:10,700 - train - INFO - Test: [   0/39]  Time: 1.113 (1.113)  Loss:  0.3694 (0.3694)  Acc@1: 90.2344 (90.2344)  Acc@5: 100.0000 (100.0000)
2024-04-03 09:10:55,502 - train - INFO - Test: [  39/39]  Time: 1.154 (1.148)  Loss:  0.4092 (0.3573)  Acc@1: 81.2500 (92.4000)  Acc@5: 100.0000 (99.7600)
2024-04-03 09:10:57,795 - train - INFO - Train: 92 [   0/195 (  0%)]  Loss:  1.780228 (1.7802)  Time: 2.102s,  121.81/s  (2.102s,  121.81/s)  LR: 1.859e-04  Data: 0.233 (0.233)
2024-04-03 09:12:36,452 - train - INFO - Train: 92 [  50/195 ( 26%)]  Loss:  1.789794 (1.5674)  Time: 2.038s,  125.59/s  (1.976s,  129.58/s)  LR: 1.859e-04  Data: 0.018 (0.014)
2024-04-03 09:14:15,738 - train - INFO - Train: 92 [ 100/195 ( 52%)]  Loss:  1.585881 (1.5767)  Time: 2.062s,  124.15/s  (1.981s,  129.26/s)  LR: 1.859e-04  Data: 0.016 (0.012)
2024-04-03 09:15:55,883 - train - INFO - Train: 92 [ 150/195 ( 77%)]  Loss:  1.759338 (1.5465)  Time: 2.020s,  126.76/s  (1.988s,  128.78/s)  LR: 1.859e-04  Data: 0.009 (0.011)
2024-04-03 09:17:23,955 - train - INFO - Train: 92 [ 194/195 (100%)]  Loss:  1.506722 (1.5552)  Time: 2.005s,  127.66/s  (1.991s,  128.58/s)  LR: 1.859e-04  Data: 0.000 (0.010)
2024-04-03 09:17:23,956 - train - INFO - True
2024-04-03 09:17:23,961 - train - INFO - alphas:tensor([0.0045, 0.9955], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,961 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,961 - train - INFO - True
2024-04-03 09:17:23,962 - train - INFO - alphas:tensor([0.0938, 0.9062], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,962 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,962 - train - INFO - True
2024-04-03 09:17:23,963 - train - INFO - alphas:tensor([0.5748, 0.4252], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,963 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,963 - train - INFO - True
2024-04-03 09:17:23,964 - train - INFO - alphas:tensor([0.4960, 0.5040], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,964 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,964 - train - INFO - True
2024-04-03 09:17:23,965 - train - INFO - alphas:tensor([0.1781, 0.8219], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,965 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,965 - train - INFO - True
2024-04-03 09:17:23,966 - train - INFO - alphas:tensor([0.2923, 0.7077], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,966 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,966 - train - INFO - True
2024-04-03 09:17:23,967 - train - INFO - alphas:tensor([0.5730, 0.4270], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,967 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,967 - train - INFO - True
2024-04-03 09:17:23,972 - train - INFO - alphas:tensor([0.4588, 0.5412], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,972 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,972 - train - INFO - True
2024-04-03 09:17:23,973 - train - INFO - alphas:tensor([0.2829, 0.7171], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,973 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,973 - train - INFO - True
2024-04-03 09:17:23,973 - train - INFO - alphas:tensor([0.4322, 0.5678], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,974 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,974 - train - INFO - True
2024-04-03 09:17:23,974 - train - INFO - alphas:tensor([0.5782, 0.4218], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,974 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,974 - train - INFO - True
2024-04-03 09:17:23,975 - train - INFO - alphas:tensor([0.4422, 0.5578], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,975 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,975 - train - INFO - True
2024-04-03 09:17:23,976 - train - INFO - alphas:tensor([0.3002, 0.6998], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,976 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,976 - train - INFO - True
2024-04-03 09:17:23,977 - train - INFO - alphas:tensor([0.4268, 0.5732], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,977 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,977 - train - INFO - True
2024-04-03 09:17:23,978 - train - INFO - alphas:tensor([0.5186, 0.4814], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,978 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,978 - train - INFO - True
2024-04-03 09:17:23,978 - train - INFO - alphas:tensor([0.3705, 0.6295], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,978 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,978 - train - INFO - True
2024-04-03 09:17:23,979 - train - INFO - alphas:tensor([0.2662, 0.7338], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,979 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,979 - train - INFO - True
2024-04-03 09:17:23,980 - train - INFO - alphas:tensor([0.3328, 0.6672], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,980 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,980 - train - INFO - True
2024-04-03 09:17:23,981 - train - INFO - alphas:tensor([0.4138, 0.5862], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,981 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,981 - train - INFO - True
2024-04-03 09:17:23,982 - train - INFO - alphas:tensor([0.2386, 0.7614], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,982 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,982 - train - INFO - True
2024-04-03 09:17:23,982 - train - INFO - alphas:tensor([0.2101, 0.7899], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,982 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,983 - train - INFO - True
2024-04-03 09:17:23,983 - train - INFO - alphas:tensor([0.2578, 0.7422], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,983 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,983 - train - INFO - True
2024-04-03 09:17:23,984 - train - INFO - alphas:tensor([0.3630, 0.6370], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,984 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,984 - train - INFO - True
2024-04-03 09:17:23,985 - train - INFO - alphas:tensor([0.1471, 0.8529], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,985 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,985 - train - INFO - True
2024-04-03 09:17:23,986 - train - INFO - alphas:tensor([0.1424, 0.8576], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,986 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,986 - train - INFO - True
2024-04-03 09:17:23,986 - train - INFO - alphas:tensor([0.0352, 0.9648], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,987 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,987 - train - INFO - True
2024-04-03 09:17:23,987 - train - INFO - alphas:tensor([0.0390, 0.9610], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,987 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,987 - train - INFO - True
2024-04-03 09:17:23,988 - train - INFO - alphas:tensor([8.1613e-05, 9.9992e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,988 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,988 - train - INFO - True
2024-04-03 09:17:23,989 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:17:23,989 - train - INFO - tau:0.4047319726783239
2024-04-03 09:17:23,989 - train - INFO - avg block size:13.413793103448276
2024-04-03 09:17:25,130 - train - INFO - Test: [   0/39]  Time: 1.139 (1.139)  Loss:  0.3711 (0.3711)  Acc@1: 93.3594 (93.3594)  Acc@5: 99.2188 (99.2188)
2024-04-03 09:18:09,663 - train - INFO - Test: [  39/39]  Time: 1.145 (1.142)  Loss:  0.4333 (0.3746)  Acc@1: 81.2500 (92.3300)  Acc@5: 100.0000 (99.6900)
2024-04-03 09:18:11,880 - train - INFO - Train: 93 [   0/195 (  0%)]  Loss:  1.523642 (1.5236)  Time: 2.043s,  125.30/s  (2.043s,  125.30/s)  LR: 1.806e-04  Data: 0.190 (0.190)
2024-04-03 09:19:50,929 - train - INFO - Train: 93 [  50/195 ( 26%)]  Loss:  1.634714 (1.5614)  Time: 2.012s,  127.23/s  (1.982s,  129.15/s)  LR: 1.806e-04  Data: 0.005 (0.013)
2024-04-03 09:21:32,641 - train - INFO - Train: 93 [ 100/195 ( 52%)]  Loss:  1.411975 (1.5541)  Time: 2.078s,  123.18/s  (2.008s,  127.49/s)  LR: 1.806e-04  Data: 0.006 (0.011)
2024-04-03 09:23:14,064 - train - INFO - Train: 93 [ 150/195 ( 77%)]  Loss:  1.655131 (1.5586)  Time: 2.140s,  119.63/s  (2.015s,  127.06/s)  LR: 1.806e-04  Data: 0.018 (0.011)
2024-04-03 09:24:40,746 - train - INFO - Train: 93 [ 194/195 (100%)]  Loss:  1.320909 (1.5486)  Time: 1.854s,  138.12/s  (2.005s,  127.70/s)  LR: 1.806e-04  Data: 0.000 (0.010)
2024-04-03 09:24:40,746 - train - INFO - True
2024-04-03 09:24:40,748 - train - INFO - alphas:tensor([0.0041, 0.9959], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,748 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,748 - train - INFO - True
2024-04-03 09:24:40,749 - train - INFO - alphas:tensor([0.0931, 0.9069], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,749 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,749 - train - INFO - True
2024-04-03 09:24:40,750 - train - INFO - alphas:tensor([0.5738, 0.4262], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,750 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,750 - train - INFO - True
2024-04-03 09:24:40,751 - train - INFO - alphas:tensor([0.4945, 0.5055], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,751 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,751 - train - INFO - True
2024-04-03 09:24:40,752 - train - INFO - alphas:tensor([0.1777, 0.8223], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,752 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,752 - train - INFO - True
2024-04-03 09:24:40,752 - train - INFO - alphas:tensor([0.2918, 0.7082], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,753 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,753 - train - INFO - True
2024-04-03 09:24:40,753 - train - INFO - alphas:tensor([0.5724, 0.4276], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,753 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,753 - train - INFO - True
2024-04-03 09:24:40,754 - train - INFO - alphas:tensor([0.4593, 0.5407], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,755 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,755 - train - INFO - True
2024-04-03 09:24:40,755 - train - INFO - alphas:tensor([0.2817, 0.7183], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,755 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,756 - train - INFO - True
2024-04-03 09:24:40,756 - train - INFO - alphas:tensor([0.4305, 0.5695], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,756 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,756 - train - INFO - True
2024-04-03 09:24:40,757 - train - INFO - alphas:tensor([0.5787, 0.4213], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,757 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,757 - train - INFO - True
2024-04-03 09:24:40,758 - train - INFO - alphas:tensor([0.4423, 0.5577], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,758 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,758 - train - INFO - True
2024-04-03 09:24:40,759 - train - INFO - alphas:tensor([0.2970, 0.7030], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,759 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,759 - train - INFO - True
2024-04-03 09:24:40,759 - train - INFO - alphas:tensor([0.4221, 0.5779], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,760 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,760 - train - INFO - True
2024-04-03 09:24:40,760 - train - INFO - alphas:tensor([0.5184, 0.4816], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,760 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,760 - train - INFO - True
2024-04-03 09:24:40,761 - train - INFO - alphas:tensor([0.3705, 0.6295], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,761 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,761 - train - INFO - True
2024-04-03 09:24:40,762 - train - INFO - alphas:tensor([0.2635, 0.7365], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,762 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,762 - train - INFO - True
2024-04-03 09:24:40,763 - train - INFO - alphas:tensor([0.3294, 0.6706], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,763 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,763 - train - INFO - True
2024-04-03 09:24:40,764 - train - INFO - alphas:tensor([0.4131, 0.5869], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,764 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,764 - train - INFO - True
2024-04-03 09:24:40,764 - train - INFO - alphas:tensor([0.2366, 0.7634], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,764 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,765 - train - INFO - True
2024-04-03 09:24:40,765 - train - INFO - alphas:tensor([0.2105, 0.7895], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,765 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,765 - train - INFO - True
2024-04-03 09:24:40,766 - train - INFO - alphas:tensor([0.2583, 0.7417], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,766 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,766 - train - INFO - True
2024-04-03 09:24:40,767 - train - INFO - alphas:tensor([0.3608, 0.6392], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,767 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,767 - train - INFO - True
2024-04-03 09:24:40,768 - train - INFO - alphas:tensor([0.1459, 0.8541], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,768 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,768 - train - INFO - True
2024-04-03 09:24:40,768 - train - INFO - alphas:tensor([0.1420, 0.8580], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,769 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,769 - train - INFO - True
2024-04-03 09:24:40,769 - train - INFO - alphas:tensor([0.0336, 0.9664], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,774 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,774 - train - INFO - True
2024-04-03 09:24:40,775 - train - INFO - alphas:tensor([0.0374, 0.9626], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,775 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,775 - train - INFO - True
2024-04-03 09:24:40,776 - train - INFO - alphas:tensor([7.2096e-05, 9.9993e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,776 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,776 - train - INFO - True
2024-04-03 09:24:40,776 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:24:40,777 - train - INFO - tau:0.40068465295154065
2024-04-03 09:24:40,777 - train - INFO - avg block size:13.413793103448276
2024-04-03 09:24:41,977 - train - INFO - Test: [   0/39]  Time: 1.198 (1.198)  Loss:  0.3662 (0.3662)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-03 09:25:26,453 - train - INFO - Test: [  39/39]  Time: 1.147 (1.142)  Loss:  0.4055 (0.3572)  Acc@1: 93.7500 (92.6000)  Acc@5: 100.0000 (99.8000)
2024-04-03 09:25:28,934 - train - INFO - Train: 94 [   0/195 (  0%)]  Loss:  1.539637 (1.5396)  Time: 2.222s,  115.21/s  (2.222s,  115.21/s)  LR: 1.754e-04  Data: 0.300 (0.300)
2024-04-03 09:27:07,478 - train - INFO - Train: 94 [  50/195 ( 26%)]  Loss:  1.287726 (1.5583)  Time: 1.983s,  129.07/s  (1.976s,  129.57/s)  LR: 1.754e-04  Data: 0.015 (0.015)
2024-04-03 09:28:48,144 - train - INFO - Train: 94 [ 100/195 ( 52%)]  Loss:  1.198299 (1.5619)  Time: 1.882s,  136.02/s  (1.994s,  128.36/s)  LR: 1.754e-04  Data: 0.005 (0.013)
2024-04-03 09:30:28,831 - train - INFO - Train: 94 [ 150/195 ( 77%)]  Loss:  1.500592 (1.5695)  Time: 2.069s,  123.72/s  (2.001s,  127.95/s)  LR: 1.754e-04  Data: 0.005 (0.012)
2024-04-03 09:31:55,351 - train - INFO - Train: 94 [ 194/195 (100%)]  Loss:  1.402458 (1.5553)  Time: 1.829s,  140.01/s  (1.993s,  128.45/s)  LR: 1.754e-04  Data: 0.000 (0.011)
2024-04-03 09:31:55,352 - train - INFO - True
2024-04-03 09:31:55,353 - train - INFO - alphas:tensor([0.0038, 0.9962], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,353 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,353 - train - INFO - True
2024-04-03 09:31:55,354 - train - INFO - alphas:tensor([0.0920, 0.9080], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,354 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,354 - train - INFO - True
2024-04-03 09:31:55,354 - train - INFO - alphas:tensor([0.5725, 0.4275], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,355 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,355 - train - INFO - True
2024-04-03 09:31:55,355 - train - INFO - alphas:tensor([0.4937, 0.5063], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,355 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,355 - train - INFO - True
2024-04-03 09:31:55,356 - train - INFO - alphas:tensor([0.1761, 0.8239], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,356 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,356 - train - INFO - True
2024-04-03 09:31:55,357 - train - INFO - alphas:tensor([0.2902, 0.7098], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,357 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,357 - train - INFO - True
2024-04-03 09:31:55,358 - train - INFO - alphas:tensor([0.5706, 0.4294], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,358 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,358 - train - INFO - True
2024-04-03 09:31:55,359 - train - INFO - alphas:tensor([0.4585, 0.5415], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,359 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,359 - train - INFO - True
2024-04-03 09:31:55,359 - train - INFO - alphas:tensor([0.2812, 0.7188], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,360 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,360 - train - INFO - True
2024-04-03 09:31:55,360 - train - INFO - alphas:tensor([0.4304, 0.5696], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,361 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,361 - train - INFO - True
2024-04-03 09:31:55,361 - train - INFO - alphas:tensor([0.5784, 0.4216], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,362 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,362 - train - INFO - True
2024-04-03 09:31:55,362 - train - INFO - alphas:tensor([0.4424, 0.5576], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,362 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,362 - train - INFO - True
2024-04-03 09:31:55,363 - train - INFO - alphas:tensor([0.2970, 0.7030], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,363 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,363 - train - INFO - True
2024-04-03 09:31:55,364 - train - INFO - alphas:tensor([0.4227, 0.5773], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,364 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,364 - train - INFO - True
2024-04-03 09:31:55,365 - train - INFO - alphas:tensor([0.5172, 0.4828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,365 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,365 - train - INFO - True
2024-04-03 09:31:55,366 - train - INFO - alphas:tensor([0.3693, 0.6307], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,366 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,366 - train - INFO - True
2024-04-03 09:31:55,366 - train - INFO - alphas:tensor([0.2642, 0.7358], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,366 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,367 - train - INFO - True
2024-04-03 09:31:55,367 - train - INFO - alphas:tensor([0.3313, 0.6687], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,367 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,367 - train - INFO - True
2024-04-03 09:31:55,368 - train - INFO - alphas:tensor([0.4129, 0.5871], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,368 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,368 - train - INFO - True
2024-04-03 09:31:55,369 - train - INFO - alphas:tensor([0.2363, 0.7637], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,369 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,369 - train - INFO - True
2024-04-03 09:31:55,370 - train - INFO - alphas:tensor([0.2075, 0.7925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,370 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,370 - train - INFO - True
2024-04-03 09:31:55,370 - train - INFO - alphas:tensor([0.2549, 0.7451], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,371 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,371 - train - INFO - True
2024-04-03 09:31:55,371 - train - INFO - alphas:tensor([0.3609, 0.6391], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,371 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,371 - train - INFO - True
2024-04-03 09:31:55,372 - train - INFO - alphas:tensor([0.1446, 0.8554], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,372 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,372 - train - INFO - True
2024-04-03 09:31:55,373 - train - INFO - alphas:tensor([0.1412, 0.8588], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,373 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,373 - train - INFO - True
2024-04-03 09:31:55,374 - train - INFO - alphas:tensor([0.0319, 0.9681], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,374 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,374 - train - INFO - True
2024-04-03 09:31:55,375 - train - INFO - alphas:tensor([0.0363, 0.9637], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,375 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,375 - train - INFO - True
2024-04-03 09:31:55,375 - train - INFO - alphas:tensor([6.3692e-05, 9.9994e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,375 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,376 - train - INFO - True
2024-04-03 09:31:55,376 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:31:55,376 - train - INFO - tau:0.39667780642202527
2024-04-03 09:31:55,376 - train - INFO - avg block size:13.413793103448276
2024-04-03 09:31:56,538 - train - INFO - Test: [   0/39]  Time: 1.159 (1.159)  Loss:  0.3545 (0.3545)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 09:32:41,744 - train - INFO - Test: [  39/39]  Time: 1.162 (1.159)  Loss:  0.4438 (0.3556)  Acc@1: 87.5000 (92.4500)  Acc@5: 100.0000 (99.7700)
2024-04-03 09:32:44,052 - train - INFO - Train: 95 [   0/195 (  0%)]  Loss:  1.216117 (1.2161)  Time: 2.187s,  117.05/s  (2.187s,  117.05/s)  LR: 1.702e-04  Data: 0.257 (0.257)
2024-04-03 09:34:21,425 - train - INFO - Train: 95 [  50/195 ( 26%)]  Loss:  1.239063 (1.5547)  Time: 1.975s,  129.60/s  (1.952s,  131.14/s)  LR: 1.702e-04  Data: 0.005 (0.014)
2024-04-03 09:36:00,717 - train - INFO - Train: 95 [ 100/195 ( 52%)]  Loss:  1.570204 (1.5440)  Time: 1.931s,  132.55/s  (1.969s,  130.03/s)  LR: 1.702e-04  Data: 0.006 (0.012)
2024-04-03 09:37:39,793 - train - INFO - Train: 95 [ 150/195 ( 77%)]  Loss:  1.719316 (1.5240)  Time: 2.092s,  122.37/s  (1.973s,  129.75/s)  LR: 1.702e-04  Data: 0.014 (0.011)
2024-04-03 09:39:08,741 - train - INFO - Train: 95 [ 194/195 (100%)]  Loss:  1.332892 (1.5305)  Time: 1.890s,  135.42/s  (1.984s,  129.04/s)  LR: 1.702e-04  Data: 0.000 (0.010)
2024-04-03 09:39:08,742 - train - INFO - True
2024-04-03 09:39:08,743 - train - INFO - alphas:tensor([0.0035, 0.9965], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,743 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,743 - train - INFO - True
2024-04-03 09:39:08,744 - train - INFO - alphas:tensor([0.0912, 0.9088], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,744 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,744 - train - INFO - True
2024-04-03 09:39:08,745 - train - INFO - alphas:tensor([0.5728, 0.4272], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,745 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,745 - train - INFO - True
2024-04-03 09:39:08,746 - train - INFO - alphas:tensor([0.4934, 0.5066], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,746 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,746 - train - INFO - True
2024-04-03 09:39:08,747 - train - INFO - alphas:tensor([0.1740, 0.8260], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,747 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,747 - train - INFO - True
2024-04-03 09:39:08,748 - train - INFO - alphas:tensor([0.2890, 0.7110], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,748 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,748 - train - INFO - True
2024-04-03 09:39:08,748 - train - INFO - alphas:tensor([0.5707, 0.4293], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,749 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,749 - train - INFO - True
2024-04-03 09:39:08,750 - train - INFO - alphas:tensor([0.4579, 0.5421], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,750 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,750 - train - INFO - True
2024-04-03 09:39:08,751 - train - INFO - alphas:tensor([0.2799, 0.7201], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,751 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,751 - train - INFO - True
2024-04-03 09:39:08,751 - train - INFO - alphas:tensor([0.4295, 0.5705], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,751 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,752 - train - INFO - True
2024-04-03 09:39:08,752 - train - INFO - alphas:tensor([0.5755, 0.4245], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,752 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,752 - train - INFO - True
2024-04-03 09:39:08,753 - train - INFO - alphas:tensor([0.4404, 0.5596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,753 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,753 - train - INFO - True
2024-04-03 09:39:08,754 - train - INFO - alphas:tensor([0.2950, 0.7050], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,754 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,754 - train - INFO - True
2024-04-03 09:39:08,755 - train - INFO - alphas:tensor([0.4200, 0.5800], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,755 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,755 - train - INFO - True
2024-04-03 09:39:08,755 - train - INFO - alphas:tensor([0.5171, 0.4829], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,756 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,756 - train - INFO - True
2024-04-03 09:39:08,756 - train - INFO - alphas:tensor([0.3688, 0.6312], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,756 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,756 - train - INFO - True
2024-04-03 09:39:08,757 - train - INFO - alphas:tensor([0.2633, 0.7367], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,757 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,757 - train - INFO - True
2024-04-03 09:39:08,758 - train - INFO - alphas:tensor([0.3297, 0.6703], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,758 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,758 - train - INFO - True
2024-04-03 09:39:08,759 - train - INFO - alphas:tensor([0.4112, 0.5888], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,759 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,759 - train - INFO - True
2024-04-03 09:39:08,760 - train - INFO - alphas:tensor([0.2335, 0.7665], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,760 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,760 - train - INFO - True
2024-04-03 09:39:08,760 - train - INFO - alphas:tensor([0.2072, 0.7928], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,760 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,760 - train - INFO - True
2024-04-03 09:39:08,761 - train - INFO - alphas:tensor([0.2541, 0.7459], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,761 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,761 - train - INFO - True
2024-04-03 09:39:08,762 - train - INFO - alphas:tensor([0.3607, 0.6393], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,762 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,762 - train - INFO - True
2024-04-03 09:39:08,763 - train - INFO - alphas:tensor([0.1433, 0.8567], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,763 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,763 - train - INFO - True
2024-04-03 09:39:08,764 - train - INFO - alphas:tensor([0.1407, 0.8593], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,764 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,764 - train - INFO - True
2024-04-03 09:39:08,764 - train - INFO - alphas:tensor([0.0303, 0.9697], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,764 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,765 - train - INFO - True
2024-04-03 09:39:08,765 - train - INFO - alphas:tensor([0.0353, 0.9647], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,765 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,765 - train - INFO - True
2024-04-03 09:39:08,766 - train - INFO - alphas:tensor([5.6257e-05, 9.9994e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,766 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,766 - train - INFO - True
2024-04-03 09:39:08,767 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:39:08,767 - train - INFO - tau:0.392711028357805
2024-04-03 09:39:08,767 - train - INFO - avg block size:13.413793103448276
2024-04-03 09:39:09,920 - train - INFO - Test: [   0/39]  Time: 1.150 (1.150)  Loss:  0.3574 (0.3574)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-03 09:39:53,560 - train - INFO - Test: [  39/39]  Time: 1.146 (1.120)  Loss:  0.3550 (0.3678)  Acc@1: 87.5000 (92.4200)  Acc@5: 100.0000 (99.7100)
2024-04-03 09:39:55,746 - train - INFO - Train: 96 [   0/195 (  0%)]  Loss:  1.199614 (1.1996)  Time: 1.999s,  128.05/s  (1.999s,  128.05/s)  LR: 1.650e-04  Data: 0.162 (0.162)
2024-04-03 09:41:35,724 - train - INFO - Train: 96 [  50/195 ( 26%)]  Loss:  1.707612 (1.5635)  Time: 2.252s,  113.69/s  (2.000s,  128.03/s)  LR: 1.650e-04  Data: 0.005 (0.013)
2024-04-03 09:43:15,705 - train - INFO - Train: 96 [ 100/195 ( 52%)]  Loss:  1.766510 (1.5399)  Time: 2.223s,  115.18/s  (2.000s,  128.03/s)  LR: 1.650e-04  Data: 0.005 (0.011)
2024-04-03 09:44:54,829 - train - INFO - Train: 96 [ 150/195 ( 77%)]  Loss:  1.793739 (1.5586)  Time: 1.837s,  139.35/s  (1.994s,  128.39/s)  LR: 1.650e-04  Data: 0.010 (0.011)
2024-04-03 09:46:21,339 - train - INFO - Train: 96 [ 194/195 (100%)]  Loss:  1.389286 (1.5525)  Time: 2.298s,  111.39/s  (1.988s,  128.80/s)  LR: 1.650e-04  Data: 0.000 (0.011)
2024-04-03 09:46:21,340 - train - INFO - True
2024-04-03 09:46:21,341 - train - INFO - alphas:tensor([0.0032, 0.9968], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,341 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,341 - train - INFO - True
2024-04-03 09:46:21,342 - train - INFO - alphas:tensor([0.0901, 0.9099], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,342 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,342 - train - INFO - True
2024-04-03 09:46:21,342 - train - INFO - alphas:tensor([0.5723, 0.4277], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,343 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,343 - train - INFO - True
2024-04-03 09:46:21,343 - train - INFO - alphas:tensor([0.4917, 0.5083], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,343 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,343 - train - INFO - True
2024-04-03 09:46:21,344 - train - INFO - alphas:tensor([0.1730, 0.8270], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,344 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,344 - train - INFO - True
2024-04-03 09:46:21,345 - train - INFO - alphas:tensor([0.2865, 0.7135], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,345 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,345 - train - INFO - True
2024-04-03 09:46:21,346 - train - INFO - alphas:tensor([0.5698, 0.4302], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,346 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,346 - train - INFO - True
2024-04-03 09:46:21,347 - train - INFO - alphas:tensor([0.4567, 0.5433], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,347 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,347 - train - INFO - True
2024-04-03 09:46:21,347 - train - INFO - alphas:tensor([0.2781, 0.7219], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,348 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,348 - train - INFO - True
2024-04-03 09:46:21,349 - train - INFO - alphas:tensor([0.4265, 0.5735], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,349 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,349 - train - INFO - True
2024-04-03 09:46:21,350 - train - INFO - alphas:tensor([0.5741, 0.4259], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,350 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,350 - train - INFO - True
2024-04-03 09:46:21,350 - train - INFO - alphas:tensor([0.4384, 0.5616], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,350 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,351 - train - INFO - True
2024-04-03 09:46:21,351 - train - INFO - alphas:tensor([0.2943, 0.7057], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,351 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,351 - train - INFO - True
2024-04-03 09:46:21,352 - train - INFO - alphas:tensor([0.4200, 0.5800], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,352 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,352 - train - INFO - True
2024-04-03 09:46:21,353 - train - INFO - alphas:tensor([0.5166, 0.4834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,353 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,353 - train - INFO - True
2024-04-03 09:46:21,354 - train - INFO - alphas:tensor([0.3685, 0.6315], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,354 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,354 - train - INFO - True
2024-04-03 09:46:21,354 - train - INFO - alphas:tensor([0.2625, 0.7375], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,354 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,355 - train - INFO - True
2024-04-03 09:46:21,355 - train - INFO - alphas:tensor([0.3297, 0.6703], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,355 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,355 - train - INFO - True
2024-04-03 09:46:21,356 - train - INFO - alphas:tensor([0.4088, 0.5912], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,356 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,356 - train - INFO - True
2024-04-03 09:46:21,357 - train - INFO - alphas:tensor([0.2317, 0.7683], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,357 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,357 - train - INFO - True
2024-04-03 09:46:21,358 - train - INFO - alphas:tensor([0.2062, 0.7938], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,358 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,358 - train - INFO - True
2024-04-03 09:46:21,358 - train - INFO - alphas:tensor([0.2535, 0.7465], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,358 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,359 - train - INFO - True
2024-04-03 09:46:21,359 - train - INFO - alphas:tensor([0.3584, 0.6416], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,359 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,359 - train - INFO - True
2024-04-03 09:46:21,360 - train - INFO - alphas:tensor([0.1402, 0.8598], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,360 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,360 - train - INFO - True
2024-04-03 09:46:21,361 - train - INFO - alphas:tensor([0.1403, 0.8597], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,361 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,361 - train - INFO - True
2024-04-03 09:46:21,362 - train - INFO - alphas:tensor([0.0288, 0.9712], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,362 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,362 - train - INFO - True
2024-04-03 09:46:21,362 - train - INFO - alphas:tensor([0.0341, 0.9659], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,363 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,363 - train - INFO - True
2024-04-03 09:46:21,363 - train - INFO - alphas:tensor([4.9670e-05, 9.9995e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,363 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,363 - train - INFO - True
2024-04-03 09:46:21,364 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:46:21,364 - train - INFO - tau:0.38878391807422696
2024-04-03 09:46:21,364 - train - INFO - avg block size:13.413793103448276
2024-04-03 09:46:22,522 - train - INFO - Test: [   0/39]  Time: 1.154 (1.154)  Loss:  0.3528 (0.3528)  Acc@1: 92.9688 (92.9688)  Acc@5: 99.6094 (99.6094)
2024-04-03 09:47:06,225 - train - INFO - Test: [  39/39]  Time: 1.073 (1.121)  Loss:  0.4546 (0.3505)  Acc@1: 81.2500 (92.5600)  Acc@5: 100.0000 (99.7600)
2024-04-03 09:47:08,330 - train - INFO - Train: 97 [   0/195 (  0%)]  Loss:  1.769868 (1.7699)  Time: 1.958s,  130.71/s  (1.958s,  130.71/s)  LR: 1.599e-04  Data: 0.131 (0.131)
2024-04-03 09:48:48,481 - train - INFO - Train: 97 [  50/195 ( 26%)]  Loss:  1.200723 (1.5267)  Time: 2.011s,  127.31/s  (2.002s,  127.86/s)  LR: 1.599e-04  Data: 0.005 (0.012)
2024-04-03 09:50:28,426 - train - INFO - Train: 97 [ 100/195 ( 52%)]  Loss:  1.646858 (1.5472)  Time: 1.979s,  129.35/s  (2.001s,  127.97/s)  LR: 1.599e-04  Data: 0.014 (0.011)
2024-04-03 09:52:06,931 - train - INFO - Train: 97 [ 150/195 ( 77%)]  Loss:  1.203508 (1.5350)  Time: 1.908s,  134.18/s  (1.990s,  128.61/s)  LR: 1.599e-04  Data: 0.010 (0.010)
2024-04-03 09:53:35,937 - train - INFO - Train: 97 [ 194/195 (100%)]  Loss:  1.430998 (1.5371)  Time: 1.901s,  134.67/s  (1.998s,  128.14/s)  LR: 1.599e-04  Data: 0.000 (0.010)
2024-04-03 09:53:35,937 - train - INFO - True
2024-04-03 09:53:35,939 - train - INFO - alphas:tensor([0.0029, 0.9971], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,939 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,939 - train - INFO - True
2024-04-03 09:53:35,940 - train - INFO - alphas:tensor([0.0886, 0.9114], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,940 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,940 - train - INFO - True
2024-04-03 09:53:35,940 - train - INFO - alphas:tensor([0.5718, 0.4282], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,940 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,940 - train - INFO - True
2024-04-03 09:53:35,941 - train - INFO - alphas:tensor([0.4919, 0.5081], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,941 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,941 - train - INFO - True
2024-04-03 09:53:35,942 - train - INFO - alphas:tensor([0.1721, 0.8279], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,942 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,942 - train - INFO - True
2024-04-03 09:53:35,943 - train - INFO - alphas:tensor([0.2859, 0.7141], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,943 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,943 - train - INFO - True
2024-04-03 09:53:35,944 - train - INFO - alphas:tensor([0.5690, 0.4310], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,944 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,944 - train - INFO - True
2024-04-03 09:53:35,944 - train - INFO - alphas:tensor([0.4542, 0.5458], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,944 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,945 - train - INFO - True
2024-04-03 09:53:35,946 - train - INFO - alphas:tensor([0.2784, 0.7216], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,949 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,949 - train - INFO - True
2024-04-03 09:53:35,950 - train - INFO - alphas:tensor([0.4269, 0.5731], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,950 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,950 - train - INFO - True
2024-04-03 09:53:35,951 - train - INFO - alphas:tensor([0.5744, 0.4256], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,951 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,951 - train - INFO - True
2024-04-03 09:53:35,952 - train - INFO - alphas:tensor([0.4390, 0.5610], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,952 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,952 - train - INFO - True
2024-04-03 09:53:35,952 - train - INFO - alphas:tensor([0.2943, 0.7057], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,952 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,953 - train - INFO - True
2024-04-03 09:53:35,954 - train - INFO - alphas:tensor([0.4194, 0.5806], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,954 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,954 - train - INFO - True
2024-04-03 09:53:35,955 - train - INFO - alphas:tensor([0.5158, 0.4842], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,955 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,955 - train - INFO - True
2024-04-03 09:53:35,955 - train - INFO - alphas:tensor([0.3682, 0.6318], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,955 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,955 - train - INFO - True
2024-04-03 09:53:35,956 - train - INFO - alphas:tensor([0.2598, 0.7402], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,956 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,956 - train - INFO - True
2024-04-03 09:53:35,957 - train - INFO - alphas:tensor([0.3273, 0.6727], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,957 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,957 - train - INFO - True
2024-04-03 09:53:35,958 - train - INFO - alphas:tensor([0.4089, 0.5911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,962 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,962 - train - INFO - True
2024-04-03 09:53:35,963 - train - INFO - alphas:tensor([0.2313, 0.7687], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,963 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,963 - train - INFO - True
2024-04-03 09:53:35,964 - train - INFO - alphas:tensor([0.2051, 0.7949], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,964 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,964 - train - INFO - True
2024-04-03 09:53:35,965 - train - INFO - alphas:tensor([0.2526, 0.7474], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,965 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,965 - train - INFO - True
2024-04-03 09:53:35,965 - train - INFO - alphas:tensor([0.3558, 0.6442], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,966 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,966 - train - INFO - True
2024-04-03 09:53:35,966 - train - INFO - alphas:tensor([0.1377, 0.8623], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,966 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,966 - train - INFO - True
2024-04-03 09:53:35,967 - train - INFO - alphas:tensor([0.1390, 0.8610], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,967 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,967 - train - INFO - True
2024-04-03 09:53:35,968 - train - INFO - alphas:tensor([0.0271, 0.9729], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,968 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,968 - train - INFO - True
2024-04-03 09:53:35,969 - train - INFO - alphas:tensor([0.0331, 0.9669], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,969 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,969 - train - INFO - True
2024-04-03 09:53:35,969 - train - INFO - alphas:tensor([4.3838e-05, 9.9996e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,970 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,970 - train - INFO - True
2024-04-03 09:53:35,970 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 09:53:35,970 - train - INFO - tau:0.3848960788934847
2024-04-03 09:53:35,970 - train - INFO - avg block size:13.413793103448276
2024-04-03 09:53:37,151 - train - INFO - Test: [   0/39]  Time: 1.174 (1.174)  Loss:  0.3679 (0.3679)  Acc@1: 92.5781 (92.5781)  Acc@5: 99.6094 (99.6094)
2024-04-03 09:54:24,289 - train - INFO - Test: [  39/39]  Time: 1.123 (1.208)  Loss:  0.3621 (0.3668)  Acc@1: 87.5000 (92.1900)  Acc@5: 100.0000 (99.7300)
2024-04-03 09:54:26,843 - train - INFO - Train: 98 [   0/195 (  0%)]  Loss:  1.781399 (1.7814)  Time: 2.342s,  109.31/s  (2.342s,  109.31/s)  LR: 1.549e-04  Data: 0.266 (0.266)
2024-04-03 09:56:06,049 - train - INFO - Train: 98 [  50/195 ( 26%)]  Loss:  1.413795 (1.5500)  Time: 1.872s,  136.78/s  (1.991s,  128.57/s)  LR: 1.549e-04  Data: 0.010 (0.014)
2024-04-03 09:57:44,875 - train - INFO - Train: 98 [ 100/195 ( 52%)]  Loss:  1.720679 (1.5451)  Time: 2.029s,  126.14/s  (1.984s,  129.04/s)  LR: 1.549e-04  Data: 0.006 (0.012)
2024-04-03 09:59:24,146 - train - INFO - Train: 98 [ 150/195 ( 77%)]  Loss:  1.724000 (1.5424)  Time: 2.101s,  121.84/s  (1.984s,  129.01/s)  LR: 1.549e-04  Data: 0.010 (0.011)
2024-04-03 10:00:52,405 - train - INFO - Train: 98 [ 194/195 (100%)]  Loss:  1.264436 (1.5495)  Time: 1.788s,  143.21/s  (1.989s,  128.69/s)  LR: 1.549e-04  Data: 0.000 (0.010)
2024-04-03 10:00:52,406 - train - INFO - True
2024-04-03 10:00:52,407 - train - INFO - alphas:tensor([0.0027, 0.9973], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,407 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,407 - train - INFO - True
2024-04-03 10:00:52,408 - train - INFO - alphas:tensor([0.0881, 0.9119], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,408 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,408 - train - INFO - True
2024-04-03 10:00:52,409 - train - INFO - alphas:tensor([0.5706, 0.4294], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,409 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,409 - train - INFO - True
2024-04-03 10:00:52,409 - train - INFO - alphas:tensor([0.4897, 0.5103], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,409 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,410 - train - INFO - True
2024-04-03 10:00:52,410 - train - INFO - alphas:tensor([0.1704, 0.8296], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,410 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,410 - train - INFO - True
2024-04-03 10:00:52,411 - train - INFO - alphas:tensor([0.2852, 0.7148], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,411 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,411 - train - INFO - True
2024-04-03 10:00:52,412 - train - INFO - alphas:tensor([0.5683, 0.4317], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,412 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,412 - train - INFO - True
2024-04-03 10:00:52,413 - train - INFO - alphas:tensor([0.4537, 0.5463], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,413 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,413 - train - INFO - True
2024-04-03 10:00:52,414 - train - INFO - alphas:tensor([0.2770, 0.7230], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,414 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,414 - train - INFO - True
2024-04-03 10:00:52,415 - train - INFO - alphas:tensor([0.4260, 0.5740], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,415 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,415 - train - INFO - True
2024-04-03 10:00:52,416 - train - INFO - alphas:tensor([0.5733, 0.4267], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,416 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,416 - train - INFO - True
2024-04-03 10:00:52,418 - train - INFO - alphas:tensor([0.4374, 0.5626], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,418 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,418 - train - INFO - True
2024-04-03 10:00:52,420 - train - INFO - alphas:tensor([0.2920, 0.7080], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,420 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,420 - train - INFO - True
2024-04-03 10:00:52,422 - train - INFO - alphas:tensor([0.4186, 0.5814], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,422 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,422 - train - INFO - True
2024-04-03 10:00:52,424 - train - INFO - alphas:tensor([0.5148, 0.4852], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,424 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,424 - train - INFO - True
2024-04-03 10:00:52,424 - train - INFO - alphas:tensor([0.3655, 0.6345], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,424 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,425 - train - INFO - True
2024-04-03 10:00:52,425 - train - INFO - alphas:tensor([0.2590, 0.7410], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,425 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,425 - train - INFO - True
2024-04-03 10:00:52,426 - train - INFO - alphas:tensor([0.3262, 0.6738], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,426 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,426 - train - INFO - True
2024-04-03 10:00:52,427 - train - INFO - alphas:tensor([0.4071, 0.5929], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,427 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,427 - train - INFO - True
2024-04-03 10:00:52,428 - train - INFO - alphas:tensor([0.2303, 0.7697], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,428 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,428 - train - INFO - True
2024-04-03 10:00:52,428 - train - INFO - alphas:tensor([0.2039, 0.7961], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,429 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,429 - train - INFO - True
2024-04-03 10:00:52,429 - train - INFO - alphas:tensor([0.2516, 0.7484], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,429 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,429 - train - INFO - True
2024-04-03 10:00:52,430 - train - INFO - alphas:tensor([0.3537, 0.6463], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,430 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,430 - train - INFO - True
2024-04-03 10:00:52,431 - train - INFO - alphas:tensor([0.1357, 0.8643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,431 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,431 - train - INFO - True
2024-04-03 10:00:52,432 - train - INFO - alphas:tensor([0.1377, 0.8623], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,432 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,432 - train - INFO - True
2024-04-03 10:00:52,432 - train - INFO - alphas:tensor([0.0257, 0.9743], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,433 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,433 - train - INFO - True
2024-04-03 10:00:52,433 - train - INFO - alphas:tensor([0.0320, 0.9680], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,433 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,433 - train - INFO - True
2024-04-03 10:00:52,434 - train - INFO - alphas:tensor([3.8703e-05, 9.9996e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,434 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,434 - train - INFO - True
2024-04-03 10:00:52,435 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:00:52,435 - train - INFO - tau:0.38104711810454983
2024-04-03 10:00:52,435 - train - INFO - avg block size:13.413793103448276
2024-04-03 10:00:53,591 - train - INFO - Test: [   0/39]  Time: 1.153 (1.153)  Loss:  0.3672 (0.3672)  Acc@1: 92.1875 (92.1875)  Acc@5: 99.6094 (99.6094)
2024-04-03 10:01:38,642 - train - INFO - Test: [  39/39]  Time: 1.115 (1.155)  Loss:  0.3538 (0.3643)  Acc@1: 87.5000 (92.4800)  Acc@5: 100.0000 (99.7300)
2024-04-03 10:01:41,000 - train - INFO - Train: 99 [   0/195 (  0%)]  Loss:  1.784992 (1.7850)  Time: 2.196s,  116.57/s  (2.196s,  116.57/s)  LR: 1.499e-04  Data: 0.229 (0.229)
2024-04-03 10:03:21,498 - train - INFO - Train: 99 [  50/195 ( 26%)]  Loss:  1.751072 (1.5391)  Time: 2.335s,  109.61/s  (2.014s,  127.14/s)  LR: 1.499e-04  Data: 0.010 (0.014)
2024-04-03 10:05:01,990 - train - INFO - Train: 99 [ 100/195 ( 52%)]  Loss:  1.687134 (1.5390)  Time: 1.893s,  135.22/s  (2.012s,  127.25/s)  LR: 1.499e-04  Data: 0.006 (0.012)
2024-04-03 10:06:41,825 - train - INFO - Train: 99 [ 150/195 ( 77%)]  Loss:  1.334296 (1.5342)  Time: 1.840s,  139.14/s  (2.007s,  127.57/s)  LR: 1.499e-04  Data: 0.005 (0.011)
2024-04-03 10:08:09,531 - train - INFO - Train: 99 [ 194/195 (100%)]  Loss:  1.372206 (1.5351)  Time: 1.757s,  145.72/s  (2.004s,  127.76/s)  LR: 1.499e-04  Data: 0.000 (0.010)
2024-04-03 10:08:09,532 - train - INFO - True
2024-04-03 10:08:09,533 - train - INFO - alphas:tensor([0.0024, 0.9976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,533 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,533 - train - INFO - True
2024-04-03 10:08:09,534 - train - INFO - alphas:tensor([0.0865, 0.9135], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,534 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,534 - train - INFO - True
2024-04-03 10:08:09,534 - train - INFO - alphas:tensor([0.5703, 0.4297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,535 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,535 - train - INFO - True
2024-04-03 10:08:09,535 - train - INFO - alphas:tensor([0.4888, 0.5112], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,535 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,535 - train - INFO - True
2024-04-03 10:08:09,536 - train - INFO - alphas:tensor([0.1695, 0.8305], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,536 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,536 - train - INFO - True
2024-04-03 10:08:09,537 - train - INFO - alphas:tensor([0.2847, 0.7153], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,537 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,537 - train - INFO - True
2024-04-03 10:08:09,538 - train - INFO - alphas:tensor([0.5689, 0.4311], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,538 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,538 - train - INFO - True
2024-04-03 10:08:09,539 - train - INFO - alphas:tensor([0.4530, 0.5470], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,539 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,540 - train - INFO - True
2024-04-03 10:08:09,540 - train - INFO - alphas:tensor([0.2743, 0.7257], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,540 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,540 - train - INFO - True
2024-04-03 10:08:09,541 - train - INFO - alphas:tensor([0.4248, 0.5752], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,541 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,541 - train - INFO - True
2024-04-03 10:08:09,542 - train - INFO - alphas:tensor([0.5737, 0.4263], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,542 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,542 - train - INFO - True
2024-04-03 10:08:09,543 - train - INFO - alphas:tensor([0.4368, 0.5632], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,543 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,543 - train - INFO - True
2024-04-03 10:08:09,544 - train - INFO - alphas:tensor([0.2909, 0.7091], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,544 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,544 - train - INFO - True
2024-04-03 10:08:09,544 - train - INFO - alphas:tensor([0.4190, 0.5810], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,545 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,545 - train - INFO - True
2024-04-03 10:08:09,545 - train - INFO - alphas:tensor([0.5140, 0.4860], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,545 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,545 - train - INFO - True
2024-04-03 10:08:09,546 - train - INFO - alphas:tensor([0.3649, 0.6351], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,546 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,546 - train - INFO - True
2024-04-03 10:08:09,547 - train - INFO - alphas:tensor([0.2589, 0.7411], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,547 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,547 - train - INFO - True
2024-04-03 10:08:09,548 - train - INFO - alphas:tensor([0.3275, 0.6725], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,548 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,548 - train - INFO - True
2024-04-03 10:08:09,549 - train - INFO - alphas:tensor([0.4077, 0.5923], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,549 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,549 - train - INFO - True
2024-04-03 10:08:09,549 - train - INFO - alphas:tensor([0.2316, 0.7684], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,549 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,550 - train - INFO - True
2024-04-03 10:08:09,550 - train - INFO - alphas:tensor([0.2028, 0.7972], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,550 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,550 - train - INFO - True
2024-04-03 10:08:09,551 - train - INFO - alphas:tensor([0.2521, 0.7479], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,551 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,551 - train - INFO - True
2024-04-03 10:08:09,552 - train - INFO - alphas:tensor([0.3557, 0.6443], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,552 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,552 - train - INFO - True
2024-04-03 10:08:09,553 - train - INFO - alphas:tensor([0.1360, 0.8640], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,553 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,553 - train - INFO - True
2024-04-03 10:08:09,554 - train - INFO - alphas:tensor([0.1371, 0.8629], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,554 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,554 - train - INFO - True
2024-04-03 10:08:09,554 - train - INFO - alphas:tensor([0.0243, 0.9757], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,554 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,555 - train - INFO - True
2024-04-03 10:08:09,555 - train - INFO - alphas:tensor([0.0311, 0.9689], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,555 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,555 - train - INFO - True
2024-04-03 10:08:09,556 - train - INFO - alphas:tensor([3.4138e-05, 9.9997e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,556 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,556 - train - INFO - True
2024-04-03 10:08:09,557 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:08:09,557 - train - INFO - tau:0.37723664692350434
2024-04-03 10:08:09,557 - train - INFO - avg block size:13.413793103448276
2024-04-03 10:08:10,801 - train - INFO - Test: [   0/39]  Time: 1.241 (1.241)  Loss:  0.3591 (0.3591)  Acc@1: 91.0156 (91.0156)  Acc@5: 99.6094 (99.6094)
2024-04-03 10:08:55,261 - train - INFO - Test: [  39/39]  Time: 1.125 (1.143)  Loss:  0.3657 (0.3588)  Acc@1: 87.5000 (92.3800)  Acc@5: 100.0000 (99.7500)
2024-04-03 10:08:57,472 - train - INFO - Train: 100 [   0/195 (  0%)]  Loss:  1.725872 (1.7259)  Time: 2.039s,  125.57/s  (2.039s,  125.57/s)  LR: 1.450e-04  Data: 0.152 (0.152)
2024-04-03 10:10:37,570 - train - INFO - Train: 100 [  50/195 ( 26%)]  Loss:  1.176567 (1.5531)  Time: 1.994s,  128.41/s  (2.003s,  127.83/s)  LR: 1.450e-04  Data: 0.009 (0.010)
2024-04-03 10:12:17,648 - train - INFO - Train: 100 [ 100/195 ( 52%)]  Loss:  1.742406 (1.5556)  Time: 2.106s,  121.54/s  (2.002s,  127.87/s)  LR: 1.450e-04  Data: 0.005 (0.009)
2024-04-03 10:13:58,579 - train - INFO - Train: 100 [ 150/195 ( 77%)]  Loss:  1.344082 (1.5687)  Time: 1.915s,  133.71/s  (2.008s,  127.52/s)  LR: 1.450e-04  Data: 0.006 (0.009)
2024-04-03 10:15:27,095 - train - INFO - Train: 100 [ 194/195 (100%)]  Loss:  1.492707 (1.5686)  Time: 1.938s,  132.10/s  (2.008s,  127.46/s)  LR: 1.450e-04  Data: 0.000 (0.009)
2024-04-03 10:15:27,096 - train - INFO - True
2024-04-03 10:15:27,097 - train - INFO - alphas:tensor([0.0022, 0.9978], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,097 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,097 - train - INFO - True
2024-04-03 10:15:27,098 - train - INFO - alphas:tensor([0.0859, 0.9141], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,098 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,098 - train - INFO - True
2024-04-03 10:15:27,099 - train - INFO - alphas:tensor([0.5711, 0.4289], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,099 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,099 - train - INFO - True
2024-04-03 10:15:27,100 - train - INFO - alphas:tensor([0.4891, 0.5109], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,100 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,100 - train - INFO - True
2024-04-03 10:15:27,101 - train - INFO - alphas:tensor([0.1675, 0.8325], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,101 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,101 - train - INFO - True
2024-04-03 10:15:27,101 - train - INFO - alphas:tensor([0.2821, 0.7179], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,102 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,102 - train - INFO - True
2024-04-03 10:15:27,102 - train - INFO - alphas:tensor([0.5663, 0.4337], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,102 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,102 - train - INFO - True
2024-04-03 10:15:27,103 - train - INFO - alphas:tensor([0.4500, 0.5500], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,103 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,104 - train - INFO - True
2024-04-03 10:15:27,104 - train - INFO - alphas:tensor([0.2748, 0.7252], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,104 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,104 - train - INFO - True
2024-04-03 10:15:27,105 - train - INFO - alphas:tensor([0.4250, 0.5750], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,105 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,105 - train - INFO - True
2024-04-03 10:15:27,106 - train - INFO - alphas:tensor([0.5734, 0.4266], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,106 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,106 - train - INFO - True
2024-04-03 10:15:27,107 - train - INFO - alphas:tensor([0.4368, 0.5632], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,107 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,107 - train - INFO - True
2024-04-03 10:15:27,108 - train - INFO - alphas:tensor([0.2910, 0.7090], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,108 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,108 - train - INFO - True
2024-04-03 10:15:27,108 - train - INFO - alphas:tensor([0.4194, 0.5806], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,108 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,108 - train - INFO - True
2024-04-03 10:15:27,109 - train - INFO - alphas:tensor([0.5127, 0.4873], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,109 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,109 - train - INFO - True
2024-04-03 10:15:27,110 - train - INFO - alphas:tensor([0.3638, 0.6362], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,110 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,110 - train - INFO - True
2024-04-03 10:15:27,111 - train - INFO - alphas:tensor([0.2566, 0.7434], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,111 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,111 - train - INFO - True
2024-04-03 10:15:27,112 - train - INFO - alphas:tensor([0.3261, 0.6739], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,112 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,112 - train - INFO - True
2024-04-03 10:15:27,112 - train - INFO - alphas:tensor([0.4058, 0.5942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,113 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,113 - train - INFO - True
2024-04-03 10:15:27,113 - train - INFO - alphas:tensor([0.2311, 0.7689], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,113 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,113 - train - INFO - True
2024-04-03 10:15:27,114 - train - INFO - alphas:tensor([0.2023, 0.7977], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,114 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,114 - train - INFO - True
2024-04-03 10:15:27,115 - train - INFO - alphas:tensor([0.2512, 0.7488], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,115 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,115 - train - INFO - True
2024-04-03 10:15:27,116 - train - INFO - alphas:tensor([0.3559, 0.6441], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,116 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,116 - train - INFO - True
2024-04-03 10:15:27,117 - train - INFO - alphas:tensor([0.1343, 0.8657], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,117 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,117 - train - INFO - True
2024-04-03 10:15:27,117 - train - INFO - alphas:tensor([0.1353, 0.8647], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,117 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,117 - train - INFO - True
2024-04-03 10:15:27,118 - train - INFO - alphas:tensor([0.0230, 0.9770], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,118 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,118 - train - INFO - True
2024-04-03 10:15:27,119 - train - INFO - alphas:tensor([0.0296, 0.9704], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,119 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,119 - train - INFO - True
2024-04-03 10:15:27,120 - train - INFO - alphas:tensor([3.0112e-05, 9.9997e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,120 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,120 - train - INFO - True
2024-04-03 10:15:27,120 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:15:27,121 - train - INFO - tau:0.37346428045426927
2024-04-03 10:15:27,121 - train - INFO - avg block size:13.413793103448276
2024-04-03 10:15:28,319 - train - INFO - Test: [   0/39]  Time: 1.195 (1.195)  Loss:  0.3550 (0.3550)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 10:16:08,482 - train - INFO - Test: [  39/39]  Time: 0.888 (1.034)  Loss:  0.3792 (0.3655)  Acc@1: 87.5000 (92.4000)  Acc@5: 100.0000 (99.7200)
2024-04-03 10:16:10,421 - train - INFO - Train: 101 [   0/195 (  0%)]  Loss:  1.806463 (1.8065)  Time: 1.828s,  140.06/s  (1.828s,  140.06/s)  LR: 1.401e-04  Data: 0.181 (0.181)
2024-04-03 10:17:30,551 - train - INFO - Train: 101 [  50/195 ( 26%)]  Loss:  1.797340 (1.5310)  Time: 1.509s,  169.68/s  (1.607s,  159.30/s)  LR: 1.401e-04  Data: 0.014 (0.011)
2024-04-03 10:18:51,694 - train - INFO - Train: 101 [ 100/195 ( 52%)]  Loss:  1.437050 (1.5341)  Time: 1.608s,  159.22/s  (1.615s,  158.53/s)  LR: 1.401e-04  Data: 0.006 (0.009)
2024-04-03 10:20:11,322 - train - INFO - Train: 101 [ 150/195 ( 77%)]  Loss:  1.714386 (1.5360)  Time: 1.590s,  160.97/s  (1.607s,  159.26/s)  LR: 1.401e-04  Data: 0.005 (0.009)
2024-04-03 10:21:21,505 - train - INFO - Train: 101 [ 194/195 (100%)]  Loss:  1.506865 (1.5352)  Time: 1.607s,  159.31/s  (1.605s,  159.54/s)  LR: 1.401e-04  Data: 0.000 (0.009)
2024-04-03 10:21:21,505 - train - INFO - True
2024-04-03 10:21:21,507 - train - INFO - alphas:tensor([0.0020, 0.9980], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,507 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,507 - train - INFO - True
2024-04-03 10:21:21,508 - train - INFO - alphas:tensor([0.0847, 0.9153], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,508 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,508 - train - INFO - True
2024-04-03 10:21:21,509 - train - INFO - alphas:tensor([0.5702, 0.4298], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,509 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,509 - train - INFO - True
2024-04-03 10:21:21,514 - train - INFO - alphas:tensor([0.4879, 0.5121], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,515 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,515 - train - INFO - True
2024-04-03 10:21:21,515 - train - INFO - alphas:tensor([0.1670, 0.8330], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,515 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,515 - train - INFO - True
2024-04-03 10:21:21,516 - train - INFO - alphas:tensor([0.2833, 0.7167], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,516 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,516 - train - INFO - True
2024-04-03 10:21:21,517 - train - INFO - alphas:tensor([0.5666, 0.4334], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,517 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,517 - train - INFO - True
2024-04-03 10:21:21,518 - train - INFO - alphas:tensor([0.4500, 0.5500], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,522 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,522 - train - INFO - True
2024-04-03 10:21:21,523 - train - INFO - alphas:tensor([0.2728, 0.7272], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,523 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,523 - train - INFO - True
2024-04-03 10:21:21,524 - train - INFO - alphas:tensor([0.4233, 0.5767], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,524 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,524 - train - INFO - True
2024-04-03 10:21:21,524 - train - INFO - alphas:tensor([0.5725, 0.4275], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,525 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,525 - train - INFO - True
2024-04-03 10:21:21,525 - train - INFO - alphas:tensor([0.4353, 0.5647], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,525 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,525 - train - INFO - True
2024-04-03 10:21:21,526 - train - INFO - alphas:tensor([0.2897, 0.7103], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,526 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,526 - train - INFO - True
2024-04-03 10:21:21,527 - train - INFO - alphas:tensor([0.4197, 0.5803], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,527 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,527 - train - INFO - True
2024-04-03 10:21:21,528 - train - INFO - alphas:tensor([0.5117, 0.4883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,528 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,528 - train - INFO - True
2024-04-03 10:21:21,528 - train - INFO - alphas:tensor([0.3618, 0.6382], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,529 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,529 - train - INFO - True
2024-04-03 10:21:21,529 - train - INFO - alphas:tensor([0.2574, 0.7426], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,529 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,529 - train - INFO - True
2024-04-03 10:21:21,530 - train - INFO - alphas:tensor([0.3264, 0.6736], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,530 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,530 - train - INFO - True
2024-04-03 10:21:21,535 - train - INFO - alphas:tensor([0.4058, 0.5942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,535 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,536 - train - INFO - True
2024-04-03 10:21:21,536 - train - INFO - alphas:tensor([0.2311, 0.7689], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,536 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,536 - train - INFO - True
2024-04-03 10:21:21,537 - train - INFO - alphas:tensor([0.2010, 0.7990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,537 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,537 - train - INFO - True
2024-04-03 10:21:21,538 - train - INFO - alphas:tensor([0.2498, 0.7502], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,538 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,538 - train - INFO - True
2024-04-03 10:21:21,539 - train - INFO - alphas:tensor([0.3545, 0.6455], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,539 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,539 - train - INFO - True
2024-04-03 10:21:21,539 - train - INFO - alphas:tensor([0.1347, 0.8653], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,539 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,540 - train - INFO - True
2024-04-03 10:21:21,540 - train - INFO - alphas:tensor([0.1342, 0.8658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,540 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,540 - train - INFO - True
2024-04-03 10:21:21,541 - train - INFO - alphas:tensor([0.0217, 0.9783], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,541 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,541 - train - INFO - True
2024-04-03 10:21:21,542 - train - INFO - alphas:tensor([0.0284, 0.9716], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,542 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,542 - train - INFO - True
2024-04-03 10:21:21,543 - train - INFO - alphas:tensor([2.6556e-05, 9.9997e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,543 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,543 - train - INFO - True
2024-04-03 10:21:21,543 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:21:21,543 - train - INFO - tau:0.36972963764972655
2024-04-03 10:21:21,543 - train - INFO - avg block size:13.413793103448276
2024-04-03 10:21:22,460 - train - INFO - Test: [   0/39]  Time: 0.910 (0.910)  Loss:  0.3477 (0.3477)  Acc@1: 93.3594 (93.3594)  Acc@5: 99.2188 (99.2188)
2024-04-03 10:21:57,839 - train - INFO - Test: [  39/39]  Time: 0.934 (0.907)  Loss:  0.3779 (0.3533)  Acc@1: 87.5000 (92.5300)  Acc@5: 100.0000 (99.7400)
2024-04-03 10:21:59,780 - train - INFO - Train: 102 [   0/195 (  0%)]  Loss:  1.581355 (1.5814)  Time: 1.844s,  138.83/s  (1.844s,  138.83/s)  LR: 1.353e-04  Data: 0.179 (0.179)
2024-04-03 10:23:20,759 - train - INFO - Train: 102 [  50/195 ( 26%)]  Loss:  1.542150 (1.5449)  Time: 1.592s,  160.83/s  (1.624s,  157.64/s)  LR: 1.353e-04  Data: 0.006 (0.011)
2024-04-03 10:24:43,076 - train - INFO - Train: 102 [ 100/195 ( 52%)]  Loss:  1.287003 (1.5610)  Time: 1.583s,  161.76/s  (1.635s,  156.58/s)  LR: 1.353e-04  Data: 0.005 (0.010)
2024-04-03 10:26:04,354 - train - INFO - Train: 102 [ 150/195 ( 77%)]  Loss:  1.579756 (1.5525)  Time: 1.555s,  164.68/s  (1.632s,  156.88/s)  LR: 1.353e-04  Data: 0.017 (0.009)
2024-04-03 10:27:14,574 - train - INFO - Train: 102 [ 194/195 (100%)]  Loss:  1.263912 (1.5505)  Time: 1.627s,  157.31/s  (1.624s,  157.66/s)  LR: 1.353e-04  Data: 0.000 (0.009)
2024-04-03 10:27:14,575 - train - INFO - True
2024-04-03 10:27:14,576 - train - INFO - alphas:tensor([0.0019, 0.9981], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,576 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,576 - train - INFO - True
2024-04-03 10:27:14,577 - train - INFO - alphas:tensor([0.0838, 0.9162], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,577 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,577 - train - INFO - True
2024-04-03 10:27:14,578 - train - INFO - alphas:tensor([0.5708, 0.4292], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,578 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,578 - train - INFO - True
2024-04-03 10:27:14,579 - train - INFO - alphas:tensor([0.4874, 0.5126], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,579 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,579 - train - INFO - True
2024-04-03 10:27:14,580 - train - INFO - alphas:tensor([0.1649, 0.8351], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,580 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,580 - train - INFO - True
2024-04-03 10:27:14,580 - train - INFO - alphas:tensor([0.2823, 0.7177], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,580 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,581 - train - INFO - True
2024-04-03 10:27:14,581 - train - INFO - alphas:tensor([0.5661, 0.4339], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,581 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,581 - train - INFO - True
2024-04-03 10:27:14,582 - train - INFO - alphas:tensor([0.4492, 0.5508], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,582 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,582 - train - INFO - True
2024-04-03 10:27:14,583 - train - INFO - alphas:tensor([0.2727, 0.7273], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,583 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,583 - train - INFO - True
2024-04-03 10:27:14,584 - train - INFO - alphas:tensor([0.4234, 0.5766], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,584 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,584 - train - INFO - True
2024-04-03 10:27:14,585 - train - INFO - alphas:tensor([0.5724, 0.4276], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,585 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,585 - train - INFO - True
2024-04-03 10:27:14,586 - train - INFO - alphas:tensor([0.4340, 0.5660], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,586 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,586 - train - INFO - True
2024-04-03 10:27:14,586 - train - INFO - alphas:tensor([0.2890, 0.7110], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,587 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,587 - train - INFO - True
2024-04-03 10:27:14,587 - train - INFO - alphas:tensor([0.4201, 0.5799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,587 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,587 - train - INFO - True
2024-04-03 10:27:14,588 - train - INFO - alphas:tensor([0.5114, 0.4886], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,588 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,588 - train - INFO - True
2024-04-03 10:27:14,589 - train - INFO - alphas:tensor([0.3625, 0.6375], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,589 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,589 - train - INFO - True
2024-04-03 10:27:14,590 - train - INFO - alphas:tensor([0.2556, 0.7444], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,590 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,590 - train - INFO - True
2024-04-03 10:27:14,590 - train - INFO - alphas:tensor([0.3249, 0.6751], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,591 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,591 - train - INFO - True
2024-04-03 10:27:14,591 - train - INFO - alphas:tensor([0.4037, 0.5963], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,591 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,591 - train - INFO - True
2024-04-03 10:27:14,592 - train - INFO - alphas:tensor([0.2286, 0.7714], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,592 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,592 - train - INFO - True
2024-04-03 10:27:14,593 - train - INFO - alphas:tensor([0.1995, 0.8005], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,593 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,593 - train - INFO - True
2024-04-03 10:27:14,594 - train - INFO - alphas:tensor([0.2466, 0.7534], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,594 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,594 - train - INFO - True
2024-04-03 10:27:14,595 - train - INFO - alphas:tensor([0.3524, 0.6476], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,595 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,595 - train - INFO - True
2024-04-03 10:27:14,595 - train - INFO - alphas:tensor([0.1330, 0.8670], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,595 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,596 - train - INFO - True
2024-04-03 10:27:14,596 - train - INFO - alphas:tensor([0.1334, 0.8666], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,596 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,596 - train - INFO - True
2024-04-03 10:27:14,597 - train - INFO - alphas:tensor([0.0204, 0.9796], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,597 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,597 - train - INFO - True
2024-04-03 10:27:14,598 - train - INFO - alphas:tensor([0.0268, 0.9732], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,598 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,598 - train - INFO - True
2024-04-03 10:27:14,599 - train - INFO - alphas:tensor([2.3397e-05, 9.9998e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,599 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,599 - train - INFO - True
2024-04-03 10:27:14,599 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:27:14,599 - train - INFO - tau:0.36603234127322926
2024-04-03 10:27:14,599 - train - INFO - avg block size:13.413793103448276
2024-04-03 10:27:15,537 - train - INFO - Test: [   0/39]  Time: 0.936 (0.936)  Loss:  0.3506 (0.3506)  Acc@1: 93.3594 (93.3594)  Acc@5: 99.6094 (99.6094)
2024-04-03 10:27:50,565 - train - INFO - Test: [  39/39]  Time: 0.849 (0.899)  Loss:  0.3582 (0.3599)  Acc@1: 87.5000 (92.5500)  Acc@5: 100.0000 (99.7300)
2024-04-03 10:27:52,535 - train - INFO - Train: 103 [   0/195 (  0%)]  Loss:  1.706925 (1.7069)  Time: 1.862s,  137.48/s  (1.862s,  137.48/s)  LR: 1.306e-04  Data: 0.199 (0.199)
2024-04-03 10:29:13,527 - train - INFO - Train: 103 [  50/195 ( 26%)]  Loss:  1.365618 (1.5494)  Time: 1.590s,  160.99/s  (1.625s,  157.58/s)  LR: 1.306e-04  Data: 0.018 (0.012)
2024-04-03 10:30:34,589 - train - INFO - Train: 103 [ 100/195 ( 52%)]  Loss:  1.240840 (1.5423)  Time: 1.590s,  161.05/s  (1.623s,  157.74/s)  LR: 1.306e-04  Data: 0.005 (0.010)
2024-04-03 10:31:54,788 - train - INFO - Train: 103 [ 150/195 ( 77%)]  Loss:  1.509598 (1.5326)  Time: 1.546s,  165.57/s  (1.617s,  158.35/s)  LR: 1.306e-04  Data: 0.011 (0.009)
2024-04-03 10:33:05,440 - train - INFO - Train: 103 [ 194/195 (100%)]  Loss:  1.419801 (1.5461)  Time: 1.523s,  168.07/s  (1.614s,  158.60/s)  LR: 1.306e-04  Data: 0.000 (0.009)
2024-04-03 10:33:05,441 - train - INFO - True
2024-04-03 10:33:05,442 - train - INFO - alphas:tensor([0.0017, 0.9983], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,442 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,442 - train - INFO - True
2024-04-03 10:33:05,443 - train - INFO - alphas:tensor([0.0824, 0.9176], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,447 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,447 - train - INFO - True
2024-04-03 10:33:05,448 - train - INFO - alphas:tensor([0.5694, 0.4306], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,448 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,448 - train - INFO - True
2024-04-03 10:33:05,449 - train - INFO - alphas:tensor([0.4854, 0.5146], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,449 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,449 - train - INFO - True
2024-04-03 10:33:05,449 - train - INFO - alphas:tensor([0.1643, 0.8357], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,450 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,450 - train - INFO - True
2024-04-03 10:33:05,450 - train - INFO - alphas:tensor([0.2806, 0.7194], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,450 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,450 - train - INFO - True
2024-04-03 10:33:05,451 - train - INFO - alphas:tensor([0.5655, 0.4345], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,456 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,456 - train - INFO - True
2024-04-03 10:33:05,456 - train - INFO - alphas:tensor([0.4482, 0.5518], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,456 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,457 - train - INFO - True
2024-04-03 10:33:05,457 - train - INFO - alphas:tensor([0.2708, 0.7292], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,457 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,457 - train - INFO - True
2024-04-03 10:33:05,458 - train - INFO - alphas:tensor([0.4217, 0.5783], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,458 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,458 - train - INFO - True
2024-04-03 10:33:05,459 - train - INFO - alphas:tensor([0.5718, 0.4282], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,459 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,459 - train - INFO - True
2024-04-03 10:33:05,460 - train - INFO - alphas:tensor([0.4337, 0.5663], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,460 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,460 - train - INFO - True
2024-04-03 10:33:05,469 - train - INFO - alphas:tensor([0.2888, 0.7112], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,474 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,474 - train - INFO - True
2024-04-03 10:33:05,475 - train - INFO - alphas:tensor([0.4191, 0.5809], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,475 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,475 - train - INFO - True
2024-04-03 10:33:05,476 - train - INFO - alphas:tensor([0.5105, 0.4895], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,476 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,476 - train - INFO - True
2024-04-03 10:33:05,476 - train - INFO - alphas:tensor([0.3625, 0.6375], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,477 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,477 - train - INFO - True
2024-04-03 10:33:05,477 - train - INFO - alphas:tensor([0.2556, 0.7444], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,477 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,477 - train - INFO - True
2024-04-03 10:33:05,481 - train - INFO - alphas:tensor([0.3258, 0.6742], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,481 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,481 - train - INFO - True
2024-04-03 10:33:05,482 - train - INFO - alphas:tensor([0.4027, 0.5973], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,482 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,482 - train - INFO - True
2024-04-03 10:33:05,483 - train - INFO - alphas:tensor([0.2290, 0.7710], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,492 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,492 - train - INFO - True
2024-04-03 10:33:05,493 - train - INFO - alphas:tensor([0.2007, 0.7993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,493 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,493 - train - INFO - True
2024-04-03 10:33:05,493 - train - INFO - alphas:tensor([0.2478, 0.7522], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,498 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,498 - train - INFO - True
2024-04-03 10:33:05,499 - train - INFO - alphas:tensor([0.3520, 0.6480], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,499 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,499 - train - INFO - True
2024-04-03 10:33:05,500 - train - INFO - alphas:tensor([0.1325, 0.8675], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,500 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,500 - train - INFO - True
2024-04-03 10:33:05,500 - train - INFO - alphas:tensor([0.1329, 0.8671], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,500 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,501 - train - INFO - True
2024-04-03 10:33:05,501 - train - INFO - alphas:tensor([0.0193, 0.9807], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,501 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,501 - train - INFO - True
2024-04-03 10:33:05,502 - train - INFO - alphas:tensor([0.0259, 0.9741], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,502 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,502 - train - INFO - True
2024-04-03 10:33:05,510 - train - INFO - alphas:tensor([2.0623e-05, 9.9998e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,510 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,510 - train - INFO - True
2024-04-03 10:33:05,510 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:33:05,510 - train - INFO - tau:0.36237201786049694
2024-04-03 10:33:05,511 - train - INFO - avg block size:13.413793103448276
2024-04-03 10:33:06,420 - train - INFO - Test: [   0/39]  Time: 0.907 (0.907)  Loss:  0.3457 (0.3457)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-03 10:33:40,678 - train - INFO - Test: [  39/39]  Time: 0.865 (0.879)  Loss:  0.3767 (0.3576)  Acc@1: 87.5000 (92.5300)  Acc@5: 100.0000 (99.7500)
2024-04-03 10:33:42,645 - train - INFO - Train: 104 [   0/195 (  0%)]  Loss:  1.437268 (1.4373)  Time: 1.829s,  140.00/s  (1.829s,  140.00/s)  LR: 1.259e-04  Data: 0.141 (0.141)
2024-04-03 10:35:05,222 - train - INFO - Train: 104 [  50/195 ( 26%)]  Loss:  1.448633 (1.5463)  Time: 2.070s,  123.69/s  (1.655s,  154.68/s)  LR: 1.259e-04  Data: 0.014 (0.011)
2024-04-03 10:36:25,759 - train - INFO - Train: 104 [ 100/195 ( 52%)]  Loss:  1.455290 (1.5450)  Time: 1.504s,  170.26/s  (1.633s,  156.76/s)  LR: 1.259e-04  Data: 0.005 (0.009)
2024-04-03 10:37:45,020 - train - INFO - Train: 104 [ 150/195 ( 77%)]  Loss:  1.445568 (1.5254)  Time: 1.679s,  152.47/s  (1.617s,  158.30/s)  LR: 1.259e-04  Data: 0.005 (0.009)
2024-04-03 10:38:54,803 - train - INFO - Train: 104 [ 194/195 (100%)]  Loss:  1.292819 (1.5299)  Time: 1.605s,  159.46/s  (1.610s,  158.99/s)  LR: 1.259e-04  Data: 0.000 (0.008)
2024-04-03 10:38:54,804 - train - INFO - True
2024-04-03 10:38:54,805 - train - INFO - alphas:tensor([0.0015, 0.9985], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,805 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,805 - train - INFO - True
2024-04-03 10:38:54,806 - train - INFO - alphas:tensor([0.0817, 0.9183], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,806 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,806 - train - INFO - True
2024-04-03 10:38:54,806 - train - INFO - alphas:tensor([0.5697, 0.4303], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,807 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,807 - train - INFO - True
2024-04-03 10:38:54,807 - train - INFO - alphas:tensor([0.4854, 0.5146], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,807 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,807 - train - INFO - True
2024-04-03 10:38:54,808 - train - INFO - alphas:tensor([0.1631, 0.8369], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,808 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,808 - train - INFO - True
2024-04-03 10:38:54,809 - train - INFO - alphas:tensor([0.2795, 0.7205], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,809 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,809 - train - INFO - True
2024-04-03 10:38:54,810 - train - INFO - alphas:tensor([0.5669, 0.4331], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,810 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,810 - train - INFO - True
2024-04-03 10:38:54,811 - train - INFO - alphas:tensor([0.4494, 0.5506], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,811 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,811 - train - INFO - True
2024-04-03 10:38:54,811 - train - INFO - alphas:tensor([0.2702, 0.7298], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,811 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,812 - train - INFO - True
2024-04-03 10:38:54,812 - train - INFO - alphas:tensor([0.4228, 0.5772], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,812 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,812 - train - INFO - True
2024-04-03 10:38:54,826 - train - INFO - alphas:tensor([0.5703, 0.4297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,826 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,826 - train - INFO - True
2024-04-03 10:38:54,827 - train - INFO - alphas:tensor([0.4300, 0.5700], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,827 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,827 - train - INFO - True
2024-04-03 10:38:54,828 - train - INFO - alphas:tensor([0.2870, 0.7130], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,828 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,828 - train - INFO - True
2024-04-03 10:38:54,829 - train - INFO - alphas:tensor([0.4173, 0.5827], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,829 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,829 - train - INFO - True
2024-04-03 10:38:54,830 - train - INFO - alphas:tensor([0.5087, 0.4913], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,830 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,830 - train - INFO - True
2024-04-03 10:38:54,830 - train - INFO - alphas:tensor([0.3602, 0.6398], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,830 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,831 - train - INFO - True
2024-04-03 10:38:54,840 - train - INFO - alphas:tensor([0.2540, 0.7460], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,840 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,840 - train - INFO - True
2024-04-03 10:38:54,841 - train - INFO - alphas:tensor([0.3250, 0.6750], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,841 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,841 - train - INFO - True
2024-04-03 10:38:54,842 - train - INFO - alphas:tensor([0.4008, 0.5992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,842 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,842 - train - INFO - True
2024-04-03 10:38:54,842 - train - INFO - alphas:tensor([0.2267, 0.7733], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,843 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,843 - train - INFO - True
2024-04-03 10:38:54,843 - train - INFO - alphas:tensor([0.1988, 0.8012], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,843 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,843 - train - INFO - True
2024-04-03 10:38:54,844 - train - INFO - alphas:tensor([0.2464, 0.7536], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,844 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,844 - train - INFO - True
2024-04-03 10:38:54,845 - train - INFO - alphas:tensor([0.3496, 0.6504], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,845 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,845 - train - INFO - True
2024-04-03 10:38:54,846 - train - INFO - alphas:tensor([0.1304, 0.8696], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,846 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,846 - train - INFO - True
2024-04-03 10:38:54,846 - train - INFO - alphas:tensor([0.1317, 0.8683], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,847 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,847 - train - INFO - True
2024-04-03 10:38:54,847 - train - INFO - alphas:tensor([0.0182, 0.9818], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,847 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,847 - train - INFO - True
2024-04-03 10:38:54,866 - train - INFO - alphas:tensor([0.0251, 0.9749], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,870 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,870 - train - INFO - True
2024-04-03 10:38:54,871 - train - INFO - alphas:tensor([1.8162e-05, 9.9998e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,871 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,871 - train - INFO - True
2024-04-03 10:38:54,872 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:38:54,872 - train - INFO - tau:0.358748297681892
2024-04-03 10:38:54,872 - train - INFO - avg block size:13.413793103448276
2024-04-03 10:38:55,833 - train - INFO - Test: [   0/39]  Time: 0.959 (0.959)  Loss:  0.3508 (0.3508)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-03 10:39:31,084 - train - INFO - Test: [  39/39]  Time: 0.902 (0.905)  Loss:  0.3989 (0.3522)  Acc@1: 81.2500 (92.7200)  Acc@5: 100.0000 (99.7700)
2024-04-03 10:39:32,948 - train - INFO - Train: 105 [   0/195 (  0%)]  Loss:  1.794408 (1.7944)  Time: 1.757s,  145.74/s  (1.757s,  145.74/s)  LR: 1.213e-04  Data: 0.184 (0.184)
2024-04-03 10:40:52,861 - train - INFO - Train: 105 [  50/195 ( 26%)]  Loss:  1.703976 (1.5181)  Time: 1.543s,  165.91/s  (1.601s,  159.86/s)  LR: 1.213e-04  Data: 0.005 (0.010)
2024-04-03 10:42:13,691 - train - INFO - Train: 105 [ 100/195 ( 52%)]  Loss:  1.230106 (1.5174)  Time: 1.664s,  153.89/s  (1.609s,  159.12/s)  LR: 1.213e-04  Data: 0.006 (0.010)
2024-04-03 10:43:34,315 - train - INFO - Train: 105 [ 150/195 ( 77%)]  Loss:  1.713997 (1.5238)  Time: 1.715s,  149.25/s  (1.610s,  159.00/s)  LR: 1.213e-04  Data: 0.006 (0.009)
2024-04-03 10:44:44,763 - train - INFO - Train: 105 [ 194/195 (100%)]  Loss:  1.260384 (1.5354)  Time: 1.471s,  174.07/s  (1.608s,  159.20/s)  LR: 1.213e-04  Data: 0.000 (0.008)
2024-04-03 10:44:44,763 - train - INFO - True
2024-04-03 10:44:44,765 - train - INFO - alphas:tensor([0.0014, 0.9986], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,765 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,765 - train - INFO - True
2024-04-03 10:44:44,766 - train - INFO - alphas:tensor([0.0805, 0.9195], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,766 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,766 - train - INFO - True
2024-04-03 10:44:44,767 - train - INFO - alphas:tensor([0.5696, 0.4304], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,767 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,767 - train - INFO - True
2024-04-03 10:44:44,768 - train - INFO - alphas:tensor([0.4842, 0.5158], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,768 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,768 - train - INFO - True
2024-04-03 10:44:44,768 - train - INFO - alphas:tensor([0.1621, 0.8379], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,769 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,769 - train - INFO - True
2024-04-03 10:44:44,769 - train - INFO - alphas:tensor([0.2778, 0.7222], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,769 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,769 - train - INFO - True
2024-04-03 10:44:44,770 - train - INFO - alphas:tensor([0.5651, 0.4349], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,770 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,770 - train - INFO - True
2024-04-03 10:44:44,771 - train - INFO - alphas:tensor([0.4459, 0.5541], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,771 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,771 - train - INFO - True
2024-04-03 10:44:44,772 - train - INFO - alphas:tensor([0.2691, 0.7309], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,772 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,772 - train - INFO - True
2024-04-03 10:44:44,773 - train - INFO - alphas:tensor([0.4201, 0.5799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,773 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,773 - train - INFO - True
2024-04-03 10:44:44,774 - train - INFO - alphas:tensor([0.5708, 0.4292], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,774 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,774 - train - INFO - True
2024-04-03 10:44:44,775 - train - INFO - alphas:tensor([0.4309, 0.5691], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,775 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,775 - train - INFO - True
2024-04-03 10:44:44,775 - train - INFO - alphas:tensor([0.2863, 0.7137], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,775 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,776 - train - INFO - True
2024-04-03 10:44:44,776 - train - INFO - alphas:tensor([0.4167, 0.5833], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,776 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,776 - train - INFO - True
2024-04-03 10:44:44,777 - train - INFO - alphas:tensor([0.5089, 0.4911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,777 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,777 - train - INFO - True
2024-04-03 10:44:44,778 - train - INFO - alphas:tensor([0.3600, 0.6400], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,778 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,778 - train - INFO - True
2024-04-03 10:44:44,779 - train - INFO - alphas:tensor([0.2537, 0.7463], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,779 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,779 - train - INFO - True
2024-04-03 10:44:44,779 - train - INFO - alphas:tensor([0.3255, 0.6745], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,780 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,780 - train - INFO - True
2024-04-03 10:44:44,780 - train - INFO - alphas:tensor([0.3996, 0.6004], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,780 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,780 - train - INFO - True
2024-04-03 10:44:44,781 - train - INFO - alphas:tensor([0.2262, 0.7738], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,781 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,781 - train - INFO - True
2024-04-03 10:44:44,782 - train - INFO - alphas:tensor([0.1981, 0.8019], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,783 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,783 - train - INFO - True
2024-04-03 10:44:44,783 - train - INFO - alphas:tensor([0.2462, 0.7538], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,783 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,783 - train - INFO - True
2024-04-03 10:44:44,784 - train - INFO - alphas:tensor([0.3487, 0.6513], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,784 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,784 - train - INFO - True
2024-04-03 10:44:44,785 - train - INFO - alphas:tensor([0.1295, 0.8705], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,785 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,785 - train - INFO - True
2024-04-03 10:44:44,786 - train - INFO - alphas:tensor([0.1316, 0.8684], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,786 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,786 - train - INFO - True
2024-04-03 10:44:44,786 - train - INFO - alphas:tensor([0.0172, 0.9828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,787 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,787 - train - INFO - True
2024-04-03 10:44:44,787 - train - INFO - alphas:tensor([0.0240, 0.9760], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,787 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,787 - train - INFO - True
2024-04-03 10:44:44,788 - train - INFO - alphas:tensor([1.5983e-05, 9.9998e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,788 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,788 - train - INFO - True
2024-04-03 10:44:44,789 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:44:44,789 - train - INFO - tau:0.35516081470507305
2024-04-03 10:44:44,789 - train - INFO - avg block size:13.413793103448276
2024-04-03 10:44:45,682 - train - INFO - Test: [   0/39]  Time: 0.889 (0.889)  Loss:  0.3542 (0.3542)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 10:45:20,969 - train - INFO - Test: [  39/39]  Time: 0.901 (0.904)  Loss:  0.3586 (0.3567)  Acc@1: 87.5000 (92.5100)  Acc@5: 100.0000 (99.7500)
2024-04-03 10:45:22,795 - train - INFO - Train: 106 [   0/195 (  0%)]  Loss:  1.380034 (1.3800)  Time: 1.682s,  152.23/s  (1.682s,  152.23/s)  LR: 1.168e-04  Data: 0.201 (0.201)
2024-04-03 10:46:44,514 - train - INFO - Train: 106 [  50/195 ( 26%)]  Loss:  1.360290 (1.5190)  Time: 1.568s,  163.31/s  (1.635s,  156.55/s)  LR: 1.168e-04  Data: 0.005 (0.011)
2024-04-03 10:48:04,715 - train - INFO - Train: 106 [ 100/195 ( 52%)]  Loss:  1.814008 (1.5175)  Time: 1.818s,  140.84/s  (1.620s,  158.04/s)  LR: 1.168e-04  Data: 0.010 (0.009)
2024-04-03 10:49:24,730 - train - INFO - Train: 106 [ 150/195 ( 77%)]  Loss:  1.739742 (1.5339)  Time: 1.623s,  157.69/s  (1.613s,  158.68/s)  LR: 1.168e-04  Data: 0.006 (0.009)
2024-04-03 10:50:35,675 - train - INFO - Train: 106 [ 194/195 (100%)]  Loss:  1.723916 (1.5404)  Time: 1.520s,  168.39/s  (1.613s,  158.70/s)  LR: 1.168e-04  Data: 0.000 (0.009)
2024-04-03 10:50:35,676 - train - INFO - True
2024-04-03 10:50:35,678 - train - INFO - alphas:tensor([0.0013, 0.9987], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,678 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,678 - train - INFO - True
2024-04-03 10:50:35,679 - train - INFO - alphas:tensor([0.0793, 0.9207], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,679 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,679 - train - INFO - True
2024-04-03 10:50:35,679 - train - INFO - alphas:tensor([0.5696, 0.4304], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,680 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,680 - train - INFO - True
2024-04-03 10:50:35,685 - train - INFO - alphas:tensor([0.4834, 0.5166], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,685 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,685 - train - INFO - True
2024-04-03 10:50:35,686 - train - INFO - alphas:tensor([0.1603, 0.8397], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,690 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,690 - train - INFO - True
2024-04-03 10:50:35,691 - train - INFO - alphas:tensor([0.2765, 0.7235], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,691 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,691 - train - INFO - True
2024-04-03 10:50:35,692 - train - INFO - alphas:tensor([0.5648, 0.4352], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,692 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,692 - train - INFO - True
2024-04-03 10:50:35,693 - train - INFO - alphas:tensor([0.4445, 0.5555], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,693 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,693 - train - INFO - True
2024-04-03 10:50:35,693 - train - INFO - alphas:tensor([0.2691, 0.7309], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,693 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,694 - train - INFO - True
2024-04-03 10:50:35,694 - train - INFO - alphas:tensor([0.4217, 0.5783], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,694 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,694 - train - INFO - True
2024-04-03 10:50:35,695 - train - INFO - alphas:tensor([0.5687, 0.4313], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,695 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,695 - train - INFO - True
2024-04-03 10:50:35,696 - train - INFO - alphas:tensor([0.4275, 0.5725], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,700 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,700 - train - INFO - True
2024-04-03 10:50:35,701 - train - INFO - alphas:tensor([0.2865, 0.7135], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,701 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,701 - train - INFO - True
2024-04-03 10:50:35,702 - train - INFO - alphas:tensor([0.4171, 0.5829], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,702 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,702 - train - INFO - True
2024-04-03 10:50:35,703 - train - INFO - alphas:tensor([0.5085, 0.4915], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,703 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,703 - train - INFO - True
2024-04-03 10:50:35,703 - train - INFO - alphas:tensor([0.3593, 0.6407], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,704 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,704 - train - INFO - True
2024-04-03 10:50:35,704 - train - INFO - alphas:tensor([0.2518, 0.7482], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,704 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,704 - train - INFO - True
2024-04-03 10:50:35,705 - train - INFO - alphas:tensor([0.3242, 0.6758], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,710 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,710 - train - INFO - True
2024-04-03 10:50:35,710 - train - INFO - alphas:tensor([0.3977, 0.6023], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,710 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,711 - train - INFO - True
2024-04-03 10:50:35,711 - train - INFO - alphas:tensor([0.2248, 0.7752], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,711 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,711 - train - INFO - True
2024-04-03 10:50:35,712 - train - INFO - alphas:tensor([0.1960, 0.8040], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,712 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,712 - train - INFO - True
2024-04-03 10:50:35,713 - train - INFO - alphas:tensor([0.2457, 0.7543], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,713 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,713 - train - INFO - True
2024-04-03 10:50:35,714 - train - INFO - alphas:tensor([0.3492, 0.6508], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,718 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,718 - train - INFO - True
2024-04-03 10:50:35,719 - train - INFO - alphas:tensor([0.1280, 0.8720], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,719 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,719 - train - INFO - True
2024-04-03 10:50:35,720 - train - INFO - alphas:tensor([0.1304, 0.8696], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,720 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,720 - train - INFO - True
2024-04-03 10:50:35,720 - train - INFO - alphas:tensor([0.0162, 0.9838], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,721 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,721 - train - INFO - True
2024-04-03 10:50:35,721 - train - INFO - alphas:tensor([0.0230, 0.9770], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,721 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,721 - train - INFO - True
2024-04-03 10:50:35,722 - train - INFO - alphas:tensor([1.4065e-05, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,722 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,722 - train - INFO - True
2024-04-03 10:50:35,723 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:50:35,723 - train - INFO - tau:0.3516092065580223
2024-04-03 10:50:35,723 - train - INFO - avg block size:13.413793103448276
2024-04-03 10:50:36,672 - train - INFO - Test: [   0/39]  Time: 0.946 (0.946)  Loss:  0.3604 (0.3604)  Acc@1: 92.5781 (92.5781)  Acc@5: 99.6094 (99.6094)
2024-04-03 10:51:12,499 - train - INFO - Test: [  39/39]  Time: 0.942 (0.919)  Loss:  0.3577 (0.3641)  Acc@1: 87.5000 (92.5400)  Acc@5: 100.0000 (99.7300)
2024-04-03 10:51:14,408 - train - INFO - Train: 107 [   0/195 (  0%)]  Loss:  1.288614 (1.2886)  Time: 1.771s,  144.55/s  (1.771s,  144.55/s)  LR: 1.123e-04  Data: 0.237 (0.237)
2024-04-03 10:52:37,096 - train - INFO - Train: 107 [  50/195 ( 26%)]  Loss:  1.677648 (1.5336)  Time: 1.534s,  166.83/s  (1.656s,  154.59/s)  LR: 1.123e-04  Data: 0.005 (0.012)
2024-04-03 10:53:58,263 - train - INFO - Train: 107 [ 100/195 ( 52%)]  Loss:  1.530343 (1.5245)  Time: 1.563s,  163.83/s  (1.640s,  156.11/s)  LR: 1.123e-04  Data: 0.022 (0.010)
2024-04-03 10:55:20,362 - train - INFO - Train: 107 [ 150/195 ( 77%)]  Loss:  1.709138 (1.5223)  Time: 1.547s,  165.48/s  (1.641s,  156.05/s)  LR: 1.123e-04  Data: 0.005 (0.009)
2024-04-03 10:56:30,982 - train - INFO - Train: 107 [ 194/195 (100%)]  Loss:  1.685763 (1.5266)  Time: 1.792s,  142.87/s  (1.633s,  156.81/s)  LR: 1.123e-04  Data: 0.000 (0.009)
2024-04-03 10:56:30,983 - train - INFO - True
2024-04-03 10:56:30,984 - train - INFO - alphas:tensor([0.0012, 0.9988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,984 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,984 - train - INFO - True
2024-04-03 10:56:30,985 - train - INFO - alphas:tensor([0.0786, 0.9214], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,985 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,985 - train - INFO - True
2024-04-03 10:56:30,986 - train - INFO - alphas:tensor([0.5683, 0.4317], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,986 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,986 - train - INFO - True
2024-04-03 10:56:30,987 - train - INFO - alphas:tensor([0.4821, 0.5179], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,987 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,987 - train - INFO - True
2024-04-03 10:56:30,987 - train - INFO - alphas:tensor([0.1590, 0.8410], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,987 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,988 - train - INFO - True
2024-04-03 10:56:30,988 - train - INFO - alphas:tensor([0.2753, 0.7247], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,988 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,988 - train - INFO - True
2024-04-03 10:56:30,989 - train - INFO - alphas:tensor([0.5634, 0.4366], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,989 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,989 - train - INFO - True
2024-04-03 10:56:30,990 - train - INFO - alphas:tensor([0.4455, 0.5545], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,990 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,990 - train - INFO - True
2024-04-03 10:56:30,991 - train - INFO - alphas:tensor([0.2679, 0.7321], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,991 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,991 - train - INFO - True
2024-04-03 10:56:30,992 - train - INFO - alphas:tensor([0.4208, 0.5792], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,992 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,992 - train - INFO - True
2024-04-03 10:56:30,993 - train - INFO - alphas:tensor([0.5693, 0.4307], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,993 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,993 - train - INFO - True
2024-04-03 10:56:30,994 - train - INFO - alphas:tensor([0.4298, 0.5702], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,994 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,994 - train - INFO - True
2024-04-03 10:56:30,994 - train - INFO - alphas:tensor([0.2843, 0.7157], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,994 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,995 - train - INFO - True
2024-04-03 10:56:30,995 - train - INFO - alphas:tensor([0.4167, 0.5833], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,995 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,995 - train - INFO - True
2024-04-03 10:56:30,996 - train - INFO - alphas:tensor([0.5088, 0.4912], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,996 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,996 - train - INFO - True
2024-04-03 10:56:30,997 - train - INFO - alphas:tensor([0.3613, 0.6387], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,997 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,997 - train - INFO - True
2024-04-03 10:56:30,998 - train - INFO - alphas:tensor([0.2525, 0.7475], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,998 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,998 - train - INFO - True
2024-04-03 10:56:30,998 - train - INFO - alphas:tensor([0.3233, 0.6767], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,998 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,999 - train - INFO - True
2024-04-03 10:56:30,999 - train - INFO - alphas:tensor([0.3981, 0.6019], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:30,999 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:30,999 - train - INFO - True
2024-04-03 10:56:31,000 - train - INFO - alphas:tensor([0.2243, 0.7757], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:31,000 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:31,000 - train - INFO - True
2024-04-03 10:56:31,001 - train - INFO - alphas:tensor([0.1962, 0.8038], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:31,001 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:31,001 - train - INFO - True
2024-04-03 10:56:31,002 - train - INFO - alphas:tensor([0.2455, 0.7545], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:31,002 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:31,002 - train - INFO - True
2024-04-03 10:56:31,002 - train - INFO - alphas:tensor([0.3488, 0.6512], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:31,003 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:31,003 - train - INFO - True
2024-04-03 10:56:31,003 - train - INFO - alphas:tensor([0.1261, 0.8739], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:31,003 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:31,003 - train - INFO - True
2024-04-03 10:56:31,004 - train - INFO - alphas:tensor([0.1300, 0.8700], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:31,004 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:31,004 - train - INFO - True
2024-04-03 10:56:31,005 - train - INFO - alphas:tensor([0.0153, 0.9847], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:31,005 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:31,005 - train - INFO - True
2024-04-03 10:56:31,006 - train - INFO - alphas:tensor([0.0221, 0.9779], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:31,006 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:31,006 - train - INFO - True
2024-04-03 10:56:31,006 - train - INFO - alphas:tensor([1.2367e-05, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:31,007 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:31,007 - train - INFO - True
2024-04-03 10:56:31,007 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 10:56:31,007 - train - INFO - tau:0.34809311449244207
2024-04-03 10:56:31,007 - train - INFO - avg block size:13.413793103448276
2024-04-03 10:56:31,942 - train - INFO - Test: [   0/39]  Time: 0.932 (0.932)  Loss:  0.3552 (0.3552)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-03 10:57:07,040 - train - INFO - Test: [  39/39]  Time: 0.931 (0.901)  Loss:  0.4358 (0.3592)  Acc@1: 81.2500 (92.4000)  Acc@5: 100.0000 (99.7800)
2024-04-03 10:57:08,999 - train - INFO - Train: 108 [   0/195 (  0%)]  Loss:  1.174936 (1.1749)  Time: 1.816s,  140.96/s  (1.816s,  140.96/s)  LR: 1.079e-04  Data: 0.209 (0.209)
2024-04-03 10:58:29,419 - train - INFO - Train: 108 [  50/195 ( 26%)]  Loss:  1.334901 (1.5366)  Time: 1.694s,  151.14/s  (1.612s,  158.77/s)  LR: 1.079e-04  Data: 0.005 (0.011)
2024-04-03 10:59:48,834 - train - INFO - Train: 108 [ 100/195 ( 52%)]  Loss:  1.743629 (1.5469)  Time: 1.659s,  154.29/s  (1.600s,  159.95/s)  LR: 1.079e-04  Data: 0.005 (0.009)
2024-04-03 11:01:09,648 - train - INFO - Train: 108 [ 150/195 ( 77%)]  Loss:  1.711301 (1.5353)  Time: 1.499s,  170.80/s  (1.606s,  159.43/s)  LR: 1.079e-04  Data: 0.006 (0.009)
2024-04-03 11:02:19,831 - train - INFO - Train: 108 [ 194/195 (100%)]  Loss:  1.302180 (1.5357)  Time: 1.661s,  154.10/s  (1.603s,  159.67/s)  LR: 1.079e-04  Data: 0.000 (0.008)
2024-04-03 11:02:19,831 - train - INFO - True
2024-04-03 11:02:19,832 - train - INFO - alphas:tensor([0.0011, 0.9989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,833 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,833 - train - INFO - True
2024-04-03 11:02:19,833 - train - INFO - alphas:tensor([0.0776, 0.9224], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,833 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,834 - train - INFO - True
2024-04-03 11:02:19,834 - train - INFO - alphas:tensor([0.5683, 0.4317], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,834 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,834 - train - INFO - True
2024-04-03 11:02:19,835 - train - INFO - alphas:tensor([0.4813, 0.5187], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,835 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,835 - train - INFO - True
2024-04-03 11:02:19,836 - train - INFO - alphas:tensor([0.1571, 0.8429], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,836 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,836 - train - INFO - True
2024-04-03 11:02:19,842 - train - INFO - alphas:tensor([0.2732, 0.7268], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,852 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,852 - train - INFO - True
2024-04-03 11:02:19,852 - train - INFO - alphas:tensor([0.5625, 0.4375], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,853 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,853 - train - INFO - True
2024-04-03 11:02:19,853 - train - INFO - alphas:tensor([0.4429, 0.5571], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,853 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,853 - train - INFO - True
2024-04-03 11:02:19,854 - train - INFO - alphas:tensor([0.2664, 0.7336], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,854 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,854 - train - INFO - True
2024-04-03 11:02:19,855 - train - INFO - alphas:tensor([0.4199, 0.5801], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,855 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,855 - train - INFO - True
2024-04-03 11:02:19,856 - train - INFO - alphas:tensor([0.5690, 0.4310], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,865 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,865 - train - INFO - True
2024-04-03 11:02:19,865 - train - INFO - alphas:tensor([0.4281, 0.5719], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,865 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,866 - train - INFO - True
2024-04-03 11:02:19,866 - train - INFO - alphas:tensor([0.2848, 0.7152], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,866 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,866 - train - INFO - True
2024-04-03 11:02:19,867 - train - INFO - alphas:tensor([0.4182, 0.5818], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,867 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,867 - train - INFO - True
2024-04-03 11:02:19,868 - train - INFO - alphas:tensor([0.5071, 0.4929], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,868 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,868 - train - INFO - True
2024-04-03 11:02:19,869 - train - INFO - alphas:tensor([0.3608, 0.6392], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,869 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,869 - train - INFO - True
2024-04-03 11:02:19,870 - train - INFO - alphas:tensor([0.2491, 0.7509], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,874 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,874 - train - INFO - True
2024-04-03 11:02:19,875 - train - INFO - alphas:tensor([0.3195, 0.6805], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,875 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,875 - train - INFO - True
2024-04-03 11:02:19,876 - train - INFO - alphas:tensor([0.3973, 0.6027], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,880 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,880 - train - INFO - True
2024-04-03 11:02:19,881 - train - INFO - alphas:tensor([0.2234, 0.7766], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,881 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,881 - train - INFO - True
2024-04-03 11:02:19,882 - train - INFO - alphas:tensor([0.1946, 0.8054], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,882 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,882 - train - INFO - True
2024-04-03 11:02:19,883 - train - INFO - alphas:tensor([0.2441, 0.7559], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,891 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,892 - train - INFO - True
2024-04-03 11:02:19,892 - train - INFO - alphas:tensor([0.3481, 0.6519], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,892 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,892 - train - INFO - True
2024-04-03 11:02:19,893 - train - INFO - alphas:tensor([0.1249, 0.8751], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,893 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,893 - train - INFO - True
2024-04-03 11:02:19,894 - train - INFO - alphas:tensor([0.1292, 0.8708], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,894 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,894 - train - INFO - True
2024-04-03 11:02:19,895 - train - INFO - alphas:tensor([0.0144, 0.9856], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,895 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,895 - train - INFO - True
2024-04-03 11:02:19,896 - train - INFO - alphas:tensor([0.0210, 0.9790], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,905 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,905 - train - INFO - True
2024-04-03 11:02:19,905 - train - INFO - alphas:tensor([1.0870e-05, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,905 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,906 - train - INFO - True
2024-04-03 11:02:19,906 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:02:19,906 - train - INFO - tau:0.34461218334751764
2024-04-03 11:02:19,906 - train - INFO - avg block size:13.413793103448276
2024-04-03 11:02:20,855 - train - INFO - Test: [   0/39]  Time: 0.946 (0.946)  Loss:  0.3540 (0.3540)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-03 11:02:56,643 - train - INFO - Test: [  39/39]  Time: 0.915 (0.918)  Loss:  0.3528 (0.3606)  Acc@1: 87.5000 (92.4700)  Acc@5: 100.0000 (99.7800)
2024-04-03 11:02:58,691 - train - INFO - Train: 109 [   0/195 (  0%)]  Loss:  1.432621 (1.4326)  Time: 1.953s,  131.11/s  (1.953s,  131.11/s)  LR: 1.036e-04  Data: 0.187 (0.187)
2024-04-03 11:04:19,449 - train - INFO - Train: 109 [  50/195 ( 26%)]  Loss:  1.643580 (1.5498)  Time: 1.488s,  172.00/s  (1.622s,  157.85/s)  LR: 1.036e-04  Data: 0.006 (0.011)
2024-04-03 11:05:40,273 - train - INFO - Train: 109 [ 100/195 ( 52%)]  Loss:  1.184059 (1.5252)  Time: 1.570s,  163.11/s  (1.619s,  158.11/s)  LR: 1.036e-04  Data: 0.014 (0.010)
2024-04-03 11:07:00,090 - train - INFO - Train: 109 [ 150/195 ( 77%)]  Loss:  1.227425 (1.5379)  Time: 1.488s,  171.99/s  (1.612s,  158.85/s)  LR: 1.036e-04  Data: 0.005 (0.009)
2024-04-03 11:08:10,321 - train - INFO - Train: 109 [ 194/195 (100%)]  Loss:  1.235764 (1.5381)  Time: 1.768s,  144.78/s  (1.608s,  159.19/s)  LR: 1.036e-04  Data: 0.000 (0.009)
2024-04-03 11:08:10,322 - train - INFO - True
2024-04-03 11:08:10,323 - train - INFO - alphas:tensor([9.7992e-04, 9.9902e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,323 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,323 - train - INFO - True
2024-04-03 11:08:10,324 - train - INFO - alphas:tensor([0.0766, 0.9234], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,324 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,324 - train - INFO - True
2024-04-03 11:08:10,325 - train - INFO - alphas:tensor([0.5675, 0.4325], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,325 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,325 - train - INFO - True
2024-04-03 11:08:10,326 - train - INFO - alphas:tensor([0.4795, 0.5205], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,326 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,326 - train - INFO - True
2024-04-03 11:08:10,327 - train - INFO - alphas:tensor([0.1571, 0.8429], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,327 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,327 - train - INFO - True
2024-04-03 11:08:10,328 - train - INFO - alphas:tensor([0.2738, 0.7262], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,328 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,328 - train - INFO - True
2024-04-03 11:08:10,329 - train - INFO - alphas:tensor([0.5630, 0.4370], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,329 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,329 - train - INFO - True
2024-04-03 11:08:10,330 - train - INFO - alphas:tensor([0.4436, 0.5564], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,330 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,330 - train - INFO - True
2024-04-03 11:08:10,330 - train - INFO - alphas:tensor([0.2663, 0.7337], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,330 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,330 - train - INFO - True
2024-04-03 11:08:10,331 - train - INFO - alphas:tensor([0.4199, 0.5801], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,331 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,331 - train - INFO - True
2024-04-03 11:08:10,332 - train - INFO - alphas:tensor([0.5690, 0.4310], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,332 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,332 - train - INFO - True
2024-04-03 11:08:10,333 - train - INFO - alphas:tensor([0.4282, 0.5718], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,333 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,333 - train - INFO - True
2024-04-03 11:08:10,334 - train - INFO - alphas:tensor([0.2831, 0.7169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,334 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,334 - train - INFO - True
2024-04-03 11:08:10,334 - train - INFO - alphas:tensor([0.4171, 0.5829], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,335 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,335 - train - INFO - True
2024-04-03 11:08:10,335 - train - INFO - alphas:tensor([0.5069, 0.4931], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,335 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,335 - train - INFO - True
2024-04-03 11:08:10,336 - train - INFO - alphas:tensor([0.3581, 0.6419], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,336 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,336 - train - INFO - True
2024-04-03 11:08:10,337 - train - INFO - alphas:tensor([0.2491, 0.7509], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,337 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,337 - train - INFO - True
2024-04-03 11:08:10,338 - train - INFO - alphas:tensor([0.3197, 0.6803], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,338 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,338 - train - INFO - True
2024-04-03 11:08:10,338 - train - INFO - alphas:tensor([0.3966, 0.6034], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,339 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,339 - train - INFO - True
2024-04-03 11:08:10,339 - train - INFO - alphas:tensor([0.2230, 0.7770], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,339 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,339 - train - INFO - True
2024-04-03 11:08:10,340 - train - INFO - alphas:tensor([0.1945, 0.8055], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,340 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,340 - train - INFO - True
2024-04-03 11:08:10,341 - train - INFO - alphas:tensor([0.2441, 0.7559], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,341 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,341 - train - INFO - True
2024-04-03 11:08:10,342 - train - INFO - alphas:tensor([0.3485, 0.6515], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,342 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,342 - train - INFO - True
2024-04-03 11:08:10,343 - train - INFO - alphas:tensor([0.1237, 0.8763], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,343 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,343 - train - INFO - True
2024-04-03 11:08:10,343 - train - INFO - alphas:tensor([0.1283, 0.8717], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,343 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,344 - train - INFO - True
2024-04-03 11:08:10,344 - train - INFO - alphas:tensor([0.0136, 0.9864], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,344 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,344 - train - INFO - True
2024-04-03 11:08:10,345 - train - INFO - alphas:tensor([0.0202, 0.9798], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,345 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,345 - train - INFO - True
2024-04-03 11:08:10,346 - train - INFO - alphas:tensor([9.5487e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,346 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,346 - train - INFO - True
2024-04-03 11:08:10,347 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:08:10,347 - train - INFO - tau:0.34116606151404244
2024-04-03 11:08:10,347 - train - INFO - avg block size:13.413793103448276
2024-04-03 11:08:11,277 - train - INFO - Test: [   0/39]  Time: 0.927 (0.927)  Loss:  0.3420 (0.3420)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-03 11:08:45,702 - train - INFO - Test: [  39/39]  Time: 0.907 (0.884)  Loss:  0.4004 (0.3510)  Acc@1: 81.2500 (92.6000)  Acc@5: 100.0000 (99.7400)
2024-04-03 11:08:47,691 - train - INFO - Train: 110 [   0/195 (  0%)]  Loss:  1.180034 (1.1800)  Time: 1.842s,  139.01/s  (1.842s,  139.01/s)  LR: 9.933e-05  Data: 0.189 (0.189)
2024-04-03 11:10:07,521 - train - INFO - Train: 110 [  50/195 ( 26%)]  Loss:  1.740474 (1.5090)  Time: 1.728s,  148.11/s  (1.601s,  159.86/s)  LR: 9.933e-05  Data: 0.005 (0.011)
2024-04-03 11:11:26,131 - train - INFO - Train: 110 [ 100/195 ( 52%)]  Loss:  1.759321 (1.5349)  Time: 1.533s,  167.02/s  (1.587s,  161.32/s)  LR: 9.933e-05  Data: 0.006 (0.009)
2024-04-03 11:12:44,820 - train - INFO - Train: 110 [ 150/195 ( 77%)]  Loss:  1.760719 (1.5369)  Time: 1.666s,  153.67/s  (1.583s,  161.76/s)  LR: 9.933e-05  Data: 0.006 (0.008)
2024-04-03 11:13:55,100 - train - INFO - Train: 110 [ 194/195 (100%)]  Loss:  1.385184 (1.5319)  Time: 1.572s,  162.80/s  (1.586s,  161.42/s)  LR: 9.933e-05  Data: 0.000 (0.008)
2024-04-03 11:13:55,101 - train - INFO - True
2024-04-03 11:13:55,102 - train - INFO - alphas:tensor([8.9220e-04, 9.9911e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,102 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,102 - train - INFO - True
2024-04-03 11:13:55,103 - train - INFO - alphas:tensor([0.0757, 0.9243], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,103 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,103 - train - INFO - True
2024-04-03 11:13:55,104 - train - INFO - alphas:tensor([0.5685, 0.4315], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,104 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,104 - train - INFO - True
2024-04-03 11:13:55,105 - train - INFO - alphas:tensor([0.4798, 0.5202], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,105 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,105 - train - INFO - True
2024-04-03 11:13:55,106 - train - INFO - alphas:tensor([0.1556, 0.8444], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,106 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,106 - train - INFO - True
2024-04-03 11:13:55,106 - train - INFO - alphas:tensor([0.2723, 0.7277], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,106 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,106 - train - INFO - True
2024-04-03 11:13:55,107 - train - INFO - alphas:tensor([0.5624, 0.4376], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,107 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,107 - train - INFO - True
2024-04-03 11:13:55,108 - train - INFO - alphas:tensor([0.4431, 0.5569], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,108 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,108 - train - INFO - True
2024-04-03 11:13:55,109 - train - INFO - alphas:tensor([0.2640, 0.7360], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,109 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,109 - train - INFO - True
2024-04-03 11:13:55,110 - train - INFO - alphas:tensor([0.4176, 0.5824], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,110 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,110 - train - INFO - True
2024-04-03 11:13:55,111 - train - INFO - alphas:tensor([0.5677, 0.4323], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,111 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,111 - train - INFO - True
2024-04-03 11:13:55,112 - train - INFO - alphas:tensor([0.4277, 0.5723], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,112 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,112 - train - INFO - True
2024-04-03 11:13:55,113 - train - INFO - alphas:tensor([0.2820, 0.7180], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,113 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,113 - train - INFO - True
2024-04-03 11:13:55,113 - train - INFO - alphas:tensor([0.4151, 0.5849], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,114 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,114 - train - INFO - True
2024-04-03 11:13:55,114 - train - INFO - alphas:tensor([0.5059, 0.4941], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,114 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,114 - train - INFO - True
2024-04-03 11:13:55,115 - train - INFO - alphas:tensor([0.3561, 0.6439], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,115 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,115 - train - INFO - True
2024-04-03 11:13:55,116 - train - INFO - alphas:tensor([0.2488, 0.7512], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,116 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,116 - train - INFO - True
2024-04-03 11:13:55,117 - train - INFO - alphas:tensor([0.3213, 0.6787], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,117 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,117 - train - INFO - True
2024-04-03 11:13:55,117 - train - INFO - alphas:tensor([0.3954, 0.6046], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,118 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,118 - train - INFO - True
2024-04-03 11:13:55,118 - train - INFO - alphas:tensor([0.2218, 0.7782], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,118 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,118 - train - INFO - True
2024-04-03 11:13:55,119 - train - INFO - alphas:tensor([0.1928, 0.8072], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,119 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,119 - train - INFO - True
2024-04-03 11:13:55,120 - train - INFO - alphas:tensor([0.2424, 0.7576], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,120 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,120 - train - INFO - True
2024-04-03 11:13:55,121 - train - INFO - alphas:tensor([0.3474, 0.6526], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,121 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,121 - train - INFO - True
2024-04-03 11:13:55,121 - train - INFO - alphas:tensor([0.1232, 0.8768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,122 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,122 - train - INFO - True
2024-04-03 11:13:55,122 - train - INFO - alphas:tensor([0.1276, 0.8724], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,122 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,122 - train - INFO - True
2024-04-03 11:13:55,123 - train - INFO - alphas:tensor([0.0128, 0.9872], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,123 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,123 - train - INFO - True
2024-04-03 11:13:55,124 - train - INFO - alphas:tensor([0.0194, 0.9806], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,124 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,124 - train - INFO - True
2024-04-03 11:13:55,125 - train - INFO - alphas:tensor([8.3849e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,125 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,125 - train - INFO - True
2024-04-03 11:13:55,125 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:13:55,125 - train - INFO - tau:0.337754400898902
2024-04-03 11:13:55,126 - train - INFO - avg block size:13.413793103448276
2024-04-03 11:13:56,060 - train - INFO - Test: [   0/39]  Time: 0.930 (0.930)  Loss:  0.3545 (0.3545)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-04-03 11:14:30,300 - train - INFO - Test: [  39/39]  Time: 0.900 (0.879)  Loss:  0.3364 (0.3614)  Acc@1: 87.5000 (92.5200)  Acc@5: 100.0000 (99.7300)
2024-04-03 11:14:32,294 - train - INFO - Train: 111 [   0/195 (  0%)]  Loss:  1.527366 (1.5274)  Time: 1.834s,  139.57/s  (1.834s,  139.57/s)  LR: 9.517e-05  Data: 0.215 (0.215)
2024-04-03 11:15:52,165 - train - INFO - Train: 111 [  50/195 ( 26%)]  Loss:  1.566694 (1.4900)  Time: 1.558s,  164.33/s  (1.602s,  159.80/s)  LR: 9.517e-05  Data: 0.005 (0.012)
2024-04-03 11:17:13,189 - train - INFO - Train: 111 [ 100/195 ( 52%)]  Loss:  1.292713 (1.5111)  Time: 1.652s,  154.99/s  (1.611s,  158.89/s)  LR: 9.517e-05  Data: 0.005 (0.010)
2024-04-03 11:18:32,586 - train - INFO - Train: 111 [ 150/195 ( 77%)]  Loss:  1.756405 (1.5366)  Time: 1.593s,  160.73/s  (1.603s,  159.65/s)  LR: 9.517e-05  Data: 0.005 (0.009)
2024-04-03 11:19:43,923 - train - INFO - Train: 111 [ 194/195 (100%)]  Loss:  1.686695 (1.5415)  Time: 1.656s,  154.55/s  (1.607s,  159.26/s)  LR: 9.517e-05  Data: 0.000 (0.008)
2024-04-03 11:19:43,923 - train - INFO - True
2024-04-03 11:19:43,925 - train - INFO - alphas:tensor([8.1262e-04, 9.9919e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,929 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,929 - train - INFO - True
2024-04-03 11:19:43,930 - train - INFO - alphas:tensor([0.0743, 0.9257], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,930 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,930 - train - INFO - True
2024-04-03 11:19:43,931 - train - INFO - alphas:tensor([0.5685, 0.4315], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,931 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,931 - train - INFO - True
2024-04-03 11:19:43,932 - train - INFO - alphas:tensor([0.4789, 0.5211], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,932 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,932 - train - INFO - True
2024-04-03 11:19:43,932 - train - INFO - alphas:tensor([0.1543, 0.8457], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,937 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,948 - train - INFO - True
2024-04-03 11:19:43,949 - train - INFO - alphas:tensor([0.2704, 0.7296], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,949 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,949 - train - INFO - True
2024-04-03 11:19:43,950 - train - INFO - alphas:tensor([0.5617, 0.4383], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,950 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,950 - train - INFO - True
2024-04-03 11:19:43,951 - train - INFO - alphas:tensor([0.4417, 0.5583], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,951 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,951 - train - INFO - True
2024-04-03 11:19:43,951 - train - INFO - alphas:tensor([0.2652, 0.7348], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,952 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,952 - train - INFO - True
2024-04-03 11:19:43,952 - train - INFO - alphas:tensor([0.4200, 0.5800], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,961 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,961 - train - INFO - True
2024-04-03 11:19:43,962 - train - INFO - alphas:tensor([0.5669, 0.4331], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,962 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,962 - train - INFO - True
2024-04-03 11:19:43,963 - train - INFO - alphas:tensor([0.4264, 0.5736], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,963 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,963 - train - INFO - True
2024-04-03 11:19:43,963 - train - INFO - alphas:tensor([0.2821, 0.7179], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,963 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,964 - train - INFO - True
2024-04-03 11:19:43,964 - train - INFO - alphas:tensor([0.4162, 0.5838], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,964 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,964 - train - INFO - True
2024-04-03 11:19:43,965 - train - INFO - alphas:tensor([0.5054, 0.4946], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,965 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,965 - train - INFO - True
2024-04-03 11:19:43,966 - train - INFO - alphas:tensor([0.3548, 0.6452], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,966 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,966 - train - INFO - True
2024-04-03 11:19:43,971 - train - INFO - alphas:tensor([0.2473, 0.7527], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,971 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,971 - train - INFO - True
2024-04-03 11:19:43,972 - train - INFO - alphas:tensor([0.3201, 0.6799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,972 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,972 - train - INFO - True
2024-04-03 11:19:43,973 - train - INFO - alphas:tensor([0.3934, 0.6066], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,973 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,973 - train - INFO - True
2024-04-03 11:19:43,973 - train - INFO - alphas:tensor([0.2206, 0.7794], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,973 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,974 - train - INFO - True
2024-04-03 11:19:43,974 - train - INFO - alphas:tensor([0.1916, 0.8084], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,974 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,974 - train - INFO - True
2024-04-03 11:19:43,975 - train - INFO - alphas:tensor([0.2417, 0.7583], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,975 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,975 - train - INFO - True
2024-04-03 11:19:43,980 - train - INFO - alphas:tensor([0.3471, 0.6529], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,980 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,980 - train - INFO - True
2024-04-03 11:19:43,981 - train - INFO - alphas:tensor([0.1217, 0.8783], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,981 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,981 - train - INFO - True
2024-04-03 11:19:43,982 - train - INFO - alphas:tensor([0.1273, 0.8727], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,982 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,982 - train - INFO - True
2024-04-03 11:19:43,983 - train - INFO - alphas:tensor([0.0121, 0.9879], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,987 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,987 - train - INFO - True
2024-04-03 11:19:43,988 - train - INFO - alphas:tensor([0.0186, 0.9814], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,988 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,988 - train - INFO - True
2024-04-03 11:19:43,989 - train - INFO - alphas:tensor([7.3575e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,989 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,989 - train - INFO - True
2024-04-03 11:19:43,989 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:19:43,989 - train - INFO - tau:0.334376856889913
2024-04-03 11:19:43,989 - train - INFO - avg block size:13.413793103448276
2024-04-03 11:19:44,883 - train - INFO - Test: [   0/39]  Time: 0.891 (0.891)  Loss:  0.3491 (0.3491)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 11:20:19,191 - train - INFO - Test: [  39/39]  Time: 0.902 (0.880)  Loss:  0.3757 (0.3584)  Acc@1: 87.5000 (92.4100)  Acc@5: 100.0000 (99.7100)
2024-04-03 11:20:21,215 - train - INFO - Train: 112 [   0/195 (  0%)]  Loss:  1.638741 (1.6387)  Time: 1.881s,  136.07/s  (1.881s,  136.07/s)  LR: 9.109e-05  Data: 0.127 (0.127)
2024-04-03 11:21:41,250 - train - INFO - Train: 112 [  50/195 ( 26%)]  Loss:  1.583653 (1.4999)  Time: 1.544s,  165.83/s  (1.606s,  159.38/s)  LR: 9.109e-05  Data: 0.006 (0.011)
2024-04-03 11:23:01,438 - train - INFO - Train: 112 [ 100/195 ( 52%)]  Loss:  1.778595 (1.5216)  Time: 1.621s,  157.96/s  (1.605s,  159.50/s)  LR: 9.109e-05  Data: 0.021 (0.009)
2024-04-03 11:24:21,227 - train - INFO - Train: 112 [ 150/195 ( 77%)]  Loss:  1.646850 (1.5382)  Time: 1.507s,  169.93/s  (1.602s,  159.81/s)  LR: 9.109e-05  Data: 0.005 (0.009)
2024-04-03 11:25:33,237 - train - INFO - Train: 112 [ 194/195 (100%)]  Loss:  1.719034 (1.5359)  Time: 1.546s,  165.55/s  (1.610s,  159.03/s)  LR: 9.109e-05  Data: 0.000 (0.008)
2024-04-03 11:25:33,237 - train - INFO - True
2024-04-03 11:25:33,238 - train - INFO - alphas:tensor([7.3952e-04, 9.9926e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,238 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,239 - train - INFO - True
2024-04-03 11:25:33,239 - train - INFO - alphas:tensor([0.0729, 0.9271], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,239 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,240 - train - INFO - True
2024-04-03 11:25:33,240 - train - INFO - alphas:tensor([0.5688, 0.4312], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,240 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,240 - train - INFO - True
2024-04-03 11:25:33,241 - train - INFO - alphas:tensor([0.4783, 0.5217], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,241 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,241 - train - INFO - True
2024-04-03 11:25:33,242 - train - INFO - alphas:tensor([0.1541, 0.8459], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,242 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,242 - train - INFO - True
2024-04-03 11:25:33,243 - train - INFO - alphas:tensor([0.2712, 0.7288], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,243 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,243 - train - INFO - True
2024-04-03 11:25:33,244 - train - INFO - alphas:tensor([0.5615, 0.4385], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,244 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,244 - train - INFO - True
2024-04-03 11:25:33,245 - train - INFO - alphas:tensor([0.4416, 0.5584], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,245 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,245 - train - INFO - True
2024-04-03 11:25:33,246 - train - INFO - alphas:tensor([0.2642, 0.7358], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,246 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,246 - train - INFO - True
2024-04-03 11:25:33,247 - train - INFO - alphas:tensor([0.4195, 0.5805], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,247 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,247 - train - INFO - True
2024-04-03 11:25:33,248 - train - INFO - alphas:tensor([0.5670, 0.4330], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,248 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,248 - train - INFO - True
2024-04-03 11:25:33,249 - train - INFO - alphas:tensor([0.4269, 0.5731], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,249 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,249 - train - INFO - True
2024-04-03 11:25:33,250 - train - INFO - alphas:tensor([0.2799, 0.7201], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,250 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,250 - train - INFO - True
2024-04-03 11:25:33,250 - train - INFO - alphas:tensor([0.4152, 0.5848], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,251 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,251 - train - INFO - True
2024-04-03 11:25:33,251 - train - INFO - alphas:tensor([0.5046, 0.4954], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,252 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,252 - train - INFO - True
2024-04-03 11:25:33,252 - train - INFO - alphas:tensor([0.3538, 0.6462], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,252 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,253 - train - INFO - True
2024-04-03 11:25:33,253 - train - INFO - alphas:tensor([0.2476, 0.7524], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,253 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,253 - train - INFO - True
2024-04-03 11:25:33,254 - train - INFO - alphas:tensor([0.3203, 0.6797], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,254 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,254 - train - INFO - True
2024-04-03 11:25:33,255 - train - INFO - alphas:tensor([0.3939, 0.6061], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,255 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,255 - train - INFO - True
2024-04-03 11:25:33,256 - train - INFO - alphas:tensor([0.2206, 0.7794], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,256 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,256 - train - INFO - True
2024-04-03 11:25:33,257 - train - INFO - alphas:tensor([0.1903, 0.8097], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,257 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,257 - train - INFO - True
2024-04-03 11:25:33,258 - train - INFO - alphas:tensor([0.2407, 0.7593], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,258 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,258 - train - INFO - True
2024-04-03 11:25:33,259 - train - INFO - alphas:tensor([0.3471, 0.6529], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,259 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,259 - train - INFO - True
2024-04-03 11:25:33,260 - train - INFO - alphas:tensor([0.1215, 0.8785], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,260 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,260 - train - INFO - True
2024-04-03 11:25:33,261 - train - INFO - alphas:tensor([0.1262, 0.8738], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,261 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,261 - train - INFO - True
2024-04-03 11:25:33,262 - train - INFO - alphas:tensor([0.0114, 0.9886], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,262 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,262 - train - INFO - True
2024-04-03 11:25:33,262 - train - INFO - alphas:tensor([0.0178, 0.9822], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,263 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,263 - train - INFO - True
2024-04-03 11:25:33,263 - train - INFO - alphas:tensor([6.4537e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,264 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,264 - train - INFO - True
2024-04-03 11:25:33,264 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:25:33,264 - train - INFO - tau:0.33103308832101386
2024-04-03 11:25:33,264 - train - INFO - avg block size:13.413793103448276
2024-04-03 11:25:34,171 - train - INFO - Test: [   0/39]  Time: 0.904 (0.904)  Loss:  0.3547 (0.3547)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-04-03 11:26:09,253 - train - INFO - Test: [  39/39]  Time: 0.918 (0.900)  Loss:  0.4048 (0.3555)  Acc@1: 81.2500 (92.6000)  Acc@5: 100.0000 (99.7800)
2024-04-03 11:26:11,142 - train - INFO - Train: 113 [   0/195 (  0%)]  Loss:  1.726921 (1.7269)  Time: 1.794s,  142.70/s  (1.794s,  142.70/s)  LR: 8.709e-05  Data: 0.201 (0.201)
2024-04-03 11:27:31,958 - train - INFO - Train: 113 [  50/195 ( 26%)]  Loss:  1.202030 (1.4986)  Time: 1.593s,  160.68/s  (1.620s,  158.05/s)  LR: 8.709e-05  Data: 0.014 (0.011)
2024-04-03 11:28:52,953 - train - INFO - Train: 113 [ 100/195 ( 52%)]  Loss:  1.211228 (1.5283)  Time: 1.643s,  155.78/s  (1.620s,  158.04/s)  LR: 8.709e-05  Data: 0.010 (0.010)
2024-04-03 11:30:12,935 - train - INFO - Train: 113 [ 150/195 ( 77%)]  Loss:  1.606782 (1.5302)  Time: 1.616s,  158.43/s  (1.613s,  158.70/s)  LR: 8.709e-05  Data: 0.005 (0.009)
2024-04-03 11:31:23,109 - train - INFO - Train: 113 [ 194/195 (100%)]  Loss:  1.540082 (1.5512)  Time: 1.517s,  168.81/s  (1.609s,  159.10/s)  LR: 8.709e-05  Data: 0.000 (0.008)
2024-04-03 11:31:23,110 - train - INFO - True
2024-04-03 11:31:23,111 - train - INFO - alphas:tensor([6.7268e-04, 9.9933e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,111 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,111 - train - INFO - True
2024-04-03 11:31:23,112 - train - INFO - alphas:tensor([0.0718, 0.9282], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,112 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,112 - train - INFO - True
2024-04-03 11:31:23,113 - train - INFO - alphas:tensor([0.5681, 0.4319], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,113 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,113 - train - INFO - True
2024-04-03 11:31:23,113 - train - INFO - alphas:tensor([0.4775, 0.5225], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,114 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,114 - train - INFO - True
2024-04-03 11:31:23,114 - train - INFO - alphas:tensor([0.1530, 0.8470], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,114 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,114 - train - INFO - True
2024-04-03 11:31:23,115 - train - INFO - alphas:tensor([0.2699, 0.7301], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,115 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,115 - train - INFO - True
2024-04-03 11:31:23,116 - train - INFO - alphas:tensor([0.5602, 0.4398], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,116 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,116 - train - INFO - True
2024-04-03 11:31:23,117 - train - INFO - alphas:tensor([0.4395, 0.5605], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,117 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,117 - train - INFO - True
2024-04-03 11:31:23,118 - train - INFO - alphas:tensor([0.2627, 0.7373], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,118 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,118 - train - INFO - True
2024-04-03 11:31:23,118 - train - INFO - alphas:tensor([0.4172, 0.5828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,119 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,119 - train - INFO - True
2024-04-03 11:31:23,120 - train - INFO - alphas:tensor([0.5672, 0.4328], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,120 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,120 - train - INFO - True
2024-04-03 11:31:23,120 - train - INFO - alphas:tensor([0.4266, 0.5734], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,120 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,121 - train - INFO - True
2024-04-03 11:31:23,121 - train - INFO - alphas:tensor([0.2794, 0.7206], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,121 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,121 - train - INFO - True
2024-04-03 11:31:23,122 - train - INFO - alphas:tensor([0.4136, 0.5864], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,122 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,122 - train - INFO - True
2024-04-03 11:31:23,123 - train - INFO - alphas:tensor([0.5048, 0.4952], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,123 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,123 - train - INFO - True
2024-04-03 11:31:23,124 - train - INFO - alphas:tensor([0.3541, 0.6459], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,124 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,124 - train - INFO - True
2024-04-03 11:31:23,124 - train - INFO - alphas:tensor([0.2459, 0.7541], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,125 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,125 - train - INFO - True
2024-04-03 11:31:23,125 - train - INFO - alphas:tensor([0.3187, 0.6813], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,125 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,125 - train - INFO - True
2024-04-03 11:31:23,126 - train - INFO - alphas:tensor([0.3930, 0.6070], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,126 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,126 - train - INFO - True
2024-04-03 11:31:23,127 - train - INFO - alphas:tensor([0.2195, 0.7805], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,127 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,127 - train - INFO - True
2024-04-03 11:31:23,128 - train - INFO - alphas:tensor([0.1908, 0.8092], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,128 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,128 - train - INFO - True
2024-04-03 11:31:23,128 - train - INFO - alphas:tensor([0.2413, 0.7587], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,129 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,129 - train - INFO - True
2024-04-03 11:31:23,129 - train - INFO - alphas:tensor([0.3456, 0.6544], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,129 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,129 - train - INFO - True
2024-04-03 11:31:23,130 - train - INFO - alphas:tensor([0.1193, 0.8807], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,130 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,130 - train - INFO - True
2024-04-03 11:31:23,131 - train - INFO - alphas:tensor([0.1257, 0.8743], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,131 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,131 - train - INFO - True
2024-04-03 11:31:23,132 - train - INFO - alphas:tensor([0.0107, 0.9893], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,132 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,132 - train - INFO - True
2024-04-03 11:31:23,133 - train - INFO - alphas:tensor([0.0170, 0.9830], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,133 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,133 - train - INFO - True
2024-04-03 11:31:23,133 - train - INFO - alphas:tensor([5.6561e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,133 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,133 - train - INFO - True
2024-04-03 11:31:23,134 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:31:23,134 - train - INFO - tau:0.3277227574378037
2024-04-03 11:31:23,134 - train - INFO - avg block size:13.413793103448276
2024-04-03 11:31:24,014 - train - INFO - Test: [   0/39]  Time: 0.877 (0.877)  Loss:  0.3572 (0.3572)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-04-03 11:31:58,271 - train - INFO - Test: [  39/39]  Time: 0.863 (0.878)  Loss:  0.3743 (0.3633)  Acc@1: 87.5000 (92.5100)  Acc@5: 100.0000 (99.7500)
2024-04-03 11:32:00,146 - train - INFO - Train: 114 [   0/195 (  0%)]  Loss:  1.516783 (1.5168)  Time: 1.801s,  142.11/s  (1.801s,  142.11/s)  LR: 8.318e-05  Data: 0.194 (0.194)
2024-04-03 11:33:19,338 - train - INFO - Train: 114 [  50/195 ( 26%)]  Loss:  1.593669 (1.5649)  Time: 1.495s,  171.24/s  (1.588s,  161.20/s)  LR: 8.318e-05  Data: 0.006 (0.011)
2024-04-03 11:34:39,249 - train - INFO - Train: 114 [ 100/195 ( 52%)]  Loss:  1.606301 (1.5598)  Time: 1.593s,  160.72/s  (1.593s,  160.69/s)  LR: 8.318e-05  Data: 0.005 (0.009)
2024-04-03 11:35:59,770 - train - INFO - Train: 114 [ 150/195 ( 77%)]  Loss:  1.281889 (1.5462)  Time: 1.643s,  155.77/s  (1.599s,  160.12/s)  LR: 8.318e-05  Data: 0.005 (0.009)
2024-04-03 11:37:11,049 - train - INFO - Train: 114 [ 194/195 (100%)]  Loss:  1.408700 (1.5438)  Time: 1.592s,  160.83/s  (1.604s,  159.64/s)  LR: 8.318e-05  Data: 0.000 (0.008)
2024-04-03 11:37:11,054 - train - INFO - True
2024-04-03 11:37:11,056 - train - INFO - alphas:tensor([6.1411e-04, 9.9939e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,056 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,056 - train - INFO - True
2024-04-03 11:37:11,057 - train - INFO - alphas:tensor([0.0709, 0.9291], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,057 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,057 - train - INFO - True
2024-04-03 11:37:11,058 - train - INFO - alphas:tensor([0.5687, 0.4313], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,058 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,058 - train - INFO - True
2024-04-03 11:37:11,058 - train - INFO - alphas:tensor([0.4765, 0.5235], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,058 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,059 - train - INFO - True
2024-04-03 11:37:11,059 - train - INFO - alphas:tensor([0.1520, 0.8480], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,059 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,059 - train - INFO - True
2024-04-03 11:37:11,060 - train - INFO - alphas:tensor([0.2695, 0.7305], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,060 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,060 - train - INFO - True
2024-04-03 11:37:11,061 - train - INFO - alphas:tensor([0.5614, 0.4386], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,061 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,061 - train - INFO - True
2024-04-03 11:37:11,062 - train - INFO - alphas:tensor([0.4406, 0.5594], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,062 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,062 - train - INFO - True
2024-04-03 11:37:11,062 - train - INFO - alphas:tensor([0.2623, 0.7377], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,062 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,063 - train - INFO - True
2024-04-03 11:37:11,063 - train - INFO - alphas:tensor([0.4171, 0.5829], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,063 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,063 - train - INFO - True
2024-04-03 11:37:11,064 - train - INFO - alphas:tensor([0.5673, 0.4327], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,064 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,064 - train - INFO - True
2024-04-03 11:37:11,065 - train - INFO - alphas:tensor([0.4261, 0.5739], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,065 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,065 - train - INFO - True
2024-04-03 11:37:11,066 - train - INFO - alphas:tensor([0.2793, 0.7207], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,066 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,066 - train - INFO - True
2024-04-03 11:37:11,066 - train - INFO - alphas:tensor([0.4141, 0.5859], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,067 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,067 - train - INFO - True
2024-04-03 11:37:11,067 - train - INFO - alphas:tensor([0.5046, 0.4954], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,067 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,067 - train - INFO - True
2024-04-03 11:37:11,068 - train - INFO - alphas:tensor([0.3532, 0.6468], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,068 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,068 - train - INFO - True
2024-04-03 11:37:11,069 - train - INFO - alphas:tensor([0.2453, 0.7547], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,069 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,069 - train - INFO - True
2024-04-03 11:37:11,070 - train - INFO - alphas:tensor([0.3190, 0.6810], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,070 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,070 - train - INFO - True
2024-04-03 11:37:11,071 - train - INFO - alphas:tensor([0.3923, 0.6077], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,071 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,071 - train - INFO - True
2024-04-03 11:37:11,078 - train - INFO - alphas:tensor([0.2183, 0.7817], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,079 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,079 - train - INFO - True
2024-04-03 11:37:11,084 - train - INFO - alphas:tensor([0.1897, 0.8103], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,084 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,084 - train - INFO - True
2024-04-03 11:37:11,086 - train - INFO - alphas:tensor([0.2406, 0.7594], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,086 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,086 - train - INFO - True
2024-04-03 11:37:11,088 - train - INFO - alphas:tensor([0.3440, 0.6560], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,088 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,088 - train - INFO - True
2024-04-03 11:37:11,090 - train - INFO - alphas:tensor([0.1172, 0.8828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,090 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,090 - train - INFO - True
2024-04-03 11:37:11,092 - train - INFO - alphas:tensor([0.1244, 0.8756], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,092 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,092 - train - INFO - True
2024-04-03 11:37:11,094 - train - INFO - alphas:tensor([0.0101, 0.9899], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,094 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,094 - train - INFO - True
2024-04-03 11:37:11,096 - train - INFO - alphas:tensor([0.0163, 0.9837], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,096 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,096 - train - INFO - True
2024-04-03 11:37:11,097 - train - INFO - alphas:tensor([4.9540e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,097 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,097 - train - INFO - True
2024-04-03 11:37:11,098 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:37:11,099 - train - INFO - tau:0.3244455298634257
2024-04-03 11:37:11,099 - train - INFO - avg block size:13.413793103448276
2024-04-03 11:37:12,017 - train - INFO - Test: [   0/39]  Time: 0.916 (0.916)  Loss:  0.3494 (0.3494)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-04-03 11:37:46,301 - train - INFO - Test: [  39/39]  Time: 0.852 (0.880)  Loss:  0.4409 (0.3519)  Acc@1: 81.2500 (92.6200)  Acc@5: 100.0000 (99.7900)
2024-04-03 11:37:48,357 - train - INFO - Train: 115 [   0/195 (  0%)]  Loss:  1.158893 (1.1589)  Time: 1.944s,  131.66/s  (1.944s,  131.66/s)  LR: 7.935e-05  Data: 0.145 (0.145)
2024-04-03 11:39:07,811 - train - INFO - Train: 115 [  50/195 ( 26%)]  Loss:  1.478959 (1.5502)  Time: 1.519s,  168.54/s  (1.596s,  160.40/s)  LR: 7.935e-05  Data: 0.005 (0.011)
2024-04-03 11:40:27,364 - train - INFO - Train: 115 [ 100/195 ( 52%)]  Loss:  1.765768 (1.5290)  Time: 1.586s,  161.43/s  (1.594s,  160.65/s)  LR: 7.935e-05  Data: 0.005 (0.009)
2024-04-03 11:41:47,648 - train - INFO - Train: 115 [ 150/195 ( 77%)]  Loss:  1.667343 (1.5202)  Time: 1.536s,  166.68/s  (1.598s,  160.24/s)  LR: 7.935e-05  Data: 0.005 (0.009)
2024-04-03 11:43:01,087 - train - INFO - Train: 115 [ 194/195 (100%)]  Loss:  1.210275 (1.5208)  Time: 1.598s,  160.23/s  (1.614s,  158.64/s)  LR: 7.935e-05  Data: 0.000 (0.009)
2024-04-03 11:43:01,088 - train - INFO - True
2024-04-03 11:43:01,089 - train - INFO - alphas:tensor([5.5915e-04, 9.9944e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,089 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,089 - train - INFO - True
2024-04-03 11:43:01,090 - train - INFO - alphas:tensor([0.0700, 0.9300], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,090 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,090 - train - INFO - True
2024-04-03 11:43:01,090 - train - INFO - alphas:tensor([0.5686, 0.4314], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,091 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,091 - train - INFO - True
2024-04-03 11:43:01,091 - train - INFO - alphas:tensor([0.4762, 0.5238], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,091 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,091 - train - INFO - True
2024-04-03 11:43:01,092 - train - INFO - alphas:tensor([0.1505, 0.8495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,092 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,092 - train - INFO - True
2024-04-03 11:43:01,093 - train - INFO - alphas:tensor([0.2682, 0.7318], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,093 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,093 - train - INFO - True
2024-04-03 11:43:01,094 - train - INFO - alphas:tensor([0.5606, 0.4394], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,094 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,094 - train - INFO - True
2024-04-03 11:43:01,095 - train - INFO - alphas:tensor([0.4393, 0.5607], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,095 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,095 - train - INFO - True
2024-04-03 11:43:01,095 - train - INFO - alphas:tensor([0.2616, 0.7384], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,096 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,096 - train - INFO - True
2024-04-03 11:43:01,097 - train - INFO - alphas:tensor([0.4187, 0.5813], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,097 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,097 - train - INFO - True
2024-04-03 11:43:01,097 - train - INFO - alphas:tensor([0.5666, 0.4334], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,098 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,098 - train - INFO - True
2024-04-03 11:43:01,098 - train - INFO - alphas:tensor([0.4239, 0.5761], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,098 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,098 - train - INFO - True
2024-04-03 11:43:01,099 - train - INFO - alphas:tensor([0.2784, 0.7216], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,099 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,099 - train - INFO - True
2024-04-03 11:43:01,100 - train - INFO - alphas:tensor([0.4131, 0.5869], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,100 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,100 - train - INFO - True
2024-04-03 11:43:01,101 - train - INFO - alphas:tensor([0.5040, 0.4960], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,101 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,101 - train - INFO - True
2024-04-03 11:43:01,102 - train - INFO - alphas:tensor([0.3520, 0.6480], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,102 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,102 - train - INFO - True
2024-04-03 11:43:01,102 - train - INFO - alphas:tensor([0.2452, 0.7548], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,102 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,103 - train - INFO - True
2024-04-03 11:43:01,103 - train - INFO - alphas:tensor([0.3187, 0.6813], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,103 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,103 - train - INFO - True
2024-04-03 11:43:01,104 - train - INFO - alphas:tensor([0.3923, 0.6077], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,104 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,104 - train - INFO - True
2024-04-03 11:43:01,105 - train - INFO - alphas:tensor([0.2181, 0.7819], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,105 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,105 - train - INFO - True
2024-04-03 11:43:01,106 - train - INFO - alphas:tensor([0.1891, 0.8109], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,106 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,106 - train - INFO - True
2024-04-03 11:43:01,106 - train - INFO - alphas:tensor([0.2391, 0.7609], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,107 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,107 - train - INFO - True
2024-04-03 11:43:01,107 - train - INFO - alphas:tensor([0.3444, 0.6556], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,107 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,107 - train - INFO - True
2024-04-03 11:43:01,108 - train - INFO - alphas:tensor([0.1165, 0.8835], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,108 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,108 - train - INFO - True
2024-04-03 11:43:01,109 - train - INFO - alphas:tensor([0.1241, 0.8759], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,109 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,109 - train - INFO - True
2024-04-03 11:43:01,110 - train - INFO - alphas:tensor([0.0095, 0.9905], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,110 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,110 - train - INFO - True
2024-04-03 11:43:01,111 - train - INFO - alphas:tensor([0.0156, 0.9844], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,111 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,111 - train - INFO - True
2024-04-03 11:43:01,111 - train - INFO - alphas:tensor([4.3366e-06, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,111 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,112 - train - INFO - True
2024-04-03 11:43:01,112 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:43:01,112 - train - INFO - tau:0.3212010745647914
2024-04-03 11:43:01,112 - train - INFO - avg block size:13.413793103448276
2024-04-03 11:43:02,055 - train - INFO - Test: [   0/39]  Time: 0.940 (0.940)  Loss:  0.3491 (0.3491)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-03 11:43:36,301 - train - INFO - Test: [  39/39]  Time: 0.866 (0.880)  Loss:  0.3450 (0.3515)  Acc@1: 87.5000 (92.5900)  Acc@5: 100.0000 (99.8000)
2024-04-03 11:43:38,101 - train - INFO - Train: 116 [   0/195 (  0%)]  Loss:  1.593271 (1.5933)  Time: 1.652s,  154.92/s  (1.652s,  154.92/s)  LR: 7.561e-05  Data: 0.158 (0.158)
2024-04-03 11:44:57,785 - train - INFO - Train: 116 [  50/195 ( 26%)]  Loss:  1.732588 (1.5684)  Time: 1.551s,  165.00/s  (1.595s,  160.53/s)  LR: 7.561e-05  Data: 0.006 (0.011)
2024-04-03 11:46:17,903 - train - INFO - Train: 116 [ 100/195 ( 52%)]  Loss:  1.680462 (1.5501)  Time: 1.648s,  155.39/s  (1.598s,  160.15/s)  LR: 7.561e-05  Data: 0.005 (0.009)
2024-04-03 11:47:37,852 - train - INFO - Train: 116 [ 150/195 ( 77%)]  Loss:  1.722847 (1.5536)  Time: 1.653s,  154.84/s  (1.599s,  160.14/s)  LR: 7.561e-05  Data: 0.006 (0.009)
2024-04-03 11:48:49,518 - train - INFO - Train: 116 [ 194/195 (100%)]  Loss:  1.563107 (1.5536)  Time: 1.606s,  159.43/s  (1.605s,  159.46/s)  LR: 7.561e-05  Data: 0.000 (0.009)
2024-04-03 11:48:49,518 - train - INFO - True
2024-04-03 11:48:49,519 - train - INFO - alphas:tensor([5.0850e-04, 9.9949e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,520 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,520 - train - INFO - True
2024-04-03 11:48:49,520 - train - INFO - alphas:tensor([0.0686, 0.9314], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,521 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,521 - train - INFO - True
2024-04-03 11:48:49,521 - train - INFO - alphas:tensor([0.5668, 0.4332], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,521 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,521 - train - INFO - True
2024-04-03 11:48:49,522 - train - INFO - alphas:tensor([0.4740, 0.5260], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,522 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,522 - train - INFO - True
2024-04-03 11:48:49,523 - train - INFO - alphas:tensor([0.1496, 0.8504], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,523 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,523 - train - INFO - True
2024-04-03 11:48:49,524 - train - INFO - alphas:tensor([0.2678, 0.7322], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,524 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,524 - train - INFO - True
2024-04-03 11:48:49,525 - train - INFO - alphas:tensor([0.5601, 0.4399], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,525 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,525 - train - INFO - True
2024-04-03 11:48:49,526 - train - INFO - alphas:tensor([0.4388, 0.5612], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,526 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,526 - train - INFO - True
2024-04-03 11:48:49,527 - train - INFO - alphas:tensor([0.2599, 0.7401], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,527 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,527 - train - INFO - True
2024-04-03 11:48:49,527 - train - INFO - alphas:tensor([0.4166, 0.5834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,531 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,531 - train - INFO - True
2024-04-03 11:48:49,532 - train - INFO - alphas:tensor([0.5667, 0.4333], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,532 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,532 - train - INFO - True
2024-04-03 11:48:49,533 - train - INFO - alphas:tensor([0.4232, 0.5768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,533 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,533 - train - INFO - True
2024-04-03 11:48:49,534 - train - INFO - alphas:tensor([0.2777, 0.7223], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,534 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,534 - train - INFO - True
2024-04-03 11:48:49,535 - train - INFO - alphas:tensor([0.4132, 0.5868], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,535 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,535 - train - INFO - True
2024-04-03 11:48:49,535 - train - INFO - alphas:tensor([0.5036, 0.4964], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,536 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,536 - train - INFO - True
2024-04-03 11:48:49,537 - train - INFO - alphas:tensor([0.3516, 0.6484], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,537 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,537 - train - INFO - True
2024-04-03 11:48:49,538 - train - INFO - alphas:tensor([0.2430, 0.7570], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,538 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,538 - train - INFO - True
2024-04-03 11:48:49,539 - train - INFO - alphas:tensor([0.3169, 0.6831], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,539 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,539 - train - INFO - True
2024-04-03 11:48:49,540 - train - INFO - alphas:tensor([0.3915, 0.6085], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,540 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,540 - train - INFO - True
2024-04-03 11:48:49,549 - train - INFO - alphas:tensor([0.2173, 0.7827], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,549 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,549 - train - INFO - True
2024-04-03 11:48:49,550 - train - INFO - alphas:tensor([0.1880, 0.8120], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,550 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,550 - train - INFO - True
2024-04-03 11:48:49,551 - train - INFO - alphas:tensor([0.2387, 0.7613], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,551 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,551 - train - INFO - True
2024-04-03 11:48:49,552 - train - INFO - alphas:tensor([0.3448, 0.6552], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,552 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,552 - train - INFO - True
2024-04-03 11:48:49,552 - train - INFO - alphas:tensor([0.1153, 0.8847], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,553 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,553 - train - INFO - True
2024-04-03 11:48:49,553 - train - INFO - alphas:tensor([0.1230, 0.8770], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,562 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,562 - train - INFO - True
2024-04-03 11:48:49,563 - train - INFO - alphas:tensor([0.0089, 0.9911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,563 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,563 - train - INFO - True
2024-04-03 11:48:49,564 - train - INFO - alphas:tensor([0.0150, 0.9850], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,564 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,564 - train - INFO - True
2024-04-03 11:48:49,564 - train - INFO - alphas:tensor([3.7930e-06, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,565 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,565 - train - INFO - True
2024-04-03 11:48:49,565 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:48:49,565 - train - INFO - tau:0.3179890638191435
2024-04-03 11:48:49,565 - train - INFO - avg block size:13.413793103448276
2024-04-03 11:48:50,506 - train - INFO - Test: [   0/39]  Time: 0.929 (0.929)  Loss:  0.3489 (0.3489)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-03 11:49:25,634 - train - INFO - Test: [  39/39]  Time: 0.951 (0.901)  Loss:  0.3538 (0.3543)  Acc@1: 87.5000 (92.7400)  Acc@5: 100.0000 (99.7600)
2024-04-03 11:49:27,614 - train - INFO - Train: 117 [   0/195 (  0%)]  Loss:  1.649085 (1.6491)  Time: 1.803s,  141.99/s  (1.803s,  141.99/s)  LR: 7.196e-05  Data: 0.294 (0.294)
2024-04-03 11:50:48,572 - train - INFO - Train: 117 [  50/195 ( 26%)]  Loss:  1.383695 (1.5305)  Time: 1.608s,  159.24/s  (1.623s,  157.76/s)  LR: 7.196e-05  Data: 0.009 (0.014)
2024-04-03 11:52:09,074 - train - INFO - Train: 117 [ 100/195 ( 52%)]  Loss:  1.202727 (1.5430)  Time: 1.608s,  159.21/s  (1.616s,  158.37/s)  LR: 7.196e-05  Data: 0.006 (0.011)
2024-04-03 11:53:29,531 - train - INFO - Train: 117 [ 150/195 ( 77%)]  Loss:  1.746654 (1.5374)  Time: 1.686s,  151.88/s  (1.614s,  158.61/s)  LR: 7.196e-05  Data: 0.005 (0.010)
2024-04-03 11:54:39,197 - train - INFO - Train: 117 [ 194/195 (100%)]  Loss:  1.674359 (1.5347)  Time: 1.519s,  168.52/s  (1.607s,  159.29/s)  LR: 7.196e-05  Data: 0.000 (0.009)
2024-04-03 11:54:39,197 - train - INFO - True
2024-04-03 11:54:39,198 - train - INFO - alphas:tensor([4.6266e-04, 9.9954e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,198 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,199 - train - INFO - True
2024-04-03 11:54:39,199 - train - INFO - alphas:tensor([0.0675, 0.9325], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,199 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,199 - train - INFO - True
2024-04-03 11:54:39,200 - train - INFO - alphas:tensor([0.5679, 0.4321], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,200 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,200 - train - INFO - True
2024-04-03 11:54:39,201 - train - INFO - alphas:tensor([0.4746, 0.5254], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,201 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,201 - train - INFO - True
2024-04-03 11:54:39,202 - train - INFO - alphas:tensor([0.1485, 0.8515], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,202 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,202 - train - INFO - True
2024-04-03 11:54:39,203 - train - INFO - alphas:tensor([0.2667, 0.7333], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,203 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,204 - train - INFO - True
2024-04-03 11:54:39,204 - train - INFO - alphas:tensor([0.5588, 0.4412], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,204 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,204 - train - INFO - True
2024-04-03 11:54:39,205 - train - INFO - alphas:tensor([0.4366, 0.5634], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,210 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,210 - train - INFO - True
2024-04-03 11:54:39,211 - train - INFO - alphas:tensor([0.2600, 0.7400], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,211 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,211 - train - INFO - True
2024-04-03 11:54:39,212 - train - INFO - alphas:tensor([0.4171, 0.5829], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,212 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,212 - train - INFO - True
2024-04-03 11:54:39,213 - train - INFO - alphas:tensor([0.5666, 0.4334], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,213 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,213 - train - INFO - True
2024-04-03 11:54:39,213 - train - INFO - alphas:tensor([0.4223, 0.5777], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,213 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,214 - train - INFO - True
2024-04-03 11:54:39,214 - train - INFO - alphas:tensor([0.2775, 0.7225], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,214 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,214 - train - INFO - True
2024-04-03 11:54:39,215 - train - INFO - alphas:tensor([0.4124, 0.5876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,220 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,220 - train - INFO - True
2024-04-03 11:54:39,220 - train - INFO - alphas:tensor([0.5029, 0.4971], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,220 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,220 - train - INFO - True
2024-04-03 11:54:39,221 - train - INFO - alphas:tensor([0.3515, 0.6485], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,221 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,221 - train - INFO - True
2024-04-03 11:54:39,222 - train - INFO - alphas:tensor([0.2423, 0.7577], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,223 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,223 - train - INFO - True
2024-04-03 11:54:39,223 - train - INFO - alphas:tensor([0.3156, 0.6844], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,223 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,223 - train - INFO - True
2024-04-03 11:54:39,224 - train - INFO - alphas:tensor([0.3903, 0.6097], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,224 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,224 - train - INFO - True
2024-04-03 11:54:39,225 - train - INFO - alphas:tensor([0.2162, 0.7838], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,225 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,225 - train - INFO - True
2024-04-03 11:54:39,226 - train - INFO - alphas:tensor([0.1869, 0.8131], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,226 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,226 - train - INFO - True
2024-04-03 11:54:39,227 - train - INFO - alphas:tensor([0.2375, 0.7625], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,227 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,227 - train - INFO - True
2024-04-03 11:54:39,227 - train - INFO - alphas:tensor([0.3442, 0.6558], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,228 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,228 - train - INFO - True
2024-04-03 11:54:39,228 - train - INFO - alphas:tensor([0.1148, 0.8852], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,228 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,228 - train - INFO - True
2024-04-03 11:54:39,229 - train - INFO - alphas:tensor([0.1224, 0.8776], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,229 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,229 - train - INFO - True
2024-04-03 11:54:39,230 - train - INFO - alphas:tensor([0.0084, 0.9916], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,230 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,230 - train - INFO - True
2024-04-03 11:54:39,231 - train - INFO - alphas:tensor([0.0143, 0.9857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,231 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,231 - train - INFO - True
2024-04-03 11:54:39,231 - train - INFO - alphas:tensor([3.3156e-06, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,232 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,232 - train - INFO - True
2024-04-03 11:54:39,232 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 11:54:39,232 - train - INFO - tau:0.31480917318095203
2024-04-03 11:54:39,232 - train - INFO - avg block size:13.413793103448276
2024-04-03 11:54:40,117 - train - INFO - Test: [   0/39]  Time: 0.883 (0.883)  Loss:  0.3479 (0.3479)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-03 11:55:15,026 - train - INFO - Test: [  39/39]  Time: 0.891 (0.895)  Loss:  0.4153 (0.3526)  Acc@1: 81.2500 (92.5800)  Acc@5: 100.0000 (99.7800)
2024-04-03 11:55:16,914 - train - INFO - Train: 118 [   0/195 (  0%)]  Loss:  1.291973 (1.2920)  Time: 1.745s,  146.69/s  (1.745s,  146.69/s)  LR: 6.840e-05  Data: 0.158 (0.158)
2024-04-03 11:56:37,182 - train - INFO - Train: 118 [  50/195 ( 26%)]  Loss:  1.286053 (1.5486)  Time: 1.502s,  170.41/s  (1.608s,  159.20/s)  LR: 6.840e-05  Data: 0.008 (0.011)
2024-04-03 11:57:58,080 - train - INFO - Train: 118 [ 100/195 ( 52%)]  Loss:  1.628633 (1.5207)  Time: 1.650s,  155.19/s  (1.613s,  158.71/s)  LR: 6.840e-05  Data: 0.005 (0.009)
2024-04-03 11:59:19,530 - train - INFO - Train: 118 [ 150/195 ( 77%)]  Loss:  1.334582 (1.5168)  Time: 1.591s,  160.86/s  (1.618s,  158.20/s)  LR: 6.840e-05  Data: 0.005 (0.009)
2024-04-03 12:00:30,568 - train - INFO - Train: 118 [ 194/195 (100%)]  Loss:  1.423864 (1.5138)  Time: 1.484s,  172.53/s  (1.617s,  158.28/s)  LR: 6.840e-05  Data: 0.000 (0.008)
2024-04-03 12:00:30,569 - train - INFO - True
2024-04-03 12:00:30,570 - train - INFO - alphas:tensor([4.2134e-04, 9.9958e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,570 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,570 - train - INFO - True
2024-04-03 12:00:30,571 - train - INFO - alphas:tensor([0.0667, 0.9333], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,571 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,571 - train - INFO - True
2024-04-03 12:00:30,572 - train - INFO - alphas:tensor([0.5670, 0.4330], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,572 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,572 - train - INFO - True
2024-04-03 12:00:30,573 - train - INFO - alphas:tensor([0.4731, 0.5269], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,573 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,573 - train - INFO - True
2024-04-03 12:00:30,573 - train - INFO - alphas:tensor([0.1477, 0.8523], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,574 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,574 - train - INFO - True
2024-04-03 12:00:30,574 - train - INFO - alphas:tensor([0.2664, 0.7336], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,574 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,574 - train - INFO - True
2024-04-03 12:00:30,575 - train - INFO - alphas:tensor([0.5589, 0.4411], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,575 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,575 - train - INFO - True
2024-04-03 12:00:30,576 - train - INFO - alphas:tensor([0.4362, 0.5638], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,576 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,576 - train - INFO - True
2024-04-03 12:00:30,577 - train - INFO - alphas:tensor([0.2585, 0.7415], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,577 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,577 - train - INFO - True
2024-04-03 12:00:30,578 - train - INFO - alphas:tensor([0.4153, 0.5847], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,578 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,578 - train - INFO - True
2024-04-03 12:00:30,579 - train - INFO - alphas:tensor([0.5663, 0.4337], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,579 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,579 - train - INFO - True
2024-04-03 12:00:30,580 - train - INFO - alphas:tensor([0.4221, 0.5779], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,580 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,580 - train - INFO - True
2024-04-03 12:00:30,580 - train - INFO - alphas:tensor([0.2778, 0.7222], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,580 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,581 - train - INFO - True
2024-04-03 12:00:30,581 - train - INFO - alphas:tensor([0.4127, 0.5873], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,581 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,581 - train - INFO - True
2024-04-03 12:00:30,582 - train - INFO - alphas:tensor([0.5029, 0.4971], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,582 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,582 - train - INFO - True
2024-04-03 12:00:30,583 - train - INFO - alphas:tensor([0.3529, 0.6471], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,583 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,583 - train - INFO - True
2024-04-03 12:00:30,584 - train - INFO - alphas:tensor([0.2421, 0.7579], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,584 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,584 - train - INFO - True
2024-04-03 12:00:30,584 - train - INFO - alphas:tensor([0.3166, 0.6834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,585 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,585 - train - INFO - True
2024-04-03 12:00:30,585 - train - INFO - alphas:tensor([0.3897, 0.6103], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,585 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,585 - train - INFO - True
2024-04-03 12:00:30,586 - train - INFO - alphas:tensor([0.2147, 0.7853], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,586 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,586 - train - INFO - True
2024-04-03 12:00:30,587 - train - INFO - alphas:tensor([0.1866, 0.8134], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,587 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,587 - train - INFO - True
2024-04-03 12:00:30,588 - train - INFO - alphas:tensor([0.2378, 0.7622], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,588 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,588 - train - INFO - True
2024-04-03 12:00:30,589 - train - INFO - alphas:tensor([0.3431, 0.6569], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,589 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,589 - train - INFO - True
2024-04-03 12:00:30,590 - train - INFO - alphas:tensor([0.1143, 0.8857], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,590 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,590 - train - INFO - True
2024-04-03 12:00:30,591 - train - INFO - alphas:tensor([0.1212, 0.8788], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,591 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,591 - train - INFO - True
2024-04-03 12:00:30,591 - train - INFO - alphas:tensor([0.0079, 0.9921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,591 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,591 - train - INFO - True
2024-04-03 12:00:30,592 - train - INFO - alphas:tensor([0.0137, 0.9863], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,592 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,592 - train - INFO - True
2024-04-03 12:00:30,593 - train - INFO - alphas:tensor([2.8953e-06, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,593 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,593 - train - INFO - True
2024-04-03 12:00:30,594 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:00:30,594 - train - INFO - tau:0.3116610814491425
2024-04-03 12:00:30,594 - train - INFO - avg block size:13.413793103448276
2024-04-03 12:00:31,523 - train - INFO - Test: [   0/39]  Time: 0.927 (0.927)  Loss:  0.3628 (0.3628)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-04-03 12:01:06,356 - train - INFO - Test: [  39/39]  Time: 0.869 (0.894)  Loss:  0.3999 (0.3632)  Acc@1: 81.2500 (92.6900)  Acc@5: 100.0000 (99.7900)
2024-04-03 12:01:08,210 - train - INFO - Train: 119 [   0/195 (  0%)]  Loss:  1.419476 (1.4195)  Time: 1.717s,  149.13/s  (1.717s,  149.13/s)  LR: 6.494e-05  Data: 0.200 (0.200)
2024-04-03 12:02:27,967 - train - INFO - Train: 119 [  50/195 ( 26%)]  Loss:  1.658148 (1.5431)  Time: 1.597s,  160.31/s  (1.598s,  160.25/s)  LR: 6.494e-05  Data: 0.010 (0.011)
2024-04-03 12:03:47,841 - train - INFO - Train: 119 [ 100/195 ( 52%)]  Loss:  1.715304 (1.5294)  Time: 1.638s,  156.33/s  (1.597s,  160.25/s)  LR: 6.494e-05  Data: 0.008 (0.009)
2024-04-03 12:05:07,691 - train - INFO - Train: 119 [ 150/195 ( 77%)]  Loss:  1.544350 (1.5242)  Time: 1.544s,  165.84/s  (1.597s,  160.27/s)  LR: 6.494e-05  Data: 0.005 (0.009)
2024-04-03 12:06:18,458 - train - INFO - Train: 119 [ 194/195 (100%)]  Loss:  1.303605 (1.5224)  Time: 1.477s,  173.32/s  (1.600s,  160.02/s)  LR: 6.494e-05  Data: 0.000 (0.009)
2024-04-03 12:06:18,459 - train - INFO - True
2024-04-03 12:06:18,460 - train - INFO - alphas:tensor([3.8371e-04, 9.9962e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,460 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,460 - train - INFO - True
2024-04-03 12:06:18,461 - train - INFO - alphas:tensor([0.0658, 0.9342], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,461 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,461 - train - INFO - True
2024-04-03 12:06:18,462 - train - INFO - alphas:tensor([0.5673, 0.4327], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,462 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,462 - train - INFO - True
2024-04-03 12:06:18,462 - train - INFO - alphas:tensor([0.4730, 0.5270], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,463 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,463 - train - INFO - True
2024-04-03 12:06:18,463 - train - INFO - alphas:tensor([0.1464, 0.8536], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,463 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,463 - train - INFO - True
2024-04-03 12:06:18,464 - train - INFO - alphas:tensor([0.2658, 0.7342], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,464 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,464 - train - INFO - True
2024-04-03 12:06:18,465 - train - INFO - alphas:tensor([0.5591, 0.4409], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,465 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,465 - train - INFO - True
2024-04-03 12:06:18,466 - train - INFO - alphas:tensor([0.4366, 0.5634], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,466 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,466 - train - INFO - True
2024-04-03 12:06:18,467 - train - INFO - alphas:tensor([0.2591, 0.7409], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,467 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,467 - train - INFO - True
2024-04-03 12:06:18,467 - train - INFO - alphas:tensor([0.4162, 0.5838], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,468 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,468 - train - INFO - True
2024-04-03 12:06:18,469 - train - INFO - alphas:tensor([0.5658, 0.4342], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,469 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,469 - train - INFO - True
2024-04-03 12:06:18,469 - train - INFO - alphas:tensor([0.4221, 0.5779], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,470 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,470 - train - INFO - True
2024-04-03 12:06:18,470 - train - INFO - alphas:tensor([0.2769, 0.7231], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,470 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,470 - train - INFO - True
2024-04-03 12:06:18,471 - train - INFO - alphas:tensor([0.4123, 0.5877], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,471 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,471 - train - INFO - True
2024-04-03 12:06:18,472 - train - INFO - alphas:tensor([0.5018, 0.4982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,472 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,472 - train - INFO - True
2024-04-03 12:06:18,473 - train - INFO - alphas:tensor([0.3517, 0.6483], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,473 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,473 - train - INFO - True
2024-04-03 12:06:18,474 - train - INFO - alphas:tensor([0.2411, 0.7589], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,474 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,474 - train - INFO - True
2024-04-03 12:06:18,474 - train - INFO - alphas:tensor([0.3155, 0.6845], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,475 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,475 - train - INFO - True
2024-04-03 12:06:18,475 - train - INFO - alphas:tensor([0.3902, 0.6098], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,475 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,475 - train - INFO - True
2024-04-03 12:06:18,476 - train - INFO - alphas:tensor([0.2151, 0.7849], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,476 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,476 - train - INFO - True
2024-04-03 12:06:18,477 - train - INFO - alphas:tensor([0.1854, 0.8146], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,477 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,477 - train - INFO - True
2024-04-03 12:06:18,478 - train - INFO - alphas:tensor([0.2369, 0.7631], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,478 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,478 - train - INFO - True
2024-04-03 12:06:18,479 - train - INFO - alphas:tensor([0.3437, 0.6563], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,479 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,479 - train - INFO - True
2024-04-03 12:06:18,479 - train - INFO - alphas:tensor([0.1131, 0.8869], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,479 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,480 - train - INFO - True
2024-04-03 12:06:18,480 - train - INFO - alphas:tensor([0.1209, 0.8791], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,480 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,480 - train - INFO - True
2024-04-03 12:06:18,481 - train - INFO - alphas:tensor([0.0074, 0.9926], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,481 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,481 - train - INFO - True
2024-04-03 12:06:18,482 - train - INFO - alphas:tensor([0.0131, 0.9869], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,482 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,482 - train - INFO - True
2024-04-03 12:06:18,483 - train - INFO - alphas:tensor([2.5266e-06, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,483 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,483 - train - INFO - True
2024-04-03 12:06:18,483 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:06:18,484 - train - INFO - tau:0.30854447063465107
2024-04-03 12:06:18,484 - train - INFO - avg block size:13.413793103448276
2024-04-03 12:06:19,447 - train - INFO - Test: [   0/39]  Time: 0.961 (0.961)  Loss:  0.3535 (0.3535)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 12:06:55,089 - train - INFO - Test: [  39/39]  Time: 0.942 (0.915)  Loss:  0.3689 (0.3573)  Acc@1: 87.5000 (92.7600)  Acc@5: 100.0000 (99.7900)
2024-04-03 12:06:56,983 - train - INFO - Train: 120 [   0/195 (  0%)]  Loss:  1.400476 (1.4005)  Time: 1.789s,  143.10/s  (1.789s,  143.10/s)  LR: 6.157e-05  Data: 0.216 (0.216)
2024-04-03 12:08:20,176 - train - INFO - Train: 120 [  50/195 ( 26%)]  Loss:  1.334291 (1.5344)  Time: 1.462s,  175.07/s  (1.666s,  153.63/s)  LR: 6.157e-05  Data: 0.006 (0.012)
2024-04-03 12:09:40,356 - train - INFO - Train: 120 [ 100/195 ( 52%)]  Loss:  1.608872 (1.5401)  Time: 1.520s,  168.38/s  (1.635s,  156.55/s)  LR: 6.157e-05  Data: 0.005 (0.009)
2024-04-03 12:10:59,661 - train - INFO - Train: 120 [ 150/195 ( 77%)]  Loss:  1.725654 (1.5376)  Time: 1.646s,  155.56/s  (1.619s,  158.13/s)  LR: 6.157e-05  Data: 0.006 (0.009)
2024-04-03 12:12:10,040 - train - INFO - Train: 120 [ 194/195 (100%)]  Loss:  1.560249 (1.5420)  Time: 1.433s,  178.61/s  (1.615s,  158.56/s)  LR: 6.157e-05  Data: 0.000 (0.008)
2024-04-03 12:12:10,041 - train - INFO - True
2024-04-03 12:12:10,042 - train - INFO - alphas:tensor([3.4869e-04, 9.9965e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,042 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,042 - train - INFO - True
2024-04-03 12:12:10,043 - train - INFO - alphas:tensor([0.0647, 0.9353], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,043 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,043 - train - INFO - True
2024-04-03 12:12:10,044 - train - INFO - alphas:tensor([0.5683, 0.4317], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,044 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,044 - train - INFO - True
2024-04-03 12:12:10,045 - train - INFO - alphas:tensor([0.4730, 0.5270], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,045 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,045 - train - INFO - True
2024-04-03 12:12:10,046 - train - INFO - alphas:tensor([0.1460, 0.8540], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,046 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,046 - train - INFO - True
2024-04-03 12:12:10,046 - train - INFO - alphas:tensor([0.2654, 0.7346], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,047 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,047 - train - INFO - True
2024-04-03 12:12:10,047 - train - INFO - alphas:tensor([0.5585, 0.4415], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,048 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,048 - train - INFO - True
2024-04-03 12:12:10,049 - train - INFO - alphas:tensor([0.4354, 0.5646], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,049 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,049 - train - INFO - True
2024-04-03 12:12:10,049 - train - INFO - alphas:tensor([0.2573, 0.7427], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,050 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,050 - train - INFO - True
2024-04-03 12:12:10,050 - train - INFO - alphas:tensor([0.4154, 0.5846], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,050 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,050 - train - INFO - True
2024-04-03 12:12:10,051 - train - INFO - alphas:tensor([0.5649, 0.4351], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,051 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,051 - train - INFO - True
2024-04-03 12:12:10,052 - train - INFO - alphas:tensor([0.4223, 0.5777], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,052 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,052 - train - INFO - True
2024-04-03 12:12:10,053 - train - INFO - alphas:tensor([0.2758, 0.7242], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,053 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,053 - train - INFO - True
2024-04-03 12:12:10,054 - train - INFO - alphas:tensor([0.4127, 0.5873], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,054 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,054 - train - INFO - True
2024-04-03 12:12:10,054 - train - INFO - alphas:tensor([0.5014, 0.4986], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,054 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,055 - train - INFO - True
2024-04-03 12:12:10,055 - train - INFO - alphas:tensor([0.3500, 0.6500], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,055 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,055 - train - INFO - True
2024-04-03 12:12:10,056 - train - INFO - alphas:tensor([0.2405, 0.7595], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,056 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,056 - train - INFO - True
2024-04-03 12:12:10,057 - train - INFO - alphas:tensor([0.3156, 0.6844], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,057 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,057 - train - INFO - True
2024-04-03 12:12:10,058 - train - INFO - alphas:tensor([0.3893, 0.6107], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,058 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,058 - train - INFO - True
2024-04-03 12:12:10,058 - train - INFO - alphas:tensor([0.2150, 0.7850], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,059 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,059 - train - INFO - True
2024-04-03 12:12:10,059 - train - INFO - alphas:tensor([0.1848, 0.8152], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,059 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,059 - train - INFO - True
2024-04-03 12:12:10,060 - train - INFO - alphas:tensor([0.2370, 0.7630], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,060 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,060 - train - INFO - True
2024-04-03 12:12:10,061 - train - INFO - alphas:tensor([0.3437, 0.6563], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,061 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,061 - train - INFO - True
2024-04-03 12:12:10,062 - train - INFO - alphas:tensor([0.1124, 0.8876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,062 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,062 - train - INFO - True
2024-04-03 12:12:10,063 - train - INFO - alphas:tensor([0.1202, 0.8798], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,063 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,063 - train - INFO - True
2024-04-03 12:12:10,063 - train - INFO - alphas:tensor([0.0070, 0.9930], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,064 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,064 - train - INFO - True
2024-04-03 12:12:10,064 - train - INFO - alphas:tensor([0.0126, 0.9874], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,064 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,064 - train - INFO - True
2024-04-03 12:12:10,065 - train - INFO - alphas:tensor([2.2029e-06, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,065 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,065 - train - INFO - True
2024-04-03 12:12:10,066 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:12:10,066 - train - INFO - tau:0.30545902592830454
2024-04-03 12:12:10,066 - train - INFO - avg block size:13.413793103448276
2024-04-03 12:12:10,989 - train - INFO - Test: [   0/39]  Time: 0.920 (0.920)  Loss:  0.3643 (0.3643)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-04-03 12:12:45,402 - train - INFO - Test: [  39/39]  Time: 0.854 (0.883)  Loss:  0.3896 (0.3571)  Acc@1: 81.2500 (92.6800)  Acc@5: 100.0000 (99.8000)
2024-04-03 12:12:47,204 - train - INFO - Train: 121 [   0/195 (  0%)]  Loss:  1.318969 (1.3190)  Time: 1.647s,  155.39/s  (1.647s,  155.39/s)  LR: 5.829e-05  Data: 0.183 (0.183)
2024-04-03 12:14:07,237 - train - INFO - Train: 121 [  50/195 ( 26%)]  Loss:  1.386631 (1.4977)  Time: 1.801s,  142.12/s  (1.602s,  159.84/s)  LR: 5.829e-05  Data: 0.005 (0.011)
2024-04-03 12:15:27,914 - train - INFO - Train: 121 [ 100/195 ( 52%)]  Loss:  1.809291 (1.5181)  Time: 1.715s,  149.31/s  (1.607s,  159.26/s)  LR: 5.829e-05  Data: 0.006 (0.009)
2024-04-03 12:16:48,324 - train - INFO - Train: 121 [ 150/195 ( 77%)]  Loss:  1.408322 (1.5273)  Time: 1.639s,  156.23/s  (1.608s,  159.23/s)  LR: 5.829e-05  Data: 0.006 (0.009)
2024-04-03 12:18:00,086 - train - INFO - Train: 121 [ 194/195 (100%)]  Loss:  1.163216 (1.5197)  Time: 1.604s,  159.63/s  (1.613s,  158.72/s)  LR: 5.829e-05  Data: 0.000 (0.009)
2024-04-03 12:18:00,086 - train - INFO - True
2024-04-03 12:18:00,088 - train - INFO - alphas:tensor([3.1718e-04, 9.9968e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,088 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,088 - train - INFO - True
2024-04-03 12:18:00,089 - train - INFO - alphas:tensor([0.0637, 0.9363], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,089 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,089 - train - INFO - True
2024-04-03 12:18:00,090 - train - INFO - alphas:tensor([0.5675, 0.4325], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,090 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,090 - train - INFO - True
2024-04-03 12:18:00,090 - train - INFO - alphas:tensor([0.4716, 0.5284], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,090 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,091 - train - INFO - True
2024-04-03 12:18:00,091 - train - INFO - alphas:tensor([0.1449, 0.8551], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,091 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,091 - train - INFO - True
2024-04-03 12:18:00,092 - train - INFO - alphas:tensor([0.2642, 0.7358], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,092 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,092 - train - INFO - True
2024-04-03 12:18:00,093 - train - INFO - alphas:tensor([0.5584, 0.4416], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,093 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,093 - train - INFO - True
2024-04-03 12:18:00,094 - train - INFO - alphas:tensor([0.4350, 0.5650], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,094 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,094 - train - INFO - True
2024-04-03 12:18:00,095 - train - INFO - alphas:tensor([0.2569, 0.7431], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,095 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,095 - train - INFO - True
2024-04-03 12:18:00,096 - train - INFO - alphas:tensor([0.4152, 0.5848], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,096 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,096 - train - INFO - True
2024-04-03 12:18:00,097 - train - INFO - alphas:tensor([0.5655, 0.4345], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,097 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,097 - train - INFO - True
2024-04-03 12:18:00,097 - train - INFO - alphas:tensor([0.4216, 0.5784], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,098 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,098 - train - INFO - True
2024-04-03 12:18:00,098 - train - INFO - alphas:tensor([0.2751, 0.7249], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,098 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,098 - train - INFO - True
2024-04-03 12:18:00,099 - train - INFO - alphas:tensor([0.4113, 0.5887], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,099 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,099 - train - INFO - True
2024-04-03 12:18:00,100 - train - INFO - alphas:tensor([0.5008, 0.4992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,100 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,100 - train - INFO - True
2024-04-03 12:18:00,101 - train - INFO - alphas:tensor([0.3493, 0.6507], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,101 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,101 - train - INFO - True
2024-04-03 12:18:00,101 - train - INFO - alphas:tensor([0.2407, 0.7593], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,102 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,102 - train - INFO - True
2024-04-03 12:18:00,102 - train - INFO - alphas:tensor([0.3160, 0.6840], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,102 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,102 - train - INFO - True
2024-04-03 12:18:00,103 - train - INFO - alphas:tensor([0.3889, 0.6111], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,103 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,103 - train - INFO - True
2024-04-03 12:18:00,104 - train - INFO - alphas:tensor([0.2138, 0.7862], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,104 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,104 - train - INFO - True
2024-04-03 12:18:00,105 - train - INFO - alphas:tensor([0.1837, 0.8163], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,105 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,105 - train - INFO - True
2024-04-03 12:18:00,105 - train - INFO - alphas:tensor([0.2356, 0.7644], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,106 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,106 - train - INFO - True
2024-04-03 12:18:00,106 - train - INFO - alphas:tensor([0.3423, 0.6577], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,106 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,106 - train - INFO - True
2024-04-03 12:18:00,107 - train - INFO - alphas:tensor([0.1110, 0.8890], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,107 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,107 - train - INFO - True
2024-04-03 12:18:00,108 - train - INFO - alphas:tensor([0.1198, 0.8802], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,108 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,108 - train - INFO - True
2024-04-03 12:18:00,109 - train - INFO - alphas:tensor([0.0066, 0.9934], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,109 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,109 - train - INFO - True
2024-04-03 12:18:00,109 - train - INFO - alphas:tensor([0.0120, 0.9880], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,110 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,110 - train - INFO - True
2024-04-03 12:18:00,110 - train - INFO - alphas:tensor([1.9189e-06, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,110 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,110 - train - INFO - True
2024-04-03 12:18:00,111 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:18:00,111 - train - INFO - tau:0.3024044356690215
2024-04-03 12:18:00,111 - train - INFO - avg block size:13.413793103448276
2024-04-03 12:18:01,013 - train - INFO - Test: [   0/39]  Time: 0.899 (0.899)  Loss:  0.3499 (0.3499)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 12:18:35,258 - train - INFO - Test: [  39/39]  Time: 0.848 (0.879)  Loss:  0.3328 (0.3486)  Acc@1: 87.5000 (92.7400)  Acc@5: 100.0000 (99.7400)
2024-04-03 12:18:37,145 - train - INFO - Train: 122 [   0/195 (  0%)]  Loss:  1.665661 (1.6657)  Time: 1.755s,  145.83/s  (1.755s,  145.83/s)  LR: 5.511e-05  Data: 0.160 (0.160)
2024-04-03 12:19:57,479 - train - INFO - Train: 122 [  50/195 ( 26%)]  Loss:  1.283503 (1.4889)  Time: 1.651s,  155.03/s  (1.610s,  159.05/s)  LR: 5.511e-05  Data: 0.009 (0.011)
2024-04-03 12:21:18,346 - train - INFO - Train: 122 [ 100/195 ( 52%)]  Loss:  1.200336 (1.5248)  Time: 1.632s,  156.85/s  (1.613s,  158.67/s)  LR: 5.511e-05  Data: 0.005 (0.009)
2024-04-03 12:22:39,456 - train - INFO - Train: 122 [ 150/195 ( 77%)]  Loss:  1.729008 (1.5259)  Time: 1.609s,  159.12/s  (1.616s,  158.39/s)  LR: 5.511e-05  Data: 0.010 (0.009)
2024-04-03 12:23:48,609 - train - INFO - Train: 122 [ 194/195 (100%)]  Loss:  1.496289 (1.5208)  Time: 1.503s,  170.35/s  (1.606s,  159.38/s)  LR: 5.511e-05  Data: 0.000 (0.009)
2024-04-03 12:23:48,610 - train - INFO - True
2024-04-03 12:23:48,611 - train - INFO - alphas:tensor([2.8833e-04, 9.9971e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,611 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,611 - train - INFO - True
2024-04-03 12:23:48,612 - train - INFO - alphas:tensor([0.0626, 0.9374], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,612 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,612 - train - INFO - True
2024-04-03 12:23:48,613 - train - INFO - alphas:tensor([0.5677, 0.4323], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,613 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,613 - train - INFO - True
2024-04-03 12:23:48,613 - train - INFO - alphas:tensor([0.4710, 0.5290], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,613 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,614 - train - INFO - True
2024-04-03 12:23:48,614 - train - INFO - alphas:tensor([0.1443, 0.8557], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,614 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,614 - train - INFO - True
2024-04-03 12:23:48,615 - train - INFO - alphas:tensor([0.2633, 0.7367], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,615 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,615 - train - INFO - True
2024-04-03 12:23:48,616 - train - INFO - alphas:tensor([0.5572, 0.4428], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,616 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,616 - train - INFO - True
2024-04-03 12:23:48,617 - train - INFO - alphas:tensor([0.4335, 0.5665], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,617 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,617 - train - INFO - True
2024-04-03 12:23:48,618 - train - INFO - alphas:tensor([0.2561, 0.7439], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,618 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,618 - train - INFO - True
2024-04-03 12:23:48,619 - train - INFO - alphas:tensor([0.4145, 0.5855], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,619 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,619 - train - INFO - True
2024-04-03 12:23:48,620 - train - INFO - alphas:tensor([0.5654, 0.4346], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,620 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,620 - train - INFO - True
2024-04-03 12:23:48,620 - train - INFO - alphas:tensor([0.4219, 0.5781], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,620 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,621 - train - INFO - True
2024-04-03 12:23:48,621 - train - INFO - alphas:tensor([0.2757, 0.7243], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,621 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,621 - train - INFO - True
2024-04-03 12:23:48,622 - train - INFO - alphas:tensor([0.4124, 0.5876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,622 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,622 - train - INFO - True
2024-04-03 12:23:48,623 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,623 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,623 - train - INFO - True
2024-04-03 12:23:48,624 - train - INFO - alphas:tensor([0.3505, 0.6495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,624 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,624 - train - INFO - True
2024-04-03 12:23:48,625 - train - INFO - alphas:tensor([0.2398, 0.7602], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,625 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,625 - train - INFO - True
2024-04-03 12:23:48,626 - train - INFO - alphas:tensor([0.3150, 0.6850], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,626 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,626 - train - INFO - True
2024-04-03 12:23:48,627 - train - INFO - alphas:tensor([0.3894, 0.6106], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,627 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,627 - train - INFO - True
2024-04-03 12:23:48,627 - train - INFO - alphas:tensor([0.2134, 0.7866], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,628 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,628 - train - INFO - True
2024-04-03 12:23:48,628 - train - INFO - alphas:tensor([0.1827, 0.8173], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,628 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,628 - train - INFO - True
2024-04-03 12:23:48,629 - train - INFO - alphas:tensor([0.2352, 0.7648], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,629 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,629 - train - INFO - True
2024-04-03 12:23:48,630 - train - INFO - alphas:tensor([0.3417, 0.6583], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,630 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,630 - train - INFO - True
2024-04-03 12:23:48,631 - train - INFO - alphas:tensor([0.1102, 0.8898], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,631 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,631 - train - INFO - True
2024-04-03 12:23:48,632 - train - INFO - alphas:tensor([0.1191, 0.8809], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,632 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,632 - train - INFO - True
2024-04-03 12:23:48,632 - train - INFO - alphas:tensor([0.0062, 0.9938], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,632 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,633 - train - INFO - True
2024-04-03 12:23:48,633 - train - INFO - alphas:tensor([0.0115, 0.9885], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,633 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,633 - train - INFO - True
2024-04-03 12:23:48,634 - train - INFO - alphas:tensor([1.6701e-06, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,634 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,634 - train - INFO - True
2024-04-03 12:23:48,635 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:23:48,635 - train - INFO - tau:0.29938039131233124
2024-04-03 12:23:48,635 - train - INFO - avg block size:13.413793103448276
2024-04-03 12:23:49,545 - train - INFO - Test: [   0/39]  Time: 0.907 (0.907)  Loss:  0.3584 (0.3584)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-04-03 12:24:24,051 - train - INFO - Test: [  39/39]  Time: 0.870 (0.885)  Loss:  0.3938 (0.3546)  Acc@1: 87.5000 (92.5600)  Acc@5: 100.0000 (99.7900)
2024-04-03 12:24:25,866 - train - INFO - Train: 123 [   0/195 (  0%)]  Loss:  1.691180 (1.6912)  Time: 1.700s,  150.60/s  (1.700s,  150.60/s)  LR: 5.203e-05  Data: 0.162 (0.162)
2024-04-03 12:25:45,873 - train - INFO - Train: 123 [  50/195 ( 26%)]  Loss:  1.164261 (1.5286)  Time: 1.487s,  172.13/s  (1.602s,  159.79/s)  LR: 5.203e-05  Data: 0.011 (0.010)
2024-04-03 12:27:04,617 - train - INFO - Train: 123 [ 100/195 ( 52%)]  Loss:  1.735775 (1.5316)  Time: 1.694s,  151.13/s  (1.589s,  161.15/s)  LR: 5.203e-05  Data: 0.015 (0.009)
2024-04-03 12:28:24,808 - train - INFO - Train: 123 [ 150/195 ( 77%)]  Loss:  1.745320 (1.5232)  Time: 1.613s,  158.70/s  (1.594s,  160.64/s)  LR: 5.203e-05  Data: 0.005 (0.008)
2024-04-03 12:29:35,354 - train - INFO - Train: 123 [ 194/195 (100%)]  Loss:  1.730371 (1.5220)  Time: 1.537s,  166.51/s  (1.596s,  160.42/s)  LR: 5.203e-05  Data: 0.000 (0.008)
2024-04-03 12:29:35,355 - train - INFO - True
2024-04-03 12:29:35,357 - train - INFO - alphas:tensor([2.6260e-04, 9.9974e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,357 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,357 - train - INFO - True
2024-04-03 12:29:35,358 - train - INFO - alphas:tensor([0.0617, 0.9383], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,361 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,361 - train - INFO - True
2024-04-03 12:29:35,362 - train - INFO - alphas:tensor([0.5678, 0.4322], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,362 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,362 - train - INFO - True
2024-04-03 12:29:35,362 - train - INFO - alphas:tensor([0.4701, 0.5299], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,362 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,363 - train - INFO - True
2024-04-03 12:29:35,363 - train - INFO - alphas:tensor([0.1433, 0.8567], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,363 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,363 - train - INFO - True
2024-04-03 12:29:35,364 - train - INFO - alphas:tensor([0.2623, 0.7377], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,364 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,364 - train - INFO - True
2024-04-03 12:29:35,365 - train - INFO - alphas:tensor([0.5569, 0.4431], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,365 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,375 - train - INFO - True
2024-04-03 12:29:35,376 - train - INFO - alphas:tensor([0.4324, 0.5676], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,376 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,376 - train - INFO - True
2024-04-03 12:29:35,377 - train - INFO - alphas:tensor([0.2557, 0.7443], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,377 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,377 - train - INFO - True
2024-04-03 12:29:35,377 - train - INFO - alphas:tensor([0.4145, 0.5855], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,378 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,378 - train - INFO - True
2024-04-03 12:29:35,378 - train - INFO - alphas:tensor([0.5655, 0.4345], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,387 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,387 - train - INFO - True
2024-04-03 12:29:35,388 - train - INFO - alphas:tensor([0.4211, 0.5789], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,388 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,388 - train - INFO - True
2024-04-03 12:29:35,389 - train - INFO - alphas:tensor([0.2743, 0.7257], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,389 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,389 - train - INFO - True
2024-04-03 12:29:35,389 - train - INFO - alphas:tensor([0.4119, 0.5881], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,390 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,390 - train - INFO - True
2024-04-03 12:29:35,390 - train - INFO - alphas:tensor([0.5005, 0.4995], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,390 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,390 - train - INFO - True
2024-04-03 12:29:35,391 - train - INFO - alphas:tensor([0.3492, 0.6508], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,391 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,391 - train - INFO - True
2024-04-03 12:29:35,401 - train - INFO - alphas:tensor([0.2385, 0.7615], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,401 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,401 - train - INFO - True
2024-04-03 12:29:35,402 - train - INFO - alphas:tensor([0.3138, 0.6862], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,402 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,402 - train - INFO - True
2024-04-03 12:29:35,402 - train - INFO - alphas:tensor([0.3892, 0.6108], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,402 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,403 - train - INFO - True
2024-04-03 12:29:35,403 - train - INFO - alphas:tensor([0.2127, 0.7873], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,403 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,403 - train - INFO - True
2024-04-03 12:29:35,404 - train - INFO - alphas:tensor([0.1818, 0.8182], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,404 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,404 - train - INFO - True
2024-04-03 12:29:35,414 - train - INFO - alphas:tensor([0.2338, 0.7662], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,414 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,414 - train - INFO - True
2024-04-03 12:29:35,414 - train - INFO - alphas:tensor([0.3400, 0.6600], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,414 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,415 - train - INFO - True
2024-04-03 12:29:35,415 - train - INFO - alphas:tensor([0.1086, 0.8914], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,415 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,415 - train - INFO - True
2024-04-03 12:29:35,416 - train - INFO - alphas:tensor([0.1183, 0.8817], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,416 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,416 - train - INFO - True
2024-04-03 12:29:35,417 - train - INFO - alphas:tensor([0.0058, 0.9942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,417 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,417 - train - INFO - True
2024-04-03 12:29:35,418 - train - INFO - alphas:tensor([0.0110, 0.9890], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,418 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,418 - train - INFO - True
2024-04-03 12:29:35,427 - train - INFO - alphas:tensor([1.4522e-06, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,431 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,432 - train - INFO - True
2024-04-03 12:29:35,432 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:29:35,432 - train - INFO - tau:0.2963865873992079
2024-04-03 12:29:35,432 - train - INFO - avg block size:13.413793103448276
2024-04-03 12:29:36,393 - train - INFO - Test: [   0/39]  Time: 0.958 (0.958)  Loss:  0.3552 (0.3552)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 12:30:11,066 - train - INFO - Test: [  39/39]  Time: 0.860 (0.891)  Loss:  0.3804 (0.3550)  Acc@1: 81.2500 (92.6300)  Acc@5: 100.0000 (99.7700)
2024-04-03 12:30:12,962 - train - INFO - Train: 124 [   0/195 (  0%)]  Loss:  1.469604 (1.4696)  Time: 1.771s,  144.55/s  (1.771s,  144.55/s)  LR: 4.905e-05  Data: 0.181 (0.181)
2024-04-03 12:31:33,430 - train - INFO - Train: 124 [  50/195 ( 26%)]  Loss:  1.617530 (1.5512)  Time: 1.569s,  163.16/s  (1.613s,  158.76/s)  LR: 4.905e-05  Data: 0.005 (0.011)
2024-04-03 12:32:52,486 - train - INFO - Train: 124 [ 100/195 ( 52%)]  Loss:  1.216651 (1.5323)  Time: 1.559s,  164.26/s  (1.597s,  160.31/s)  LR: 4.905e-05  Data: 0.005 (0.009)
2024-04-03 12:34:11,831 - train - INFO - Train: 124 [ 150/195 ( 77%)]  Loss:  1.630291 (1.5253)  Time: 1.671s,  153.20/s  (1.594s,  160.64/s)  LR: 4.905e-05  Data: 0.006 (0.008)
2024-04-03 12:35:21,606 - train - INFO - Train: 124 [ 194/195 (100%)]  Loss:  1.306299 (1.5286)  Time: 1.629s,  157.11/s  (1.592s,  160.82/s)  LR: 4.905e-05  Data: 0.000 (0.008)
2024-04-03 12:35:21,606 - train - INFO - True
2024-04-03 12:35:21,607 - train - INFO - alphas:tensor([2.3847e-04, 9.9976e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,608 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,608 - train - INFO - True
2024-04-03 12:35:21,608 - train - INFO - alphas:tensor([0.0607, 0.9393], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,608 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,609 - train - INFO - True
2024-04-03 12:35:21,609 - train - INFO - alphas:tensor([0.5674, 0.4326], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,609 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,609 - train - INFO - True
2024-04-03 12:35:21,610 - train - INFO - alphas:tensor([0.4690, 0.5310], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,610 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,610 - train - INFO - True
2024-04-03 12:35:21,611 - train - INFO - alphas:tensor([0.1426, 0.8574], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,611 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,611 - train - INFO - True
2024-04-03 12:35:21,612 - train - INFO - alphas:tensor([0.2620, 0.7380], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,612 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,612 - train - INFO - True
2024-04-03 12:35:21,612 - train - INFO - alphas:tensor([0.5566, 0.4434], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,613 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,613 - train - INFO - True
2024-04-03 12:35:21,613 - train - INFO - alphas:tensor([0.4313, 0.5687], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,613 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,613 - train - INFO - True
2024-04-03 12:35:21,614 - train - INFO - alphas:tensor([0.2548, 0.7452], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,614 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,614 - train - INFO - True
2024-04-03 12:35:21,615 - train - INFO - alphas:tensor([0.4142, 0.5858], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,615 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,615 - train - INFO - True
2024-04-03 12:35:21,616 - train - INFO - alphas:tensor([0.5649, 0.4351], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,616 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,616 - train - INFO - True
2024-04-03 12:35:21,617 - train - INFO - alphas:tensor([0.4210, 0.5790], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,617 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,617 - train - INFO - True
2024-04-03 12:35:21,617 - train - INFO - alphas:tensor([0.2732, 0.7268], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,617 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,618 - train - INFO - True
2024-04-03 12:35:21,618 - train - INFO - alphas:tensor([0.4115, 0.5885], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,619 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,619 - train - INFO - True
2024-04-03 12:35:21,619 - train - INFO - alphas:tensor([0.5006, 0.4994], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,619 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,619 - train - INFO - True
2024-04-03 12:35:21,620 - train - INFO - alphas:tensor([0.3492, 0.6508], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,620 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,620 - train - INFO - True
2024-04-03 12:35:21,621 - train - INFO - alphas:tensor([0.2381, 0.7619], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,621 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,621 - train - INFO - True
2024-04-03 12:35:21,622 - train - INFO - alphas:tensor([0.3137, 0.6863], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,622 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,622 - train - INFO - True
2024-04-03 12:35:21,623 - train - INFO - alphas:tensor([0.3897, 0.6103], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,623 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,623 - train - INFO - True
2024-04-03 12:35:21,623 - train - INFO - alphas:tensor([0.2139, 0.7861], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,623 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,624 - train - INFO - True
2024-04-03 12:35:21,624 - train - INFO - alphas:tensor([0.1816, 0.8184], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,624 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,624 - train - INFO - True
2024-04-03 12:35:21,625 - train - INFO - alphas:tensor([0.2333, 0.7667], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,625 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,625 - train - INFO - True
2024-04-03 12:35:21,626 - train - INFO - alphas:tensor([0.3403, 0.6597], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,626 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,626 - train - INFO - True
2024-04-03 12:35:21,627 - train - INFO - alphas:tensor([0.1079, 0.8921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,627 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,627 - train - INFO - True
2024-04-03 12:35:21,627 - train - INFO - alphas:tensor([0.1180, 0.8820], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,628 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,628 - train - INFO - True
2024-04-03 12:35:21,628 - train - INFO - alphas:tensor([0.0055, 0.9945], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,628 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,628 - train - INFO - True
2024-04-03 12:35:21,629 - train - INFO - alphas:tensor([0.0105, 0.9895], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,629 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,629 - train - INFO - True
2024-04-03 12:35:21,630 - train - INFO - alphas:tensor([1.2614e-06, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,630 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,630 - train - INFO - True
2024-04-03 12:35:21,631 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:35:21,631 - train - INFO - tau:0.29342272152521587
2024-04-03 12:35:21,631 - train - INFO - avg block size:13.413793103448276
2024-04-03 12:35:22,535 - train - INFO - Test: [   0/39]  Time: 0.902 (0.902)  Loss:  0.3513 (0.3513)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 12:35:56,844 - train - INFO - Test: [  39/39]  Time: 0.826 (0.880)  Loss:  0.3596 (0.3539)  Acc@1: 87.5000 (92.7100)  Acc@5: 100.0000 (99.7800)
2024-04-03 12:35:58,563 - train - INFO - Train: 125 [   0/195 (  0%)]  Loss:  1.688601 (1.6886)  Time: 1.619s,  158.16/s  (1.619s,  158.16/s)  LR: 4.617e-05  Data: 0.143 (0.143)
2024-04-03 12:37:18,655 - train - INFO - Train: 125 [  50/195 ( 26%)]  Loss:  1.677640 (1.5138)  Time: 1.510s,  169.51/s  (1.602s,  159.79/s)  LR: 4.617e-05  Data: 0.005 (0.011)
2024-04-03 12:38:38,371 - train - INFO - Train: 125 [ 100/195 ( 52%)]  Loss:  1.669765 (1.5221)  Time: 1.498s,  170.86/s  (1.598s,  160.17/s)  LR: 4.617e-05  Data: 0.005 (0.009)
2024-04-03 12:39:57,790 - train - INFO - Train: 125 [ 150/195 ( 77%)]  Loss:  1.674967 (1.5215)  Time: 1.482s,  172.71/s  (1.595s,  160.50/s)  LR: 4.617e-05  Data: 0.007 (0.009)
2024-04-03 12:41:07,719 - train - INFO - Train: 125 [ 194/195 (100%)]  Loss:  1.754452 (1.5245)  Time: 1.618s,  158.23/s  (1.594s,  160.63/s)  LR: 4.617e-05  Data: 0.000 (0.009)
2024-04-03 12:41:07,719 - train - INFO - True
2024-04-03 12:41:07,720 - train - INFO - alphas:tensor([2.1644e-04, 9.9978e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,721 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,721 - train - INFO - True
2024-04-03 12:41:07,722 - train - INFO - alphas:tensor([0.0594, 0.9406], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,722 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,722 - train - INFO - True
2024-04-03 12:41:07,723 - train - INFO - alphas:tensor([0.5671, 0.4329], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,723 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,723 - train - INFO - True
2024-04-03 12:41:07,723 - train - INFO - alphas:tensor([0.4684, 0.5316], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,723 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,724 - train - INFO - True
2024-04-03 12:41:07,724 - train - INFO - alphas:tensor([0.1414, 0.8586], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,724 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,724 - train - INFO - True
2024-04-03 12:41:07,725 - train - INFO - alphas:tensor([0.2617, 0.7383], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,726 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,726 - train - INFO - True
2024-04-03 12:41:07,726 - train - INFO - alphas:tensor([0.5567, 0.4433], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,726 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,726 - train - INFO - True
2024-04-03 12:41:07,727 - train - INFO - alphas:tensor([0.4319, 0.5681], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,727 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,727 - train - INFO - True
2024-04-03 12:41:07,728 - train - INFO - alphas:tensor([0.2547, 0.7453], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,728 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,728 - train - INFO - True
2024-04-03 12:41:07,729 - train - INFO - alphas:tensor([0.4145, 0.5855], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,729 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,729 - train - INFO - True
2024-04-03 12:41:07,730 - train - INFO - alphas:tensor([0.5648, 0.4352], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,730 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,730 - train - INFO - True
2024-04-03 12:41:07,730 - train - INFO - alphas:tensor([0.4206, 0.5794], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,731 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,731 - train - INFO - True
2024-04-03 12:41:07,731 - train - INFO - alphas:tensor([0.2723, 0.7277], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,731 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,731 - train - INFO - True
2024-04-03 12:41:07,732 - train - INFO - alphas:tensor([0.4115, 0.5885], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,732 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,732 - train - INFO - True
2024-04-03 12:41:07,733 - train - INFO - alphas:tensor([0.5012, 0.4988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,733 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,733 - train - INFO - True
2024-04-03 12:41:07,734 - train - INFO - alphas:tensor([0.3494, 0.6506], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,734 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,734 - train - INFO - True
2024-04-03 12:41:07,734 - train - INFO - alphas:tensor([0.2384, 0.7616], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,735 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,735 - train - INFO - True
2024-04-03 12:41:07,735 - train - INFO - alphas:tensor([0.3142, 0.6858], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,735 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,735 - train - INFO - True
2024-04-03 12:41:07,736 - train - INFO - alphas:tensor([0.3892, 0.6108], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,736 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,736 - train - INFO - True
2024-04-03 12:41:07,737 - train - INFO - alphas:tensor([0.2134, 0.7866], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,737 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,737 - train - INFO - True
2024-04-03 12:41:07,738 - train - INFO - alphas:tensor([0.1807, 0.8193], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,738 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,738 - train - INFO - True
2024-04-03 12:41:07,739 - train - INFO - alphas:tensor([0.2328, 0.7672], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,739 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,739 - train - INFO - True
2024-04-03 12:41:07,739 - train - INFO - alphas:tensor([0.3396, 0.6604], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,739 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,740 - train - INFO - True
2024-04-03 12:41:07,740 - train - INFO - alphas:tensor([0.1067, 0.8933], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,740 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,740 - train - INFO - True
2024-04-03 12:41:07,741 - train - INFO - alphas:tensor([0.1171, 0.8829], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,741 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,741 - train - INFO - True
2024-04-03 12:41:07,742 - train - INFO - alphas:tensor([0.0051, 0.9949], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,742 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,742 - train - INFO - True
2024-04-03 12:41:07,743 - train - INFO - alphas:tensor([0.0100, 0.9900], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,743 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,743 - train - INFO - True
2024-04-03 12:41:07,743 - train - INFO - alphas:tensor([1.0947e-06, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,743 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,744 - train - INFO - True
2024-04-03 12:41:07,744 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:41:07,744 - train - INFO - tau:0.2904884943099637
2024-04-03 12:41:07,744 - train - INFO - avg block size:13.413793103448276
2024-04-03 12:41:08,719 - train - INFO - Test: [   0/39]  Time: 0.971 (0.971)  Loss:  0.3477 (0.3477)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 12:41:43,043 - train - INFO - Test: [  39/39]  Time: 0.877 (0.882)  Loss:  0.3960 (0.3557)  Acc@1: 87.5000 (92.6400)  Acc@5: 100.0000 (99.7600)
2024-04-03 12:41:44,835 - train - INFO - Train: 126 [   0/195 (  0%)]  Loss:  1.312394 (1.3124)  Time: 1.641s,  155.96/s  (1.641s,  155.96/s)  LR: 4.340e-05  Data: 0.135 (0.135)
2024-04-03 12:43:04,213 - train - INFO - Train: 126 [  50/195 ( 26%)]  Loss:  1.394122 (1.5433)  Time: 1.597s,  160.31/s  (1.589s,  161.15/s)  LR: 4.340e-05  Data: 0.006 (0.010)
2024-04-03 12:44:25,056 - train - INFO - Train: 126 [ 100/195 ( 52%)]  Loss:  1.693535 (1.5328)  Time: 1.500s,  170.67/s  (1.603s,  159.74/s)  LR: 4.340e-05  Data: 0.005 (0.009)
2024-04-03 12:45:45,045 - train - INFO - Train: 126 [ 150/195 ( 77%)]  Loss:  1.191197 (1.5156)  Time: 1.755s,  145.88/s  (1.602s,  159.84/s)  LR: 4.340e-05  Data: 0.011 (0.009)
2024-04-03 12:46:56,317 - train - INFO - Train: 126 [ 194/195 (100%)]  Loss:  1.652042 (1.5172)  Time: 1.644s,  155.73/s  (1.606s,  159.43/s)  LR: 4.340e-05  Data: 0.000 (0.008)
2024-04-03 12:46:56,318 - train - INFO - True
2024-04-03 12:46:56,319 - train - INFO - alphas:tensor([1.9645e-04, 9.9980e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,319 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,319 - train - INFO - True
2024-04-03 12:46:56,320 - train - INFO - alphas:tensor([0.0584, 0.9416], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,320 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,320 - train - INFO - True
2024-04-03 12:46:56,321 - train - INFO - alphas:tensor([0.5679, 0.4321], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,321 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,321 - train - INFO - True
2024-04-03 12:46:56,322 - train - INFO - alphas:tensor([0.4685, 0.5315], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,322 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,322 - train - INFO - True
2024-04-03 12:46:56,323 - train - INFO - alphas:tensor([0.1405, 0.8595], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,323 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,323 - train - INFO - True
2024-04-03 12:46:56,323 - train - INFO - alphas:tensor([0.2614, 0.7386], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,324 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,324 - train - INFO - True
2024-04-03 12:46:56,324 - train - INFO - alphas:tensor([0.5562, 0.4438], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,324 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,324 - train - INFO - True
2024-04-03 12:46:56,325 - train - INFO - alphas:tensor([0.4316, 0.5684], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,325 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,325 - train - INFO - True
2024-04-03 12:46:56,326 - train - INFO - alphas:tensor([0.2535, 0.7465], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,326 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,326 - train - INFO - True
2024-04-03 12:46:56,327 - train - INFO - alphas:tensor([0.4141, 0.5859], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,327 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,327 - train - INFO - True
2024-04-03 12:46:56,327 - train - INFO - alphas:tensor([0.5649, 0.4351], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,328 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,328 - train - INFO - True
2024-04-03 12:46:56,328 - train - INFO - alphas:tensor([0.4194, 0.5806], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,328 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,328 - train - INFO - True
2024-04-03 12:46:56,329 - train - INFO - alphas:tensor([0.2719, 0.7281], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,329 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,329 - train - INFO - True
2024-04-03 12:46:56,330 - train - INFO - alphas:tensor([0.4113, 0.5887], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,330 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,330 - train - INFO - True
2024-04-03 12:46:56,331 - train - INFO - alphas:tensor([0.5011, 0.4989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,331 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,331 - train - INFO - True
2024-04-03 12:46:56,332 - train - INFO - alphas:tensor([0.3488, 0.6512], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,332 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,332 - train - INFO - True
2024-04-03 12:46:56,332 - train - INFO - alphas:tensor([0.2373, 0.7627], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,332 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,332 - train - INFO - True
2024-04-03 12:46:56,333 - train - INFO - alphas:tensor([0.3135, 0.6865], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,333 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,333 - train - INFO - True
2024-04-03 12:46:56,334 - train - INFO - alphas:tensor([0.3886, 0.6114], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,334 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,334 - train - INFO - True
2024-04-03 12:46:56,335 - train - INFO - alphas:tensor([0.2126, 0.7874], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,335 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,335 - train - INFO - True
2024-04-03 12:46:56,336 - train - INFO - alphas:tensor([0.1799, 0.8201], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,336 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,336 - train - INFO - True
2024-04-03 12:46:56,336 - train - INFO - alphas:tensor([0.2323, 0.7677], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,336 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,337 - train - INFO - True
2024-04-03 12:46:56,337 - train - INFO - alphas:tensor([0.3396, 0.6604], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,337 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,337 - train - INFO - True
2024-04-03 12:46:56,338 - train - INFO - alphas:tensor([0.1058, 0.8942], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,338 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,338 - train - INFO - True
2024-04-03 12:46:56,339 - train - INFO - alphas:tensor([0.1162, 0.8838], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,339 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,339 - train - INFO - True
2024-04-03 12:46:56,340 - train - INFO - alphas:tensor([0.0048, 0.9952], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,340 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,340 - train - INFO - True
2024-04-03 12:46:56,340 - train - INFO - alphas:tensor([0.0096, 0.9904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,340 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,341 - train - INFO - True
2024-04-03 12:46:56,341 - train - INFO - alphas:tensor([9.4902e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,341 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,341 - train - INFO - True
2024-04-03 12:46:56,342 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:46:56,342 - train - INFO - tau:0.28758360936686406
2024-04-03 12:46:56,342 - train - INFO - avg block size:13.413793103448276
2024-04-03 12:46:57,288 - train - INFO - Test: [   0/39]  Time: 0.943 (0.943)  Loss:  0.3484 (0.3484)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-04-03 12:47:31,392 - train - INFO - Test: [  39/39]  Time: 0.859 (0.876)  Loss:  0.3865 (0.3511)  Acc@1: 81.2500 (92.7500)  Acc@5: 100.0000 (99.7500)
2024-04-03 12:47:33,477 - train - INFO - Train: 127 [   0/195 (  0%)]  Loss:  1.720710 (1.7207)  Time: 1.956s,  130.88/s  (1.956s,  130.88/s)  LR: 4.073e-05  Data: 0.182 (0.182)
2024-04-03 12:48:53,581 - train - INFO - Train: 127 [  50/195 ( 26%)]  Loss:  1.466380 (1.5000)  Time: 1.571s,  162.97/s  (1.609s,  159.11/s)  LR: 4.073e-05  Data: 0.012 (0.012)
2024-04-03 12:50:13,059 - train - INFO - Train: 127 [ 100/195 ( 52%)]  Loss:  1.622586 (1.5254)  Time: 1.607s,  159.27/s  (1.599s,  160.06/s)  LR: 4.073e-05  Data: 0.005 (0.010)
2024-04-03 12:51:35,117 - train - INFO - Train: 127 [ 150/195 ( 77%)]  Loss:  1.496730 (1.5280)  Time: 1.702s,  150.39/s  (1.613s,  158.69/s)  LR: 4.073e-05  Data: 0.005 (0.010)
2024-04-03 12:52:46,608 - train - INFO - Train: 127 [ 194/195 (100%)]  Loss:  1.488564 (1.5323)  Time: 1.784s,  143.50/s  (1.616s,  158.43/s)  LR: 4.073e-05  Data: 0.000 (0.009)
2024-04-03 12:52:46,609 - train - INFO - True
2024-04-03 12:52:46,611 - train - INFO - alphas:tensor([1.7839e-04, 9.9982e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,611 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,611 - train - INFO - True
2024-04-03 12:52:46,612 - train - INFO - alphas:tensor([0.0575, 0.9425], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,612 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,612 - train - INFO - True
2024-04-03 12:52:46,612 - train - INFO - alphas:tensor([0.5672, 0.4328], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,613 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,613 - train - INFO - True
2024-04-03 12:52:46,613 - train - INFO - alphas:tensor([0.4673, 0.5327], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,613 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,613 - train - INFO - True
2024-04-03 12:52:46,614 - train - INFO - alphas:tensor([0.1398, 0.8602], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,614 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,614 - train - INFO - True
2024-04-03 12:52:46,615 - train - INFO - alphas:tensor([0.2612, 0.7388], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,615 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,615 - train - INFO - True
2024-04-03 12:52:46,616 - train - INFO - alphas:tensor([0.5556, 0.4444], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,616 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,616 - train - INFO - True
2024-04-03 12:52:46,617 - train - INFO - alphas:tensor([0.4310, 0.5690], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,617 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,617 - train - INFO - True
2024-04-03 12:52:46,618 - train - INFO - alphas:tensor([0.2531, 0.7469], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,618 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,618 - train - INFO - True
2024-04-03 12:52:46,619 - train - INFO - alphas:tensor([0.4142, 0.5858], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,619 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,619 - train - INFO - True
2024-04-03 12:52:46,619 - train - INFO - alphas:tensor([0.5649, 0.4351], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,620 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,620 - train - INFO - True
2024-04-03 12:52:46,621 - train - INFO - alphas:tensor([0.4185, 0.5815], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,621 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,621 - train - INFO - True
2024-04-03 12:52:46,622 - train - INFO - alphas:tensor([0.2716, 0.7284], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,622 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,622 - train - INFO - True
2024-04-03 12:52:46,622 - train - INFO - alphas:tensor([0.4120, 0.5880], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,623 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,623 - train - INFO - True
2024-04-03 12:52:46,623 - train - INFO - alphas:tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,623 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,623 - train - INFO - True
2024-04-03 12:52:46,624 - train - INFO - alphas:tensor([0.3483, 0.6517], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,624 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,624 - train - INFO - True
2024-04-03 12:52:46,625 - train - INFO - alphas:tensor([0.2368, 0.7632], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,625 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,625 - train - INFO - True
2024-04-03 12:52:46,626 - train - INFO - alphas:tensor([0.3135, 0.6865], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,626 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,626 - train - INFO - True
2024-04-03 12:52:46,626 - train - INFO - alphas:tensor([0.3875, 0.6125], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,627 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,627 - train - INFO - True
2024-04-03 12:52:46,627 - train - INFO - alphas:tensor([0.2115, 0.7885], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,627 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,627 - train - INFO - True
2024-04-03 12:52:46,628 - train - INFO - alphas:tensor([0.1787, 0.8213], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,628 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,628 - train - INFO - True
2024-04-03 12:52:46,629 - train - INFO - alphas:tensor([0.2315, 0.7685], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,629 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,629 - train - INFO - True
2024-04-03 12:52:46,630 - train - INFO - alphas:tensor([0.3390, 0.6610], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,630 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,630 - train - INFO - True
2024-04-03 12:52:46,631 - train - INFO - alphas:tensor([0.1044, 0.8956], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,631 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,631 - train - INFO - True
2024-04-03 12:52:46,631 - train - INFO - alphas:tensor([0.1154, 0.8846], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,631 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,632 - train - INFO - True
2024-04-03 12:52:46,632 - train - INFO - alphas:tensor([0.0045, 0.9955], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,632 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,632 - train - INFO - True
2024-04-03 12:52:46,633 - train - INFO - alphas:tensor([0.0091, 0.9909], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,633 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,633 - train - INFO - True
2024-04-03 12:52:46,634 - train - INFO - alphas:tensor([8.2179e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,634 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,634 - train - INFO - True
2024-04-03 12:52:46,634 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:52:46,635 - train - INFO - tau:0.2847077732731954
2024-04-03 12:52:46,635 - train - INFO - avg block size:13.413793103448276
2024-04-03 12:52:47,568 - train - INFO - Test: [   0/39]  Time: 0.930 (0.930)  Loss:  0.3545 (0.3545)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-04-03 12:53:22,050 - train - INFO - Test: [  39/39]  Time: 0.942 (0.885)  Loss:  0.4082 (0.3562)  Acc@1: 81.2500 (92.6500)  Acc@5: 100.0000 (99.7300)
2024-04-03 12:53:23,896 - train - INFO - Train: 128 [   0/195 (  0%)]  Loss:  1.500684 (1.5007)  Time: 1.726s,  148.33/s  (1.726s,  148.33/s)  LR: 3.816e-05  Data: 0.172 (0.172)
2024-04-03 12:54:44,320 - train - INFO - Train: 128 [  50/195 ( 26%)]  Loss:  1.672060 (1.5328)  Time: 1.500s,  170.71/s  (1.611s,  158.93/s)  LR: 3.816e-05  Data: 0.010 (0.011)
2024-04-03 12:56:04,196 - train - INFO - Train: 128 [ 100/195 ( 52%)]  Loss:  1.781592 (1.5531)  Time: 1.462s,  175.13/s  (1.604s,  159.58/s)  LR: 3.816e-05  Data: 0.005 (0.009)
2024-04-03 12:57:24,503 - train - INFO - Train: 128 [ 150/195 ( 77%)]  Loss:  1.748644 (1.5457)  Time: 1.580s,  162.02/s  (1.605s,  159.52/s)  LR: 3.816e-05  Data: 0.006 (0.008)
2024-04-03 12:58:34,661 - train - INFO - Train: 128 [ 194/195 (100%)]  Loss:  1.762009 (1.5416)  Time: 1.516s,  168.88/s  (1.602s,  159.75/s)  LR: 3.816e-05  Data: 0.000 (0.008)
2024-04-03 12:58:34,662 - train - INFO - True
2024-04-03 12:58:34,663 - train - INFO - alphas:tensor([1.6190e-04, 9.9984e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,663 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,663 - train - INFO - True
2024-04-03 12:58:34,663 - train - INFO - alphas:tensor([0.0566, 0.9434], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,664 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,664 - train - INFO - True
2024-04-03 12:58:34,664 - train - INFO - alphas:tensor([0.5683, 0.4317], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,664 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,664 - train - INFO - True
2024-04-03 12:58:34,665 - train - INFO - alphas:tensor([0.4679, 0.5321], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,665 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,665 - train - INFO - True
2024-04-03 12:58:34,666 - train - INFO - alphas:tensor([0.1387, 0.8613], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,666 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,666 - train - INFO - True
2024-04-03 12:58:34,667 - train - INFO - alphas:tensor([0.2604, 0.7396], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,667 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,667 - train - INFO - True
2024-04-03 12:58:34,672 - train - INFO - alphas:tensor([0.5562, 0.4438], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,672 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,672 - train - INFO - True
2024-04-03 12:58:34,673 - train - INFO - alphas:tensor([0.4312, 0.5688], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,673 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,673 - train - INFO - True
2024-04-03 12:58:34,674 - train - INFO - alphas:tensor([0.2524, 0.7476], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,674 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,674 - train - INFO - True
2024-04-03 12:58:34,675 - train - INFO - alphas:tensor([0.4145, 0.5855], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,675 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,675 - train - INFO - True
2024-04-03 12:58:34,676 - train - INFO - alphas:tensor([0.5648, 0.4352], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,676 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,676 - train - INFO - True
2024-04-03 12:58:34,676 - train - INFO - alphas:tensor([0.4175, 0.5825], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,676 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,676 - train - INFO - True
2024-04-03 12:58:34,677 - train - INFO - alphas:tensor([0.2713, 0.7287], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,677 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,677 - train - INFO - True
2024-04-03 12:58:34,678 - train - INFO - alphas:tensor([0.4124, 0.5876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,678 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,678 - train - INFO - True
2024-04-03 12:58:34,679 - train - INFO - alphas:tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,679 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,679 - train - INFO - True
2024-04-03 12:58:34,680 - train - INFO - alphas:tensor([0.3477, 0.6523], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,680 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,680 - train - INFO - True
2024-04-03 12:58:34,680 - train - INFO - alphas:tensor([0.2359, 0.7641], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,681 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,681 - train - INFO - True
2024-04-03 12:58:34,686 - train - INFO - alphas:tensor([0.3135, 0.6865], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,695 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,695 - train - INFO - True
2024-04-03 12:58:34,695 - train - INFO - alphas:tensor([0.3881, 0.6119], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,695 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,695 - train - INFO - True
2024-04-03 12:58:34,696 - train - INFO - alphas:tensor([0.2111, 0.7889], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,696 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,696 - train - INFO - True
2024-04-03 12:58:34,697 - train - INFO - alphas:tensor([0.1781, 0.8219], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,697 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,697 - train - INFO - True
2024-04-03 12:58:34,698 - train - INFO - alphas:tensor([0.2312, 0.7688], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,698 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,698 - train - INFO - True
2024-04-03 12:58:34,699 - train - INFO - alphas:tensor([0.3384, 0.6616], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,707 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,707 - train - INFO - True
2024-04-03 12:58:34,708 - train - INFO - alphas:tensor([0.1035, 0.8965], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,708 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,708 - train - INFO - True
2024-04-03 12:58:34,709 - train - INFO - alphas:tensor([0.1148, 0.8852], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,709 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,709 - train - INFO - True
2024-04-03 12:58:34,710 - train - INFO - alphas:tensor([0.0043, 0.9957], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,710 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,710 - train - INFO - True
2024-04-03 12:58:34,710 - train - INFO - alphas:tensor([0.0087, 0.9913], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,711 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,711 - train - INFO - True
2024-04-03 12:58:34,711 - train - INFO - alphas:tensor([7.1088e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,720 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,720 - train - INFO - True
2024-04-03 12:58:34,721 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 12:58:34,721 - train - INFO - tau:0.28186069554046345
2024-04-03 12:58:34,721 - train - INFO - avg block size:13.413793103448276
2024-04-03 12:58:35,619 - train - INFO - Test: [   0/39]  Time: 0.894 (0.894)  Loss:  0.3481 (0.3481)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-03 12:59:09,869 - train - INFO - Test: [  39/39]  Time: 0.897 (0.879)  Loss:  0.3540 (0.3511)  Acc@1: 87.5000 (92.7300)  Acc@5: 100.0000 (99.7800)
2024-04-03 12:59:11,893 - train - INFO - Train: 129 [   0/195 (  0%)]  Loss:  1.264143 (1.2641)  Time: 1.898s,  134.90/s  (1.898s,  134.90/s)  LR: 3.570e-05  Data: 0.132 (0.132)
2024-04-03 13:00:32,191 - train - INFO - Train: 129 [  50/195 ( 26%)]  Loss:  1.468684 (1.4982)  Time: 1.757s,  145.69/s  (1.612s,  158.84/s)  LR: 3.570e-05  Data: 0.010 (0.010)
2024-04-03 13:01:52,463 - train - INFO - Train: 129 [ 100/195 ( 52%)]  Loss:  1.170512 (1.4962)  Time: 1.711s,  149.60/s  (1.609s,  159.15/s)  LR: 3.570e-05  Data: 0.005 (0.009)
2024-04-03 13:03:13,754 - train - INFO - Train: 129 [ 150/195 ( 77%)]  Loss:  1.779808 (1.5007)  Time: 1.507s,  169.88/s  (1.614s,  158.59/s)  LR: 3.570e-05  Data: 0.012 (0.008)
2024-04-03 13:04:24,526 - train - INFO - Train: 129 [ 194/195 (100%)]  Loss:  1.296099 (1.4930)  Time: 1.485s,  172.42/s  (1.613s,  158.71/s)  LR: 3.570e-05  Data: 0.000 (0.008)
2024-04-03 13:04:24,526 - train - INFO - True
2024-04-03 13:04:24,527 - train - INFO - alphas:tensor([1.4690e-04, 9.9985e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,528 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,528 - train - INFO - True
2024-04-03 13:04:24,532 - train - INFO - alphas:tensor([0.0555, 0.9445], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,533 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,533 - train - INFO - True
2024-04-03 13:04:24,534 - train - INFO - alphas:tensor([0.5683, 0.4317], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,534 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,534 - train - INFO - True
2024-04-03 13:04:24,535 - train - INFO - alphas:tensor([0.4670, 0.5330], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,535 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,535 - train - INFO - True
2024-04-03 13:04:24,535 - train - INFO - alphas:tensor([0.1375, 0.8625], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,536 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,536 - train - INFO - True
2024-04-03 13:04:24,536 - train - INFO - alphas:tensor([0.2595, 0.7405], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,541 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,541 - train - INFO - True
2024-04-03 13:04:24,542 - train - INFO - alphas:tensor([0.5562, 0.4438], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,542 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,542 - train - INFO - True
2024-04-03 13:04:24,543 - train - INFO - alphas:tensor([0.4306, 0.5694], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,543 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,543 - train - INFO - True
2024-04-03 13:04:24,544 - train - INFO - alphas:tensor([0.2521, 0.7479], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,544 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,544 - train - INFO - True
2024-04-03 13:04:24,545 - train - INFO - alphas:tensor([0.4148, 0.5852], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,545 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,545 - train - INFO - True
2024-04-03 13:04:24,545 - train - INFO - alphas:tensor([0.5657, 0.4343], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,550 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,550 - train - INFO - True
2024-04-03 13:04:24,551 - train - INFO - alphas:tensor([0.4177, 0.5823], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,551 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,551 - train - INFO - True
2024-04-03 13:04:24,552 - train - INFO - alphas:tensor([0.2713, 0.7287], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,552 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,552 - train - INFO - True
2024-04-03 13:04:24,552 - train - INFO - alphas:tensor([0.4133, 0.5867], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,552 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,552 - train - INFO - True
2024-04-03 13:04:24,553 - train - INFO - alphas:tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,553 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,553 - train - INFO - True
2024-04-03 13:04:24,554 - train - INFO - alphas:tensor([0.3472, 0.6528], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,554 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,554 - train - INFO - True
2024-04-03 13:04:24,555 - train - INFO - alphas:tensor([0.2353, 0.7647], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,555 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,555 - train - INFO - True
2024-04-03 13:04:24,556 - train - INFO - alphas:tensor([0.3138, 0.6862], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,556 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,556 - train - INFO - True
2024-04-03 13:04:24,556 - train - INFO - alphas:tensor([0.3876, 0.6124], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,557 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,557 - train - INFO - True
2024-04-03 13:04:24,557 - train - INFO - alphas:tensor([0.2100, 0.7900], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,557 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,557 - train - INFO - True
2024-04-03 13:04:24,558 - train - INFO - alphas:tensor([0.1774, 0.8226], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,558 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,558 - train - INFO - True
2024-04-03 13:04:24,563 - train - INFO - alphas:tensor([0.2309, 0.7691], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,564 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,564 - train - INFO - True
2024-04-03 13:04:24,564 - train - INFO - alphas:tensor([0.3380, 0.6620], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,564 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,564 - train - INFO - True
2024-04-03 13:04:24,565 - train - INFO - alphas:tensor([0.1025, 0.8975], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,565 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,565 - train - INFO - True
2024-04-03 13:04:24,566 - train - INFO - alphas:tensor([0.1140, 0.8860], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,566 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,566 - train - INFO - True
2024-04-03 13:04:24,567 - train - INFO - alphas:tensor([0.0040, 0.9960], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,567 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,567 - train - INFO - True
2024-04-03 13:04:24,568 - train - INFO - alphas:tensor([0.0083, 0.9917], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,568 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,568 - train - INFO - True
2024-04-03 13:04:24,568 - train - INFO - alphas:tensor([6.1422e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,568 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,568 - train - INFO - True
2024-04-03 13:04:24,569 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:04:24,569 - train - INFO - tau:0.2790420885850588
2024-04-03 13:04:24,569 - train - INFO - avg block size:13.931034482758621
2024-04-03 13:04:25,506 - train - INFO - Test: [   0/39]  Time: 0.927 (0.927)  Loss:  0.3562 (0.3562)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 13:05:00,421 - train - INFO - Test: [  39/39]  Time: 0.893 (0.896)  Loss:  0.3428 (0.3521)  Acc@1: 87.5000 (92.6900)  Acc@5: 100.0000 (99.7800)
2024-04-03 13:05:02,285 - train - INFO - Train: 130 [   0/195 (  0%)]  Loss:  1.472327 (1.4723)  Time: 1.735s,  147.59/s  (1.735s,  147.59/s)  LR: 3.334e-05  Data: 0.199 (0.199)
2024-04-03 13:06:22,636 - train - INFO - Train: 130 [  50/195 ( 26%)]  Loss:  1.576527 (1.5145)  Time: 1.908s,  134.20/s  (1.610s,  159.05/s)  LR: 3.334e-05  Data: 0.006 (0.011)
2024-04-03 13:07:43,338 - train - INFO - Train: 130 [ 100/195 ( 52%)]  Loss:  1.746943 (1.5391)  Time: 1.548s,  165.42/s  (1.612s,  158.84/s)  LR: 3.334e-05  Data: 0.013 (0.009)
2024-04-03 13:09:04,290 - train - INFO - Train: 130 [ 150/195 ( 77%)]  Loss:  1.741081 (1.5668)  Time: 1.669s,  153.36/s  (1.614s,  158.60/s)  LR: 3.334e-05  Data: 0.005 (0.009)
2024-04-03 13:10:17,100 - train - INFO - Train: 130 [ 194/195 (100%)]  Loss:  1.731929 (1.5569)  Time: 1.519s,  168.50/s  (1.623s,  157.70/s)  LR: 3.334e-05  Data: 0.000 (0.009)
2024-04-03 13:10:17,101 - train - INFO - True
2024-04-03 13:10:17,103 - train - INFO - alphas:tensor([1.3326e-04, 9.9987e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,103 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,103 - train - INFO - True
2024-04-03 13:10:17,104 - train - INFO - alphas:tensor([0.0546, 0.9454], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,104 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,104 - train - INFO - True
2024-04-03 13:10:17,105 - train - INFO - alphas:tensor([0.5682, 0.4318], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,105 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,105 - train - INFO - True
2024-04-03 13:10:17,106 - train - INFO - alphas:tensor([0.4659, 0.5341], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,106 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,106 - train - INFO - True
2024-04-03 13:10:17,107 - train - INFO - alphas:tensor([0.1368, 0.8632], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,107 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,107 - train - INFO - True
2024-04-03 13:10:17,107 - train - INFO - alphas:tensor([0.2594, 0.7406], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,107 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,108 - train - INFO - True
2024-04-03 13:10:17,108 - train - INFO - alphas:tensor([0.5555, 0.4445], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,108 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,108 - train - INFO - True
2024-04-03 13:10:17,109 - train - INFO - alphas:tensor([0.4290, 0.5710], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,109 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,109 - train - INFO - True
2024-04-03 13:10:17,110 - train - INFO - alphas:tensor([0.2512, 0.7488], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,110 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,110 - train - INFO - True
2024-04-03 13:10:17,111 - train - INFO - alphas:tensor([0.4149, 0.5851], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,111 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,111 - train - INFO - True
2024-04-03 13:10:17,111 - train - INFO - alphas:tensor([0.5645, 0.4355], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,112 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,112 - train - INFO - True
2024-04-03 13:10:17,112 - train - INFO - alphas:tensor([0.4160, 0.5840], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,112 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,113 - train - INFO - True
2024-04-03 13:10:17,113 - train - INFO - alphas:tensor([0.2697, 0.7303], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,113 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,113 - train - INFO - True
2024-04-03 13:10:17,114 - train - INFO - alphas:tensor([0.4129, 0.5871], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,114 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,114 - train - INFO - True
2024-04-03 13:10:17,115 - train - INFO - alphas:tensor([0.5005, 0.4995], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,115 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,115 - train - INFO - True
2024-04-03 13:10:17,116 - train - INFO - alphas:tensor([0.3473, 0.6527], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,116 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,116 - train - INFO - True
2024-04-03 13:10:17,117 - train - INFO - alphas:tensor([0.2351, 0.7649], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,117 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,117 - train - INFO - True
2024-04-03 13:10:17,117 - train - INFO - alphas:tensor([0.3141, 0.6859], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,117 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,118 - train - INFO - True
2024-04-03 13:10:17,118 - train - INFO - alphas:tensor([0.3875, 0.6125], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,118 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,118 - train - INFO - True
2024-04-03 13:10:17,119 - train - INFO - alphas:tensor([0.2093, 0.7907], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,119 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,119 - train - INFO - True
2024-04-03 13:10:17,120 - train - INFO - alphas:tensor([0.1770, 0.8230], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,120 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,120 - train - INFO - True
2024-04-03 13:10:17,121 - train - INFO - alphas:tensor([0.2305, 0.7695], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,121 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,121 - train - INFO - True
2024-04-03 13:10:17,121 - train - INFO - alphas:tensor([0.3371, 0.6629], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,122 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,122 - train - INFO - True
2024-04-03 13:10:17,122 - train - INFO - alphas:tensor([0.1016, 0.8984], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,122 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,122 - train - INFO - True
2024-04-03 13:10:17,123 - train - INFO - alphas:tensor([0.1133, 0.8867], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,123 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,123 - train - INFO - True
2024-04-03 13:10:17,124 - train - INFO - alphas:tensor([0.0038, 0.9962], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,124 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,124 - train - INFO - True
2024-04-03 13:10:17,125 - train - INFO - alphas:tensor([0.0079, 0.9921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,125 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,125 - train - INFO - True
2024-04-03 13:10:17,126 - train - INFO - alphas:tensor([5.3009e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,126 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,126 - train - INFO - True
2024-04-03 13:10:17,126 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:10:17,126 - train - INFO - tau:0.2762516676992082
2024-04-03 13:10:17,127 - train - INFO - avg block size:13.413793103448276
2024-04-03 13:10:18,104 - train - INFO - Test: [   0/39]  Time: 0.975 (0.975)  Loss:  0.3521 (0.3521)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-03 13:10:53,743 - train - INFO - Test: [  39/39]  Time: 0.942 (0.915)  Loss:  0.3616 (0.3513)  Acc@1: 87.5000 (92.6800)  Acc@5: 100.0000 (99.7900)
2024-04-03 13:10:55,720 - train - INFO - Train: 131 [   0/195 (  0%)]  Loss:  1.201658 (1.2017)  Time: 1.830s,  139.90/s  (1.830s,  139.90/s)  LR: 3.110e-05  Data: 0.163 (0.163)
2024-04-03 13:12:16,962 - train - INFO - Train: 131 [  50/195 ( 26%)]  Loss:  1.685013 (1.5657)  Time: 1.565s,  163.58/s  (1.629s,  157.17/s)  LR: 3.110e-05  Data: 0.018 (0.011)
2024-04-03 13:13:37,493 - train - INFO - Train: 131 [ 100/195 ( 52%)]  Loss:  1.602438 (1.5479)  Time: 1.622s,  157.87/s  (1.620s,  158.04/s)  LR: 3.110e-05  Data: 0.005 (0.010)
2024-04-03 13:14:57,831 - train - INFO - Train: 131 [ 150/195 ( 77%)]  Loss:  1.556155 (1.5328)  Time: 1.616s,  158.40/s  (1.615s,  158.47/s)  LR: 3.110e-05  Data: 0.014 (0.009)
2024-04-03 13:16:08,186 - train - INFO - Train: 131 [ 194/195 (100%)]  Loss:  1.246296 (1.5422)  Time: 1.564s,  163.73/s  (1.612s,  158.83/s)  LR: 3.110e-05  Data: 0.000 (0.009)
2024-04-03 13:16:08,187 - train - INFO - True
2024-04-03 13:16:08,189 - train - INFO - alphas:tensor([1.2055e-04, 9.9988e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,189 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,189 - train - INFO - True
2024-04-03 13:16:08,189 - train - INFO - alphas:tensor([0.0534, 0.9466], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,190 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,190 - train - INFO - True
2024-04-03 13:16:08,190 - train - INFO - alphas:tensor([0.5688, 0.4312], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,190 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,190 - train - INFO - True
2024-04-03 13:16:08,191 - train - INFO - alphas:tensor([0.4658, 0.5342], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,191 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,191 - train - INFO - True
2024-04-03 13:16:08,192 - train - INFO - alphas:tensor([0.1357, 0.8643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,192 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,192 - train - INFO - True
2024-04-03 13:16:08,193 - train - INFO - alphas:tensor([0.2581, 0.7419], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,193 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,193 - train - INFO - True
2024-04-03 13:16:08,194 - train - INFO - alphas:tensor([0.5562, 0.4438], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,194 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,194 - train - INFO - True
2024-04-03 13:16:08,194 - train - INFO - alphas:tensor([0.4295, 0.5705], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,195 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,195 - train - INFO - True
2024-04-03 13:16:08,196 - train - INFO - alphas:tensor([0.2508, 0.7492], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,196 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,196 - train - INFO - True
2024-04-03 13:16:08,196 - train - INFO - alphas:tensor([0.4150, 0.5850], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,197 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,197 - train - INFO - True
2024-04-03 13:16:08,197 - train - INFO - alphas:tensor([0.5647, 0.4353], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,197 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,197 - train - INFO - True
2024-04-03 13:16:08,198 - train - INFO - alphas:tensor([0.4155, 0.5845], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,198 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,198 - train - INFO - True
2024-04-03 13:16:08,199 - train - INFO - alphas:tensor([0.2693, 0.7307], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,199 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,199 - train - INFO - True
2024-04-03 13:16:08,200 - train - INFO - alphas:tensor([0.4128, 0.5872], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,200 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,200 - train - INFO - True
2024-04-03 13:16:08,200 - train - INFO - alphas:tensor([0.5005, 0.4995], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,200 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,201 - train - INFO - True
2024-04-03 13:16:08,201 - train - INFO - alphas:tensor([0.3469, 0.6531], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,201 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,201 - train - INFO - True
2024-04-03 13:16:08,202 - train - INFO - alphas:tensor([0.2342, 0.7658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,202 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,202 - train - INFO - True
2024-04-03 13:16:08,203 - train - INFO - alphas:tensor([0.3137, 0.6863], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,203 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,203 - train - INFO - True
2024-04-03 13:16:08,204 - train - INFO - alphas:tensor([0.3875, 0.6125], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,204 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,204 - train - INFO - True
2024-04-03 13:16:08,204 - train - INFO - alphas:tensor([0.2087, 0.7913], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,205 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,205 - train - INFO - True
2024-04-03 13:16:08,205 - train - INFO - alphas:tensor([0.1756, 0.8244], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,205 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,205 - train - INFO - True
2024-04-03 13:16:08,206 - train - INFO - alphas:tensor([0.2295, 0.7705], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,206 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,206 - train - INFO - True
2024-04-03 13:16:08,207 - train - INFO - alphas:tensor([0.3364, 0.6636], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,207 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,207 - train - INFO - True
2024-04-03 13:16:08,208 - train - INFO - alphas:tensor([0.1005, 0.8995], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,208 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,208 - train - INFO - True
2024-04-03 13:16:08,209 - train - INFO - alphas:tensor([0.1126, 0.8874], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,209 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,209 - train - INFO - True
2024-04-03 13:16:08,209 - train - INFO - alphas:tensor([0.0035, 0.9965], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,209 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,210 - train - INFO - True
2024-04-03 13:16:08,210 - train - INFO - alphas:tensor([0.0075, 0.9925], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,210 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,210 - train - INFO - True
2024-04-03 13:16:08,211 - train - INFO - alphas:tensor([4.5691e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,211 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,211 - train - INFO - True
2024-04-03 13:16:08,212 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:16:08,212 - train - INFO - tau:0.27348915102221616
2024-04-03 13:16:08,212 - train - INFO - avg block size:13.413793103448276
2024-04-03 13:16:09,130 - train - INFO - Test: [   0/39]  Time: 0.915 (0.915)  Loss:  0.3535 (0.3535)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 13:16:43,731 - train - INFO - Test: [  39/39]  Time: 0.914 (0.888)  Loss:  0.3601 (0.3531)  Acc@1: 87.5000 (92.7300)  Acc@5: 100.0000 (99.7900)
2024-04-03 13:16:45,576 - train - INFO - Train: 132 [   0/195 (  0%)]  Loss:  1.603456 (1.6035)  Time: 1.725s,  148.40/s  (1.725s,  148.40/s)  LR: 2.896e-05  Data: 0.132 (0.132)
2024-04-03 13:18:06,995 - train - INFO - Train: 132 [  50/195 ( 26%)]  Loss:  1.371614 (1.5042)  Time: 1.714s,  149.33/s  (1.630s,  157.03/s)  LR: 2.896e-05  Data: 0.005 (0.011)
2024-04-03 13:19:28,366 - train - INFO - Train: 132 [ 100/195 ( 52%)]  Loss:  1.630109 (1.5071)  Time: 1.611s,  158.86/s  (1.629s,  157.17/s)  LR: 2.896e-05  Data: 0.006 (0.010)
2024-04-03 13:20:48,470 - train - INFO - Train: 132 [ 150/195 ( 77%)]  Loss:  1.236325 (1.5087)  Time: 1.536s,  166.66/s  (1.620s,  158.03/s)  LR: 2.896e-05  Data: 0.009 (0.009)
2024-04-03 13:22:00,934 - train - INFO - Train: 132 [ 194/195 (100%)]  Loss:  1.671052 (1.5085)  Time: 1.681s,  152.29/s  (1.626s,  157.44/s)  LR: 2.896e-05  Data: 0.000 (0.009)
2024-04-03 13:22:00,934 - train - INFO - True
2024-04-03 13:22:00,936 - train - INFO - alphas:tensor([1.0926e-04, 9.9989e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,936 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,936 - train - INFO - True
2024-04-03 13:22:00,936 - train - INFO - alphas:tensor([0.0524, 0.9476], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,937 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,937 - train - INFO - True
2024-04-03 13:22:00,937 - train - INFO - alphas:tensor([0.5689, 0.4311], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,937 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,937 - train - INFO - True
2024-04-03 13:22:00,938 - train - INFO - alphas:tensor([0.4650, 0.5350], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,938 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,938 - train - INFO - True
2024-04-03 13:22:00,939 - train - INFO - alphas:tensor([0.1349, 0.8651], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,939 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,939 - train - INFO - True
2024-04-03 13:22:00,940 - train - INFO - alphas:tensor([0.2581, 0.7419], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,940 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,940 - train - INFO - True
2024-04-03 13:22:00,941 - train - INFO - alphas:tensor([0.5564, 0.4436], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,941 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,941 - train - INFO - True
2024-04-03 13:22:00,942 - train - INFO - alphas:tensor([0.4286, 0.5714], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,942 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,942 - train - INFO - True
2024-04-03 13:22:00,943 - train - INFO - alphas:tensor([0.2506, 0.7494], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,943 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,943 - train - INFO - True
2024-04-03 13:22:00,944 - train - INFO - alphas:tensor([0.4152, 0.5848], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,944 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,944 - train - INFO - True
2024-04-03 13:22:00,945 - train - INFO - alphas:tensor([0.5646, 0.4354], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,945 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,945 - train - INFO - True
2024-04-03 13:22:00,946 - train - INFO - alphas:tensor([0.4146, 0.5854], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,946 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,946 - train - INFO - True
2024-04-03 13:22:00,946 - train - INFO - alphas:tensor([0.2686, 0.7314], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,947 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,947 - train - INFO - True
2024-04-03 13:22:00,947 - train - INFO - alphas:tensor([0.4123, 0.5877], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,947 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,947 - train - INFO - True
2024-04-03 13:22:00,948 - train - INFO - alphas:tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,948 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,948 - train - INFO - True
2024-04-03 13:22:00,949 - train - INFO - alphas:tensor([0.3459, 0.6541], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,949 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,949 - train - INFO - True
2024-04-03 13:22:00,950 - train - INFO - alphas:tensor([0.2329, 0.7671], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,950 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,950 - train - INFO - True
2024-04-03 13:22:00,951 - train - INFO - alphas:tensor([0.3128, 0.6872], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,951 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,951 - train - INFO - True
2024-04-03 13:22:00,951 - train - INFO - alphas:tensor([0.3871, 0.6129], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,951 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,952 - train - INFO - True
2024-04-03 13:22:00,952 - train - INFO - alphas:tensor([0.2079, 0.7921], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,952 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,952 - train - INFO - True
2024-04-03 13:22:00,953 - train - INFO - alphas:tensor([0.1747, 0.8253], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,953 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,953 - train - INFO - True
2024-04-03 13:22:00,954 - train - INFO - alphas:tensor([0.2290, 0.7710], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,954 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,954 - train - INFO - True
2024-04-03 13:22:00,955 - train - INFO - alphas:tensor([0.3363, 0.6637], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,955 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,955 - train - INFO - True
2024-04-03 13:22:00,955 - train - INFO - alphas:tensor([0.0996, 0.9004], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,956 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,956 - train - INFO - True
2024-04-03 13:22:00,956 - train - INFO - alphas:tensor([0.1117, 0.8883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,956 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,956 - train - INFO - True
2024-04-03 13:22:00,957 - train - INFO - alphas:tensor([0.0033, 0.9967], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,957 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,957 - train - INFO - True
2024-04-03 13:22:00,958 - train - INFO - alphas:tensor([0.0072, 0.9928], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,958 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,958 - train - INFO - True
2024-04-03 13:22:00,959 - train - INFO - alphas:tensor([3.9336e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,959 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,959 - train - INFO - True
2024-04-03 13:22:00,959 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:22:00,960 - train - INFO - tau:0.270754259511994
2024-04-03 13:22:00,960 - train - INFO - avg block size:13.413793103448276
2024-04-03 13:22:01,914 - train - INFO - Test: [   0/39]  Time: 0.951 (0.951)  Loss:  0.3503 (0.3503)  Acc@1: 92.5781 (92.5781)  Acc@5: 100.0000 (100.0000)
2024-04-03 13:22:37,010 - train - INFO - Test: [  39/39]  Time: 0.881 (0.901)  Loss:  0.3730 (0.3518)  Acc@1: 87.5000 (92.6800)  Acc@5: 100.0000 (99.7800)
2024-04-03 13:22:38,829 - train - INFO - Train: 133 [   0/195 (  0%)]  Loss:  1.505737 (1.5057)  Time: 1.694s,  151.15/s  (1.694s,  151.15/s)  LR: 2.693e-05  Data: 0.146 (0.146)
2024-04-03 13:23:59,342 - train - INFO - Train: 133 [  50/195 ( 26%)]  Loss:  1.784857 (1.5712)  Time: 1.557s,  164.37/s  (1.612s,  158.82/s)  LR: 2.693e-05  Data: 0.010 (0.011)
2024-04-03 13:25:19,775 - train - INFO - Train: 133 [ 100/195 ( 52%)]  Loss:  1.784098 (1.5415)  Time: 1.643s,  155.80/s  (1.610s,  158.98/s)  LR: 2.693e-05  Data: 0.005 (0.009)
2024-04-03 13:26:41,892 - train - INFO - Train: 133 [ 150/195 ( 77%)]  Loss:  1.203576 (1.5132)  Time: 1.647s,  155.45/s  (1.621s,  157.94/s)  LR: 2.693e-05  Data: 0.006 (0.008)
2024-04-03 13:27:52,701 - train - INFO - Train: 133 [ 194/195 (100%)]  Loss:  1.799927 (1.5151)  Time: 1.572s,  162.89/s  (1.618s,  158.19/s)  LR: 2.693e-05  Data: 0.000 (0.008)
2024-04-03 13:27:52,706 - train - INFO - True
2024-04-03 13:27:52,708 - train - INFO - alphas:tensor([9.8966e-05, 9.9990e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,711 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,711 - train - INFO - True
2024-04-03 13:27:52,712 - train - INFO - alphas:tensor([0.0514, 0.9486], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,715 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,715 - train - INFO - True
2024-04-03 13:27:52,716 - train - INFO - alphas:tensor([0.5689, 0.4311], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,716 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,728 - train - INFO - True
2024-04-03 13:27:52,734 - train - INFO - alphas:tensor([0.4641, 0.5359], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,734 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,734 - train - INFO - True
2024-04-03 13:27:52,735 - train - INFO - alphas:tensor([0.1339, 0.8661], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,735 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,735 - train - INFO - True
2024-04-03 13:27:52,735 - train - INFO - alphas:tensor([0.2576, 0.7424], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,735 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,736 - train - INFO - True
2024-04-03 13:27:52,736 - train - INFO - alphas:tensor([0.5566, 0.4434], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,736 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,736 - train - INFO - True
2024-04-03 13:27:52,737 - train - INFO - alphas:tensor([0.4285, 0.5715], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,737 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,737 - train - INFO - True
2024-04-03 13:27:52,738 - train - INFO - alphas:tensor([0.2494, 0.7506], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,742 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,742 - train - INFO - True
2024-04-03 13:27:52,743 - train - INFO - alphas:tensor([0.4145, 0.5855], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,743 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,743 - train - INFO - True
2024-04-03 13:27:52,744 - train - INFO - alphas:tensor([0.5650, 0.4350], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,744 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,744 - train - INFO - True
2024-04-03 13:27:52,745 - train - INFO - alphas:tensor([0.4141, 0.5859], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,745 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,745 - train - INFO - True
2024-04-03 13:27:52,746 - train - INFO - alphas:tensor([0.2681, 0.7319], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,746 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,746 - train - INFO - True
2024-04-03 13:27:52,746 - train - INFO - alphas:tensor([0.4125, 0.5875], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,746 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,747 - train - INFO - True
2024-04-03 13:27:52,747 - train - INFO - alphas:tensor([0.5004, 0.4996], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,747 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,747 - train - INFO - True
2024-04-03 13:27:52,748 - train - INFO - alphas:tensor([0.3455, 0.6545], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,763 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,763 - train - INFO - True
2024-04-03 13:27:52,763 - train - INFO - alphas:tensor([0.2327, 0.7673], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,772 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,772 - train - INFO - True
2024-04-03 13:27:52,773 - train - INFO - alphas:tensor([0.3129, 0.6871], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,773 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,773 - train - INFO - True
2024-04-03 13:27:52,773 - train - INFO - alphas:tensor([0.3865, 0.6135], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,773 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,774 - train - INFO - True
2024-04-03 13:27:52,774 - train - INFO - alphas:tensor([0.2067, 0.7933], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,774 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,774 - train - INFO - True
2024-04-03 13:27:52,775 - train - INFO - alphas:tensor([0.1743, 0.8257], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,775 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,775 - train - INFO - True
2024-04-03 13:27:52,776 - train - INFO - alphas:tensor([0.2280, 0.7720], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,776 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,776 - train - INFO - True
2024-04-03 13:27:52,777 - train - INFO - alphas:tensor([0.3358, 0.6642], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,781 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,781 - train - INFO - True
2024-04-03 13:27:52,782 - train - INFO - alphas:tensor([0.0986, 0.9014], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,782 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,782 - train - INFO - True
2024-04-03 13:27:52,783 - train - INFO - alphas:tensor([0.1109, 0.8891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,783 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,783 - train - INFO - True
2024-04-03 13:27:52,783 - train - INFO - alphas:tensor([0.0031, 0.9969], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,784 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,784 - train - INFO - True
2024-04-03 13:27:52,784 - train - INFO - alphas:tensor([0.0069, 0.9931], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,784 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,784 - train - INFO - True
2024-04-03 13:27:52,785 - train - INFO - alphas:tensor([3.3821e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,785 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,785 - train - INFO - True
2024-04-03 13:27:52,786 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:27:52,786 - train - INFO - tau:0.26804671691687404
2024-04-03 13:27:52,786 - train - INFO - avg block size:13.413793103448276
2024-04-03 13:27:53,736 - train - INFO - Test: [   0/39]  Time: 0.946 (0.946)  Loss:  0.3479 (0.3479)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 13:28:29,017 - train - INFO - Test: [  39/39]  Time: 0.937 (0.906)  Loss:  0.3748 (0.3479)  Acc@1: 87.5000 (92.5700)  Acc@5: 100.0000 (99.7800)
2024-04-03 13:28:31,018 - train - INFO - Train: 134 [   0/195 (  0%)]  Loss:  1.636924 (1.6369)  Time: 1.879s,  136.22/s  (1.879s,  136.22/s)  LR: 2.502e-05  Data: 0.213 (0.213)
2024-04-03 13:29:51,427 - train - INFO - Train: 134 [  50/195 ( 26%)]  Loss:  1.153662 (1.5297)  Time: 1.482s,  172.79/s  (1.613s,  158.67/s)  LR: 2.502e-05  Data: 0.005 (0.011)
2024-04-03 13:31:10,955 - train - INFO - Train: 134 [ 100/195 ( 52%)]  Loss:  1.311198 (1.5407)  Time: 1.579s,  162.17/s  (1.602s,  159.79/s)  LR: 2.502e-05  Data: 0.005 (0.009)
2024-04-03 13:32:30,692 - train - INFO - Train: 134 [ 150/195 ( 77%)]  Loss:  1.717710 (1.5364)  Time: 1.564s,  163.72/s  (1.600s,  160.03/s)  LR: 2.502e-05  Data: 0.006 (0.009)
2024-04-03 13:33:41,123 - train - INFO - Train: 134 [ 194/195 (100%)]  Loss:  1.461536 (1.5272)  Time: 1.504s,  170.18/s  (1.600s,  160.01/s)  LR: 2.502e-05  Data: 0.000 (0.008)
2024-04-03 13:33:41,123 - train - INFO - True
2024-04-03 13:33:41,124 - train - INFO - alphas:tensor([8.9641e-05, 9.9991e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,124 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,124 - train - INFO - True
2024-04-03 13:33:41,125 - train - INFO - alphas:tensor([0.0504, 0.9496], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,125 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,125 - train - INFO - True
2024-04-03 13:33:41,126 - train - INFO - alphas:tensor([0.5694, 0.4306], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,126 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,126 - train - INFO - True
2024-04-03 13:33:41,127 - train - INFO - alphas:tensor([0.4637, 0.5363], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,127 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,127 - train - INFO - True
2024-04-03 13:33:41,128 - train - INFO - alphas:tensor([0.1333, 0.8667], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,128 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,128 - train - INFO - True
2024-04-03 13:33:41,128 - train - INFO - alphas:tensor([0.2577, 0.7423], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,129 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,129 - train - INFO - True
2024-04-03 13:33:41,129 - train - INFO - alphas:tensor([0.5564, 0.4436], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,129 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,129 - train - INFO - True
2024-04-03 13:33:41,130 - train - INFO - alphas:tensor([0.4274, 0.5726], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,135 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,135 - train - INFO - True
2024-04-03 13:33:41,136 - train - INFO - alphas:tensor([0.2491, 0.7509], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,136 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,136 - train - INFO - True
2024-04-03 13:33:41,136 - train - INFO - alphas:tensor([0.4150, 0.5850], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,136 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,137 - train - INFO - True
2024-04-03 13:33:41,137 - train - INFO - alphas:tensor([0.5647, 0.4353], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,137 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,137 - train - INFO - True
2024-04-03 13:33:41,138 - train - INFO - alphas:tensor([0.4132, 0.5868], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,138 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,138 - train - INFO - True
2024-04-03 13:33:41,139 - train - INFO - alphas:tensor([0.2672, 0.7328], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,139 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,139 - train - INFO - True
2024-04-03 13:33:41,140 - train - INFO - alphas:tensor([0.4126, 0.5874], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,140 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,140 - train - INFO - True
2024-04-03 13:33:41,140 - train - INFO - alphas:tensor([0.5003, 0.4997], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,141 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,141 - train - INFO - True
2024-04-03 13:33:41,141 - train - INFO - alphas:tensor([0.3451, 0.6549], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,141 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,141 - train - INFO - True
2024-04-03 13:33:41,142 - train - INFO - alphas:tensor([0.2320, 0.7680], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,142 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,142 - train - INFO - True
2024-04-03 13:33:41,143 - train - INFO - alphas:tensor([0.3123, 0.6877], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,143 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,143 - train - INFO - True
2024-04-03 13:33:41,148 - train - INFO - alphas:tensor([0.3857, 0.6143], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,148 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,148 - train - INFO - True
2024-04-03 13:33:41,149 - train - INFO - alphas:tensor([0.2060, 0.7940], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,149 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,149 - train - INFO - True
2024-04-03 13:33:41,150 - train - INFO - alphas:tensor([0.1735, 0.8265], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,150 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,150 - train - INFO - True
2024-04-03 13:33:41,151 - train - INFO - alphas:tensor([0.2275, 0.7725], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,151 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,151 - train - INFO - True
2024-04-03 13:33:41,151 - train - INFO - alphas:tensor([0.3365, 0.6635], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,152 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,152 - train - INFO - True
2024-04-03 13:33:41,152 - train - INFO - alphas:tensor([0.0981, 0.9019], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,157 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,157 - train - INFO - True
2024-04-03 13:33:41,157 - train - INFO - alphas:tensor([0.1103, 0.8897], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,158 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,158 - train - INFO - True
2024-04-03 13:33:41,158 - train - INFO - alphas:tensor([0.0029, 0.9971], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,158 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,158 - train - INFO - True
2024-04-03 13:33:41,159 - train - INFO - alphas:tensor([0.0065, 0.9935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,159 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,159 - train - INFO - True
2024-04-03 13:33:41,160 - train - INFO - alphas:tensor([2.9041e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,160 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,160 - train - INFO - True
2024-04-03 13:33:41,161 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:33:41,161 - train - INFO - tau:0.2653662497477053
2024-04-03 13:33:41,161 - train - INFO - avg block size:13.413793103448276
2024-04-03 13:33:42,087 - train - INFO - Test: [   0/39]  Time: 0.924 (0.924)  Loss:  0.3467 (0.3467)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 13:34:17,002 - train - INFO - Test: [  39/39]  Time: 0.878 (0.896)  Loss:  0.3694 (0.3548)  Acc@1: 87.5000 (92.6600)  Acc@5: 100.0000 (99.8100)
2024-04-03 13:34:18,975 - train - INFO - Train: 135 [   0/195 (  0%)]  Loss:  1.715623 (1.7156)  Time: 1.836s,  139.47/s  (1.836s,  139.47/s)  LR: 2.321e-05  Data: 0.148 (0.148)
2024-04-03 13:35:39,636 - train - INFO - Train: 135 [  50/195 ( 26%)]  Loss:  1.211804 (1.5038)  Time: 1.546s,  165.55/s  (1.618s,  158.26/s)  LR: 2.321e-05  Data: 0.005 (0.010)
2024-04-03 13:37:00,050 - train - INFO - Train: 135 [ 100/195 ( 52%)]  Loss:  1.458704 (1.5441)  Time: 1.631s,  156.99/s  (1.613s,  158.71/s)  LR: 2.321e-05  Data: 0.005 (0.008)
2024-04-03 13:38:21,303 - train - INFO - Train: 135 [ 150/195 ( 77%)]  Loss:  1.701711 (1.5336)  Time: 1.531s,  167.24/s  (1.617s,  158.32/s)  LR: 2.321e-05  Data: 0.006 (0.008)
2024-04-03 13:39:31,896 - train - INFO - Train: 135 [ 194/195 (100%)]  Loss:  1.140268 (1.5331)  Time: 1.671s,  153.21/s  (1.614s,  158.60/s)  LR: 2.321e-05  Data: 0.000 (0.008)
2024-04-03 13:39:31,902 - train - INFO - True
2024-04-03 13:39:31,904 - train - INFO - alphas:tensor([8.1024e-05, 9.9992e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,904 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,904 - train - INFO - True
2024-04-03 13:39:31,905 - train - INFO - alphas:tensor([0.0493, 0.9507], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,905 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,905 - train - INFO - True
2024-04-03 13:39:31,906 - train - INFO - alphas:tensor([0.5695, 0.4305], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,906 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,906 - train - INFO - True
2024-04-03 13:39:31,907 - train - INFO - alphas:tensor([0.4630, 0.5370], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,907 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,907 - train - INFO - True
2024-04-03 13:39:31,907 - train - INFO - alphas:tensor([0.1322, 0.8678], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,908 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,908 - train - INFO - True
2024-04-03 13:39:31,908 - train - INFO - alphas:tensor([0.2568, 0.7432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,908 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,908 - train - INFO - True
2024-04-03 13:39:31,909 - train - INFO - alphas:tensor([0.5565, 0.4435], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,909 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,909 - train - INFO - True
2024-04-03 13:39:31,914 - train - INFO - alphas:tensor([0.4270, 0.5730], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,914 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,914 - train - INFO - True
2024-04-03 13:39:31,915 - train - INFO - alphas:tensor([0.2481, 0.7519], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,915 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,915 - train - INFO - True
2024-04-03 13:39:31,916 - train - INFO - alphas:tensor([0.4149, 0.5851], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,916 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,916 - train - INFO - True
2024-04-03 13:39:31,917 - train - INFO - alphas:tensor([0.5651, 0.4349], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,917 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,917 - train - INFO - True
2024-04-03 13:39:31,918 - train - INFO - alphas:tensor([0.4129, 0.5871], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,918 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,918 - train - INFO - True
2024-04-03 13:39:31,919 - train - INFO - alphas:tensor([0.2670, 0.7330], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,922 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,931 - train - INFO - True
2024-04-03 13:39:31,932 - train - INFO - alphas:tensor([0.4132, 0.5868], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,932 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,932 - train - INFO - True
2024-04-03 13:39:31,932 - train - INFO - alphas:tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,932 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,932 - train - INFO - True
2024-04-03 13:39:31,933 - train - INFO - alphas:tensor([0.3445, 0.6555], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,933 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,933 - train - INFO - True
2024-04-03 13:39:31,934 - train - INFO - alphas:tensor([0.2316, 0.7684], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,938 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,939 - train - INFO - True
2024-04-03 13:39:31,939 - train - INFO - alphas:tensor([0.3121, 0.6879], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,944 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,944 - train - INFO - True
2024-04-03 13:39:31,944 - train - INFO - alphas:tensor([0.3849, 0.6151], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,945 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,945 - train - INFO - True
2024-04-03 13:39:31,945 - train - INFO - alphas:tensor([0.2052, 0.7948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,945 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,945 - train - INFO - True
2024-04-03 13:39:31,946 - train - INFO - alphas:tensor([0.1730, 0.8270], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,946 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,946 - train - INFO - True
2024-04-03 13:39:31,947 - train - INFO - alphas:tensor([0.2271, 0.7729], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,947 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,947 - train - INFO - True
2024-04-03 13:39:31,948 - train - INFO - alphas:tensor([0.3360, 0.6640], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,957 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,957 - train - INFO - True
2024-04-03 13:39:31,958 - train - INFO - alphas:tensor([0.0970, 0.9030], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,958 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,958 - train - INFO - True
2024-04-03 13:39:31,959 - train - INFO - alphas:tensor([0.1095, 0.8905], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,959 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,959 - train - INFO - True
2024-04-03 13:39:31,960 - train - INFO - alphas:tensor([0.0028, 0.9972], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,960 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,960 - train - INFO - True
2024-04-03 13:39:31,961 - train - INFO - alphas:tensor([0.0062, 0.9938], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,961 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,961 - train - INFO - True
2024-04-03 13:39:31,961 - train - INFO - alphas:tensor([2.4904e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,961 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,961 - train - INFO - True
2024-04-03 13:39:31,962 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:39:31,967 - train - INFO - tau:0.2627125872502282
2024-04-03 13:39:31,975 - train - INFO - avg block size:13.413793103448276
2024-04-03 13:39:32,902 - train - INFO - Test: [   0/39]  Time: 0.909 (0.909)  Loss:  0.3508 (0.3508)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-03 13:40:07,354 - train - INFO - Test: [  39/39]  Time: 0.873 (0.884)  Loss:  0.3989 (0.3536)  Acc@1: 81.2500 (92.6800)  Acc@5: 100.0000 (99.7800)
2024-04-03 13:40:09,560 - train - INFO - Train: 136 [   0/195 (  0%)]  Loss:  1.446664 (1.4467)  Time: 2.081s,  123.03/s  (2.081s,  123.03/s)  LR: 2.152e-05  Data: 0.159 (0.159)
2024-04-03 13:41:30,206 - train - INFO - Train: 136 [  50/195 ( 26%)]  Loss:  1.379655 (1.5233)  Time: 1.566s,  163.45/s  (1.622s,  157.82/s)  LR: 2.152e-05  Data: 0.008 (0.012)
2024-04-03 13:42:51,372 - train - INFO - Train: 136 [ 100/195 ( 52%)]  Loss:  1.474775 (1.5073)  Time: 1.862s,  137.46/s  (1.623s,  157.76/s)  LR: 2.152e-05  Data: 0.005 (0.009)
2024-04-03 13:44:11,851 - train - INFO - Train: 136 [ 150/195 ( 77%)]  Loss:  1.588367 (1.4978)  Time: 1.781s,  143.74/s  (1.618s,  158.19/s)  LR: 2.152e-05  Data: 0.005 (0.009)
2024-04-03 13:45:22,747 - train - INFO - Train: 136 [ 194/195 (100%)]  Loss:  1.791397 (1.5149)  Time: 1.580s,  162.03/s  (1.617s,  158.35/s)  LR: 2.152e-05  Data: 0.000 (0.009)
2024-04-03 13:45:22,748 - train - INFO - True
2024-04-03 13:45:22,749 - train - INFO - alphas:tensor([7.3204e-05, 9.9993e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,749 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,749 - train - INFO - True
2024-04-03 13:45:22,750 - train - INFO - alphas:tensor([0.0482, 0.9518], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,750 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,750 - train - INFO - True
2024-04-03 13:45:22,751 - train - INFO - alphas:tensor([0.5703, 0.4297], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,751 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,751 - train - INFO - True
2024-04-03 13:45:22,752 - train - INFO - alphas:tensor([0.4626, 0.5374], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,752 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,752 - train - INFO - True
2024-04-03 13:45:22,753 - train - INFO - alphas:tensor([0.1315, 0.8685], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,753 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,753 - train - INFO - True
2024-04-03 13:45:22,753 - train - INFO - alphas:tensor([0.2568, 0.7432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,753 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,754 - train - INFO - True
2024-04-03 13:45:22,754 - train - INFO - alphas:tensor([0.5567, 0.4433], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,754 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,754 - train - INFO - True
2024-04-03 13:45:22,755 - train - INFO - alphas:tensor([0.4265, 0.5735], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,755 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,755 - train - INFO - True
2024-04-03 13:45:22,756 - train - INFO - alphas:tensor([0.2482, 0.7518], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,756 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,756 - train - INFO - True
2024-04-03 13:45:22,758 - train - INFO - alphas:tensor([0.4159, 0.5841], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,758 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,758 - train - INFO - True
2024-04-03 13:45:22,759 - train - INFO - alphas:tensor([0.5650, 0.4350], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,759 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,759 - train - INFO - True
2024-04-03 13:45:22,759 - train - INFO - alphas:tensor([0.4121, 0.5879], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,760 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,760 - train - INFO - True
2024-04-03 13:45:22,760 - train - INFO - alphas:tensor([0.2665, 0.7335], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,760 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,760 - train - INFO - True
2024-04-03 13:45:22,761 - train - INFO - alphas:tensor([0.4133, 0.5867], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,761 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,761 - train - INFO - True
2024-04-03 13:45:22,762 - train - INFO - alphas:tensor([0.5002, 0.4998], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,762 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,762 - train - INFO - True
2024-04-03 13:45:22,763 - train - INFO - alphas:tensor([0.3447, 0.6553], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,763 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,763 - train - INFO - True
2024-04-03 13:45:22,764 - train - INFO - alphas:tensor([0.2310, 0.7690], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,764 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,764 - train - INFO - True
2024-04-03 13:45:22,764 - train - INFO - alphas:tensor([0.3124, 0.6876], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,765 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,765 - train - INFO - True
2024-04-03 13:45:22,765 - train - INFO - alphas:tensor([0.3850, 0.6150], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,765 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,765 - train - INFO - True
2024-04-03 13:45:22,766 - train - INFO - alphas:tensor([0.2047, 0.7953], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,766 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,766 - train - INFO - True
2024-04-03 13:45:22,767 - train - INFO - alphas:tensor([0.1723, 0.8277], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,767 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,767 - train - INFO - True
2024-04-03 13:45:22,768 - train - INFO - alphas:tensor([0.2269, 0.7731], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,768 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,768 - train - INFO - True
2024-04-03 13:45:22,769 - train - INFO - alphas:tensor([0.3360, 0.6640], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,769 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,769 - train - INFO - True
2024-04-03 13:45:22,769 - train - INFO - alphas:tensor([0.0962, 0.9038], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,770 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,770 - train - INFO - True
2024-04-03 13:45:22,770 - train - INFO - alphas:tensor([0.1087, 0.8913], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,770 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,770 - train - INFO - True
2024-04-03 13:45:22,771 - train - INFO - alphas:tensor([0.0026, 0.9974], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,771 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,771 - train - INFO - True
2024-04-03 13:45:22,772 - train - INFO - alphas:tensor([0.0060, 0.9940], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,772 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,772 - train - INFO - True
2024-04-03 13:45:22,773 - train - INFO - alphas:tensor([2.1328e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,773 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,773 - train - INFO - True
2024-04-03 13:45:22,773 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:45:22,774 - train - INFO - tau:0.2600854613777259
2024-04-03 13:45:22,774 - train - INFO - avg block size:13.413793103448276
2024-04-03 13:45:23,615 - train - INFO - Test: [   0/39]  Time: 0.839 (0.839)  Loss:  0.3496 (0.3496)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-03 13:45:58,112 - train - INFO - Test: [  39/39]  Time: 0.901 (0.883)  Loss:  0.3699 (0.3532)  Acc@1: 87.5000 (92.7000)  Acc@5: 100.0000 (99.7900)
2024-04-03 13:46:00,051 - train - INFO - Train: 137 [   0/195 (  0%)]  Loss:  1.774953 (1.7750)  Time: 1.847s,  138.63/s  (1.847s,  138.63/s)  LR: 1.995e-05  Data: 0.135 (0.135)
2024-04-03 13:47:19,966 - train - INFO - Train: 137 [  50/195 ( 26%)]  Loss:  1.168594 (1.4949)  Time: 1.784s,  143.53/s  (1.603s,  159.69/s)  LR: 1.995e-05  Data: 0.010 (0.010)
2024-04-03 13:48:40,130 - train - INFO - Train: 137 [ 100/195 ( 52%)]  Loss:  1.618812 (1.5371)  Time: 1.632s,  156.87/s  (1.603s,  159.68/s)  LR: 1.995e-05  Data: 0.005 (0.009)
2024-04-03 13:50:02,266 - train - INFO - Train: 137 [ 150/195 ( 77%)]  Loss:  1.213589 (1.5368)  Time: 1.648s,  155.29/s  (1.616s,  158.39/s)  LR: 1.995e-05  Data: 0.006 (0.008)
2024-04-03 13:51:14,225 - train - INFO - Train: 137 [ 194/195 (100%)]  Loss:  1.202186 (1.5419)  Time: 1.515s,  168.96/s  (1.621s,  157.97/s)  LR: 1.995e-05  Data: 0.000 (0.008)
2024-04-03 13:51:14,225 - train - INFO - True
2024-04-03 13:51:14,226 - train - INFO - alphas:tensor([6.6169e-05, 9.9993e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,227 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,227 - train - INFO - True
2024-04-03 13:51:14,228 - train - INFO - alphas:tensor([0.0473, 0.9527], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,228 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,228 - train - INFO - True
2024-04-03 13:51:14,228 - train - INFO - alphas:tensor([0.5708, 0.4292], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,229 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,229 - train - INFO - True
2024-04-03 13:51:14,234 - train - INFO - alphas:tensor([0.4622, 0.5378], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,234 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,234 - train - INFO - True
2024-04-03 13:51:14,235 - train - INFO - alphas:tensor([0.1304, 0.8696], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,235 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,235 - train - INFO - True
2024-04-03 13:51:14,236 - train - INFO - alphas:tensor([0.2562, 0.7438], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,236 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,236 - train - INFO - True
2024-04-03 13:51:14,237 - train - INFO - alphas:tensor([0.5566, 0.4434], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,237 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,237 - train - INFO - True
2024-04-03 13:51:14,238 - train - INFO - alphas:tensor([0.4257, 0.5743], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,238 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,238 - train - INFO - True
2024-04-03 13:51:14,239 - train - INFO - alphas:tensor([0.2472, 0.7528], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,239 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,239 - train - INFO - True
2024-04-03 13:51:14,240 - train - INFO - alphas:tensor([0.4156, 0.5844], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,240 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,240 - train - INFO - True
2024-04-03 13:51:14,241 - train - INFO - alphas:tensor([0.5653, 0.4347], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,241 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,241 - train - INFO - True
2024-04-03 13:51:14,242 - train - INFO - alphas:tensor([0.4115, 0.5885], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,242 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,242 - train - INFO - True
2024-04-03 13:51:14,243 - train - INFO - alphas:tensor([0.2659, 0.7341], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,243 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,243 - train - INFO - True
2024-04-03 13:51:14,244 - train - INFO - alphas:tensor([0.4135, 0.5865], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,244 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,244 - train - INFO - True
2024-04-03 13:51:14,245 - train - INFO - alphas:tensor([0.5002, 0.4998], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,245 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,245 - train - INFO - True
2024-04-03 13:51:14,246 - train - INFO - alphas:tensor([0.3441, 0.6559], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,246 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,246 - train - INFO - True
2024-04-03 13:51:14,246 - train - INFO - alphas:tensor([0.2303, 0.7697], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,247 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,247 - train - INFO - True
2024-04-03 13:51:14,247 - train - INFO - alphas:tensor([0.3116, 0.6884], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,247 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,247 - train - INFO - True
2024-04-03 13:51:14,248 - train - INFO - alphas:tensor([0.3842, 0.6158], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,248 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,248 - train - INFO - True
2024-04-03 13:51:14,249 - train - INFO - alphas:tensor([0.2037, 0.7963], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,249 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,249 - train - INFO - True
2024-04-03 13:51:14,250 - train - INFO - alphas:tensor([0.1712, 0.8288], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,250 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,250 - train - INFO - True
2024-04-03 13:51:14,250 - train - INFO - alphas:tensor([0.2262, 0.7738], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,251 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,251 - train - INFO - True
2024-04-03 13:51:14,251 - train - INFO - alphas:tensor([0.3355, 0.6645], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,251 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,251 - train - INFO - True
2024-04-03 13:51:14,252 - train - INFO - alphas:tensor([0.0952, 0.9048], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,252 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,252 - train - INFO - True
2024-04-03 13:51:14,253 - train - INFO - alphas:tensor([0.1080, 0.8920], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,253 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,253 - train - INFO - True
2024-04-03 13:51:14,254 - train - INFO - alphas:tensor([0.0024, 0.9976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,254 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,254 - train - INFO - True
2024-04-03 13:51:14,254 - train - INFO - alphas:tensor([0.0057, 0.9943], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,255 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,255 - train - INFO - True
2024-04-03 13:51:14,255 - train - INFO - alphas:tensor([1.8238e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,255 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,255 - train - INFO - True
2024-04-03 13:51:14,256 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:51:14,256 - train - INFO - tau:0.2574846067639487
2024-04-03 13:51:14,256 - train - INFO - avg block size:13.413793103448276
2024-04-03 13:51:15,186 - train - INFO - Test: [   0/39]  Time: 0.928 (0.928)  Loss:  0.3545 (0.3545)  Acc@1: 94.1406 (94.1406)  Acc@5: 100.0000 (100.0000)
2024-04-03 13:51:51,256 - train - INFO - Test: [  39/39]  Time: 0.943 (0.925)  Loss:  0.3652 (0.3556)  Acc@1: 87.5000 (92.5900)  Acc@5: 100.0000 (99.7800)
2024-04-03 13:51:53,193 - train - INFO - Train: 138 [   0/195 (  0%)]  Loss:  1.315656 (1.3157)  Time: 1.808s,  141.63/s  (1.808s,  141.63/s)  LR: 1.848e-05  Data: 0.220 (0.220)
2024-04-03 13:53:14,072 - train - INFO - Train: 138 [  50/195 ( 26%)]  Loss:  1.177990 (1.5210)  Time: 1.535s,  166.77/s  (1.621s,  157.90/s)  LR: 1.848e-05  Data: 0.005 (0.012)
2024-04-03 13:54:34,595 - train - INFO - Train: 138 [ 100/195 ( 52%)]  Loss:  1.752041 (1.5298)  Time: 1.554s,  164.73/s  (1.616s,  158.42/s)  LR: 1.848e-05  Data: 0.005 (0.010)
2024-04-03 13:55:55,893 - train - INFO - Train: 138 [ 150/195 ( 77%)]  Loss:  1.759834 (1.5287)  Time: 1.683s,  152.09/s  (1.619s,  158.10/s)  LR: 1.848e-05  Data: 0.005 (0.009)
2024-04-03 13:57:07,813 - train - INFO - Train: 138 [ 194/195 (100%)]  Loss:  1.200729 (1.5297)  Time: 1.563s,  163.79/s  (1.623s,  157.76/s)  LR: 1.848e-05  Data: 0.000 (0.009)
2024-04-03 13:57:07,814 - train - INFO - True
2024-04-03 13:57:07,815 - train - INFO - alphas:tensor([5.9747e-05, 9.9994e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,815 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,815 - train - INFO - True
2024-04-03 13:57:07,816 - train - INFO - alphas:tensor([0.0462, 0.9538], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,816 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,816 - train - INFO - True
2024-04-03 13:57:07,817 - train - INFO - alphas:tensor([0.5706, 0.4294], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,817 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,817 - train - INFO - True
2024-04-03 13:57:07,817 - train - INFO - alphas:tensor([0.4612, 0.5388], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,818 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,818 - train - INFO - True
2024-04-03 13:57:07,818 - train - INFO - alphas:tensor([0.1294, 0.8706], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,818 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,818 - train - INFO - True
2024-04-03 13:57:07,819 - train - INFO - alphas:tensor([0.2558, 0.7442], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,819 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,819 - train - INFO - True
2024-04-03 13:57:07,820 - train - INFO - alphas:tensor([0.5567, 0.4433], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,820 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,820 - train - INFO - True
2024-04-03 13:57:07,821 - train - INFO - alphas:tensor([0.4253, 0.5747], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,821 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,821 - train - INFO - True
2024-04-03 13:57:07,821 - train - INFO - alphas:tensor([0.2469, 0.7531], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,822 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,822 - train - INFO - True
2024-04-03 13:57:07,823 - train - INFO - alphas:tensor([0.4160, 0.5840], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,823 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,823 - train - INFO - True
2024-04-03 13:57:07,824 - train - INFO - alphas:tensor([0.5654, 0.4346], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,824 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,824 - train - INFO - True
2024-04-03 13:57:07,824 - train - INFO - alphas:tensor([0.4110, 0.5890], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,824 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,825 - train - INFO - True
2024-04-03 13:57:07,825 - train - INFO - alphas:tensor([0.2654, 0.7346], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,825 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,825 - train - INFO - True
2024-04-03 13:57:07,826 - train - INFO - alphas:tensor([0.4137, 0.5863], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,826 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,826 - train - INFO - True
2024-04-03 13:57:07,827 - train - INFO - alphas:tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,827 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,827 - train - INFO - True
2024-04-03 13:57:07,828 - train - INFO - alphas:tensor([0.3433, 0.6567], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,828 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,828 - train - INFO - True
2024-04-03 13:57:07,828 - train - INFO - alphas:tensor([0.2294, 0.7706], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,828 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,829 - train - INFO - True
2024-04-03 13:57:07,829 - train - INFO - alphas:tensor([0.3114, 0.6886], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,829 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,829 - train - INFO - True
2024-04-03 13:57:07,830 - train - INFO - alphas:tensor([0.3844, 0.6156], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,830 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,830 - train - INFO - True
2024-04-03 13:57:07,831 - train - INFO - alphas:tensor([0.2032, 0.7968], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,831 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,831 - train - INFO - True
2024-04-03 13:57:07,832 - train - INFO - alphas:tensor([0.1706, 0.8294], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,832 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,832 - train - INFO - True
2024-04-03 13:57:07,832 - train - INFO - alphas:tensor([0.2260, 0.7740], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,833 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,833 - train - INFO - True
2024-04-03 13:57:07,833 - train - INFO - alphas:tensor([0.3352, 0.6648], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,833 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,833 - train - INFO - True
2024-04-03 13:57:07,834 - train - INFO - alphas:tensor([0.0941, 0.9059], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,834 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,834 - train - INFO - True
2024-04-03 13:57:07,835 - train - INFO - alphas:tensor([0.1071, 0.8929], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,835 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,835 - train - INFO - True
2024-04-03 13:57:07,836 - train - INFO - alphas:tensor([0.0023, 0.9977], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,836 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,836 - train - INFO - True
2024-04-03 13:57:07,836 - train - INFO - alphas:tensor([0.0054, 0.9946], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,836 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,837 - train - INFO - True
2024-04-03 13:57:07,837 - train - INFO - alphas:tensor([1.5575e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,837 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,837 - train - INFO - True
2024-04-03 13:57:07,838 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 13:57:07,838 - train - INFO - tau:0.2549097606963092
2024-04-03 13:57:07,838 - train - INFO - avg block size:13.931034482758621
2024-04-03 13:57:08,790 - train - INFO - Test: [   0/39]  Time: 0.949 (0.949)  Loss:  0.3516 (0.3516)  Acc@1: 94.1406 (94.1406)  Acc@5: 100.0000 (100.0000)
2024-04-03 13:57:44,797 - train - INFO - Test: [  39/39]  Time: 0.910 (0.924)  Loss:  0.3687 (0.3545)  Acc@1: 87.5000 (92.6800)  Acc@5: 100.0000 (99.7700)
2024-04-03 13:57:46,654 - train - INFO - Train: 139 [   0/195 (  0%)]  Loss:  1.841437 (1.8414)  Time: 1.720s,  148.86/s  (1.720s,  148.86/s)  LR: 1.713e-05  Data: 0.143 (0.143)
2024-04-03 13:59:08,252 - train - INFO - Train: 139 [  50/195 ( 26%)]  Loss:  1.279583 (1.5305)  Time: 1.542s,  166.05/s  (1.634s,  156.70/s)  LR: 1.713e-05  Data: 0.005 (0.009)
2024-04-03 14:00:28,837 - train - INFO - Train: 139 [ 100/195 ( 52%)]  Loss:  1.162960 (1.5181)  Time: 1.887s,  135.67/s  (1.623s,  157.75/s)  LR: 1.713e-05  Data: 0.010 (0.008)
2024-04-03 14:01:50,403 - train - INFO - Train: 139 [ 150/195 ( 77%)]  Loss:  1.211845 (1.5104)  Time: 1.695s,  151.07/s  (1.626s,  157.48/s)  LR: 1.713e-05  Data: 0.005 (0.008)
2024-04-03 14:03:02,282 - train - INFO - Train: 139 [ 194/195 (100%)]  Loss:  1.223238 (1.5143)  Time: 1.519s,  168.57/s  (1.627s,  157.31/s)  LR: 1.713e-05  Data: 0.000 (0.008)
2024-04-03 14:03:02,283 - train - INFO - True
2024-04-03 14:03:02,284 - train - INFO - alphas:tensor([5.3916e-05, 9.9995e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,284 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,284 - train - INFO - True
2024-04-03 14:03:02,285 - train - INFO - alphas:tensor([0.0453, 0.9547], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,285 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,286 - train - INFO - True
2024-04-03 14:03:02,286 - train - INFO - alphas:tensor([0.5714, 0.4286], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,286 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,287 - train - INFO - True
2024-04-03 14:03:02,287 - train - INFO - alphas:tensor([0.4612, 0.5388], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,287 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,287 - train - INFO - True
2024-04-03 14:03:02,288 - train - INFO - alphas:tensor([0.1288, 0.8712], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,288 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,288 - train - INFO - True
2024-04-03 14:03:02,289 - train - INFO - alphas:tensor([0.2563, 0.7437], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,289 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,289 - train - INFO - True
2024-04-03 14:03:02,290 - train - INFO - alphas:tensor([0.5563, 0.4437], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,290 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,290 - train - INFO - True
2024-04-03 14:03:02,290 - train - INFO - alphas:tensor([0.4247, 0.5753], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,290 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,291 - train - INFO - True
2024-04-03 14:03:02,291 - train - INFO - alphas:tensor([0.2461, 0.7539], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,291 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,291 - train - INFO - True
2024-04-03 14:03:02,292 - train - INFO - alphas:tensor([0.4163, 0.5837], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,292 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,292 - train - INFO - True
2024-04-03 14:03:02,293 - train - INFO - alphas:tensor([0.5659, 0.4341], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,293 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,293 - train - INFO - True
2024-04-03 14:03:02,294 - train - INFO - alphas:tensor([0.4108, 0.5892], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,294 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,294 - train - INFO - True
2024-04-03 14:03:02,294 - train - INFO - alphas:tensor([0.2643, 0.7357], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,295 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,295 - train - INFO - True
2024-04-03 14:03:02,295 - train - INFO - alphas:tensor([0.4135, 0.5865], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,295 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,295 - train - INFO - True
2024-04-03 14:03:02,296 - train - INFO - alphas:tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,296 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,296 - train - INFO - True
2024-04-03 14:03:02,297 - train - INFO - alphas:tensor([0.3430, 0.6570], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,297 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,297 - train - INFO - True
2024-04-03 14:03:02,298 - train - INFO - alphas:tensor([0.2287, 0.7713], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,298 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,298 - train - INFO - True
2024-04-03 14:03:02,298 - train - INFO - alphas:tensor([0.3111, 0.6889], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,299 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,299 - train - INFO - True
2024-04-03 14:03:02,299 - train - INFO - alphas:tensor([0.3840, 0.6160], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,299 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,299 - train - INFO - True
2024-04-03 14:03:02,300 - train - INFO - alphas:tensor([0.2024, 0.7976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,300 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,300 - train - INFO - True
2024-04-03 14:03:02,301 - train - INFO - alphas:tensor([0.1696, 0.8304], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,301 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,301 - train - INFO - True
2024-04-03 14:03:02,302 - train - INFO - alphas:tensor([0.2253, 0.7747], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,302 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,302 - train - INFO - True
2024-04-03 14:03:02,302 - train - INFO - alphas:tensor([0.3348, 0.6652], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,303 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,303 - train - INFO - True
2024-04-03 14:03:02,303 - train - INFO - alphas:tensor([0.0930, 0.9070], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,303 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,303 - train - INFO - True
2024-04-03 14:03:02,304 - train - INFO - alphas:tensor([0.1061, 0.8939], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,304 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,304 - train - INFO - True
2024-04-03 14:03:02,305 - train - INFO - alphas:tensor([0.0021, 0.9979], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,305 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,305 - train - INFO - True
2024-04-03 14:03:02,306 - train - INFO - alphas:tensor([0.0051, 0.9949], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,306 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,306 - train - INFO - True
2024-04-03 14:03:02,306 - train - INFO - alphas:tensor([1.3280e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,307 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,307 - train - INFO - True
2024-04-03 14:03:02,307 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:03:02,307 - train - INFO - tau:0.2523606630893461
2024-04-03 14:03:02,307 - train - INFO - avg block size:13.413793103448276
2024-04-03 14:03:03,212 - train - INFO - Test: [   0/39]  Time: 0.902 (0.902)  Loss:  0.3538 (0.3538)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-03 14:03:38,515 - train - INFO - Test: [  39/39]  Time: 0.885 (0.905)  Loss:  0.3784 (0.3526)  Acc@1: 87.5000 (92.7500)  Acc@5: 100.0000 (99.8000)
2024-04-03 14:03:40,287 - train - INFO - Train: 140 [   0/195 (  0%)]  Loss:  1.350846 (1.3508)  Time: 1.683s,  152.13/s  (1.683s,  152.13/s)  LR: 1.590e-05  Data: 0.174 (0.174)
2024-04-03 14:05:01,091 - train - INFO - Train: 140 [  50/195 ( 26%)]  Loss:  1.650836 (1.5013)  Time: 1.604s,  159.58/s  (1.617s,  158.28/s)  LR: 1.590e-05  Data: 0.005 (0.010)
2024-04-03 14:06:21,443 - train - INFO - Train: 140 [ 100/195 ( 52%)]  Loss:  1.709238 (1.5414)  Time: 1.663s,  153.96/s  (1.612s,  158.79/s)  LR: 1.590e-05  Data: 0.010 (0.009)
2024-04-03 14:07:41,759 - train - INFO - Train: 140 [ 150/195 ( 77%)]  Loss:  1.420352 (1.5329)  Time: 1.547s,  165.45/s  (1.610s,  158.98/s)  LR: 1.590e-05  Data: 0.005 (0.009)
2024-04-03 14:08:54,152 - train - INFO - Train: 140 [ 194/195 (100%)]  Loss:  1.268018 (1.5367)  Time: 1.622s,  157.85/s  (1.618s,  158.21/s)  LR: 1.590e-05  Data: 0.000 (0.009)
2024-04-03 14:08:54,153 - train - INFO - True
2024-04-03 14:08:54,154 - train - INFO - alphas:tensor([4.8604e-05, 9.9995e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,154 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,154 - train - INFO - True
2024-04-03 14:08:54,155 - train - INFO - alphas:tensor([0.0443, 0.9557], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,155 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,156 - train - INFO - True
2024-04-03 14:08:54,156 - train - INFO - alphas:tensor([0.5714, 0.4286], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,156 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,156 - train - INFO - True
2024-04-03 14:08:54,157 - train - INFO - alphas:tensor([0.4606, 0.5394], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,157 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,157 - train - INFO - True
2024-04-03 14:08:54,158 - train - INFO - alphas:tensor([0.1276, 0.8724], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,158 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,158 - train - INFO - True
2024-04-03 14:08:54,159 - train - INFO - alphas:tensor([0.2555, 0.7445], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,159 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,159 - train - INFO - True
2024-04-03 14:08:54,159 - train - INFO - alphas:tensor([0.5563, 0.4437], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,160 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,160 - train - INFO - True
2024-04-03 14:08:54,160 - train - INFO - alphas:tensor([0.4236, 0.5764], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,160 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,160 - train - INFO - True
2024-04-03 14:08:54,161 - train - INFO - alphas:tensor([0.2456, 0.7544], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,161 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,161 - train - INFO - True
2024-04-03 14:08:54,162 - train - INFO - alphas:tensor([0.4169, 0.5831], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,162 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,162 - train - INFO - True
2024-04-03 14:08:54,163 - train - INFO - alphas:tensor([0.5663, 0.4337], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,163 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,163 - train - INFO - True
2024-04-03 14:08:54,163 - train - INFO - alphas:tensor([0.4101, 0.5899], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,164 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,164 - train - INFO - True
2024-04-03 14:08:54,164 - train - INFO - alphas:tensor([0.2640, 0.7360], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,164 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,164 - train - INFO - True
2024-04-03 14:08:54,165 - train - INFO - alphas:tensor([0.4144, 0.5856], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,165 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,165 - train - INFO - True
2024-04-03 14:08:54,166 - train - INFO - alphas:tensor([0.5003, 0.4997], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,166 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,166 - train - INFO - True
2024-04-03 14:08:54,167 - train - INFO - alphas:tensor([0.3428, 0.6572], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,167 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,167 - train - INFO - True
2024-04-03 14:08:54,168 - train - INFO - alphas:tensor([0.2282, 0.7718], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,168 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,168 - train - INFO - True
2024-04-03 14:08:54,168 - train - INFO - alphas:tensor([0.3107, 0.6893], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,168 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,168 - train - INFO - True
2024-04-03 14:08:54,169 - train - INFO - alphas:tensor([0.3838, 0.6162], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,169 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,169 - train - INFO - True
2024-04-03 14:08:54,170 - train - INFO - alphas:tensor([0.2016, 0.7984], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,170 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,170 - train - INFO - True
2024-04-03 14:08:54,171 - train - INFO - alphas:tensor([0.1688, 0.8312], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,171 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,171 - train - INFO - True
2024-04-03 14:08:54,172 - train - INFO - alphas:tensor([0.2248, 0.7752], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,172 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,172 - train - INFO - True
2024-04-03 14:08:54,172 - train - INFO - alphas:tensor([0.3344, 0.6656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,172 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,172 - train - INFO - True
2024-04-03 14:08:54,173 - train - INFO - alphas:tensor([0.0918, 0.9082], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,173 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,173 - train - INFO - True
2024-04-03 14:08:54,174 - train - INFO - alphas:tensor([0.1051, 0.8949], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,174 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,174 - train - INFO - True
2024-04-03 14:08:54,175 - train - INFO - alphas:tensor([0.0020, 0.9980], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,175 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,175 - train - INFO - True
2024-04-03 14:08:54,176 - train - INFO - alphas:tensor([0.0049, 0.9951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,176 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,176 - train - INFO - True
2024-04-03 14:08:54,176 - train - INFO - alphas:tensor([1.1307e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,176 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,176 - train - INFO - True
2024-04-03 14:08:54,177 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:08:54,177 - train - INFO - tau:0.24983705645845267
2024-04-03 14:08:54,177 - train - INFO - avg block size:13.413793103448276
2024-04-03 14:08:55,122 - train - INFO - Test: [   0/39]  Time: 0.942 (0.942)  Loss:  0.3545 (0.3545)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 14:09:30,153 - train - INFO - Test: [  39/39]  Time: 0.918 (0.899)  Loss:  0.3835 (0.3573)  Acc@1: 87.5000 (92.6600)  Acc@5: 100.0000 (99.7500)
2024-04-03 14:09:32,297 - train - INFO - Train: 141 [   0/195 (  0%)]  Loss:  1.218836 (1.2188)  Time: 1.972s,  129.84/s  (1.972s,  129.84/s)  LR: 1.478e-05  Data: 0.179 (0.179)
2024-04-03 14:10:53,796 - train - INFO - Train: 141 [  50/195 ( 26%)]  Loss:  1.826784 (1.5706)  Time: 1.631s,  156.92/s  (1.637s,  156.42/s)  LR: 1.478e-05  Data: 0.007 (0.011)
2024-04-03 14:12:17,714 - train - INFO - Train: 141 [ 100/195 ( 52%)]  Loss:  1.746701 (1.5543)  Time: 1.597s,  160.35/s  (1.657s,  154.47/s)  LR: 1.478e-05  Data: 0.005 (0.010)
2024-04-03 14:13:37,829 - train - INFO - Train: 141 [ 150/195 ( 77%)]  Loss:  1.513124 (1.5579)  Time: 1.788s,  143.15/s  (1.639s,  156.19/s)  LR: 1.478e-05  Data: 0.016 (0.009)
2024-04-03 14:14:49,298 - train - INFO - Train: 141 [ 194/195 (100%)]  Loss:  1.777619 (1.5597)  Time: 1.523s,  168.06/s  (1.636s,  156.50/s)  LR: 1.478e-05  Data: 0.000 (0.008)
2024-04-03 14:14:49,299 - train - INFO - True
2024-04-03 14:14:49,301 - train - INFO - alphas:tensor([4.3797e-05, 9.9996e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,301 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,301 - train - INFO - True
2024-04-03 14:14:49,302 - train - INFO - alphas:tensor([0.0433, 0.9567], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,302 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,302 - train - INFO - True
2024-04-03 14:14:49,302 - train - INFO - alphas:tensor([0.5718, 0.4282], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,303 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,303 - train - INFO - True
2024-04-03 14:14:49,303 - train - INFO - alphas:tensor([0.4602, 0.5398], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,303 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,303 - train - INFO - True
2024-04-03 14:14:49,304 - train - INFO - alphas:tensor([0.1265, 0.8735], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,304 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,304 - train - INFO - True
2024-04-03 14:14:49,305 - train - INFO - alphas:tensor([0.2550, 0.7450], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,305 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,305 - train - INFO - True
2024-04-03 14:14:49,306 - train - INFO - alphas:tensor([0.5568, 0.4432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,306 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,306 - train - INFO - True
2024-04-03 14:14:49,307 - train - INFO - alphas:tensor([0.4237, 0.5763], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,307 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,307 - train - INFO - True
2024-04-03 14:14:49,307 - train - INFO - alphas:tensor([0.2447, 0.7553], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,307 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,307 - train - INFO - True
2024-04-03 14:14:49,308 - train - INFO - alphas:tensor([0.4168, 0.5832], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,308 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,308 - train - INFO - True
2024-04-03 14:14:49,309 - train - INFO - alphas:tensor([0.5666, 0.4334], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,309 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,309 - train - INFO - True
2024-04-03 14:14:49,310 - train - INFO - alphas:tensor([0.4096, 0.5904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,310 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,310 - train - INFO - True
2024-04-03 14:14:49,311 - train - INFO - alphas:tensor([0.2633, 0.7367], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,311 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,311 - train - INFO - True
2024-04-03 14:14:49,312 - train - INFO - alphas:tensor([0.4147, 0.5853], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,312 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,312 - train - INFO - True
2024-04-03 14:14:49,313 - train - INFO - alphas:tensor([0.5006, 0.4994], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,313 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,313 - train - INFO - True
2024-04-03 14:14:49,314 - train - INFO - alphas:tensor([0.3429, 0.6571], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,314 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,314 - train - INFO - True
2024-04-03 14:14:49,314 - train - INFO - alphas:tensor([0.2274, 0.7726], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,314 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,314 - train - INFO - True
2024-04-03 14:14:49,315 - train - INFO - alphas:tensor([0.3104, 0.6896], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,315 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,315 - train - INFO - True
2024-04-03 14:14:49,316 - train - INFO - alphas:tensor([0.3837, 0.6163], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,316 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,316 - train - INFO - True
2024-04-03 14:14:49,317 - train - INFO - alphas:tensor([0.2009, 0.7991], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,317 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,317 - train - INFO - True
2024-04-03 14:14:49,318 - train - INFO - alphas:tensor([0.1682, 0.8318], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,318 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,318 - train - INFO - True
2024-04-03 14:14:49,318 - train - INFO - alphas:tensor([0.2245, 0.7755], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,318 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,319 - train - INFO - True
2024-04-03 14:14:49,319 - train - INFO - alphas:tensor([0.3341, 0.6659], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,319 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,319 - train - INFO - True
2024-04-03 14:14:49,320 - train - INFO - alphas:tensor([0.0907, 0.9093], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,320 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,320 - train - INFO - True
2024-04-03 14:14:49,321 - train - INFO - alphas:tensor([0.1041, 0.8959], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,321 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,321 - train - INFO - True
2024-04-03 14:14:49,322 - train - INFO - alphas:tensor([0.0019, 0.9981], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,322 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,322 - train - INFO - True
2024-04-03 14:14:49,327 - train - INFO - alphas:tensor([0.0046, 0.9954], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,327 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,327 - train - INFO - True
2024-04-03 14:14:49,328 - train - INFO - alphas:tensor([9.6130e-08, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,328 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,328 - train - INFO - True
2024-04-03 14:14:49,329 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:14:49,329 - train - INFO - tau:0.24733868589386815
2024-04-03 14:14:49,329 - train - INFO - avg block size:13.413793103448276
2024-04-03 14:14:50,315 - train - INFO - Test: [   0/39]  Time: 0.979 (0.979)  Loss:  0.3521 (0.3521)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 14:15:26,061 - train - INFO - Test: [  39/39]  Time: 0.903 (0.918)  Loss:  0.3696 (0.3555)  Acc@1: 87.5000 (92.7100)  Acc@5: 100.0000 (99.7500)
2024-04-03 14:15:27,925 - train - INFO - Train: 142 [   0/195 (  0%)]  Loss:  1.387336 (1.3873)  Time: 1.685s,  151.89/s  (1.685s,  151.89/s)  LR: 1.378e-05  Data: 0.129 (0.129)
2024-04-03 14:16:47,419 - train - INFO - Train: 142 [  50/195 ( 26%)]  Loss:  1.590386 (1.5160)  Time: 1.564s,  163.70/s  (1.592s,  160.83/s)  LR: 1.378e-05  Data: 0.009 (0.009)
2024-04-03 14:18:08,468 - train - INFO - Train: 142 [ 100/195 ( 52%)]  Loss:  1.811934 (1.5362)  Time: 1.588s,  161.21/s  (1.606s,  159.38/s)  LR: 1.378e-05  Data: 0.017 (0.009)
2024-04-03 14:19:30,275 - train - INFO - Train: 142 [ 150/195 ( 77%)]  Loss:  1.605038 (1.5468)  Time: 1.653s,  154.91/s  (1.616s,  158.41/s)  LR: 1.378e-05  Data: 0.006 (0.008)
2024-04-03 14:20:41,114 - train - INFO - Train: 142 [ 194/195 (100%)]  Loss:  1.372782 (1.5342)  Time: 1.769s,  144.75/s  (1.615s,  158.54/s)  LR: 1.378e-05  Data: 0.000 (0.008)
2024-04-03 14:20:41,115 - train - INFO - True
2024-04-03 14:20:41,116 - train - INFO - alphas:tensor([3.9433e-05, 9.9996e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,116 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,116 - train - INFO - True
2024-04-03 14:20:41,117 - train - INFO - alphas:tensor([0.0423, 0.9577], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,117 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,117 - train - INFO - True
2024-04-03 14:20:41,118 - train - INFO - alphas:tensor([0.5724, 0.4276], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,118 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,118 - train - INFO - True
2024-04-03 14:20:41,118 - train - INFO - alphas:tensor([0.4598, 0.5402], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,118 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,119 - train - INFO - True
2024-04-03 14:20:41,119 - train - INFO - alphas:tensor([0.1255, 0.8745], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,119 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,119 - train - INFO - True
2024-04-03 14:20:41,120 - train - INFO - alphas:tensor([0.2544, 0.7456], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,120 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,120 - train - INFO - True
2024-04-03 14:20:41,121 - train - INFO - alphas:tensor([0.5569, 0.4431], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,121 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,121 - train - INFO - True
2024-04-03 14:20:41,122 - train - INFO - alphas:tensor([0.4230, 0.5770], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,122 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,122 - train - INFO - True
2024-04-03 14:20:41,122 - train - INFO - alphas:tensor([0.2442, 0.7558], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,123 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,123 - train - INFO - True
2024-04-03 14:20:41,124 - train - INFO - alphas:tensor([0.4176, 0.5824], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,124 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,124 - train - INFO - True
2024-04-03 14:20:41,124 - train - INFO - alphas:tensor([0.5671, 0.4329], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,125 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,125 - train - INFO - True
2024-04-03 14:20:41,125 - train - INFO - alphas:tensor([0.4092, 0.5908], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,125 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,125 - train - INFO - True
2024-04-03 14:20:41,126 - train - INFO - alphas:tensor([0.2626, 0.7374], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,126 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,126 - train - INFO - True
2024-04-03 14:20:41,127 - train - INFO - alphas:tensor([0.4149, 0.5851], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,127 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,127 - train - INFO - True
2024-04-03 14:20:41,128 - train - INFO - alphas:tensor([0.5008, 0.4992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,128 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,128 - train - INFO - True
2024-04-03 14:20:41,128 - train - INFO - alphas:tensor([0.3424, 0.6576], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,129 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,129 - train - INFO - True
2024-04-03 14:20:41,129 - train - INFO - alphas:tensor([0.2272, 0.7728], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,129 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,129 - train - INFO - True
2024-04-03 14:20:41,130 - train - INFO - alphas:tensor([0.3109, 0.6891], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,130 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,130 - train - INFO - True
2024-04-03 14:20:41,131 - train - INFO - alphas:tensor([0.3834, 0.6166], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,131 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,131 - train - INFO - True
2024-04-03 14:20:41,132 - train - INFO - alphas:tensor([0.2001, 0.7999], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,132 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,132 - train - INFO - True
2024-04-03 14:20:41,133 - train - INFO - alphas:tensor([0.1675, 0.8325], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,133 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,133 - train - INFO - True
2024-04-03 14:20:41,134 - train - INFO - alphas:tensor([0.2240, 0.7760], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,134 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,134 - train - INFO - True
2024-04-03 14:20:41,135 - train - INFO - alphas:tensor([0.3342, 0.6658], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,135 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,135 - train - INFO - True
2024-04-03 14:20:41,135 - train - INFO - alphas:tensor([0.0898, 0.9102], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,136 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,136 - train - INFO - True
2024-04-03 14:20:41,136 - train - INFO - alphas:tensor([0.1032, 0.8968], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,136 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,136 - train - INFO - True
2024-04-03 14:20:41,137 - train - INFO - alphas:tensor([0.0018, 0.9982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,137 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,137 - train - INFO - True
2024-04-03 14:20:41,138 - train - INFO - alphas:tensor([0.0044, 0.9956], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,138 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,138 - train - INFO - True
2024-04-03 14:20:41,139 - train - INFO - alphas:tensor([8.1594e-08, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,139 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,139 - train - INFO - True
2024-04-03 14:20:41,139 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:20:41,140 - train - INFO - tau:0.24486529903492946
2024-04-03 14:20:41,140 - train - INFO - avg block size:13.413793103448276
2024-04-03 14:20:42,067 - train - INFO - Test: [   0/39]  Time: 0.925 (0.925)  Loss:  0.3481 (0.3481)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 14:21:17,157 - train - INFO - Test: [  39/39]  Time: 0.895 (0.900)  Loss:  0.3767 (0.3513)  Acc@1: 87.5000 (92.6500)  Acc@5: 100.0000 (99.7500)
2024-04-03 14:21:19,169 - train - INFO - Train: 143 [   0/195 (  0%)]  Loss:  1.793375 (1.7934)  Time: 1.931s,  132.59/s  (1.931s,  132.59/s)  LR: 1.290e-05  Data: 0.261 (0.261)
2024-04-03 14:22:40,447 - train - INFO - Train: 143 [  50/195 ( 26%)]  Loss:  1.317485 (1.5217)  Time: 1.757s,  145.67/s  (1.632s,  156.91/s)  LR: 1.290e-05  Data: 0.009 (0.013)
2024-04-03 14:24:01,039 - train - INFO - Train: 143 [ 100/195 ( 52%)]  Loss:  1.276419 (1.5012)  Time: 1.737s,  147.34/s  (1.622s,  157.85/s)  LR: 1.290e-05  Data: 0.005 (0.010)
2024-04-03 14:25:22,424 - train - INFO - Train: 143 [ 150/195 ( 77%)]  Loss:  1.535599 (1.5152)  Time: 1.503s,  170.29/s  (1.624s,  157.66/s)  LR: 1.290e-05  Data: 0.013 (0.010)
2024-04-03 14:26:33,698 - train - INFO - Train: 143 [ 194/195 (100%)]  Loss:  1.803038 (1.5062)  Time: 1.655s,  154.65/s  (1.623s,  157.75/s)  LR: 1.290e-05  Data: 0.000 (0.010)
2024-04-03 14:26:33,699 - train - INFO - True
2024-04-03 14:26:33,700 - train - INFO - alphas:tensor([3.5493e-05, 9.9996e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,700 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,700 - train - INFO - True
2024-04-03 14:26:33,701 - train - INFO - alphas:tensor([0.0413, 0.9587], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,701 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,701 - train - INFO - True
2024-04-03 14:26:33,702 - train - INFO - alphas:tensor([0.5729, 0.4271], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,702 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,702 - train - INFO - True
2024-04-03 14:26:33,703 - train - INFO - alphas:tensor([0.4593, 0.5407], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,703 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,703 - train - INFO - True
2024-04-03 14:26:33,703 - train - INFO - alphas:tensor([0.1247, 0.8753], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,703 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,704 - train - INFO - True
2024-04-03 14:26:33,704 - train - INFO - alphas:tensor([0.2545, 0.7455], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,704 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,704 - train - INFO - True
2024-04-03 14:26:33,705 - train - INFO - alphas:tensor([0.5573, 0.4427], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,705 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,705 - train - INFO - True
2024-04-03 14:26:33,706 - train - INFO - alphas:tensor([0.4227, 0.5773], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,706 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,706 - train - INFO - True
2024-04-03 14:26:33,707 - train - INFO - alphas:tensor([0.2437, 0.7563], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,707 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,707 - train - INFO - True
2024-04-03 14:26:33,707 - train - INFO - alphas:tensor([0.4182, 0.5818], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,708 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,708 - train - INFO - True
2024-04-03 14:26:33,708 - train - INFO - alphas:tensor([0.5676, 0.4324], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,708 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,708 - train - INFO - True
2024-04-03 14:26:33,709 - train - INFO - alphas:tensor([0.4088, 0.5912], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,709 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,709 - train - INFO - True
2024-04-03 14:26:33,710 - train - INFO - alphas:tensor([0.2619, 0.7381], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,710 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,710 - train - INFO - True
2024-04-03 14:26:33,711 - train - INFO - alphas:tensor([0.4154, 0.5846], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,711 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,711 - train - INFO - True
2024-04-03 14:26:33,712 - train - INFO - alphas:tensor([0.5008, 0.4992], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,712 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,712 - train - INFO - True
2024-04-03 14:26:33,712 - train - INFO - alphas:tensor([0.3419, 0.6581], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,713 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,713 - train - INFO - True
2024-04-03 14:26:33,718 - train - INFO - alphas:tensor([0.2265, 0.7735], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,718 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,718 - train - INFO - True
2024-04-03 14:26:33,718 - train - INFO - alphas:tensor([0.3111, 0.6889], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,719 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,719 - train - INFO - True
2024-04-03 14:26:33,719 - train - INFO - alphas:tensor([0.3834, 0.6166], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,719 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,719 - train - INFO - True
2024-04-03 14:26:33,720 - train - INFO - alphas:tensor([0.1991, 0.8009], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,720 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,720 - train - INFO - True
2024-04-03 14:26:33,721 - train - INFO - alphas:tensor([0.1665, 0.8335], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,721 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,721 - train - INFO - True
2024-04-03 14:26:33,722 - train - INFO - alphas:tensor([0.2232, 0.7768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,722 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,722 - train - INFO - True
2024-04-03 14:26:33,723 - train - INFO - alphas:tensor([0.3340, 0.6660], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,723 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,723 - train - INFO - True
2024-04-03 14:26:33,723 - train - INFO - alphas:tensor([0.0889, 0.9111], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,724 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,724 - train - INFO - True
2024-04-03 14:26:33,724 - train - INFO - alphas:tensor([0.1024, 0.8976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,724 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,724 - train - INFO - True
2024-04-03 14:26:33,725 - train - INFO - alphas:tensor([0.0017, 0.9983], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,725 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,725 - train - INFO - True
2024-04-03 14:26:33,726 - train - INFO - alphas:tensor([0.0042, 0.9958], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,726 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,726 - train - INFO - True
2024-04-03 14:26:33,727 - train - INFO - alphas:tensor([6.9147e-08, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,727 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,727 - train - INFO - True
2024-04-03 14:26:33,727 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:26:33,728 - train - INFO - tau:0.24241664604458016
2024-04-03 14:26:33,728 - train - INFO - avg block size:13.413793103448276
2024-04-03 14:26:34,702 - train - INFO - Test: [   0/39]  Time: 0.967 (0.967)  Loss:  0.3486 (0.3486)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 14:27:11,884 - train - INFO - Test: [  39/39]  Time: 0.889 (0.954)  Loss:  0.3701 (0.3504)  Acc@1: 87.5000 (92.6900)  Acc@5: 100.0000 (99.7500)
2024-04-03 14:27:13,711 - train - INFO - Train: 144 [   0/195 (  0%)]  Loss:  1.428920 (1.4289)  Time: 1.707s,  149.99/s  (1.707s,  149.99/s)  LR: 1.213e-05  Data: 0.214 (0.214)
2024-04-03 14:28:33,615 - train - INFO - Train: 144 [  50/195 ( 26%)]  Loss:  1.784230 (1.5228)  Time: 1.643s,  155.79/s  (1.600s,  159.98/s)  LR: 1.213e-05  Data: 0.014 (0.011)
2024-04-03 14:29:52,959 - train - INFO - Train: 144 [ 100/195 ( 52%)]  Loss:  1.700013 (1.5261)  Time: 1.520s,  168.46/s  (1.594s,  160.64/s)  LR: 1.213e-05  Data: 0.006 (0.010)
2024-04-03 14:31:12,676 - train - INFO - Train: 144 [ 150/195 ( 77%)]  Loss:  1.757036 (1.5402)  Time: 1.675s,  152.83/s  (1.594s,  160.62/s)  LR: 1.213e-05  Data: 0.016 (0.010)
2024-04-03 14:32:25,169 - train - INFO - Train: 144 [ 194/195 (100%)]  Loss:  1.812930 (1.5424)  Time: 1.685s,  151.95/s  (1.606s,  159.41/s)  LR: 1.213e-05  Data: 0.000 (0.009)
2024-04-03 14:32:25,169 - train - INFO - True
2024-04-03 14:32:25,170 - train - INFO - alphas:tensor([3.1907e-05, 9.9997e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,171 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,171 - train - INFO - True
2024-04-03 14:32:25,171 - train - INFO - alphas:tensor([0.0404, 0.9596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,171 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,172 - train - INFO - True
2024-04-03 14:32:25,172 - train - INFO - alphas:tensor([0.5735, 0.4265], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,172 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,172 - train - INFO - True
2024-04-03 14:32:25,173 - train - INFO - alphas:tensor([0.4588, 0.5412], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,173 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,173 - train - INFO - True
2024-04-03 14:32:25,174 - train - INFO - alphas:tensor([0.1237, 0.8763], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,174 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,174 - train - INFO - True
2024-04-03 14:32:25,175 - train - INFO - alphas:tensor([0.2539, 0.7461], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,175 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,175 - train - INFO - True
2024-04-03 14:32:25,175 - train - INFO - alphas:tensor([0.5577, 0.4423], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,176 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,176 - train - INFO - True
2024-04-03 14:32:25,176 - train - INFO - alphas:tensor([0.4223, 0.5777], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,176 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,177 - train - INFO - True
2024-04-03 14:32:25,177 - train - INFO - alphas:tensor([0.2428, 0.7572], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,178 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,178 - train - INFO - True
2024-04-03 14:32:25,178 - train - INFO - alphas:tensor([0.4184, 0.5816], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,178 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,178 - train - INFO - True
2024-04-03 14:32:25,179 - train - INFO - alphas:tensor([0.5681, 0.4319], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,179 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,179 - train - INFO - True
2024-04-03 14:32:25,180 - train - INFO - alphas:tensor([0.4084, 0.5916], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,180 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,180 - train - INFO - True
2024-04-03 14:32:25,181 - train - INFO - alphas:tensor([0.2614, 0.7386], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,181 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,181 - train - INFO - True
2024-04-03 14:32:25,182 - train - INFO - alphas:tensor([0.4158, 0.5842], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,182 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,182 - train - INFO - True
2024-04-03 14:32:25,182 - train - INFO - alphas:tensor([0.5010, 0.4990], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,182 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,183 - train - INFO - True
2024-04-03 14:32:25,183 - train - INFO - alphas:tensor([0.3416, 0.6584], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,183 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,183 - train - INFO - True
2024-04-03 14:32:25,184 - train - INFO - alphas:tensor([0.2258, 0.7742], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,184 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,184 - train - INFO - True
2024-04-03 14:32:25,185 - train - INFO - alphas:tensor([0.3105, 0.6895], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,185 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,185 - train - INFO - True
2024-04-03 14:32:25,186 - train - INFO - alphas:tensor([0.3836, 0.6164], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,186 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,186 - train - INFO - True
2024-04-03 14:32:25,186 - train - INFO - alphas:tensor([0.1987, 0.8013], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,187 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,187 - train - INFO - True
2024-04-03 14:32:25,187 - train - INFO - alphas:tensor([0.1656, 0.8344], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,187 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,188 - train - INFO - True
2024-04-03 14:32:25,188 - train - INFO - alphas:tensor([0.2227, 0.7773], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,188 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,188 - train - INFO - True
2024-04-03 14:32:25,189 - train - INFO - alphas:tensor([0.3338, 0.6662], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,189 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,189 - train - INFO - True
2024-04-03 14:32:25,190 - train - INFO - alphas:tensor([0.0879, 0.9121], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,190 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,190 - train - INFO - True
2024-04-03 14:32:25,191 - train - INFO - alphas:tensor([0.1015, 0.8985], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,191 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,191 - train - INFO - True
2024-04-03 14:32:25,191 - train - INFO - alphas:tensor([0.0016, 0.9984], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,192 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,192 - train - INFO - True
2024-04-03 14:32:25,192 - train - INFO - alphas:tensor([0.0040, 0.9960], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,192 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,192 - train - INFO - True
2024-04-03 14:32:25,193 - train - INFO - alphas:tensor([5.8510e-08, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,193 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,193 - train - INFO - True
2024-04-03 14:32:25,194 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:32:25,194 - train - INFO - tau:0.23999247958413436
2024-04-03 14:32:25,194 - train - INFO - avg block size:13.413793103448276
2024-04-03 14:32:26,123 - train - INFO - Test: [   0/39]  Time: 0.927 (0.927)  Loss:  0.3491 (0.3491)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 14:33:01,273 - train - INFO - Test: [  39/39]  Time: 0.917 (0.902)  Loss:  0.3838 (0.3529)  Acc@1: 87.5000 (92.6200)  Acc@5: 100.0000 (99.7700)
2024-04-03 14:33:03,189 - train - INFO - Train: 145 [   0/195 (  0%)]  Loss:  1.269140 (1.2691)  Time: 1.711s,  149.59/s  (1.711s,  149.59/s)  LR: 1.148e-05  Data: 0.189 (0.189)
2024-04-03 14:34:23,565 - train - INFO - Train: 145 [  50/195 ( 26%)]  Loss:  1.708681 (1.5950)  Time: 1.611s,  158.90/s  (1.610s,  159.05/s)  LR: 1.148e-05  Data: 0.008 (0.012)
2024-04-03 14:35:44,074 - train - INFO - Train: 145 [ 100/195 ( 52%)]  Loss:  1.183246 (1.5696)  Time: 1.554s,  164.73/s  (1.610s,  159.02/s)  LR: 1.148e-05  Data: 0.006 (0.009)
2024-04-03 14:37:05,314 - train - INFO - Train: 145 [ 150/195 ( 77%)]  Loss:  1.173474 (1.5490)  Time: 1.592s,  160.79/s  (1.615s,  158.53/s)  LR: 1.148e-05  Data: 0.005 (0.009)
2024-04-03 14:38:15,999 - train - INFO - Train: 145 [ 194/195 (100%)]  Loss:  1.185672 (1.5467)  Time: 1.580s,  161.98/s  (1.613s,  158.72/s)  LR: 1.148e-05  Data: 0.000 (0.009)
2024-04-03 14:38:15,999 - train - INFO - True
2024-04-03 14:38:16,001 - train - INFO - alphas:tensor([2.8664e-05, 9.9997e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,001 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,001 - train - INFO - True
2024-04-03 14:38:16,002 - train - INFO - alphas:tensor([0.0394, 0.9606], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,002 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,002 - train - INFO - True
2024-04-03 14:38:16,003 - train - INFO - alphas:tensor([0.5738, 0.4262], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,003 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,003 - train - INFO - True
2024-04-03 14:38:16,003 - train - INFO - alphas:tensor([0.4583, 0.5417], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,004 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,004 - train - INFO - True
2024-04-03 14:38:16,004 - train - INFO - alphas:tensor([0.1227, 0.8773], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,004 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,004 - train - INFO - True
2024-04-03 14:38:16,005 - train - INFO - alphas:tensor([0.2535, 0.7465], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,005 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,005 - train - INFO - True
2024-04-03 14:38:16,006 - train - INFO - alphas:tensor([0.5577, 0.4423], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,006 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,006 - train - INFO - True
2024-04-03 14:38:16,007 - train - INFO - alphas:tensor([0.4214, 0.5786], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,007 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,007 - train - INFO - True
2024-04-03 14:38:16,008 - train - INFO - alphas:tensor([0.2421, 0.7579], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,008 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,008 - train - INFO - True
2024-04-03 14:38:16,008 - train - INFO - alphas:tensor([0.4187, 0.5813], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,008 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,009 - train - INFO - True
2024-04-03 14:38:16,009 - train - INFO - alphas:tensor([0.5686, 0.4314], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,009 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,009 - train - INFO - True
2024-04-03 14:38:16,010 - train - INFO - alphas:tensor([0.4083, 0.5917], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,010 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,010 - train - INFO - True
2024-04-03 14:38:16,011 - train - INFO - alphas:tensor([0.2608, 0.7392], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,011 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,011 - train - INFO - True
2024-04-03 14:38:16,012 - train - INFO - alphas:tensor([0.4160, 0.5840], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,012 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,012 - train - INFO - True
2024-04-03 14:38:16,012 - train - INFO - alphas:tensor([0.5012, 0.4988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,013 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,013 - train - INFO - True
2024-04-03 14:38:16,013 - train - INFO - alphas:tensor([0.3414, 0.6586], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,013 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,013 - train - INFO - True
2024-04-03 14:38:16,014 - train - INFO - alphas:tensor([0.2249, 0.7751], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,014 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,014 - train - INFO - True
2024-04-03 14:38:16,015 - train - INFO - alphas:tensor([0.3099, 0.6901], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,015 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,015 - train - INFO - True
2024-04-03 14:38:16,016 - train - INFO - alphas:tensor([0.3833, 0.6167], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,016 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,016 - train - INFO - True
2024-04-03 14:38:16,016 - train - INFO - alphas:tensor([0.1977, 0.8023], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,017 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,017 - train - INFO - True
2024-04-03 14:38:16,018 - train - INFO - alphas:tensor([0.1647, 0.8353], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,018 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,018 - train - INFO - True
2024-04-03 14:38:16,019 - train - INFO - alphas:tensor([0.2220, 0.7780], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,019 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,019 - train - INFO - True
2024-04-03 14:38:16,020 - train - INFO - alphas:tensor([0.3335, 0.6665], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,020 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,020 - train - INFO - True
2024-04-03 14:38:16,021 - train - INFO - alphas:tensor([0.0866, 0.9134], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,021 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,021 - train - INFO - True
2024-04-03 14:38:16,022 - train - INFO - alphas:tensor([0.1004, 0.8996], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,022 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,022 - train - INFO - True
2024-04-03 14:38:16,023 - train - INFO - alphas:tensor([0.0015, 0.9985], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,023 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,023 - train - INFO - True
2024-04-03 14:38:16,023 - train - INFO - alphas:tensor([0.0038, 0.9962], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,024 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,024 - train - INFO - True
2024-04-03 14:38:16,024 - train - INFO - alphas:tensor([4.9429e-08, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,024 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,024 - train - INFO - True
2024-04-03 14:38:16,025 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:38:16,025 - train - INFO - tau:0.23759255478829303
2024-04-03 14:38:16,025 - train - INFO - avg block size:13.413793103448276
2024-04-03 14:38:16,989 - train - INFO - Test: [   0/39]  Time: 0.961 (0.961)  Loss:  0.3506 (0.3506)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 14:38:52,035 - train - INFO - Test: [  39/39]  Time: 0.962 (0.900)  Loss:  0.3977 (0.3521)  Acc@1: 87.5000 (92.6900)  Acc@5: 100.0000 (99.7700)
2024-04-03 14:38:54,059 - train - INFO - Train: 146 [   0/195 (  0%)]  Loss:  1.487118 (1.4871)  Time: 1.851s,  138.32/s  (1.851s,  138.32/s)  LR: 1.095e-05  Data: 0.179 (0.179)
2024-04-03 14:40:14,575 - train - INFO - Train: 146 [  50/195 ( 26%)]  Loss:  1.659163 (1.5236)  Time: 1.631s,  156.92/s  (1.615s,  158.51/s)  LR: 1.095e-05  Data: 0.006 (0.011)
2024-04-03 14:41:35,705 - train - INFO - Train: 146 [ 100/195 ( 52%)]  Loss:  1.630133 (1.4846)  Time: 1.623s,  157.73/s  (1.619s,  158.15/s)  LR: 1.095e-05  Data: 0.013 (0.010)
2024-04-03 14:42:56,930 - train - INFO - Train: 146 [ 150/195 ( 77%)]  Loss:  1.715707 (1.5052)  Time: 1.585s,  161.50/s  (1.621s,  157.96/s)  LR: 1.095e-05  Data: 0.006 (0.009)
2024-04-03 14:44:13,089 - train - INFO - Train: 146 [ 194/195 (100%)]  Loss:  1.575788 (1.5162)  Time: 1.581s,  161.96/s  (1.646s,  155.57/s)  LR: 1.095e-05  Data: 0.000 (0.009)
2024-04-03 14:44:13,090 - train - INFO - True
2024-04-03 14:44:13,091 - train - INFO - alphas:tensor([2.5714e-05, 9.9997e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,091 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,091 - train - INFO - True
2024-04-03 14:44:13,092 - train - INFO - alphas:tensor([0.0384, 0.9616], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,092 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,092 - train - INFO - True
2024-04-03 14:44:13,093 - train - INFO - alphas:tensor([0.5741, 0.4259], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,093 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,093 - train - INFO - True
2024-04-03 14:44:13,094 - train - INFO - alphas:tensor([0.4578, 0.5422], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,094 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,094 - train - INFO - True
2024-04-03 14:44:13,094 - train - INFO - alphas:tensor([0.1216, 0.8784], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,099 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,100 - train - INFO - True
2024-04-03 14:44:13,109 - train - INFO - alphas:tensor([0.2527, 0.7473], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,110 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,110 - train - INFO - True
2024-04-03 14:44:13,110 - train - INFO - alphas:tensor([0.5580, 0.4420], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,110 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,110 - train - INFO - True
2024-04-03 14:44:13,111 - train - INFO - alphas:tensor([0.4212, 0.5788], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,111 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,111 - train - INFO - True
2024-04-03 14:44:13,112 - train - INFO - alphas:tensor([0.2417, 0.7583], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,112 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,112 - train - INFO - True
2024-04-03 14:44:13,113 - train - INFO - alphas:tensor([0.4195, 0.5805], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,113 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,113 - train - INFO - True
2024-04-03 14:44:13,118 - train - INFO - alphas:tensor([0.5690, 0.4310], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,118 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,118 - train - INFO - True
2024-04-03 14:44:13,119 - train - INFO - alphas:tensor([0.4077, 0.5923], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,119 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,119 - train - INFO - True
2024-04-03 14:44:13,120 - train - INFO - alphas:tensor([0.2602, 0.7398], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,120 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,120 - train - INFO - True
2024-04-03 14:44:13,120 - train - INFO - alphas:tensor([0.4164, 0.5836], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,121 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,121 - train - INFO - True
2024-04-03 14:44:13,121 - train - INFO - alphas:tensor([0.5015, 0.4985], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,121 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,121 - train - INFO - True
2024-04-03 14:44:13,122 - train - INFO - alphas:tensor([0.3411, 0.6589], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,122 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,122 - train - INFO - True
2024-04-03 14:44:13,123 - train - INFO - alphas:tensor([0.2242, 0.7758], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,123 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,123 - train - INFO - True
2024-04-03 14:44:13,124 - train - INFO - alphas:tensor([0.3096, 0.6904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,124 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,124 - train - INFO - True
2024-04-03 14:44:13,125 - train - INFO - alphas:tensor([0.3830, 0.6170], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,125 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,125 - train - INFO - True
2024-04-03 14:44:13,125 - train - INFO - alphas:tensor([0.1970, 0.8030], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,125 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,126 - train - INFO - True
2024-04-03 14:44:13,126 - train - INFO - alphas:tensor([0.1639, 0.8361], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,126 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,126 - train - INFO - True
2024-04-03 14:44:13,127 - train - INFO - alphas:tensor([0.2214, 0.7786], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,127 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,127 - train - INFO - True
2024-04-03 14:44:13,128 - train - INFO - alphas:tensor([0.3333, 0.6667], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,132 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,132 - train - INFO - True
2024-04-03 14:44:13,133 - train - INFO - alphas:tensor([0.0856, 0.9144], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,133 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,133 - train - INFO - True
2024-04-03 14:44:13,134 - train - INFO - alphas:tensor([0.0995, 0.9005], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,134 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,134 - train - INFO - True
2024-04-03 14:44:13,135 - train - INFO - alphas:tensor([0.0014, 0.9986], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,135 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,135 - train - INFO - True
2024-04-03 14:44:13,135 - train - INFO - alphas:tensor([0.0036, 0.9964], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,136 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,136 - train - INFO - True
2024-04-03 14:44:13,136 - train - INFO - alphas:tensor([4.1688e-08, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,137 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,137 - train - INFO - True
2024-04-03 14:44:13,137 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:44:13,137 - train - INFO - tau:0.2352166292404101
2024-04-03 14:44:13,137 - train - INFO - avg block size:13.413793103448276
2024-04-03 14:44:14,038 - train - INFO - Test: [   0/39]  Time: 0.896 (0.896)  Loss:  0.3516 (0.3516)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 14:44:49,377 - train - INFO - Test: [  39/39]  Time: 0.884 (0.906)  Loss:  0.3870 (0.3537)  Acc@1: 87.5000 (92.7000)  Acc@5: 100.0000 (99.7800)
2024-04-03 14:44:51,293 - train - INFO - Train: 147 [   0/195 (  0%)]  Loss:  1.303990 (1.3040)  Time: 1.785s,  143.41/s  (1.785s,  143.41/s)  LR: 1.053e-05  Data: 0.203 (0.203)
2024-04-03 14:46:14,794 - train - INFO - Train: 147 [  50/195 ( 26%)]  Loss:  1.193003 (1.5166)  Time: 1.610s,  159.04/s  (1.672s,  153.09/s)  LR: 1.053e-05  Data: 0.005 (0.011)
2024-04-03 14:47:36,822 - train - INFO - Train: 147 [ 100/195 ( 52%)]  Loss:  1.773388 (1.5328)  Time: 1.929s,  132.72/s  (1.657s,  154.54/s)  LR: 1.053e-05  Data: 0.005 (0.010)
2024-04-03 14:49:01,473 - train - INFO - Train: 147 [ 150/195 ( 77%)]  Loss:  1.222693 (1.5213)  Time: 1.582s,  161.82/s  (1.669s,  153.42/s)  LR: 1.053e-05  Data: 0.005 (0.009)
2024-04-03 14:50:14,853 - train - INFO - Train: 147 [ 194/195 (100%)]  Loss:  1.688403 (1.5361)  Time: 1.610s,  158.96/s  (1.668s,  153.44/s)  LR: 1.053e-05  Data: 0.000 (0.009)
2024-04-03 14:50:14,854 - train - INFO - True
2024-04-03 14:50:14,855 - train - INFO - alphas:tensor([2.3044e-05, 9.9998e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,856 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,856 - train - INFO - True
2024-04-03 14:50:14,856 - train - INFO - alphas:tensor([0.0375, 0.9625], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,857 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,857 - train - INFO - True
2024-04-03 14:50:14,857 - train - INFO - alphas:tensor([0.5745, 0.4255], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,857 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,857 - train - INFO - True
2024-04-03 14:50:14,858 - train - INFO - alphas:tensor([0.4571, 0.5429], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,858 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,858 - train - INFO - True
2024-04-03 14:50:14,859 - train - INFO - alphas:tensor([0.1206, 0.8794], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,859 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,859 - train - INFO - True
2024-04-03 14:50:14,860 - train - INFO - alphas:tensor([0.2523, 0.7477], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,860 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,860 - train - INFO - True
2024-04-03 14:50:14,861 - train - INFO - alphas:tensor([0.5584, 0.4416], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,861 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,861 - train - INFO - True
2024-04-03 14:50:14,861 - train - INFO - alphas:tensor([0.4206, 0.5794], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,861 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,862 - train - INFO - True
2024-04-03 14:50:14,862 - train - INFO - alphas:tensor([0.2409, 0.7591], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,862 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,862 - train - INFO - True
2024-04-03 14:50:14,863 - train - INFO - alphas:tensor([0.4198, 0.5802], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,863 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,863 - train - INFO - True
2024-04-03 14:50:14,864 - train - INFO - alphas:tensor([0.5691, 0.4309], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,864 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,864 - train - INFO - True
2024-04-03 14:50:14,865 - train - INFO - alphas:tensor([0.4070, 0.5930], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,865 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,865 - train - INFO - True
2024-04-03 14:50:14,865 - train - INFO - alphas:tensor([0.2594, 0.7406], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,866 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,866 - train - INFO - True
2024-04-03 14:50:14,866 - train - INFO - alphas:tensor([0.4164, 0.5836], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,866 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,866 - train - INFO - True
2024-04-03 14:50:14,867 - train - INFO - alphas:tensor([0.5013, 0.4987], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,867 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,867 - train - INFO - True
2024-04-03 14:50:14,868 - train - INFO - alphas:tensor([0.3406, 0.6594], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,868 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,869 - train - INFO - True
2024-04-03 14:50:14,869 - train - INFO - alphas:tensor([0.2235, 0.7765], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,869 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,869 - train - INFO - True
2024-04-03 14:50:14,870 - train - INFO - alphas:tensor([0.3096, 0.6904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,870 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,870 - train - INFO - True
2024-04-03 14:50:14,871 - train - INFO - alphas:tensor([0.3829, 0.6171], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,871 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,871 - train - INFO - True
2024-04-03 14:50:14,872 - train - INFO - alphas:tensor([0.1961, 0.8039], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,872 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,872 - train - INFO - True
2024-04-03 14:50:14,872 - train - INFO - alphas:tensor([0.1630, 0.8370], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,873 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,873 - train - INFO - True
2024-04-03 14:50:14,873 - train - INFO - alphas:tensor([0.2208, 0.7792], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,873 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,873 - train - INFO - True
2024-04-03 14:50:14,874 - train - INFO - alphas:tensor([0.3333, 0.6667], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,874 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,874 - train - INFO - True
2024-04-03 14:50:14,875 - train - INFO - alphas:tensor([0.0846, 0.9154], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,875 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,875 - train - INFO - True
2024-04-03 14:50:14,876 - train - INFO - alphas:tensor([0.0987, 0.9013], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,876 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,876 - train - INFO - True
2024-04-03 14:50:14,876 - train - INFO - alphas:tensor([0.0013, 0.9987], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,877 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,877 - train - INFO - True
2024-04-03 14:50:14,877 - train - INFO - alphas:tensor([0.0034, 0.9966], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,877 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,877 - train - INFO - True
2024-04-03 14:50:14,878 - train - INFO - alphas:tensor([3.5099e-08, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,878 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,878 - train - INFO - True
2024-04-03 14:50:14,879 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:50:14,879 - train - INFO - tau:0.232864462948006
2024-04-03 14:50:14,879 - train - INFO - avg block size:13.413793103448276
2024-04-03 14:50:15,816 - train - INFO - Test: [   0/39]  Time: 0.933 (0.933)  Loss:  0.3525 (0.3525)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 14:50:54,707 - train - INFO - Test: [  39/39]  Time: 0.951 (0.996)  Loss:  0.3909 (0.3542)  Acc@1: 87.5000 (92.5900)  Acc@5: 100.0000 (99.7900)
2024-04-03 14:50:56,575 - train - INFO - Train: 148 [   0/195 (  0%)]  Loss:  1.150829 (1.1508)  Time: 1.734s,  147.64/s  (1.734s,  147.64/s)  LR: 1.024e-05  Data: 0.153 (0.153)
2024-04-03 14:52:21,908 - train - INFO - Train: 148 [  50/195 ( 26%)]  Loss:  1.220791 (1.4867)  Time: 1.871s,  136.81/s  (1.707s,  149.96/s)  LR: 1.024e-05  Data: 0.025 (0.012)
2024-04-03 14:53:44,740 - train - INFO - Train: 148 [ 100/195 ( 52%)]  Loss:  1.668715 (1.4995)  Time: 1.796s,  142.50/s  (1.682s,  152.19/s)  LR: 1.024e-05  Data: 0.005 (0.010)
2024-04-03 14:55:09,805 - train - INFO - Train: 148 [ 150/195 ( 77%)]  Loss:  1.581192 (1.5141)  Time: 1.610s,  159.05/s  (1.688s,  151.62/s)  LR: 1.024e-05  Data: 0.005 (0.009)
2024-04-03 14:56:26,547 - train - INFO - Train: 148 [ 194/195 (100%)]  Loss:  1.657207 (1.5150)  Time: 1.608s,  159.24/s  (1.701s,  150.50/s)  LR: 1.024e-05  Data: 0.000 (0.009)
2024-04-03 14:56:26,548 - train - INFO - True
2024-04-03 14:56:26,549 - train - INFO - alphas:tensor([2.0641e-05, 9.9998e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,549 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,549 - train - INFO - True
2024-04-03 14:56:26,550 - train - INFO - alphas:tensor([0.0366, 0.9634], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,550 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,550 - train - INFO - True
2024-04-03 14:56:26,551 - train - INFO - alphas:tensor([0.5752, 0.4248], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,551 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,551 - train - INFO - True
2024-04-03 14:56:26,551 - train - INFO - alphas:tensor([0.4569, 0.5431], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,552 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,552 - train - INFO - True
2024-04-03 14:56:26,553 - train - INFO - alphas:tensor([0.1195, 0.8805], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,553 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,553 - train - INFO - True
2024-04-03 14:56:26,553 - train - INFO - alphas:tensor([0.2519, 0.7481], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,553 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,554 - train - INFO - True
2024-04-03 14:56:26,554 - train - INFO - alphas:tensor([0.5589, 0.4411], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,554 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,554 - train - INFO - True
2024-04-03 14:56:26,555 - train - INFO - alphas:tensor([0.4204, 0.5796], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,555 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,555 - train - INFO - True
2024-04-03 14:56:26,556 - train - INFO - alphas:tensor([0.2403, 0.7597], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,556 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,556 - train - INFO - True
2024-04-03 14:56:26,557 - train - INFO - alphas:tensor([0.4203, 0.5797], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,557 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,557 - train - INFO - True
2024-04-03 14:56:26,558 - train - INFO - alphas:tensor([0.5698, 0.4302], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,558 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,558 - train - INFO - True
2024-04-03 14:56:26,558 - train - INFO - alphas:tensor([0.4069, 0.5931], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,558 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,559 - train - INFO - True
2024-04-03 14:56:26,559 - train - INFO - alphas:tensor([0.2589, 0.7411], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,559 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,559 - train - INFO - True
2024-04-03 14:56:26,560 - train - INFO - alphas:tensor([0.4169, 0.5831], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,560 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,560 - train - INFO - True
2024-04-03 14:56:26,561 - train - INFO - alphas:tensor([0.5019, 0.4981], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,561 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,561 - train - INFO - True
2024-04-03 14:56:26,562 - train - INFO - alphas:tensor([0.3404, 0.6596], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,562 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,562 - train - INFO - True
2024-04-03 14:56:26,563 - train - INFO - alphas:tensor([0.2229, 0.7771], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,563 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,563 - train - INFO - True
2024-04-03 14:56:26,563 - train - INFO - alphas:tensor([0.3097, 0.6903], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,563 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,564 - train - INFO - True
2024-04-03 14:56:26,564 - train - INFO - alphas:tensor([0.3830, 0.6170], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,564 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,564 - train - INFO - True
2024-04-03 14:56:26,565 - train - INFO - alphas:tensor([0.1954, 0.8046], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,565 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,565 - train - INFO - True
2024-04-03 14:56:26,566 - train - INFO - alphas:tensor([0.1622, 0.8378], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,566 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,566 - train - INFO - True
2024-04-03 14:56:26,567 - train - INFO - alphas:tensor([0.2204, 0.7796], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,567 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,567 - train - INFO - True
2024-04-03 14:56:26,567 - train - INFO - alphas:tensor([0.3331, 0.6669], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,568 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,568 - train - INFO - True
2024-04-03 14:56:26,568 - train - INFO - alphas:tensor([0.0835, 0.9165], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,568 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,568 - train - INFO - True
2024-04-03 14:56:26,569 - train - INFO - alphas:tensor([0.0977, 0.9023], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,569 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,569 - train - INFO - True
2024-04-03 14:56:26,570 - train - INFO - alphas:tensor([0.0012, 0.9988], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,570 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,570 - train - INFO - True
2024-04-03 14:56:26,571 - train - INFO - alphas:tensor([0.0032, 0.9968], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,571 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,572 - train - INFO - True
2024-04-03 14:56:26,572 - train - INFO - alphas:tensor([2.9500e-08, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,572 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,572 - train - INFO - True
2024-04-03 14:56:26,573 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 14:56:26,573 - train - INFO - tau:0.23053581831852593
2024-04-03 14:56:26,573 - train - INFO - avg block size:13.413793103448276
2024-04-03 14:56:27,550 - train - INFO - Test: [   0/39]  Time: 0.974 (0.974)  Loss:  0.3486 (0.3486)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-03 14:57:03,862 - train - INFO - Test: [  39/39]  Time: 0.943 (0.932)  Loss:  0.3750 (0.3523)  Acc@1: 87.5000 (92.7000)  Acc@5: 100.0000 (99.7900)
2024-04-03 14:57:05,979 - train - INFO - Train: 149 [   0/195 (  0%)]  Loss:  1.319362 (1.3194)  Time: 1.988s,  128.75/s  (1.988s,  128.75/s)  LR: 1.006e-05  Data: 0.242 (0.242)
2024-04-03 14:58:26,965 - train - INFO - Train: 149 [  50/195 ( 26%)]  Loss:  1.229298 (1.4924)  Time: 1.564s,  163.67/s  (1.627s,  157.35/s)  LR: 1.006e-05  Data: 0.005 (0.012)
2024-04-03 14:59:47,712 - train - INFO - Train: 149 [ 100/195 ( 52%)]  Loss:  1.745152 (1.5237)  Time: 1.679s,  152.47/s  (1.621s,  157.93/s)  LR: 1.006e-05  Data: 0.032 (0.010)
2024-04-03 15:01:08,232 - train - INFO - Train: 149 [ 150/195 ( 77%)]  Loss:  1.715899 (1.5418)  Time: 1.679s,  152.44/s  (1.617s,  158.27/s)  LR: 1.006e-05  Data: 0.021 (0.009)
2024-04-03 15:02:19,610 - train - INFO - Train: 149 [ 194/195 (100%)]  Loss:  1.505808 (1.5248)  Time: 1.550s,  165.21/s  (1.619s,  158.17/s)  LR: 1.006e-05  Data: 0.000 (0.009)
2024-04-03 15:02:19,611 - train - INFO - True
2024-04-03 15:02:19,612 - train - INFO - alphas:tensor([1.8464e-05, 9.9998e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,612 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,612 - train - INFO - True
2024-04-03 15:02:19,613 - train - INFO - alphas:tensor([0.0357, 0.9643], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,613 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,613 - train - INFO - True
2024-04-03 15:02:19,614 - train - INFO - alphas:tensor([0.5760, 0.4240], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,614 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,614 - train - INFO - True
2024-04-03 15:02:19,614 - train - INFO - alphas:tensor([0.4566, 0.5434], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,615 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,615 - train - INFO - True
2024-04-03 15:02:19,615 - train - INFO - alphas:tensor([0.1187, 0.8813], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,616 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,616 - train - INFO - True
2024-04-03 15:02:19,616 - train - INFO - alphas:tensor([0.2517, 0.7483], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,617 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,617 - train - INFO - True
2024-04-03 15:02:19,617 - train - INFO - alphas:tensor([0.5592, 0.4408], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,617 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,617 - train - INFO - True
2024-04-03 15:02:19,618 - train - INFO - alphas:tensor([0.4201, 0.5799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,618 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,618 - train - INFO - True
2024-04-03 15:02:19,619 - train - INFO - alphas:tensor([0.2398, 0.7602], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,619 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,619 - train - INFO - True
2024-04-03 15:02:19,620 - train - INFO - alphas:tensor([0.4211, 0.5789], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,620 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,620 - train - INFO - True
2024-04-03 15:02:19,621 - train - INFO - alphas:tensor([0.5705, 0.4295], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,621 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,621 - train - INFO - True
2024-04-03 15:02:19,621 - train - INFO - alphas:tensor([0.4065, 0.5935], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,622 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,622 - train - INFO - True
2024-04-03 15:02:19,622 - train - INFO - alphas:tensor([0.2583, 0.7417], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,622 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,622 - train - INFO - True
2024-04-03 15:02:19,623 - train - INFO - alphas:tensor([0.4172, 0.5828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,623 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,623 - train - INFO - True
2024-04-03 15:02:19,624 - train - INFO - alphas:tensor([0.5022, 0.4978], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,624 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,624 - train - INFO - True
2024-04-03 15:02:19,625 - train - INFO - alphas:tensor([0.3401, 0.6599], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,625 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,625 - train - INFO - True
2024-04-03 15:02:19,626 - train - INFO - alphas:tensor([0.2224, 0.7776], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,626 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,626 - train - INFO - True
2024-04-03 15:02:19,626 - train - INFO - alphas:tensor([0.3097, 0.6903], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,626 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,626 - train - INFO - True
2024-04-03 15:02:19,627 - train - INFO - alphas:tensor([0.3826, 0.6174], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,627 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,627 - train - INFO - True
2024-04-03 15:02:19,628 - train - INFO - alphas:tensor([0.1944, 0.8056], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,628 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,628 - train - INFO - True
2024-04-03 15:02:19,629 - train - INFO - alphas:tensor([0.1614, 0.8386], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,629 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,629 - train - INFO - True
2024-04-03 15:02:19,630 - train - INFO - alphas:tensor([0.2200, 0.7800], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,630 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,630 - train - INFO - True
2024-04-03 15:02:19,630 - train - INFO - alphas:tensor([0.3329, 0.6671], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,630 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,631 - train - INFO - True
2024-04-03 15:02:19,631 - train - INFO - alphas:tensor([0.0825, 0.9175], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,631 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,631 - train - INFO - True
2024-04-03 15:02:19,632 - train - INFO - alphas:tensor([0.0966, 0.9034], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,632 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,632 - train - INFO - True
2024-04-03 15:02:19,633 - train - INFO - alphas:tensor([0.0011, 0.9989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,633 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,633 - train - INFO - True
2024-04-03 15:02:19,634 - train - INFO - alphas:tensor([0.0030, 0.9970], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,634 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,634 - train - INFO - True
2024-04-03 15:02:19,634 - train - INFO - alphas:tensor([2.4751e-08, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,634 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,634 - train - INFO - True
2024-04-03 15:02:19,635 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:02:19,635 - train - INFO - tau:0.22823046013534068
2024-04-03 15:02:19,635 - train - INFO - avg block size:13.413793103448276
2024-04-03 15:02:20,530 - train - INFO - Test: [   0/39]  Time: 0.891 (0.891)  Loss:  0.3455 (0.3455)  Acc@1: 94.1406 (94.1406)  Acc@5: 100.0000 (100.0000)
2024-04-03 15:02:56,402 - train - INFO - Test: [  39/39]  Time: 0.910 (0.919)  Loss:  0.3708 (0.3508)  Acc@1: 87.5000 (92.6600)  Acc@5: 100.0000 (99.7800)
2024-04-03 15:02:58,306 - train - INFO - Train: 150 [   0/195 (  0%)]  Loss:  1.729000 (1.7290)  Time: 1.821s,  140.56/s  (1.821s,  140.56/s)  LR: 1.000e-05  Data: 0.140 (0.140)
2024-04-03 15:04:19,670 - train - INFO - Train: 150 [  50/195 ( 26%)]  Loss:  1.652655 (1.5632)  Time: 1.802s,  142.06/s  (1.631s,  156.95/s)  LR: 1.000e-05  Data: 0.005 (0.009)
2024-04-03 15:05:41,957 - train - INFO - Train: 150 [ 100/195 ( 52%)]  Loss:  1.178741 (1.5277)  Time: 1.550s,  165.17/s  (1.638s,  156.26/s)  LR: 1.000e-05  Data: 0.010 (0.009)
2024-04-03 15:07:02,783 - train - INFO - Train: 150 [ 150/195 ( 77%)]  Loss:  1.806279 (1.5285)  Time: 1.536s,  166.65/s  (1.631s,  156.95/s)  LR: 1.000e-05  Data: 0.005 (0.008)
2024-04-03 15:08:14,171 - train - INFO - Train: 150 [ 194/195 (100%)]  Loss:  1.352743 (1.5201)  Time: 1.681s,  152.34/s  (1.629s,  157.14/s)  LR: 1.000e-05  Data: 0.000 (0.008)
2024-04-03 15:08:14,172 - train - INFO - True
2024-04-03 15:08:14,173 - train - INFO - alphas:tensor([1.6490e-05, 9.9998e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,173 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,173 - train - INFO - True
2024-04-03 15:08:14,174 - train - INFO - alphas:tensor([0.0348, 0.9652], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,174 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,174 - train - INFO - True
2024-04-03 15:08:14,175 - train - INFO - alphas:tensor([0.5759, 0.4241], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,180 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,180 - train - INFO - True
2024-04-03 15:08:14,180 - train - INFO - alphas:tensor([0.4557, 0.5443], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,180 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,180 - train - INFO - True
2024-04-03 15:08:14,181 - train - INFO - alphas:tensor([0.1178, 0.8822], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,181 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,181 - train - INFO - True
2024-04-03 15:08:14,182 - train - INFO - alphas:tensor([0.2514, 0.7486], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,182 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,182 - train - INFO - True
2024-04-03 15:08:14,183 - train - INFO - alphas:tensor([0.5595, 0.4405], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,183 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,183 - train - INFO - True
2024-04-03 15:08:14,184 - train - INFO - alphas:tensor([0.4196, 0.5804], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,184 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,184 - train - INFO - True
2024-04-03 15:08:14,184 - train - INFO - alphas:tensor([0.2395, 0.7605], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,184 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,185 - train - INFO - True
2024-04-03 15:08:14,185 - train - INFO - alphas:tensor([0.4219, 0.5781], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,185 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,185 - train - INFO - True
2024-04-03 15:08:14,186 - train - INFO - alphas:tensor([0.5709, 0.4291], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,186 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,186 - train - INFO - True
2024-04-03 15:08:14,187 - train - INFO - alphas:tensor([0.4060, 0.5940], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,187 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,187 - train - INFO - True
2024-04-03 15:08:14,188 - train - INFO - alphas:tensor([0.2580, 0.7420], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,192 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,192 - train - INFO - True
2024-04-03 15:08:14,193 - train - INFO - alphas:tensor([0.4181, 0.5819], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,193 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,193 - train - INFO - True
2024-04-03 15:08:14,194 - train - INFO - alphas:tensor([0.5023, 0.4977], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,194 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,194 - train - INFO - True
2024-04-03 15:08:14,195 - train - INFO - alphas:tensor([0.3398, 0.6602], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,195 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,195 - train - INFO - True
2024-04-03 15:08:14,195 - train - INFO - alphas:tensor([0.2216, 0.7784], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,195 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,195 - train - INFO - True
2024-04-03 15:08:14,196 - train - INFO - alphas:tensor([0.3096, 0.6904], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,201 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,201 - train - INFO - True
2024-04-03 15:08:14,201 - train - INFO - alphas:tensor([0.3826, 0.6174], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,201 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,202 - train - INFO - True
2024-04-03 15:08:14,202 - train - INFO - alphas:tensor([0.1936, 0.8064], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,202 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,202 - train - INFO - True
2024-04-03 15:08:14,203 - train - INFO - alphas:tensor([0.1607, 0.8393], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,203 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,203 - train - INFO - True
2024-04-03 15:08:14,204 - train - INFO - alphas:tensor([0.2195, 0.7805], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,204 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,204 - train - INFO - True
2024-04-03 15:08:14,205 - train - INFO - alphas:tensor([0.3330, 0.6670], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,205 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,205 - train - INFO - True
2024-04-03 15:08:14,205 - train - INFO - alphas:tensor([0.0815, 0.9185], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,210 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,210 - train - INFO - True
2024-04-03 15:08:14,211 - train - INFO - alphas:tensor([0.0956, 0.9044], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,211 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,211 - train - INFO - True
2024-04-03 15:08:14,212 - train - INFO - alphas:tensor([0.0011, 0.9989], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,212 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,212 - train - INFO - True
2024-04-03 15:08:14,212 - train - INFO - alphas:tensor([0.0029, 0.9971], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,212 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,213 - train - INFO - True
2024-04-03 15:08:14,213 - train - INFO - alphas:tensor([2.0731e-08, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,213 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,213 - train - INFO - True
2024-04-03 15:08:14,214 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:08:14,214 - train - INFO - tau:0.22594815553398728
2024-04-03 15:08:14,214 - train - INFO - avg block size:13.413793103448276
2024-04-03 15:08:15,210 - train - INFO - Test: [   0/39]  Time: 0.994 (0.994)  Loss:  0.3474 (0.3474)  Acc@1: 94.1406 (94.1406)  Acc@5: 100.0000 (100.0000)
2024-04-03 15:08:51,295 - train - INFO - Test: [  39/39]  Time: 0.898 (0.927)  Loss:  0.3618 (0.3546)  Acc@1: 87.5000 (92.6400)  Acc@5: 100.0000 (99.7800)
2024-04-03 15:08:53,168 - train - INFO - Train: 151 [   0/195 (  0%)]  Loss:  1.304284 (1.3043)  Time: 1.794s,  142.73/s  (1.794s,  142.73/s)  LR: 1.000e-05  Data: 0.249 (0.249)
2024-04-03 15:10:14,424 - train - INFO - Train: 151 [  50/195 ( 26%)]  Loss:  1.272398 (1.5064)  Time: 1.623s,  157.77/s  (1.628s,  157.21/s)  LR: 1.000e-05  Data: 0.008 (0.013)
2024-04-03 15:11:35,934 - train - INFO - Train: 151 [ 100/195 ( 52%)]  Loss:  1.264972 (1.5130)  Time: 1.707s,  149.93/s  (1.629s,  157.12/s)  LR: 1.000e-05  Data: 0.015 (0.010)
2024-04-03 15:12:58,090 - train - INFO - Train: 151 [ 150/195 ( 77%)]  Loss:  1.217895 (1.5080)  Time: 1.580s,  162.06/s  (1.634s,  156.68/s)  LR: 1.000e-05  Data: 0.006 (0.010)
2024-04-03 15:14:08,804 - train - INFO - Train: 151 [ 194/195 (100%)]  Loss:  1.740037 (1.5227)  Time: 1.593s,  160.70/s  (1.628s,  157.27/s)  LR: 1.000e-05  Data: 0.000 (0.009)
2024-04-03 15:14:08,805 - train - INFO - True
2024-04-03 15:14:08,806 - train - INFO - alphas:tensor([1.4720e-05, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,807 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,807 - train - INFO - True
2024-04-03 15:14:08,807 - train - INFO - alphas:tensor([0.0339, 0.9661], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,808 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,808 - train - INFO - True
2024-04-03 15:14:08,808 - train - INFO - alphas:tensor([0.5767, 0.4233], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,808 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,808 - train - INFO - True
2024-04-03 15:14:08,809 - train - INFO - alphas:tensor([0.4554, 0.5446], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,809 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,809 - train - INFO - True
2024-04-03 15:14:08,810 - train - INFO - alphas:tensor([0.1169, 0.8831], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,810 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,810 - train - INFO - True
2024-04-03 15:14:08,811 - train - INFO - alphas:tensor([0.2512, 0.7488], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,811 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,811 - train - INFO - True
2024-04-03 15:14:08,812 - train - INFO - alphas:tensor([0.5598, 0.4402], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,812 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,812 - train - INFO - True
2024-04-03 15:14:08,812 - train - INFO - alphas:tensor([0.4194, 0.5806], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,813 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,813 - train - INFO - True
2024-04-03 15:14:08,814 - train - INFO - alphas:tensor([0.2387, 0.7613], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,814 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,814 - train - INFO - True
2024-04-03 15:14:08,814 - train - INFO - alphas:tensor([0.4220, 0.5780], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,815 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,815 - train - INFO - True
2024-04-03 15:14:08,815 - train - INFO - alphas:tensor([0.5715, 0.4285], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,815 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,815 - train - INFO - True
2024-04-03 15:14:08,817 - train - INFO - alphas:tensor([0.4059, 0.5941], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,817 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,817 - train - INFO - True
2024-04-03 15:14:08,818 - train - INFO - alphas:tensor([0.2575, 0.7425], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,818 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,818 - train - INFO - True
2024-04-03 15:14:08,818 - train - INFO - alphas:tensor([0.4187, 0.5813], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,818 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,819 - train - INFO - True
2024-04-03 15:14:08,819 - train - INFO - alphas:tensor([0.5022, 0.4978], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,819 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,819 - train - INFO - True
2024-04-03 15:14:08,820 - train - INFO - alphas:tensor([0.3392, 0.6608], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,820 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,820 - train - INFO - True
2024-04-03 15:14:08,821 - train - INFO - alphas:tensor([0.2209, 0.7791], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,821 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,821 - train - INFO - True
2024-04-03 15:14:08,822 - train - INFO - alphas:tensor([0.3093, 0.6907], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,822 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,822 - train - INFO - True
2024-04-03 15:14:08,822 - train - INFO - alphas:tensor([0.3827, 0.6173], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,823 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,823 - train - INFO - True
2024-04-03 15:14:08,823 - train - INFO - alphas:tensor([0.1929, 0.8071], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,823 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,823 - train - INFO - True
2024-04-03 15:14:08,824 - train - INFO - alphas:tensor([0.1597, 0.8403], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,824 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,824 - train - INFO - True
2024-04-03 15:14:08,825 - train - INFO - alphas:tensor([0.2189, 0.7811], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,825 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,825 - train - INFO - True
2024-04-03 15:14:08,826 - train - INFO - alphas:tensor([0.3326, 0.6674], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,826 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,826 - train - INFO - True
2024-04-03 15:14:08,827 - train - INFO - alphas:tensor([0.0804, 0.9196], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,827 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,827 - train - INFO - True
2024-04-03 15:14:08,828 - train - INFO - alphas:tensor([0.0946, 0.9054], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,828 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,828 - train - INFO - True
2024-04-03 15:14:08,829 - train - INFO - alphas:tensor([9.8161e-04, 9.9902e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,829 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,829 - train - INFO - True
2024-04-03 15:14:08,829 - train - INFO - alphas:tensor([0.0027, 0.9973], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,830 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,830 - train - INFO - True
2024-04-03 15:14:08,830 - train - INFO - alphas:tensor([1.7333e-08, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,830 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,830 - train - INFO - True
2024-04-03 15:14:08,831 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:14:08,831 - train - INFO - tau:0.22368867397864742
2024-04-03 15:14:08,831 - train - INFO - avg block size:13.413793103448276
2024-04-03 15:14:09,725 - train - INFO - Test: [   0/39]  Time: 0.891 (0.891)  Loss:  0.3489 (0.3489)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-03 15:14:44,837 - train - INFO - Test: [  39/39]  Time: 0.863 (0.900)  Loss:  0.3608 (0.3543)  Acc@1: 87.5000 (92.6100)  Acc@5: 100.0000 (99.7700)
2024-04-03 15:14:46,868 - train - INFO - Train: 152 [   0/195 (  0%)]  Loss:  1.400398 (1.4004)  Time: 1.918s,  133.46/s  (1.918s,  133.46/s)  LR: 1.000e-05  Data: 0.260 (0.260)
2024-04-03 15:16:06,387 - train - INFO - Train: 152 [  50/195 ( 26%)]  Loss:  1.374368 (1.5408)  Time: 1.633s,  156.78/s  (1.597s,  160.32/s)  LR: 1.000e-05  Data: 0.005 (0.012)
2024-04-03 15:17:27,854 - train - INFO - Train: 152 [ 100/195 ( 52%)]  Loss:  1.399718 (1.5541)  Time: 1.507s,  169.88/s  (1.613s,  158.72/s)  LR: 1.000e-05  Data: 0.005 (0.010)
2024-04-03 15:18:47,305 - train - INFO - Train: 152 [ 150/195 ( 77%)]  Loss:  1.749522 (1.5563)  Time: 1.481s,  172.82/s  (1.605s,  159.50/s)  LR: 1.000e-05  Data: 0.005 (0.009)
2024-04-03 15:19:58,191 - train - INFO - Train: 152 [ 194/195 (100%)]  Loss:  1.574083 (1.5530)  Time: 1.649s,  155.21/s  (1.606s,  159.37/s)  LR: 1.000e-05  Data: 0.000 (0.009)
2024-04-03 15:19:58,191 - train - INFO - True
2024-04-03 15:19:58,192 - train - INFO - alphas:tensor([1.3126e-05, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,192 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,193 - train - INFO - True
2024-04-03 15:19:58,193 - train - INFO - alphas:tensor([0.0331, 0.9669], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,193 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,193 - train - INFO - True
2024-04-03 15:19:58,194 - train - INFO - alphas:tensor([0.5769, 0.4231], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,194 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,194 - train - INFO - True
2024-04-03 15:19:58,195 - train - INFO - alphas:tensor([0.4545, 0.5455], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,195 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,195 - train - INFO - True
2024-04-03 15:19:58,196 - train - INFO - alphas:tensor([0.1161, 0.8839], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,196 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,196 - train - INFO - True
2024-04-03 15:19:58,197 - train - INFO - alphas:tensor([0.2511, 0.7489], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,197 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,197 - train - INFO - True
2024-04-03 15:19:58,197 - train - INFO - alphas:tensor([0.5604, 0.4396], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,197 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,198 - train - INFO - True
2024-04-03 15:19:58,198 - train - INFO - alphas:tensor([0.4189, 0.5811], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,198 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,198 - train - INFO - True
2024-04-03 15:19:58,199 - train - INFO - alphas:tensor([0.2384, 0.7616], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,199 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,199 - train - INFO - True
2024-04-03 15:19:58,200 - train - INFO - alphas:tensor([0.4228, 0.5772], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,200 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,200 - train - INFO - True
2024-04-03 15:19:58,201 - train - INFO - alphas:tensor([0.5720, 0.4280], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,201 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,201 - train - INFO - True
2024-04-03 15:19:58,201 - train - INFO - alphas:tensor([0.4055, 0.5945], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,202 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,202 - train - INFO - True
2024-04-03 15:19:58,202 - train - INFO - alphas:tensor([0.2568, 0.7432], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,202 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,202 - train - INFO - True
2024-04-03 15:19:58,203 - train - INFO - alphas:tensor([0.4192, 0.5808], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,203 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,203 - train - INFO - True
2024-04-03 15:19:58,204 - train - INFO - alphas:tensor([0.5024, 0.4976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,204 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,204 - train - INFO - True
2024-04-03 15:19:58,205 - train - INFO - alphas:tensor([0.3390, 0.6610], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,205 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,205 - train - INFO - True
2024-04-03 15:19:58,206 - train - INFO - alphas:tensor([0.2204, 0.7796], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,206 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,206 - train - INFO - True
2024-04-03 15:19:58,206 - train - INFO - alphas:tensor([0.3092, 0.6908], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,206 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,207 - train - INFO - True
2024-04-03 15:19:58,207 - train - INFO - alphas:tensor([0.3826, 0.6174], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,207 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,207 - train - INFO - True
2024-04-03 15:19:58,208 - train - INFO - alphas:tensor([0.1922, 0.8078], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,208 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,208 - train - INFO - True
2024-04-03 15:19:58,209 - train - INFO - alphas:tensor([0.1589, 0.8411], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,209 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,209 - train - INFO - True
2024-04-03 15:19:58,210 - train - INFO - alphas:tensor([0.2182, 0.7818], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,210 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,210 - train - INFO - True
2024-04-03 15:19:58,210 - train - INFO - alphas:tensor([0.3325, 0.6675], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,211 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,211 - train - INFO - True
2024-04-03 15:19:58,211 - train - INFO - alphas:tensor([0.0794, 0.9206], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,211 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,211 - train - INFO - True
2024-04-03 15:19:58,212 - train - INFO - alphas:tensor([0.0937, 0.9063], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,212 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,212 - train - INFO - True
2024-04-03 15:19:58,213 - train - INFO - alphas:tensor([9.1524e-04, 9.9908e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,213 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,213 - train - INFO - True
2024-04-03 15:19:58,214 - train - INFO - alphas:tensor([0.0026, 0.9974], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,214 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,214 - train - INFO - True
2024-04-03 15:19:58,215 - train - INFO - alphas:tensor([1.4466e-08, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,215 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,215 - train - INFO - True
2024-04-03 15:19:58,216 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:19:58,216 - train - INFO - tau:0.22145178723886094
2024-04-03 15:19:58,216 - train - INFO - avg block size:13.413793103448276
2024-04-03 15:19:59,182 - train - INFO - Test: [   0/39]  Time: 0.963 (0.963)  Loss:  0.3481 (0.3481)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-03 15:20:33,991 - train - INFO - Test: [  39/39]  Time: 0.844 (0.894)  Loss:  0.3696 (0.3551)  Acc@1: 87.5000 (92.6600)  Acc@5: 100.0000 (99.7800)
2024-04-03 15:20:35,820 - train - INFO - Train: 153 [   0/195 (  0%)]  Loss:  1.775292 (1.7753)  Time: 1.660s,  154.19/s  (1.660s,  154.19/s)  LR: 1.000e-05  Data: 0.143 (0.143)
2024-04-03 15:21:56,439 - train - INFO - Train: 153 [  50/195 ( 26%)]  Loss:  1.226185 (1.5635)  Time: 1.532s,  167.14/s  (1.613s,  158.68/s)  LR: 1.000e-05  Data: 0.014 (0.010)
2024-04-03 15:23:16,585 - train - INFO - Train: 153 [ 100/195 ( 52%)]  Loss:  1.315531 (1.5235)  Time: 1.596s,  160.41/s  (1.608s,  159.19/s)  LR: 1.000e-05  Data: 0.009 (0.009)
2024-04-03 15:24:39,662 - train - INFO - Train: 153 [ 150/195 ( 77%)]  Loss:  1.614855 (1.5185)  Time: 1.628s,  157.21/s  (1.626s,  157.46/s)  LR: 1.000e-05  Data: 0.009 (0.009)
2024-04-03 15:25:50,854 - train - INFO - Train: 153 [ 194/195 (100%)]  Loss:  1.457210 (1.5250)  Time: 1.778s,  143.94/s  (1.624s,  157.63/s)  LR: 1.000e-05  Data: 0.000 (0.009)
2024-04-03 15:25:50,855 - train - INFO - True
2024-04-03 15:25:50,856 - train - INFO - alphas:tensor([1.1686e-05, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,856 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,856 - train - INFO - True
2024-04-03 15:25:50,857 - train - INFO - alphas:tensor([0.0322, 0.9678], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,857 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,857 - train - INFO - True
2024-04-03 15:25:50,857 - train - INFO - alphas:tensor([0.5772, 0.4228], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,857 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,858 - train - INFO - True
2024-04-03 15:25:50,858 - train - INFO - alphas:tensor([0.4538, 0.5462], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,858 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,858 - train - INFO - True
2024-04-03 15:25:50,859 - train - INFO - alphas:tensor([0.1151, 0.8849], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,859 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,859 - train - INFO - True
2024-04-03 15:25:50,860 - train - INFO - alphas:tensor([0.2508, 0.7492], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,860 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,860 - train - INFO - True
2024-04-03 15:25:50,861 - train - INFO - alphas:tensor([0.5606, 0.4394], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,870 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,870 - train - INFO - True
2024-04-03 15:25:50,871 - train - INFO - alphas:tensor([0.4185, 0.5815], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,871 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,872 - train - INFO - True
2024-04-03 15:25:50,872 - train - INFO - alphas:tensor([0.2375, 0.7625], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,872 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,872 - train - INFO - True
2024-04-03 15:25:50,873 - train - INFO - alphas:tensor([0.4230, 0.5770], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,873 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,873 - train - INFO - True
2024-04-03 15:25:50,874 - train - INFO - alphas:tensor([0.5724, 0.4276], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,874 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,874 - train - INFO - True
2024-04-03 15:25:50,879 - train - INFO - alphas:tensor([0.4054, 0.5946], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,888 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,888 - train - INFO - True
2024-04-03 15:25:50,889 - train - INFO - alphas:tensor([0.2562, 0.7438], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,889 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,889 - train - INFO - True
2024-04-03 15:25:50,890 - train - INFO - alphas:tensor([0.4196, 0.5804], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,890 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,890 - train - INFO - True
2024-04-03 15:25:50,891 - train - INFO - alphas:tensor([0.5026, 0.4974], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,891 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,891 - train - INFO - True
2024-04-03 15:25:50,892 - train - INFO - alphas:tensor([0.3387, 0.6613], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,892 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,892 - train - INFO - True
2024-04-03 15:25:50,906 - train - INFO - alphas:tensor([0.2200, 0.7800], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,906 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,906 - train - INFO - True
2024-04-03 15:25:50,907 - train - INFO - alphas:tensor([0.3090, 0.6910], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,907 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,907 - train - INFO - True
2024-04-03 15:25:50,908 - train - INFO - alphas:tensor([0.3825, 0.6175], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,908 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,908 - train - INFO - True
2024-04-03 15:25:50,908 - train - INFO - alphas:tensor([0.1912, 0.8088], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,909 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,909 - train - INFO - True
2024-04-03 15:25:50,909 - train - INFO - alphas:tensor([0.1580, 0.8420], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,909 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,909 - train - INFO - True
2024-04-03 15:25:50,910 - train - INFO - alphas:tensor([0.2176, 0.7824], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,910 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,910 - train - INFO - True
2024-04-03 15:25:50,911 - train - INFO - alphas:tensor([0.3323, 0.6677], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,911 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,911 - train - INFO - True
2024-04-03 15:25:50,912 - train - INFO - alphas:tensor([0.0783, 0.9217], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,912 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,912 - train - INFO - True
2024-04-03 15:25:50,913 - train - INFO - alphas:tensor([0.0928, 0.9072], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,913 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,913 - train - INFO - True
2024-04-03 15:25:50,913 - train - INFO - alphas:tensor([8.5352e-04, 9.9915e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,913 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,914 - train - INFO - True
2024-04-03 15:25:50,914 - train - INFO - alphas:tensor([0.0024, 0.9976], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,914 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,914 - train - INFO - True
2024-04-03 15:25:50,915 - train - INFO - alphas:tensor([1.2051e-08, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,915 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,915 - train - INFO - True
2024-04-03 15:25:50,916 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:25:50,916 - train - INFO - tau:0.21923726936647234
2024-04-03 15:25:50,916 - train - INFO - avg block size:13.413793103448276
2024-04-03 15:25:51,866 - train - INFO - Test: [   0/39]  Time: 0.945 (0.945)  Loss:  0.3508 (0.3508)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 15:26:26,813 - train - INFO - Test: [  39/39]  Time: 0.880 (0.897)  Loss:  0.3542 (0.3550)  Acc@1: 87.5000 (92.6200)  Acc@5: 100.0000 (99.7800)
2024-04-03 15:26:29,001 - train - INFO - Train: 154 [   0/195 (  0%)]  Loss:  1.744252 (1.7443)  Time: 1.978s,  129.45/s  (1.978s,  129.45/s)  LR: 1.000e-05  Data: 0.272 (0.272)
2024-04-03 15:27:49,421 - train - INFO - Train: 154 [  50/195 ( 26%)]  Loss:  1.761104 (1.4598)  Time: 1.774s,  144.27/s  (1.616s,  158.45/s)  LR: 1.000e-05  Data: 0.005 (0.013)
2024-04-03 15:29:10,607 - train - INFO - Train: 154 [ 100/195 ( 52%)]  Loss:  1.642256 (1.5027)  Time: 1.714s,  149.33/s  (1.620s,  158.06/s)  LR: 1.000e-05  Data: 0.016 (0.010)
2024-04-03 15:30:31,313 - train - INFO - Train: 154 [ 150/195 ( 77%)]  Loss:  1.301244 (1.5148)  Time: 1.514s,  169.04/s  (1.618s,  158.24/s)  LR: 1.000e-05  Data: 0.006 (0.009)
2024-04-03 15:31:43,962 - train - INFO - Train: 154 [ 194/195 (100%)]  Loss:  1.796351 (1.5245)  Time: 1.554s,  164.74/s  (1.625s,  157.51/s)  LR: 1.000e-05  Data: 0.000 (0.009)
2024-04-03 15:31:43,963 - train - INFO - True
2024-04-03 15:31:43,964 - train - INFO - alphas:tensor([1.0393e-05, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,964 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,964 - train - INFO - True
2024-04-03 15:31:43,965 - train - INFO - alphas:tensor([0.0314, 0.9686], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,965 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,965 - train - INFO - True
2024-04-03 15:31:43,966 - train - INFO - alphas:tensor([0.5777, 0.4223], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,966 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,966 - train - INFO - True
2024-04-03 15:31:43,967 - train - INFO - alphas:tensor([0.4535, 0.5465], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,967 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,967 - train - INFO - True
2024-04-03 15:31:43,967 - train - INFO - alphas:tensor([0.1142, 0.8858], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,968 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,968 - train - INFO - True
2024-04-03 15:31:43,968 - train - INFO - alphas:tensor([0.2504, 0.7496], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,968 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,968 - train - INFO - True
2024-04-03 15:31:43,969 - train - INFO - alphas:tensor([0.5606, 0.4394], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,969 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,969 - train - INFO - True
2024-04-03 15:31:43,970 - train - INFO - alphas:tensor([0.4180, 0.5820], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,970 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,970 - train - INFO - True
2024-04-03 15:31:43,971 - train - INFO - alphas:tensor([0.2368, 0.7632], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,971 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,971 - train - INFO - True
2024-04-03 15:31:43,972 - train - INFO - alphas:tensor([0.4233, 0.5767], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,972 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,972 - train - INFO - True
2024-04-03 15:31:43,973 - train - INFO - alphas:tensor([0.5728, 0.4272], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,973 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,973 - train - INFO - True
2024-04-03 15:31:43,974 - train - INFO - alphas:tensor([0.4052, 0.5948], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,974 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,974 - train - INFO - True
2024-04-03 15:31:43,975 - train - INFO - alphas:tensor([0.2558, 0.7442], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,975 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,975 - train - INFO - True
2024-04-03 15:31:43,975 - train - INFO - alphas:tensor([0.4201, 0.5799], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,976 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,976 - train - INFO - True
2024-04-03 15:31:43,976 - train - INFO - alphas:tensor([0.5027, 0.4973], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,976 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,976 - train - INFO - True
2024-04-03 15:31:43,977 - train - INFO - alphas:tensor([0.3382, 0.6618], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,977 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,977 - train - INFO - True
2024-04-03 15:31:43,978 - train - INFO - alphas:tensor([0.2194, 0.7806], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,978 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,978 - train - INFO - True
2024-04-03 15:31:43,979 - train - INFO - alphas:tensor([0.3089, 0.6911], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,979 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,979 - train - INFO - True
2024-04-03 15:31:43,980 - train - INFO - alphas:tensor([0.3823, 0.6177], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,980 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,980 - train - INFO - True
2024-04-03 15:31:43,980 - train - INFO - alphas:tensor([0.1905, 0.8095], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,981 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,981 - train - INFO - True
2024-04-03 15:31:43,981 - train - INFO - alphas:tensor([0.1571, 0.8429], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,981 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,981 - train - INFO - True
2024-04-03 15:31:43,982 - train - INFO - alphas:tensor([0.2170, 0.7830], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,982 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,982 - train - INFO - True
2024-04-03 15:31:43,983 - train - INFO - alphas:tensor([0.3321, 0.6679], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,983 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,983 - train - INFO - True
2024-04-03 15:31:43,984 - train - INFO - alphas:tensor([0.0774, 0.9226], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,984 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,984 - train - INFO - True
2024-04-03 15:31:43,985 - train - INFO - alphas:tensor([0.0918, 0.9082], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,985 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,985 - train - INFO - True
2024-04-03 15:31:43,985 - train - INFO - alphas:tensor([7.9509e-04, 9.9920e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,985 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,986 - train - INFO - True
2024-04-03 15:31:43,986 - train - INFO - alphas:tensor([0.0023, 0.9977], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,986 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,986 - train - INFO - True
2024-04-03 15:31:43,987 - train - INFO - alphas:tensor([1.0022e-08, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,987 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,987 - train - INFO - True
2024-04-03 15:31:43,988 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:31:43,988 - train - INFO - tau:0.2170448966728076
2024-04-03 15:31:43,988 - train - INFO - avg block size:13.413793103448276
2024-04-03 15:31:44,873 - train - INFO - Test: [   0/39]  Time: 0.882 (0.882)  Loss:  0.3540 (0.3540)  Acc@1: 93.3594 (93.3594)  Acc@5: 100.0000 (100.0000)
2024-04-03 15:32:19,814 - train - INFO - Test: [  39/39]  Time: 0.880 (0.896)  Loss:  0.3770 (0.3567)  Acc@1: 87.5000 (92.5900)  Acc@5: 100.0000 (99.8000)
2024-04-03 15:32:21,679 - train - INFO - Train: 155 [   0/195 (  0%)]  Loss:  1.539585 (1.5396)  Time: 1.732s,  147.83/s  (1.732s,  147.83/s)  LR: 1.000e-05  Data: 0.182 (0.182)
2024-04-03 15:33:41,964 - train - INFO - Train: 155 [  50/195 ( 26%)]  Loss:  1.418990 (1.4877)  Time: 1.635s,  156.61/s  (1.608s,  159.19/s)  LR: 1.000e-05  Data: 0.005 (0.011)
2024-04-03 15:35:02,719 - train - INFO - Train: 155 [ 100/195 ( 52%)]  Loss:  1.558586 (1.5227)  Time: 1.746s,  146.63/s  (1.612s,  158.85/s)  LR: 1.000e-05  Data: 0.005 (0.009)
2024-04-03 15:36:21,995 - train - INFO - Train: 155 [ 150/195 ( 77%)]  Loss:  1.386114 (1.5156)  Time: 1.697s,  150.82/s  (1.603s,  159.71/s)  LR: 1.000e-05  Data: 0.005 (0.009)
2024-04-03 15:37:32,499 - train - INFO - Train: 155 [ 194/195 (100%)]  Loss:  1.748343 (1.5261)  Time: 1.518s,  168.65/s  (1.603s,  159.72/s)  LR: 1.000e-05  Data: 0.000 (0.008)
2024-04-03 15:37:32,499 - train - INFO - True
2024-04-03 15:37:32,500 - train - INFO - alphas:tensor([9.2368e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,500 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,501 - train - INFO - True
2024-04-03 15:37:32,501 - train - INFO - alphas:tensor([0.0306, 0.9694], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,501 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,501 - train - INFO - True
2024-04-03 15:37:32,502 - train - INFO - alphas:tensor([0.5781, 0.4219], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,502 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,502 - train - INFO - True
2024-04-03 15:37:32,503 - train - INFO - alphas:tensor([0.4529, 0.5471], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,503 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,503 - train - INFO - True
2024-04-03 15:37:32,504 - train - INFO - alphas:tensor([0.1134, 0.8866], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,504 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,504 - train - INFO - True
2024-04-03 15:37:32,505 - train - INFO - alphas:tensor([0.2504, 0.7496], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,505 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,505 - train - INFO - True
2024-04-03 15:37:32,505 - train - INFO - alphas:tensor([0.5609, 0.4391], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,506 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,506 - train - INFO - True
2024-04-03 15:37:32,506 - train - INFO - alphas:tensor([0.4175, 0.5825], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,506 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,506 - train - INFO - True
2024-04-03 15:37:32,507 - train - INFO - alphas:tensor([0.2365, 0.7635], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,507 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,508 - train - INFO - True
2024-04-03 15:37:32,508 - train - INFO - alphas:tensor([0.4240, 0.5760], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,508 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,508 - train - INFO - True
2024-04-03 15:37:32,509 - train - INFO - alphas:tensor([0.5734, 0.4266], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,509 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,509 - train - INFO - True
2024-04-03 15:37:32,510 - train - INFO - alphas:tensor([0.4049, 0.5951], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,510 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,510 - train - INFO - True
2024-04-03 15:37:32,511 - train - INFO - alphas:tensor([0.2555, 0.7445], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,511 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,511 - train - INFO - True
2024-04-03 15:37:32,512 - train - INFO - alphas:tensor([0.4208, 0.5792], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,512 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,512 - train - INFO - True
2024-04-03 15:37:32,512 - train - INFO - alphas:tensor([0.5028, 0.4972], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,513 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,513 - train - INFO - True
2024-04-03 15:37:32,513 - train - INFO - alphas:tensor([0.3379, 0.6621], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,513 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,513 - train - INFO - True
2024-04-03 15:37:32,514 - train - INFO - alphas:tensor([0.2190, 0.7810], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,514 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,514 - train - INFO - True
2024-04-03 15:37:32,515 - train - INFO - alphas:tensor([0.3092, 0.6908], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,515 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,515 - train - INFO - True
2024-04-03 15:37:32,516 - train - INFO - alphas:tensor([0.3825, 0.6175], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,516 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,516 - train - INFO - True
2024-04-03 15:37:32,517 - train - INFO - alphas:tensor([0.1902, 0.8098], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,517 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,517 - train - INFO - True
2024-04-03 15:37:32,518 - train - INFO - alphas:tensor([0.1564, 0.8436], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,518 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,518 - train - INFO - True
2024-04-03 15:37:32,519 - train - INFO - alphas:tensor([0.2166, 0.7834], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,519 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,519 - train - INFO - True
2024-04-03 15:37:32,520 - train - INFO - alphas:tensor([0.3322, 0.6678], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,520 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,520 - train - INFO - True
2024-04-03 15:37:32,521 - train - INFO - alphas:tensor([0.0764, 0.9236], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,521 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,521 - train - INFO - True
2024-04-03 15:37:32,521 - train - INFO - alphas:tensor([0.0912, 0.9088], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,521 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,522 - train - INFO - True
2024-04-03 15:37:32,522 - train - INFO - alphas:tensor([7.4185e-04, 9.9926e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,522 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,522 - train - INFO - True
2024-04-03 15:37:32,523 - train - INFO - alphas:tensor([0.0022, 0.9978], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,523 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,523 - train - INFO - True
2024-04-03 15:37:32,524 - train - INFO - alphas:tensor([8.3181e-09, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,524 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,524 - train - INFO - True
2024-04-03 15:37:32,525 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:37:32,525 - train - INFO - tau:0.21487444770607952
2024-04-03 15:37:32,525 - train - INFO - avg block size:13.413793103448276
2024-04-03 15:37:33,475 - train - INFO - Test: [   0/39]  Time: 0.947 (0.947)  Loss:  0.3521 (0.3521)  Acc@1: 94.1406 (94.1406)  Acc@5: 100.0000 (100.0000)
2024-04-03 15:38:08,311 - train - INFO - Test: [  39/39]  Time: 0.906 (0.895)  Loss:  0.3623 (0.3567)  Acc@1: 87.5000 (92.6600)  Acc@5: 100.0000 (99.8100)
2024-04-03 15:38:10,250 - train - INFO - Train: 156 [   0/195 (  0%)]  Loss:  1.706487 (1.7065)  Time: 1.794s,  142.71/s  (1.794s,  142.71/s)  LR: 1.000e-05  Data: 0.169 (0.169)
2024-04-03 15:39:31,455 - train - INFO - Train: 156 [  50/195 ( 26%)]  Loss:  1.666283 (1.5263)  Time: 1.583s,  161.71/s  (1.627s,  157.30/s)  LR: 1.000e-05  Data: 0.007 (0.011)
2024-04-03 15:40:52,787 - train - INFO - Train: 156 [ 100/195 ( 52%)]  Loss:  1.603051 (1.5204)  Time: 1.743s,  146.85/s  (1.627s,  157.34/s)  LR: 1.000e-05  Data: 0.006 (0.010)
2024-04-03 15:42:12,578 - train - INFO - Train: 156 [ 150/195 ( 77%)]  Loss:  1.487966 (1.5186)  Time: 1.531s,  167.16/s  (1.617s,  158.35/s)  LR: 1.000e-05  Data: 0.005 (0.009)
2024-04-03 15:43:22,236 - train - INFO - Train: 156 [ 194/195 (100%)]  Loss:  1.442311 (1.5283)  Time: 1.489s,  171.98/s  (1.609s,  159.09/s)  LR: 1.000e-05  Data: 0.000 (0.008)
2024-04-03 15:43:22,237 - train - INFO - True
2024-04-03 15:43:22,238 - train - INFO - alphas:tensor([8.1969e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,238 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,239 - train - INFO - True
2024-04-03 15:43:22,239 - train - INFO - alphas:tensor([0.0298, 0.9702], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,239 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,239 - train - INFO - True
2024-04-03 15:43:22,240 - train - INFO - alphas:tensor([0.5787, 0.4213], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,240 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,240 - train - INFO - True
2024-04-03 15:43:22,241 - train - INFO - alphas:tensor([0.4524, 0.5476], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,241 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,241 - train - INFO - True
2024-04-03 15:43:22,242 - train - INFO - alphas:tensor([0.1127, 0.8873], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,242 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,242 - train - INFO - True
2024-04-03 15:43:22,242 - train - INFO - alphas:tensor([0.2505, 0.7495], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,243 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,243 - train - INFO - True
2024-04-03 15:43:22,244 - train - INFO - alphas:tensor([0.5613, 0.4387], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,244 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,244 - train - INFO - True
2024-04-03 15:43:22,244 - train - INFO - alphas:tensor([0.4172, 0.5828], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,244 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,245 - train - INFO - True
2024-04-03 15:43:22,245 - train - INFO - alphas:tensor([0.2361, 0.7639], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,245 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,245 - train - INFO - True
2024-04-03 15:43:22,246 - train - INFO - alphas:tensor([0.4246, 0.5754], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,246 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,246 - train - INFO - True
2024-04-03 15:43:22,247 - train - INFO - alphas:tensor([0.5736, 0.4264], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,247 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,247 - train - INFO - True
2024-04-03 15:43:22,248 - train - INFO - alphas:tensor([0.4045, 0.5955], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,248 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,249 - train - INFO - True
2024-04-03 15:43:22,250 - train - INFO - alphas:tensor([0.2554, 0.7446], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,250 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,250 - train - INFO - True
2024-04-03 15:43:22,251 - train - INFO - alphas:tensor([0.4218, 0.5782], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,251 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,251 - train - INFO - True
2024-04-03 15:43:22,251 - train - INFO - alphas:tensor([0.5030, 0.4970], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,256 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,260 - train - INFO - True
2024-04-03 15:43:22,261 - train - INFO - alphas:tensor([0.3379, 0.6621], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,261 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,261 - train - INFO - True
2024-04-03 15:43:22,262 - train - INFO - alphas:tensor([0.2188, 0.7812], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,262 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,262 - train - INFO - True
2024-04-03 15:43:22,263 - train - INFO - alphas:tensor([0.3097, 0.6903], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,263 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,263 - train - INFO - True
2024-04-03 15:43:22,264 - train - INFO - alphas:tensor([0.3828, 0.6172], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,264 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,264 - train - INFO - True
2024-04-03 15:43:22,264 - train - INFO - alphas:tensor([0.1896, 0.8104], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,264 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,265 - train - INFO - True
2024-04-03 15:43:22,265 - train - INFO - alphas:tensor([0.1557, 0.8443], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,270 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,270 - train - INFO - True
2024-04-03 15:43:22,271 - train - INFO - alphas:tensor([0.2160, 0.7840], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,271 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,271 - train - INFO - True
2024-04-03 15:43:22,271 - train - INFO - alphas:tensor([0.3322, 0.6678], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,271 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,271 - train - INFO - True
2024-04-03 15:43:22,272 - train - INFO - alphas:tensor([0.0755, 0.9245], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,272 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,277 - train - INFO - True
2024-04-03 15:43:22,277 - train - INFO - alphas:tensor([0.0904, 0.9096], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,277 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,278 - train - INFO - True
2024-04-03 15:43:22,278 - train - INFO - alphas:tensor([6.9156e-04, 9.9931e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,278 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,278 - train - INFO - True
2024-04-03 15:43:22,279 - train - INFO - alphas:tensor([0.0020, 0.9980], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,279 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,279 - train - INFO - True
2024-04-03 15:43:22,280 - train - INFO - alphas:tensor([6.8908e-09, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,280 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,280 - train - INFO - True
2024-04-03 15:43:22,281 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:43:22,281 - train - INFO - tau:0.21272570322901874
2024-04-03 15:43:22,281 - train - INFO - avg block size:13.413793103448276
2024-04-03 15:43:23,217 - train - INFO - Test: [   0/39]  Time: 0.933 (0.933)  Loss:  0.3481 (0.3481)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-03 15:43:57,529 - train - INFO - Test: [  39/39]  Time: 0.863 (0.881)  Loss:  0.3667 (0.3542)  Acc@1: 87.5000 (92.6500)  Acc@5: 100.0000 (99.7900)
2024-04-03 15:43:59,323 - train - INFO - Train: 157 [   0/195 (  0%)]  Loss:  1.711253 (1.7113)  Time: 1.668s,  153.48/s  (1.668s,  153.48/s)  LR: 1.000e-05  Data: 0.193 (0.193)
2024-04-03 15:45:18,619 - train - INFO - Train: 157 [  50/195 ( 26%)]  Loss:  1.653307 (1.4919)  Time: 1.633s,  156.77/s  (1.588s,  161.26/s)  LR: 1.000e-05  Data: 0.009 (0.011)
2024-04-03 15:46:40,358 - train - INFO - Train: 157 [ 100/195 ( 52%)]  Loss:  1.186761 (1.5202)  Time: 1.652s,  155.00/s  (1.611s,  158.92/s)  LR: 1.000e-05  Data: 0.005 (0.010)
2024-04-03 15:48:00,524 - train - INFO - Train: 157 [ 150/195 ( 77%)]  Loss:  1.567717 (1.5216)  Time: 1.498s,  170.87/s  (1.608s,  159.17/s)  LR: 1.000e-05  Data: 0.005 (0.009)
2024-04-03 15:49:10,398 - train - INFO - Train: 157 [ 194/195 (100%)]  Loss:  1.665110 (1.5082)  Time: 1.768s,  144.83/s  (1.604s,  159.62/s)  LR: 1.000e-05  Data: 0.000 (0.009)
2024-04-03 15:49:10,398 - train - INFO - True
2024-04-03 15:49:10,400 - train - INFO - alphas:tensor([7.2673e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,400 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,400 - train - INFO - True
2024-04-03 15:49:10,401 - train - INFO - alphas:tensor([0.0290, 0.9710], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,401 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,401 - train - INFO - True
2024-04-03 15:49:10,401 - train - INFO - alphas:tensor([0.5793, 0.4207], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,401 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,402 - train - INFO - True
2024-04-03 15:49:10,402 - train - INFO - alphas:tensor([0.4520, 0.5480], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,402 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,402 - train - INFO - True
2024-04-03 15:49:10,403 - train - INFO - alphas:tensor([0.1117, 0.8883], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,403 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,403 - train - INFO - True
2024-04-03 15:49:10,404 - train - INFO - alphas:tensor([0.2502, 0.7498], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,404 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,404 - train - INFO - True
2024-04-03 15:49:10,405 - train - INFO - alphas:tensor([0.5614, 0.4386], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,405 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,405 - train - INFO - True
2024-04-03 15:49:10,406 - train - INFO - alphas:tensor([0.4165, 0.5835], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,406 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,406 - train - INFO - True
2024-04-03 15:49:10,406 - train - INFO - alphas:tensor([0.2355, 0.7645], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,406 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,406 - train - INFO - True
2024-04-03 15:49:10,407 - train - INFO - alphas:tensor([0.4251, 0.5749], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,407 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,407 - train - INFO - True
2024-04-03 15:49:10,408 - train - INFO - alphas:tensor([0.5737, 0.4263], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,408 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,408 - train - INFO - True
2024-04-03 15:49:10,409 - train - INFO - alphas:tensor([0.4041, 0.5959], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,409 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,409 - train - INFO - True
2024-04-03 15:49:10,410 - train - INFO - alphas:tensor([0.2548, 0.7452], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,410 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,410 - train - INFO - True
2024-04-03 15:49:10,410 - train - INFO - alphas:tensor([0.4224, 0.5776], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,411 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,411 - train - INFO - True
2024-04-03 15:49:10,411 - train - INFO - alphas:tensor([0.5036, 0.4964], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,411 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,411 - train - INFO - True
2024-04-03 15:49:10,412 - train - INFO - alphas:tensor([0.3379, 0.6621], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,412 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,412 - train - INFO - True
2024-04-03 15:49:10,413 - train - INFO - alphas:tensor([0.2183, 0.7817], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,413 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,413 - train - INFO - True
2024-04-03 15:49:10,414 - train - INFO - alphas:tensor([0.3098, 0.6902], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,414 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,414 - train - INFO - True
2024-04-03 15:49:10,415 - train - INFO - alphas:tensor([0.3831, 0.6169], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,415 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,415 - train - INFO - True
2024-04-03 15:49:10,416 - train - INFO - alphas:tensor([0.1890, 0.8110], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,416 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,416 - train - INFO - True
2024-04-03 15:49:10,416 - train - INFO - alphas:tensor([0.1550, 0.8450], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,417 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,417 - train - INFO - True
2024-04-03 15:49:10,417 - train - INFO - alphas:tensor([0.2158, 0.7842], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,417 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,417 - train - INFO - True
2024-04-03 15:49:10,423 - train - INFO - alphas:tensor([0.3327, 0.6673], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,423 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,423 - train - INFO - True
2024-04-03 15:49:10,424 - train - INFO - alphas:tensor([0.0746, 0.9254], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,424 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,424 - train - INFO - True
2024-04-03 15:49:10,425 - train - INFO - alphas:tensor([0.0896, 0.9104], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,425 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,425 - train - INFO - True
2024-04-03 15:49:10,425 - train - INFO - alphas:tensor([6.4377e-04, 9.9936e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,426 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,426 - train - INFO - True
2024-04-03 15:49:10,426 - train - INFO - alphas:tensor([0.0019, 0.9981], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,426 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,427 - train - INFO - True
2024-04-03 15:49:10,427 - train - INFO - alphas:tensor([5.6987e-09, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,427 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,428 - train - INFO - True
2024-04-03 15:49:10,428 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:49:10,428 - train - INFO - tau:0.21059844619672854
2024-04-03 15:49:10,428 - train - INFO - avg block size:13.413793103448276
2024-04-03 15:49:11,367 - train - INFO - Test: [   0/39]  Time: 0.931 (0.931)  Loss:  0.3528 (0.3528)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-03 15:49:46,076 - train - INFO - Test: [  39/39]  Time: 0.907 (0.891)  Loss:  0.3550 (0.3539)  Acc@1: 87.5000 (92.6000)  Acc@5: 100.0000 (99.7800)
2024-04-03 15:49:47,863 - train - INFO - Train: 158 [   0/195 (  0%)]  Loss:  1.275521 (1.2755)  Time: 1.683s,  152.15/s  (1.683s,  152.15/s)  LR: 1.000e-05  Data: 0.166 (0.166)
2024-04-03 15:51:07,877 - train - INFO - Train: 158 [  50/195 ( 26%)]  Loss:  1.650264 (1.5617)  Time: 1.586s,  161.39/s  (1.602s,  159.81/s)  LR: 1.000e-05  Data: 0.015 (0.011)
2024-04-03 15:52:29,504 - train - INFO - Train: 158 [ 100/195 ( 52%)]  Loss:  1.255669 (1.5554)  Time: 1.579s,  162.18/s  (1.617s,  158.31/s)  LR: 1.000e-05  Data: 0.005 (0.009)
2024-04-03 15:53:51,048 - train - INFO - Train: 158 [ 150/195 ( 77%)]  Loss:  1.779093 (1.5444)  Time: 1.574s,  162.65/s  (1.622s,  157.87/s)  LR: 1.000e-05  Data: 0.011 (0.009)
2024-04-03 15:55:01,115 - train - INFO - Train: 158 [ 194/195 (100%)]  Loss:  1.742244 (1.5355)  Time: 1.703s,  150.29/s  (1.615s,  158.51/s)  LR: 1.000e-05  Data: 0.000 (0.009)
2024-04-03 15:55:01,116 - train - INFO - True
2024-04-03 15:55:01,118 - train - INFO - alphas:tensor([6.4353e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,118 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,118 - train - INFO - True
2024-04-03 15:55:01,119 - train - INFO - alphas:tensor([0.0283, 0.9717], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,119 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,119 - train - INFO - True
2024-04-03 15:55:01,119 - train - INFO - alphas:tensor([0.5798, 0.4202], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,120 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,120 - train - INFO - True
2024-04-03 15:55:01,120 - train - INFO - alphas:tensor([0.4518, 0.5482], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,120 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,120 - train - INFO - True
2024-04-03 15:55:01,121 - train - INFO - alphas:tensor([0.1110, 0.8890], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,121 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,121 - train - INFO - True
2024-04-03 15:55:01,122 - train - INFO - alphas:tensor([0.2500, 0.7500], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,129 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,129 - train - INFO - True
2024-04-03 15:55:01,129 - train - INFO - alphas:tensor([0.5615, 0.4385], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,129 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,129 - train - INFO - True
2024-04-03 15:55:01,130 - train - INFO - alphas:tensor([0.4159, 0.5841], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,130 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,130 - train - INFO - True
2024-04-03 15:55:01,131 - train - INFO - alphas:tensor([0.2353, 0.7647], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,131 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,131 - train - INFO - True
2024-04-03 15:55:01,132 - train - INFO - alphas:tensor([0.4258, 0.5742], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,132 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,132 - train - INFO - True
2024-04-03 15:55:01,133 - train - INFO - alphas:tensor([0.5744, 0.4256], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,133 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,133 - train - INFO - True
2024-04-03 15:55:01,133 - train - INFO - alphas:tensor([0.4043, 0.5957], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,133 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,134 - train - INFO - True
2024-04-03 15:55:01,134 - train - INFO - alphas:tensor([0.2542, 0.7458], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,134 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,134 - train - INFO - True
2024-04-03 15:55:01,135 - train - INFO - alphas:tensor([0.4227, 0.5773], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,135 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,135 - train - INFO - True
2024-04-03 15:55:01,140 - train - INFO - alphas:tensor([0.5041, 0.4959], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,140 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,140 - train - INFO - True
2024-04-03 15:55:01,141 - train - INFO - alphas:tensor([0.3381, 0.6619], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,141 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,141 - train - INFO - True
2024-04-03 15:55:01,142 - train - INFO - alphas:tensor([0.2178, 0.7822], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,142 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,142 - train - INFO - True
2024-04-03 15:55:01,143 - train - INFO - alphas:tensor([0.3097, 0.6903], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,143 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,143 - train - INFO - True
2024-04-03 15:55:01,144 - train - INFO - alphas:tensor([0.3833, 0.6167], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,144 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,144 - train - INFO - True
2024-04-03 15:55:01,144 - train - INFO - alphas:tensor([0.1884, 0.8116], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,149 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,149 - train - INFO - True
2024-04-03 15:55:01,150 - train - INFO - alphas:tensor([0.1546, 0.8454], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,150 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,150 - train - INFO - True
2024-04-03 15:55:01,150 - train - INFO - alphas:tensor([0.2157, 0.7843], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,151 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,151 - train - INFO - True
2024-04-03 15:55:01,151 - train - INFO - alphas:tensor([0.3330, 0.6670], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,151 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,151 - train - INFO - True
2024-04-03 15:55:01,152 - train - INFO - alphas:tensor([0.0737, 0.9263], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,152 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,152 - train - INFO - True
2024-04-03 15:55:01,153 - train - INFO - alphas:tensor([0.0887, 0.9113], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,153 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,153 - train - INFO - True
2024-04-03 15:55:01,154 - train - INFO - alphas:tensor([5.9867e-04, 9.9940e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,157 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,157 - train - INFO - True
2024-04-03 15:55:01,158 - train - INFO - alphas:tensor([0.0018, 0.9982], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,158 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,159 - train - INFO - True
2024-04-03 15:55:01,159 - train - INFO - alphas:tensor([4.7038e-09, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,173 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,173 - train - INFO - True
2024-04-03 15:55:01,173 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 15:55:01,174 - train - INFO - tau:0.20849246173476127
2024-04-03 15:55:01,174 - train - INFO - avg block size:13.413793103448276
2024-04-03 15:55:02,102 - train - INFO - Test: [   0/39]  Time: 0.925 (0.925)  Loss:  0.3494 (0.3494)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-03 15:55:37,056 - train - INFO - Test: [  39/39]  Time: 0.890 (0.897)  Loss:  0.3652 (0.3533)  Acc@1: 87.5000 (92.5700)  Acc@5: 100.0000 (99.7600)
2024-04-03 15:55:38,893 - train - INFO - Train: 159 [   0/195 (  0%)]  Loss:  1.281016 (1.2810)  Time: 1.742s,  146.92/s  (1.742s,  146.92/s)  LR: 1.000e-05  Data: 0.133 (0.133)
2024-04-03 15:56:58,198 - train - INFO - Train: 159 [  50/195 ( 26%)]  Loss:  1.695116 (1.5428)  Time: 1.605s,  159.50/s  (1.589s,  161.09/s)  LR: 1.000e-05  Data: 0.005 (0.010)
2024-04-03 15:58:18,733 - train - INFO - Train: 159 [ 100/195 ( 52%)]  Loss:  1.275785 (1.5205)  Time: 1.553s,  164.86/s  (1.600s,  160.02/s)  LR: 1.000e-05  Data: 0.019 (0.009)
2024-04-03 15:59:39,993 - train - INFO - Train: 159 [ 150/195 ( 77%)]  Loss:  1.737522 (1.5333)  Time: 1.524s,  167.94/s  (1.608s,  159.18/s)  LR: 1.000e-05  Data: 0.005 (0.009)
2024-04-03 16:00:50,825 - train - INFO - Train: 159 [ 194/195 (100%)]  Loss:  1.404964 (1.5248)  Time: 1.628s,  157.21/s  (1.609s,  159.15/s)  LR: 1.000e-05  Data: 0.000 (0.009)
2024-04-03 16:00:50,825 - train - INFO - True
2024-04-03 16:00:50,827 - train - INFO - alphas:tensor([5.6909e-06, 9.9999e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,827 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,827 - train - INFO - True
2024-04-03 16:00:50,828 - train - INFO - alphas:tensor([0.0275, 0.9725], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,828 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,828 - train - INFO - True
2024-04-03 16:00:50,828 - train - INFO - alphas:tensor([0.5799, 0.4201], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,829 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,829 - train - INFO - True
2024-04-03 16:00:50,829 - train - INFO - alphas:tensor([0.4510, 0.5490], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,829 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,829 - train - INFO - True
2024-04-03 16:00:50,830 - train - INFO - alphas:tensor([0.1102, 0.8898], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,830 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,830 - train - INFO - True
2024-04-03 16:00:50,831 - train - INFO - alphas:tensor([0.2499, 0.7501], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,831 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,831 - train - INFO - True
2024-04-03 16:00:50,832 - train - INFO - alphas:tensor([0.5620, 0.4380], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,832 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,832 - train - INFO - True
2024-04-03 16:00:50,833 - train - INFO - alphas:tensor([0.4160, 0.5840], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,833 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,833 - train - INFO - True
2024-04-03 16:00:50,834 - train - INFO - alphas:tensor([0.2352, 0.7648], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,834 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,834 - train - INFO - True
2024-04-03 16:00:50,835 - train - INFO - alphas:tensor([0.4267, 0.5733], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,835 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,835 - train - INFO - True
2024-04-03 16:00:50,835 - train - INFO - alphas:tensor([0.5748, 0.4252], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,836 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,836 - train - INFO - True
2024-04-03 16:00:50,836 - train - INFO - alphas:tensor([0.4039, 0.5961], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,836 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,837 - train - INFO - True
2024-04-03 16:00:50,837 - train - INFO - alphas:tensor([0.2535, 0.7465], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,837 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,837 - train - INFO - True
2024-04-03 16:00:50,838 - train - INFO - alphas:tensor([0.4232, 0.5768], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,838 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,838 - train - INFO - True
2024-04-03 16:00:50,839 - train - INFO - alphas:tensor([0.5041, 0.4959], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,839 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,839 - train - INFO - True
2024-04-03 16:00:50,840 - train - INFO - alphas:tensor([0.3376, 0.6624], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,840 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,840 - train - INFO - True
2024-04-03 16:00:50,840 - train - INFO - alphas:tensor([0.2173, 0.7827], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,841 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,841 - train - INFO - True
2024-04-03 16:00:50,841 - train - INFO - alphas:tensor([0.3098, 0.6902], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,841 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,842 - train - INFO - True
2024-04-03 16:00:50,842 - train - INFO - alphas:tensor([0.3833, 0.6167], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,842 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,842 - train - INFO - True
2024-04-03 16:00:50,843 - train - INFO - alphas:tensor([0.1878, 0.8122], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,843 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,843 - train - INFO - True
2024-04-03 16:00:50,844 - train - INFO - alphas:tensor([0.1537, 0.8463], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,844 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,844 - train - INFO - True
2024-04-03 16:00:50,845 - train - INFO - alphas:tensor([0.2152, 0.7848], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,845 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,845 - train - INFO - True
2024-04-03 16:00:50,846 - train - INFO - alphas:tensor([0.3331, 0.6669], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,846 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,846 - train - INFO - True
2024-04-03 16:00:50,846 - train - INFO - alphas:tensor([0.0728, 0.9272], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,846 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,847 - train - INFO - True
2024-04-03 16:00:50,847 - train - INFO - alphas:tensor([0.0879, 0.9121], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,847 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,847 - train - INFO - True
2024-04-03 16:00:50,848 - train - INFO - alphas:tensor([5.5663e-04, 9.9944e-01], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,848 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,848 - train - INFO - True
2024-04-03 16:00:50,849 - train - INFO - alphas:tensor([0.0017, 0.9983], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,849 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,849 - train - INFO - True
2024-04-03 16:00:50,850 - train - INFO - alphas:tensor([3.8752e-09, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,850 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,850 - train - INFO - True
2024-04-03 16:00:50,850 - train - INFO - alphas:tensor([1.], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-03 16:00:50,851 - train - INFO - tau:0.20640753711741366
2024-04-03 16:00:50,851 - train - INFO - avg block size:13.413793103448276
2024-04-03 16:00:51,812 - train - INFO - Test: [   0/39]  Time: 0.959 (0.959)  Loss:  0.3462 (0.3462)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)
2024-04-03 16:01:27,305 - train - INFO - Test: [  39/39]  Time: 0.905 (0.911)  Loss:  0.3665 (0.3536)  Acc@1: 87.5000 (92.6600)  Acc@5: 100.0000 (99.7700)
2024-04-03 16:01:27,399 - train - INFO - *** Best metric: 92.76 (epoch 119)
