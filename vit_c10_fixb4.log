2024-03-31 15:29:25,413 - train - INFO - Training with a single process on 1 GPUs.
2024-03-31 15:29:40,225 - train - INFO - Model vit_7_4_32 created, param count:3717016
2024-03-31 15:29:40,243 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-03-31 15:29:40,243 - train - INFO - Scheduled epochs: 310
2024-03-31 15:29:41,818 - train - INFO - Verifying teacher model
2024-03-31 15:29:42,540 - train - INFO - Test: [   0/78]  Time: 0.721 (0.721)  Loss:  0.3445 (0.3445)  Acc@1: 92.9688 (92.9688)  Acc@5: 100.0000 (100.0000)
2024-03-31 15:29:43,151 - train - INFO - Test: [  50/78]  Time: 0.017 (0.026)  Loss:  0.2869 (0.3467)  Acc@1: 96.0938 (93.3211)  Acc@5: 100.0000 (99.6630)
2024-03-31 15:29:43,609 - train - INFO - Test: [  78/78]  Time: 0.099 (0.023)  Loss:  0.3740 (0.3449)  Acc@1: 93.7500 (93.5400)  Acc@5: 100.0000 (99.7600)
2024-03-31 15:29:43,610 - train - INFO - Verifying initial model
2024-03-31 15:29:45,116 - train - INFO - Test: [   0/78]  Time: 1.505 (1.505)  Loss:  2.2656 (2.2656)  Acc@1: 19.5312 (19.5312)  Acc@5: 61.7188 (61.7188)
2024-03-31 15:31:19,464 - train - INFO - Test: [  50/78]  Time: 2.187 (1.879)  Loss:  2.2852 (2.2930)  Acc@1: 12.5000 (14.4455)  Acc@5: 60.9375 (54.2279)
2024-03-31 15:32:14,051 - train - INFO - Test: [  78/78]  Time: 1.747 (1.904)  Loss:  2.2773 (2.2928)  Acc@1: 18.7500 (14.3900)  Acc@5: 56.2500 (54.3200)
2024-03-31 15:32:17,002 - train - INFO - Train: 0 [   0/390 (  0%)]  Loss:  2.302428 (2.3024)  Time: 2.946s,   43.44/s  (2.946s,   43.44/s)  LR: 1.000e-05  Data: 0.710 (0.710)
2024-03-31 15:33:57,570 - train - INFO - Train: 0 [  50/390 ( 13%)]  Loss:  2.300118 (2.2987)  Time: 1.878s,   68.16/s  (2.030s,   63.06/s)  LR: 1.000e-05  Data: 0.003 (0.020)
2024-03-31 15:35:35,651 - train - INFO - Train: 0 [ 100/390 ( 26%)]  Loss:  2.278270 (2.2929)  Time: 1.926s,   66.46/s  (1.996s,   64.13/s)  LR: 1.000e-05  Data: 0.003 (0.014)
2024-03-31 15:37:14,726 - train - INFO - Train: 0 [ 150/390 ( 39%)]  Loss:  2.280651 (2.2892)  Time: 1.869s,   68.49/s  (1.991s,   64.28/s)  LR: 1.000e-05  Data: 0.005 (0.012)
