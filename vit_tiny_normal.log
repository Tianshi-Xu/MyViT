2024-04-06 13:48:39,339 - train - INFO - Training with a single process on 1 GPUs.
2024-04-06 13:48:44,176 - train - INFO - Model vit_9_12_64 created, param count:2766144
2024-04-06 13:48:44,189 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-04-06 13:48:44,190 - train - INFO - Scheduled epochs: 160
2024-04-06 13:48:44,463 - train - INFO - Verifying teacher model
2024-04-06 13:48:46,068 - train - INFO - Test: [   0/78]  Time: 1.605 (1.605)  Loss:  0.9009 (0.9009)  Acc@1: 82.0312 (82.0312)  Acc@5: 94.5312 (94.5312)
2024-04-06 13:48:48,176 - train - INFO - Test: [  50/78]  Time: 0.041 (0.073)  Loss:  1.7285 (1.6075)  Acc@1: 58.5938 (63.1127)  Acc@5: 83.5938 (84.9112)
2024-04-06 13:48:49,347 - train - INFO - Test: [  78/78]  Time: 0.050 (0.062)  Loss:  1.8408 (1.6375)  Acc@1: 56.2500 (62.6500)  Acc@5: 75.0000 (84.3200)
2024-04-06 13:48:49,347 - train - INFO - Verifying initial model
2024-04-06 13:48:49,545 - train - INFO - Test: [   0/78]  Time: 0.196 (0.196)  Loss:  5.3594 (5.3594)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
2024-04-06 13:48:53,838 - train - INFO - Test: [  50/78]  Time: 0.081 (0.088)  Loss:  5.3398 (5.2082)  Acc@1:  0.0000 ( 1.2102)  Acc@5:  0.0000 ( 5.0398)
2024-04-06 13:48:56,321 - train - INFO - Test: [  78/78]  Time: 0.074 (0.088)  Loss:  5.0898 (5.2248)  Acc@1:  0.0000 ( 0.9800)  Acc@5:  0.0000 ( 4.1400)
2024-04-06 13:48:58,134 - train - INFO - Train: 0 [   0/781 (  0%)]  Loss:  5.335610 (5.3356)  Time: 1.808s,   70.79/s  (1.808s,   70.79/s)  LR: 1.000e-06  Data: 0.425 (0.425)
2024-04-06 13:49:41,397 - train - INFO - Train: 0 [  50/781 (  6%)]  Loss:  5.299550 (5.3219)  Time: 0.775s,  165.16/s  (0.884s,  144.85/s)  LR: 1.000e-06  Data: 0.005 (0.016)
2024-04-06 13:50:22,013 - train - INFO - Train: 0 [ 100/781 ( 13%)]  Loss:  5.324676 (5.3187)  Time: 0.776s,  164.95/s  (0.848s,  150.88/s)  LR: 1.000e-06  Data: 0.006 (0.011)
2024-04-06 13:51:04,075 - train - INFO - Train: 0 [ 150/781 ( 19%)]  Loss:  5.314989 (5.3177)  Time: 1.112s,  115.09/s  (0.846s,  151.30/s)  LR: 1.000e-06  Data: 0.006 (0.010)
2024-04-06 13:51:50,120 - train - INFO - Train: 0 [ 200/781 ( 26%)]  Loss:  5.343277 (5.3182)  Time: 1.002s,  127.70/s  (0.865s,  148.04/s)  LR: 1.000e-06  Data: 0.007 (0.009)
2024-04-06 13:52:31,736 - train - INFO - Train: 0 [ 250/781 ( 32%)]  Loss:  5.322471 (5.3164)  Time: 0.772s,  165.81/s  (0.858s,  149.16/s)  LR: 1.000e-06  Data: 0.005 (0.009)
2024-04-06 13:53:21,165 - train - INFO - Train: 0 [ 300/781 ( 38%)]  Loss:  5.303780 (5.3155)  Time: 0.991s,  129.17/s  (0.880s,  145.48/s)  LR: 1.000e-06  Data: 0.008 (0.009)
2024-04-06 13:54:07,760 - train - INFO - Train: 0 [ 350/781 ( 45%)]  Loss:  5.293990 (5.3149)  Time: 0.769s,  166.34/s  (0.887s,  144.27/s)  LR: 1.000e-06  Data: 0.005 (0.009)
2024-04-06 13:54:56,135 - train - INFO - Train: 0 [ 400/781 ( 51%)]  Loss:  5.305630 (5.3143)  Time: 1.070s,  119.66/s  (0.897s,  142.66/s)  LR: 1.000e-06  Data: 0.011 (0.009)
2024-04-06 13:55:38,268 - train - INFO - Train: 0 [ 450/781 ( 58%)]  Loss:  5.318392 (5.3135)  Time: 1.086s,  117.87/s  (0.891s,  143.63/s)  LR: 1.000e-06  Data: 0.010 (0.009)
2024-04-06 13:56:20,091 - train - INFO - Train: 0 [ 500/781 ( 64%)]  Loss:  5.292252 (5.3126)  Time: 0.767s,  166.80/s  (0.886s,  144.52/s)  LR: 1.000e-06  Data: 0.007 (0.008)
2024-04-06 13:57:00,682 - train - INFO - Train: 0 [ 550/781 ( 71%)]  Loss:  5.316113 (5.3117)  Time: 0.771s,  166.13/s  (0.879s,  145.62/s)  LR: 1.000e-06  Data: 0.007 (0.008)
2024-04-06 13:57:42,441 - train - INFO - Train: 0 [ 600/781 ( 77%)]  Loss:  5.298661 (5.3109)  Time: 0.793s,  161.42/s  (0.875s,  146.23/s)  LR: 1.000e-06  Data: 0.007 (0.008)
2024-04-06 13:58:21,966 - train - INFO - Train: 0 [ 650/781 ( 83%)]  Loss:  5.305820 (5.3099)  Time: 1.149s,  111.42/s  (0.869s,  147.32/s)  LR: 1.000e-06  Data: 0.010 (0.008)
2024-04-06 13:59:03,451 - train - INFO - Train: 0 [ 700/781 ( 90%)]  Loss:  5.290137 (5.3092)  Time: 0.754s,  169.87/s  (0.866s,  147.80/s)  LR: 1.000e-06  Data: 0.005 (0.008)
2024-04-06 13:59:44,575 - train - INFO - Train: 0 [ 750/781 ( 96%)]  Loss:  5.277921 (5.3083)  Time: 0.766s,  167.02/s  (0.863s,  148.30/s)  LR: 1.000e-06  Data: 0.007 (0.008)
2024-04-06 14:00:07,962 - train - INFO - Train: 0 [ 780/781 (100%)]  Loss:  5.300297 (5.3079)  Time: 0.780s,  164.09/s  (0.860s,  148.85/s)  LR: 1.000e-06  Data: 0.000 (0.008)
2024-04-06 14:00:07,963 - train - INFO - True
2024-04-06 14:00:07,969 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,970 - train - INFO - True
2024-04-06 14:00:07,971 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,971 - train - INFO - True
2024-04-06 14:00:07,972 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,972 - train - INFO - True
2024-04-06 14:00:07,973 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,973 - train - INFO - True
2024-04-06 14:00:07,974 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,975 - train - INFO - True
2024-04-06 14:00:07,976 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,976 - train - INFO - True
2024-04-06 14:00:07,977 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,977 - train - INFO - True
2024-04-06 14:00:07,978 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,978 - train - INFO - True
2024-04-06 14:00:07,979 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,979 - train - INFO - True
2024-04-06 14:00:07,980 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,981 - train - INFO - True
2024-04-06 14:00:07,982 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,982 - train - INFO - True
2024-04-06 14:00:07,983 - train - INFO - alphas:tensor([0.2001, 0.2001, 0.2000, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,983 - train - INFO - True
2024-04-06 14:00:07,984 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,984 - train - INFO - True
2024-04-06 14:00:07,985 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,985 - train - INFO - True
2024-04-06 14:00:07,986 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,986 - train - INFO - True
2024-04-06 14:00:07,988 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,988 - train - INFO - True
2024-04-06 14:00:07,989 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,989 - train - INFO - True
2024-04-06 14:00:07,990 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.2000, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,990 - train - INFO - True
2024-04-06 14:00:07,991 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,991 - train - INFO - True
2024-04-06 14:00:07,992 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,992 - train - INFO - True
2024-04-06 14:00:07,993 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,993 - train - INFO - True
2024-04-06 14:00:07,994 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,995 - train - INFO - True
2024-04-06 14:00:07,996 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,996 - train - INFO - True
2024-04-06 14:00:07,997 - train - INFO - alphas:tensor([0.2002, 0.2000, 0.1999, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,997 - train - INFO - True
2024-04-06 14:00:07,998 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,998 - train - INFO - True
2024-04-06 14:00:07,999 - train - INFO - alphas:tensor([0.2002, 0.2000, 0.2000, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:07,999 - train - INFO - True
2024-04-06 14:00:08,000 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:08,000 - train - INFO - True
2024-04-06 14:00:08,001 - train - INFO - alphas:tensor([0.2001, 0.1999, 0.1999, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:08,001 - train - INFO - True
2024-04-06 14:00:08,002 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:08,002 - train - INFO - True
2024-04-06 14:00:08,003 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:08,004 - train - INFO - True
2024-04-06 14:00:08,004 - train - INFO - alphas:tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:08,005 - train - INFO - True
2024-04-06 14:00:08,006 - train - INFO - alphas:tensor([0.2000, 0.2001, 0.1999, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:08,006 - train - INFO - True
2024-04-06 14:00:08,007 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:08,007 - train - INFO - True
2024-04-06 14:00:08,008 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:08,008 - train - INFO - True
2024-04-06 14:00:08,009 - train - INFO - alphas:tensor([0.2000, 0.2000, 0.2001, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:08,009 - train - INFO - True
2024-04-06 14:00:08,010 - train - INFO - alphas:tensor([0.1999, 0.1999, 0.2000, 0.2001, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:08,010 - train - INFO - True
2024-04-06 14:00:08,011 - train - INFO - alphas:tensor([0.2502, 0.2500, 0.2499, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:00:08,011 - train - INFO - avg block size:1.5135135135135136
2024-04-06 14:00:08,276 - train - INFO - Test: [   0/78]  Time: 0.262 (0.262)  Loss:  5.1680 (5.1680)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  7.8125 ( 7.8125)
2024-04-06 14:00:13,391 - train - INFO - Test: [  50/78]  Time: 0.099 (0.105)  Loss:  5.3164 (5.1839)  Acc@1:  0.0000 ( 1.3787)  Acc@5:  1.5625 ( 6.5104)
2024-04-06 14:00:16,021 - train - INFO - Test: [  78/78]  Time: 0.054 (0.101)  Loss:  4.9844 (5.1843)  Acc@1:  0.0000 ( 1.3900)  Acc@5:  0.0000 ( 6.0200)
2024-04-06 14:00:17,402 - train - INFO - Train: 1 [   0/781 (  0%)]  Loss:  5.303951 (5.3040)  Time: 1.319s,   97.06/s  (1.319s,   97.06/s)  LR: 5.090e-05  Data: 0.192 (0.192)
2024-04-06 14:00:56,687 - train - INFO - Train: 1 [  50/781 (  6%)]  Loss:  5.241506 (5.2710)  Time: 0.783s,  163.55/s  (0.796s,  160.78/s)  LR: 5.090e-05  Data: 0.007 (0.010)
2024-04-06 14:01:35,813 - train - INFO - Train: 1 [ 100/781 ( 13%)]  Loss:  5.191483 (5.2503)  Time: 0.772s,  165.70/s  (0.789s,  162.15/s)  LR: 5.090e-05  Data: 0.007 (0.009)
2024-04-06 14:02:15,391 - train - INFO - Train: 1 [ 150/781 ( 19%)]  Loss:  5.126710 (5.2293)  Time: 0.801s,  159.82/s  (0.790s,  162.01/s)  LR: 5.090e-05  Data: 0.010 (0.008)
2024-04-06 14:02:55,309 - train - INFO - Train: 1 [ 200/781 ( 26%)]  Loss:  5.186853 (5.2084)  Time: 0.793s,  161.32/s  (0.792s,  161.59/s)  LR: 5.090e-05  Data: 0.008 (0.008)
2024-04-06 14:03:35,536 - train - INFO - Train: 1 [ 250/781 ( 32%)]  Loss:  5.100466 (5.1882)  Time: 0.756s,  169.30/s  (0.795s,  161.09/s)  LR: 5.090e-05  Data: 0.005 (0.007)
2024-04-06 14:04:17,550 - train - INFO - Train: 1 [ 300/781 ( 38%)]  Loss:  5.036368 (5.1688)  Time: 0.814s,  157.23/s  (0.802s,  159.56/s)  LR: 5.090e-05  Data: 0.009 (0.007)
2024-04-06 14:04:58,854 - train - INFO - Train: 1 [ 350/781 ( 45%)]  Loss:  5.043874 (5.1516)  Time: 0.753s,  170.08/s  (0.806s,  158.89/s)  LR: 5.090e-05  Data: 0.005 (0.007)
2024-04-06 14:05:38,052 - train - INFO - Train: 1 [ 400/781 ( 51%)]  Loss:  5.121878 (5.1360)  Time: 0.766s,  167.01/s  (0.803s,  159.42/s)  LR: 5.090e-05  Data: 0.005 (0.007)
2024-04-06 14:06:17,004 - train - INFO - Train: 1 [ 450/781 ( 58%)]  Loss:  4.977108 (5.1215)  Time: 0.764s,  167.63/s  (0.800s,  159.95/s)  LR: 5.090e-05  Data: 0.005 (0.007)
2024-04-06 14:06:55,843 - train - INFO - Train: 1 [ 500/781 ( 64%)]  Loss:  4.927001 (5.1070)  Time: 0.754s,  169.71/s  (0.798s,  160.42/s)  LR: 5.090e-05  Data: 0.006 (0.007)
2024-04-06 14:07:34,824 - train - INFO - Train: 1 [ 550/781 ( 71%)]  Loss:  4.938210 (5.0950)  Time: 0.756s,  169.22/s  (0.796s,  160.76/s)  LR: 5.090e-05  Data: 0.006 (0.007)
2024-04-06 14:08:13,219 - train - INFO - Train: 1 [ 600/781 ( 77%)]  Loss:  4.755356 (5.0839)  Time: 0.758s,  168.83/s  (0.794s,  161.23/s)  LR: 5.090e-05  Data: 0.005 (0.007)
2024-04-06 14:08:52,318 - train - INFO - Train: 1 [ 650/781 ( 83%)]  Loss:  5.146530 (5.0731)  Time: 0.797s,  160.57/s  (0.793s,  161.42/s)  LR: 5.090e-05  Data: 0.006 (0.007)
2024-04-06 14:09:32,517 - train - INFO - Train: 1 [ 700/781 ( 90%)]  Loss:  5.086766 (5.0648)  Time: 0.826s,  154.93/s  (0.794s,  161.26/s)  LR: 5.090e-05  Data: 0.010 (0.007)
2024-04-06 14:10:13,908 - train - INFO - Train: 1 [ 750/781 ( 96%)]  Loss:  5.021277 (5.0554)  Time: 0.785s,  163.12/s  (0.796s,  160.80/s)  LR: 5.090e-05  Data: 0.006 (0.007)
2024-04-06 14:10:40,518 - train - INFO - Train: 1 [ 780/781 (100%)]  Loss:  5.010829 (5.0489)  Time: 1.117s,  114.58/s  (0.800s,  160.10/s)  LR: 5.090e-05  Data: 0.000 (0.007)
2024-04-06 14:10:40,519 - train - INFO - True
2024-04-06 14:10:40,522 - train - INFO - alphas:tensor([0.2120, 0.2120, 0.1922, 0.1920, 0.1919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,522 - train - INFO - True
2024-04-06 14:10:40,524 - train - INFO - alphas:tensor([0.2099, 0.2097, 0.1940, 0.1932, 0.1932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,524 - train - INFO - True
2024-04-06 14:10:40,526 - train - INFO - alphas:tensor([0.2153, 0.2140, 0.1909, 0.1899, 0.1898], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,527 - train - INFO - True
2024-04-06 14:10:40,528 - train - INFO - alphas:tensor([0.2137, 0.2123, 0.1925, 0.1909, 0.1905], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,529 - train - INFO - True
2024-04-06 14:10:40,531 - train - INFO - alphas:tensor([0.2143, 0.2142, 0.1907, 0.1905, 0.1903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,531 - train - INFO - True
2024-04-06 14:10:40,533 - train - INFO - alphas:tensor([0.2141, 0.2122, 0.1920, 0.1909, 0.1908], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,533 - train - INFO - True
2024-04-06 14:10:40,535 - train - INFO - alphas:tensor([0.2136, 0.2133, 0.1910, 0.1910, 0.1910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,535 - train - INFO - True
2024-04-06 14:10:40,537 - train - INFO - alphas:tensor([0.2136, 0.2106, 0.1925, 0.1917, 0.1915], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,537 - train - INFO - True
2024-04-06 14:10:40,539 - train - INFO - alphas:tensor([0.2137, 0.2132, 0.1907, 0.1909, 0.1914], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,539 - train - INFO - True
2024-04-06 14:10:40,541 - train - INFO - alphas:tensor([0.2121, 0.2090, 0.1937, 0.1929, 0.1924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,541 - train - INFO - True
2024-04-06 14:10:40,543 - train - INFO - alphas:tensor([0.2138, 0.2114, 0.1923, 0.1908, 0.1916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,543 - train - INFO - True
2024-04-06 14:10:40,544 - train - INFO - alphas:tensor([0.2118, 0.2060, 0.1951, 0.1936, 0.1935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,545 - train - INFO - True
2024-04-06 14:10:40,546 - train - INFO - alphas:tensor([0.2119, 0.2123, 0.1923, 0.1918, 0.1916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,547 - train - INFO - True
2024-04-06 14:10:40,548 - train - INFO - alphas:tensor([0.2113, 0.2085, 0.1941, 0.1931, 0.1930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,548 - train - INFO - True
2024-04-06 14:10:40,550 - train - INFO - alphas:tensor([0.2132, 0.2104, 0.1938, 0.1915, 0.1911], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,550 - train - INFO - True
2024-04-06 14:10:40,552 - train - INFO - alphas:tensor([0.2093, 0.2068, 0.1948, 0.1945, 0.1947], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,552 - train - INFO - True
2024-04-06 14:10:40,554 - train - INFO - alphas:tensor([0.2116, 0.2116, 0.1925, 0.1923, 0.1920], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,554 - train - INFO - True
2024-04-06 14:10:40,555 - train - INFO - alphas:tensor([0.2124, 0.2090, 0.1922, 0.1933, 0.1930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,556 - train - INFO - True
2024-04-06 14:10:40,557 - train - INFO - alphas:tensor([0.2104, 0.2077, 0.1950, 0.1936, 0.1934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,557 - train - INFO - True
2024-04-06 14:10:40,559 - train - INFO - alphas:tensor([0.2081, 0.2043, 0.1970, 0.1953, 0.1954], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,559 - train - INFO - True
2024-04-06 14:10:40,561 - train - INFO - alphas:tensor([0.2117, 0.2107, 0.1932, 0.1923, 0.1921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,561 - train - INFO - True
2024-04-06 14:10:40,563 - train - INFO - alphas:tensor([0.2113, 0.2078, 0.1937, 0.1934, 0.1938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,563 - train - INFO - True
2024-04-06 14:10:40,564 - train - INFO - alphas:tensor([0.2098, 0.2073, 0.1945, 0.1942, 0.1942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,564 - train - INFO - True
2024-04-06 14:10:40,566 - train - INFO - alphas:tensor([0.2041, 0.2018, 0.1981, 0.1982, 0.1978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,566 - train - INFO - True
2024-04-06 14:10:40,568 - train - INFO - alphas:tensor([0.2131, 0.2123, 0.1921, 0.1913, 0.1913], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,568 - train - INFO - True
2024-04-06 14:10:40,569 - train - INFO - alphas:tensor([0.2131, 0.2082, 0.1935, 0.1923, 0.1929], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,569 - train - INFO - True
2024-04-06 14:10:40,571 - train - INFO - alphas:tensor([0.2095, 0.2061, 0.1962, 0.1948, 0.1934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,571 - train - INFO - True
2024-04-06 14:10:40,573 - train - INFO - alphas:tensor([0.2063, 0.2028, 0.1972, 0.1966, 0.1970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,573 - train - INFO - True
2024-04-06 14:10:40,574 - train - INFO - alphas:tensor([0.2123, 0.2112, 0.1923, 0.1920, 0.1921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,574 - train - INFO - True
2024-04-06 14:10:40,576 - train - INFO - alphas:tensor([0.2114, 0.2085, 0.1935, 0.1935, 0.1932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,576 - train - INFO - True
2024-04-06 14:10:40,577 - train - INFO - alphas:tensor([0.2086, 0.2069, 0.1964, 0.1945, 0.1935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,578 - train - INFO - True
2024-04-06 14:10:40,579 - train - INFO - alphas:tensor([0.2104, 0.2054, 0.1955, 0.1939, 0.1948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,579 - train - INFO - True
2024-04-06 14:10:40,581 - train - INFO - alphas:tensor([0.2099, 0.2100, 0.1932, 0.1934, 0.1934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,581 - train - INFO - True
2024-04-06 14:10:40,582 - train - INFO - alphas:tensor([0.2097, 0.2080, 0.1939, 0.1942, 0.1942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,582 - train - INFO - True
2024-04-06 14:10:40,584 - train - INFO - alphas:tensor([0.2113, 0.2085, 0.1955, 0.1925, 0.1922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,584 - train - INFO - True
2024-04-06 14:10:40,585 - train - INFO - alphas:tensor([0.2089, 0.2058, 0.1957, 0.1948, 0.1948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,585 - train - INFO - True
2024-04-06 14:10:40,587 - train - INFO - alphas:tensor([0.2697, 0.2491, 0.2403, 0.2409], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:10:40,587 - train - INFO - avg block size:1.054054054054054
2024-04-06 14:10:40,842 - train - INFO - Test: [   0/78]  Time: 0.251 (0.251)  Loss:  3.3086 (3.3086)  Acc@1: 46.0938 (46.0938)  Acc@5: 75.0000 (75.0000)
2024-04-06 14:10:45,971 - train - INFO - Test: [  50/78]  Time: 0.096 (0.106)  Loss:  4.0430 (4.1104)  Acc@1: 25.0000 (18.9185)  Acc@5: 46.0938 (41.3603)
2024-04-06 14:10:49,024 - train - INFO - Test: [  78/78]  Time: 0.065 (0.107)  Loss:  4.0859 (4.0948)  Acc@1: 12.5000 (18.7400)  Acc@5: 43.7500 (41.6200)
2024-04-06 14:10:50,340 - train - INFO - Train: 2 [   0/781 (  0%)]  Loss:  4.990104 (4.9901)  Time: 1.251s,  102.34/s  (1.251s,  102.34/s)  LR: 1.008e-04  Data: 0.204 (0.204)
2024-04-06 14:11:30,336 - train - INFO - Train: 2 [  50/781 (  6%)]  Loss:  5.028975 (4.9210)  Time: 0.819s,  156.21/s  (0.809s,  158.27/s)  LR: 1.008e-04  Data: 0.008 (0.010)
2024-04-06 14:12:09,216 - train - INFO - Train: 2 [ 100/781 ( 13%)]  Loss:  4.987075 (4.9114)  Time: 0.755s,  169.63/s  (0.793s,  161.35/s)  LR: 1.008e-04  Data: 0.005 (0.008)
2024-04-06 14:12:50,124 - train - INFO - Train: 2 [ 150/781 ( 19%)]  Loss:  4.858887 (4.8901)  Time: 0.771s,  166.01/s  (0.802s,  159.69/s)  LR: 1.008e-04  Data: 0.005 (0.008)
2024-04-06 14:13:28,562 - train - INFO - Train: 2 [ 200/781 ( 26%)]  Loss:  4.959177 (4.8767)  Time: 0.748s,  171.04/s  (0.793s,  161.34/s)  LR: 1.008e-04  Data: 0.006 (0.007)
2024-04-06 14:14:07,607 - train - INFO - Train: 2 [ 250/781 ( 32%)]  Loss:  4.975266 (4.8701)  Time: 0.765s,  167.37/s  (0.791s,  161.84/s)  LR: 1.008e-04  Data: 0.006 (0.007)
2024-04-06 14:14:46,549 - train - INFO - Train: 2 [ 300/781 ( 38%)]  Loss:  4.675356 (4.8638)  Time: 0.814s,  157.22/s  (0.789s,  162.25/s)  LR: 1.008e-04  Data: 0.009 (0.007)
2024-04-06 14:15:28,151 - train - INFO - Train: 2 [ 350/781 ( 45%)]  Loss:  4.524413 (4.8521)  Time: 0.761s,  168.11/s  (0.795s,  161.00/s)  LR: 1.008e-04  Data: 0.006 (0.007)
2024-04-06 14:16:08,382 - train - INFO - Train: 2 [ 400/781 ( 51%)]  Loss:  4.771606 (4.8470)  Time: 0.792s,  161.65/s  (0.796s,  160.76/s)  LR: 1.008e-04  Data: 0.007 (0.007)
2024-04-06 14:16:46,888 - train - INFO - Train: 2 [ 450/781 ( 58%)]  Loss:  4.517629 (4.8392)  Time: 0.757s,  169.04/s  (0.793s,  161.35/s)  LR: 1.008e-04  Data: 0.005 (0.007)
2024-04-06 14:17:25,714 - train - INFO - Train: 2 [ 500/781 ( 64%)]  Loss:  4.528547 (4.8316)  Time: 0.775s,  165.17/s  (0.792s,  161.69/s)  LR: 1.008e-04  Data: 0.005 (0.007)
2024-04-06 14:18:04,576 - train - INFO - Train: 2 [ 550/781 ( 71%)]  Loss:  4.905509 (4.8271)  Time: 0.812s,  157.63/s  (0.790s,  161.96/s)  LR: 1.008e-04  Data: 0.008 (0.007)
2024-04-06 14:18:43,095 - train - INFO - Train: 2 [ 600/781 ( 77%)]  Loss:  4.817746 (4.8201)  Time: 0.759s,  168.72/s  (0.789s,  162.30/s)  LR: 1.008e-04  Data: 0.005 (0.007)
2024-04-06 14:19:21,732 - train - INFO - Train: 2 [ 650/781 ( 83%)]  Loss:  4.719645 (4.8131)  Time: 0.763s,  167.81/s  (0.787s,  162.55/s)  LR: 1.008e-04  Data: 0.005 (0.006)
2024-04-06 14:19:59,892 - train - INFO - Train: 2 [ 700/781 ( 90%)]  Loss:  4.501777 (4.8047)  Time: 0.759s,  168.67/s  (0.786s,  162.91/s)  LR: 1.008e-04  Data: 0.005 (0.006)
2024-04-06 14:20:38,151 - train - INFO - Train: 2 [ 750/781 ( 96%)]  Loss:  4.822115 (4.7994)  Time: 0.762s,  167.90/s  (0.784s,  163.19/s)  LR: 1.008e-04  Data: 0.005 (0.006)
2024-04-06 14:21:02,031 - train - INFO - Train: 2 [ 780/781 (100%)]  Loss:  4.309979 (4.7952)  Time: 0.813s,  157.36/s  (0.785s,  163.10/s)  LR: 1.008e-04  Data: 0.000 (0.006)
2024-04-06 14:21:02,032 - train - INFO - True
2024-04-06 14:21:02,033 - train - INFO - alphas:tensor([0.2212, 0.2192, 0.1859, 0.1868, 0.1869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,033 - train - INFO - True
2024-04-06 14:21:02,034 - train - INFO - alphas:tensor([0.2208, 0.2160, 0.1873, 0.1873, 0.1886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,034 - train - INFO - True
2024-04-06 14:21:02,035 - train - INFO - alphas:tensor([0.2423, 0.2358, 0.1754, 0.1732, 0.1732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,036 - train - INFO - True
2024-04-06 14:21:02,037 - train - INFO - alphas:tensor([0.2419, 0.2284, 0.1773, 0.1766, 0.1758], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,037 - train - INFO - True
2024-04-06 14:21:02,038 - train - INFO - alphas:tensor([0.2336, 0.2294, 0.1787, 0.1791, 0.1793], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,038 - train - INFO - True
2024-04-06 14:21:02,039 - train - INFO - alphas:tensor([0.2341, 0.2228, 0.1814, 0.1808, 0.1809], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,039 - train - INFO - True
2024-04-06 14:21:02,040 - train - INFO - alphas:tensor([0.2356, 0.2319, 0.1776, 0.1774, 0.1776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,040 - train - INFO - True
2024-04-06 14:21:02,041 - train - INFO - alphas:tensor([0.2339, 0.2244, 0.1832, 0.1795, 0.1791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,041 - train - INFO - True
2024-04-06 14:21:02,042 - train - INFO - alphas:tensor([0.2357, 0.2304, 0.1772, 0.1777, 0.1790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,042 - train - INFO - True
2024-04-06 14:21:02,043 - train - INFO - alphas:tensor([0.2332, 0.2210, 0.1830, 0.1814, 0.1815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,043 - train - INFO - True
2024-04-06 14:21:02,044 - train - INFO - alphas:tensor([0.2364, 0.2263, 0.1795, 0.1779, 0.1799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,044 - train - INFO - True
2024-04-06 14:21:02,045 - train - INFO - alphas:tensor([0.2311, 0.2137, 0.1863, 0.1851, 0.1837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,045 - train - INFO - True
2024-04-06 14:21:02,046 - train - INFO - alphas:tensor([0.2305, 0.2258, 0.1808, 0.1813, 0.1816], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,047 - train - INFO - True
2024-04-06 14:21:02,047 - train - INFO - alphas:tensor([0.2329, 0.2148, 0.1849, 0.1834, 0.1840], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,048 - train - INFO - True
2024-04-06 14:21:02,049 - train - INFO - alphas:tensor([0.2351, 0.2233, 0.1836, 0.1792, 0.1787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,049 - train - INFO - True
2024-04-06 14:21:02,050 - train - INFO - alphas:tensor([0.2261, 0.2151, 0.1876, 0.1849, 0.1863], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,050 - train - INFO - True
2024-04-06 14:21:02,051 - train - INFO - alphas:tensor([0.2273, 0.2226, 0.1829, 0.1835, 0.1837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,051 - train - INFO - True
2024-04-06 14:21:02,052 - train - INFO - alphas:tensor([0.2324, 0.2162, 0.1832, 0.1839, 0.1843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,052 - train - INFO - True
2024-04-06 14:21:02,053 - train - INFO - alphas:tensor([0.2327, 0.2222, 0.1837, 0.1810, 0.1804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,053 - train - INFO - True
2024-04-06 14:21:02,054 - train - INFO - alphas:tensor([0.2254, 0.2127, 0.1893, 0.1860, 0.1867], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,054 - train - INFO - True
2024-04-06 14:21:02,055 - train - INFO - alphas:tensor([0.2296, 0.2230, 0.1824, 0.1824, 0.1826], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,055 - train - INFO - True
2024-04-06 14:21:02,056 - train - INFO - alphas:tensor([0.2356, 0.2162, 0.1824, 0.1826, 0.1831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,056 - train - INFO - True
2024-04-06 14:21:02,057 - train - INFO - alphas:tensor([0.2330, 0.2199, 0.1828, 0.1821, 0.1822], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,057 - train - INFO - True
2024-04-06 14:21:02,058 - train - INFO - alphas:tensor([0.2177, 0.2075, 0.1922, 0.1911, 0.1915], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,058 - train - INFO - True
2024-04-06 14:21:02,059 - train - INFO - alphas:tensor([0.2301, 0.2236, 0.1813, 0.1823, 0.1827], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,059 - train - INFO - True
2024-04-06 14:21:02,060 - train - INFO - alphas:tensor([0.2348, 0.2151, 0.1846, 0.1819, 0.1835], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,060 - train - INFO - True
2024-04-06 14:21:02,061 - train - INFO - alphas:tensor([0.2373, 0.2226, 0.1829, 0.1796, 0.1775], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,061 - train - INFO - True
2024-04-06 14:21:02,062 - train - INFO - alphas:tensor([0.2240, 0.2113, 0.1899, 0.1872, 0.1876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,062 - train - INFO - True
2024-04-06 14:21:02,063 - train - INFO - alphas:tensor([0.2293, 0.2243, 0.1817, 0.1822, 0.1825], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,063 - train - INFO - True
2024-04-06 14:21:02,064 - train - INFO - alphas:tensor([0.2326, 0.2185, 0.1833, 0.1826, 0.1830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,064 - train - INFO - True
2024-04-06 14:21:02,065 - train - INFO - alphas:tensor([0.2406, 0.2285, 0.1796, 0.1760, 0.1752], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,065 - train - INFO - True
2024-04-06 14:21:02,066 - train - INFO - alphas:tensor([0.2288, 0.2155, 0.1877, 0.1837, 0.1843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,066 - train - INFO - True
2024-04-06 14:21:02,067 - train - INFO - alphas:tensor([0.2241, 0.2220, 0.1841, 0.1847, 0.1852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,067 - train - INFO - True
2024-04-06 14:21:02,068 - train - INFO - alphas:tensor([0.2235, 0.2157, 0.1866, 0.1871, 0.1872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,068 - train - INFO - True
2024-04-06 14:21:02,069 - train - INFO - alphas:tensor([0.2399, 0.2311, 0.1770, 0.1761, 0.1758], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,069 - train - INFO - True
2024-04-06 14:21:02,070 - train - INFO - alphas:tensor([0.2272, 0.2183, 0.1854, 0.1843, 0.1847], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,070 - train - INFO - True
2024-04-06 14:21:02,071 - train - INFO - alphas:tensor([0.2983, 0.2427, 0.2283, 0.2308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:21:02,071 - train - INFO - avg block size:1.0
2024-04-06 14:21:02,261 - train - INFO - Test: [   0/78]  Time: 0.186 (0.186)  Loss:  2.5352 (2.5352)  Acc@1: 57.0312 (57.0312)  Acc@5: 78.1250 (78.1250)
2024-04-06 14:21:07,423 - train - INFO - Test: [  50/78]  Time: 0.096 (0.105)  Loss:  3.4727 (3.5506)  Acc@1: 34.3750 (27.9871)  Acc@5: 58.5938 (52.6501)
2024-04-06 14:21:10,066 - train - INFO - Test: [  78/78]  Time: 0.067 (0.101)  Loss:  3.7051 (3.5269)  Acc@1: 12.5000 (27.9000)  Acc@5: 43.7500 (53.5700)
2024-04-06 14:21:11,420 - train - INFO - Train: 3 [   0/781 (  0%)]  Loss:  4.763505 (4.7635)  Time: 1.286s,   99.51/s  (1.286s,   99.51/s)  LR: 1.507e-04  Data: 0.202 (0.202)
2024-04-06 14:21:51,160 - train - INFO - Train: 3 [  50/781 (  6%)]  Loss:  4.526649 (4.7042)  Time: 0.764s,  167.55/s  (0.804s,  159.12/s)  LR: 1.507e-04  Data: 0.006 (0.010)
2024-04-06 14:22:29,608 - train - INFO - Train: 3 [ 100/781 ( 13%)]  Loss:  4.428938 (4.7206)  Time: 0.779s,  164.29/s  (0.787s,  162.67/s)  LR: 1.507e-04  Data: 0.006 (0.008)
2024-04-06 14:23:08,161 - train - INFO - Train: 3 [ 150/781 ( 19%)]  Loss:  4.723628 (4.6832)  Time: 0.766s,  167.14/s  (0.782s,  163.76/s)  LR: 1.507e-04  Data: 0.005 (0.007)
2024-04-06 14:23:47,011 - train - INFO - Train: 3 [ 200/781 ( 26%)]  Loss:  4.337654 (4.6569)  Time: 0.761s,  168.12/s  (0.780s,  164.00/s)  LR: 1.507e-04  Data: 0.005 (0.007)
2024-04-06 14:24:25,376 - train - INFO - Train: 3 [ 250/781 ( 32%)]  Loss:  4.688854 (4.6526)  Time: 0.754s,  169.83/s  (0.778s,  164.56/s)  LR: 1.507e-04  Data: 0.005 (0.007)
2024-04-06 14:25:05,772 - train - INFO - Train: 3 [ 300/781 ( 38%)]  Loss:  4.292280 (4.6417)  Time: 0.768s,  166.71/s  (0.783s,  163.51/s)  LR: 1.507e-04  Data: 0.005 (0.006)
2024-04-06 14:25:44,607 - train - INFO - Train: 3 [ 350/781 ( 45%)]  Loss:  4.611601 (4.6335)  Time: 0.820s,  156.16/s  (0.782s,  163.69/s)  LR: 1.507e-04  Data: 0.009 (0.006)
2024-04-06 14:26:25,747 - train - INFO - Train: 3 [ 400/781 ( 51%)]  Loss:  4.622692 (4.6176)  Time: 0.772s,  165.81/s  (0.787s,  162.63/s)  LR: 1.507e-04  Data: 0.006 (0.006)
2024-04-06 14:27:07,207 - train - INFO - Train: 3 [ 450/781 ( 58%)]  Loss:  4.400846 (4.6108)  Time: 0.813s,  157.39/s  (0.792s,  161.67/s)  LR: 1.507e-04  Data: 0.008 (0.006)
2024-04-06 14:27:47,016 - train - INFO - Train: 3 [ 500/781 ( 64%)]  Loss:  4.569974 (4.5977)  Time: 0.810s,  158.12/s  (0.792s,  161.58/s)  LR: 1.507e-04  Data: 0.009 (0.006)
2024-04-06 14:28:25,953 - train - INFO - Train: 3 [ 550/781 ( 71%)]  Loss:  4.263132 (4.5902)  Time: 0.766s,  167.04/s  (0.791s,  161.83/s)  LR: 1.507e-04  Data: 0.005 (0.006)
2024-04-06 14:29:04,923 - train - INFO - Train: 3 [ 600/781 ( 77%)]  Loss:  4.754627 (4.5813)  Time: 0.751s,  170.51/s  (0.790s,  162.03/s)  LR: 1.507e-04  Data: 0.005 (0.006)
2024-04-06 14:29:44,215 - train - INFO - Train: 3 [ 650/781 ( 83%)]  Loss:  4.347313 (4.5725)  Time: 0.767s,  166.85/s  (0.790s,  162.10/s)  LR: 1.507e-04  Data: 0.006 (0.006)
2024-04-06 14:30:22,940 - train - INFO - Train: 3 [ 700/781 ( 90%)]  Loss:  4.769423 (4.5707)  Time: 0.810s,  158.08/s  (0.789s,  162.32/s)  LR: 1.507e-04  Data: 0.008 (0.006)
2024-04-06 14:31:02,190 - train - INFO - Train: 3 [ 750/781 ( 96%)]  Loss:  4.720242 (4.5629)  Time: 0.770s,  166.29/s  (0.788s,  162.37/s)  LR: 1.507e-04  Data: 0.005 (0.006)
2024-04-06 14:31:26,173 - train - INFO - Train: 3 [ 780/781 (100%)]  Loss:  4.657922 (4.5601)  Time: 0.749s,  170.91/s  (0.789s,  162.28/s)  LR: 1.507e-04  Data: 0.000 (0.006)
2024-04-06 14:31:26,174 - train - INFO - True
2024-04-06 14:31:26,175 - train - INFO - alphas:tensor([0.2293, 0.2245, 0.1806, 0.1825, 0.1831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,175 - train - INFO - tau:0.99
2024-04-06 14:31:26,175 - train - INFO - True
2024-04-06 14:31:26,176 - train - INFO - alphas:tensor([0.2302, 0.2194, 0.1808, 0.1835, 0.1860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,176 - train - INFO - tau:0.99
2024-04-06 14:31:26,176 - train - INFO - True
2024-04-06 14:31:26,177 - train - INFO - alphas:tensor([0.2805, 0.2572, 0.1563, 0.1530, 0.1531], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,177 - train - INFO - tau:0.99
2024-04-06 14:31:26,178 - train - INFO - True
2024-04-06 14:31:26,178 - train - INFO - alphas:tensor([0.2846, 0.2397, 0.1584, 0.1593, 0.1579], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,179 - train - INFO - tau:0.99
2024-04-06 14:31:26,179 - train - INFO - True
2024-04-06 14:31:26,179 - train - INFO - alphas:tensor([0.2630, 0.2454, 0.1623, 0.1640, 0.1653], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,180 - train - INFO - tau:0.99
2024-04-06 14:31:26,180 - train - INFO - True
2024-04-06 14:31:26,181 - train - INFO - alphas:tensor([0.2649, 0.2314, 0.1677, 0.1678, 0.1682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,181 - train - INFO - tau:0.99
2024-04-06 14:31:26,181 - train - INFO - True
2024-04-06 14:31:26,182 - train - INFO - alphas:tensor([0.2705, 0.2508, 0.1589, 0.1596, 0.1602], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,182 - train - INFO - tau:0.99
2024-04-06 14:31:26,182 - train - INFO - True
2024-04-06 14:31:26,183 - train - INFO - alphas:tensor([0.2649, 0.2379, 0.1698, 0.1642, 0.1631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,183 - train - INFO - tau:0.99
2024-04-06 14:31:26,183 - train - INFO - True
2024-04-06 14:31:26,184 - train - INFO - alphas:tensor([0.2726, 0.2502, 0.1579, 0.1588, 0.1606], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,184 - train - INFO - tau:0.99
2024-04-06 14:31:26,184 - train - INFO - True
2024-04-06 14:31:26,185 - train - INFO - alphas:tensor([0.2726, 0.2328, 0.1657, 0.1642, 0.1646], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,185 - train - INFO - tau:0.99
2024-04-06 14:31:26,185 - train - INFO - True
2024-04-06 14:31:26,186 - train - INFO - alphas:tensor([0.2736, 0.2425, 0.1606, 0.1602, 0.1631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,186 - train - INFO - tau:0.99
2024-04-06 14:31:26,186 - train - INFO - True
2024-04-06 14:31:26,187 - train - INFO - alphas:tensor([0.2618, 0.2220, 0.1742, 0.1725, 0.1695], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,187 - train - INFO - tau:0.99
2024-04-06 14:31:26,187 - train - INFO - True
2024-04-06 14:31:26,188 - train - INFO - alphas:tensor([0.2668, 0.2447, 0.1613, 0.1631, 0.1641], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,188 - train - INFO - tau:0.99
2024-04-06 14:31:26,188 - train - INFO - True
2024-04-06 14:31:26,189 - train - INFO - alphas:tensor([0.2751, 0.2231, 0.1684, 0.1663, 0.1671], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,189 - train - INFO - tau:0.99
2024-04-06 14:31:26,189 - train - INFO - True
2024-04-06 14:31:26,190 - train - INFO - alphas:tensor([0.2692, 0.2361, 0.1686, 0.1630, 0.1630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,190 - train - INFO - tau:0.99
2024-04-06 14:31:26,190 - train - INFO - True
2024-04-06 14:31:26,191 - train - INFO - alphas:tensor([0.2526, 0.2237, 0.1769, 0.1721, 0.1748], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,191 - train - INFO - tau:0.99
2024-04-06 14:31:26,191 - train - INFO - True
2024-04-06 14:31:26,192 - train - INFO - alphas:tensor([0.2584, 0.2388, 0.1660, 0.1677, 0.1691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,192 - train - INFO - tau:0.99
2024-04-06 14:31:26,192 - train - INFO - True
2024-04-06 14:31:26,193 - train - INFO - alphas:tensor([0.2707, 0.2217, 0.1698, 0.1689, 0.1689], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,193 - train - INFO - tau:0.99
2024-04-06 14:31:26,193 - train - INFO - True
2024-04-06 14:31:26,194 - train - INFO - alphas:tensor([0.2674, 0.2378, 0.1677, 0.1641, 0.1630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,194 - train - INFO - tau:0.99
2024-04-06 14:31:26,194 - train - INFO - True
2024-04-06 14:31:26,195 - train - INFO - alphas:tensor([0.2530, 0.2199, 0.1784, 0.1739, 0.1747], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,195 - train - INFO - tau:0.99
2024-04-06 14:31:26,195 - train - INFO - True
2024-04-06 14:31:26,196 - train - INFO - alphas:tensor([0.2557, 0.2326, 0.1688, 0.1707, 0.1721], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,196 - train - INFO - tau:0.99
2024-04-06 14:31:26,196 - train - INFO - True
2024-04-06 14:31:26,197 - train - INFO - alphas:tensor([0.2746, 0.2191, 0.1683, 0.1686, 0.1693], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,197 - train - INFO - tau:0.99
2024-04-06 14:31:26,197 - train - INFO - True
2024-04-06 14:31:26,198 - train - INFO - alphas:tensor([0.2728, 0.2336, 0.1654, 0.1639, 0.1642], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,198 - train - INFO - tau:0.99
2024-04-06 14:31:26,198 - train - INFO - True
2024-04-06 14:31:26,199 - train - INFO - alphas:tensor([0.2418, 0.2145, 0.1833, 0.1799, 0.1806], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,199 - train - INFO - tau:0.99
2024-04-06 14:31:26,199 - train - INFO - True
2024-04-06 14:31:26,200 - train - INFO - alphas:tensor([0.2539, 0.2325, 0.1682, 0.1722, 0.1732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,200 - train - INFO - tau:0.99
2024-04-06 14:31:26,200 - train - INFO - True
2024-04-06 14:31:26,201 - train - INFO - alphas:tensor([0.2697, 0.2186, 0.1718, 0.1687, 0.1713], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,201 - train - INFO - tau:0.99
2024-04-06 14:31:26,201 - train - INFO - True
2024-04-06 14:31:26,202 - train - INFO - alphas:tensor([0.2828, 0.2388, 0.1623, 0.1589, 0.1572], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,202 - train - INFO - tau:0.99
2024-04-06 14:31:26,202 - train - INFO - True
2024-04-06 14:31:26,203 - train - INFO - alphas:tensor([0.2561, 0.2206, 0.1775, 0.1733, 0.1724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,203 - train - INFO - tau:0.99
2024-04-06 14:31:26,203 - train - INFO - True
2024-04-06 14:31:26,204 - train - INFO - alphas:tensor([0.2535, 0.2341, 0.1692, 0.1712, 0.1720], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,204 - train - INFO - tau:0.99
2024-04-06 14:31:26,204 - train - INFO - True
2024-04-06 14:31:26,205 - train - INFO - alphas:tensor([0.2680, 0.2261, 0.1687, 0.1674, 0.1698], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,205 - train - INFO - tau:0.99
2024-04-06 14:31:26,205 - train - INFO - True
2024-04-06 14:31:26,206 - train - INFO - alphas:tensor([0.2856, 0.2487, 0.1570, 0.1543, 0.1544], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,206 - train - INFO - tau:0.99
2024-04-06 14:31:26,206 - train - INFO - True
2024-04-06 14:31:26,207 - train - INFO - alphas:tensor([0.2649, 0.2288, 0.1720, 0.1669, 0.1674], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,207 - train - INFO - tau:0.99
2024-04-06 14:31:26,207 - train - INFO - True
2024-04-06 14:31:26,208 - train - INFO - alphas:tensor([0.2455, 0.2353, 0.1713, 0.1731, 0.1747], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,208 - train - INFO - tau:0.99
2024-04-06 14:31:26,208 - train - INFO - True
2024-04-06 14:31:26,209 - train - INFO - alphas:tensor([0.2494, 0.2227, 0.1751, 0.1762, 0.1765], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,209 - train - INFO - tau:0.99
2024-04-06 14:31:26,209 - train - INFO - True
2024-04-06 14:31:26,210 - train - INFO - alphas:tensor([0.2812, 0.2506, 0.1555, 0.1562, 0.1565], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,210 - train - INFO - tau:0.99
2024-04-06 14:31:26,210 - train - INFO - True
2024-04-06 14:31:26,211 - train - INFO - alphas:tensor([0.2635, 0.2352, 0.1667, 0.1667, 0.1680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,211 - train - INFO - tau:0.99
2024-04-06 14:31:26,211 - train - INFO - True
2024-04-06 14:31:26,212 - train - INFO - alphas:tensor([0.3413, 0.2257, 0.2142, 0.2188], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:31:26,212 - train - INFO - tau:0.99
2024-04-06 14:31:26,212 - train - INFO - avg block size:1.0
2024-04-06 14:31:26,467 - train - INFO - Test: [   0/78]  Time: 0.250 (0.250)  Loss:  1.9346 (1.9346)  Acc@1: 61.7188 (61.7188)  Acc@5: 81.2500 (81.2500)
2024-04-06 14:31:31,172 - train - INFO - Test: [  50/78]  Time: 0.098 (0.097)  Loss:  2.7832 (3.0011)  Acc@1: 47.6562 (37.1477)  Acc@5: 68.7500 (63.5570)
2024-04-06 14:31:33,482 - train - INFO - Test: [  78/78]  Time: 0.052 (0.092)  Loss:  3.0801 (2.9857)  Acc@1: 25.0000 (37.2500)  Acc@5: 56.2500 (63.8200)
2024-04-06 14:31:34,974 - train - INFO - Train: 4 [   0/781 (  0%)]  Loss:  4.606521 (4.6065)  Time: 1.354s,   94.54/s  (1.354s,   94.54/s)  LR: 2.006e-04  Data: 0.185 (0.185)
2024-04-06 14:32:16,613 - train - INFO - Train: 4 [  50/781 (  6%)]  Loss:  4.698939 (4.4625)  Time: 0.979s,  130.70/s  (0.843s,  151.84/s)  LR: 2.006e-04  Data: 0.010 (0.010)
2024-04-06 14:32:56,850 - train - INFO - Train: 4 [ 100/781 ( 13%)]  Loss:  4.042723 (4.4499)  Time: 0.811s,  157.85/s  (0.824s,  155.33/s)  LR: 2.006e-04  Data: 0.005 (0.008)
2024-04-06 14:33:36,545 - train - INFO - Train: 4 [ 150/781 ( 19%)]  Loss:  4.277654 (4.4475)  Time: 0.811s,  157.88/s  (0.814s,  157.24/s)  LR: 2.006e-04  Data: 0.009 (0.008)
2024-04-06 14:34:17,677 - train - INFO - Train: 4 [ 200/781 ( 26%)]  Loss:  4.314928 (4.4396)  Time: 0.759s,  168.61/s  (0.816s,  156.83/s)  LR: 2.006e-04  Data: 0.005 (0.007)
2024-04-06 14:34:56,560 - train - INFO - Train: 4 [ 250/781 ( 32%)]  Loss:  4.071448 (4.4472)  Time: 0.798s,  160.46/s  (0.808s,  158.32/s)  LR: 2.006e-04  Data: 0.010 (0.007)
2024-04-06 14:35:36,108 - train - INFO - Train: 4 [ 300/781 ( 38%)]  Loss:  4.778444 (4.4413)  Time: 0.770s,  166.23/s  (0.806s,  158.89/s)  LR: 2.006e-04  Data: 0.006 (0.007)
2024-04-06 14:36:16,220 - train - INFO - Train: 4 [ 350/781 ( 45%)]  Loss:  4.752504 (4.4408)  Time: 0.749s,  170.92/s  (0.805s,  158.99/s)  LR: 2.006e-04  Data: 0.005 (0.007)
2024-04-06 14:36:55,487 - train - INFO - Train: 4 [ 400/781 ( 51%)]  Loss:  4.002965 (4.4294)  Time: 0.758s,  168.96/s  (0.803s,  159.48/s)  LR: 2.006e-04  Data: 0.006 (0.007)
2024-04-06 14:37:34,205 - train - INFO - Train: 4 [ 450/781 ( 58%)]  Loss:  3.882261 (4.4187)  Time: 0.799s,  160.27/s  (0.799s,  160.10/s)  LR: 2.006e-04  Data: 0.005 (0.007)
2024-04-06 14:38:15,267 - train - INFO - Train: 4 [ 500/781 ( 64%)]  Loss:  4.321748 (4.4147)  Time: 0.800s,  159.95/s  (0.802s,  159.67/s)  LR: 2.006e-04  Data: 0.005 (0.007)
2024-04-06 14:38:56,017 - train - INFO - Train: 4 [ 550/781 ( 71%)]  Loss:  4.477312 (4.4005)  Time: 0.846s,  151.28/s  (0.803s,  159.43/s)  LR: 2.006e-04  Data: 0.007 (0.007)
2024-04-06 14:39:39,655 - train - INFO - Train: 4 [ 600/781 ( 77%)]  Loss:  4.002419 (4.3905)  Time: 0.740s,  173.01/s  (0.809s,  158.28/s)  LR: 2.006e-04  Data: 0.005 (0.007)
2024-04-06 14:40:18,161 - train - INFO - Train: 4 [ 650/781 ( 83%)]  Loss:  4.314084 (4.3792)  Time: 0.760s,  168.35/s  (0.806s,  158.86/s)  LR: 2.006e-04  Data: 0.005 (0.007)
2024-04-06 14:40:56,654 - train - INFO - Train: 4 [ 700/781 ( 90%)]  Loss:  4.572539 (4.3734)  Time: 0.753s,  169.95/s  (0.803s,  159.37/s)  LR: 2.006e-04  Data: 0.005 (0.007)
2024-04-06 14:41:34,990 - train - INFO - Train: 4 [ 750/781 ( 96%)]  Loss:  3.985450 (4.3661)  Time: 0.752s,  170.32/s  (0.801s,  159.85/s)  LR: 2.006e-04  Data: 0.005 (0.007)
2024-04-06 14:41:59,382 - train - INFO - Train: 4 [ 780/781 (100%)]  Loss:  3.976706 (4.3610)  Time: 0.768s,  166.60/s  (0.801s,  159.76/s)  LR: 2.006e-04  Data: 0.000 (0.007)
2024-04-06 14:41:59,383 - train - INFO - True
2024-04-06 14:41:59,384 - train - INFO - alphas:tensor([0.2395, 0.2306, 0.1740, 0.1773, 0.1786], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,384 - train - INFO - tau:0.9801
2024-04-06 14:41:59,384 - train - INFO - True
2024-04-06 14:41:59,386 - train - INFO - alphas:tensor([0.2419, 0.2221, 0.1737, 0.1791, 0.1832], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,386 - train - INFO - tau:0.9801
2024-04-06 14:41:59,386 - train - INFO - True
2024-04-06 14:41:59,387 - train - INFO - alphas:tensor([0.3324, 0.2597, 0.1374, 0.1350, 0.1355], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,387 - train - INFO - tau:0.9801
2024-04-06 14:41:59,387 - train - INFO - True
2024-04-06 14:41:59,388 - train - INFO - alphas:tensor([0.3400, 0.2337, 0.1405, 0.1434, 0.1424], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,388 - train - INFO - tau:0.9801
2024-04-06 14:41:59,389 - train - INFO - True
2024-04-06 14:41:59,390 - train - INFO - alphas:tensor([0.3032, 0.2511, 0.1455, 0.1488, 0.1515], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,390 - train - INFO - tau:0.9801
2024-04-06 14:41:59,390 - train - INFO - True
2024-04-06 14:41:59,391 - train - INFO - alphas:tensor([0.3093, 0.2306, 0.1518, 0.1534, 0.1550], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,391 - train - INFO - tau:0.9801
2024-04-06 14:41:59,391 - train - INFO - True
2024-04-06 14:41:59,392 - train - INFO - alphas:tensor([0.3214, 0.2575, 0.1390, 0.1403, 0.1419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,392 - train - INFO - tau:0.9801
2024-04-06 14:41:59,393 - train - INFO - True
2024-04-06 14:41:59,394 - train - INFO - alphas:tensor([0.3100, 0.2436, 0.1529, 0.1475, 0.1460], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,394 - train - INFO - tau:0.9801
2024-04-06 14:41:59,394 - train - INFO - True
2024-04-06 14:41:59,395 - train - INFO - alphas:tensor([0.3203, 0.2509, 0.1402, 0.1430, 0.1455], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,395 - train - INFO - tau:0.9801
2024-04-06 14:41:59,395 - train - INFO - True
2024-04-06 14:41:59,396 - train - INFO - alphas:tensor([0.3281, 0.2310, 0.1473, 0.1461, 0.1476], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,396 - train - INFO - tau:0.9801
2024-04-06 14:41:59,396 - train - INFO - True
2024-04-06 14:41:59,398 - train - INFO - alphas:tensor([0.3315, 0.2487, 0.1382, 0.1391, 0.1425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,398 - train - INFO - tau:0.9801
2024-04-06 14:41:59,398 - train - INFO - True
2024-04-06 14:41:59,399 - train - INFO - alphas:tensor([0.3121, 0.2280, 0.1558, 0.1538, 0.1503], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,399 - train - INFO - tau:0.9801
2024-04-06 14:41:59,399 - train - INFO - True
2024-04-06 14:41:59,400 - train - INFO - alphas:tensor([0.3212, 0.2490, 0.1402, 0.1438, 0.1457], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,400 - train - INFO - tau:0.9801
2024-04-06 14:41:59,400 - train - INFO - True
2024-04-06 14:41:59,401 - train - INFO - alphas:tensor([0.3414, 0.2197, 0.1470, 0.1454, 0.1465], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,401 - train - INFO - tau:0.9801
2024-04-06 14:41:59,402 - train - INFO - True
2024-04-06 14:41:59,403 - train - INFO - alphas:tensor([0.3233, 0.2428, 0.1483, 0.1423, 0.1433], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,403 - train - INFO - tau:0.9801
2024-04-06 14:41:59,403 - train - INFO - True
2024-04-06 14:41:59,404 - train - INFO - alphas:tensor([0.2976, 0.2302, 0.1602, 0.1541, 0.1578], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,404 - train - INFO - tau:0.9801
2024-04-06 14:41:59,404 - train - INFO - True
2024-04-06 14:41:59,405 - train - INFO - alphas:tensor([0.3097, 0.2464, 0.1447, 0.1483, 0.1510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,405 - train - INFO - tau:0.9801
2024-04-06 14:41:59,405 - train - INFO - True
2024-04-06 14:41:59,406 - train - INFO - alphas:tensor([0.3306, 0.2182, 0.1515, 0.1502, 0.1495], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,407 - train - INFO - tau:0.9801
2024-04-06 14:41:59,407 - train - INFO - True
2024-04-06 14:41:59,408 - train - INFO - alphas:tensor([0.3222, 0.2435, 0.1473, 0.1439, 0.1431], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,408 - train - INFO - tau:0.9801
2024-04-06 14:41:59,408 - train - INFO - True
2024-04-06 14:41:59,409 - train - INFO - alphas:tensor([0.2981, 0.2239, 0.1626, 0.1578, 0.1576], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,409 - train - INFO - tau:0.9801
2024-04-06 14:41:59,409 - train - INFO - True
2024-04-06 14:41:59,410 - train - INFO - alphas:tensor([0.2960, 0.2361, 0.1531, 0.1560, 0.1588], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,410 - train - INFO - tau:0.9801
2024-04-06 14:41:59,410 - train - INFO - True
2024-04-06 14:41:59,411 - train - INFO - alphas:tensor([0.3314, 0.2121, 0.1511, 0.1521, 0.1533], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,412 - train - INFO - tau:0.9801
2024-04-06 14:41:59,412 - train - INFO - True
2024-04-06 14:41:59,413 - train - INFO - alphas:tensor([0.3333, 0.2374, 0.1439, 0.1425, 0.1429], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,413 - train - INFO - tau:0.9801
2024-04-06 14:41:59,413 - train - INFO - True
2024-04-06 14:41:59,414 - train - INFO - alphas:tensor([0.2833, 0.2185, 0.1696, 0.1638, 0.1647], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,414 - train - INFO - tau:0.9801
2024-04-06 14:41:59,414 - train - INFO - True
2024-04-06 14:41:59,415 - train - INFO - alphas:tensor([0.2930, 0.2359, 0.1518, 0.1585, 0.1608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,415 - train - INFO - tau:0.9801
2024-04-06 14:41:59,415 - train - INFO - True
2024-04-06 14:41:59,416 - train - INFO - alphas:tensor([0.3216, 0.2130, 0.1562, 0.1528, 0.1564], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,416 - train - INFO - tau:0.9801
2024-04-06 14:41:59,417 - train - INFO - True
2024-04-06 14:41:59,418 - train - INFO - alphas:tensor([0.3479, 0.2373, 0.1398, 0.1378, 0.1372], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,418 - train - INFO - tau:0.9801
2024-04-06 14:41:59,418 - train - INFO - True
2024-04-06 14:41:59,419 - train - INFO - alphas:tensor([0.3057, 0.2237, 0.1605, 0.1560, 0.1542], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,419 - train - INFO - tau:0.9801
2024-04-06 14:41:59,419 - train - INFO - True
2024-04-06 14:41:59,420 - train - INFO - alphas:tensor([0.2883, 0.2387, 0.1544, 0.1583, 0.1602], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,420 - train - INFO - tau:0.9801
2024-04-06 14:41:59,420 - train - INFO - True
2024-04-06 14:41:59,421 - train - INFO - alphas:tensor([0.3208, 0.2205, 0.1522, 0.1515, 0.1550], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,421 - train - INFO - tau:0.9801
2024-04-06 14:41:59,421 - train - INFO - True
2024-04-06 14:41:59,422 - train - INFO - alphas:tensor([0.3478, 0.2446, 0.1361, 0.1351, 0.1363], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,423 - train - INFO - tau:0.9801
2024-04-06 14:41:59,423 - train - INFO - True
2024-04-06 14:41:59,424 - train - INFO - alphas:tensor([0.3180, 0.2326, 0.1522, 0.1484, 0.1489], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,424 - train - INFO - tau:0.9801
2024-04-06 14:41:59,424 - train - INFO - True
2024-04-06 14:41:59,425 - train - INFO - alphas:tensor([0.2756, 0.2437, 0.1568, 0.1605, 0.1634], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,425 - train - INFO - tau:0.9801
2024-04-06 14:41:59,425 - train - INFO - True
2024-04-06 14:41:59,426 - train - INFO - alphas:tensor([0.2929, 0.2245, 0.1596, 0.1610, 0.1621], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,426 - train - INFO - tau:0.9801
2024-04-06 14:41:59,426 - train - INFO - True
2024-04-06 14:41:59,427 - train - INFO - alphas:tensor([0.3393, 0.2467, 0.1359, 0.1386, 0.1395], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,427 - train - INFO - tau:0.9801
2024-04-06 14:41:59,427 - train - INFO - True
2024-04-06 14:41:59,428 - train - INFO - alphas:tensor([0.3154, 0.2378, 0.1474, 0.1486, 0.1509], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,429 - train - INFO - tau:0.9801
2024-04-06 14:41:59,429 - train - INFO - True
2024-04-06 14:41:59,430 - train - INFO - alphas:tensor([0.3918, 0.2007, 0.2001, 0.2074], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:41:59,430 - train - INFO - tau:0.9801
2024-04-06 14:41:59,430 - train - INFO - avg block size:1.0
2024-04-06 14:41:59,684 - train - INFO - Test: [   0/78]  Time: 0.252 (0.252)  Loss:  1.6035 (1.6035)  Acc@1: 63.2812 (63.2812)  Acc@5: 85.1562 (85.1562)
2024-04-06 14:42:04,492 - train - INFO - Test: [  50/78]  Time: 0.083 (0.099)  Loss:  2.3867 (2.4713)  Acc@1: 49.2188 (45.9406)  Acc@5: 76.5625 (72.9013)
2024-04-06 14:42:06,796 - train - INFO - Test: [  78/78]  Time: 0.053 (0.093)  Loss:  2.7031 (2.4777)  Acc@1: 37.5000 (45.7900)  Acc@5: 68.7500 (72.6600)
2024-04-06 14:42:08,185 - train - INFO - Train: 5 [   0/781 (  0%)]  Loss:  3.757934 (3.7579)  Time: 1.329s,   96.34/s  (1.329s,   96.34/s)  LR: 2.505e-04  Data: 0.205 (0.205)
2024-04-06 14:42:48,200 - train - INFO - Train: 5 [  50/781 (  6%)]  Loss:  4.550851 (4.2785)  Time: 0.787s,  162.66/s  (0.811s,  157.90/s)  LR: 2.505e-04  Data: 0.007 (0.011)
2024-04-06 14:43:28,168 - train - INFO - Train: 5 [ 100/781 ( 13%)]  Loss:  4.020814 (4.2631)  Time: 0.779s,  164.27/s  (0.805s,  159.00/s)  LR: 2.505e-04  Data: 0.007 (0.009)
2024-04-06 14:44:10,595 - train - INFO - Train: 5 [ 150/781 ( 19%)]  Loss:  4.013896 (4.2227)  Time: 1.000s,  128.01/s  (0.819s,  156.21/s)  LR: 2.505e-04  Data: 0.006 (0.008)
2024-04-06 14:44:56,022 - train - INFO - Train: 5 [ 200/781 ( 26%)]  Loss:  4.119987 (4.2227)  Time: 0.772s,  165.82/s  (0.842s,  152.09/s)  LR: 2.505e-04  Data: 0.006 (0.008)
2024-04-06 14:45:44,078 - train - INFO - Train: 5 [ 250/781 ( 32%)]  Loss:  4.524232 (4.2097)  Time: 0.923s,  138.69/s  (0.865s,  147.91/s)  LR: 2.505e-04  Data: 0.006 (0.008)
2024-04-06 14:46:28,251 - train - INFO - Train: 5 [ 300/781 ( 38%)]  Loss:  4.335880 (4.1888)  Time: 1.105s,  115.87/s  (0.868s,  147.40/s)  LR: 2.505e-04  Data: 0.009 (0.008)
2024-04-06 14:47:15,762 - train - INFO - Train: 5 [ 350/781 ( 45%)]  Loss:  4.167096 (4.1734)  Time: 0.797s,  160.56/s  (0.880s,  145.45/s)  LR: 2.505e-04  Data: 0.006 (0.008)
2024-04-06 14:48:01,949 - train - INFO - Train: 5 [ 400/781 ( 51%)]  Loss:  4.492857 (4.1682)  Time: 0.794s,  161.26/s  (0.885s,  144.56/s)  LR: 2.505e-04  Data: 0.006 (0.008)
2024-04-06 14:48:49,313 - train - INFO - Train: 5 [ 450/781 ( 58%)]  Loss:  4.325448 (4.1653)  Time: 0.787s,  162.69/s  (0.892s,  143.45/s)  LR: 2.505e-04  Data: 0.007 (0.008)
2024-04-06 14:49:35,524 - train - INFO - Train: 5 [ 500/781 ( 64%)]  Loss:  3.948036 (4.1522)  Time: 0.939s,  136.25/s  (0.895s,  142.94/s)  LR: 2.505e-04  Data: 0.011 (0.008)
2024-04-06 14:50:21,624 - train - INFO - Train: 5 [ 550/781 ( 71%)]  Loss:  3.422634 (4.1431)  Time: 1.056s,  121.20/s  (0.898s,  142.56/s)  LR: 2.505e-04  Data: 0.009 (0.008)
2024-04-06 14:51:05,290 - train - INFO - Train: 5 [ 600/781 ( 77%)]  Loss:  4.289133 (4.1376)  Time: 0.779s,  164.27/s  (0.896s,  142.88/s)  LR: 2.505e-04  Data: 0.007 (0.008)
2024-04-06 14:51:50,805 - train - INFO - Train: 5 [ 650/781 ( 83%)]  Loss:  3.395687 (4.1302)  Time: 0.956s,  133.93/s  (0.897s,  142.71/s)  LR: 2.505e-04  Data: 0.005 (0.008)
2024-04-06 14:52:34,149 - train - INFO - Train: 5 [ 700/781 ( 90%)]  Loss:  4.100037 (4.1257)  Time: 0.776s,  164.99/s  (0.895s,  143.05/s)  LR: 2.505e-04  Data: 0.005 (0.008)
2024-04-06 14:53:18,079 - train - INFO - Train: 5 [ 750/781 ( 96%)]  Loss:  4.045691 (4.1210)  Time: 0.822s,  155.75/s  (0.894s,  143.22/s)  LR: 2.505e-04  Data: 0.009 (0.008)
2024-04-06 14:53:45,637 - train - INFO - Train: 5 [ 780/781 (100%)]  Loss:  4.367998 (4.1216)  Time: 0.765s,  167.42/s  (0.895s,  143.07/s)  LR: 2.505e-04  Data: 0.000 (0.008)
2024-04-06 14:53:45,638 - train - INFO - True
2024-04-06 14:53:45,639 - train - INFO - alphas:tensor([0.2525, 0.2374, 0.1659, 0.1709, 0.1732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,639 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,640 - train - INFO - True
2024-04-06 14:53:45,642 - train - INFO - alphas:tensor([0.2579, 0.2216, 0.1662, 0.1742, 0.1801], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,642 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,642 - train - INFO - True
2024-04-06 14:53:45,644 - train - INFO - alphas:tensor([0.3900, 0.2418, 0.1231, 0.1220, 0.1231], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,644 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,645 - train - INFO - True
2024-04-06 14:53:45,646 - train - INFO - alphas:tensor([0.3949, 0.2154, 0.1267, 0.1314, 0.1316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,647 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,647 - train - INFO - True
2024-04-06 14:53:45,648 - train - INFO - alphas:tensor([0.3498, 0.2372, 0.1327, 0.1382, 0.1421], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,649 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,649 - train - INFO - True
2024-04-06 14:53:45,650 - train - INFO - alphas:tensor([0.3608, 0.2184, 0.1370, 0.1408, 0.1430], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,651 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,651 - train - INFO - True
2024-04-06 14:53:45,652 - train - INFO - alphas:tensor([0.3917, 0.2418, 0.1201, 0.1218, 0.1246], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,653 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,653 - train - INFO - True
2024-04-06 14:53:45,654 - train - INFO - alphas:tensor([0.3758, 0.2327, 0.1339, 0.1294, 0.1283], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,655 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,655 - train - INFO - True
2024-04-06 14:53:45,656 - train - INFO - alphas:tensor([0.3751, 0.2302, 0.1272, 0.1320, 0.1355], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,657 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,657 - train - INFO - True
2024-04-06 14:53:45,658 - train - INFO - alphas:tensor([0.3920, 0.2137, 0.1309, 0.1305, 0.1330], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,659 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,659 - train - INFO - True
2024-04-06 14:53:45,660 - train - INFO - alphas:tensor([0.4106, 0.2294, 0.1173, 0.1195, 0.1233], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,660 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,661 - train - INFO - True
2024-04-06 14:53:45,662 - train - INFO - alphas:tensor([0.3798, 0.2197, 0.1353, 0.1342, 0.1309], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,662 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,662 - train - INFO - True
2024-04-06 14:53:45,664 - train - INFO - alphas:tensor([0.3833, 0.2288, 0.1246, 0.1301, 0.1333], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,664 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,664 - train - INFO - True
2024-04-06 14:53:45,666 - train - INFO - alphas:tensor([0.4151, 0.1989, 0.1286, 0.1279, 0.1295], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,666 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,666 - train - INFO - True
2024-04-06 14:53:45,668 - train - INFO - alphas:tensor([0.3979, 0.2301, 0.1271, 0.1217, 0.1232], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,668 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,668 - train - INFO - True
2024-04-06 14:53:45,670 - train - INFO - alphas:tensor([0.3610, 0.2254, 0.1401, 0.1346, 0.1388], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,670 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,670 - train - INFO - True
2024-04-06 14:53:45,671 - train - INFO - alphas:tensor([0.3755, 0.2303, 0.1263, 0.1319, 0.1360], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,671 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,672 - train - INFO - True
2024-04-06 14:53:45,673 - train - INFO - alphas:tensor([0.4069, 0.1985, 0.1320, 0.1318, 0.1308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,673 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,673 - train - INFO - True
2024-04-06 14:53:45,675 - train - INFO - alphas:tensor([0.3995, 0.2266, 0.1264, 0.1240, 0.1235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,675 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,675 - train - INFO - True
2024-04-06 14:53:45,676 - train - INFO - alphas:tensor([0.3596, 0.2181, 0.1439, 0.1395, 0.1388], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,677 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,677 - train - INFO - True
2024-04-06 14:53:45,678 - train - INFO - alphas:tensor([0.3532, 0.2268, 0.1354, 0.1403, 0.1443], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,678 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,678 - train - INFO - True
2024-04-06 14:53:45,680 - train - INFO - alphas:tensor([0.4047, 0.1933, 0.1327, 0.1340, 0.1354], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,680 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,680 - train - INFO - True
2024-04-06 14:53:45,681 - train - INFO - alphas:tensor([0.4189, 0.2200, 0.1203, 0.1202, 0.1206], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,682 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,682 - train - INFO - True
2024-04-06 14:53:45,685 - train - INFO - alphas:tensor([0.3473, 0.2130, 0.1502, 0.1443, 0.1453], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,685 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,685 - train - INFO - True
2024-04-06 14:53:45,686 - train - INFO - alphas:tensor([0.3470, 0.2262, 0.1350, 0.1441, 0.1477], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,687 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,687 - train - INFO - True
2024-04-06 14:53:45,688 - train - INFO - alphas:tensor([0.3910, 0.1958, 0.1380, 0.1354, 0.1398], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,688 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,688 - train - INFO - True
2024-04-06 14:53:45,690 - train - INFO - alphas:tensor([0.4369, 0.2094, 0.1184, 0.1174, 0.1179], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,690 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,690 - train - INFO - True
2024-04-06 14:53:45,691 - train - INFO - alphas:tensor([0.3760, 0.2136, 0.1391, 0.1365, 0.1347], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,691 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,692 - train - INFO - True
2024-04-06 14:53:45,693 - train - INFO - alphas:tensor([0.3361, 0.2291, 0.1399, 0.1460, 0.1490], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,693 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,693 - train - INFO - True
2024-04-06 14:53:45,694 - train - INFO - alphas:tensor([0.3902, 0.2011, 0.1346, 0.1350, 0.1391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,695 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,695 - train - INFO - True
2024-04-06 14:53:45,696 - train - INFO - alphas:tensor([0.4308, 0.2127, 0.1178, 0.1183, 0.1204], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,696 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,696 - train - INFO - True
2024-04-06 14:53:45,697 - train - INFO - alphas:tensor([0.3915, 0.2131, 0.1331, 0.1309, 0.1314], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,698 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,698 - train - INFO - True
2024-04-06 14:53:45,699 - train - INFO - alphas:tensor([0.3202, 0.2403, 0.1408, 0.1471, 0.1516], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,699 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,699 - train - INFO - True
2024-04-06 14:53:45,700 - train - INFO - alphas:tensor([0.3574, 0.2135, 0.1408, 0.1432, 0.1451], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,700 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,701 - train - INFO - True
2024-04-06 14:53:45,702 - train - INFO - alphas:tensor([0.4194, 0.2148, 0.1182, 0.1230, 0.1245], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,702 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,702 - train - INFO - True
2024-04-06 14:53:45,703 - train - INFO - alphas:tensor([0.3856, 0.2180, 0.1295, 0.1320, 0.1349], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,703 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,703 - train - INFO - True
2024-04-06 14:53:45,705 - train - INFO - alphas:tensor([0.4447, 0.1744, 0.1855, 0.1953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 14:53:45,705 - train - INFO - tau:0.9702989999999999
2024-04-06 14:53:45,705 - train - INFO - avg block size:1.0
2024-04-06 14:53:45,941 - train - INFO - Test: [   0/78]  Time: 0.231 (0.231)  Loss:  1.1699 (1.1699)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.9688 (92.9688)
2024-04-06 14:53:50,881 - train - INFO - Test: [  50/78]  Time: 0.127 (0.101)  Loss:  2.1602 (2.1117)  Acc@1: 55.4688 (52.5429)  Acc@5: 78.1250 (77.8952)
2024-04-06 14:53:53,863 - train - INFO - Test: [  78/78]  Time: 0.058 (0.103)  Loss:  1.5703 (2.1452)  Acc@1: 56.2500 (51.6100)  Acc@5: 100.0000 (77.1900)
2024-04-06 14:53:55,155 - train - INFO - Train: 6 [   0/781 (  0%)]  Loss:  3.791361 (3.7914)  Time: 1.219s,  105.02/s  (1.219s,  105.02/s)  LR: 3.004e-04  Data: 0.164 (0.164)
2024-04-06 14:54:39,404 - train - INFO - Train: 6 [  50/781 (  6%)]  Loss:  4.309972 (3.9733)  Time: 0.831s,  154.07/s  (0.891s,  143.58/s)  LR: 3.004e-04  Data: 0.009 (0.010)
2024-04-06 14:55:22,499 - train - INFO - Train: 6 [ 100/781 ( 13%)]  Loss:  4.385310 (3.9933)  Time: 1.026s,  124.72/s  (0.877s,  145.98/s)  LR: 3.004e-04  Data: 0.006 (0.009)
2024-04-06 14:56:04,431 - train - INFO - Train: 6 [ 150/781 ( 19%)]  Loss:  4.359577 (4.0517)  Time: 0.831s,  154.02/s  (0.864s,  148.12/s)  LR: 3.004e-04  Data: 0.008 (0.009)
2024-04-06 14:56:47,148 - train - INFO - Train: 6 [ 200/781 ( 26%)]  Loss:  3.626965 (4.0633)  Time: 1.058s,  121.01/s  (0.862s,  148.54/s)  LR: 3.004e-04  Data: 0.010 (0.008)
2024-04-06 14:57:32,123 - train - INFO - Train: 6 [ 250/781 ( 32%)]  Loss:  3.587440 (4.0427)  Time: 0.775s,  165.14/s  (0.869s,  147.26/s)  LR: 3.004e-04  Data: 0.006 (0.008)
2024-04-06 14:58:13,503 - train - INFO - Train: 6 [ 300/781 ( 38%)]  Loss:  4.127263 (4.0338)  Time: 0.776s,  164.99/s  (0.862s,  148.44/s)  LR: 3.004e-04  Data: 0.005 (0.008)
2024-04-06 14:58:54,697 - train - INFO - Train: 6 [ 350/781 ( 45%)]  Loss:  3.331969 (4.0286)  Time: 0.774s,  165.39/s  (0.857s,  149.39/s)  LR: 3.004e-04  Data: 0.005 (0.008)
2024-04-06 14:59:36,932 - train - INFO - Train: 6 [ 400/781 ( 51%)]  Loss:  3.859205 (4.0308)  Time: 1.064s,  120.28/s  (0.855s,  149.65/s)  LR: 3.004e-04  Data: 0.009 (0.008)
2024-04-06 15:00:20,421 - train - INFO - Train: 6 [ 450/781 ( 58%)]  Loss:  3.944421 (4.0295)  Time: 0.821s,  155.87/s  (0.857s,  149.37/s)  LR: 3.004e-04  Data: 0.008 (0.008)
2024-04-06 15:01:05,580 - train - INFO - Train: 6 [ 500/781 ( 64%)]  Loss:  4.234650 (4.0194)  Time: 0.940s,  136.20/s  (0.862s,  148.57/s)  LR: 3.004e-04  Data: 0.005 (0.008)
2024-04-06 15:01:56,209 - train - INFO - Train: 6 [ 550/781 ( 71%)]  Loss:  3.209619 (4.0116)  Time: 1.148s,  111.53/s  (0.875s,  146.25/s)  LR: 3.004e-04  Data: 0.009 (0.008)
2024-04-06 15:02:45,181 - train - INFO - Train: 6 [ 600/781 ( 77%)]  Loss:  4.166325 (4.0130)  Time: 0.815s,  157.08/s  (0.884s,  144.81/s)  LR: 3.004e-04  Data: 0.005 (0.008)
2024-04-06 15:03:33,703 - train - INFO - Train: 6 [ 650/781 ( 83%)]  Loss:  3.521748 (4.0083)  Time: 1.244s,  102.93/s  (0.891s,  143.73/s)  LR: 3.004e-04  Data: 0.010 (0.008)
2024-04-06 15:04:21,015 - train - INFO - Train: 6 [ 700/781 ( 90%)]  Loss:  4.151230 (3.9942)  Time: 0.949s,  134.89/s  (0.895s,  143.10/s)  LR: 3.004e-04  Data: 0.009 (0.008)
2024-04-06 15:05:09,997 - train - INFO - Train: 6 [ 750/781 ( 96%)]  Loss:  3.307767 (3.9911)  Time: 0.900s,  142.25/s  (0.900s,  142.20/s)  LR: 3.004e-04  Data: 0.010 (0.008)
2024-04-06 15:05:39,687 - train - INFO - Train: 6 [ 780/781 (100%)]  Loss:  4.120565 (3.9893)  Time: 1.060s,  120.78/s  (0.904s,  141.66/s)  LR: 3.004e-04  Data: 0.001 (0.008)
2024-04-06 15:05:39,689 - train - INFO - True
2024-04-06 15:05:39,692 - train - INFO - alphas:tensor([0.2643, 0.2409, 0.1598, 0.1660, 0.1690], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,692 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,692 - train - INFO - True
2024-04-06 15:05:39,694 - train - INFO - alphas:tensor([0.2753, 0.2194, 0.1586, 0.1693, 0.1774], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,695 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,695 - train - INFO - True
2024-04-06 15:05:39,697 - train - INFO - alphas:tensor([0.4414, 0.2180, 0.1130, 0.1129, 0.1147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,697 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,697 - train - INFO - True
2024-04-06 15:05:39,699 - train - INFO - alphas:tensor([0.4403, 0.1963, 0.1164, 0.1229, 0.1242], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,699 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,699 - train - INFO - True
2024-04-06 15:05:39,701 - train - INFO - alphas:tensor([0.3911, 0.2166, 0.1243, 0.1315, 0.1365], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,701 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,701 - train - INFO - True
2024-04-06 15:05:39,703 - train - INFO - alphas:tensor([0.4109, 0.2015, 0.1246, 0.1300, 0.1330], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,703 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,703 - train - INFO - True
2024-04-06 15:05:39,705 - train - INFO - alphas:tensor([0.4673, 0.2102, 0.1048, 0.1071, 0.1106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,705 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,705 - train - INFO - True
2024-04-06 15:05:39,707 - train - INFO - alphas:tensor([0.4490, 0.2082, 0.1165, 0.1135, 0.1128], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,707 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,708 - train - INFO - True
2024-04-06 15:05:39,711 - train - INFO - alphas:tensor([0.4258, 0.2042, 0.1174, 0.1238, 0.1287], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,711 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,711 - train - INFO - True
2024-04-06 15:05:39,713 - train - INFO - alphas:tensor([0.4513, 0.1923, 0.1169, 0.1181, 0.1213], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,713 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,714 - train - INFO - True
2024-04-06 15:05:39,715 - train - INFO - alphas:tensor([0.4944, 0.1947, 0.1003, 0.1034, 0.1073], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,715 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,715 - train - INFO - True
2024-04-06 15:05:39,717 - train - INFO - alphas:tensor([0.4526, 0.1980, 0.1173, 0.1173, 0.1147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,717 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,717 - train - INFO - True
2024-04-06 15:05:39,719 - train - INFO - alphas:tensor([0.4417, 0.1999, 0.1128, 0.1205, 0.1251], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,719 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,719 - train - INFO - True
2024-04-06 15:05:39,721 - train - INFO - alphas:tensor([0.4840, 0.1740, 0.1129, 0.1134, 0.1157], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,721 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,721 - train - INFO - True
2024-04-06 15:05:39,723 - train - INFO - alphas:tensor([0.4782, 0.2030, 0.1087, 0.1041, 0.1060], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,723 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,723 - train - INFO - True
2024-04-06 15:05:39,725 - train - INFO - alphas:tensor([0.4315, 0.2079, 0.1217, 0.1171, 0.1217], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,725 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,725 - train - INFO - True
2024-04-06 15:05:39,726 - train - INFO - alphas:tensor([0.4404, 0.2028, 0.1120, 0.1196, 0.1251], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,727 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,727 - train - INFO - True
2024-04-06 15:05:39,728 - train - INFO - alphas:tensor([0.4820, 0.1737, 0.1143, 0.1153, 0.1147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,728 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,729 - train - INFO - True
2024-04-06 15:05:39,730 - train - INFO - alphas:tensor([0.4832, 0.1954, 0.1079, 0.1067, 0.1068], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,730 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,730 - train - INFO - True
2024-04-06 15:05:39,732 - train - INFO - alphas:tensor([0.4265, 0.2004, 0.1268, 0.1234, 0.1230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,732 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,732 - train - INFO - True
2024-04-06 15:05:39,734 - train - INFO - alphas:tensor([0.4142, 0.2045, 0.1212, 0.1276, 0.1325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,734 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,734 - train - INFO - True
2024-04-06 15:05:39,735 - train - INFO - alphas:tensor([0.4782, 0.1703, 0.1155, 0.1171, 0.1189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,736 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,736 - train - INFO - True
2024-04-06 15:05:39,737 - train - INFO - alphas:tensor([0.5143, 0.1864, 0.0989, 0.0999, 0.1006], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,737 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,737 - train - INFO - True
2024-04-06 15:05:39,739 - train - INFO - alphas:tensor([0.4268, 0.1940, 0.1297, 0.1241, 0.1254], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,739 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,739 - train - INFO - True
2024-04-06 15:05:39,741 - train - INFO - alphas:tensor([0.4053, 0.2059, 0.1205, 0.1318, 0.1365], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,741 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,741 - train - INFO - True
2024-04-06 15:05:39,742 - train - INFO - alphas:tensor([0.4637, 0.1720, 0.1209, 0.1191, 0.1243], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,742 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,743 - train - INFO - True
2024-04-06 15:05:39,744 - train - INFO - alphas:tensor([0.5257, 0.1744, 0.0993, 0.0997, 0.1009], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,744 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,744 - train - INFO - True
2024-04-06 15:05:39,746 - train - INFO - alphas:tensor([0.4547, 0.1900, 0.1198, 0.1185, 0.1171], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,746 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,746 - train - INFO - True
2024-04-06 15:05:39,747 - train - INFO - alphas:tensor([0.3881, 0.2097, 0.1269, 0.1354, 0.1400], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,747 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,748 - train - INFO - True
2024-04-06 15:05:39,749 - train - INFO - alphas:tensor([0.4632, 0.1759, 0.1176, 0.1193, 0.1240], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,749 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,749 - train - INFO - True
2024-04-06 15:05:39,751 - train - INFO - alphas:tensor([0.5127, 0.1767, 0.1013, 0.1033, 0.1061], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,751 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,751 - train - INFO - True
2024-04-06 15:05:39,752 - train - INFO - alphas:tensor([0.4683, 0.1836, 0.1162, 0.1154, 0.1164], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,752 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,753 - train - INFO - True
2024-04-06 15:05:39,754 - train - INFO - alphas:tensor([0.3727, 0.2188, 0.1281, 0.1369, 0.1435], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,754 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,754 - train - INFO - True
2024-04-06 15:05:39,755 - train - INFO - alphas:tensor([0.4355, 0.1866, 0.1224, 0.1265, 0.1290], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,756 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,756 - train - INFO - True
2024-04-06 15:05:39,757 - train - INFO - alphas:tensor([0.4990, 0.1790, 0.1024, 0.1088, 0.1109], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,757 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,757 - train - INFO - True
2024-04-06 15:05:39,759 - train - INFO - alphas:tensor([0.4590, 0.1875, 0.1141, 0.1179, 0.1215], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,759 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,759 - train - INFO - True
2024-04-06 15:05:39,760 - train - INFO - alphas:tensor([0.4887, 0.1534, 0.1729, 0.1850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:05:39,760 - train - INFO - tau:0.96059601
2024-04-06 15:05:39,760 - train - INFO - avg block size:1.0
2024-04-06 15:05:39,761 - train - INFO - lasso_alpha:1.1000000000000001e-05
2024-04-06 15:05:40,014 - train - INFO - Test: [   0/78]  Time: 0.247 (0.247)  Loss:  1.1416 (1.1416)  Acc@1: 78.1250 (78.1250)  Acc@5: 90.6250 (90.6250)
2024-04-06 15:05:44,359 - train - INFO - Test: [  50/78]  Time: 0.107 (0.090)  Loss:  2.1699 (1.9170)  Acc@1: 50.0000 (55.9130)  Acc@5: 78.9062 (80.2849)
2024-04-06 15:05:47,054 - train - INFO - Test: [  78/78]  Time: 0.077 (0.092)  Loss:  1.9072 (1.9525)  Acc@1: 37.5000 (55.0100)  Acc@5: 93.7500 (79.7500)
2024-04-06 15:05:48,445 - train - INFO - Train: 7 [   0/781 (  0%)]  Loss:  4.154868 (4.1549)  Time: 1.292s,   99.10/s  (1.292s,   99.10/s)  LR: 3.503e-04  Data: 0.191 (0.191)
2024-04-06 15:06:36,659 - train - INFO - Train: 7 [  50/781 (  6%)]  Loss:  4.306096 (3.9373)  Time: 0.779s,  164.34/s  (0.971s,  131.87/s)  LR: 3.503e-04  Data: 0.005 (0.012)
2024-04-06 15:07:26,260 - train - INFO - Train: 7 [ 100/781 ( 13%)]  Loss:  4.277472 (3.9061)  Time: 0.929s,  137.75/s  (0.981s,  130.45/s)  LR: 3.503e-04  Data: 0.009 (0.010)
2024-04-06 15:08:16,117 - train - INFO - Train: 7 [ 150/781 ( 19%)]  Loss:  4.472877 (3.9302)  Time: 1.099s,  116.47/s  (0.986s,  129.76/s)  LR: 3.503e-04  Data: 0.008 (0.010)
2024-04-06 15:09:06,289 - train - INFO - Train: 7 [ 200/781 ( 26%)]  Loss:  4.263134 (3.9072)  Time: 1.159s,  110.43/s  (0.991s,  129.21/s)  LR: 3.503e-04  Data: 0.011 (0.009)
2024-04-06 15:09:57,804 - train - INFO - Train: 7 [ 250/781 ( 32%)]  Loss:  3.672379 (3.9043)  Time: 0.797s,  160.61/s  (0.999s,  128.19/s)  LR: 3.503e-04  Data: 0.007 (0.009)
2024-04-06 15:10:44,385 - train - INFO - Train: 7 [ 300/781 ( 38%)]  Loss:  3.995820 (3.8947)  Time: 0.911s,  140.48/s  (0.987s,  129.63/s)  LR: 3.503e-04  Data: 0.009 (0.009)
2024-04-06 15:11:34,199 - train - INFO - Train: 7 [ 350/781 ( 45%)]  Loss:  4.108455 (3.8908)  Time: 0.998s,  128.21/s  (0.989s,  129.47/s)  LR: 3.503e-04  Data: 0.010 (0.009)
2024-04-06 15:12:25,532 - train - INFO - Train: 7 [ 400/781 ( 51%)]  Loss:  3.534413 (3.8958)  Time: 0.787s,  162.73/s  (0.993s,  128.85/s)  LR: 3.503e-04  Data: 0.007 (0.009)
2024-04-06 15:13:13,067 - train - INFO - Train: 7 [ 450/781 ( 58%)]  Loss:  3.488968 (3.9071)  Time: 1.103s,  116.00/s  (0.989s,  129.47/s)  LR: 3.503e-04  Data: 0.009 (0.009)
2024-04-06 15:14:00,684 - train - INFO - Train: 7 [ 500/781 ( 64%)]  Loss:  4.229975 (3.8983)  Time: 0.785s,  163.13/s  (0.985s,  129.95/s)  LR: 3.503e-04  Data: 0.006 (0.009)
2024-04-06 15:14:49,225 - train - INFO - Train: 7 [ 550/781 ( 71%)]  Loss:  4.276596 (3.8978)  Time: 1.046s,  122.31/s  (0.984s,  130.12/s)  LR: 3.503e-04  Data: 0.011 (0.009)
2024-04-06 15:15:37,579 - train - INFO - Train: 7 [ 600/781 ( 77%)]  Loss:  4.397984 (3.8924)  Time: 0.845s,  151.41/s  (0.982s,  130.30/s)  LR: 3.503e-04  Data: 0.010 (0.009)
2024-04-06 15:16:25,371 - train - INFO - Train: 7 [ 650/781 ( 83%)]  Loss:  4.258582 (3.8987)  Time: 1.184s,  108.15/s  (0.980s,  130.57/s)  LR: 3.503e-04  Data: 0.010 (0.009)
2024-04-06 15:17:15,069 - train - INFO - Train: 7 [ 700/781 ( 90%)]  Loss:  3.772118 (3.8926)  Time: 0.771s,  165.96/s  (0.981s,  130.44/s)  LR: 3.503e-04  Data: 0.006 (0.009)
2024-04-06 15:17:57,065 - train - INFO - Train: 7 [ 750/781 ( 96%)]  Loss:  4.310015 (3.9012)  Time: 1.050s,  121.90/s  (0.972s,  131.71/s)  LR: 3.503e-04  Data: 0.010 (0.009)
2024-04-06 15:18:22,656 - train - INFO - Train: 7 [ 780/781 (100%)]  Loss:  3.067195 (3.9004)  Time: 0.808s,  158.41/s  (0.967s,  132.33/s)  LR: 3.503e-04  Data: 0.000 (0.008)
2024-04-06 15:18:22,657 - train - INFO - True
2024-04-06 15:18:22,659 - train - INFO - alphas:tensor([0.2729, 0.2414, 0.1560, 0.1630, 0.1667], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,660 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,660 - train - INFO - True
2024-04-06 15:18:22,661 - train - INFO - alphas:tensor([0.2931, 0.2138, 0.1520, 0.1654, 0.1757], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,662 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,662 - train - INFO - True
2024-04-06 15:18:22,663 - train - INFO - alphas:tensor([0.4870, 0.1953, 0.1046, 0.1055, 0.1076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,663 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,664 - train - INFO - True
2024-04-06 15:18:22,665 - train - INFO - alphas:tensor([0.4806, 0.1785, 0.1076, 0.1154, 0.1178], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,665 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,665 - train - INFO - True
2024-04-06 15:18:22,667 - train - INFO - alphas:tensor([0.4246, 0.1971, 0.1181, 0.1271, 0.1331], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,667 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,667 - train - INFO - True
2024-04-06 15:18:22,669 - train - INFO - alphas:tensor([0.4573, 0.1832, 0.1139, 0.1209, 0.1247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,669 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,669 - train - INFO - True
2024-04-06 15:18:22,670 - train - INFO - alphas:tensor([0.5349, 0.1801, 0.0918, 0.0945, 0.0988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,670 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,671 - train - INFO - True
2024-04-06 15:18:22,672 - train - INFO - alphas:tensor([0.5185, 0.1811, 0.1012, 0.0997, 0.0995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,672 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,672 - train - INFO - True
2024-04-06 15:18:22,674 - train - INFO - alphas:tensor([0.4624, 0.1822, 0.1107, 0.1193, 0.1254], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,674 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,674 - train - INFO - True
2024-04-06 15:18:22,675 - train - INFO - alphas:tensor([0.5018, 0.1719, 0.1059, 0.1082, 0.1122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,675 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,676 - train - INFO - True
2024-04-06 15:18:22,677 - train - INFO - alphas:tensor([0.5640, 0.1641, 0.0868, 0.0904, 0.0947], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,677 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,677 - train - INFO - True
2024-04-06 15:18:22,679 - train - INFO - alphas:tensor([0.5181, 0.1732, 0.1027, 0.1040, 0.1021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,679 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,679 - train - INFO - True
2024-04-06 15:18:22,680 - train - INFO - alphas:tensor([0.4855, 0.1753, 0.1046, 0.1142, 0.1204], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,680 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,680 - train - INFO - True
2024-04-06 15:18:22,682 - train - INFO - alphas:tensor([0.5392, 0.1525, 0.1008, 0.1025, 0.1051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,682 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,682 - train - INFO - True
2024-04-06 15:18:22,683 - train - INFO - alphas:tensor([0.5472, 0.1750, 0.0940, 0.0907, 0.0931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,684 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,684 - train - INFO - True
2024-04-06 15:18:22,685 - train - INFO - alphas:tensor([0.4962, 0.1836, 0.1069, 0.1041, 0.1092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,685 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,685 - train - INFO - True
2024-04-06 15:18:22,687 - train - INFO - alphas:tensor([0.4869, 0.1781, 0.1031, 0.1124, 0.1196], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,687 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,687 - train - INFO - True
2024-04-06 15:18:22,688 - train - INFO - alphas:tensor([0.5433, 0.1505, 0.1008, 0.1025, 0.1028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,688 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,688 - train - INFO - True
2024-04-06 15:18:22,690 - train - INFO - alphas:tensor([0.5591, 0.1644, 0.0919, 0.0921, 0.0926], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,690 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,690 - train - INFO - True
2024-04-06 15:18:22,691 - train - INFO - alphas:tensor([0.4917, 0.1764, 0.1115, 0.1101, 0.1103], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,691 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,691 - train - INFO - True
2024-04-06 15:18:22,693 - train - INFO - alphas:tensor([0.4652, 0.1798, 0.1107, 0.1190, 0.1253], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,693 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,693 - train - INFO - True
2024-04-06 15:18:22,694 - train - INFO - alphas:tensor([0.5413, 0.1474, 0.1016, 0.1038, 0.1059], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,694 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,694 - train - INFO - True
2024-04-06 15:18:22,696 - train - INFO - alphas:tensor([0.5949, 0.1541, 0.0824, 0.0837, 0.0849], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,696 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,696 - train - INFO - True
2024-04-06 15:18:22,697 - train - INFO - alphas:tensor([0.5020, 0.1688, 0.1118, 0.1078, 0.1096], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,697 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,697 - train - INFO - True
2024-04-06 15:18:22,698 - train - INFO - alphas:tensor([0.4573, 0.1815, 0.1095, 0.1229, 0.1288], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,699 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,699 - train - INFO - True
2024-04-06 15:18:22,700 - train - INFO - alphas:tensor([0.5300, 0.1490, 0.1056, 0.1051, 0.1104], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,700 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,700 - train - INFO - True
2024-04-06 15:18:22,701 - train - INFO - alphas:tensor([0.5994, 0.1443, 0.0838, 0.0854, 0.0872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,702 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,702 - train - INFO - True
2024-04-06 15:18:22,703 - train - INFO - alphas:tensor([0.5260, 0.1639, 0.1033, 0.1037, 0.1031], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,703 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,703 - train - INFO - True
2024-04-06 15:18:22,704 - train - INFO - alphas:tensor([0.4379, 0.1834, 0.1171, 0.1277, 0.1339], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,704 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,704 - train - INFO - True
2024-04-06 15:18:22,706 - train - INFO - alphas:tensor([0.5273, 0.1520, 0.1035, 0.1061, 0.1112], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,706 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,706 - train - INFO - True
2024-04-06 15:18:22,707 - train - INFO - alphas:tensor([0.5819, 0.1469, 0.0873, 0.0902, 0.0937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,707 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,707 - train - INFO - True
2024-04-06 15:18:22,708 - train - INFO - alphas:tensor([0.5379, 0.1555, 0.1011, 0.1021, 0.1035], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,709 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,709 - train - INFO - True
2024-04-06 15:18:22,710 - train - INFO - alphas:tensor([0.4213, 0.1905, 0.1186, 0.1306, 0.1390], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,710 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,710 - train - INFO - True
2024-04-06 15:18:22,711 - train - INFO - alphas:tensor([0.5056, 0.1596, 0.1066, 0.1123, 0.1158], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,711 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,711 - train - INFO - True
2024-04-06 15:18:22,713 - train - INFO - alphas:tensor([0.5632, 0.1502, 0.0898, 0.0970, 0.0999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,713 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,713 - train - INFO - True
2024-04-06 15:18:22,714 - train - INFO - alphas:tensor([0.5201, 0.1604, 0.1017, 0.1069, 0.1110], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,714 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,714 - train - INFO - True
2024-04-06 15:18:22,715 - train - INFO - alphas:tensor([0.5232, 0.1368, 0.1630, 0.1769], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:18:22,715 - train - INFO - tau:0.9509900498999999
2024-04-06 15:18:22,715 - train - INFO - avg block size:1.0
2024-04-06 15:18:22,998 - train - INFO - Test: [   0/78]  Time: 0.279 (0.279)  Loss:  1.1484 (1.1484)  Acc@1: 75.7812 (75.7812)  Acc@5: 89.8438 (89.8438)
2024-04-06 15:18:28,101 - train - INFO - Test: [  50/78]  Time: 0.082 (0.106)  Loss:  2.1152 (1.8470)  Acc@1: 51.5625 (57.3376)  Acc@5: 79.6875 (81.2194)
2024-04-06 15:18:30,987 - train - INFO - Test: [  78/78]  Time: 0.051 (0.105)  Loss:  1.7803 (1.8670)  Acc@1: 56.2500 (56.7100)  Acc@5: 93.7500 (80.8400)
2024-04-06 15:18:32,306 - train - INFO - Train: 8 [   0/781 (  0%)]  Loss:  3.629899 (3.6299)  Time: 1.252s,  102.25/s  (1.252s,  102.25/s)  LR: 4.002e-04  Data: 0.197 (0.197)
2024-04-06 15:19:21,531 - train - INFO - Train: 8 [  50/781 (  6%)]  Loss:  4.325268 (3.7774)  Time: 0.819s,  156.22/s  (0.990s,  129.33/s)  LR: 4.002e-04  Data: 0.009 (0.012)
2024-04-06 15:20:07,185 - train - INFO - Train: 8 [ 100/781 ( 13%)]  Loss:  4.162021 (3.8196)  Time: 0.781s,  163.85/s  (0.952s,  134.49/s)  LR: 4.002e-04  Data: 0.005 (0.010)
2024-04-06 15:20:54,456 - train - INFO - Train: 8 [ 150/781 ( 19%)]  Loss:  4.505500 (3.8288)  Time: 0.786s,  162.90/s  (0.950s,  134.79/s)  LR: 4.002e-04  Data: 0.006 (0.009)
2024-04-06 15:21:40,817 - train - INFO - Train: 8 [ 200/781 ( 26%)]  Loss:  3.111808 (3.8364)  Time: 1.164s,  109.94/s  (0.944s,  135.59/s)  LR: 4.002e-04  Data: 0.009 (0.009)
2024-04-06 15:22:28,897 - train - INFO - Train: 8 [ 250/781 ( 32%)]  Loss:  4.362113 (3.8270)  Time: 0.817s,  156.66/s  (0.948s,  135.09/s)  LR: 4.002e-04  Data: 0.009 (0.009)
2024-04-06 15:23:09,714 - train - INFO - Train: 8 [ 300/781 ( 38%)]  Loss:  3.534830 (3.8214)  Time: 0.767s,  166.90/s  (0.926s,  138.27/s)  LR: 4.002e-04  Data: 0.006 (0.008)
2024-04-06 15:23:49,261 - train - INFO - Train: 8 [ 350/781 ( 45%)]  Loss:  3.304907 (3.8238)  Time: 0.759s,  168.54/s  (0.907s,  141.20/s)  LR: 4.002e-04  Data: 0.006 (0.008)
2024-04-06 15:24:28,195 - train - INFO - Train: 8 [ 400/781 ( 51%)]  Loss:  3.320793 (3.8105)  Time: 0.807s,  158.53/s  (0.891s,  143.73/s)  LR: 4.002e-04  Data: 0.009 (0.008)
2024-04-06 15:25:07,362 - train - INFO - Train: 8 [ 450/781 ( 58%)]  Loss:  3.739840 (3.8160)  Time: 0.761s,  168.18/s  (0.879s,  145.67/s)  LR: 4.002e-04  Data: 0.005 (0.008)
2024-04-06 15:25:46,507 - train - INFO - Train: 8 [ 500/781 ( 64%)]  Loss:  4.338109 (3.8247)  Time: 0.763s,  167.72/s  (0.869s,  147.27/s)  LR: 4.002e-04  Data: 0.005 (0.007)
2024-04-06 15:26:26,222 - train - INFO - Train: 8 [ 550/781 ( 71%)]  Loss:  4.155141 (3.8292)  Time: 0.802s,  159.64/s  (0.862s,  148.43/s)  LR: 4.002e-04  Data: 0.007 (0.007)
2024-04-06 15:27:05,836 - train - INFO - Train: 8 [ 600/781 ( 77%)]  Loss:  3.995837 (3.8359)  Time: 0.766s,  167.21/s  (0.857s,  149.44/s)  LR: 4.002e-04  Data: 0.005 (0.007)
2024-04-06 15:27:45,688 - train - INFO - Train: 8 [ 650/781 ( 83%)]  Loss:  3.184972 (3.8374)  Time: 0.764s,  167.44/s  (0.852s,  150.25/s)  LR: 4.002e-04  Data: 0.005 (0.007)
2024-04-06 15:28:25,459 - train - INFO - Train: 8 [ 700/781 ( 90%)]  Loss:  4.246301 (3.8435)  Time: 0.807s,  158.70/s  (0.848s,  150.96/s)  LR: 4.002e-04  Data: 0.008 (0.007)
2024-04-06 15:29:05,844 - train - INFO - Train: 8 [ 750/781 ( 96%)]  Loss:  3.421776 (3.8459)  Time: 0.766s,  167.15/s  (0.845s,  151.44/s)  LR: 4.002e-04  Data: 0.005 (0.007)
2024-04-06 15:29:29,590 - train - INFO - Train: 8 [ 780/781 (100%)]  Loss:  3.323014 (3.8428)  Time: 0.800s,  159.91/s  (0.843s,  151.81/s)  LR: 4.002e-04  Data: 0.000 (0.007)
2024-04-06 15:29:29,591 - train - INFO - True
2024-04-06 15:29:29,594 - train - INFO - alphas:tensor([0.2805, 0.2397, 0.1531, 0.1612, 0.1655], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,594 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,595 - train - INFO - True
2024-04-06 15:29:29,596 - train - INFO - alphas:tensor([0.3090, 0.2073, 0.1459, 0.1623, 0.1754], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,596 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,596 - train - INFO - True
2024-04-06 15:29:29,598 - train - INFO - alphas:tensor([0.5256, 0.1760, 0.0976, 0.0993, 0.1016], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,598 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,598 - train - INFO - True
2024-04-06 15:29:29,600 - train - INFO - alphas:tensor([0.5158, 0.1620, 0.1004, 0.1092, 0.1126], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,600 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,600 - train - INFO - True
2024-04-06 15:29:29,602 - train - INFO - alphas:tensor([0.4513, 0.1803, 0.1134, 0.1239, 0.1311], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,602 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,602 - train - INFO - True
2024-04-06 15:29:29,603 - train - INFO - alphas:tensor([0.4979, 0.1667, 0.1052, 0.1128, 0.1174], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,603 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,604 - train - INFO - True
2024-04-06 15:29:29,605 - train - INFO - alphas:tensor([0.5923, 0.1535, 0.0809, 0.0843, 0.0890], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,605 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,605 - train - INFO - True
2024-04-06 15:29:29,607 - train - INFO - alphas:tensor([0.5791, 0.1565, 0.0882, 0.0879, 0.0883], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,607 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,607 - train - INFO - True
2024-04-06 15:29:29,608 - train - INFO - alphas:tensor([0.4937, 0.1630, 0.1050, 0.1154, 0.1230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,608 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,609 - train - INFO - True
2024-04-06 15:29:29,610 - train - INFO - alphas:tensor([0.5446, 0.1546, 0.0966, 0.0998, 0.1044], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,610 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,610 - train - INFO - True
2024-04-06 15:29:29,612 - train - INFO - alphas:tensor([0.6184, 0.1400, 0.0765, 0.0804, 0.0848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,612 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,612 - train - INFO - True
2024-04-06 15:29:29,613 - train - INFO - alphas:tensor([0.5718, 0.1508, 0.0913, 0.0936, 0.0925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,613 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,613 - train - INFO - True
2024-04-06 15:29:29,615 - train - INFO - alphas:tensor([0.5150, 0.1567, 0.0990, 0.1106, 0.1186], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,615 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,615 - train - INFO - True
2024-04-06 15:29:29,616 - train - INFO - alphas:tensor([0.5805, 0.1352, 0.0918, 0.0945, 0.0979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,616 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,617 - train - INFO - True
2024-04-06 15:29:29,618 - train - INFO - alphas:tensor([0.6026, 0.1512, 0.0826, 0.0805, 0.0831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,618 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,618 - train - INFO - True
2024-04-06 15:29:29,619 - train - INFO - alphas:tensor([0.5455, 0.1638, 0.0959, 0.0945, 0.1003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,620 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,620 - train - INFO - True
2024-04-06 15:29:29,621 - train - INFO - alphas:tensor([0.5228, 0.1564, 0.0963, 0.1078, 0.1167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,621 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,621 - train - INFO - True
2024-04-06 15:29:29,623 - train - INFO - alphas:tensor([0.5893, 0.1326, 0.0907, 0.0931, 0.0942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,623 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,623 - train - INFO - True
2024-04-06 15:29:29,624 - train - INFO - alphas:tensor([0.6207, 0.1389, 0.0794, 0.0798, 0.0811], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,624 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,624 - train - INFO - True
2024-04-06 15:29:29,625 - train - INFO - alphas:tensor([0.5440, 0.1554, 0.0998, 0.0998, 0.1010], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,626 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,626 - train - INFO - True
2024-04-06 15:29:29,627 - train - INFO - alphas:tensor([0.5030, 0.1596, 0.1030, 0.1134, 0.1209], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,627 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,627 - train - INFO - True
2024-04-06 15:29:29,628 - train - INFO - alphas:tensor([0.5935, 0.1287, 0.0899, 0.0925, 0.0953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,629 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,629 - train - INFO - True
2024-04-06 15:29:29,630 - train - INFO - alphas:tensor([0.6548, 0.1299, 0.0701, 0.0717, 0.0735], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,630 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,630 - train - INFO - True
2024-04-06 15:29:29,631 - train - INFO - alphas:tensor([0.5614, 0.1468, 0.0978, 0.0958, 0.0983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,632 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,632 - train - INFO - True
2024-04-06 15:29:29,633 - train - INFO - alphas:tensor([0.4952, 0.1604, 0.1022, 0.1175, 0.1247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,633 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,633 - train - INFO - True
2024-04-06 15:29:29,634 - train - INFO - alphas:tensor([0.5802, 0.1312, 0.0936, 0.0947, 0.1003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,634 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,634 - train - INFO - True
2024-04-06 15:29:29,636 - train - INFO - alphas:tensor([0.6548, 0.1218, 0.0722, 0.0744, 0.0768], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,636 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,636 - train - INFO - True
2024-04-06 15:29:29,637 - train - INFO - alphas:tensor([0.5851, 0.1391, 0.0907, 0.0924, 0.0927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,637 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,637 - train - INFO - True
2024-04-06 15:29:29,638 - train - INFO - alphas:tensor([0.4783, 0.1597, 0.1096, 0.1222, 0.1302], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,638 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,639 - train - INFO - True
2024-04-06 15:29:29,640 - train - INFO - alphas:tensor([0.5811, 0.1308, 0.0915, 0.0955, 0.1011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,640 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,640 - train - INFO - True
2024-04-06 15:29:29,641 - train - INFO - alphas:tensor([0.6352, 0.1239, 0.0762, 0.0802, 0.0845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,641 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,641 - train - INFO - True
2024-04-06 15:29:29,643 - train - INFO - alphas:tensor([0.5945, 0.1327, 0.0886, 0.0910, 0.0932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,643 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,643 - train - INFO - True
2024-04-06 15:29:29,644 - train - INFO - alphas:tensor([0.4593, 0.1644, 0.1114, 0.1269, 0.1380], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,644 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,644 - train - INFO - True
2024-04-06 15:29:29,645 - train - INFO - alphas:tensor([0.5590, 0.1374, 0.0949, 0.1021, 0.1066], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,645 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,645 - train - INFO - True
2024-04-06 15:29:29,646 - train - INFO - alphas:tensor([0.6099, 0.1294, 0.0801, 0.0884, 0.0922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,647 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,647 - train - INFO - True
2024-04-06 15:29:29,648 - train - INFO - alphas:tensor([0.5673, 0.1387, 0.0922, 0.0985, 0.1033], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,648 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,648 - train - INFO - True
2024-04-06 15:29:29,649 - train - INFO - alphas:tensor([0.5493, 0.1249, 0.1551, 0.1707], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:29:29,649 - train - INFO - tau:0.9414801494009999
2024-04-06 15:29:29,649 - train - INFO - avg block size:1.0
2024-04-06 15:29:29,649 - train - INFO - lasso_alpha:1.2100000000000003e-05
2024-04-06 15:29:29,906 - train - INFO - Test: [   0/78]  Time: 0.253 (0.253)  Loss:  1.0508 (1.0508)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.1875 (92.1875)
2024-04-06 15:29:34,487 - train - INFO - Test: [  50/78]  Time: 0.083 (0.095)  Loss:  1.9512 (1.7914)  Acc@1: 55.4688 (58.1036)  Acc@5: 82.8125 (81.7096)
2024-04-06 15:29:36,764 - train - INFO - Test: [  78/78]  Time: 0.052 (0.090)  Loss:  1.4404 (1.8061)  Acc@1: 56.2500 (57.8600)  Acc@5: 100.0000 (81.1800)
2024-04-06 15:29:37,992 - train - INFO - Train: 9 [   0/781 (  0%)]  Loss:  4.285727 (4.2857)  Time: 1.161s,  110.21/s  (1.161s,  110.21/s)  LR: 4.501e-04  Data: 0.160 (0.160)
2024-04-06 15:30:16,816 - train - INFO - Train: 9 [  50/781 (  6%)]  Loss:  4.382014 (3.8557)  Time: 0.776s,  165.05/s  (0.784s,  163.26/s)  LR: 4.501e-04  Data: 0.005 (0.009)
2024-04-06 15:30:56,925 - train - INFO - Train: 9 [ 100/781 ( 13%)]  Loss:  4.109409 (3.8627)  Time: 0.770s,  166.24/s  (0.793s,  161.41/s)  LR: 4.501e-04  Data: 0.005 (0.008)
2024-04-06 15:31:37,973 - train - INFO - Train: 9 [ 150/781 ( 19%)]  Loss:  3.376975 (3.8634)  Time: 0.893s,  143.32/s  (0.802s,  159.55/s)  LR: 4.501e-04  Data: 0.007 (0.007)
2024-04-06 15:32:20,036 - train - INFO - Train: 9 [ 200/781 ( 26%)]  Loss:  4.166366 (3.8861)  Time: 0.766s,  167.19/s  (0.812s,  157.65/s)  LR: 4.501e-04  Data: 0.006 (0.007)
2024-04-06 15:33:01,020 - train - INFO - Train: 9 [ 250/781 ( 32%)]  Loss:  4.246132 (3.8964)  Time: 0.818s,  156.42/s  (0.813s,  157.35/s)  LR: 4.501e-04  Data: 0.008 (0.007)
2024-04-06 15:33:41,964 - train - INFO - Train: 9 [ 300/781 ( 38%)]  Loss:  3.307503 (3.8815)  Time: 0.776s,  164.92/s  (0.814s,  157.18/s)  LR: 4.501e-04  Data: 0.005 (0.007)
2024-04-06 15:34:23,305 - train - INFO - Train: 9 [ 350/781 ( 45%)]  Loss:  3.333217 (3.8692)  Time: 0.817s,  156.63/s  (0.816s,  156.84/s)  LR: 4.501e-04  Data: 0.008 (0.007)
2024-04-06 15:35:04,036 - train - INFO - Train: 9 [ 400/781 ( 51%)]  Loss:  4.037128 (3.8590)  Time: 0.802s,  159.57/s  (0.816s,  156.87/s)  LR: 4.501e-04  Data: 0.007 (0.007)
2024-04-06 15:35:45,557 - train - INFO - Train: 9 [ 450/781 ( 58%)]  Loss:  3.585129 (3.8561)  Time: 0.772s,  165.76/s  (0.818s,  156.57/s)  LR: 4.501e-04  Data: 0.005 (0.007)
2024-04-06 15:36:26,563 - train - INFO - Train: 9 [ 500/781 ( 64%)]  Loss:  4.204036 (3.8461)  Time: 0.816s,  156.96/s  (0.818s,  156.52/s)  LR: 4.501e-04  Data: 0.007 (0.007)
2024-04-06 15:37:06,627 - train - INFO - Train: 9 [ 550/781 ( 71%)]  Loss:  3.363509 (3.8448)  Time: 0.816s,  156.95/s  (0.816s,  156.81/s)  LR: 4.501e-04  Data: 0.008 (0.007)
2024-04-06 15:37:47,220 - train - INFO - Train: 9 [ 600/781 ( 77%)]  Loss:  3.520915 (3.8572)  Time: 0.772s,  165.74/s  (0.816s,  156.88/s)  LR: 4.501e-04  Data: 0.006 (0.007)
2024-04-06 15:38:27,511 - train - INFO - Train: 9 [ 650/781 ( 83%)]  Loss:  3.767675 (3.8569)  Time: 0.874s,  146.47/s  (0.815s,  157.03/s)  LR: 4.501e-04  Data: 0.005 (0.007)
2024-04-06 15:39:11,798 - train - INFO - Train: 9 [ 700/781 ( 90%)]  Loss:  3.253851 (3.8525)  Time: 0.773s,  165.50/s  (0.820s,  156.06/s)  LR: 4.501e-04  Data: 0.005 (0.007)
2024-04-06 15:39:52,178 - train - INFO - Train: 9 [ 750/781 ( 96%)]  Loss:  3.408258 (3.8551)  Time: 0.823s,  155.52/s  (0.819s,  156.22/s)  LR: 4.501e-04  Data: 0.008 (0.007)
2024-04-06 15:40:15,626 - train - INFO - Train: 9 [ 780/781 (100%)]  Loss:  3.456209 (3.8603)  Time: 0.758s,  168.82/s  (0.818s,  156.50/s)  LR: 4.501e-04  Data: 0.000 (0.007)
2024-04-06 15:40:15,626 - train - INFO - True
2024-04-06 15:40:15,628 - train - INFO - alphas:tensor([0.2870, 0.2350, 0.1514, 0.1608, 0.1658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,628 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,628 - train - INFO - True
2024-04-06 15:40:15,629 - train - INFO - alphas:tensor([0.3252, 0.1990, 0.1406, 0.1596, 0.1757], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,629 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,629 - train - INFO - True
2024-04-06 15:40:15,630 - train - INFO - alphas:tensor([0.5588, 0.1600, 0.0913, 0.0937, 0.0962], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,630 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,630 - train - INFO - True
2024-04-06 15:40:15,631 - train - INFO - alphas:tensor([0.5478, 0.1462, 0.0941, 0.1039, 0.1080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,631 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,632 - train - INFO - True
2024-04-06 15:40:15,632 - train - INFO - alphas:tensor([0.4734, 0.1657, 0.1092, 0.1216, 0.1300], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,633 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,633 - train - INFO - True
2024-04-06 15:40:15,634 - train - INFO - alphas:tensor([0.5360, 0.1519, 0.0966, 0.1052, 0.1103], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,634 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,634 - train - INFO - True
2024-04-06 15:40:15,635 - train - INFO - alphas:tensor([0.6369, 0.1330, 0.0726, 0.0762, 0.0814], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,635 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,635 - train - INFO - True
2024-04-06 15:40:15,636 - train - INFO - alphas:tensor([0.6275, 0.1364, 0.0778, 0.0786, 0.0797], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,636 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,636 - train - INFO - True
2024-04-06 15:40:15,637 - train - INFO - alphas:tensor([0.5157, 0.1480, 0.1007, 0.1130, 0.1226], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,637 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,637 - train - INFO - True
2024-04-06 15:40:15,638 - train - INFO - alphas:tensor([0.5794, 0.1397, 0.0891, 0.0934, 0.0985], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,638 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,638 - train - INFO - True
2024-04-06 15:40:15,639 - train - INFO - alphas:tensor([0.6592, 0.1224, 0.0682, 0.0728, 0.0774], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,639 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,639 - train - INFO - True
2024-04-06 15:40:15,640 - train - INFO - alphas:tensor([0.6117, 0.1333, 0.0828, 0.0864, 0.0858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,640 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,641 - train - INFO - True
2024-04-06 15:40:15,641 - train - INFO - alphas:tensor([0.5376, 0.1422, 0.0944, 0.1081, 0.1177], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,642 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,642 - train - INFO - True
2024-04-06 15:40:15,643 - train - INFO - alphas:tensor([0.6133, 0.1222, 0.0845, 0.0880, 0.0920], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,643 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,643 - train - INFO - True
2024-04-06 15:40:15,644 - train - INFO - alphas:tensor([0.6414, 0.1341, 0.0746, 0.0732, 0.0767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,644 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,644 - train - INFO - True
2024-04-06 15:40:15,645 - train - INFO - alphas:tensor([0.5809, 0.1467, 0.0884, 0.0887, 0.0953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,645 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,645 - train - INFO - True
2024-04-06 15:40:15,646 - train - INFO - alphas:tensor([0.5441, 0.1411, 0.0921, 0.1060, 0.1167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,646 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,646 - train - INFO - True
2024-04-06 15:40:15,647 - train - INFO - alphas:tensor([0.6237, 0.1181, 0.0834, 0.0866, 0.0882], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,647 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,647 - train - INFO - True
2024-04-06 15:40:15,648 - train - INFO - alphas:tensor([0.6640, 0.1208, 0.0705, 0.0713, 0.0735], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,648 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,648 - train - INFO - True
2024-04-06 15:40:15,649 - train - INFO - alphas:tensor([0.5824, 0.1382, 0.0909, 0.0929, 0.0955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,649 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,649 - train - INFO - True
2024-04-06 15:40:15,650 - train - INFO - alphas:tensor([0.5263, 0.1440, 0.0983, 0.1110, 0.1204], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,650 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,650 - train - INFO - True
2024-04-06 15:40:15,651 - train - INFO - alphas:tensor([0.6297, 0.1145, 0.0820, 0.0853, 0.0884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,651 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,651 - train - INFO - True
2024-04-06 15:40:15,652 - train - INFO - alphas:tensor([0.6956, 0.1127, 0.0618, 0.0638, 0.0660], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,652 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,652 - train - INFO - True
2024-04-06 15:40:15,653 - train - INFO - alphas:tensor([0.6054, 0.1273, 0.0876, 0.0881, 0.0915], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,653 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,653 - train - INFO - True
2024-04-06 15:40:15,654 - train - INFO - alphas:tensor([0.5230, 0.1429, 0.0968, 0.1144, 0.1228], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,654 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,655 - train - INFO - True
2024-04-06 15:40:15,655 - train - INFO - alphas:tensor([0.6218, 0.1158, 0.0842, 0.0860, 0.0922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,656 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,656 - train - INFO - True
2024-04-06 15:40:15,656 - train - INFO - alphas:tensor([0.6925, 0.1060, 0.0642, 0.0670, 0.0703], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,657 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,657 - train - INFO - True
2024-04-06 15:40:15,657 - train - INFO - alphas:tensor([0.6229, 0.1229, 0.0819, 0.0853, 0.0869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,658 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,658 - train - INFO - True
2024-04-06 15:40:15,659 - train - INFO - alphas:tensor([0.5036, 0.1416, 0.1046, 0.1201, 0.1300], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,659 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,659 - train - INFO - True
2024-04-06 15:40:15,660 - train - INFO - alphas:tensor([0.6206, 0.1148, 0.0825, 0.0880, 0.0940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,660 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,660 - train - INFO - True
2024-04-06 15:40:15,661 - train - INFO - alphas:tensor([0.6704, 0.1087, 0.0686, 0.0735, 0.0788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,661 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,661 - train - INFO - True
2024-04-06 15:40:15,662 - train - INFO - alphas:tensor([0.6311, 0.1161, 0.0807, 0.0845, 0.0876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,662 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,662 - train - INFO - True
2024-04-06 15:40:15,663 - train - INFO - alphas:tensor([0.4820, 0.1450, 0.1070, 0.1260, 0.1399], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,663 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,663 - train - INFO - True
2024-04-06 15:40:15,664 - train - INFO - alphas:tensor([0.5964, 0.1220, 0.0867, 0.0946, 0.1003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,664 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,664 - train - INFO - True
2024-04-06 15:40:15,665 - train - INFO - alphas:tensor([0.6421, 0.1145, 0.0735, 0.0825, 0.0874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,665 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,665 - train - INFO - True
2024-04-06 15:40:15,666 - train - INFO - alphas:tensor([0.6013, 0.1230, 0.0851, 0.0925, 0.0980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,666 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,666 - train - INFO - True
2024-04-06 15:40:15,667 - train - INFO - alphas:tensor([0.5680, 0.1163, 0.1494, 0.1663], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:40:15,667 - train - INFO - tau:0.9320653479069899
2024-04-06 15:40:15,667 - train - INFO - avg block size:1.0
2024-04-06 15:40:15,920 - train - INFO - Test: [   0/78]  Time: 0.251 (0.251)  Loss:  0.9111 (0.9111)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-06 15:40:20,234 - train - INFO - Test: [  50/78]  Time: 0.082 (0.089)  Loss:  1.9336 (1.7947)  Acc@1: 56.2500 (57.8738)  Acc@5: 77.3438 (81.7402)
2024-04-06 15:40:22,732 - train - INFO - Test: [  78/78]  Time: 0.052 (0.089)  Loss:  1.6797 (1.8109)  Acc@1: 62.5000 (57.9400)  Acc@5: 100.0000 (81.3300)
2024-04-06 15:40:24,048 - train - INFO - Train: 10 [   0/781 (  0%)]  Loss:  3.273365 (3.2734)  Time: 1.253s,  102.20/s  (1.253s,  102.20/s)  LR: 4.946e-04  Data: 0.187 (0.187)
2024-04-06 15:41:03,820 - train - INFO - Train: 10 [  50/781 (  6%)]  Loss:  3.820671 (3.8036)  Time: 0.815s,  157.10/s  (0.804s,  159.13/s)  LR: 4.946e-04  Data: 0.009 (0.010)
2024-04-06 15:41:44,823 - train - INFO - Train: 10 [ 100/781 ( 13%)]  Loss:  3.432628 (3.8096)  Time: 0.767s,  166.78/s  (0.812s,  157.61/s)  LR: 4.946e-04  Data: 0.006 (0.008)
2024-04-06 15:42:23,876 - train - INFO - Train: 10 [ 150/781 ( 19%)]  Loss:  4.128576 (3.8190)  Time: 0.765s,  167.36/s  (0.802s,  159.63/s)  LR: 4.946e-04  Data: 0.005 (0.007)
2024-04-06 15:43:03,567 - train - INFO - Train: 10 [ 200/781 ( 26%)]  Loss:  3.435536 (3.8165)  Time: 0.811s,  157.80/s  (0.800s,  160.03/s)  LR: 4.946e-04  Data: 0.008 (0.007)
2024-04-06 15:43:42,579 - train - INFO - Train: 10 [ 250/781 ( 32%)]  Loss:  3.517314 (3.8152)  Time: 0.769s,  166.51/s  (0.796s,  160.82/s)  LR: 4.946e-04  Data: 0.005 (0.007)
2024-04-06 15:44:23,355 - train - INFO - Train: 10 [ 300/781 ( 38%)]  Loss:  3.747771 (3.8218)  Time: 0.787s,  162.68/s  (0.799s,  160.17/s)  LR: 4.946e-04  Data: 0.006 (0.007)
2024-04-06 15:45:02,884 - train - INFO - Train: 10 [ 350/781 ( 45%)]  Loss:  4.338918 (3.8329)  Time: 0.767s,  166.97/s  (0.798s,  160.41/s)  LR: 4.946e-04  Data: 0.005 (0.007)
2024-04-06 15:45:43,110 - train - INFO - Train: 10 [ 400/781 ( 51%)]  Loss:  4.115366 (3.8425)  Time: 0.771s,  165.93/s  (0.799s,  160.25/s)  LR: 4.946e-04  Data: 0.006 (0.007)
2024-04-06 15:46:25,313 - train - INFO - Train: 10 [ 450/781 ( 58%)]  Loss:  3.519568 (3.8485)  Time: 0.773s,  165.52/s  (0.804s,  159.25/s)  LR: 4.946e-04  Data: 0.006 (0.007)
2024-04-06 15:47:08,610 - train - INFO - Train: 10 [ 500/781 ( 64%)]  Loss:  3.254765 (3.8464)  Time: 0.814s,  157.32/s  (0.810s,  158.03/s)  LR: 4.946e-04  Data: 0.008 (0.007)
2024-04-06 15:47:49,351 - train - INFO - Train: 10 [ 550/781 ( 71%)]  Loss:  3.527159 (3.8456)  Time: 0.813s,  157.37/s  (0.810s,  157.94/s)  LR: 4.946e-04  Data: 0.008 (0.007)
2024-04-06 15:48:29,658 - train - INFO - Train: 10 [ 600/781 ( 77%)]  Loss:  3.823488 (3.8419)  Time: 0.812s,  157.69/s  (0.810s,  158.01/s)  LR: 4.946e-04  Data: 0.008 (0.007)
2024-04-06 15:49:09,958 - train - INFO - Train: 10 [ 650/781 ( 83%)]  Loss:  3.613956 (3.8418)  Time: 0.774s,  165.46/s  (0.810s,  158.07/s)  LR: 4.946e-04  Data: 0.006 (0.007)
2024-04-06 15:49:49,508 - train - INFO - Train: 10 [ 700/781 ( 90%)]  Loss:  4.448918 (3.8450)  Time: 0.777s,  164.67/s  (0.808s,  158.34/s)  LR: 4.946e-04  Data: 0.004 (0.007)
2024-04-06 15:50:28,820 - train - INFO - Train: 10 [ 750/781 ( 96%)]  Loss:  3.262295 (3.8466)  Time: 0.766s,  167.14/s  (0.807s,  158.63/s)  LR: 4.946e-04  Data: 0.005 (0.007)
2024-04-06 15:50:52,467 - train - INFO - Train: 10 [ 780/781 (100%)]  Loss:  4.260947 (3.8467)  Time: 0.807s,  158.56/s  (0.806s,  158.77/s)  LR: 4.946e-04  Data: 0.000 (0.007)
2024-04-06 15:50:52,468 - train - INFO - True
2024-04-06 15:50:52,470 - train - INFO - alphas:tensor([0.2934, 0.2290, 0.1500, 0.1609, 0.1666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,470 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,470 - train - INFO - True
2024-04-06 15:50:52,472 - train - INFO - alphas:tensor([0.3401, 0.1876, 0.1362, 0.1585, 0.1776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,472 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,472 - train - INFO - True
2024-04-06 15:50:52,474 - train - INFO - alphas:tensor([0.5902, 0.1458, 0.0852, 0.0881, 0.0909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,474 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,474 - train - INFO - True
2024-04-06 15:50:52,476 - train - INFO - alphas:tensor([0.5781, 0.1324, 0.0879, 0.0983, 0.1033], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,476 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,476 - train - INFO - True
2024-04-06 15:50:52,478 - train - INFO - alphas:tensor([0.4908, 0.1528, 0.1062, 0.1202, 0.1299], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,478 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,478 - train - INFO - True
2024-04-06 15:50:52,480 - train - INFO - alphas:tensor([0.5672, 0.1391, 0.0898, 0.0991, 0.1047], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,480 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,480 - train - INFO - True
2024-04-06 15:50:52,481 - train - INFO - alphas:tensor([0.6710, 0.1180, 0.0658, 0.0698, 0.0753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,482 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,482 - train - INFO - True
2024-04-06 15:50:52,483 - train - INFO - alphas:tensor([0.6666, 0.1196, 0.0696, 0.0714, 0.0728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,483 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,483 - train - INFO - True
2024-04-06 15:50:52,485 - train - INFO - alphas:tensor([0.5329, 0.1356, 0.0972, 0.1116, 0.1227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,485 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,485 - train - INFO - True
2024-04-06 15:50:52,487 - train - INFO - alphas:tensor([0.6072, 0.1270, 0.0831, 0.0884, 0.0943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,487 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,487 - train - INFO - True
2024-04-06 15:50:52,488 - train - INFO - alphas:tensor([0.6899, 0.1083, 0.0624, 0.0672, 0.0721], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,488 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,489 - train - INFO - True
2024-04-06 15:50:52,490 - train - INFO - alphas:tensor([0.6461, 0.1188, 0.0752, 0.0798, 0.0801], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,490 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,490 - train - INFO - True
2024-04-06 15:50:52,492 - train - INFO - alphas:tensor([0.5543, 0.1294, 0.0911, 0.1068, 0.1184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,492 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,492 - train - INFO - True
2024-04-06 15:50:52,493 - train - INFO - alphas:tensor([0.6350, 0.1125, 0.0796, 0.0842, 0.0887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,494 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,494 - train - INFO - True
2024-04-06 15:50:52,495 - train - INFO - alphas:tensor([0.6733, 0.1194, 0.0681, 0.0676, 0.0715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,495 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,495 - train - INFO - True
2024-04-06 15:50:52,497 - train - INFO - alphas:tensor([0.6105, 0.1318, 0.0821, 0.0839, 0.0916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,497 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,497 - train - INFO - True
2024-04-06 15:50:52,498 - train - INFO - alphas:tensor([0.5612, 0.1282, 0.0885, 0.1048, 0.1173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,498 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,498 - train - INFO - True
2024-04-06 15:50:52,500 - train - INFO - alphas:tensor([0.6484, 0.1075, 0.0779, 0.0819, 0.0843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,500 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,500 - train - INFO - True
2024-04-06 15:50:52,501 - train - INFO - alphas:tensor([0.6977, 0.1065, 0.0634, 0.0649, 0.0674], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,502 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,502 - train - INFO - True
2024-04-06 15:50:52,503 - train - INFO - alphas:tensor([0.6109, 0.1235, 0.0848, 0.0884, 0.0924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,503 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,503 - train - INFO - True
2024-04-06 15:50:52,504 - train - INFO - alphas:tensor([0.5460, 0.1297, 0.0941, 0.1095, 0.1206], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,505 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,505 - train - INFO - True
2024-04-06 15:50:52,506 - train - INFO - alphas:tensor([0.6605, 0.1029, 0.0749, 0.0788, 0.0828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,506 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,506 - train - INFO - True
2024-04-06 15:50:52,507 - train - INFO - alphas:tensor([0.7248, 0.1004, 0.0558, 0.0581, 0.0609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,508 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,508 - train - INFO - True
2024-04-06 15:50:52,509 - train - INFO - alphas:tensor([0.6347, 0.1136, 0.0809, 0.0831, 0.0877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,509 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,509 - train - INFO - True
2024-04-06 15:50:52,510 - train - INFO - alphas:tensor([0.5406, 0.1295, 0.0934, 0.1131, 0.1234], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,511 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,511 - train - INFO - True
2024-04-06 15:50:52,512 - train - INFO - alphas:tensor([0.6515, 0.1043, 0.0773, 0.0801, 0.0867], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,512 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,512 - train - INFO - True
2024-04-06 15:50:52,513 - train - INFO - alphas:tensor([0.7166, 0.0952, 0.0590, 0.0624, 0.0668], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,514 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,514 - train - INFO - True
2024-04-06 15:50:52,515 - train - INFO - alphas:tensor([0.6481, 0.1099, 0.0762, 0.0813, 0.0845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,515 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,515 - train - INFO - True
2024-04-06 15:50:52,516 - train - INFO - alphas:tensor([0.5226, 0.1276, 0.1006, 0.1185, 0.1308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,517 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,517 - train - INFO - True
2024-04-06 15:50:52,518 - train - INFO - alphas:tensor([0.6477, 0.1032, 0.0763, 0.0830, 0.0897], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,518 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,518 - train - INFO - True
2024-04-06 15:50:52,519 - train - INFO - alphas:tensor([0.6915, 0.0987, 0.0638, 0.0698, 0.0762], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,519 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,519 - train - INFO - True
2024-04-06 15:50:52,521 - train - INFO - alphas:tensor([0.6550, 0.1046, 0.0751, 0.0806, 0.0847], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,521 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,521 - train - INFO - True
2024-04-06 15:50:52,522 - train - INFO - alphas:tensor([0.4987, 0.1291, 0.1035, 0.1260, 0.1428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,522 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,522 - train - INFO - True
2024-04-06 15:50:52,523 - train - INFO - alphas:tensor([0.6220, 0.1099, 0.0813, 0.0900, 0.0968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,524 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,524 - train - INFO - True
2024-04-06 15:50:52,525 - train - INFO - alphas:tensor([0.6631, 0.1044, 0.0688, 0.0788, 0.0850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,525 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,525 - train - INFO - True
2024-04-06 15:50:52,526 - train - INFO - alphas:tensor([0.6280, 0.1101, 0.0792, 0.0880, 0.0947], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,526 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,527 - train - INFO - True
2024-04-06 15:50:52,528 - train - INFO - alphas:tensor([0.5826, 0.1094, 0.1450, 0.1630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 15:50:52,528 - train - INFO - tau:0.92274469442792
2024-04-06 15:50:52,528 - train - INFO - avg block size:1.0
2024-04-06 15:50:52,528 - train - INFO - lasso_alpha:1.3310000000000005e-05
2024-04-06 15:50:52,771 - train - INFO - Test: [   0/78]  Time: 0.240 (0.240)  Loss:  1.0586 (1.0586)  Acc@1: 76.5625 (76.5625)  Acc@5: 90.6250 (90.6250)
2024-04-06 15:50:57,044 - train - INFO - Test: [  50/78]  Time: 0.082 (0.088)  Loss:  1.8564 (1.7739)  Acc@1: 55.4688 (58.1955)  Acc@5: 82.0312 (82.0159)
2024-04-06 15:50:59,530 - train - INFO - Test: [  78/78]  Time: 0.056 (0.089)  Loss:  1.6348 (1.8090)  Acc@1: 62.5000 (57.7000)  Acc@5: 93.7500 (81.5100)
2024-04-06 15:51:00,564 - train - INFO - Train: 11 [   0/781 (  0%)]  Loss:  4.361229 (4.3612)  Time: 0.971s,  131.85/s  (0.971s,  131.85/s)  LR: 4.935e-04  Data: 0.187 (0.187)
2024-04-06 15:51:41,580 - train - INFO - Train: 11 [  50/781 (  6%)]  Loss:  3.628839 (3.8833)  Time: 0.812s,  157.73/s  (0.823s,  155.48/s)  LR: 4.935e-04  Data: 0.008 (0.010)
2024-04-06 15:52:21,390 - train - INFO - Train: 11 [ 100/781 ( 13%)]  Loss:  3.544271 (3.8494)  Time: 0.767s,  166.89/s  (0.810s,  158.06/s)  LR: 4.935e-04  Data: 0.005 (0.008)
2024-04-06 15:53:01,263 - train - INFO - Train: 11 [ 150/781 ( 19%)]  Loss:  4.300868 (3.8344)  Time: 0.773s,  165.69/s  (0.806s,  158.86/s)  LR: 4.935e-04  Data: 0.005 (0.007)
2024-04-06 15:53:41,188 - train - INFO - Train: 11 [ 200/781 ( 26%)]  Loss:  3.784252 (3.8477)  Time: 1.012s,  126.43/s  (0.804s,  159.22/s)  LR: 4.935e-04  Data: 0.006 (0.007)
2024-04-06 15:54:20,637 - train - INFO - Train: 11 [ 250/781 ( 32%)]  Loss:  3.408518 (3.8349)  Time: 0.765s,  167.31/s  (0.801s,  159.81/s)  LR: 4.935e-04  Data: 0.005 (0.007)
2024-04-06 15:54:59,545 - train - INFO - Train: 11 [ 300/781 ( 38%)]  Loss:  4.359442 (3.8448)  Time: 0.810s,  158.00/s  (0.797s,  160.57/s)  LR: 4.935e-04  Data: 0.009 (0.007)
2024-04-06 15:55:38,782 - train - INFO - Train: 11 [ 350/781 ( 45%)]  Loss:  3.643524 (3.8427)  Time: 0.807s,  158.52/s  (0.795s,  160.93/s)  LR: 4.935e-04  Data: 0.007 (0.007)
2024-04-06 15:56:18,627 - train - INFO - Train: 11 [ 400/781 ( 51%)]  Loss:  3.585134 (3.8476)  Time: 0.764s,  167.45/s  (0.796s,  160.89/s)  LR: 4.935e-04  Data: 0.005 (0.007)
2024-04-06 15:56:59,817 - train - INFO - Train: 11 [ 450/781 ( 58%)]  Loss:  3.738566 (3.8423)  Time: 0.845s,  151.39/s  (0.799s,  160.26/s)  LR: 4.935e-04  Data: 0.006 (0.007)
2024-04-06 15:57:44,165 - train - INFO - Train: 11 [ 500/781 ( 64%)]  Loss:  4.043149 (3.8505)  Time: 0.762s,  168.01/s  (0.807s,  158.51/s)  LR: 4.935e-04  Data: 0.005 (0.007)
2024-04-06 15:58:27,578 - train - INFO - Train: 11 [ 550/781 ( 71%)]  Loss:  3.635714 (3.8480)  Time: 0.776s,  165.04/s  (0.813s,  157.44/s)  LR: 4.935e-04  Data: 0.005 (0.007)
2024-04-06 15:59:08,266 - train - INFO - Train: 11 [ 600/781 ( 77%)]  Loss:  3.848813 (3.8463)  Time: 0.770s,  166.28/s  (0.813s,  157.43/s)  LR: 4.935e-04  Data: 0.005 (0.007)
2024-04-06 15:59:50,958 - train - INFO - Train: 11 [ 650/781 ( 83%)]  Loss:  3.934112 (3.8446)  Time: 0.775s,  165.15/s  (0.816s,  156.83/s)  LR: 4.935e-04  Data: 0.006 (0.007)
2024-04-06 16:00:32,379 - train - INFO - Train: 11 [ 700/781 ( 90%)]  Loss:  3.814815 (3.8425)  Time: 0.834s,  153.46/s  (0.817s,  156.66/s)  LR: 4.935e-04  Data: 0.009 (0.007)
2024-04-06 16:01:13,462 - train - INFO - Train: 11 [ 750/781 ( 96%)]  Loss:  4.050757 (3.8395)  Time: 0.780s,  164.03/s  (0.817s,  156.60/s)  LR: 4.935e-04  Data: 0.004 (0.007)
2024-04-06 16:01:40,528 - train - INFO - Train: 11 [ 780/781 (100%)]  Loss:  4.288976 (3.8380)  Time: 0.764s,  167.53/s  (0.821s,  155.98/s)  LR: 4.935e-04  Data: 0.000 (0.007)
2024-04-06 16:01:40,529 - train - INFO - True
2024-04-06 16:01:40,531 - train - INFO - alphas:tensor([0.2983, 0.2232, 0.1490, 0.1616, 0.1680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,531 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,531 - train - INFO - True
2024-04-06 16:01:40,533 - train - INFO - alphas:tensor([0.3507, 0.1777, 0.1329, 0.1583, 0.1804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,533 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,533 - train - INFO - True
2024-04-06 16:01:40,535 - train - INFO - alphas:tensor([0.6121, 0.1355, 0.0809, 0.0842, 0.0873], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,535 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,535 - train - INFO - True
2024-04-06 16:01:40,537 - train - INFO - alphas:tensor([0.6001, 0.1223, 0.0831, 0.0945, 0.1000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,537 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,537 - train - INFO - True
2024-04-06 16:01:40,538 - train - INFO - alphas:tensor([0.5029, 0.1424, 0.1040, 0.1197, 0.1311], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,539 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,539 - train - INFO - True
2024-04-06 16:01:40,540 - train - INFO - alphas:tensor([0.5896, 0.1290, 0.0850, 0.0950, 0.1014], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,540 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,541 - train - INFO - True
2024-04-06 16:01:40,542 - train - INFO - alphas:tensor([0.6976, 0.1062, 0.0605, 0.0650, 0.0708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,542 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,542 - train - INFO - True
2024-04-06 16:01:40,544 - train - INFO - alphas:tensor([0.6955, 0.1073, 0.0634, 0.0660, 0.0678], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,544 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,544 - train - INFO - True
2024-04-06 16:01:40,546 - train - INFO - alphas:tensor([0.5446, 0.1260, 0.0947, 0.1110, 0.1236], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,546 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,546 - train - INFO - True
2024-04-06 16:01:40,547 - train - INFO - alphas:tensor([0.6262, 0.1182, 0.0793, 0.0850, 0.0914], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,547 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,547 - train - INFO - True
2024-04-06 16:01:40,549 - train - INFO - alphas:tensor([0.7071, 0.1001, 0.0590, 0.0642, 0.0696], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,549 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,549 - train - INFO - True
2024-04-06 16:01:40,550 - train - INFO - alphas:tensor([0.6666, 0.1087, 0.0708, 0.0764, 0.0774], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,551 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,551 - train - INFO - True
2024-04-06 16:01:40,552 - train - INFO - alphas:tensor([0.5657, 0.1203, 0.0884, 0.1060, 0.1195], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,552 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,553 - train - INFO - True
2024-04-06 16:01:40,554 - train - INFO - alphas:tensor([0.6544, 0.1044, 0.0751, 0.0803, 0.0858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,554 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,554 - train - INFO - True
2024-04-06 16:01:40,555 - train - INFO - alphas:tensor([0.6944, 0.1096, 0.0637, 0.0639, 0.0684], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,556 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,556 - train - INFO - True
2024-04-06 16:01:40,557 - train - INFO - alphas:tensor([0.6276, 0.1210, 0.0786, 0.0820, 0.0907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,557 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,557 - train - INFO - True
2024-04-06 16:01:40,559 - train - INFO - alphas:tensor([0.5730, 0.1184, 0.0857, 0.1044, 0.1186], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,559 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,559 - train - INFO - True
2024-04-06 16:01:40,560 - train - INFO - alphas:tensor([0.6675, 0.0992, 0.0735, 0.0783, 0.0815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,560 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,561 - train - INFO - True
2024-04-06 16:01:40,562 - train - INFO - alphas:tensor([0.7156, 0.0982, 0.0595, 0.0617, 0.0649], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,562 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,562 - train - INFO - True
2024-04-06 16:01:40,563 - train - INFO - alphas:tensor([0.6229, 0.1149, 0.0818, 0.0875, 0.0930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,563 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,564 - train - INFO - True
2024-04-06 16:01:40,565 - train - INFO - alphas:tensor([0.5563, 0.1196, 0.0920, 0.1095, 0.1226], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,565 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,565 - train - INFO - True
2024-04-06 16:01:40,566 - train - INFO - alphas:tensor([0.6834, 0.0938, 0.0698, 0.0743, 0.0788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,567 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,567 - train - INFO - True
2024-04-06 16:01:40,568 - train - INFO - alphas:tensor([0.7399, 0.0934, 0.0527, 0.0555, 0.0586], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,568 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,568 - train - INFO - True
2024-04-06 16:01:40,569 - train - INFO - alphas:tensor([0.6496, 0.1038, 0.0774, 0.0815, 0.0876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,570 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,570 - train - INFO - True
2024-04-06 16:01:40,571 - train - INFO - alphas:tensor([0.5536, 0.1182, 0.0905, 0.1128, 0.1249], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,571 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,571 - train - INFO - True
2024-04-06 16:01:40,572 - train - INFO - alphas:tensor([0.6725, 0.0953, 0.0724, 0.0763, 0.0835], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,573 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,573 - train - INFO - True
2024-04-06 16:01:40,574 - train - INFO - alphas:tensor([0.7337, 0.0873, 0.0551, 0.0595, 0.0645], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,574 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,574 - train - INFO - True
2024-04-06 16:01:40,575 - train - INFO - alphas:tensor([0.6628, 0.1011, 0.0726, 0.0792, 0.0844], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,576 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,576 - train - INFO - True
2024-04-06 16:01:40,577 - train - INFO - alphas:tensor([0.5342, 0.1159, 0.0979, 0.1186, 0.1333], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,577 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,577 - train - INFO - True
2024-04-06 16:01:40,578 - train - INFO - alphas:tensor([0.6664, 0.0952, 0.0722, 0.0791, 0.0871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,578 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,578 - train - INFO - True
2024-04-06 16:01:40,580 - train - INFO - alphas:tensor([0.7055, 0.0904, 0.0608, 0.0678, 0.0754], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,580 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,580 - train - INFO - True
2024-04-06 16:01:40,581 - train - INFO - alphas:tensor([0.6731, 0.0949, 0.0709, 0.0780, 0.0831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,581 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,581 - train - INFO - True
2024-04-06 16:01:40,582 - train - INFO - alphas:tensor([0.5110, 0.1162, 0.1004, 0.1265, 0.1460], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,583 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,583 - train - INFO - True
2024-04-06 16:01:40,584 - train - INFO - alphas:tensor([0.6396, 0.1009, 0.0769, 0.0872, 0.0954], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,584 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,584 - train - INFO - True
2024-04-06 16:01:40,585 - train - INFO - alphas:tensor([0.6751, 0.0970, 0.0657, 0.0774, 0.0848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,585 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,586 - train - INFO - True
2024-04-06 16:01:40,587 - train - INFO - alphas:tensor([0.6452, 0.1003, 0.0752, 0.0858, 0.0935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,587 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,587 - train - INFO - True
2024-04-06 16:01:40,588 - train - INFO - alphas:tensor([0.5939, 0.1045, 0.1412, 0.1604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:01:40,588 - train - INFO - tau:0.9135172474836407
2024-04-06 16:01:40,588 - train - INFO - avg block size:1.0
2024-04-06 16:01:40,832 - train - INFO - Test: [   0/78]  Time: 0.240 (0.240)  Loss:  0.9902 (0.9902)  Acc@1: 78.9062 (78.9062)  Acc@5: 92.1875 (92.1875)
2024-04-06 16:01:45,124 - train - INFO - Test: [  50/78]  Time: 0.083 (0.089)  Loss:  1.8838 (1.7325)  Acc@1: 53.9062 (59.4669)  Acc@5: 79.6875 (82.5827)
2024-04-06 16:01:47,409 - train - INFO - Test: [  78/78]  Time: 0.052 (0.086)  Loss:  1.6943 (1.7729)  Acc@1: 56.2500 (58.3700)  Acc@5: 93.7500 (82.0200)
2024-04-06 16:01:48,679 - train - INFO - Train: 12 [   0/781 (  0%)]  Loss:  3.386563 (3.3866)  Time: 1.205s,  106.25/s  (1.205s,  106.25/s)  LR: 4.923e-04  Data: 0.179 (0.179)
2024-04-06 16:02:31,871 - train - INFO - Train: 12 [  50/781 (  6%)]  Loss:  4.197422 (3.9581)  Time: 0.779s,  164.40/s  (0.870s,  147.04/s)  LR: 4.923e-04  Data: 0.006 (0.010)
2024-04-06 16:03:13,222 - train - INFO - Train: 12 [ 100/781 ( 13%)]  Loss:  3.969679 (3.9188)  Time: 0.780s,  164.07/s  (0.849s,  150.77/s)  LR: 4.923e-04  Data: 0.005 (0.009)
2024-04-06 16:03:55,006 - train - INFO - Train: 12 [ 150/781 ( 19%)]  Loss:  4.201827 (3.8884)  Time: 0.897s,  142.66/s  (0.845s,  151.56/s)  LR: 4.923e-04  Data: 0.007 (0.008)
2024-04-06 16:04:40,347 - train - INFO - Train: 12 [ 200/781 ( 26%)]  Loss:  3.872706 (3.8846)  Time: 0.816s,  156.93/s  (0.860s,  148.83/s)  LR: 4.923e-04  Data: 0.005 (0.008)
2024-04-06 16:05:21,999 - train - INFO - Train: 12 [ 250/781 ( 32%)]  Loss:  3.656965 (3.8850)  Time: 0.773s,  165.55/s  (0.855s,  149.77/s)  LR: 4.923e-04  Data: 0.005 (0.008)
2024-04-06 16:06:03,831 - train - INFO - Train: 12 [ 300/781 ( 38%)]  Loss:  3.584507 (3.8761)  Time: 0.829s,  154.35/s  (0.852s,  150.30/s)  LR: 4.923e-04  Data: 0.012 (0.008)
2024-04-06 16:06:49,641 - train - INFO - Train: 12 [ 350/781 ( 45%)]  Loss:  3.661019 (3.8674)  Time: 1.120s,  114.26/s  (0.861s,  148.69/s)  LR: 4.923e-04  Data: 0.011 (0.008)
2024-04-06 16:07:32,018 - train - INFO - Train: 12 [ 400/781 ( 51%)]  Loss:  3.613703 (3.8651)  Time: 1.140s,  112.23/s  (0.859s,  148.98/s)  LR: 4.923e-04  Data: 0.013 (0.008)
2024-04-06 16:08:20,813 - train - INFO - Train: 12 [ 450/781 ( 58%)]  Loss:  3.505903 (3.8686)  Time: 1.060s,  120.74/s  (0.872s,  146.77/s)  LR: 4.923e-04  Data: 0.010 (0.008)
2024-04-06 16:09:07,334 - train - INFO - Train: 12 [ 500/781 ( 64%)]  Loss:  4.236728 (3.8658)  Time: 0.782s,  163.63/s  (0.878s,  145.80/s)  LR: 4.923e-04  Data: 0.008 (0.008)
2024-04-06 16:09:52,887 - train - INFO - Train: 12 [ 550/781 ( 71%)]  Loss:  3.224998 (3.8570)  Time: 0.814s,  157.29/s  (0.881s,  145.30/s)  LR: 4.923e-04  Data: 0.007 (0.008)
2024-04-06 16:10:38,742 - train - INFO - Train: 12 [ 600/781 ( 77%)]  Loss:  3.532862 (3.8546)  Time: 0.821s,  155.87/s  (0.884s,  144.81/s)  LR: 4.923e-04  Data: 0.010 (0.008)
2024-04-06 16:11:22,275 - train - INFO - Train: 12 [ 650/781 ( 83%)]  Loss:  3.357040 (3.8518)  Time: 1.006s,  127.28/s  (0.883s,  144.98/s)  LR: 4.923e-04  Data: 0.006 (0.008)
2024-04-06 16:12:03,913 - train - INFO - Train: 12 [ 700/781 ( 90%)]  Loss:  4.042688 (3.8528)  Time: 0.823s,  155.52/s  (0.879s,  145.57/s)  LR: 4.923e-04  Data: 0.008 (0.008)
2024-04-06 16:12:48,290 - train - INFO - Train: 12 [ 750/781 ( 96%)]  Loss:  3.243312 (3.8483)  Time: 0.826s,  155.01/s  (0.880s,  145.48/s)  LR: 4.923e-04  Data: 0.010 (0.008)
2024-04-06 16:13:15,576 - train - INFO - Train: 12 [ 780/781 (100%)]  Loss:  3.796767 (3.8519)  Time: 0.814s,  157.23/s  (0.881s,  145.29/s)  LR: 4.923e-04  Data: 0.000 (0.008)
2024-04-06 16:13:15,577 - train - INFO - True
2024-04-06 16:13:15,579 - train - INFO - alphas:tensor([0.3020, 0.2163, 0.1490, 0.1629, 0.1699], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,580 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,580 - train - INFO - True
2024-04-06 16:13:15,581 - train - INFO - alphas:tensor([0.3592, 0.1695, 0.1304, 0.1577, 0.1832], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,581 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,581 - train - INFO - True
2024-04-06 16:13:15,583 - train - INFO - alphas:tensor([0.6328, 0.1264, 0.0768, 0.0804, 0.0836], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,583 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,583 - train - INFO - True
2024-04-06 16:13:15,585 - train - INFO - alphas:tensor([0.6199, 0.1141, 0.0788, 0.0906, 0.0967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,585 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,585 - train - INFO - True
2024-04-06 16:13:15,586 - train - INFO - alphas:tensor([0.5151, 0.1325, 0.1018, 0.1190, 0.1317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,586 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,587 - train - INFO - True
2024-04-06 16:13:15,588 - train - INFO - alphas:tensor([0.6108, 0.1205, 0.0801, 0.0908, 0.0979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,588 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,588 - train - INFO - True
2024-04-06 16:13:15,590 - train - INFO - alphas:tensor([0.7180, 0.0972, 0.0565, 0.0610, 0.0673], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,590 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,590 - train - INFO - True
2024-04-06 16:13:15,591 - train - INFO - alphas:tensor([0.7162, 0.0983, 0.0590, 0.0622, 0.0644], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,591 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,592 - train - INFO - True
2024-04-06 16:13:15,593 - train - INFO - alphas:tensor([0.5555, 0.1178, 0.0922, 0.1103, 0.1243], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,593 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,593 - train - INFO - True
2024-04-06 16:13:15,594 - train - INFO - alphas:tensor([0.6426, 0.1115, 0.0755, 0.0816, 0.0888], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,595 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,595 - train - INFO - True
2024-04-06 16:13:15,596 - train - INFO - alphas:tensor([0.7234, 0.0929, 0.0558, 0.0610, 0.0670], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,596 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,596 - train - INFO - True
2024-04-06 16:13:15,598 - train - INFO - alphas:tensor([0.6852, 0.0998, 0.0668, 0.0733, 0.0749], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,598 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,598 - train - INFO - True
2024-04-06 16:13:15,599 - train - INFO - alphas:tensor([0.5744, 0.1126, 0.0862, 0.1057, 0.1210], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,599 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,599 - train - INFO - True
2024-04-06 16:13:15,601 - train - INFO - alphas:tensor([0.6682, 0.0977, 0.0717, 0.0781, 0.0844], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,601 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,601 - train - INFO - True
2024-04-06 16:13:15,602 - train - INFO - alphas:tensor([0.7094, 0.1018, 0.0604, 0.0617, 0.0667], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,602 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,602 - train - INFO - True
2024-04-06 16:13:15,604 - train - INFO - alphas:tensor([0.6387, 0.1130, 0.0757, 0.0812, 0.0914], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,604 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,604 - train - INFO - True
2024-04-06 16:13:15,605 - train - INFO - alphas:tensor([0.5812, 0.1113, 0.0835, 0.1041, 0.1200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,605 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,605 - train - INFO - True
2024-04-06 16:13:15,607 - train - INFO - alphas:tensor([0.6823, 0.0931, 0.0697, 0.0755, 0.0795], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,607 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,607 - train - INFO - True
2024-04-06 16:13:15,608 - train - INFO - alphas:tensor([0.7307, 0.0917, 0.0562, 0.0588, 0.0626], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,608 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,609 - train - INFO - True
2024-04-06 16:13:15,610 - train - INFO - alphas:tensor([0.6338, 0.1063, 0.0790, 0.0870, 0.0939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,610 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,610 - train - INFO - True
2024-04-06 16:13:15,611 - train - INFO - alphas:tensor([0.5670, 0.1115, 0.0894, 0.1088, 0.1233], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,611 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,611 - train - INFO - True
2024-04-06 16:13:15,613 - train - INFO - alphas:tensor([0.6986, 0.0877, 0.0660, 0.0714, 0.0762], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,613 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,613 - train - INFO - True
2024-04-06 16:13:15,614 - train - INFO - alphas:tensor([0.7505, 0.0877, 0.0505, 0.0537, 0.0576], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,614 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,614 - train - INFO - True
2024-04-06 16:13:15,615 - train - INFO - alphas:tensor([0.6587, 0.0974, 0.0745, 0.0807, 0.0887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,616 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,616 - train - INFO - True
2024-04-06 16:13:15,617 - train - INFO - alphas:tensor([0.5623, 0.1098, 0.0883, 0.1127, 0.1270], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,617 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,617 - train - INFO - True
2024-04-06 16:13:15,618 - train - INFO - alphas:tensor([0.6883, 0.0880, 0.0685, 0.0736, 0.0816], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,618 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,619 - train - INFO - True
2024-04-06 16:13:15,620 - train - INFO - alphas:tensor([0.7427, 0.0818, 0.0532, 0.0582, 0.0641], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,620 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,620 - train - INFO - True
2024-04-06 16:13:15,621 - train - INFO - alphas:tensor([0.6727, 0.0934, 0.0697, 0.0784, 0.0859], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,621 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,621 - train - INFO - True
2024-04-06 16:13:15,622 - train - INFO - alphas:tensor([0.5442, 0.1064, 0.0957, 0.1185, 0.1352], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,623 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,623 - train - INFO - True
2024-04-06 16:13:15,624 - train - INFO - alphas:tensor([0.6804, 0.0887, 0.0689, 0.0766, 0.0853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,624 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,624 - train - INFO - True
2024-04-06 16:13:15,625 - train - INFO - alphas:tensor([0.7174, 0.0841, 0.0579, 0.0658, 0.0747], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,625 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,625 - train - INFO - True
2024-04-06 16:13:15,626 - train - INFO - alphas:tensor([0.6858, 0.0876, 0.0680, 0.0761, 0.0825], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,627 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,627 - train - INFO - True
2024-04-06 16:13:15,628 - train - INFO - alphas:tensor([0.5209, 0.1061, 0.0979, 0.1264, 0.1487], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,628 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,628 - train - INFO - True
2024-04-06 16:13:15,629 - train - INFO - alphas:tensor([0.6544, 0.0929, 0.0736, 0.0848, 0.0943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,629 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,629 - train - INFO - True
2024-04-06 16:13:15,631 - train - INFO - alphas:tensor([0.6850, 0.0903, 0.0632, 0.0764, 0.0852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,631 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,631 - train - INFO - True
2024-04-06 16:13:15,632 - train - INFO - alphas:tensor([0.6550, 0.0941, 0.0728, 0.0847, 0.0934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,632 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,632 - train - INFO - True
2024-04-06 16:13:15,633 - train - INFO - alphas:tensor([0.6027, 0.1005, 0.1383, 0.1585], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:13:15,633 - train - INFO - tau:0.9043820750088043
2024-04-06 16:13:15,633 - train - INFO - avg block size:1.0
2024-04-06 16:13:15,633 - train - INFO - lasso_alpha:1.4641000000000006e-05
2024-04-06 16:13:15,851 - train - INFO - Test: [   0/78]  Time: 0.214 (0.214)  Loss:  1.0107 (1.0107)  Acc@1: 78.1250 (78.1250)  Acc@5: 95.3125 (95.3125)
2024-04-06 16:13:20,570 - train - INFO - Test: [  50/78]  Time: 0.096 (0.097)  Loss:  1.8242 (1.7486)  Acc@1: 52.3438 (59.2525)  Acc@5: 82.8125 (82.1844)
2024-04-06 16:13:22,916 - train - INFO - Test: [  78/78]  Time: 0.055 (0.092)  Loss:  1.8271 (1.7708)  Acc@1: 62.5000 (58.9800)  Acc@5: 81.2500 (81.6900)
2024-04-06 16:13:24,224 - train - INFO - Train: 13 [   0/781 (  0%)]  Loss:  3.835574 (3.8356)  Time: 1.241s,  103.13/s  (1.241s,  103.13/s)  LR: 4.910e-04  Data: 0.189 (0.189)
2024-04-06 16:14:10,458 - train - INFO - Train: 13 [  50/781 (  6%)]  Loss:  4.265433 (3.8350)  Time: 0.828s,  154.52/s  (0.931s,  137.51/s)  LR: 4.910e-04  Data: 0.008 (0.011)
2024-04-06 16:14:54,629 - train - INFO - Train: 13 [ 100/781 ( 13%)]  Loss:  3.970354 (3.8696)  Time: 0.832s,  153.79/s  (0.907s,  141.07/s)  LR: 4.910e-04  Data: 0.008 (0.009)
2024-04-06 16:15:39,146 - train - INFO - Train: 13 [ 150/781 ( 19%)]  Loss:  3.532801 (3.8724)  Time: 0.831s,  153.98/s  (0.902s,  141.95/s)  LR: 4.910e-04  Data: 0.009 (0.009)
2024-04-06 16:16:24,612 - train - INFO - Train: 13 [ 200/781 ( 26%)]  Loss:  3.370897 (3.8461)  Time: 0.796s,  160.76/s  (0.904s,  141.66/s)  LR: 4.910e-04  Data: 0.006 (0.009)
2024-04-06 16:17:06,567 - train - INFO - Train: 13 [ 250/781 ( 32%)]  Loss:  4.344401 (3.8409)  Time: 0.819s,  156.35/s  (0.891s,  143.70/s)  LR: 4.910e-04  Data: 0.008 (0.008)
2024-04-06 16:17:49,660 - train - INFO - Train: 13 [ 300/781 ( 38%)]  Loss:  3.531203 (3.8396)  Time: 0.875s,  146.28/s  (0.886s,  144.48/s)  LR: 4.910e-04  Data: 0.008 (0.008)
2024-04-06 16:18:33,708 - train - INFO - Train: 13 [ 350/781 ( 45%)]  Loss:  4.137936 (3.8306)  Time: 0.783s,  163.51/s  (0.885s,  144.60/s)  LR: 4.910e-04  Data: 0.005 (0.008)
2024-04-06 16:19:13,693 - train - INFO - Train: 13 [ 400/781 ( 51%)]  Loss:  3.642362 (3.8242)  Time: 0.782s,  163.64/s  (0.875s,  146.36/s)  LR: 4.910e-04  Data: 0.005 (0.008)
2024-04-06 16:19:54,326 - train - INFO - Train: 13 [ 450/781 ( 58%)]  Loss:  3.822773 (3.8268)  Time: 0.771s,  166.02/s  (0.868s,  147.52/s)  LR: 4.910e-04  Data: 0.005 (0.008)
2024-04-06 16:20:34,953 - train - INFO - Train: 13 [ 500/781 ( 64%)]  Loss:  3.300490 (3.8265)  Time: 0.804s,  159.13/s  (0.862s,  148.46/s)  LR: 4.910e-04  Data: 0.008 (0.008)
2024-04-06 16:21:15,829 - train - INFO - Train: 13 [ 550/781 ( 71%)]  Loss:  3.310389 (3.8299)  Time: 0.819s,  156.36/s  (0.858s,  149.16/s)  LR: 4.910e-04  Data: 0.009 (0.008)
2024-04-06 16:21:57,621 - train - INFO - Train: 13 [ 600/781 ( 77%)]  Loss:  3.656877 (3.8320)  Time: 1.130s,  113.32/s  (0.856s,  149.49/s)  LR: 4.910e-04  Data: 0.005 (0.008)
2024-04-06 16:22:38,645 - train - INFO - Train: 13 [ 650/781 ( 83%)]  Loss:  3.323633 (3.8306)  Time: 0.775s,  165.19/s  (0.854s,  149.97/s)  LR: 4.910e-04  Data: 0.005 (0.007)
2024-04-06 16:23:18,601 - train - INFO - Train: 13 [ 700/781 ( 90%)]  Loss:  4.376729 (3.8282)  Time: 1.055s,  121.38/s  (0.850s,  150.65/s)  LR: 4.910e-04  Data: 0.010 (0.007)
2024-04-06 16:23:58,320 - train - INFO - Train: 13 [ 750/781 ( 96%)]  Loss:  3.797069 (3.8324)  Time: 0.780s,  164.17/s  (0.846s,  151.31/s)  LR: 4.910e-04  Data: 0.005 (0.007)
2024-04-06 16:24:22,128 - train - INFO - Train: 13 [ 780/781 (100%)]  Loss:  3.087507 (3.8354)  Time: 1.092s,  117.24/s  (0.844s,  151.67/s)  LR: 4.910e-04  Data: 0.000 (0.007)
2024-04-06 16:24:22,128 - train - INFO - True
2024-04-06 16:24:22,130 - train - INFO - alphas:tensor([0.3051, 0.2102, 0.1486, 0.1642, 0.1719], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,130 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,130 - train - INFO - True
2024-04-06 16:24:22,131 - train - INFO - alphas:tensor([0.3663, 0.1603, 0.1283, 0.1583, 0.1869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,132 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,132 - train - INFO - True
2024-04-06 16:24:22,133 - train - INFO - alphas:tensor([0.6480, 0.1199, 0.0735, 0.0775, 0.0810], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,133 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,133 - train - INFO - True
2024-04-06 16:24:22,134 - train - INFO - alphas:tensor([0.6358, 0.1066, 0.0755, 0.0878, 0.0943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,134 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,134 - train - INFO - True
2024-04-06 16:24:22,135 - train - INFO - alphas:tensor([0.5205, 0.1264, 0.1005, 0.1191, 0.1335], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,135 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,135 - train - INFO - True
2024-04-06 16:24:22,136 - train - INFO - alphas:tensor([0.6245, 0.1140, 0.0771, 0.0884, 0.0960], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,136 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,136 - train - INFO - True
2024-04-06 16:24:22,137 - train - INFO - alphas:tensor([0.7324, 0.0910, 0.0534, 0.0584, 0.0648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,137 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,137 - train - INFO - True
2024-04-06 16:24:22,138 - train - INFO - alphas:tensor([0.7341, 0.0908, 0.0550, 0.0589, 0.0612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,138 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,138 - train - INFO - True
2024-04-06 16:24:22,139 - train - INFO - alphas:tensor([0.5612, 0.1116, 0.0908, 0.1105, 0.1259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,139 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,139 - train - INFO - True
2024-04-06 16:24:22,140 - train - INFO - alphas:tensor([0.6544, 0.1055, 0.0729, 0.0797, 0.0875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,141 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,141 - train - INFO - True
2024-04-06 16:24:22,142 - train - INFO - alphas:tensor([0.7321, 0.0878, 0.0538, 0.0598, 0.0664], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,142 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,142 - train - INFO - True
2024-04-06 16:24:22,143 - train - INFO - alphas:tensor([0.6950, 0.0940, 0.0648, 0.0719, 0.0743], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,143 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,143 - train - INFO - True
2024-04-06 16:24:22,144 - train - INFO - alphas:tensor([0.5835, 0.1050, 0.0839, 0.1053, 0.1222], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,144 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,144 - train - INFO - True
2024-04-06 16:24:22,145 - train - INFO - alphas:tensor([0.6778, 0.0928, 0.0692, 0.0765, 0.0837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,145 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,145 - train - INFO - True
2024-04-06 16:24:22,146 - train - INFO - alphas:tensor([0.7215, 0.0953, 0.0576, 0.0599, 0.0656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,146 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,146 - train - INFO - True
2024-04-06 16:24:22,147 - train - INFO - alphas:tensor([0.6494, 0.1050, 0.0731, 0.0803, 0.0921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,147 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,147 - train - INFO - True
2024-04-06 16:24:22,148 - train - INFO - alphas:tensor([0.5868, 0.1045, 0.0822, 0.1044, 0.1221], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,148 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,148 - train - INFO - True
2024-04-06 16:24:22,149 - train - INFO - alphas:tensor([0.6920, 0.0879, 0.0672, 0.0740, 0.0788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,149 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,150 - train - INFO - True
2024-04-06 16:24:22,150 - train - INFO - alphas:tensor([0.7388, 0.0871, 0.0544, 0.0576, 0.0621], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,151 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,151 - train - INFO - True
2024-04-06 16:24:22,152 - train - INFO - alphas:tensor([0.6384, 0.1003, 0.0775, 0.0876, 0.0963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,152 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,152 - train - INFO - True
2024-04-06 16:24:22,153 - train - INFO - alphas:tensor([0.5720, 0.1049, 0.0882, 0.1093, 0.1256], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,153 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,153 - train - INFO - True
2024-04-06 16:24:22,154 - train - INFO - alphas:tensor([0.7084, 0.0830, 0.0637, 0.0697, 0.0752], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,154 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,154 - train - INFO - True
2024-04-06 16:24:22,155 - train - INFO - alphas:tensor([0.7553, 0.0840, 0.0493, 0.0534, 0.0580], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,155 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,155 - train - INFO - True
2024-04-06 16:24:22,156 - train - INFO - alphas:tensor([0.6592, 0.0926, 0.0735, 0.0825, 0.0922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,156 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,156 - train - INFO - True
2024-04-06 16:24:22,157 - train - INFO - alphas:tensor([0.5668, 0.1033, 0.0871, 0.1133, 0.1295], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,157 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,157 - train - INFO - True
2024-04-06 16:24:22,158 - train - INFO - alphas:tensor([0.7024, 0.0817, 0.0652, 0.0708, 0.0799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,158 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,159 - train - INFO - True
2024-04-06 16:24:22,159 - train - INFO - alphas:tensor([0.7450, 0.0787, 0.0524, 0.0585, 0.0654], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,160 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,160 - train - INFO - True
2024-04-06 16:24:22,161 - train - INFO - alphas:tensor([0.6792, 0.0874, 0.0673, 0.0786, 0.0875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,161 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,161 - train - INFO - True
2024-04-06 16:24:22,162 - train - INFO - alphas:tensor([0.5471, 0.1005, 0.0945, 0.1195, 0.1385], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,162 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,162 - train - INFO - True
2024-04-06 16:24:22,163 - train - INFO - alphas:tensor([0.6891, 0.0839, 0.0666, 0.0754, 0.0850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,163 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,163 - train - INFO - True
2024-04-06 16:24:22,164 - train - INFO - alphas:tensor([0.7213, 0.0798, 0.0571, 0.0658, 0.0759], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,164 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,164 - train - INFO - True
2024-04-06 16:24:22,165 - train - INFO - alphas:tensor([0.6922, 0.0819, 0.0661, 0.0761, 0.0836], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,165 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,165 - train - INFO - True
2024-04-06 16:24:22,166 - train - INFO - alphas:tensor([0.5261, 0.0983, 0.0959, 0.1272, 0.1525], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,166 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,166 - train - INFO - True
2024-04-06 16:24:22,167 - train - INFO - alphas:tensor([0.6644, 0.0871, 0.0710, 0.0833, 0.0941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,167 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,167 - train - INFO - True
2024-04-06 16:24:22,168 - train - INFO - alphas:tensor([0.6927, 0.0845, 0.0610, 0.0756, 0.0862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,169 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,169 - train - INFO - True
2024-04-06 16:24:22,169 - train - INFO - alphas:tensor([0.6646, 0.0879, 0.0702, 0.0836, 0.0937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,170 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,170 - train - INFO - True
2024-04-06 16:24:22,171 - train - INFO - alphas:tensor([0.6106, 0.0971, 0.1356, 0.1567], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:24:22,171 - train - INFO - tau:0.8953382542587163
2024-04-06 16:24:22,171 - train - INFO - avg block size:1.0
2024-04-06 16:24:22,409 - train - INFO - Test: [   0/78]  Time: 0.235 (0.235)  Loss:  0.8271 (0.8271)  Acc@1: 82.8125 (82.8125)  Acc@5: 94.5312 (94.5312)
2024-04-06 16:24:26,699 - train - INFO - Test: [  50/78]  Time: 0.084 (0.089)  Loss:  1.9941 (1.7227)  Acc@1: 50.7812 (59.5741)  Acc@5: 82.0312 (82.5827)
2024-04-06 16:24:28,992 - train - INFO - Test: [  78/78]  Time: 0.051 (0.086)  Loss:  1.6670 (1.7622)  Acc@1: 50.0000 (58.4700)  Acc@5: 93.7500 (81.8400)
2024-04-06 16:24:30,309 - train - INFO - Train: 14 [   0/781 (  0%)]  Loss:  4.197543 (4.1975)  Time: 1.254s,  102.06/s  (1.254s,  102.06/s)  LR: 4.895e-04  Data: 0.197 (0.197)
2024-04-06 16:25:11,301 - train - INFO - Train: 14 [  50/781 (  6%)]  Loss:  3.240319 (3.8076)  Time: 0.779s,  164.26/s  (0.828s,  154.53/s)  LR: 4.895e-04  Data: 0.005 (0.010)
2024-04-06 16:25:51,177 - train - INFO - Train: 14 [ 100/781 ( 13%)]  Loss:  4.492982 (3.8334)  Time: 0.778s,  164.60/s  (0.813s,  157.43/s)  LR: 4.895e-04  Data: 0.005 (0.008)
2024-04-06 16:26:31,697 - train - INFO - Train: 14 [ 150/781 ( 19%)]  Loss:  4.259822 (3.8274)  Time: 0.815s,  156.96/s  (0.812s,  157.60/s)  LR: 4.895e-04  Data: 0.008 (0.008)
2024-04-06 16:27:13,349 - train - INFO - Train: 14 [ 200/781 ( 26%)]  Loss:  3.959901 (3.8222)  Time: 0.779s,  164.30/s  (0.817s,  156.60/s)  LR: 4.895e-04  Data: 0.005 (0.008)
2024-04-06 16:27:55,731 - train - INFO - Train: 14 [ 250/781 ( 32%)]  Loss:  3.288867 (3.8154)  Time: 1.161s,  110.25/s  (0.823s,  155.46/s)  LR: 4.895e-04  Data: 0.007 (0.007)
2024-04-06 16:28:37,736 - train - INFO - Train: 14 [ 300/781 ( 38%)]  Loss:  3.030626 (3.8152)  Time: 0.766s,  167.02/s  (0.826s,  154.93/s)  LR: 4.895e-04  Data: 0.005 (0.007)
2024-04-06 16:29:18,175 - train - INFO - Train: 14 [ 350/781 ( 45%)]  Loss:  3.227018 (3.8162)  Time: 0.789s,  162.29/s  (0.824s,  155.40/s)  LR: 4.895e-04  Data: 0.005 (0.007)
2024-04-06 16:29:59,064 - train - INFO - Train: 14 [ 400/781 ( 51%)]  Loss:  4.507885 (3.8199)  Time: 0.755s,  169.53/s  (0.823s,  155.54/s)  LR: 4.895e-04  Data: 0.004 (0.007)
2024-04-06 16:30:43,642 - train - INFO - Train: 14 [ 450/781 ( 58%)]  Loss:  3.709543 (3.8154)  Time: 0.790s,  162.00/s  (0.831s,  154.12/s)  LR: 4.895e-04  Data: 0.005 (0.007)
2024-04-06 16:31:30,896 - train - INFO - Train: 14 [ 500/781 ( 64%)]  Loss:  3.743973 (3.8159)  Time: 0.798s,  160.32/s  (0.842s,  152.02/s)  LR: 4.895e-04  Data: 0.009 (0.007)
2024-04-06 16:32:13,274 - train - INFO - Train: 14 [ 550/781 ( 71%)]  Loss:  4.005984 (3.8232)  Time: 0.773s,  165.59/s  (0.842s,  151.93/s)  LR: 4.895e-04  Data: 0.005 (0.007)
2024-04-06 16:32:52,906 - train - INFO - Train: 14 [ 600/781 ( 77%)]  Loss:  4.068922 (3.8222)  Time: 0.776s,  164.94/s  (0.838s,  152.69/s)  LR: 4.895e-04  Data: 0.005 (0.007)
2024-04-06 16:33:32,981 - train - INFO - Train: 14 [ 650/781 ( 83%)]  Loss:  4.001547 (3.8287)  Time: 0.776s,  164.91/s  (0.835s,  153.20/s)  LR: 4.895e-04  Data: 0.005 (0.007)
2024-04-06 16:34:12,874 - train - INFO - Train: 14 [ 700/781 ( 90%)]  Loss:  3.455593 (3.8306)  Time: 0.804s,  159.12/s  (0.833s,  153.70/s)  LR: 4.895e-04  Data: 0.007 (0.007)
2024-04-06 16:34:52,698 - train - INFO - Train: 14 [ 750/781 ( 96%)]  Loss:  4.364176 (3.8314)  Time: 0.831s,  154.11/s  (0.830s,  154.15/s)  LR: 4.895e-04  Data: 0.008 (0.007)
2024-04-06 16:35:16,676 - train - INFO - Train: 14 [ 780/781 (100%)]  Loss:  4.256577 (3.8337)  Time: 0.764s,  167.51/s  (0.829s,  154.37/s)  LR: 4.895e-04  Data: 0.000 (0.007)
2024-04-06 16:35:16,677 - train - INFO - True
2024-04-06 16:35:16,678 - train - INFO - alphas:tensor([0.3077, 0.2033, 0.1488, 0.1658, 0.1744], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,678 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,679 - train - INFO - True
2024-04-06 16:35:16,680 - train - INFO - alphas:tensor([0.3739, 0.1515, 0.1253, 0.1582, 0.1910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,680 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,680 - train - INFO - True
2024-04-06 16:35:16,681 - train - INFO - alphas:tensor([0.6631, 0.1132, 0.0705, 0.0748, 0.0784], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,681 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,681 - train - INFO - True
2024-04-06 16:35:16,682 - train - INFO - alphas:tensor([0.6511, 0.0999, 0.0722, 0.0848, 0.0919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,682 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,682 - train - INFO - True
2024-04-06 16:35:16,683 - train - INFO - alphas:tensor([0.5268, 0.1197, 0.0992, 0.1192, 0.1351], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,683 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,683 - train - INFO - True
2024-04-06 16:35:16,684 - train - INFO - alphas:tensor([0.6357, 0.1085, 0.0748, 0.0865, 0.0945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,684 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,684 - train - INFO - True
2024-04-06 16:35:16,685 - train - INFO - alphas:tensor([0.7436, 0.0857, 0.0512, 0.0565, 0.0630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,685 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,685 - train - INFO - True
2024-04-06 16:35:16,686 - train - INFO - alphas:tensor([0.7440, 0.0868, 0.0526, 0.0571, 0.0596], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,687 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,687 - train - INFO - True
2024-04-06 16:35:16,688 - train - INFO - alphas:tensor([0.5698, 0.1056, 0.0888, 0.1094, 0.1264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,688 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,688 - train - INFO - True
2024-04-06 16:35:16,689 - train - INFO - alphas:tensor([0.6643, 0.1004, 0.0708, 0.0781, 0.0864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,689 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,689 - train - INFO - True
2024-04-06 16:35:16,690 - train - INFO - alphas:tensor([0.7412, 0.0827, 0.0519, 0.0586, 0.0656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,690 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,690 - train - INFO - True
2024-04-06 16:35:16,691 - train - INFO - alphas:tensor([0.7040, 0.0892, 0.0625, 0.0706, 0.0737], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,691 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,691 - train - INFO - True
2024-04-06 16:35:16,692 - train - INFO - alphas:tensor([0.5898, 0.0996, 0.0826, 0.1050, 0.1230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,692 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,692 - train - INFO - True
2024-04-06 16:35:16,693 - train - INFO - alphas:tensor([0.6881, 0.0876, 0.0665, 0.0748, 0.0829], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,693 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,693 - train - INFO - True
2024-04-06 16:35:16,694 - train - INFO - alphas:tensor([0.7277, 0.0913, 0.0561, 0.0592, 0.0656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,694 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,694 - train - INFO - True
2024-04-06 16:35:16,695 - train - INFO - alphas:tensor([0.6523, 0.1007, 0.0719, 0.0810, 0.0941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,695 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,695 - train - INFO - True
2024-04-06 16:35:16,696 - train - INFO - alphas:tensor([0.5936, 0.0988, 0.0801, 0.1040, 0.1235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,696 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,697 - train - INFO - True
2024-04-06 16:35:16,697 - train - INFO - alphas:tensor([0.6998, 0.0836, 0.0650, 0.0730, 0.0787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,698 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,698 - train - INFO - True
2024-04-06 16:35:16,698 - train - INFO - alphas:tensor([0.7465, 0.0829, 0.0526, 0.0565, 0.0616], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,699 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,699 - train - INFO - True
2024-04-06 16:35:16,700 - train - INFO - alphas:tensor([0.6447, 0.0948, 0.0751, 0.0871, 0.0983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,700 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,700 - train - INFO - True
2024-04-06 16:35:16,701 - train - INFO - alphas:tensor([0.5757, 0.0993, 0.0868, 0.1100, 0.1282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,701 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,701 - train - INFO - True
2024-04-06 16:35:16,702 - train - INFO - alphas:tensor([0.7205, 0.0782, 0.0607, 0.0671, 0.0735], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,702 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,702 - train - INFO - True
2024-04-06 16:35:16,703 - train - INFO - alphas:tensor([0.7615, 0.0803, 0.0479, 0.0525, 0.0577], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,703 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,703 - train - INFO - True
2024-04-06 16:35:16,704 - train - INFO - alphas:tensor([0.6639, 0.0870, 0.0711, 0.0831, 0.0949], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,704 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,704 - train - INFO - True
2024-04-06 16:35:16,705 - train - INFO - alphas:tensor([0.5715, 0.0974, 0.0855, 0.1135, 0.1322], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,705 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,705 - train - INFO - True
2024-04-06 16:35:16,706 - train - INFO - alphas:tensor([0.7104, 0.0777, 0.0633, 0.0694, 0.0793], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,706 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,706 - train - INFO - True
2024-04-06 16:35:16,707 - train - INFO - alphas:tensor([0.7481, 0.0756, 0.0515, 0.0585, 0.0663], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,707 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,707 - train - INFO - True
2024-04-06 16:35:16,708 - train - INFO - alphas:tensor([0.6805, 0.0833, 0.0662, 0.0797, 0.0902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,708 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,708 - train - INFO - True
2024-04-06 16:35:16,709 - train - INFO - alphas:tensor([0.5525, 0.0942, 0.0927, 0.1196, 0.1410], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,709 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,709 - train - INFO - True
2024-04-06 16:35:16,710 - train - INFO - alphas:tensor([0.6993, 0.0791, 0.0642, 0.0734, 0.0840], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,710 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,710 - train - INFO - True
2024-04-06 16:35:16,711 - train - INFO - alphas:tensor([0.7258, 0.0759, 0.0554, 0.0657, 0.0771], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,711 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,711 - train - INFO - True
2024-04-06 16:35:16,712 - train - INFO - alphas:tensor([0.6963, 0.0781, 0.0639, 0.0765, 0.0852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,712 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,712 - train - INFO - True
2024-04-06 16:35:16,713 - train - INFO - alphas:tensor([0.5286, 0.0924, 0.0944, 0.1283, 0.1564], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,713 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,713 - train - INFO - True
2024-04-06 16:35:16,714 - train - INFO - alphas:tensor([0.6713, 0.0823, 0.0691, 0.0827, 0.0945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,714 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,714 - train - INFO - True
2024-04-06 16:35:16,715 - train - INFO - alphas:tensor([0.6991, 0.0794, 0.0593, 0.0752, 0.0870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,715 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,715 - train - INFO - True
2024-04-06 16:35:16,716 - train - INFO - alphas:tensor([0.6743, 0.0818, 0.0674, 0.0825, 0.0939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,716 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,716 - train - INFO - True
2024-04-06 16:35:16,717 - train - INFO - alphas:tensor([0.6175, 0.0941, 0.1332, 0.1551], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:35:16,717 - train - INFO - tau:0.8863848717161291
2024-04-06 16:35:16,717 - train - INFO - avg block size:1.0
2024-04-06 16:35:16,717 - train - INFO - lasso_alpha:1.610510000000001e-05
2024-04-06 16:35:16,929 - train - INFO - Test: [   0/78]  Time: 0.208 (0.208)  Loss:  0.9136 (0.9136)  Acc@1: 82.0312 (82.0312)  Acc@5: 94.5312 (94.5312)
2024-04-06 16:35:21,117 - train - INFO - Test: [  50/78]  Time: 0.083 (0.086)  Loss:  1.8770 (1.7279)  Acc@1: 57.8125 (59.8346)  Acc@5: 82.0312 (82.6440)
2024-04-06 16:35:23,677 - train - INFO - Test: [  78/78]  Time: 0.067 (0.088)  Loss:  2.1074 (1.7712)  Acc@1: 50.0000 (58.6000)  Acc@5: 75.0000 (82.0100)
2024-04-06 16:35:24,823 - train - INFO - Train: 15 [   0/781 (  0%)]  Loss:  4.372693 (4.3727)  Time: 1.071s,  119.48/s  (1.071s,  119.48/s)  LR: 4.880e-04  Data: 0.185 (0.185)
2024-04-06 16:36:06,944 - train - INFO - Train: 15 [  50/781 (  6%)]  Loss:  3.243080 (3.7832)  Time: 0.857s,  149.29/s  (0.847s,  151.14/s)  LR: 4.880e-04  Data: 0.005 (0.011)
2024-04-06 16:36:47,418 - train - INFO - Train: 15 [ 100/781 ( 13%)]  Loss:  3.525868 (3.8412)  Time: 0.773s,  165.50/s  (0.828s,  154.52/s)  LR: 4.880e-04  Data: 0.004 (0.009)
2024-04-06 16:37:30,426 - train - INFO - Train: 15 [ 150/781 ( 19%)]  Loss:  3.693957 (3.8071)  Time: 0.792s,  161.65/s  (0.839s,  152.59/s)  LR: 4.880e-04  Data: 0.005 (0.008)
2024-04-06 16:38:12,010 - train - INFO - Train: 15 [ 200/781 ( 26%)]  Loss:  4.048393 (3.8125)  Time: 1.113s,  114.97/s  (0.837s,  152.91/s)  LR: 4.880e-04  Data: 0.005 (0.008)
2024-04-06 16:38:53,154 - train - INFO - Train: 15 [ 250/781 ( 32%)]  Loss:  4.170628 (3.8269)  Time: 0.795s,  161.09/s  (0.834s,  153.43/s)  LR: 4.880e-04  Data: 0.006 (0.008)
2024-04-06 16:39:34,953 - train - INFO - Train: 15 [ 300/781 ( 38%)]  Loss:  4.403953 (3.8416)  Time: 0.839s,  152.64/s  (0.835s,  153.38/s)  LR: 4.880e-04  Data: 0.006 (0.008)
2024-04-06 16:40:18,076 - train - INFO - Train: 15 [ 350/781 ( 45%)]  Loss:  3.298427 (3.8233)  Time: 0.765s,  167.24/s  (0.838s,  152.65/s)  LR: 4.880e-04  Data: 0.004 (0.007)
2024-04-06 16:41:01,813 - train - INFO - Train: 15 [ 400/781 ( 51%)]  Loss:  4.355156 (3.8307)  Time: 0.936s,  136.81/s  (0.843s,  151.84/s)  LR: 4.880e-04  Data: 0.008 (0.007)
2024-04-06 16:41:46,908 - train - INFO - Train: 15 [ 450/781 ( 58%)]  Loss:  3.654840 (3.8338)  Time: 1.047s,  122.23/s  (0.850s,  150.67/s)  LR: 4.880e-04  Data: 0.009 (0.007)
2024-04-06 16:42:27,622 - train - INFO - Train: 15 [ 500/781 ( 64%)]  Loss:  3.957494 (3.8338)  Time: 0.820s,  156.11/s  (0.846s,  151.30/s)  LR: 4.880e-04  Data: 0.008 (0.007)
2024-04-06 16:43:07,374 - train - INFO - Train: 15 [ 550/781 ( 71%)]  Loss:  3.796831 (3.8297)  Time: 0.779s,  164.39/s  (0.841s,  152.13/s)  LR: 4.880e-04  Data: 0.005 (0.007)
2024-04-06 16:43:48,197 - train - INFO - Train: 15 [ 600/781 ( 77%)]  Loss:  3.534695 (3.8283)  Time: 0.838s,  152.74/s  (0.839s,  152.51/s)  LR: 4.880e-04  Data: 0.008 (0.007)
2024-04-06 16:44:29,774 - train - INFO - Train: 15 [ 650/781 ( 83%)]  Loss:  4.103145 (3.8332)  Time: 0.816s,  156.94/s  (0.839s,  152.62/s)  LR: 4.880e-04  Data: 0.008 (0.007)
2024-04-06 16:45:10,638 - train - INFO - Train: 15 [ 700/781 ( 90%)]  Loss:  3.763349 (3.8350)  Time: 0.820s,  156.10/s  (0.837s,  152.89/s)  LR: 4.880e-04  Data: 0.008 (0.007)
2024-04-06 16:45:53,259 - train - INFO - Train: 15 [ 750/781 ( 96%)]  Loss:  3.898329 (3.8348)  Time: 0.832s,  153.87/s  (0.838s,  152.71/s)  LR: 4.880e-04  Data: 0.008 (0.007)
2024-04-06 16:46:20,541 - train - INFO - Train: 15 [ 780/781 (100%)]  Loss:  3.203504 (3.8341)  Time: 0.943s,  135.74/s  (0.841s,  152.21/s)  LR: 4.880e-04  Data: 0.000 (0.007)
2024-04-06 16:46:20,542 - train - INFO - True
2024-04-06 16:46:20,545 - train - INFO - alphas:tensor([0.3089, 0.1972, 0.1490, 0.1678, 0.1771], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,545 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,545 - train - INFO - True
2024-04-06 16:46:20,547 - train - INFO - alphas:tensor([0.3780, 0.1446, 0.1232, 0.1590, 0.1952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,547 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,547 - train - INFO - True
2024-04-06 16:46:20,550 - train - INFO - alphas:tensor([0.6758, 0.1075, 0.0680, 0.0724, 0.0762], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,550 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,550 - train - INFO - True
2024-04-06 16:46:20,552 - train - INFO - alphas:tensor([0.6628, 0.0940, 0.0698, 0.0830, 0.0904], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,552 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,552 - train - INFO - True
2024-04-06 16:46:20,554 - train - INFO - alphas:tensor([0.5321, 0.1139, 0.0982, 0.1192, 0.1365], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,554 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,554 - train - INFO - True
2024-04-06 16:46:20,556 - train - INFO - alphas:tensor([0.6454, 0.1039, 0.0725, 0.0848, 0.0934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,556 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,556 - train - INFO - True
2024-04-06 16:46:20,558 - train - INFO - alphas:tensor([0.7522, 0.0819, 0.0493, 0.0548, 0.0618], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,558 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,558 - train - INFO - True
2024-04-06 16:46:20,560 - train - INFO - alphas:tensor([0.7554, 0.0818, 0.0498, 0.0549, 0.0580], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,560 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,560 - train - INFO - True
2024-04-06 16:46:20,562 - train - INFO - alphas:tensor([0.5742, 0.1008, 0.0874, 0.1095, 0.1282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,562 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,562 - train - INFO - True
2024-04-06 16:46:20,564 - train - INFO - alphas:tensor([0.6738, 0.0955, 0.0685, 0.0767, 0.0856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,564 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,564 - train - INFO - True
2024-04-06 16:46:20,566 - train - INFO - alphas:tensor([0.7459, 0.0792, 0.0509, 0.0581, 0.0659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,566 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,566 - train - INFO - True
2024-04-06 16:46:20,568 - train - INFO - alphas:tensor([0.7127, 0.0841, 0.0603, 0.0696, 0.0733], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,568 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,568 - train - INFO - True
2024-04-06 16:46:20,569 - train - INFO - alphas:tensor([0.5940, 0.0953, 0.0807, 0.1052, 0.1247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,570 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,570 - train - INFO - True
2024-04-06 16:46:20,571 - train - INFO - alphas:tensor([0.6943, 0.0834, 0.0653, 0.0739, 0.0831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,571 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,572 - train - INFO - True
2024-04-06 16:46:20,573 - train - INFO - alphas:tensor([0.7309, 0.0882, 0.0551, 0.0592, 0.0666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,573 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,573 - train - INFO - True
2024-04-06 16:46:20,575 - train - INFO - alphas:tensor([0.6523, 0.0969, 0.0711, 0.0825, 0.0972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,575 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,575 - train - INFO - True
2024-04-06 16:46:20,577 - train - INFO - alphas:tensor([0.6012, 0.0922, 0.0781, 0.1037, 0.1248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,577 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,577 - train - INFO - True
2024-04-06 16:46:20,578 - train - INFO - alphas:tensor([0.7061, 0.0794, 0.0635, 0.0724, 0.0786], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,579 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,579 - train - INFO - True
2024-04-06 16:46:20,580 - train - INFO - alphas:tensor([0.7512, 0.0790, 0.0517, 0.0560, 0.0621], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,580 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,580 - train - INFO - True
2024-04-06 16:46:20,582 - train - INFO - alphas:tensor([0.6450, 0.0897, 0.0743, 0.0886, 0.1023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,582 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,582 - train - INFO - True
2024-04-06 16:46:20,583 - train - INFO - alphas:tensor([0.5771, 0.0946, 0.0858, 0.1109, 0.1316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,584 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,584 - train - INFO - True
2024-04-06 16:46:20,585 - train - INFO - alphas:tensor([0.7269, 0.0746, 0.0590, 0.0662, 0.0734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,585 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,585 - train - INFO - True
2024-04-06 16:46:20,587 - train - INFO - alphas:tensor([0.7664, 0.0772, 0.0464, 0.0519, 0.0581], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,587 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,587 - train - INFO - True
2024-04-06 16:46:20,588 - train - INFO - alphas:tensor([0.6638, 0.0829, 0.0706, 0.0845, 0.0982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,589 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,589 - train - INFO - True
2024-04-06 16:46:20,590 - train - INFO - alphas:tensor([0.5751, 0.0916, 0.0841, 0.1142, 0.1350], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,590 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,590 - train - INFO - True
2024-04-06 16:46:20,592 - train - INFO - alphas:tensor([0.7203, 0.0735, 0.0605, 0.0676, 0.0780], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,592 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,592 - train - INFO - True
2024-04-06 16:46:20,593 - train - INFO - alphas:tensor([0.7525, 0.0715, 0.0503, 0.0582, 0.0675], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,593 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,593 - train - INFO - True
2024-04-06 16:46:20,595 - train - INFO - alphas:tensor([0.6805, 0.0792, 0.0650, 0.0813, 0.0941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,595 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,595 - train - INFO - True
2024-04-06 16:46:20,596 - train - INFO - alphas:tensor([0.5532, 0.0891, 0.0916, 0.1211, 0.1450], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,597 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,597 - train - INFO - True
2024-04-06 16:46:20,598 - train - INFO - alphas:tensor([0.7027, 0.0752, 0.0629, 0.0736, 0.0856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,598 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,598 - train - INFO - True
2024-04-06 16:46:20,599 - train - INFO - alphas:tensor([0.7261, 0.0733, 0.0548, 0.0665, 0.0794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,600 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,600 - train - INFO - True
2024-04-06 16:46:20,601 - train - INFO - alphas:tensor([0.6955, 0.0751, 0.0630, 0.0775, 0.0888], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,601 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,601 - train - INFO - True
2024-04-06 16:46:20,602 - train - INFO - alphas:tensor([0.5303, 0.0873, 0.0930, 0.1293, 0.1601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,603 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,603 - train - INFO - True
2024-04-06 16:46:20,604 - train - INFO - alphas:tensor([0.6744, 0.0792, 0.0678, 0.0827, 0.0958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,604 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,604 - train - INFO - True
2024-04-06 16:46:20,605 - train - INFO - alphas:tensor([0.6982, 0.0773, 0.0589, 0.0761, 0.0894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,606 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,606 - train - INFO - True
2024-04-06 16:46:20,607 - train - INFO - alphas:tensor([0.6764, 0.0771, 0.0663, 0.0834, 0.0968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,607 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,607 - train - INFO - True
2024-04-06 16:46:20,608 - train - INFO - alphas:tensor([0.6259, 0.0906, 0.1303, 0.1533], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:46:20,609 - train - INFO - tau:0.8775210229989678
2024-04-06 16:46:20,609 - train - INFO - avg block size:1.0
2024-04-06 16:46:20,838 - train - INFO - Test: [   0/78]  Time: 0.224 (0.224)  Loss:  0.9775 (0.9775)  Acc@1: 81.2500 (81.2500)  Acc@5: 92.9688 (92.9688)
2024-04-06 16:46:25,543 - train - INFO - Test: [  50/78]  Time: 0.107 (0.097)  Loss:  1.9600 (1.7425)  Acc@1: 54.6875 (59.2371)  Acc@5: 79.6875 (82.2304)
2024-04-06 16:46:27,985 - train - INFO - Test: [  78/78]  Time: 0.054 (0.093)  Loss:  1.5576 (1.7702)  Acc@1: 56.2500 (58.5800)  Acc@5: 93.7500 (81.7900)
2024-04-06 16:46:29,065 - train - INFO - Train: 16 [   0/781 (  0%)]  Loss:  4.213684 (4.2137)  Time: 1.012s,  126.53/s  (1.012s,  126.53/s)  LR: 4.864e-04  Data: 0.178 (0.178)
2024-04-06 16:47:11,822 - train - INFO - Train: 16 [  50/781 (  6%)]  Loss:  3.598985 (3.7876)  Time: 0.813s,  157.35/s  (0.858s,  149.15/s)  LR: 4.864e-04  Data: 0.007 (0.010)
2024-04-06 16:47:53,878 - train - INFO - Train: 16 [ 100/781 ( 13%)]  Loss:  3.729037 (3.7764)  Time: 0.809s,  158.28/s  (0.850s,  150.64/s)  LR: 4.864e-04  Data: 0.007 (0.009)
2024-04-06 16:48:37,031 - train - INFO - Train: 16 [ 150/781 ( 19%)]  Loss:  3.713662 (3.8134)  Time: 0.788s,  162.45/s  (0.854s,  149.86/s)  LR: 4.864e-04  Data: 0.005 (0.008)
2024-04-06 16:49:20,107 - train - INFO - Train: 16 [ 200/781 ( 26%)]  Loss:  3.549624 (3.8367)  Time: 0.790s,  161.94/s  (0.856s,  149.54/s)  LR: 4.864e-04  Data: 0.005 (0.008)
2024-04-06 16:50:05,002 - train - INFO - Train: 16 [ 250/781 ( 32%)]  Loss:  4.304324 (3.8394)  Time: 0.819s,  156.38/s  (0.864s,  148.10/s)  LR: 4.864e-04  Data: 0.009 (0.008)
2024-04-06 16:50:49,170 - train - INFO - Train: 16 [ 300/781 ( 38%)]  Loss:  4.364421 (3.8412)  Time: 1.005s,  127.36/s  (0.867s,  147.56/s)  LR: 4.864e-04  Data: 0.006 (0.008)
2024-04-06 16:51:31,724 - train - INFO - Train: 16 [ 350/781 ( 45%)]  Loss:  3.777761 (3.8340)  Time: 1.061s,  120.63/s  (0.865s,  147.96/s)  LR: 4.864e-04  Data: 0.008 (0.008)
2024-04-06 16:52:14,656 - train - INFO - Train: 16 [ 400/781 ( 51%)]  Loss:  4.250402 (3.8356)  Time: 0.796s,  160.72/s  (0.864s,  148.10/s)  LR: 4.864e-04  Data: 0.005 (0.008)
2024-04-06 16:52:55,231 - train - INFO - Train: 16 [ 450/781 ( 58%)]  Loss:  3.940204 (3.8355)  Time: 0.823s,  155.60/s  (0.858s,  149.11/s)  LR: 4.864e-04  Data: 0.008 (0.007)
2024-04-06 16:53:37,484 - train - INFO - Train: 16 [ 500/781 ( 64%)]  Loss:  3.530488 (3.8335)  Time: 0.827s,  154.71/s  (0.857s,  149.34/s)  LR: 4.864e-04  Data: 0.008 (0.007)
2024-04-06 16:54:22,104 - train - INFO - Train: 16 [ 550/781 ( 71%)]  Loss:  3.684449 (3.8285)  Time: 0.772s,  165.85/s  (0.860s,  148.78/s)  LR: 4.864e-04  Data: 0.006 (0.007)
2024-04-06 16:55:03,785 - train - INFO - Train: 16 [ 600/781 ( 77%)]  Loss:  4.463000 (3.8314)  Time: 0.836s,  153.14/s  (0.858s,  149.17/s)  LR: 4.864e-04  Data: 0.009 (0.007)
2024-04-06 16:55:46,134 - train - INFO - Train: 16 [ 650/781 ( 83%)]  Loss:  3.065597 (3.8319)  Time: 0.805s,  159.07/s  (0.857s,  149.32/s)  LR: 4.864e-04  Data: 0.006 (0.007)
2024-04-06 16:56:30,444 - train - INFO - Train: 16 [ 700/781 ( 90%)]  Loss:  4.097600 (3.8260)  Time: 1.163s,  110.08/s  (0.859s,  148.96/s)  LR: 4.864e-04  Data: 0.009 (0.007)
2024-04-06 16:57:12,719 - train - INFO - Train: 16 [ 750/781 ( 96%)]  Loss:  4.080388 (3.8281)  Time: 0.818s,  156.53/s  (0.858s,  149.12/s)  LR: 4.864e-04  Data: 0.005 (0.007)
2024-04-06 16:57:38,288 - train - INFO - Train: 16 [ 780/781 (100%)]  Loss:  3.415501 (3.8311)  Time: 0.824s,  155.30/s  (0.858s,  149.16/s)  LR: 4.864e-04  Data: 0.000 (0.007)
2024-04-06 16:57:38,289 - train - INFO - True
2024-04-06 16:57:38,290 - train - INFO - alphas:tensor([0.3099, 0.1918, 0.1491, 0.1695, 0.1797], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,290 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,290 - train - INFO - True
2024-04-06 16:57:38,291 - train - INFO - alphas:tensor([0.3808, 0.1388, 0.1216, 0.1595, 0.1992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,292 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,292 - train - INFO - True
2024-04-06 16:57:38,293 - train - INFO - alphas:tensor([0.6866, 0.1034, 0.0657, 0.0702, 0.0742], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,293 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,293 - train - INFO - True
2024-04-06 16:57:38,294 - train - INFO - alphas:tensor([0.6732, 0.0895, 0.0675, 0.0809, 0.0889], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,294 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,294 - train - INFO - True
2024-04-06 16:57:38,295 - train - INFO - alphas:tensor([0.5382, 0.1082, 0.0967, 0.1192, 0.1378], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,295 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,295 - train - INFO - True
2024-04-06 16:57:38,296 - train - INFO - alphas:tensor([0.6543, 0.0995, 0.0703, 0.0832, 0.0926], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,296 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,296 - train - INFO - True
2024-04-06 16:57:38,297 - train - INFO - alphas:tensor([0.7605, 0.0777, 0.0478, 0.0534, 0.0606], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,297 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,298 - train - INFO - True
2024-04-06 16:57:38,298 - train - INFO - alphas:tensor([0.7637, 0.0778, 0.0479, 0.0536, 0.0570], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,299 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,299 - train - INFO - True
2024-04-06 16:57:38,300 - train - INFO - alphas:tensor([0.5776, 0.0967, 0.0863, 0.1096, 0.1298], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,300 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,300 - train - INFO - True
2024-04-06 16:57:38,301 - train - INFO - alphas:tensor([0.6814, 0.0913, 0.0668, 0.0756, 0.0849], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,301 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,301 - train - INFO - True
2024-04-06 16:57:38,302 - train - INFO - alphas:tensor([0.7501, 0.0758, 0.0500, 0.0578, 0.0662], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,302 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,302 - train - INFO - True
2024-04-06 16:57:38,303 - train - INFO - alphas:tensor([0.7158, 0.0809, 0.0594, 0.0698, 0.0741], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,303 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,303 - train - INFO - True
2024-04-06 16:57:38,304 - train - INFO - alphas:tensor([0.5964, 0.0910, 0.0796, 0.1060, 0.1270], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,304 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,304 - train - INFO - True
2024-04-06 16:57:38,305 - train - INFO - alphas:tensor([0.6987, 0.0799, 0.0641, 0.0735, 0.0838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,305 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,306 - train - INFO - True
2024-04-06 16:57:38,306 - train - INFO - alphas:tensor([0.7347, 0.0850, 0.0539, 0.0591, 0.0672], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,307 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,307 - train - INFO - True
2024-04-06 16:57:38,308 - train - INFO - alphas:tensor([0.6534, 0.0926, 0.0704, 0.0835, 0.1002], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,308 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,308 - train - INFO - True
2024-04-06 16:57:38,309 - train - INFO - alphas:tensor([0.6023, 0.0883, 0.0773, 0.1047, 0.1274], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,309 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,309 - train - INFO - True
2024-04-06 16:57:38,310 - train - INFO - alphas:tensor([0.7078, 0.0767, 0.0632, 0.0725, 0.0798], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,310 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,310 - train - INFO - True
2024-04-06 16:57:38,311 - train - INFO - alphas:tensor([0.7548, 0.0762, 0.0506, 0.0557, 0.0627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,311 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,311 - train - INFO - True
2024-04-06 16:57:38,312 - train - INFO - alphas:tensor([0.6426, 0.0860, 0.0740, 0.0907, 0.1067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,312 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,312 - train - INFO - True
2024-04-06 16:57:38,313 - train - INFO - alphas:tensor([0.5812, 0.0892, 0.0846, 0.1112, 0.1337], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,313 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,313 - train - INFO - True
2024-04-06 16:57:38,314 - train - INFO - alphas:tensor([0.7338, 0.0713, 0.0571, 0.0649, 0.0730], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,314 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,314 - train - INFO - True
2024-04-06 16:57:38,315 - train - INFO - alphas:tensor([0.7674, 0.0749, 0.0461, 0.0523, 0.0593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,315 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,316 - train - INFO - True
2024-04-06 16:57:38,316 - train - INFO - alphas:tensor([0.6637, 0.0791, 0.0693, 0.0863, 0.1017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,317 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,317 - train - INFO - True
2024-04-06 16:57:38,317 - train - INFO - alphas:tensor([0.5790, 0.0869, 0.0824, 0.1144, 0.1373], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,318 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,318 - train - INFO - True
2024-04-06 16:57:38,319 - train - INFO - alphas:tensor([0.7255, 0.0702, 0.0592, 0.0668, 0.0783], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,319 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,319 - train - INFO - True
2024-04-06 16:57:38,320 - train - INFO - alphas:tensor([0.7542, 0.0687, 0.0492, 0.0588, 0.0691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,320 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,320 - train - INFO - True
2024-04-06 16:57:38,321 - train - INFO - alphas:tensor([0.6793, 0.0764, 0.0636, 0.0828, 0.0979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,321 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,321 - train - INFO - True
2024-04-06 16:57:38,322 - train - INFO - alphas:tensor([0.5554, 0.0843, 0.0901, 0.1219, 0.1483], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,322 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,322 - train - INFO - True
2024-04-06 16:57:38,323 - train - INFO - alphas:tensor([0.7073, 0.0717, 0.0616, 0.0733, 0.0861], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,323 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,323 - train - INFO - True
2024-04-06 16:57:38,324 - train - INFO - alphas:tensor([0.7316, 0.0697, 0.0530, 0.0658, 0.0799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,324 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,324 - train - INFO - True
2024-04-06 16:57:38,325 - train - INFO - alphas:tensor([0.7011, 0.0716, 0.0609, 0.0771, 0.0893], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,325 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,325 - train - INFO - True
2024-04-06 16:57:38,326 - train - INFO - alphas:tensor([0.5302, 0.0825, 0.0920, 0.1308, 0.1645], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,326 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,326 - train - INFO - True
2024-04-06 16:57:38,327 - train - INFO - alphas:tensor([0.6740, 0.0764, 0.0675, 0.0837, 0.0985], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,327 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,327 - train - INFO - True
2024-04-06 16:57:38,328 - train - INFO - alphas:tensor([0.7007, 0.0736, 0.0579, 0.0766, 0.0912], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,328 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,328 - train - INFO - True
2024-04-06 16:57:38,329 - train - INFO - alphas:tensor([0.6791, 0.0739, 0.0651, 0.0835, 0.0984], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,329 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,329 - train - INFO - True
2024-04-06 16:57:38,330 - train - INFO - alphas:tensor([0.6308, 0.0884, 0.1284, 0.1523], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 16:57:38,330 - train - INFO - tau:0.8687458127689781
2024-04-06 16:57:38,330 - train - INFO - avg block size:1.0
2024-04-06 16:57:38,330 - train - INFO - lasso_alpha:1.771561000000001e-05
2024-04-06 16:57:38,558 - train - INFO - Test: [   0/78]  Time: 0.225 (0.225)  Loss:  1.0518 (1.0518)  Acc@1: 76.5625 (76.5625)  Acc@5: 89.0625 (89.0625)
2024-04-06 16:57:43,371 - train - INFO - Test: [  50/78]  Time: 0.085 (0.099)  Loss:  1.8018 (1.7350)  Acc@1: 58.5938 (59.0533)  Acc@5: 85.1562 (82.3836)
2024-04-06 16:57:45,720 - train - INFO - Test: [  78/78]  Time: 0.053 (0.093)  Loss:  1.7109 (1.7537)  Acc@1: 50.0000 (58.7200)  Acc@5: 100.0000 (82.1800)
2024-04-06 16:57:46,975 - train - INFO - Train: 17 [   0/781 (  0%)]  Loss:  4.410727 (4.4107)  Time: 1.189s,  107.69/s  (1.189s,  107.69/s)  LR: 4.846e-04  Data: 0.187 (0.187)
2024-04-06 16:58:29,615 - train - INFO - Train: 17 [  50/781 (  6%)]  Loss:  3.231374 (3.9592)  Time: 0.813s,  157.49/s  (0.859s,  148.95/s)  LR: 4.846e-04  Data: 0.007 (0.011)
2024-04-06 16:59:09,816 - train - INFO - Train: 17 [ 100/781 ( 13%)]  Loss:  3.289160 (3.9103)  Time: 1.029s,  124.38/s  (0.832s,  153.86/s)  LR: 4.846e-04  Data: 0.007 (0.009)
2024-04-06 16:59:49,958 - train - INFO - Train: 17 [ 150/781 ( 19%)]  Loss:  3.836562 (3.9053)  Time: 0.835s,  153.34/s  (0.822s,  155.66/s)  LR: 4.846e-04  Data: 0.007 (0.008)
2024-04-06 17:00:30,628 - train - INFO - Train: 17 [ 200/781 ( 26%)]  Loss:  3.766522 (3.8874)  Time: 0.794s,  161.30/s  (0.820s,  156.08/s)  LR: 4.846e-04  Data: 0.006 (0.007)
2024-04-06 17:01:10,581 - train - INFO - Train: 17 [ 250/781 ( 32%)]  Loss:  3.587620 (3.8692)  Time: 0.813s,  157.49/s  (0.816s,  156.89/s)  LR: 4.846e-04  Data: 0.008 (0.007)
2024-04-06 17:01:50,692 - train - INFO - Train: 17 [ 300/781 ( 38%)]  Loss:  2.984420 (3.8493)  Time: 0.793s,  161.43/s  (0.814s,  157.32/s)  LR: 4.846e-04  Data: 0.006 (0.007)
2024-04-06 17:02:31,581 - train - INFO - Train: 17 [ 350/781 ( 45%)]  Loss:  3.400127 (3.8557)  Time: 0.803s,  159.33/s  (0.814s,  157.21/s)  LR: 4.846e-04  Data: 0.008 (0.007)
2024-04-06 17:03:12,090 - train - INFO - Train: 17 [ 400/781 ( 51%)]  Loss:  3.751233 (3.8474)  Time: 0.778s,  164.52/s  (0.814s,  157.31/s)  LR: 4.846e-04  Data: 0.005 (0.007)
2024-04-06 17:03:53,017 - train - INFO - Train: 17 [ 450/781 ( 58%)]  Loss:  3.467691 (3.8457)  Time: 0.827s,  154.86/s  (0.814s,  157.20/s)  LR: 4.846e-04  Data: 0.008 (0.007)
2024-04-06 17:04:33,251 - train - INFO - Train: 17 [ 500/781 ( 64%)]  Loss:  3.262737 (3.8426)  Time: 0.783s,  163.38/s  (0.813s,  157.39/s)  LR: 4.846e-04  Data: 0.005 (0.007)
2024-04-06 17:05:12,770 - train - INFO - Train: 17 [ 550/781 ( 71%)]  Loss:  3.382330 (3.8507)  Time: 0.774s,  165.30/s  (0.811s,  157.79/s)  LR: 4.846e-04  Data: 0.005 (0.007)
2024-04-06 17:05:53,225 - train - INFO - Train: 17 [ 600/781 ( 77%)]  Loss:  4.097794 (3.8499)  Time: 0.810s,  158.05/s  (0.811s,  157.83/s)  LR: 4.846e-04  Data: 0.007 (0.007)
2024-04-06 17:06:32,774 - train - INFO - Train: 17 [ 650/781 ( 83%)]  Loss:  3.511326 (3.8478)  Time: 0.812s,  157.72/s  (0.809s,  158.13/s)  LR: 4.846e-04  Data: 0.009 (0.007)
2024-04-06 17:07:12,621 - train - INFO - Train: 17 [ 700/781 ( 90%)]  Loss:  3.966219 (3.8477)  Time: 0.818s,  156.38/s  (0.809s,  158.30/s)  LR: 4.846e-04  Data: 0.008 (0.007)
2024-04-06 17:07:53,965 - train - INFO - Train: 17 [ 750/781 ( 96%)]  Loss:  4.186324 (3.8495)  Time: 0.819s,  156.26/s  (0.810s,  158.06/s)  LR: 4.846e-04  Data: 0.008 (0.007)
2024-04-06 17:08:18,166 - train - INFO - Train: 17 [ 780/781 (100%)]  Loss:  4.363965 (3.8519)  Time: 0.771s,  166.09/s  (0.810s,  158.09/s)  LR: 4.846e-04  Data: 0.000 (0.007)
2024-04-06 17:08:18,167 - train - INFO - True
2024-04-06 17:08:18,169 - train - INFO - alphas:tensor([0.3097, 0.1873, 0.1493, 0.1713, 0.1824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,169 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,169 - train - INFO - True
2024-04-06 17:08:18,170 - train - INFO - alphas:tensor([0.3824, 0.1325, 0.1203, 0.1606, 0.2042], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,171 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,171 - train - INFO - True
2024-04-06 17:08:18,172 - train - INFO - alphas:tensor([0.6956, 0.0992, 0.0638, 0.0686, 0.0728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,172 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,173 - train - INFO - True
2024-04-06 17:08:18,174 - train - INFO - alphas:tensor([0.6806, 0.0865, 0.0657, 0.0793, 0.0878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,174 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,174 - train - INFO - True
2024-04-06 17:08:18,175 - train - INFO - alphas:tensor([0.5388, 0.1053, 0.0960, 0.1198, 0.1401], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,176 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,176 - train - INFO - True
2024-04-06 17:08:18,177 - train - INFO - alphas:tensor([0.6593, 0.0968, 0.0691, 0.0825, 0.0923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,177 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,177 - train - INFO - True
2024-04-06 17:08:18,178 - train - INFO - alphas:tensor([0.7653, 0.0754, 0.0465, 0.0526, 0.0602], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,179 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,179 - train - INFO - True
2024-04-06 17:08:18,180 - train - INFO - alphas:tensor([0.7660, 0.0761, 0.0471, 0.0534, 0.0575], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,180 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,180 - train - INFO - True
2024-04-06 17:08:18,182 - train - INFO - alphas:tensor([0.5822, 0.0926, 0.0847, 0.1095, 0.1311], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,182 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,182 - train - INFO - True
2024-04-06 17:08:18,183 - train - INFO - alphas:tensor([0.6882, 0.0876, 0.0652, 0.0744, 0.0846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,183 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,184 - train - INFO - True
2024-04-06 17:08:18,185 - train - INFO - alphas:tensor([0.7526, 0.0737, 0.0495, 0.0577, 0.0666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,185 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,185 - train - INFO - True
2024-04-06 17:08:18,186 - train - INFO - alphas:tensor([0.7200, 0.0777, 0.0580, 0.0696, 0.0747], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,186 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,186 - train - INFO - True
2024-04-06 17:08:18,188 - train - INFO - alphas:tensor([0.6011, 0.0868, 0.0780, 0.1057, 0.1284], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,188 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,188 - train - INFO - True
2024-04-06 17:08:18,189 - train - INFO - alphas:tensor([0.7029, 0.0774, 0.0629, 0.0731, 0.0839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,189 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,189 - train - INFO - True
2024-04-06 17:08:18,191 - train - INFO - alphas:tensor([0.7372, 0.0820, 0.0533, 0.0591, 0.0684], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,191 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,191 - train - INFO - True
2024-04-06 17:08:18,192 - train - INFO - alphas:tensor([0.6510, 0.0890, 0.0698, 0.0855, 0.1047], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,192 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,192 - train - INFO - True
2024-04-06 17:08:18,193 - train - INFO - alphas:tensor([0.6030, 0.0855, 0.0766, 0.1050, 0.1298], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,194 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,194 - train - INFO - True
2024-04-06 17:08:18,195 - train - INFO - alphas:tensor([0.7111, 0.0734, 0.0619, 0.0725, 0.0811], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,195 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,195 - train - INFO - True
2024-04-06 17:08:18,196 - train - INFO - alphas:tensor([0.7530, 0.0742, 0.0505, 0.0571, 0.0652], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,196 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,197 - train - INFO - True
2024-04-06 17:08:18,198 - train - INFO - alphas:tensor([0.6364, 0.0833, 0.0738, 0.0937, 0.1129], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,198 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,198 - train - INFO - True
2024-04-06 17:08:18,199 - train - INFO - alphas:tensor([0.5830, 0.0851, 0.0836, 0.1118, 0.1364], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,199 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,199 - train - INFO - True
2024-04-06 17:08:18,201 - train - INFO - alphas:tensor([0.7377, 0.0682, 0.0562, 0.0646, 0.0732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,201 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,201 - train - INFO - True
2024-04-06 17:08:18,202 - train - INFO - alphas:tensor([0.7682, 0.0731, 0.0457, 0.0525, 0.0605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,202 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,202 - train - INFO - True
2024-04-06 17:08:18,203 - train - INFO - alphas:tensor([0.6608, 0.0755, 0.0684, 0.0885, 0.1068], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,203 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,204 - train - INFO - True
2024-04-06 17:08:18,205 - train - INFO - alphas:tensor([0.5798, 0.0824, 0.0812, 0.1158, 0.1409], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,205 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,205 - train - INFO - True
2024-04-06 17:08:18,206 - train - INFO - alphas:tensor([0.7281, 0.0674, 0.0585, 0.0666, 0.0792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,206 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,206 - train - INFO - True
2024-04-06 17:08:18,207 - train - INFO - alphas:tensor([0.7529, 0.0667, 0.0491, 0.0598, 0.0715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,208 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,208 - train - INFO - True
2024-04-06 17:08:18,209 - train - INFO - alphas:tensor([0.6748, 0.0738, 0.0633, 0.0848, 0.1032], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,209 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,209 - train - INFO - True
2024-04-06 17:08:18,210 - train - INFO - alphas:tensor([0.5577, 0.0797, 0.0886, 0.1224, 0.1515], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,210 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,210 - train - INFO - True
2024-04-06 17:08:18,211 - train - INFO - alphas:tensor([0.7119, 0.0680, 0.0602, 0.0728, 0.0871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,212 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,212 - train - INFO - True
2024-04-06 17:08:18,213 - train - INFO - alphas:tensor([0.7336, 0.0668, 0.0521, 0.0660, 0.0815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,213 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,213 - train - INFO - True
2024-04-06 17:08:18,214 - train - INFO - alphas:tensor([0.6985, 0.0692, 0.0607, 0.0786, 0.0930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,214 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,214 - train - INFO - True
2024-04-06 17:08:18,215 - train - INFO - alphas:tensor([0.5323, 0.0775, 0.0903, 0.1315, 0.1684], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,215 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,216 - train - INFO - True
2024-04-06 17:08:18,217 - train - INFO - alphas:tensor([0.6737, 0.0745, 0.0664, 0.0843, 0.1011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,217 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,217 - train - INFO - True
2024-04-06 17:08:18,218 - train - INFO - alphas:tensor([0.7026, 0.0712, 0.0567, 0.0767, 0.0929], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,218 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,218 - train - INFO - True
2024-04-06 17:08:18,219 - train - INFO - alphas:tensor([0.6806, 0.0708, 0.0635, 0.0843, 0.1008], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,219 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,219 - train - INFO - True
2024-04-06 17:08:18,220 - train - INFO - alphas:tensor([0.6365, 0.0859, 0.1266, 0.1510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:08:18,220 - train - INFO - tau:0.8600583546412883
2024-04-06 17:08:18,221 - train - INFO - avg block size:1.0
2024-04-06 17:08:18,438 - train - INFO - Test: [   0/78]  Time: 0.214 (0.214)  Loss:  1.0713 (1.0713)  Acc@1: 77.3438 (77.3438)  Acc@5: 91.4062 (91.4062)
2024-04-06 17:08:22,609 - train - INFO - Test: [  50/78]  Time: 0.083 (0.086)  Loss:  1.9482 (1.7351)  Acc@1: 57.0312 (59.4669)  Acc@5: 81.2500 (82.1844)
2024-04-06 17:08:24,916 - train - INFO - Test: [  78/78]  Time: 0.062 (0.085)  Loss:  1.5713 (1.7687)  Acc@1: 50.0000 (58.7900)  Acc@5: 100.0000 (81.6800)
2024-04-06 17:08:26,182 - train - INFO - Train: 18 [   0/781 (  0%)]  Loss:  4.087897 (4.0879)  Time: 1.196s,  107.00/s  (1.196s,  107.00/s)  LR: 4.828e-04  Data: 0.189 (0.189)
2024-04-06 17:09:05,760 - train - INFO - Train: 18 [  50/781 (  6%)]  Loss:  4.177707 (3.8829)  Time: 0.790s,  162.12/s  (0.799s,  160.10/s)  LR: 4.828e-04  Data: 0.006 (0.009)
2024-04-06 17:09:46,050 - train - INFO - Train: 18 [ 100/781 ( 13%)]  Loss:  3.395612 (3.8414)  Time: 0.807s,  158.57/s  (0.803s,  159.48/s)  LR: 4.828e-04  Data: 0.008 (0.008)
2024-04-06 17:10:27,272 - train - INFO - Train: 18 [ 150/781 ( 19%)]  Loss:  3.347616 (3.8283)  Time: 0.832s,  153.82/s  (0.810s,  158.06/s)  LR: 4.828e-04  Data: 0.008 (0.008)
2024-04-06 17:11:08,222 - train - INFO - Train: 18 [ 200/781 ( 26%)]  Loss:  3.687328 (3.8297)  Time: 0.760s,  168.45/s  (0.812s,  157.62/s)  LR: 4.828e-04  Data: 0.005 (0.008)
2024-04-06 17:11:48,521 - train - INFO - Train: 18 [ 250/781 ( 32%)]  Loss:  4.177268 (3.8193)  Time: 0.820s,  156.16/s  (0.811s,  157.85/s)  LR: 4.828e-04  Data: 0.008 (0.008)
2024-04-06 17:12:28,865 - train - INFO - Train: 18 [ 300/781 ( 38%)]  Loss:  4.404199 (3.8206)  Time: 0.799s,  160.22/s  (0.810s,  157.98/s)  LR: 4.828e-04  Data: 0.006 (0.007)
2024-04-06 17:13:09,263 - train - INFO - Train: 18 [ 350/781 ( 45%)]  Loss:  3.836739 (3.8304)  Time: 0.775s,  165.25/s  (0.810s,  158.05/s)  LR: 4.828e-04  Data: 0.005 (0.007)
2024-04-06 17:13:50,694 - train - INFO - Train: 18 [ 400/781 ( 51%)]  Loss:  3.897368 (3.8334)  Time: 0.804s,  159.24/s  (0.812s,  157.59/s)  LR: 4.828e-04  Data: 0.005 (0.007)
2024-04-06 17:14:30,734 - train - INFO - Train: 18 [ 450/781 ( 58%)]  Loss:  4.483432 (3.8489)  Time: 0.791s,  161.89/s  (0.811s,  157.84/s)  LR: 4.828e-04  Data: 0.005 (0.007)
2024-04-06 17:15:10,900 - train - INFO - Train: 18 [ 500/781 ( 64%)]  Loss:  3.404761 (3.8416)  Time: 0.821s,  155.95/s  (0.810s,  157.99/s)  LR: 4.828e-04  Data: 0.008 (0.007)
2024-04-06 17:15:52,180 - train - INFO - Train: 18 [ 550/781 ( 71%)]  Loss:  4.079309 (3.8486)  Time: 1.034s,  123.84/s  (0.812s,  157.72/s)  LR: 4.828e-04  Data: 0.008 (0.007)
2024-04-06 17:16:33,696 - train - INFO - Train: 18 [ 600/781 ( 77%)]  Loss:  3.354756 (3.8477)  Time: 0.832s,  153.81/s  (0.813s,  157.42/s)  LR: 4.828e-04  Data: 0.008 (0.007)
2024-04-06 17:17:15,672 - train - INFO - Train: 18 [ 650/781 ( 83%)]  Loss:  3.443291 (3.8441)  Time: 0.786s,  162.88/s  (0.815s,  157.02/s)  LR: 4.828e-04  Data: 0.006 (0.007)
2024-04-06 17:17:57,474 - train - INFO - Train: 18 [ 700/781 ( 90%)]  Loss:  4.459869 (3.8434)  Time: 0.809s,  158.27/s  (0.817s,  156.74/s)  LR: 4.828e-04  Data: 0.008 (0.007)
2024-04-06 17:18:37,593 - train - INFO - Train: 18 [ 750/781 ( 96%)]  Loss:  3.559787 (3.8397)  Time: 0.820s,  156.14/s  (0.816s,  156.92/s)  LR: 4.828e-04  Data: 0.008 (0.007)
2024-04-06 17:19:02,642 - train - INFO - Train: 18 [ 780/781 (100%)]  Loss:  4.039330 (3.8428)  Time: 0.942s,  135.91/s  (0.816s,  156.78/s)  LR: 4.828e-04  Data: 0.000 (0.007)
2024-04-06 17:19:02,643 - train - INFO - True
2024-04-06 17:19:02,645 - train - INFO - alphas:tensor([0.3088, 0.1816, 0.1499, 0.1739, 0.1857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,645 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,645 - train - INFO - True
2024-04-06 17:19:02,647 - train - INFO - alphas:tensor([0.3833, 0.1269, 0.1189, 0.1617, 0.2092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,647 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,647 - train - INFO - True
2024-04-06 17:19:02,648 - train - INFO - alphas:tensor([0.7032, 0.0960, 0.0621, 0.0671, 0.0715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,648 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,649 - train - INFO - True
2024-04-06 17:19:02,650 - train - INFO - alphas:tensor([0.6881, 0.0829, 0.0640, 0.0780, 0.0869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,650 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,650 - train - INFO - True
2024-04-06 17:19:02,652 - train - INFO - alphas:tensor([0.5416, 0.1005, 0.0956, 0.1204, 0.1419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,652 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,652 - train - INFO - True
2024-04-06 17:19:02,653 - train - INFO - alphas:tensor([0.6674, 0.0925, 0.0672, 0.0813, 0.0915], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,653 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,654 - train - INFO - True
2024-04-06 17:19:02,655 - train - INFO - alphas:tensor([0.7691, 0.0731, 0.0456, 0.0521, 0.0600], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,655 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,655 - train - INFO - True
2024-04-06 17:19:02,656 - train - INFO - alphas:tensor([0.7706, 0.0732, 0.0461, 0.0527, 0.0574], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,657 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,657 - train - INFO - True
2024-04-06 17:19:02,658 - train - INFO - alphas:tensor([0.5837, 0.0895, 0.0838, 0.1099, 0.1331], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,658 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,658 - train - INFO - True
2024-04-06 17:19:02,659 - train - INFO - alphas:tensor([0.6909, 0.0850, 0.0643, 0.0744, 0.0854], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,660 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,660 - train - INFO - True
2024-04-06 17:19:02,661 - train - INFO - alphas:tensor([0.7535, 0.0720, 0.0489, 0.0579, 0.0677], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,661 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,661 - train - INFO - True
2024-04-06 17:19:02,663 - train - INFO - alphas:tensor([0.7187, 0.0756, 0.0579, 0.0709, 0.0769], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,663 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,663 - train - INFO - True
2024-04-06 17:19:02,664 - train - INFO - alphas:tensor([0.6027, 0.0838, 0.0773, 0.1058, 0.1303], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,664 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,664 - train - INFO - True
2024-04-06 17:19:02,666 - train - INFO - alphas:tensor([0.7056, 0.0751, 0.0616, 0.0730, 0.0847], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,666 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,666 - train - INFO - True
2024-04-06 17:19:02,667 - train - INFO - alphas:tensor([0.7365, 0.0801, 0.0530, 0.0599, 0.0705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,667 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,667 - train - INFO - True
2024-04-06 17:19:02,669 - train - INFO - alphas:tensor([0.6490, 0.0854, 0.0694, 0.0873, 0.1090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,669 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,669 - train - INFO - True
2024-04-06 17:19:02,670 - train - INFO - alphas:tensor([0.6043, 0.0821, 0.0756, 0.1056, 0.1324], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,670 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,670 - train - INFO - True
2024-04-06 17:19:02,672 - train - INFO - alphas:tensor([0.7095, 0.0722, 0.0620, 0.0735, 0.0828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,672 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,672 - train - INFO - True
2024-04-06 17:19:02,673 - train - INFO - alphas:tensor([0.7555, 0.0718, 0.0496, 0.0570, 0.0661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,673 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,673 - train - INFO - True
2024-04-06 17:19:02,675 - train - INFO - alphas:tensor([0.6354, 0.0794, 0.0726, 0.0954, 0.1172], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,675 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,675 - train - INFO - True
2024-04-06 17:19:02,676 - train - INFO - alphas:tensor([0.5839, 0.0813, 0.0827, 0.1126, 0.1394], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,676 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,676 - train - INFO - True
2024-04-06 17:19:02,677 - train - INFO - alphas:tensor([0.7402, 0.0661, 0.0553, 0.0644, 0.0740], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,678 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,678 - train - INFO - True
2024-04-06 17:19:02,679 - train - INFO - alphas:tensor([0.7676, 0.0716, 0.0455, 0.0532, 0.0621], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,679 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,679 - train - INFO - True
2024-04-06 17:19:02,680 - train - INFO - alphas:tensor([0.6573, 0.0720, 0.0678, 0.0910, 0.1119], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,680 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,681 - train - INFO - True
2024-04-06 17:19:02,682 - train - INFO - alphas:tensor([0.5790, 0.0789, 0.0806, 0.1169, 0.1445], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,682 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,682 - train - INFO - True
2024-04-06 17:19:02,683 - train - INFO - alphas:tensor([0.7314, 0.0651, 0.0575, 0.0663, 0.0797], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,683 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,683 - train - INFO - True
2024-04-06 17:19:02,684 - train - INFO - alphas:tensor([0.7526, 0.0649, 0.0487, 0.0603, 0.0735], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,685 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,685 - train - INFO - True
2024-04-06 17:19:02,686 - train - INFO - alphas:tensor([0.6739, 0.0695, 0.0625, 0.0865, 0.1076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,686 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,686 - train - INFO - True
2024-04-06 17:19:02,687 - train - INFO - alphas:tensor([0.5552, 0.0762, 0.0883, 0.1241, 0.1562], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,687 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,687 - train - INFO - True
2024-04-06 17:19:02,688 - train - INFO - alphas:tensor([0.7116, 0.0658, 0.0600, 0.0735, 0.0891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,689 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,689 - train - INFO - True
2024-04-06 17:19:02,690 - train - INFO - alphas:tensor([0.7320, 0.0652, 0.0518, 0.0668, 0.0842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,690 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,690 - train - INFO - True
2024-04-06 17:19:02,691 - train - INFO - alphas:tensor([0.6963, 0.0661, 0.0605, 0.0804, 0.0967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,691 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,691 - train - INFO - True
2024-04-06 17:19:02,693 - train - INFO - alphas:tensor([0.5302, 0.0734, 0.0899, 0.1331, 0.1735], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,693 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,693 - train - INFO - True
2024-04-06 17:19:02,694 - train - INFO - alphas:tensor([0.6763, 0.0711, 0.0651, 0.0843, 0.1033], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,694 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,694 - train - INFO - True
2024-04-06 17:19:02,695 - train - INFO - alphas:tensor([0.7070, 0.0681, 0.0549, 0.0764, 0.0936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,695 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,695 - train - INFO - True
2024-04-06 17:19:02,696 - train - INFO - alphas:tensor([0.6845, 0.0673, 0.0622, 0.0840, 0.1020], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,697 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,697 - train - INFO - True
2024-04-06 17:19:02,698 - train - INFO - alphas:tensor([0.6415, 0.0840, 0.1247, 0.1497], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:19:02,698 - train - INFO - tau:0.8514577710948754
2024-04-06 17:19:02,698 - train - INFO - avg block size:1.0
2024-04-06 17:19:02,698 - train - INFO - lasso_alpha:1.9487171000000013e-05
2024-04-06 17:19:02,944 - train - INFO - Test: [   0/78]  Time: 0.243 (0.243)  Loss:  1.0977 (1.0977)  Acc@1: 76.5625 (76.5625)  Acc@5: 88.2812 (88.2812)
2024-04-06 17:19:07,337 - train - INFO - Test: [  50/78]  Time: 0.084 (0.091)  Loss:  1.9756 (1.7513)  Acc@1: 52.3438 (59.0686)  Acc@5: 81.2500 (82.2917)
2024-04-06 17:19:10,027 - train - INFO - Test: [  78/78]  Time: 0.133 (0.093)  Loss:  1.5098 (1.7743)  Acc@1: 62.5000 (59.0300)  Acc@5: 93.7500 (81.8600)
2024-04-06 17:19:11,458 - train - INFO - Train: 19 [   0/781 (  0%)]  Loss:  4.351121 (4.3511)  Time: 1.327s,   96.49/s  (1.327s,   96.49/s)  LR: 4.809e-04  Data: 0.199 (0.199)
2024-04-06 17:19:57,377 - train - INFO - Train: 19 [  50/781 (  6%)]  Loss:  3.555891 (3.9049)  Time: 0.788s,  162.52/s  (0.926s,  138.18/s)  LR: 4.809e-04  Data: 0.008 (0.011)
2024-04-06 17:20:45,317 - train - INFO - Train: 19 [ 100/781 ( 13%)]  Loss:  3.102585 (3.8874)  Time: 0.824s,  155.34/s  (0.942s,  135.83/s)  LR: 4.809e-04  Data: 0.011 (0.010)
2024-04-06 17:21:31,033 - train - INFO - Train: 19 [ 150/781 ( 19%)]  Loss:  3.669073 (3.8733)  Time: 1.100s,  116.33/s  (0.933s,  137.18/s)  LR: 4.809e-04  Data: 0.011 (0.009)
2024-04-06 17:22:17,779 - train - INFO - Train: 19 [ 200/781 ( 26%)]  Loss:  3.959785 (3.8583)  Time: 0.810s,  158.03/s  (0.934s,  137.12/s)  LR: 4.809e-04  Data: 0.007 (0.009)
2024-04-06 17:23:02,408 - train - INFO - Train: 19 [ 250/781 ( 32%)]  Loss:  3.512800 (3.8610)  Time: 0.836s,  153.14/s  (0.925s,  138.33/s)  LR: 4.809e-04  Data: 0.008 (0.009)
2024-04-06 17:23:45,263 - train - INFO - Train: 19 [ 300/781 ( 38%)]  Loss:  3.275699 (3.8580)  Time: 0.809s,  158.16/s  (0.914s,  140.04/s)  LR: 4.809e-04  Data: 0.005 (0.009)
2024-04-06 17:24:30,014 - train - INFO - Train: 19 [ 350/781 ( 45%)]  Loss:  4.181486 (3.8495)  Time: 0.790s,  161.94/s  (0.911s,  140.46/s)  LR: 4.809e-04  Data: 0.005 (0.008)
2024-04-06 17:25:14,744 - train - INFO - Train: 19 [ 400/781 ( 51%)]  Loss:  4.398602 (3.8591)  Time: 0.891s,  143.73/s  (0.909s,  140.78/s)  LR: 4.809e-04  Data: 0.004 (0.008)
2024-04-06 17:26:00,213 - train - INFO - Train: 19 [ 450/781 ( 58%)]  Loss:  4.052355 (3.8572)  Time: 1.078s,  118.69/s  (0.909s,  140.78/s)  LR: 4.809e-04  Data: 0.005 (0.008)
2024-04-06 17:26:46,318 - train - INFO - Train: 19 [ 500/781 ( 64%)]  Loss:  3.220509 (3.8500)  Time: 0.811s,  157.90/s  (0.910s,  140.58/s)  LR: 4.809e-04  Data: 0.008 (0.008)
2024-04-06 17:27:30,374 - train - INFO - Train: 19 [ 550/781 ( 71%)]  Loss:  3.361080 (3.8509)  Time: 0.825s,  155.10/s  (0.908s,  141.00/s)  LR: 4.809e-04  Data: 0.006 (0.008)
2024-04-06 17:28:17,557 - train - INFO - Train: 19 [ 600/781 ( 77%)]  Loss:  3.250882 (3.8541)  Time: 1.069s,  119.78/s  (0.911s,  140.54/s)  LR: 4.809e-04  Data: 0.009 (0.008)
2024-04-06 17:29:03,509 - train - INFO - Train: 19 [ 650/781 ( 83%)]  Loss:  4.201878 (3.8597)  Time: 0.825s,  155.18/s  (0.911s,  140.44/s)  LR: 4.809e-04  Data: 0.009 (0.008)
2024-04-06 17:29:48,809 - train - INFO - Train: 19 [ 700/781 ( 90%)]  Loss:  3.840204 (3.8647)  Time: 0.792s,  161.58/s  (0.911s,  140.50/s)  LR: 4.809e-04  Data: 0.006 (0.008)
2024-04-06 17:30:33,617 - train - INFO - Train: 19 [ 750/781 ( 96%)]  Loss:  4.136360 (3.8671)  Time: 0.835s,  153.26/s  (0.910s,  140.65/s)  LR: 4.809e-04  Data: 0.006 (0.008)
2024-04-06 17:30:59,978 - train - INFO - Train: 19 [ 780/781 (100%)]  Loss:  3.311475 (3.8679)  Time: 0.824s,  155.26/s  (0.909s,  140.84/s)  LR: 4.809e-04  Data: 0.000 (0.008)
2024-04-06 17:30:59,979 - train - INFO - True
2024-04-06 17:30:59,981 - train - INFO - alphas:tensor([0.3087, 0.1768, 0.1503, 0.1759, 0.1884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:30:59,982 - train - INFO - tau:0.8429431933839266
2024-04-06 17:30:59,982 - train - INFO - True
2024-04-06 17:30:59,984 - train - INFO - alphas:tensor([0.3828, 0.1226, 0.1173, 0.1628, 0.2146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:30:59,985 - train - INFO - tau:0.8429431933839266
2024-04-06 17:30:59,985 - train - INFO - True
2024-04-06 17:30:59,987 - train - INFO - alphas:tensor([0.7108, 0.0929, 0.0604, 0.0657, 0.0701], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:30:59,990 - train - INFO - tau:0.8429431933839266
2024-04-06 17:30:59,990 - train - INFO - True
2024-04-06 17:30:59,991 - train - INFO - alphas:tensor([0.6951, 0.0795, 0.0624, 0.0768, 0.0862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:30:59,992 - train - INFO - tau:0.8429431933839266
2024-04-06 17:30:59,992 - train - INFO - True
2024-04-06 17:30:59,993 - train - INFO - alphas:tensor([0.5427, 0.0972, 0.0948, 0.1210, 0.1442], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:30:59,994 - train - INFO - tau:0.8429431933839266
2024-04-06 17:30:59,994 - train - INFO - True
2024-04-06 17:30:59,995 - train - INFO - alphas:tensor([0.6718, 0.0900, 0.0658, 0.0807, 0.0918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:30:59,996 - train - INFO - tau:0.8429431933839266
2024-04-06 17:30:59,996 - train - INFO - True
2024-04-06 17:30:59,997 - train - INFO - alphas:tensor([0.7719, 0.0714, 0.0448, 0.0518, 0.0601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:30:59,998 - train - INFO - tau:0.8429431933839266
2024-04-06 17:30:59,998 - train - INFO - True
2024-04-06 17:30:59,999 - train - INFO - alphas:tensor([0.7718, 0.0716, 0.0457, 0.0529, 0.0580], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:30:59,999 - train - INFO - tau:0.8429431933839266
2024-04-06 17:30:59,999 - train - INFO - True
2024-04-06 17:31:00,001 - train - INFO - alphas:tensor([0.5864, 0.0862, 0.0827, 0.1100, 0.1348], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,001 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,001 - train - INFO - True
2024-04-06 17:31:00,002 - train - INFO - alphas:tensor([0.6938, 0.0825, 0.0634, 0.0741, 0.0862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,003 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,003 - train - INFO - True
2024-04-06 17:31:00,004 - train - INFO - alphas:tensor([0.7552, 0.0699, 0.0484, 0.0580, 0.0686], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,004 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,004 - train - INFO - True
2024-04-06 17:31:00,006 - train - INFO - alphas:tensor([0.7167, 0.0741, 0.0583, 0.0719, 0.0790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,006 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,006 - train - INFO - True
2024-04-06 17:31:00,007 - train - INFO - alphas:tensor([0.6057, 0.0808, 0.0757, 0.1057, 0.1321], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,007 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,008 - train - INFO - True
2024-04-06 17:31:00,009 - train - INFO - alphas:tensor([0.7074, 0.0725, 0.0610, 0.0732, 0.0859], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,009 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,009 - train - INFO - True
2024-04-06 17:31:00,010 - train - INFO - alphas:tensor([0.7342, 0.0788, 0.0529, 0.0612, 0.0729], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,010 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,011 - train - INFO - True
2024-04-06 17:31:00,012 - train - INFO - alphas:tensor([0.6449, 0.0825, 0.0692, 0.0896, 0.1138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,012 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,012 - train - INFO - True
2024-04-06 17:31:00,013 - train - INFO - alphas:tensor([0.6063, 0.0786, 0.0745, 0.1060, 0.1346], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,014 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,014 - train - INFO - True
2024-04-06 17:31:00,015 - train - INFO - alphas:tensor([0.7117, 0.0693, 0.0611, 0.0736, 0.0843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,015 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,015 - train - INFO - True
2024-04-06 17:31:00,016 - train - INFO - alphas:tensor([0.7527, 0.0701, 0.0499, 0.0586, 0.0688], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,017 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,017 - train - INFO - True
2024-04-06 17:31:00,018 - train - INFO - alphas:tensor([0.6270, 0.0764, 0.0727, 0.0991, 0.1248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,018 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,018 - train - INFO - True
2024-04-06 17:31:00,019 - train - INFO - alphas:tensor([0.5810, 0.0788, 0.0824, 0.1145, 0.1434], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,019 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,020 - train - INFO - True
2024-04-06 17:31:00,021 - train - INFO - alphas:tensor([0.7394, 0.0639, 0.0554, 0.0653, 0.0760], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,021 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,021 - train - INFO - True
2024-04-06 17:31:00,022 - train - INFO - alphas:tensor([0.7673, 0.0693, 0.0454, 0.0541, 0.0639], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,022 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,023 - train - INFO - True
2024-04-06 17:31:00,024 - train - INFO - alphas:tensor([0.6484, 0.0698, 0.0676, 0.0952, 0.1190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,024 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,024 - train - INFO - True
2024-04-06 17:31:00,025 - train - INFO - alphas:tensor([0.5781, 0.0752, 0.0799, 0.1182, 0.1486], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,025 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,025 - train - INFO - True
2024-04-06 17:31:00,027 - train - INFO - alphas:tensor([0.7347, 0.0624, 0.0564, 0.0659, 0.0806], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,027 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,027 - train - INFO - True
2024-04-06 17:31:00,028 - train - INFO - alphas:tensor([0.7467, 0.0642, 0.0495, 0.0622, 0.0774], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,028 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,028 - train - INFO - True
2024-04-06 17:31:00,029 - train - INFO - alphas:tensor([0.6614, 0.0677, 0.0635, 0.0912, 0.1163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,029 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,030 - train - INFO - True
2024-04-06 17:31:00,031 - train - INFO - alphas:tensor([0.5552, 0.0716, 0.0871, 0.1255, 0.1607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,031 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,031 - train - INFO - True
2024-04-06 17:31:00,032 - train - INFO - alphas:tensor([0.7093, 0.0644, 0.0599, 0.0744, 0.0920], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,032 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,032 - train - INFO - True
2024-04-06 17:31:00,033 - train - INFO - alphas:tensor([0.7313, 0.0633, 0.0516, 0.0675, 0.0864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,034 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,034 - train - INFO - True
2024-04-06 17:31:00,035 - train - INFO - alphas:tensor([0.6925, 0.0636, 0.0602, 0.0826, 0.1012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,035 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,035 - train - INFO - True
2024-04-06 17:31:00,036 - train - INFO - alphas:tensor([0.5295, 0.0701, 0.0885, 0.1342, 0.1778], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,036 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,036 - train - INFO - True
2024-04-06 17:31:00,037 - train - INFO - alphas:tensor([0.6764, 0.0682, 0.0646, 0.0850, 0.1058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,038 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,038 - train - INFO - True
2024-04-06 17:31:00,039 - train - INFO - alphas:tensor([0.7049, 0.0665, 0.0549, 0.0774, 0.0964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,039 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,039 - train - INFO - True
2024-04-06 17:31:00,040 - train - INFO - alphas:tensor([0.6820, 0.0647, 0.0617, 0.0857, 0.1059], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,040 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,040 - train - INFO - True
2024-04-06 17:31:00,041 - train - INFO - alphas:tensor([0.6469, 0.0818, 0.1229, 0.1484], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:31:00,042 - train - INFO - tau:0.8429431933839266
2024-04-06 17:31:00,042 - train - INFO - avg block size:1.0
2024-04-06 17:31:00,274 - train - INFO - Test: [   0/78]  Time: 0.228 (0.228)  Loss:  0.9243 (0.9243)  Acc@1: 78.9062 (78.9062)  Acc@5: 93.7500 (93.7500)
2024-04-06 17:31:05,073 - train - INFO - Test: [  50/78]  Time: 0.098 (0.099)  Loss:  1.8926 (1.7239)  Acc@1: 53.9062 (59.8805)  Acc@5: 83.5938 (82.8431)
2024-04-06 17:31:07,799 - train - INFO - Test: [  78/78]  Time: 0.078 (0.098)  Loss:  2.1465 (1.7647)  Acc@1: 56.2500 (59.1000)  Acc@5: 87.5000 (82.0400)
2024-04-06 17:31:09,147 - train - INFO - Train: 20 [   0/781 (  0%)]  Loss:  3.468491 (3.4685)  Time: 1.248s,  102.55/s  (1.248s,  102.55/s)  LR: 4.788e-04  Data: 0.188 (0.188)
2024-04-06 17:31:52,311 - train - INFO - Train: 20 [  50/781 (  6%)]  Loss:  3.363485 (3.7631)  Time: 0.791s,  161.92/s  (0.871s,  147.00/s)  LR: 4.788e-04  Data: 0.006 (0.011)
2024-04-06 17:32:39,371 - train - INFO - Train: 20 [ 100/781 ( 13%)]  Loss:  3.562129 (3.7918)  Time: 1.084s,  118.11/s  (0.906s,  141.34/s)  LR: 4.788e-04  Data: 0.010 (0.010)
2024-04-06 17:33:22,934 - train - INFO - Train: 20 [ 150/781 ( 19%)]  Loss:  4.289541 (3.8525)  Time: 1.080s,  118.56/s  (0.894s,  143.14/s)  LR: 4.788e-04  Data: 0.012 (0.009)
2024-04-06 17:34:08,767 - train - INFO - Train: 20 [ 200/781 ( 26%)]  Loss:  4.444527 (3.8447)  Time: 0.835s,  153.27/s  (0.900s,  142.26/s)  LR: 4.788e-04  Data: 0.008 (0.009)
2024-04-06 17:34:53,268 - train - INFO - Train: 20 [ 250/781 ( 32%)]  Loss:  3.877348 (3.8569)  Time: 0.830s,  154.23/s  (0.898s,  142.57/s)  LR: 4.788e-04  Data: 0.008 (0.008)
2024-04-06 17:35:35,189 - train - INFO - Train: 20 [ 300/781 ( 38%)]  Loss:  4.347448 (3.8805)  Time: 0.821s,  155.92/s  (0.888s,  144.15/s)  LR: 4.788e-04  Data: 0.009 (0.008)
2024-04-06 17:36:15,243 - train - INFO - Train: 20 [ 350/781 ( 45%)]  Loss:  4.005522 (3.8862)  Time: 0.779s,  164.23/s  (0.876s,  146.19/s)  LR: 4.788e-04  Data: 0.005 (0.008)
2024-04-06 17:36:56,391 - train - INFO - Train: 20 [ 400/781 ( 51%)]  Loss:  4.280537 (3.8731)  Time: 0.780s,  164.07/s  (0.869s,  147.29/s)  LR: 4.788e-04  Data: 0.006 (0.008)
2024-04-06 17:37:39,050 - train - INFO - Train: 20 [ 450/781 ( 58%)]  Loss:  3.790774 (3.8717)  Time: 0.825s,  155.20/s  (0.867s,  147.59/s)  LR: 4.788e-04  Data: 0.009 (0.008)
2024-04-06 17:38:22,013 - train - INFO - Train: 20 [ 500/781 ( 64%)]  Loss:  3.926574 (3.8803)  Time: 0.822s,  155.67/s  (0.866s,  147.73/s)  LR: 4.788e-04  Data: 0.009 (0.008)
2024-04-06 17:39:02,295 - train - INFO - Train: 20 [ 550/781 ( 71%)]  Loss:  3.425043 (3.8815)  Time: 0.824s,  155.29/s  (0.861s,  148.68/s)  LR: 4.788e-04  Data: 0.009 (0.008)
2024-04-06 17:39:42,202 - train - INFO - Train: 20 [ 600/781 ( 77%)]  Loss:  4.076081 (3.8833)  Time: 0.814s,  157.27/s  (0.856s,  149.58/s)  LR: 4.788e-04  Data: 0.009 (0.008)
2024-04-06 17:40:22,975 - train - INFO - Train: 20 [ 650/781 ( 83%)]  Loss:  3.495917 (3.8757)  Time: 0.819s,  156.20/s  (0.853s,  150.13/s)  LR: 4.788e-04  Data: 0.008 (0.008)
2024-04-06 17:41:04,179 - train - INFO - Train: 20 [ 700/781 ( 90%)]  Loss:  3.477273 (3.8720)  Time: 1.024s,  125.00/s  (0.851s,  150.49/s)  LR: 4.788e-04  Data: 0.008 (0.008)
2024-04-06 17:41:44,109 - train - INFO - Train: 20 [ 750/781 ( 96%)]  Loss:  4.161944 (3.8689)  Time: 0.780s,  164.09/s  (0.847s,  151.10/s)  LR: 4.788e-04  Data: 0.005 (0.007)
2024-04-06 17:42:08,421 - train - INFO - Train: 20 [ 780/781 (100%)]  Loss:  4.458166 (3.8647)  Time: 0.766s,  167.01/s  (0.846s,  151.35/s)  LR: 4.788e-04  Data: 0.000 (0.007)
2024-04-06 17:42:08,421 - train - INFO - True
2024-04-06 17:42:08,423 - train - INFO - alphas:tensor([0.3068, 0.1730, 0.1508, 0.1780, 0.1915], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,423 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,423 - train - INFO - True
2024-04-06 17:42:08,424 - train - INFO - alphas:tensor([0.3825, 0.1186, 0.1154, 0.1638, 0.2197], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,424 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,424 - train - INFO - True
2024-04-06 17:42:08,425 - train - INFO - alphas:tensor([0.7168, 0.0903, 0.0591, 0.0647, 0.0692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,425 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,425 - train - INFO - True
2024-04-06 17:42:08,426 - train - INFO - alphas:tensor([0.6990, 0.0776, 0.0610, 0.0761, 0.0862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,427 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,427 - train - INFO - True
2024-04-06 17:42:08,428 - train - INFO - alphas:tensor([0.5438, 0.0938, 0.0940, 0.1217, 0.1466], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,428 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,428 - train - INFO - True
2024-04-06 17:42:08,429 - train - INFO - alphas:tensor([0.6739, 0.0879, 0.0649, 0.0807, 0.0925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,429 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,429 - train - INFO - True
2024-04-06 17:42:08,430 - train - INFO - alphas:tensor([0.7772, 0.0688, 0.0435, 0.0508, 0.0596], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,430 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,430 - train - INFO - True
2024-04-06 17:42:08,431 - train - INFO - alphas:tensor([0.7751, 0.0696, 0.0445, 0.0525, 0.0583], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,431 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,431 - train - INFO - True
2024-04-06 17:42:08,432 - train - INFO - alphas:tensor([0.5877, 0.0832, 0.0821, 0.1103, 0.1367], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,432 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,432 - train - INFO - True
2024-04-06 17:42:08,433 - train - INFO - alphas:tensor([0.6966, 0.0795, 0.0628, 0.0739, 0.0872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,433 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,433 - train - INFO - True
2024-04-06 17:42:08,434 - train - INFO - alphas:tensor([0.7554, 0.0680, 0.0483, 0.0584, 0.0699], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,434 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,435 - train - INFO - True
2024-04-06 17:42:08,435 - train - INFO - alphas:tensor([0.7171, 0.0720, 0.0575, 0.0725, 0.0808], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,436 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,436 - train - INFO - True
2024-04-06 17:42:08,436 - train - INFO - alphas:tensor([0.6065, 0.0780, 0.0748, 0.1064, 0.1342], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,437 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,437 - train - INFO - True
2024-04-06 17:42:08,438 - train - INFO - alphas:tensor([0.7068, 0.0708, 0.0607, 0.0738, 0.0878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,438 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,438 - train - INFO - True
2024-04-06 17:42:08,439 - train - INFO - alphas:tensor([0.7331, 0.0769, 0.0528, 0.0620, 0.0751], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,439 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,439 - train - INFO - True
2024-04-06 17:42:08,440 - train - INFO - alphas:tensor([0.6425, 0.0794, 0.0683, 0.0914, 0.1184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,440 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,440 - train - INFO - True
2024-04-06 17:42:08,441 - train - INFO - alphas:tensor([0.6059, 0.0757, 0.0737, 0.1070, 0.1377], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,441 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,441 - train - INFO - True
2024-04-06 17:42:08,442 - train - INFO - alphas:tensor([0.7152, 0.0663, 0.0599, 0.0734, 0.0851], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,442 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,442 - train - INFO - True
2024-04-06 17:42:08,443 - train - INFO - alphas:tensor([0.7495, 0.0690, 0.0501, 0.0601, 0.0713], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,443 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,443 - train - INFO - True
2024-04-06 17:42:08,444 - train - INFO - alphas:tensor([0.6236, 0.0734, 0.0714, 0.1011, 0.1305], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,444 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,444 - train - INFO - True
2024-04-06 17:42:08,445 - train - INFO - alphas:tensor([0.5820, 0.0761, 0.0809, 0.1148, 0.1461], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,445 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,445 - train - INFO - True
2024-04-06 17:42:08,446 - train - INFO - alphas:tensor([0.7435, 0.0616, 0.0540, 0.0647, 0.0763], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,446 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,446 - train - INFO - True
2024-04-06 17:42:08,447 - train - INFO - alphas:tensor([0.7664, 0.0678, 0.0451, 0.0548, 0.0659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,447 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,447 - train - INFO - True
2024-04-06 17:42:08,448 - train - INFO - alphas:tensor([0.6423, 0.0663, 0.0666, 0.0985, 0.1263], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,448 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,449 - train - INFO - True
2024-04-06 17:42:08,449 - train - INFO - alphas:tensor([0.5757, 0.0722, 0.0793, 0.1198, 0.1531], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,449 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,450 - train - INFO - True
2024-04-06 17:42:08,450 - train - INFO - alphas:tensor([0.7329, 0.0617, 0.0558, 0.0669, 0.0828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,451 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,451 - train - INFO - True
2024-04-06 17:42:08,451 - train - INFO - alphas:tensor([0.7482, 0.0616, 0.0487, 0.0624, 0.0791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,452 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,452 - train - INFO - True
2024-04-06 17:42:08,452 - train - INFO - alphas:tensor([0.6596, 0.0650, 0.0623, 0.0920, 0.1211], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,453 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,453 - train - INFO - True
2024-04-06 17:42:08,454 - train - INFO - alphas:tensor([0.5553, 0.0688, 0.0857, 0.1262, 0.1640], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,454 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,454 - train - INFO - True
2024-04-06 17:42:08,455 - train - INFO - alphas:tensor([0.7130, 0.0615, 0.0589, 0.0738, 0.0928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,455 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,455 - train - INFO - True
2024-04-06 17:42:08,456 - train - INFO - alphas:tensor([0.7338, 0.0600, 0.0505, 0.0676, 0.0881], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,456 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,456 - train - INFO - True
2024-04-06 17:42:08,457 - train - INFO - alphas:tensor([0.6917, 0.0607, 0.0592, 0.0833, 0.1051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,457 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,457 - train - INFO - True
2024-04-06 17:42:08,458 - train - INFO - alphas:tensor([0.5268, 0.0666, 0.0877, 0.1357, 0.1832], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,458 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,458 - train - INFO - True
2024-04-06 17:42:08,459 - train - INFO - alphas:tensor([0.6752, 0.0654, 0.0636, 0.0861, 0.1098], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,459 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,459 - train - INFO - True
2024-04-06 17:42:08,460 - train - INFO - alphas:tensor([0.7042, 0.0646, 0.0540, 0.0781, 0.0991], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,460 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,460 - train - INFO - True
2024-04-06 17:42:08,461 - train - INFO - alphas:tensor([0.6805, 0.0621, 0.0609, 0.0871, 0.1094], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,461 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,461 - train - INFO - True
2024-04-06 17:42:08,462 - train - INFO - alphas:tensor([0.6505, 0.0801, 0.1215, 0.1479], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:42:08,462 - train - INFO - tau:0.8345137614500874
2024-04-06 17:42:08,462 - train - INFO - avg block size:1.0
2024-04-06 17:42:08,462 - train - INFO - lasso_alpha:2.1435888100000015e-05
2024-04-06 17:42:08,702 - train - INFO - Test: [   0/78]  Time: 0.237 (0.237)  Loss:  1.1240 (1.1240)  Acc@1: 77.3438 (77.3438)  Acc@5: 91.4062 (91.4062)
2024-04-06 17:42:13,490 - train - INFO - Test: [  50/78]  Time: 0.084 (0.099)  Loss:  1.9521 (1.7215)  Acc@1: 52.3438 (59.6048)  Acc@5: 77.3438 (82.4908)
2024-04-06 17:42:16,143 - train - INFO - Test: [  78/78]  Time: 0.051 (0.097)  Loss:  1.7656 (1.7446)  Acc@1: 62.5000 (59.1100)  Acc@5: 81.2500 (82.2300)
2024-04-06 17:42:17,471 - train - INFO - Train: 21 [   0/781 (  0%)]  Loss:  4.358928 (4.3589)  Time: 1.263s,  101.38/s  (1.263s,  101.38/s)  LR: 4.767e-04  Data: 0.191 (0.191)
2024-04-06 17:42:58,385 - train - INFO - Train: 21 [  50/781 (  6%)]  Loss:  3.967549 (3.8728)  Time: 0.787s,  162.62/s  (0.827s,  154.79/s)  LR: 4.767e-04  Data: 0.006 (0.010)
2024-04-06 17:43:39,430 - train - INFO - Train: 21 [ 100/781 ( 13%)]  Loss:  4.303984 (3.8370)  Time: 0.807s,  158.57/s  (0.824s,  155.35/s)  LR: 4.767e-04  Data: 0.006 (0.009)
2024-04-06 17:44:21,073 - train - INFO - Train: 21 [ 150/781 ( 19%)]  Loss:  4.278666 (3.8604)  Time: 0.791s,  161.77/s  (0.827s,  154.80/s)  LR: 4.767e-04  Data: 0.005 (0.008)
2024-04-06 17:45:01,972 - train - INFO - Train: 21 [ 200/781 ( 26%)]  Loss:  4.249292 (3.8770)  Time: 0.761s,  168.11/s  (0.825s,  155.21/s)  LR: 4.767e-04  Data: 0.005 (0.008)
2024-04-06 17:45:42,334 - train - INFO - Train: 21 [ 250/781 ( 32%)]  Loss:  4.330719 (3.8920)  Time: 0.846s,  151.36/s  (0.821s,  155.87/s)  LR: 4.767e-04  Data: 0.008 (0.008)
2024-04-06 17:46:22,721 - train - INFO - Train: 21 [ 300/781 ( 38%)]  Loss:  3.351457 (3.8776)  Time: 0.786s,  162.92/s  (0.819s,  156.30/s)  LR: 4.767e-04  Data: 0.005 (0.007)
2024-04-06 17:47:03,297 - train - INFO - Train: 21 [ 350/781 ( 45%)]  Loss:  4.250369 (3.8904)  Time: 0.829s,  154.45/s  (0.818s,  156.50/s)  LR: 4.767e-04  Data: 0.009 (0.007)
2024-04-06 17:47:43,628 - train - INFO - Train: 21 [ 400/781 ( 51%)]  Loss:  3.317449 (3.8913)  Time: 0.786s,  162.92/s  (0.816s,  156.77/s)  LR: 4.767e-04  Data: 0.005 (0.007)
2024-04-06 17:48:23,397 - train - INFO - Train: 21 [ 450/781 ( 58%)]  Loss:  4.366604 (3.8867)  Time: 0.784s,  163.23/s  (0.814s,  157.22/s)  LR: 4.767e-04  Data: 0.005 (0.007)
2024-04-06 17:49:04,266 - train - INFO - Train: 21 [ 500/781 ( 64%)]  Loss:  4.271890 (3.8828)  Time: 0.820s,  156.18/s  (0.814s,  157.16/s)  LR: 4.767e-04  Data: 0.009 (0.007)
2024-04-06 17:49:45,494 - train - INFO - Train: 21 [ 550/781 ( 71%)]  Loss:  4.116897 (3.8750)  Time: 0.798s,  160.33/s  (0.815s,  156.98/s)  LR: 4.767e-04  Data: 0.006 (0.007)
2024-04-06 17:50:26,650 - train - INFO - Train: 21 [ 600/781 ( 77%)]  Loss:  4.343031 (3.8659)  Time: 0.801s,  159.90/s  (0.816s,  156.86/s)  LR: 4.767e-04  Data: 0.006 (0.007)
2024-04-06 17:51:07,202 - train - INFO - Train: 21 [ 650/781 ( 83%)]  Loss:  3.999244 (3.8659)  Time: 0.818s,  156.52/s  (0.816s,  156.93/s)  LR: 4.767e-04  Data: 0.009 (0.007)
2024-04-06 17:51:47,774 - train - INFO - Train: 21 [ 700/781 ( 90%)]  Loss:  3.265212 (3.8656)  Time: 0.975s,  131.23/s  (0.815s,  156.99/s)  LR: 4.767e-04  Data: 0.006 (0.007)
2024-04-06 17:52:28,489 - train - INFO - Train: 21 [ 750/781 ( 96%)]  Loss:  4.266319 (3.8677)  Time: 0.827s,  154.69/s  (0.815s,  157.00/s)  LR: 4.767e-04  Data: 0.008 (0.007)
2024-04-06 17:52:52,915 - train - INFO - Train: 21 [ 780/781 (100%)]  Loss:  4.143283 (3.8680)  Time: 0.777s,  164.78/s  (0.815s,  157.01/s)  LR: 4.767e-04  Data: 0.000 (0.007)
2024-04-06 17:52:52,916 - train - INFO - True
2024-04-06 17:52:52,918 - train - INFO - alphas:tensor([0.3033, 0.1686, 0.1518, 0.1810, 0.1953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,918 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,918 - train - INFO - True
2024-04-06 17:52:52,919 - train - INFO - alphas:tensor([0.3813, 0.1135, 0.1141, 0.1652, 0.2258], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,919 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,919 - train - INFO - True
2024-04-06 17:52:52,920 - train - INFO - alphas:tensor([0.7220, 0.0879, 0.0579, 0.0637, 0.0684], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,920 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,920 - train - INFO - True
2024-04-06 17:52:52,921 - train - INFO - alphas:tensor([0.7037, 0.0748, 0.0600, 0.0756, 0.0860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,921 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,922 - train - INFO - True
2024-04-06 17:52:52,922 - train - INFO - alphas:tensor([0.5450, 0.0913, 0.0930, 0.1221, 0.1485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,923 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,923 - train - INFO - True
2024-04-06 17:52:52,924 - train - INFO - alphas:tensor([0.6753, 0.0855, 0.0646, 0.0808, 0.0938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,924 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,924 - train - INFO - True
2024-04-06 17:52:52,925 - train - INFO - alphas:tensor([0.7779, 0.0674, 0.0433, 0.0511, 0.0603], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,925 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,925 - train - INFO - True
2024-04-06 17:52:52,926 - train - INFO - alphas:tensor([0.7725, 0.0691, 0.0447, 0.0537, 0.0601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,926 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,926 - train - INFO - True
2024-04-06 17:52:52,927 - train - INFO - alphas:tensor([0.5909, 0.0802, 0.0807, 0.1100, 0.1382], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,927 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,927 - train - INFO - True
2024-04-06 17:52:52,928 - train - INFO - alphas:tensor([0.7004, 0.0777, 0.0612, 0.0734, 0.0873], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,928 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,929 - train - INFO - True
2024-04-06 17:52:52,929 - train - INFO - alphas:tensor([0.7539, 0.0668, 0.0481, 0.0594, 0.0718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,930 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,930 - train - INFO - True
2024-04-06 17:52:52,931 - train - INFO - alphas:tensor([0.7155, 0.0700, 0.0571, 0.0740, 0.0834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,931 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,931 - train - INFO - True
2024-04-06 17:52:52,932 - train - INFO - alphas:tensor([0.6066, 0.0749, 0.0740, 0.1074, 0.1371], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,932 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,932 - train - INFO - True
2024-04-06 17:52:52,933 - train - INFO - alphas:tensor([0.7069, 0.0686, 0.0602, 0.0747, 0.0895], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,933 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,933 - train - INFO - True
2024-04-06 17:52:52,934 - train - INFO - alphas:tensor([0.7275, 0.0764, 0.0536, 0.0642, 0.0784], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,934 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,934 - train - INFO - True
2024-04-06 17:52:52,935 - train - INFO - alphas:tensor([0.6329, 0.0768, 0.0689, 0.0953, 0.1260], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,935 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,935 - train - INFO - True
2024-04-06 17:52:52,936 - train - INFO - alphas:tensor([0.6077, 0.0732, 0.0723, 0.1071, 0.1398], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,936 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,937 - train - INFO - True
2024-04-06 17:52:52,937 - train - INFO - alphas:tensor([0.7152, 0.0645, 0.0597, 0.0738, 0.0869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,938 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,938 - train - INFO - True
2024-04-06 17:52:52,938 - train - INFO - alphas:tensor([0.7464, 0.0678, 0.0501, 0.0614, 0.0742], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,939 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,939 - train - INFO - True
2024-04-06 17:52:52,940 - train - INFO - alphas:tensor([0.6190, 0.0701, 0.0700, 0.1036, 0.1373], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,940 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,940 - train - INFO - True
2024-04-06 17:52:52,941 - train - INFO - alphas:tensor([0.5803, 0.0733, 0.0802, 0.1160, 0.1502], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,941 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,941 - train - INFO - True
2024-04-06 17:52:52,942 - train - INFO - alphas:tensor([0.7426, 0.0605, 0.0534, 0.0653, 0.0782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,942 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,942 - train - INFO - True
2024-04-06 17:52:52,943 - train - INFO - alphas:tensor([0.7615, 0.0678, 0.0453, 0.0564, 0.0691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,943 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,943 - train - INFO - True
2024-04-06 17:52:52,944 - train - INFO - alphas:tensor([0.6342, 0.0633, 0.0660, 0.1017, 0.1348], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,944 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,944 - train - INFO - True
2024-04-06 17:52:52,945 - train - INFO - alphas:tensor([0.5741, 0.0696, 0.0785, 0.1209, 0.1569], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,945 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,945 - train - INFO - True
2024-04-06 17:52:52,946 - train - INFO - alphas:tensor([0.7345, 0.0595, 0.0550, 0.0666, 0.0845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,946 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,946 - train - INFO - True
2024-04-06 17:52:52,947 - train - INFO - alphas:tensor([0.7486, 0.0597, 0.0478, 0.0628, 0.0811], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,947 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,947 - train - INFO - True
2024-04-06 17:52:52,948 - train - INFO - alphas:tensor([0.6529, 0.0627, 0.0619, 0.0946, 0.1279], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,948 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,949 - train - INFO - True
2024-04-06 17:52:52,949 - train - INFO - alphas:tensor([0.5490, 0.0658, 0.0857, 0.1291, 0.1704], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,949 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,950 - train - INFO - True
2024-04-06 17:52:52,950 - train - INFO - alphas:tensor([0.7089, 0.0597, 0.0593, 0.0753, 0.0968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,951 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,951 - train - INFO - True
2024-04-06 17:52:52,951 - train - INFO - alphas:tensor([0.7300, 0.0586, 0.0507, 0.0691, 0.0916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,952 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,952 - train - INFO - True
2024-04-06 17:52:52,953 - train - INFO - alphas:tensor([0.6859, 0.0589, 0.0586, 0.0858, 0.1108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,953 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,953 - train - INFO - True
2024-04-06 17:52:52,954 - train - INFO - alphas:tensor([0.5255, 0.0625, 0.0867, 0.1369, 0.1884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,954 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,954 - train - INFO - True
2024-04-06 17:52:52,955 - train - INFO - alphas:tensor([0.6710, 0.0644, 0.0634, 0.0874, 0.1137], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,955 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,955 - train - INFO - True
2024-04-06 17:52:52,956 - train - INFO - alphas:tensor([0.7037, 0.0628, 0.0531, 0.0788, 0.1016], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,956 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,956 - train - INFO - True
2024-04-06 17:52:52,957 - train - INFO - alphas:tensor([0.6783, 0.0599, 0.0603, 0.0883, 0.1131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,957 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,957 - train - INFO - True
2024-04-06 17:52:52,958 - train - INFO - alphas:tensor([0.6553, 0.0782, 0.1197, 0.1468], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 17:52:52,958 - train - INFO - tau:0.8261686238355865
2024-04-06 17:52:52,958 - train - INFO - avg block size:1.0
2024-04-06 17:52:53,179 - train - INFO - Test: [   0/78]  Time: 0.218 (0.218)  Loss:  0.9116 (0.9116)  Acc@1: 79.6875 (79.6875)  Acc@5: 95.3125 (95.3125)
2024-04-06 17:52:57,422 - train - INFO - Test: [  50/78]  Time: 0.086 (0.087)  Loss:  2.1035 (1.7690)  Acc@1: 49.2188 (58.2721)  Acc@5: 78.1250 (82.4755)
2024-04-06 17:52:59,743 - train - INFO - Test: [  78/78]  Time: 0.053 (0.086)  Loss:  2.3262 (1.7945)  Acc@1: 43.7500 (57.8000)  Acc@5: 87.5000 (81.9200)
2024-04-06 17:53:01,021 - train - INFO - Train: 22 [   0/781 (  0%)]  Loss:  3.394368 (3.3944)  Time: 1.218s,  105.13/s  (1.218s,  105.13/s)  LR: 4.744e-04  Data: 0.179 (0.179)
2024-04-06 17:53:42,162 - train - INFO - Train: 22 [  50/781 (  6%)]  Loss:  4.294624 (3.9738)  Time: 0.797s,  160.70/s  (0.831s,  154.12/s)  LR: 4.744e-04  Data: 0.006 (0.010)
2024-04-06 17:54:23,124 - train - INFO - Train: 22 [ 100/781 ( 13%)]  Loss:  4.116698 (3.9518)  Time: 0.832s,  153.88/s  (0.825s,  155.16/s)  LR: 4.744e-04  Data: 0.008 (0.009)
2024-04-06 17:55:03,816 - train - INFO - Train: 22 [ 150/781 ( 19%)]  Loss:  4.356573 (3.9454)  Time: 0.784s,  163.17/s  (0.821s,  155.86/s)  LR: 4.744e-04  Data: 0.005 (0.008)
2024-04-06 17:55:44,020 - train - INFO - Train: 22 [ 200/781 ( 26%)]  Loss:  3.953161 (3.9514)  Time: 0.790s,  162.06/s  (0.817s,  156.68/s)  LR: 4.744e-04  Data: 0.006 (0.008)
2024-04-06 17:56:23,911 - train - INFO - Train: 22 [ 250/781 ( 32%)]  Loss:  4.237830 (3.9394)  Time: 0.793s,  161.48/s  (0.813s,  157.41/s)  LR: 4.744e-04  Data: 0.005 (0.007)
2024-04-06 17:57:05,075 - train - INFO - Train: 22 [ 300/781 ( 38%)]  Loss:  3.264207 (3.9236)  Time: 0.802s,  159.60/s  (0.815s,  157.09/s)  LR: 4.744e-04  Data: 0.007 (0.008)
2024-04-06 17:57:46,503 - train - INFO - Train: 22 [ 350/781 ( 45%)]  Loss:  4.348316 (3.9102)  Time: 0.786s,  162.95/s  (0.817s,  156.71/s)  LR: 4.744e-04  Data: 0.006 (0.008)
2024-04-06 17:58:26,575 - train - INFO - Train: 22 [ 400/781 ( 51%)]  Loss:  3.786199 (3.9034)  Time: 0.823s,  155.58/s  (0.815s,  157.08/s)  LR: 4.744e-04  Data: 0.009 (0.007)
2024-04-06 17:59:06,573 - train - INFO - Train: 22 [ 450/781 ( 58%)]  Loss:  3.845584 (3.8986)  Time: 0.782s,  163.68/s  (0.813s,  157.40/s)  LR: 4.744e-04  Data: 0.006 (0.007)
2024-04-06 17:59:46,837 - train - INFO - Train: 22 [ 500/781 ( 64%)]  Loss:  3.469232 (3.8945)  Time: 0.789s,  162.18/s  (0.812s,  157.55/s)  LR: 4.744e-04  Data: 0.007 (0.007)
2024-04-06 18:00:26,690 - train - INFO - Train: 22 [ 550/781 ( 71%)]  Loss:  3.942010 (3.8889)  Time: 0.779s,  164.34/s  (0.811s,  157.83/s)  LR: 4.744e-04  Data: 0.005 (0.007)
2024-04-06 18:01:06,393 - train - INFO - Train: 22 [ 600/781 ( 77%)]  Loss:  4.315841 (3.8848)  Time: 0.826s,  154.87/s  (0.810s,  158.10/s)  LR: 4.744e-04  Data: 0.009 (0.007)
2024-04-06 18:01:48,166 - train - INFO - Train: 22 [ 650/781 ( 83%)]  Loss:  4.104108 (3.8755)  Time: 0.822s,  155.67/s  (0.812s,  157.72/s)  LR: 4.744e-04  Data: 0.009 (0.007)
2024-04-06 18:02:28,625 - train - INFO - Train: 22 [ 700/781 ( 90%)]  Loss:  4.145534 (3.8739)  Time: 1.055s,  121.33/s  (0.811s,  157.75/s)  LR: 4.744e-04  Data: 0.008 (0.007)
2024-04-06 18:03:10,271 - train - INFO - Train: 22 [ 750/781 ( 96%)]  Loss:  3.636416 (3.8757)  Time: 0.783s,  163.42/s  (0.813s,  157.47/s)  LR: 4.744e-04  Data: 0.005 (0.007)
2024-04-06 18:03:34,740 - train - INFO - Train: 22 [ 780/781 (100%)]  Loss:  4.340580 (3.8776)  Time: 0.817s,  156.77/s  (0.813s,  157.45/s)  LR: 4.744e-04  Data: 0.000 (0.007)
2024-04-06 18:03:34,742 - train - INFO - True
2024-04-06 18:03:34,744 - train - INFO - alphas:tensor([0.3011, 0.1646, 0.1522, 0.1835, 0.1987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,744 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,744 - train - INFO - True
2024-04-06 18:03:34,746 - train - INFO - alphas:tensor([0.3796, 0.1097, 0.1134, 0.1661, 0.2312], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,746 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,746 - train - INFO - True
2024-04-06 18:03:34,748 - train - INFO - alphas:tensor([0.7277, 0.0856, 0.0567, 0.0626, 0.0674], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,748 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,748 - train - INFO - True
2024-04-06 18:03:34,750 - train - INFO - alphas:tensor([0.7079, 0.0728, 0.0588, 0.0748, 0.0857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,750 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,750 - train - INFO - True
2024-04-06 18:03:34,752 - train - INFO - alphas:tensor([0.5434, 0.0892, 0.0926, 0.1232, 0.1515], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,752 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,752 - train - INFO - True
2024-04-06 18:03:34,753 - train - INFO - alphas:tensor([0.6778, 0.0829, 0.0638, 0.0807, 0.0947], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,754 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,754 - train - INFO - True
2024-04-06 18:03:34,755 - train - INFO - alphas:tensor([0.7794, 0.0660, 0.0428, 0.0510, 0.0608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,755 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,755 - train - INFO - True
2024-04-06 18:03:34,757 - train - INFO - alphas:tensor([0.7699, 0.0693, 0.0446, 0.0544, 0.0619], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,757 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,757 - train - INFO - True
2024-04-06 18:03:34,759 - train - INFO - alphas:tensor([0.5877, 0.0785, 0.0805, 0.1115, 0.1419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,759 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,759 - train - INFO - True
2024-04-06 18:03:34,760 - train - INFO - alphas:tensor([0.7013, 0.0759, 0.0607, 0.0736, 0.0885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,761 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,761 - train - INFO - True
2024-04-06 18:03:34,762 - train - INFO - alphas:tensor([0.7542, 0.0647, 0.0478, 0.0599, 0.0734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,762 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,762 - train - INFO - True
2024-04-06 18:03:34,764 - train - INFO - alphas:tensor([0.7095, 0.0693, 0.0578, 0.0763, 0.0871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,764 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,764 - train - INFO - True
2024-04-06 18:03:34,765 - train - INFO - alphas:tensor([0.6073, 0.0724, 0.0731, 0.1077, 0.1395], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,766 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,766 - train - INFO - True
2024-04-06 18:03:34,767 - train - INFO - alphas:tensor([0.7072, 0.0664, 0.0598, 0.0752, 0.0914], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,767 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,768 - train - INFO - True
2024-04-06 18:03:34,769 - train - INFO - alphas:tensor([0.7255, 0.0744, 0.0533, 0.0656, 0.0811], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,769 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,769 - train - INFO - True
2024-04-06 18:03:34,770 - train - INFO - alphas:tensor([0.6280, 0.0743, 0.0684, 0.0976, 0.1317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,771 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,771 - train - INFO - True
2024-04-06 18:03:34,772 - train - INFO - alphas:tensor([0.6059, 0.0709, 0.0717, 0.1083, 0.1431], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,772 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,772 - train - INFO - True
2024-04-06 18:03:34,774 - train - INFO - alphas:tensor([0.7144, 0.0626, 0.0593, 0.0745, 0.0891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,774 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,774 - train - INFO - True
2024-04-06 18:03:34,775 - train - INFO - alphas:tensor([0.7438, 0.0664, 0.0500, 0.0629, 0.0769], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,775 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,776 - train - INFO - True
2024-04-06 18:03:34,777 - train - INFO - alphas:tensor([0.6152, 0.0671, 0.0683, 0.1055, 0.1439], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,777 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,777 - train - INFO - True
2024-04-06 18:03:34,778 - train - INFO - alphas:tensor([0.5794, 0.0708, 0.0791, 0.1171, 0.1536], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,779 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,779 - train - INFO - True
2024-04-06 18:03:34,780 - train - INFO - alphas:tensor([0.7409, 0.0591, 0.0535, 0.0661, 0.0803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,780 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,780 - train - INFO - True
2024-04-06 18:03:34,781 - train - INFO - alphas:tensor([0.7582, 0.0672, 0.0453, 0.0575, 0.0717], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,782 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,782 - train - INFO - True
2024-04-06 18:03:34,783 - train - INFO - alphas:tensor([0.6288, 0.0613, 0.0653, 0.1036, 0.1411], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,783 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,783 - train - INFO - True
2024-04-06 18:03:34,784 - train - INFO - alphas:tensor([0.5725, 0.0669, 0.0779, 0.1220, 0.1608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,785 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,785 - train - INFO - True
2024-04-06 18:03:34,786 - train - INFO - alphas:tensor([0.7337, 0.0580, 0.0548, 0.0670, 0.0864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,786 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,786 - train - INFO - True
2024-04-06 18:03:34,787 - train - INFO - alphas:tensor([0.7478, 0.0579, 0.0473, 0.0636, 0.0834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,788 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,788 - train - INFO - True
2024-04-06 18:03:34,789 - train - INFO - alphas:tensor([0.6508, 0.0604, 0.0599, 0.0957, 0.1332], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,789 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,789 - train - INFO - True
2024-04-06 18:03:34,790 - train - INFO - alphas:tensor([0.5467, 0.0629, 0.0851, 0.1303, 0.1750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,791 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,791 - train - INFO - True
2024-04-06 18:03:34,792 - train - INFO - alphas:tensor([0.7084, 0.0576, 0.0591, 0.0759, 0.0990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,792 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,792 - train - INFO - True
2024-04-06 18:03:34,793 - train - INFO - alphas:tensor([0.7302, 0.0561, 0.0498, 0.0697, 0.0942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,793 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,794 - train - INFO - True
2024-04-06 18:03:34,795 - train - INFO - alphas:tensor([0.6816, 0.0569, 0.0582, 0.0881, 0.1152], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,795 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,795 - train - INFO - True
2024-04-06 18:03:34,796 - train - INFO - alphas:tensor([0.5241, 0.0603, 0.0853, 0.1376, 0.1928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,796 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,796 - train - INFO - True
2024-04-06 18:03:34,798 - train - INFO - alphas:tensor([0.6729, 0.0616, 0.0619, 0.0874, 0.1162], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,798 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,798 - train - INFO - True
2024-04-06 18:03:34,799 - train - INFO - alphas:tensor([0.7034, 0.0611, 0.0523, 0.0791, 0.1041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,799 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,799 - train - INFO - True
2024-04-06 18:03:34,800 - train - INFO - alphas:tensor([0.6768, 0.0575, 0.0594, 0.0896, 0.1168], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,801 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,801 - train - INFO - True
2024-04-06 18:03:34,802 - train - INFO - alphas:tensor([0.6596, 0.0761, 0.1182, 0.1461], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:03:34,802 - train - INFO - tau:0.8179069375972307
2024-04-06 18:03:34,802 - train - INFO - avg block size:1.0
2024-04-06 18:03:34,802 - train - INFO - lasso_alpha:2.357947691000002e-05
2024-04-06 18:03:35,041 - train - INFO - Test: [   0/78]  Time: 0.235 (0.235)  Loss:  1.0674 (1.0674)  Acc@1: 76.5625 (76.5625)  Acc@5: 91.4062 (91.4062)
2024-04-06 18:03:39,408 - train - INFO - Test: [  50/78]  Time: 0.084 (0.090)  Loss:  1.9785 (1.7469)  Acc@1: 53.1250 (59.4516)  Acc@5: 77.3438 (82.2763)
2024-04-06 18:03:41,716 - train - INFO - Test: [  78/78]  Time: 0.052 (0.087)  Loss:  1.9219 (1.7699)  Acc@1: 56.2500 (58.9700)  Acc@5: 81.2500 (82.1300)
2024-04-06 18:03:42,856 - train - INFO - Train: 23 [   0/781 (  0%)]  Loss:  3.871925 (3.8719)  Time: 1.069s,  119.69/s  (1.069s,  119.69/s)  LR: 4.721e-04  Data: 0.174 (0.174)
2024-04-06 18:04:24,714 - train - INFO - Train: 23 [  50/781 (  6%)]  Loss:  4.279023 (3.8846)  Time: 0.827s,  154.72/s  (0.842s,  152.08/s)  LR: 4.721e-04  Data: 0.008 (0.010)
2024-04-06 18:05:06,365 - train - INFO - Train: 23 [ 100/781 ( 13%)]  Loss:  3.418721 (3.8689)  Time: 0.831s,  153.94/s  (0.837s,  152.86/s)  LR: 4.721e-04  Data: 0.009 (0.009)
2024-04-06 18:05:47,660 - train - INFO - Train: 23 [ 150/781 ( 19%)]  Loss:  3.211565 (3.8553)  Time: 0.822s,  155.76/s  (0.834s,  153.56/s)  LR: 4.721e-04  Data: 0.008 (0.008)
2024-04-06 18:06:28,668 - train - INFO - Train: 23 [ 200/781 ( 26%)]  Loss:  4.028934 (3.8474)  Time: 0.807s,  158.65/s  (0.830s,  154.18/s)  LR: 4.721e-04  Data: 0.008 (0.008)
2024-04-06 18:07:09,118 - train - INFO - Train: 23 [ 250/781 ( 32%)]  Loss:  4.025425 (3.8630)  Time: 0.783s,  163.41/s  (0.826s,  154.97/s)  LR: 4.721e-04  Data: 0.005 (0.008)
2024-04-06 18:07:49,029 - train - INFO - Train: 23 [ 300/781 ( 38%)]  Loss:  3.285475 (3.8415)  Time: 0.796s,  160.78/s  (0.821s,  155.84/s)  LR: 4.721e-04  Data: 0.005 (0.008)
2024-04-06 18:08:30,608 - train - INFO - Train: 23 [ 350/781 ( 45%)]  Loss:  4.225125 (3.8438)  Time: 0.777s,  164.75/s  (0.823s,  155.56/s)  LR: 4.721e-04  Data: 0.006 (0.007)
2024-04-06 18:09:11,080 - train - INFO - Train: 23 [ 400/781 ( 51%)]  Loss:  3.218088 (3.8363)  Time: 0.805s,  158.95/s  (0.821s,  155.88/s)  LR: 4.721e-04  Data: 0.009 (0.007)
2024-04-06 18:09:51,420 - train - INFO - Train: 23 [ 450/781 ( 58%)]  Loss:  3.514529 (3.8434)  Time: 0.774s,  165.35/s  (0.820s,  156.18/s)  LR: 4.721e-04  Data: 0.005 (0.007)
2024-04-06 18:10:31,572 - train - INFO - Train: 23 [ 500/781 ( 64%)]  Loss:  3.678128 (3.8524)  Time: 0.792s,  161.70/s  (0.818s,  156.50/s)  LR: 4.721e-04  Data: 0.005 (0.007)
2024-04-06 18:11:12,562 - train - INFO - Train: 23 [ 550/781 ( 71%)]  Loss:  3.656722 (3.8541)  Time: 0.825s,  155.24/s  (0.818s,  156.46/s)  LR: 4.721e-04  Data: 0.007 (0.007)
2024-04-06 18:11:54,345 - train - INFO - Train: 23 [ 600/781 ( 77%)]  Loss:  4.068575 (3.8592)  Time: 0.816s,  156.96/s  (0.820s,  156.19/s)  LR: 4.721e-04  Data: 0.008 (0.007)
2024-04-06 18:12:36,953 - train - INFO - Train: 23 [ 650/781 ( 83%)]  Loss:  3.872624 (3.8513)  Time: 0.828s,  154.65/s  (0.822s,  155.71/s)  LR: 4.721e-04  Data: 0.009 (0.007)
2024-04-06 18:13:17,642 - train - INFO - Train: 23 [ 700/781 ( 90%)]  Loss:  3.764692 (3.8589)  Time: 0.818s,  156.43/s  (0.821s,  155.82/s)  LR: 4.721e-04  Data: 0.007 (0.007)
2024-04-06 18:13:58,857 - train - INFO - Train: 23 [ 750/781 ( 96%)]  Loss:  4.375137 (3.8611)  Time: 0.787s,  162.64/s  (0.822s,  155.79/s)  LR: 4.721e-04  Data: 0.006 (0.007)
2024-04-06 18:14:23,544 - train - INFO - Train: 23 [ 780/781 (100%)]  Loss:  3.470030 (3.8643)  Time: 0.816s,  156.94/s  (0.822s,  155.78/s)  LR: 4.721e-04  Data: 0.000 (0.007)
2024-04-06 18:14:23,545 - train - INFO - True
2024-04-06 18:14:23,547 - train - INFO - alphas:tensor([0.2975, 0.1604, 0.1527, 0.1866, 0.2027], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,547 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,548 - train - INFO - True
2024-04-06 18:14:23,549 - train - INFO - alphas:tensor([0.3764, 0.1063, 0.1122, 0.1669, 0.2383], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,549 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,549 - train - INFO - True
2024-04-06 18:14:23,551 - train - INFO - alphas:tensor([0.7311, 0.0841, 0.0558, 0.0620, 0.0669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,551 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,551 - train - INFO - True
2024-04-06 18:14:23,553 - train - INFO - alphas:tensor([0.7095, 0.0710, 0.0583, 0.0748, 0.0864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,553 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,553 - train - INFO - True
2024-04-06 18:14:23,555 - train - INFO - alphas:tensor([0.5427, 0.0862, 0.0923, 0.1242, 0.1546], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,555 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,555 - train - INFO - True
2024-04-06 18:14:23,556 - train - INFO - alphas:tensor([0.6747, 0.0815, 0.0643, 0.0823, 0.0972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,556 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,557 - train - INFO - True
2024-04-06 18:14:23,558 - train - INFO - alphas:tensor([0.7818, 0.0644, 0.0422, 0.0508, 0.0609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,558 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,558 - train - INFO - True
2024-04-06 18:14:23,560 - train - INFO - alphas:tensor([0.7659, 0.0690, 0.0450, 0.0559, 0.0642], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,560 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,560 - train - INFO - True
2024-04-06 18:14:23,561 - train - INFO - alphas:tensor([0.5893, 0.0757, 0.0795, 0.1116, 0.1439], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,562 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,562 - train - INFO - True
2024-04-06 18:14:23,563 - train - INFO - alphas:tensor([0.7034, 0.0741, 0.0598, 0.0734, 0.0893], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,563 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,563 - train - INFO - True
2024-04-06 18:14:23,565 - train - INFO - alphas:tensor([0.7495, 0.0645, 0.0482, 0.0616, 0.0763], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,565 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,565 - train - INFO - True
2024-04-06 18:14:23,566 - train - INFO - alphas:tensor([0.7011, 0.0685, 0.0588, 0.0795, 0.0921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,566 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,567 - train - INFO - True
2024-04-06 18:14:23,568 - train - INFO - alphas:tensor([0.6062, 0.0698, 0.0728, 0.1088, 0.1425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,568 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,568 - train - INFO - True
2024-04-06 18:14:23,569 - train - INFO - alphas:tensor([0.7054, 0.0647, 0.0599, 0.0762, 0.0938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,570 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,570 - train - INFO - True
2024-04-06 18:14:23,571 - train - INFO - alphas:tensor([0.7219, 0.0735, 0.0534, 0.0670, 0.0843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,571 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,571 - train - INFO - True
2024-04-06 18:14:23,573 - train - INFO - alphas:tensor([0.6188, 0.0720, 0.0687, 0.1005, 0.1400], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,573 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,573 - train - INFO - True
2024-04-06 18:14:23,574 - train - INFO - alphas:tensor([0.6038, 0.0688, 0.0713, 0.1094, 0.1468], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,574 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,575 - train - INFO - True
2024-04-06 18:14:23,576 - train - INFO - alphas:tensor([0.7085, 0.0623, 0.0598, 0.0764, 0.0931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,576 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,576 - train - INFO - True
2024-04-06 18:14:23,577 - train - INFO - alphas:tensor([0.7385, 0.0649, 0.0504, 0.0652, 0.0810], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,577 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,578 - train - INFO - True
2024-04-06 18:14:23,579 - train - INFO - alphas:tensor([0.6028, 0.0657, 0.0687, 0.1091, 0.1537], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,579 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,579 - train - INFO - True
2024-04-06 18:14:23,580 - train - INFO - alphas:tensor([0.5741, 0.0684, 0.0790, 0.1194, 0.1591], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,581 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,581 - train - INFO - True
2024-04-06 18:14:23,582 - train - INFO - alphas:tensor([0.7371, 0.0576, 0.0541, 0.0679, 0.0833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,582 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,582 - train - INFO - True
2024-04-06 18:14:23,583 - train - INFO - alphas:tensor([0.7559, 0.0654, 0.0453, 0.0589, 0.0744], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,584 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,584 - train - INFO - True
2024-04-06 18:14:23,585 - train - INFO - alphas:tensor([0.6211, 0.0584, 0.0641, 0.1064, 0.1500], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,585 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,585 - train - INFO - True
2024-04-06 18:14:23,586 - train - INFO - alphas:tensor([0.5661, 0.0649, 0.0780, 0.1243, 0.1668], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,586 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,587 - train - INFO - True
2024-04-06 18:14:23,588 - train - INFO - alphas:tensor([0.7274, 0.0570, 0.0558, 0.0692, 0.0907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,588 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,588 - train - INFO - True
2024-04-06 18:14:23,589 - train - INFO - alphas:tensor([0.7446, 0.0567, 0.0470, 0.0649, 0.0868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,589 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,589 - train - INFO - True
2024-04-06 18:14:23,591 - train - INFO - alphas:tensor([0.6394, 0.0590, 0.0600, 0.0995, 0.1422], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,591 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,591 - train - INFO - True
2024-04-06 18:14:23,592 - train - INFO - alphas:tensor([0.5431, 0.0609, 0.0841, 0.1318, 0.1801], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,592 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,592 - train - INFO - True
2024-04-06 18:14:23,593 - train - INFO - alphas:tensor([0.7030, 0.0564, 0.0589, 0.0782, 0.1035], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,594 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,594 - train - INFO - True
2024-04-06 18:14:23,595 - train - INFO - alphas:tensor([0.7291, 0.0545, 0.0491, 0.0705, 0.0969], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,595 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,595 - train - INFO - True
2024-04-06 18:14:23,596 - train - INFO - alphas:tensor([0.6783, 0.0550, 0.0572, 0.0895, 0.1200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,596 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,597 - train - INFO - True
2024-04-06 18:14:23,598 - train - INFO - alphas:tensor([0.5190, 0.0576, 0.0845, 0.1394, 0.1995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,598 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,598 - train - INFO - True
2024-04-06 18:14:23,599 - train - INFO - alphas:tensor([0.6651, 0.0594, 0.0634, 0.0900, 0.1220], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,599 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,599 - train - INFO - True
2024-04-06 18:14:23,600 - train - INFO - alphas:tensor([0.7019, 0.0592, 0.0513, 0.0802, 0.1073], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,601 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,601 - train - INFO - True
2024-04-06 18:14:23,602 - train - INFO - alphas:tensor([0.6716, 0.0554, 0.0591, 0.0915, 0.1224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,602 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,602 - train - INFO - True
2024-04-06 18:14:23,603 - train - INFO - alphas:tensor([0.6630, 0.0749, 0.1167, 0.1454], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:14:23,603 - train - INFO - tau:0.8097278682212583
2024-04-06 18:14:23,603 - train - INFO - avg block size:1.0
2024-04-06 18:14:23,849 - train - INFO - Test: [   0/78]  Time: 0.242 (0.242)  Loss:  0.8936 (0.8936)  Acc@1: 81.2500 (81.2500)  Acc@5: 94.5312 (94.5312)
2024-04-06 18:14:28,219 - train - INFO - Test: [  50/78]  Time: 0.085 (0.090)  Loss:  1.8164 (1.6987)  Acc@1: 60.1562 (60.3707)  Acc@5: 82.8125 (82.8891)
2024-04-06 18:14:30,548 - train - INFO - Test: [  78/78]  Time: 0.052 (0.088)  Loss:  2.1660 (1.7356)  Acc@1: 43.7500 (59.7000)  Acc@5: 75.0000 (82.3600)
2024-04-06 18:14:31,840 - train - INFO - Train: 24 [   0/781 (  0%)]  Loss:  4.451344 (4.4513)  Time: 1.227s,  104.33/s  (1.227s,  104.33/s)  LR: 4.697e-04  Data: 0.179 (0.179)
2024-04-06 18:15:12,434 - train - INFO - Train: 24 [  50/781 (  6%)]  Loss:  3.958599 (3.8787)  Time: 0.835s,  153.33/s  (0.820s,  156.10/s)  LR: 4.697e-04  Data: 0.008 (0.010)
2024-04-06 18:15:52,892 - train - INFO - Train: 24 [ 100/781 ( 13%)]  Loss:  4.376021 (3.8655)  Time: 0.838s,  152.73/s  (0.815s,  157.13/s)  LR: 4.697e-04  Data: 0.009 (0.009)
2024-04-06 18:16:33,519 - train - INFO - Train: 24 [ 150/781 ( 19%)]  Loss:  3.165382 (3.8704)  Time: 0.813s,  157.41/s  (0.814s,  157.26/s)  LR: 4.697e-04  Data: 0.009 (0.008)
2024-04-06 18:17:14,226 - train - INFO - Train: 24 [ 200/781 ( 26%)]  Loss:  4.253377 (3.8421)  Time: 0.828s,  154.66/s  (0.814s,  157.25/s)  LR: 4.697e-04  Data: 0.009 (0.008)
2024-04-06 18:17:55,115 - train - INFO - Train: 24 [ 250/781 ( 32%)]  Loss:  4.093875 (3.8550)  Time: 0.823s,  155.46/s  (0.815s,  157.11/s)  LR: 4.697e-04  Data: 0.009 (0.008)
2024-04-06 18:18:36,699 - train - INFO - Train: 24 [ 300/781 ( 38%)]  Loss:  3.885832 (3.8652)  Time: 0.819s,  156.20/s  (0.818s,  156.57/s)  LR: 4.697e-04  Data: 0.008 (0.008)
2024-04-06 18:19:17,616 - train - INFO - Train: 24 [ 350/781 ( 45%)]  Loss:  3.297503 (3.8565)  Time: 0.805s,  159.10/s  (0.818s,  156.55/s)  LR: 4.697e-04  Data: 0.006 (0.008)
2024-04-06 18:19:57,741 - train - INFO - Train: 24 [ 400/781 ( 51%)]  Loss:  3.158827 (3.8475)  Time: 0.824s,  155.27/s  (0.816s,  156.91/s)  LR: 4.697e-04  Data: 0.008 (0.008)
2024-04-06 18:20:40,878 - train - INFO - Train: 24 [ 450/781 ( 58%)]  Loss:  3.844637 (3.8468)  Time: 0.789s,  162.14/s  (0.821s,  155.92/s)  LR: 4.697e-04  Data: 0.006 (0.008)
2024-04-06 18:21:24,597 - train - INFO - Train: 24 [ 500/781 ( 64%)]  Loss:  4.304075 (3.8486)  Time: 0.828s,  154.68/s  (0.826s,  154.91/s)  LR: 4.697e-04  Data: 0.008 (0.007)
2024-04-06 18:22:05,981 - train - INFO - Train: 24 [ 550/781 ( 71%)]  Loss:  3.489969 (3.8503)  Time: 0.791s,  161.82/s  (0.826s,  154.89/s)  LR: 4.697e-04  Data: 0.005 (0.007)
2024-04-06 18:22:46,245 - train - INFO - Train: 24 [ 600/781 ( 77%)]  Loss:  3.160144 (3.8556)  Time: 0.785s,  162.96/s  (0.825s,  155.22/s)  LR: 4.697e-04  Data: 0.005 (0.007)
2024-04-06 18:23:27,152 - train - INFO - Train: 24 [ 650/781 ( 83%)]  Loss:  4.091317 (3.8572)  Time: 0.785s,  163.02/s  (0.824s,  155.31/s)  LR: 4.697e-04  Data: 0.005 (0.007)
2024-04-06 18:24:07,955 - train - INFO - Train: 24 [ 700/781 ( 90%)]  Loss:  3.917132 (3.8584)  Time: 0.816s,  156.89/s  (0.824s,  155.42/s)  LR: 4.697e-04  Data: 0.009 (0.007)
2024-04-06 18:24:48,377 - train - INFO - Train: 24 [ 750/781 ( 96%)]  Loss:  3.937937 (3.8603)  Time: 0.794s,  161.20/s  (0.823s,  155.61/s)  LR: 4.697e-04  Data: 0.005 (0.007)
2024-04-06 18:25:12,376 - train - INFO - Train: 24 [ 780/781 (100%)]  Loss:  4.438587 (3.8671)  Time: 0.780s,  164.18/s  (0.822s,  155.78/s)  LR: 4.697e-04  Data: 0.000 (0.007)
2024-04-06 18:25:12,377 - train - INFO - True
2024-04-06 18:25:12,380 - train - INFO - alphas:tensor([0.2936, 0.1570, 0.1531, 0.1896, 0.2066], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,380 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,380 - train - INFO - True
2024-04-06 18:25:12,382 - train - INFO - alphas:tensor([0.3722, 0.1033, 0.1107, 0.1686, 0.2453], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,382 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,382 - train - INFO - True
2024-04-06 18:25:12,384 - train - INFO - alphas:tensor([0.7362, 0.0819, 0.0547, 0.0611, 0.0661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,384 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,384 - train - INFO - True
2024-04-06 18:25:12,385 - train - INFO - alphas:tensor([0.7125, 0.0690, 0.0575, 0.0744, 0.0867], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,386 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,386 - train - INFO - True
2024-04-06 18:25:12,387 - train - INFO - alphas:tensor([0.5427, 0.0845, 0.0917, 0.1246, 0.1565], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,387 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,388 - train - INFO - True
2024-04-06 18:25:12,389 - train - INFO - alphas:tensor([0.6740, 0.0798, 0.0641, 0.0831, 0.0991], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,389 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,389 - train - INFO - True
2024-04-06 18:25:12,391 - train - INFO - alphas:tensor([0.7815, 0.0637, 0.0419, 0.0511, 0.0618], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,391 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,391 - train - INFO - True
2024-04-06 18:25:12,393 - train - INFO - alphas:tensor([0.7633, 0.0683, 0.0450, 0.0570, 0.0664], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,393 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,393 - train - INFO - True
2024-04-06 18:25:12,394 - train - INFO - alphas:tensor([0.5879, 0.0740, 0.0788, 0.1125, 0.1468], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,395 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,395 - train - INFO - True
2024-04-06 18:25:12,396 - train - INFO - alphas:tensor([0.7013, 0.0722, 0.0603, 0.0744, 0.0918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,396 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,396 - train - INFO - True
2024-04-06 18:25:12,398 - train - INFO - alphas:tensor([0.7515, 0.0625, 0.0474, 0.0615, 0.0771], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,398 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,398 - train - INFO - True
2024-04-06 18:25:12,399 - train - INFO - alphas:tensor([0.6988, 0.0663, 0.0584, 0.0813, 0.0952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,400 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,400 - train - INFO - True
2024-04-06 18:25:12,401 - train - INFO - alphas:tensor([0.6062, 0.0676, 0.0718, 0.1092, 0.1453], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,401 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,402 - train - INFO - True
2024-04-06 18:25:12,403 - train - INFO - alphas:tensor([0.7051, 0.0626, 0.0592, 0.0769, 0.0962], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,403 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,403 - train - INFO - True
2024-04-06 18:25:12,405 - train - INFO - alphas:tensor([0.7182, 0.0729, 0.0531, 0.0684, 0.0874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,405 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,405 - train - INFO - True
2024-04-06 18:25:12,406 - train - INFO - alphas:tensor([0.6146, 0.0690, 0.0675, 0.1026, 0.1464], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,406 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,407 - train - INFO - True
2024-04-06 18:25:12,408 - train - INFO - alphas:tensor([0.6014, 0.0666, 0.0707, 0.1105, 0.1507], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,408 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,408 - train - INFO - True
2024-04-06 18:25:12,409 - train - INFO - alphas:tensor([0.7098, 0.0598, 0.0588, 0.0765, 0.0952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,410 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,410 - train - INFO - True
2024-04-06 18:25:12,411 - train - INFO - alphas:tensor([0.7337, 0.0641, 0.0504, 0.0671, 0.0848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,411 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,411 - train - INFO - True
2024-04-06 18:25:12,413 - train - INFO - alphas:tensor([0.5952, 0.0622, 0.0677, 0.1122, 0.1627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,413 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,413 - train - INFO - True
2024-04-06 18:25:12,414 - train - INFO - alphas:tensor([0.5725, 0.0662, 0.0779, 0.1203, 0.1631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,414 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,415 - train - INFO - True
2024-04-06 18:25:12,416 - train - INFO - alphas:tensor([0.7372, 0.0556, 0.0535, 0.0684, 0.0853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,416 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,416 - train - INFO - True
2024-04-06 18:25:12,417 - train - INFO - alphas:tensor([0.7527, 0.0642, 0.0455, 0.0601, 0.0775], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,417 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,418 - train - INFO - True
2024-04-06 18:25:12,419 - train - INFO - alphas:tensor([0.6104, 0.0560, 0.0635, 0.1101, 0.1601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,419 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,419 - train - INFO - True
2024-04-06 18:25:12,420 - train - INFO - alphas:tensor([0.5645, 0.0621, 0.0768, 0.1252, 0.1714], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,420 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,421 - train - INFO - True
2024-04-06 18:25:12,422 - train - INFO - alphas:tensor([0.7242, 0.0555, 0.0557, 0.0704, 0.0943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,422 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,422 - train - INFO - True
2024-04-06 18:25:12,423 - train - INFO - alphas:tensor([0.7418, 0.0556, 0.0468, 0.0660, 0.0898], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,423 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,424 - train - INFO - True
2024-04-06 18:25:12,425 - train - INFO - alphas:tensor([0.6353, 0.0565, 0.0584, 0.1007, 0.1491], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,425 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,425 - train - INFO - True
2024-04-06 18:25:12,426 - train - INFO - alphas:tensor([0.5429, 0.0576, 0.0825, 0.1324, 0.1846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,426 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,426 - train - INFO - True
2024-04-06 18:25:12,428 - train - INFO - alphas:tensor([0.7026, 0.0542, 0.0582, 0.0789, 0.1061], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,428 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,428 - train - INFO - True
2024-04-06 18:25:12,429 - train - INFO - alphas:tensor([0.7252, 0.0533, 0.0489, 0.0719, 0.1008], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,429 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,429 - train - INFO - True
2024-04-06 18:25:12,430 - train - INFO - alphas:tensor([0.6704, 0.0535, 0.0571, 0.0920, 0.1269], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,431 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,431 - train - INFO - True
2024-04-06 18:25:12,432 - train - INFO - alphas:tensor([0.5167, 0.0548, 0.0836, 0.1405, 0.2044], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,432 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,432 - train - INFO - True
2024-04-06 18:25:12,433 - train - INFO - alphas:tensor([0.6617, 0.0574, 0.0627, 0.0913, 0.1268], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,434 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,434 - train - INFO - True
2024-04-06 18:25:12,435 - train - INFO - alphas:tensor([0.7017, 0.0577, 0.0505, 0.0803, 0.1098], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,435 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,435 - train - INFO - True
2024-04-06 18:25:12,436 - train - INFO - alphas:tensor([0.6697, 0.0536, 0.0581, 0.0923, 0.1263], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,436 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,436 - train - INFO - True
2024-04-06 18:25:12,437 - train - INFO - alphas:tensor([0.6668, 0.0732, 0.1154, 0.1447], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:25:12,438 - train - INFO - tau:0.8016305895390458
2024-04-06 18:25:12,438 - train - INFO - avg block size:1.0
2024-04-06 18:25:12,438 - train - INFO - lasso_alpha:2.5937424601000023e-05
2024-04-06 18:25:12,679 - train - INFO - Test: [   0/78]  Time: 0.237 (0.237)  Loss:  0.9756 (0.9756)  Acc@1: 77.3438 (77.3438)  Acc@5: 91.4062 (91.4062)
2024-04-06 18:25:17,024 - train - INFO - Test: [  50/78]  Time: 0.085 (0.090)  Loss:  1.7832 (1.7263)  Acc@1: 57.8125 (59.7273)  Acc@5: 83.5938 (82.6746)
2024-04-06 18:25:19,339 - train - INFO - Test: [  78/78]  Time: 0.052 (0.087)  Loss:  1.6553 (1.7544)  Acc@1: 56.2500 (59.0200)  Acc@5: 93.7500 (82.3300)
2024-04-06 18:25:20,639 - train - INFO - Train: 25 [   0/781 (  0%)]  Loss:  3.590007 (3.5900)  Time: 1.238s,  103.35/s  (1.238s,  103.35/s)  LR: 4.672e-04  Data: 0.182 (0.182)
2024-04-06 18:26:00,858 - train - INFO - Train: 25 [  50/781 (  6%)]  Loss:  3.884388 (3.7748)  Time: 0.816s,  156.77/s  (0.813s,  157.47/s)  LR: 4.672e-04  Data: 0.007 (0.010)
2024-04-06 18:26:41,643 - train - INFO - Train: 25 [ 100/781 ( 13%)]  Loss:  3.815931 (3.8267)  Time: 0.813s,  157.35/s  (0.814s,  157.20/s)  LR: 4.672e-04  Data: 0.008 (0.008)
2024-04-06 18:27:21,886 - train - INFO - Train: 25 [ 150/781 ( 19%)]  Loss:  3.850764 (3.8258)  Time: 0.806s,  158.72/s  (0.811s,  157.80/s)  LR: 4.672e-04  Data: 0.008 (0.008)
2024-04-06 18:28:02,057 - train - INFO - Train: 25 [ 200/781 ( 26%)]  Loss:  4.438628 (3.8586)  Time: 0.816s,  156.93/s  (0.809s,  158.18/s)  LR: 4.672e-04  Data: 0.009 (0.008)
2024-04-06 18:28:42,441 - train - INFO - Train: 25 [ 250/781 ( 32%)]  Loss:  3.703691 (3.8643)  Time: 0.833s,  153.73/s  (0.809s,  158.24/s)  LR: 4.672e-04  Data: 0.007 (0.007)
2024-04-06 18:29:23,639 - train - INFO - Train: 25 [ 300/781 ( 38%)]  Loss:  3.403085 (3.8544)  Time: 0.790s,  162.12/s  (0.811s,  157.75/s)  LR: 4.672e-04  Data: 0.005 (0.007)
2024-04-06 18:30:03,511 - train - INFO - Train: 25 [ 350/781 ( 45%)]  Loss:  3.205723 (3.8555)  Time: 0.831s,  154.09/s  (0.809s,  158.14/s)  LR: 4.672e-04  Data: 0.008 (0.007)
2024-04-06 18:30:44,455 - train - INFO - Train: 25 [ 400/781 ( 51%)]  Loss:  4.334898 (3.8603)  Time: 0.784s,  163.34/s  (0.811s,  157.91/s)  LR: 4.672e-04  Data: 0.005 (0.007)
2024-04-06 18:31:25,305 - train - INFO - Train: 25 [ 450/781 ( 58%)]  Loss:  3.930659 (3.8557)  Time: 0.819s,  156.20/s  (0.811s,  157.77/s)  LR: 4.672e-04  Data: 0.008 (0.007)
2024-04-06 18:32:05,437 - train - INFO - Train: 25 [ 500/781 ( 64%)]  Loss:  3.301045 (3.8474)  Time: 0.818s,  156.41/s  (0.810s,  157.94/s)  LR: 4.672e-04  Data: 0.007 (0.007)
2024-04-06 18:32:47,196 - train - INFO - Train: 25 [ 550/781 ( 71%)]  Loss:  3.688441 (3.8476)  Time: 0.816s,  156.85/s  (0.813s,  157.51/s)  LR: 4.672e-04  Data: 0.008 (0.007)
2024-04-06 18:33:27,932 - train - INFO - Train: 25 [ 600/781 ( 77%)]  Loss:  4.389821 (3.8568)  Time: 0.793s,  161.47/s  (0.813s,  157.47/s)  LR: 4.672e-04  Data: 0.006 (0.007)
2024-04-06 18:34:09,322 - train - INFO - Train: 25 [ 650/781 ( 83%)]  Loss:  4.214075 (3.8607)  Time: 0.795s,  160.93/s  (0.814s,  157.25/s)  LR: 4.672e-04  Data: 0.005 (0.007)
2024-04-06 18:34:49,669 - train - INFO - Train: 25 [ 700/781 ( 90%)]  Loss:  3.932428 (3.8610)  Time: 1.074s,  119.16/s  (0.813s,  157.35/s)  LR: 4.672e-04  Data: 0.008 (0.007)
2024-04-06 18:35:29,541 - train - INFO - Train: 25 [ 750/781 ( 96%)]  Loss:  3.833756 (3.8532)  Time: 0.779s,  164.22/s  (0.812s,  157.56/s)  LR: 4.672e-04  Data: 0.006 (0.007)
2024-04-06 18:35:54,439 - train - INFO - Train: 25 [ 780/781 (100%)]  Loss:  3.757607 (3.8529)  Time: 0.790s,  162.11/s  (0.813s,  157.43/s)  LR: 4.672e-04  Data: 0.000 (0.007)
2024-04-06 18:35:54,440 - train - INFO - True
2024-04-06 18:35:54,442 - train - INFO - alphas:tensor([0.2920, 0.1544, 0.1528, 0.1913, 0.2094], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,442 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,442 - train - INFO - True
2024-04-06 18:35:54,444 - train - INFO - alphas:tensor([0.3702, 0.1007, 0.1094, 0.1691, 0.2506], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,444 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,444 - train - INFO - True
2024-04-06 18:35:54,446 - train - INFO - alphas:tensor([0.7365, 0.0814, 0.0545, 0.0611, 0.0664], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,446 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,446 - train - INFO - True
2024-04-06 18:35:54,447 - train - INFO - alphas:tensor([0.7113, 0.0677, 0.0575, 0.0752, 0.0883], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,447 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,448 - train - INFO - True
2024-04-06 18:35:54,449 - train - INFO - alphas:tensor([0.5398, 0.0817, 0.0914, 0.1264, 0.1607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,449 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,449 - train - INFO - True
2024-04-06 18:35:54,451 - train - INFO - alphas:tensor([0.6741, 0.0782, 0.0634, 0.0835, 0.1008], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,451 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,451 - train - INFO - True
2024-04-06 18:35:54,452 - train - INFO - alphas:tensor([0.7813, 0.0631, 0.0415, 0.0515, 0.0625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,453 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,453 - train - INFO - True
2024-04-06 18:35:54,454 - train - INFO - alphas:tensor([0.7586, 0.0678, 0.0456, 0.0587, 0.0692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,454 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,454 - train - INFO - True
2024-04-06 18:35:54,456 - train - INFO - alphas:tensor([0.5873, 0.0720, 0.0783, 0.1129, 0.1494], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,456 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,456 - train - INFO - True
2024-04-06 18:35:54,457 - train - INFO - alphas:tensor([0.7034, 0.0700, 0.0597, 0.0742, 0.0927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,457 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,457 - train - INFO - True
2024-04-06 18:35:54,459 - train - INFO - alphas:tensor([0.7510, 0.0606, 0.0472, 0.0622, 0.0788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,459 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,459 - train - INFO - True
2024-04-06 18:35:54,460 - train - INFO - alphas:tensor([0.6947, 0.0646, 0.0584, 0.0831, 0.0992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,460 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,461 - train - INFO - True
2024-04-06 18:35:54,462 - train - INFO - alphas:tensor([0.6049, 0.0653, 0.0713, 0.1101, 0.1483], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,462 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,462 - train - INFO - True
2024-04-06 18:35:54,463 - train - INFO - alphas:tensor([0.7037, 0.0610, 0.0589, 0.0777, 0.0988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,464 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,464 - train - INFO - True
2024-04-06 18:35:54,465 - train - INFO - alphas:tensor([0.7137, 0.0716, 0.0533, 0.0702, 0.0912], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,465 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,465 - train - INFO - True
2024-04-06 18:35:54,466 - train - INFO - alphas:tensor([0.6072, 0.0656, 0.0671, 0.1055, 0.1546], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,467 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,467 - train - INFO - True
2024-04-06 18:35:54,468 - train - INFO - alphas:tensor([0.5996, 0.0643, 0.0701, 0.1116, 0.1544], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,468 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,468 - train - INFO - True
2024-04-06 18:35:54,469 - train - INFO - alphas:tensor([0.7085, 0.0582, 0.0582, 0.0775, 0.0976], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,470 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,470 - train - INFO - True
2024-04-06 18:35:54,471 - train - INFO - alphas:tensor([0.7311, 0.0622, 0.0502, 0.0684, 0.0881], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,471 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,471 - train - INFO - True
2024-04-06 18:35:54,472 - train - INFO - alphas:tensor([0.5881, 0.0597, 0.0661, 0.1146, 0.1714], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,473 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,473 - train - INFO - True
2024-04-06 18:35:54,474 - train - INFO - alphas:tensor([0.5648, 0.0643, 0.0781, 0.1232, 0.1696], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,474 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,474 - train - INFO - True
2024-04-06 18:35:54,475 - train - INFO - alphas:tensor([0.7336, 0.0543, 0.0535, 0.0698, 0.0888], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,475 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,476 - train - INFO - True
2024-04-06 18:35:54,477 - train - INFO - alphas:tensor([0.7476, 0.0637, 0.0456, 0.0619, 0.0812], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,477 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,477 - train - INFO - True
2024-04-06 18:35:54,478 - train - INFO - alphas:tensor([0.6044, 0.0532, 0.0621, 0.1120, 0.1682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,478 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,479 - train - INFO - True
2024-04-06 18:35:54,480 - train - INFO - alphas:tensor([0.5612, 0.0600, 0.0765, 0.1264, 0.1758], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,480 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,480 - train - INFO - True
2024-04-06 18:35:54,481 - train - INFO - alphas:tensor([0.7258, 0.0526, 0.0547, 0.0705, 0.0964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,481 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,481 - train - INFO - True
2024-04-06 18:35:54,482 - train - INFO - alphas:tensor([0.7374, 0.0544, 0.0466, 0.0675, 0.0940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,483 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,483 - train - INFO - True
2024-04-06 18:35:54,484 - train - INFO - alphas:tensor([0.6237, 0.0549, 0.0585, 0.1042, 0.1587], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,484 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,484 - train - INFO - True
2024-04-06 18:35:54,485 - train - INFO - alphas:tensor([0.5359, 0.0556, 0.0823, 0.1350, 0.1912], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,485 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,486 - train - INFO - True
2024-04-06 18:35:54,487 - train - INFO - alphas:tensor([0.6987, 0.0528, 0.0578, 0.0805, 0.1101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,487 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,487 - train - INFO - True
2024-04-06 18:35:54,488 - train - INFO - alphas:tensor([0.7246, 0.0518, 0.0484, 0.0720, 0.1031], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,488 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,488 - train - INFO - True
2024-04-06 18:35:54,489 - train - INFO - alphas:tensor([0.6662, 0.0521, 0.0560, 0.0933, 0.1323], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,490 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,490 - train - INFO - True
2024-04-06 18:35:54,491 - train - INFO - alphas:tensor([0.5127, 0.0517, 0.0832, 0.1418, 0.2106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,491 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,491 - train - INFO - True
2024-04-06 18:35:54,492 - train - INFO - alphas:tensor([0.6576, 0.0549, 0.0627, 0.0930, 0.1319], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,492 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,492 - train - INFO - True
2024-04-06 18:35:54,493 - train - INFO - alphas:tensor([0.7006, 0.0553, 0.0497, 0.0814, 0.1131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,494 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,494 - train - INFO - True
2024-04-06 18:35:54,495 - train - INFO - alphas:tensor([0.6621, 0.0522, 0.0578, 0.0952, 0.1327], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,495 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,495 - train - INFO - True
2024-04-06 18:35:54,496 - train - INFO - alphas:tensor([0.6716, 0.0713, 0.1137, 0.1434], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:35:54,496 - train - INFO - tau:0.7936142836436553
2024-04-06 18:35:54,496 - train - INFO - avg block size:1.0
2024-04-06 18:35:54,741 - train - INFO - Test: [   0/78]  Time: 0.241 (0.241)  Loss:  0.9756 (0.9756)  Acc@1: 78.9062 (78.9062)  Acc@5: 93.7500 (93.7500)
2024-04-06 18:35:59,075 - train - INFO - Test: [  50/78]  Time: 0.084 (0.090)  Loss:  1.9990 (1.7210)  Acc@1: 53.9062 (59.3750)  Acc@5: 81.2500 (82.5980)
2024-04-06 18:36:01,781 - train - INFO - Test: [  78/78]  Time: 0.053 (0.092)  Loss:  1.9414 (1.7470)  Acc@1: 56.2500 (58.9100)  Acc@5: 87.5000 (82.1400)
2024-04-06 18:36:02,913 - train - INFO - Train: 26 [   0/781 (  0%)]  Loss:  4.407189 (4.4072)  Time: 0.991s,  129.16/s  (0.991s,  129.16/s)  LR: 4.646e-04  Data: 0.183 (0.183)
2024-04-06 18:36:44,273 - train - INFO - Train: 26 [  50/781 (  6%)]  Loss:  3.703379 (3.9051)  Time: 0.827s,  154.82/s  (0.830s,  154.15/s)  LR: 4.646e-04  Data: 0.009 (0.010)
2024-04-06 18:37:24,836 - train - INFO - Train: 26 [ 100/781 ( 13%)]  Loss:  4.135686 (3.9049)  Time: 0.794s,  161.16/s  (0.821s,  155.93/s)  LR: 4.646e-04  Data: 0.005 (0.009)
2024-04-06 18:38:06,952 - train - INFO - Train: 26 [ 150/781 ( 19%)]  Loss:  3.923314 (3.9171)  Time: 0.833s,  153.75/s  (0.828s,  154.59/s)  LR: 4.646e-04  Data: 0.008 (0.008)
2024-04-06 18:38:48,053 - train - INFO - Train: 26 [ 200/781 ( 26%)]  Loss:  3.547501 (3.9046)  Time: 0.804s,  159.15/s  (0.826s,  154.87/s)  LR: 4.646e-04  Data: 0.006 (0.008)
2024-04-06 18:39:29,958 - train - INFO - Train: 26 [ 250/781 ( 32%)]  Loss:  3.758757 (3.8975)  Time: 0.816s,  156.91/s  (0.829s,  154.44/s)  LR: 4.646e-04  Data: 0.009 (0.008)
2024-04-06 18:40:11,005 - train - INFO - Train: 26 [ 300/781 ( 38%)]  Loss:  3.932149 (3.8999)  Time: 0.811s,  157.84/s  (0.827s,  154.68/s)  LR: 4.646e-04  Data: 0.008 (0.008)
2024-04-06 18:40:51,831 - train - INFO - Train: 26 [ 350/781 ( 45%)]  Loss:  4.310199 (3.9005)  Time: 0.775s,  165.21/s  (0.826s,  154.98/s)  LR: 4.646e-04  Data: 0.005 (0.008)
2024-04-06 18:41:32,513 - train - INFO - Train: 26 [ 400/781 ( 51%)]  Loss:  3.562029 (3.9033)  Time: 0.817s,  156.69/s  (0.824s,  155.27/s)  LR: 4.646e-04  Data: 0.008 (0.008)
2024-04-06 18:42:14,996 - train - INFO - Train: 26 [ 450/781 ( 58%)]  Loss:  4.182930 (3.9015)  Time: 0.822s,  155.78/s  (0.827s,  154.74/s)  LR: 4.646e-04  Data: 0.008 (0.008)
2024-04-06 18:42:56,653 - train - INFO - Train: 26 [ 500/781 ( 64%)]  Loss:  3.371677 (3.8953)  Time: 0.786s,  162.84/s  (0.828s,  154.63/s)  LR: 4.646e-04  Data: 0.007 (0.008)
2024-04-06 18:43:37,802 - train - INFO - Train: 26 [ 550/781 ( 71%)]  Loss:  4.219828 (3.8941)  Time: 0.767s,  166.81/s  (0.827s,  154.71/s)  LR: 4.646e-04  Data: 0.005 (0.008)
2024-04-06 18:44:17,552 - train - INFO - Train: 26 [ 600/781 ( 77%)]  Loss:  4.094988 (3.8850)  Time: 0.784s,  163.19/s  (0.825s,  155.22/s)  LR: 4.646e-04  Data: 0.005 (0.007)
2024-04-06 18:44:57,624 - train - INFO - Train: 26 [ 650/781 ( 83%)]  Loss:  3.887875 (3.8783)  Time: 0.793s,  161.36/s  (0.823s,  155.55/s)  LR: 4.646e-04  Data: 0.005 (0.007)
2024-04-06 18:45:37,972 - train - INFO - Train: 26 [ 700/781 ( 90%)]  Loss:  4.494636 (3.8743)  Time: 0.797s,  160.52/s  (0.822s,  155.77/s)  LR: 4.646e-04  Data: 0.007 (0.007)
2024-04-06 18:46:18,573 - train - INFO - Train: 26 [ 750/781 ( 96%)]  Loss:  3.799032 (3.8722)  Time: 0.813s,  157.36/s  (0.821s,  155.89/s)  LR: 4.646e-04  Data: 0.007 (0.007)
2024-04-06 18:46:43,205 - train - INFO - Train: 26 [ 780/781 (100%)]  Loss:  3.529552 (3.8765)  Time: 0.792s,  161.58/s  (0.821s,  155.89/s)  LR: 4.646e-04  Data: 0.000 (0.007)
2024-04-06 18:46:43,206 - train - INFO - True
2024-04-06 18:46:43,208 - train - INFO - alphas:tensor([0.2864, 0.1501, 0.1540, 0.1951, 0.2144], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,208 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,208 - train - INFO - True
2024-04-06 18:46:43,210 - train - INFO - alphas:tensor([0.3648, 0.0972, 0.1083, 0.1710, 0.2588], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,210 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,210 - train - INFO - True
2024-04-06 18:46:43,211 - train - INFO - alphas:tensor([0.7404, 0.0798, 0.0535, 0.0605, 0.0658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,212 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,212 - train - INFO - True
2024-04-06 18:46:43,213 - train - INFO - alphas:tensor([0.7118, 0.0665, 0.0571, 0.0755, 0.0892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,213 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,214 - train - INFO - True
2024-04-06 18:46:43,215 - train - INFO - alphas:tensor([0.5379, 0.0792, 0.0916, 0.1277, 0.1636], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,215 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,215 - train - INFO - True
2024-04-06 18:46:43,217 - train - INFO - alphas:tensor([0.6733, 0.0768, 0.0631, 0.0839, 0.1028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,217 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,217 - train - INFO - True
2024-04-06 18:46:43,218 - train - INFO - alphas:tensor([0.7823, 0.0619, 0.0410, 0.0516, 0.0631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,218 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,219 - train - INFO - True
2024-04-06 18:46:43,220 - train - INFO - alphas:tensor([0.7556, 0.0668, 0.0457, 0.0602, 0.0717], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,220 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,220 - train - INFO - True
2024-04-06 18:46:43,222 - train - INFO - alphas:tensor([0.5838, 0.0704, 0.0782, 0.1143, 0.1533], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,222 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,222 - train - INFO - True
2024-04-06 18:46:43,223 - train - INFO - alphas:tensor([0.6997, 0.0691, 0.0600, 0.0755, 0.0956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,224 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,224 - train - INFO - True
2024-04-06 18:46:43,225 - train - INFO - alphas:tensor([0.7479, 0.0596, 0.0474, 0.0635, 0.0816], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,225 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,225 - train - INFO - True
2024-04-06 18:46:43,227 - train - INFO - alphas:tensor([0.6874, 0.0640, 0.0586, 0.0856, 0.1044], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,227 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,227 - train - INFO - True
2024-04-06 18:46:43,228 - train - INFO - alphas:tensor([0.6026, 0.0637, 0.0708, 0.1111, 0.1518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,228 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,228 - train - INFO - True
2024-04-06 18:46:43,230 - train - INFO - alphas:tensor([0.7025, 0.0591, 0.0585, 0.0783, 0.1015], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,230 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,230 - train - INFO - True
2024-04-06 18:46:43,231 - train - INFO - alphas:tensor([0.7113, 0.0698, 0.0527, 0.0714, 0.0947], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,232 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,232 - train - INFO - True
2024-04-06 18:46:43,233 - train - INFO - alphas:tensor([0.6028, 0.0619, 0.0662, 0.1073, 0.1617], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,233 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,233 - train - INFO - True
2024-04-06 18:46:43,234 - train - INFO - alphas:tensor([0.5961, 0.0624, 0.0700, 0.1130, 0.1585], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,235 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,235 - train - INFO - True
2024-04-06 18:46:43,236 - train - INFO - alphas:tensor([0.7041, 0.0570, 0.0583, 0.0792, 0.1015], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,236 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,236 - train - INFO - True
2024-04-06 18:46:43,237 - train - INFO - alphas:tensor([0.7262, 0.0612, 0.0504, 0.0701, 0.0922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,238 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,238 - train - INFO - True
2024-04-06 18:46:43,239 - train - INFO - alphas:tensor([0.5830, 0.0570, 0.0649, 0.1162, 0.1790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,239 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,239 - train - INFO - True
2024-04-06 18:46:43,240 - train - INFO - alphas:tensor([0.5645, 0.0621, 0.0770, 0.1235, 0.1728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,241 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,241 - train - INFO - True
2024-04-06 18:46:43,242 - train - INFO - alphas:tensor([0.7300, 0.0529, 0.0537, 0.0712, 0.0921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,242 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,242 - train - INFO - True
2024-04-06 18:46:43,243 - train - INFO - alphas:tensor([0.7445, 0.0624, 0.0454, 0.0632, 0.0845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,244 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,244 - train - INFO - True
2024-04-06 18:46:43,245 - train - INFO - alphas:tensor([0.5982, 0.0507, 0.0604, 0.1137, 0.1769], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,245 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,245 - train - INFO - True
2024-04-06 18:46:43,246 - train - INFO - alphas:tensor([0.5563, 0.0580, 0.0756, 0.1282, 0.1818], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,247 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,247 - train - INFO - True
2024-04-06 18:46:43,248 - train - INFO - alphas:tensor([0.7228, 0.0515, 0.0544, 0.0714, 0.0999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,248 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,248 - train - INFO - True
2024-04-06 18:46:43,249 - train - INFO - alphas:tensor([0.7382, 0.0525, 0.0458, 0.0677, 0.0958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,249 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,249 - train - INFO - True
2024-04-06 18:46:43,251 - train - INFO - alphas:tensor([0.6218, 0.0518, 0.0565, 0.1051, 0.1648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,251 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,251 - train - INFO - True
2024-04-06 18:46:43,252 - train - INFO - alphas:tensor([0.5303, 0.0539, 0.0816, 0.1367, 0.1974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,252 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,252 - train - INFO - True
2024-04-06 18:46:43,253 - train - INFO - alphas:tensor([0.6956, 0.0511, 0.0575, 0.0818, 0.1140], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,254 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,254 - train - INFO - True
2024-04-06 18:46:43,255 - train - INFO - alphas:tensor([0.7276, 0.0494, 0.0469, 0.0715, 0.1047], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,255 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,255 - train - INFO - True
2024-04-06 18:46:43,256 - train - INFO - alphas:tensor([0.6621, 0.0497, 0.0553, 0.0952, 0.1378], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,256 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,256 - train - INFO - True
2024-04-06 18:46:43,258 - train - INFO - alphas:tensor([0.5076, 0.0497, 0.0821, 0.1432, 0.2173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,258 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,258 - train - INFO - True
2024-04-06 18:46:43,259 - train - INFO - alphas:tensor([0.6503, 0.0527, 0.0626, 0.0957, 0.1388], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,259 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,259 - train - INFO - True
2024-04-06 18:46:43,260 - train - INFO - alphas:tensor([0.6970, 0.0536, 0.0496, 0.0826, 0.1171], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,260 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,261 - train - INFO - True
2024-04-06 18:46:43,262 - train - INFO - alphas:tensor([0.6573, 0.0501, 0.0573, 0.0970, 0.1383], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,262 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,262 - train - INFO - True
2024-04-06 18:46:43,263 - train - INFO - alphas:tensor([0.6731, 0.0706, 0.1127, 0.1436], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:46:43,263 - train - INFO - tau:0.7856781408072188
2024-04-06 18:46:43,263 - train - INFO - avg block size:1.0
2024-04-06 18:46:43,263 - train - INFO - lasso_alpha:2.8531167061100026e-05
2024-04-06 18:46:43,494 - train - INFO - Test: [   0/78]  Time: 0.227 (0.227)  Loss:  0.9658 (0.9658)  Acc@1: 78.9062 (78.9062)  Acc@5: 92.9688 (92.9688)
2024-04-06 18:46:47,865 - train - INFO - Test: [  50/78]  Time: 0.085 (0.090)  Loss:  2.0078 (1.7234)  Acc@1: 53.1250 (60.1716)  Acc@5: 82.0312 (83.2108)
2024-04-06 18:46:50,195 - train - INFO - Test: [  78/78]  Time: 0.054 (0.088)  Loss:  1.9541 (1.7627)  Acc@1: 50.0000 (59.1900)  Acc@5: 81.2500 (82.5100)
2024-04-06 18:46:51,496 - train - INFO - Train: 27 [   0/781 (  0%)]  Loss:  3.529459 (3.5295)  Time: 1.233s,  103.84/s  (1.233s,  103.84/s)  LR: 4.619e-04  Data: 0.176 (0.176)
2024-04-06 18:47:33,335 - train - INFO - Train: 27 [  50/781 (  6%)]  Loss:  4.321351 (3.9181)  Time: 0.819s,  156.25/s  (0.845s,  151.57/s)  LR: 4.619e-04  Data: 0.008 (0.011)
2024-04-06 18:48:14,352 - train - INFO - Train: 27 [ 100/781 ( 13%)]  Loss:  3.357050 (3.8838)  Time: 0.993s,  128.96/s  (0.833s,  153.75/s)  LR: 4.619e-04  Data: 0.006 (0.009)
2024-04-06 18:48:54,328 - train - INFO - Train: 27 [ 150/781 ( 19%)]  Loss:  4.125397 (3.8765)  Time: 0.791s,  161.76/s  (0.822s,  155.80/s)  LR: 4.619e-04  Data: 0.006 (0.008)
2024-04-06 18:49:35,274 - train - INFO - Train: 27 [ 200/781 ( 26%)]  Loss:  3.292390 (3.8835)  Time: 0.799s,  160.12/s  (0.821s,  155.92/s)  LR: 4.619e-04  Data: 0.007 (0.008)
2024-04-06 18:50:16,317 - train - INFO - Train: 27 [ 250/781 ( 32%)]  Loss:  3.871871 (3.8915)  Time: 1.015s,  126.07/s  (0.821s,  155.93/s)  LR: 4.619e-04  Data: 0.008 (0.008)
2024-04-06 18:50:56,743 - train - INFO - Train: 27 [ 300/781 ( 38%)]  Loss:  4.290666 (3.8796)  Time: 0.821s,  155.89/s  (0.819s,  156.32/s)  LR: 4.619e-04  Data: 0.009 (0.008)
2024-04-06 18:51:37,057 - train - INFO - Train: 27 [ 350/781 ( 45%)]  Loss:  4.080314 (3.8784)  Time: 0.827s,  154.69/s  (0.817s,  156.66/s)  LR: 4.619e-04  Data: 0.009 (0.007)
2024-04-06 18:52:17,402 - train - INFO - Train: 27 [ 400/781 ( 51%)]  Loss:  4.330312 (3.8760)  Time: 0.810s,  157.97/s  (0.816s,  156.90/s)  LR: 4.619e-04  Data: 0.007 (0.007)
2024-04-06 18:52:57,558 - train - INFO - Train: 27 [ 450/781 ( 58%)]  Loss:  4.430846 (3.8699)  Time: 0.825s,  155.11/s  (0.814s,  157.18/s)  LR: 4.619e-04  Data: 0.008 (0.007)
2024-04-06 18:53:39,297 - train - INFO - Train: 27 [ 500/781 ( 64%)]  Loss:  3.459008 (3.8654)  Time: 0.823s,  155.50/s  (0.816s,  156.78/s)  LR: 4.619e-04  Data: 0.008 (0.007)
2024-04-06 18:54:20,635 - train - INFO - Train: 27 [ 550/781 ( 71%)]  Loss:  4.280468 (3.8612)  Time: 0.825s,  155.19/s  (0.817s,  156.60/s)  LR: 4.619e-04  Data: 0.008 (0.007)
2024-04-06 18:55:01,598 - train - INFO - Train: 27 [ 600/781 ( 77%)]  Loss:  4.344320 (3.8642)  Time: 0.802s,  159.67/s  (0.818s,  156.57/s)  LR: 4.619e-04  Data: 0.007 (0.007)
2024-04-06 18:55:42,536 - train - INFO - Train: 27 [ 650/781 ( 83%)]  Loss:  3.805662 (3.8673)  Time: 0.802s,  159.65/s  (0.818s,  156.56/s)  LR: 4.619e-04  Data: 0.006 (0.007)
2024-04-06 18:56:23,348 - train - INFO - Train: 27 [ 700/781 ( 90%)]  Loss:  3.319494 (3.8670)  Time: 0.809s,  158.24/s  (0.817s,  156.58/s)  LR: 4.619e-04  Data: 0.008 (0.007)
2024-04-06 18:57:04,196 - train - INFO - Train: 27 [ 750/781 ( 96%)]  Loss:  3.636443 (3.8621)  Time: 0.781s,  163.97/s  (0.817s,  156.58/s)  LR: 4.619e-04  Data: 0.005 (0.007)
2024-04-06 18:57:28,145 - train - INFO - Train: 27 [ 780/781 (100%)]  Loss:  3.563160 (3.8662)  Time: 0.781s,  163.88/s  (0.817s,  156.72/s)  LR: 4.619e-04  Data: 0.000 (0.007)
2024-04-06 18:57:28,146 - train - INFO - True
2024-04-06 18:57:28,147 - train - INFO - alphas:tensor([0.2803, 0.1464, 0.1557, 0.1986, 0.2190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,147 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,147 - train - INFO - True
2024-04-06 18:57:28,148 - train - INFO - alphas:tensor([0.3585, 0.0948, 0.1075, 0.1722, 0.2670], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,148 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,148 - train - INFO - True
2024-04-06 18:57:28,149 - train - INFO - alphas:tensor([0.7426, 0.0789, 0.0528, 0.0600, 0.0657], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,149 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,150 - train - INFO - True
2024-04-06 18:57:28,150 - train - INFO - alphas:tensor([0.7110, 0.0653, 0.0569, 0.0761, 0.0907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,151 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,151 - train - INFO - True
2024-04-06 18:57:28,151 - train - INFO - alphas:tensor([0.5344, 0.0778, 0.0913, 0.1289, 0.1676], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,152 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,152 - train - INFO - True
2024-04-06 18:57:28,153 - train - INFO - alphas:tensor([0.6700, 0.0753, 0.0636, 0.0854, 0.1058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,153 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,153 - train - INFO - True
2024-04-06 18:57:28,154 - train - INFO - alphas:tensor([0.7808, 0.0615, 0.0411, 0.0523, 0.0643], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,154 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,154 - train - INFO - True
2024-04-06 18:57:28,155 - train - INFO - alphas:tensor([0.7473, 0.0675, 0.0467, 0.0627, 0.0758], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,155 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,155 - train - INFO - True
2024-04-06 18:57:28,156 - train - INFO - alphas:tensor([0.5807, 0.0683, 0.0781, 0.1159, 0.1571], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,156 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,156 - train - INFO - True
2024-04-06 18:57:28,157 - train - INFO - alphas:tensor([0.6996, 0.0675, 0.0593, 0.0761, 0.0975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,157 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,157 - train - INFO - True
2024-04-06 18:57:28,158 - train - INFO - alphas:tensor([0.7437, 0.0586, 0.0479, 0.0650, 0.0848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,158 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,158 - train - INFO - True
2024-04-06 18:57:28,159 - train - INFO - alphas:tensor([0.6787, 0.0633, 0.0593, 0.0887, 0.1101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,159 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,159 - train - INFO - True
2024-04-06 18:57:28,160 - train - INFO - alphas:tensor([0.5982, 0.0623, 0.0709, 0.1125, 0.1562], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,160 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,160 - train - INFO - True
2024-04-06 18:57:28,161 - train - INFO - alphas:tensor([0.6960, 0.0583, 0.0591, 0.0806, 0.1060], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,161 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,161 - train - INFO - True
2024-04-06 18:57:28,162 - train - INFO - alphas:tensor([0.7076, 0.0684, 0.0526, 0.0730, 0.0984], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,162 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,162 - train - INFO - True
2024-04-06 18:57:28,163 - train - INFO - alphas:tensor([0.5955, 0.0594, 0.0651, 0.1096, 0.1703], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,163 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,163 - train - INFO - True
2024-04-06 18:57:28,164 - train - INFO - alphas:tensor([0.5931, 0.0613, 0.0693, 0.1141, 0.1622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,164 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,164 - train - INFO - True
2024-04-06 18:57:28,165 - train - INFO - alphas:tensor([0.7030, 0.0547, 0.0578, 0.0801, 0.1043], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,165 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,165 - train - INFO - True
2024-04-06 18:57:28,166 - train - INFO - alphas:tensor([0.7188, 0.0601, 0.0507, 0.0729, 0.0974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,166 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,166 - train - INFO - True
2024-04-06 18:57:28,167 - train - INFO - alphas:tensor([0.5683, 0.0546, 0.0642, 0.1210, 0.1918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,167 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,167 - train - INFO - True
2024-04-06 18:57:28,168 - train - INFO - alphas:tensor([0.5588, 0.0598, 0.0767, 0.1256, 0.1791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,168 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,168 - train - INFO - True
2024-04-06 18:57:28,169 - train - INFO - alphas:tensor([0.7264, 0.0515, 0.0538, 0.0725, 0.0957], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,169 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,169 - train - INFO - True
2024-04-06 18:57:28,170 - train - INFO - alphas:tensor([0.7380, 0.0621, 0.0457, 0.0653, 0.0890], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,170 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,170 - train - INFO - True
2024-04-06 18:57:28,171 - train - INFO - alphas:tensor([0.5872, 0.0492, 0.0594, 0.1161, 0.1883], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,171 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,171 - train - INFO - True
2024-04-06 18:57:28,172 - train - INFO - alphas:tensor([0.5516, 0.0551, 0.0753, 0.1302, 0.1878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,172 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,172 - train - INFO - True
2024-04-06 18:57:28,173 - train - INFO - alphas:tensor([0.7185, 0.0500, 0.0542, 0.0732, 0.1040], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,173 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,173 - train - INFO - True
2024-04-06 18:57:28,174 - train - INFO - alphas:tensor([0.7309, 0.0518, 0.0464, 0.0702, 0.1008], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,174 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,174 - train - INFO - True
2024-04-06 18:57:28,175 - train - INFO - alphas:tensor([0.6108, 0.0501, 0.0559, 0.1075, 0.1757], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,175 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,175 - train - INFO - True
2024-04-06 18:57:28,176 - train - INFO - alphas:tensor([0.5267, 0.0517, 0.0803, 0.1380, 0.2033], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,176 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,176 - train - INFO - True
2024-04-06 18:57:28,177 - train - INFO - alphas:tensor([0.6893, 0.0501, 0.0570, 0.0838, 0.1198], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,177 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,177 - train - INFO - True
2024-04-06 18:57:28,178 - train - INFO - alphas:tensor([0.7227, 0.0486, 0.0467, 0.0731, 0.1088], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,178 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,178 - train - INFO - True
2024-04-06 18:57:28,179 - train - INFO - alphas:tensor([0.6560, 0.0477, 0.0543, 0.0973, 0.1448], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,179 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,179 - train - INFO - True
2024-04-06 18:57:28,180 - train - INFO - alphas:tensor([0.5062, 0.0471, 0.0807, 0.1437, 0.2224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,180 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,180 - train - INFO - True
2024-04-06 18:57:28,181 - train - INFO - alphas:tensor([0.6477, 0.0512, 0.0618, 0.0961, 0.1432], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,181 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,181 - train - INFO - True
2024-04-06 18:57:28,182 - train - INFO - alphas:tensor([0.6997, 0.0520, 0.0478, 0.0820, 0.1185], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,182 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,182 - train - INFO - True
2024-04-06 18:57:28,183 - train - INFO - alphas:tensor([0.6543, 0.0480, 0.0564, 0.0981, 0.1432], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,183 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,183 - train - INFO - True
2024-04-06 18:57:28,184 - train - INFO - alphas:tensor([0.6776, 0.0687, 0.1113, 0.1425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 18:57:28,184 - train - INFO - tau:0.7778213593991465
2024-04-06 18:57:28,184 - train - INFO - avg block size:1.0
2024-04-06 18:57:28,414 - train - INFO - Test: [   0/78]  Time: 0.227 (0.227)  Loss:  0.9927 (0.9927)  Acc@1: 78.1250 (78.1250)  Acc@5: 93.7500 (93.7500)
2024-04-06 18:57:32,728 - train - INFO - Test: [  50/78]  Time: 0.084 (0.089)  Loss:  1.8789 (1.6848)  Acc@1: 57.8125 (60.1256)  Acc@5: 79.6875 (83.1189)
2024-04-06 18:57:35,062 - train - INFO - Test: [  78/78]  Time: 0.052 (0.087)  Loss:  1.6201 (1.7211)  Acc@1: 62.5000 (59.6400)  Acc@5: 87.5000 (82.5800)
2024-04-06 18:57:36,390 - train - INFO - Train: 28 [   0/781 (  0%)]  Loss:  3.659782 (3.6598)  Time: 1.260s,  101.62/s  (1.260s,  101.62/s)  LR: 4.591e-04  Data: 0.189 (0.189)
2024-04-06 18:58:17,745 - train - INFO - Train: 28 [  50/781 (  6%)]  Loss:  3.342316 (3.8837)  Time: 1.060s,  120.76/s  (0.836s,  153.19/s)  LR: 4.591e-04  Data: 0.008 (0.010)
2024-04-06 18:58:58,364 - train - INFO - Train: 28 [ 100/781 ( 13%)]  Loss:  4.017375 (3.8732)  Time: 0.782s,  163.73/s  (0.824s,  155.33/s)  LR: 4.591e-04  Data: 0.005 (0.008)
2024-04-06 18:59:39,186 - train - INFO - Train: 28 [ 150/781 ( 19%)]  Loss:  3.406995 (3.8908)  Time: 0.819s,  156.27/s  (0.822s,  155.81/s)  LR: 4.591e-04  Data: 0.008 (0.008)
2024-04-06 19:00:20,732 - train - INFO - Train: 28 [ 200/781 ( 26%)]  Loss:  4.373341 (3.8627)  Time: 0.800s,  160.03/s  (0.824s,  155.37/s)  LR: 4.591e-04  Data: 0.005 (0.008)
2024-04-06 19:01:01,529 - train - INFO - Train: 28 [ 250/781 ( 32%)]  Loss:  4.329911 (3.8868)  Time: 0.816s,  156.91/s  (0.822s,  155.67/s)  LR: 4.591e-04  Data: 0.008 (0.008)
2024-04-06 19:01:44,443 - train - INFO - Train: 28 [ 300/781 ( 38%)]  Loss:  4.041315 (3.8916)  Time: 0.867s,  147.69/s  (0.828s,  154.54/s)  LR: 4.591e-04  Data: 0.006 (0.007)
2024-04-06 19:02:25,815 - train - INFO - Train: 28 [ 350/781 ( 45%)]  Loss:  4.221767 (3.8842)  Time: 0.791s,  161.87/s  (0.828s,  154.57/s)  LR: 4.591e-04  Data: 0.005 (0.007)
2024-04-06 19:03:09,024 - train - INFO - Train: 28 [ 400/781 ( 51%)]  Loss:  4.087068 (3.8841)  Time: 0.824s,  155.27/s  (0.833s,  153.73/s)  LR: 4.591e-04  Data: 0.008 (0.008)
2024-04-06 19:03:48,990 - train - INFO - Train: 28 [ 450/781 ( 58%)]  Loss:  4.187652 (3.8784)  Time: 0.793s,  161.40/s  (0.829s,  154.42/s)  LR: 4.591e-04  Data: 0.005 (0.007)
2024-04-06 19:04:30,833 - train - INFO - Train: 28 [ 500/781 ( 64%)]  Loss:  4.367832 (3.8865)  Time: 0.831s,  154.11/s  (0.830s,  154.27/s)  LR: 4.591e-04  Data: 0.008 (0.007)
2024-04-06 19:05:12,557 - train - INFO - Train: 28 [ 550/781 ( 71%)]  Loss:  3.108662 (3.8872)  Time: 0.834s,  153.44/s  (0.830s,  154.19/s)  LR: 4.591e-04  Data: 0.008 (0.007)
2024-04-06 19:05:52,995 - train - INFO - Train: 28 [ 600/781 ( 77%)]  Loss:  3.534696 (3.8860)  Time: 0.829s,  154.35/s  (0.828s,  154.52/s)  LR: 4.591e-04  Data: 0.008 (0.007)
2024-04-06 19:06:33,151 - train - INFO - Train: 28 [ 650/781 ( 83%)]  Loss:  3.135272 (3.8733)  Time: 0.789s,  162.33/s  (0.826s,  154.88/s)  LR: 4.591e-04  Data: 0.006 (0.007)
2024-04-06 19:07:13,116 - train - INFO - Train: 28 [ 700/781 ( 90%)]  Loss:  3.690015 (3.8712)  Time: 0.832s,  153.81/s  (0.824s,  155.25/s)  LR: 4.591e-04  Data: 0.009 (0.007)
2024-04-06 19:07:53,232 - train - INFO - Train: 28 [ 750/781 ( 96%)]  Loss:  4.521540 (3.8764)  Time: 0.821s,  155.88/s  (0.823s,  155.53/s)  LR: 4.591e-04  Data: 0.008 (0.007)
2024-04-06 19:08:17,649 - train - INFO - Train: 28 [ 780/781 (100%)]  Loss:  4.472396 (3.8769)  Time: 0.779s,  164.28/s  (0.823s,  155.59/s)  LR: 4.591e-04  Data: 0.000 (0.007)
2024-04-06 19:08:17,650 - train - INFO - True
2024-04-06 19:08:17,651 - train - INFO - alphas:tensor([0.2759, 0.1432, 0.1566, 0.2014, 0.2230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,651 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,651 - train - INFO - True
2024-04-06 19:08:17,652 - train - INFO - alphas:tensor([0.3562, 0.0921, 0.1060, 0.1726, 0.2732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,653 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,653 - train - INFO - True
2024-04-06 19:08:17,654 - train - INFO - alphas:tensor([0.7438, 0.0779, 0.0525, 0.0600, 0.0658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,654 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,654 - train - INFO - True
2024-04-06 19:08:17,655 - train - INFO - alphas:tensor([0.7105, 0.0640, 0.0566, 0.0766, 0.0922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,655 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,655 - train - INFO - True
2024-04-06 19:08:17,656 - train - INFO - alphas:tensor([0.5303, 0.0761, 0.0912, 0.1305, 0.1719], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,656 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,656 - train - INFO - True
2024-04-06 19:08:17,657 - train - INFO - alphas:tensor([0.6698, 0.0736, 0.0628, 0.0858, 0.1079], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,657 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,657 - train - INFO - True
2024-04-06 19:08:17,658 - train - INFO - alphas:tensor([0.7803, 0.0607, 0.0407, 0.0528, 0.0654], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,658 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,658 - train - INFO - True
2024-04-06 19:08:17,659 - train - INFO - alphas:tensor([0.7440, 0.0666, 0.0467, 0.0641, 0.0785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,659 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,659 - train - INFO - True
2024-04-06 19:08:17,660 - train - INFO - alphas:tensor([0.5804, 0.0664, 0.0771, 0.1162, 0.1598], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,660 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,661 - train - INFO - True
2024-04-06 19:08:17,661 - train - INFO - alphas:tensor([0.6974, 0.0662, 0.0591, 0.0772, 0.1001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,662 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,662 - train - INFO - True
2024-04-06 19:08:17,663 - train - INFO - alphas:tensor([0.7410, 0.0578, 0.0480, 0.0659, 0.0873], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,663 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,663 - train - INFO - True
2024-04-06 19:08:17,664 - train - INFO - alphas:tensor([0.6743, 0.0611, 0.0594, 0.0906, 0.1147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,664 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,664 - train - INFO - True
2024-04-06 19:08:17,665 - train - INFO - alphas:tensor([0.5976, 0.0604, 0.0699, 0.1131, 0.1590], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,665 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,665 - train - INFO - True
2024-04-06 19:08:17,666 - train - INFO - alphas:tensor([0.6972, 0.0565, 0.0583, 0.0804, 0.1076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,666 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,666 - train - INFO - True
2024-04-06 19:08:17,667 - train - INFO - alphas:tensor([0.7028, 0.0672, 0.0524, 0.0748, 0.1028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,667 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,667 - train - INFO - True
2024-04-06 19:08:17,668 - train - INFO - alphas:tensor([0.5871, 0.0577, 0.0642, 0.1120, 0.1790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,668 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,668 - train - INFO - True
2024-04-06 19:08:17,669 - train - INFO - alphas:tensor([0.5903, 0.0588, 0.0685, 0.1153, 0.1671], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,669 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,669 - train - INFO - True
2024-04-06 19:08:17,670 - train - INFO - alphas:tensor([0.6976, 0.0538, 0.0585, 0.0816, 0.1086], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,670 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,670 - train - INFO - True
2024-04-06 19:08:17,671 - train - INFO - alphas:tensor([0.7172, 0.0585, 0.0502, 0.0736, 0.1005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,671 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,672 - train - INFO - True
2024-04-06 19:08:17,672 - train - INFO - alphas:tensor([0.5684, 0.0521, 0.0622, 0.1206, 0.1968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,673 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,673 - train - INFO - True
2024-04-06 19:08:17,673 - train - INFO - alphas:tensor([0.5572, 0.0573, 0.0757, 0.1263, 0.1836], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,674 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,674 - train - INFO - True
2024-04-06 19:08:17,674 - train - INFO - alphas:tensor([0.7256, 0.0496, 0.0535, 0.0729, 0.0984], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,675 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,675 - train - INFO - True
2024-04-06 19:08:17,676 - train - INFO - alphas:tensor([0.7312, 0.0620, 0.0463, 0.0673, 0.0933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,676 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,676 - train - INFO - True
2024-04-06 19:08:17,677 - train - INFO - alphas:tensor([0.5808, 0.0469, 0.0581, 0.1174, 0.1969], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,677 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,677 - train - INFO - True
2024-04-06 19:08:17,678 - train - INFO - alphas:tensor([0.5481, 0.0527, 0.0744, 0.1315, 0.1934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,678 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,678 - train - INFO - True
2024-04-06 19:08:17,679 - train - INFO - alphas:tensor([0.7109, 0.0494, 0.0546, 0.0752, 0.1099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,679 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,679 - train - INFO - True
2024-04-06 19:08:17,680 - train - INFO - alphas:tensor([0.7290, 0.0500, 0.0459, 0.0711, 0.1041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,680 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,680 - train - INFO - True
2024-04-06 19:08:17,681 - train - INFO - alphas:tensor([0.6035, 0.0480, 0.0548, 0.1097, 0.1840], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,681 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,681 - train - INFO - True
2024-04-06 19:08:17,682 - train - INFO - alphas:tensor([0.5221, 0.0488, 0.0798, 0.1393, 0.2099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,682 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,682 - train - INFO - True
2024-04-06 19:08:17,683 - train - INFO - alphas:tensor([0.6852, 0.0481, 0.0569, 0.0851, 0.1247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,683 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,683 - train - INFO - True
2024-04-06 19:08:17,684 - train - INFO - alphas:tensor([0.7232, 0.0468, 0.0457, 0.0731, 0.1113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,684 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,684 - train - INFO - True
2024-04-06 19:08:17,685 - train - INFO - alphas:tensor([0.6495, 0.0457, 0.0535, 0.0995, 0.1518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,685 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,685 - train - INFO - True
2024-04-06 19:08:17,686 - train - INFO - alphas:tensor([0.4999, 0.0448, 0.0802, 0.1456, 0.2294], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,686 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,686 - train - INFO - True
2024-04-06 19:08:17,687 - train - INFO - alphas:tensor([0.6394, 0.0497, 0.0617, 0.0984, 0.1508], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,687 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,687 - train - INFO - True
2024-04-06 19:08:17,688 - train - INFO - alphas:tensor([0.6973, 0.0503, 0.0473, 0.0832, 0.1219], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,688 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,688 - train - INFO - True
2024-04-06 19:08:17,689 - train - INFO - alphas:tensor([0.6489, 0.0461, 0.0555, 0.1003, 0.1492], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,689 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,689 - train - INFO - True
2024-04-06 19:08:17,690 - train - INFO - alphas:tensor([0.6811, 0.0671, 0.1099, 0.1419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:08:17,690 - train - INFO - tau:0.7700431458051551
2024-04-06 19:08:17,690 - train - INFO - avg block size:1.0
2024-04-06 19:08:17,690 - train - INFO - lasso_alpha:3.138428376721003e-05
2024-04-06 19:08:17,941 - train - INFO - Test: [   0/78]  Time: 0.247 (0.247)  Loss:  1.0146 (1.0146)  Acc@1: 80.4688 (80.4688)  Acc@5: 94.5312 (94.5312)
2024-04-06 19:08:22,478 - train - INFO - Test: [  50/78]  Time: 0.084 (0.094)  Loss:  1.8877 (1.7110)  Acc@1: 57.8125 (60.2482)  Acc@5: 81.2500 (83.1036)
2024-04-06 19:08:24,792 - train - INFO - Test: [  78/78]  Time: 0.052 (0.090)  Loss:  1.9023 (1.7417)  Acc@1: 50.0000 (59.3500)  Acc@5: 87.5000 (82.5700)
2024-04-06 19:08:25,823 - train - INFO - Train: 29 [   0/781 (  0%)]  Loss:  4.202466 (4.2025)  Time: 0.966s,  132.52/s  (0.966s,  132.52/s)  LR: 4.562e-04  Data: 0.182 (0.182)
2024-04-06 19:09:06,126 - train - INFO - Train: 29 [  50/781 (  6%)]  Loss:  3.936566 (3.8309)  Time: 0.827s,  154.79/s  (0.809s,  158.19/s)  LR: 4.562e-04  Data: 0.007 (0.010)
2024-04-06 19:09:47,416 - train - INFO - Train: 29 [ 100/781 ( 13%)]  Loss:  3.599407 (3.8549)  Time: 0.831s,  154.04/s  (0.817s,  156.60/s)  LR: 4.562e-04  Data: 0.009 (0.009)
2024-04-06 19:10:28,096 - train - INFO - Train: 29 [ 150/781 ( 19%)]  Loss:  3.577790 (3.8547)  Time: 0.820s,  156.01/s  (0.816s,  156.84/s)  LR: 4.562e-04  Data: 0.007 (0.008)
2024-04-06 19:11:09,183 - train - INFO - Train: 29 [ 200/781 ( 26%)]  Loss:  4.397054 (3.8489)  Time: 0.791s,  161.89/s  (0.818s,  156.57/s)  LR: 4.562e-04  Data: 0.005 (0.008)
2024-04-06 19:11:50,254 - train - INFO - Train: 29 [ 250/781 ( 32%)]  Loss:  3.486031 (3.8578)  Time: 0.784s,  163.21/s  (0.818s,  156.42/s)  LR: 4.562e-04  Data: 0.005 (0.008)
2024-04-06 19:12:31,511 - train - INFO - Train: 29 [ 300/781 ( 38%)]  Loss:  4.405218 (3.8773)  Time: 0.809s,  158.17/s  (0.819s,  156.21/s)  LR: 4.562e-04  Data: 0.007 (0.008)
2024-04-06 19:13:12,193 - train - INFO - Train: 29 [ 350/781 ( 45%)]  Loss:  3.940984 (3.8787)  Time: 0.816s,  156.77/s  (0.819s,  156.37/s)  LR: 4.562e-04  Data: 0.008 (0.008)
2024-04-06 19:13:53,041 - train - INFO - Train: 29 [ 400/781 ( 51%)]  Loss:  4.091767 (3.8782)  Time: 0.819s,  156.32/s  (0.818s,  156.41/s)  LR: 4.562e-04  Data: 0.008 (0.008)
2024-04-06 19:14:33,879 - train - INFO - Train: 29 [ 450/781 ( 58%)]  Loss:  4.309603 (3.8834)  Time: 0.782s,  163.71/s  (0.818s,  156.44/s)  LR: 4.562e-04  Data: 0.005 (0.008)
2024-04-06 19:15:15,809 - train - INFO - Train: 29 [ 500/781 ( 64%)]  Loss:  4.468259 (3.8758)  Time: 0.775s,  165.09/s  (0.820s,  156.05/s)  LR: 4.562e-04  Data: 0.005 (0.008)
2024-04-06 19:15:56,924 - train - INFO - Train: 29 [ 550/781 ( 71%)]  Loss:  4.201273 (3.8792)  Time: 1.062s,  120.54/s  (0.820s,  156.02/s)  LR: 4.562e-04  Data: 0.009 (0.008)
2024-04-06 19:16:37,839 - train - INFO - Train: 29 [ 600/781 ( 77%)]  Loss:  3.354251 (3.8782)  Time: 0.823s,  155.58/s  (0.820s,  156.05/s)  LR: 4.562e-04  Data: 0.009 (0.007)
2024-04-06 19:17:17,642 - train - INFO - Train: 29 [ 650/781 ( 83%)]  Loss:  4.470229 (3.8800)  Time: 0.796s,  160.84/s  (0.818s,  156.41/s)  LR: 4.562e-04  Data: 0.007 (0.007)
2024-04-06 19:17:58,054 - train - INFO - Train: 29 [ 700/781 ( 90%)]  Loss:  3.191110 (3.8756)  Time: 0.786s,  162.77/s  (0.818s,  156.54/s)  LR: 4.562e-04  Data: 0.005 (0.007)
2024-04-06 19:18:38,671 - train - INFO - Train: 29 [ 750/781 ( 96%)]  Loss:  4.088628 (3.8717)  Time: 0.795s,  161.03/s  (0.817s,  156.61/s)  LR: 4.562e-04  Data: 0.005 (0.007)
2024-04-06 19:19:02,553 - train - INFO - Train: 29 [ 780/781 (100%)]  Loss:  4.121027 (3.8701)  Time: 0.760s,  168.48/s  (0.816s,  156.77/s)  LR: 4.562e-04  Data: 0.000 (0.007)
2024-04-06 19:19:02,554 - train - INFO - True
2024-04-06 19:19:02,555 - train - INFO - alphas:tensor([0.2701, 0.1403, 0.1571, 0.2048, 0.2277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,556 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,556 - train - INFO - True
2024-04-06 19:19:02,557 - train - INFO - alphas:tensor([0.3517, 0.0897, 0.1052, 0.1735, 0.2800], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,557 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,557 - train - INFO - True
2024-04-06 19:19:02,559 - train - INFO - alphas:tensor([0.7455, 0.0768, 0.0520, 0.0598, 0.0659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,559 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,559 - train - INFO - True
2024-04-06 19:19:02,560 - train - INFO - alphas:tensor([0.7082, 0.0633, 0.0566, 0.0776, 0.0943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,561 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,561 - train - INFO - True
2024-04-06 19:19:02,562 - train - INFO - alphas:tensor([0.5293, 0.0735, 0.0905, 0.1315, 0.1752], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,562 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,562 - train - INFO - True
2024-04-06 19:19:02,563 - train - INFO - alphas:tensor([0.6688, 0.0715, 0.0627, 0.0867, 0.1102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,564 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,564 - train - INFO - True
2024-04-06 19:19:02,565 - train - INFO - alphas:tensor([0.7802, 0.0600, 0.0403, 0.0531, 0.0665], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,565 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,565 - train - INFO - True
2024-04-06 19:19:02,566 - train - INFO - alphas:tensor([0.7357, 0.0667, 0.0477, 0.0667, 0.0831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,567 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,567 - train - INFO - True
2024-04-06 19:19:02,568 - train - INFO - alphas:tensor([0.5788, 0.0644, 0.0767, 0.1170, 0.1631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,568 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,568 - train - INFO - True
2024-04-06 19:19:02,569 - train - INFO - alphas:tensor([0.6957, 0.0647, 0.0592, 0.0779, 0.1025], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,570 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,570 - train - INFO - True
2024-04-06 19:19:02,571 - train - INFO - alphas:tensor([0.7370, 0.0569, 0.0481, 0.0674, 0.0905], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,571 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,571 - train - INFO - True
2024-04-06 19:19:02,572 - train - INFO - alphas:tensor([0.6661, 0.0595, 0.0598, 0.0937, 0.1209], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,573 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,573 - train - INFO - True
2024-04-06 19:19:02,574 - train - INFO - alphas:tensor([0.5945, 0.0584, 0.0692, 0.1144, 0.1634], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,574 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,574 - train - INFO - True
2024-04-06 19:19:02,575 - train - INFO - alphas:tensor([0.6939, 0.0551, 0.0580, 0.0815, 0.1115], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,575 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,576 - train - INFO - True
2024-04-06 19:19:02,577 - train - INFO - alphas:tensor([0.6957, 0.0661, 0.0531, 0.0771, 0.1081], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,577 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,577 - train - INFO - True
2024-04-06 19:19:02,578 - train - INFO - alphas:tensor([0.5788, 0.0549, 0.0634, 0.1144, 0.1884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,578 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,578 - train - INFO - True
2024-04-06 19:19:02,580 - train - INFO - alphas:tensor([0.5885, 0.0568, 0.0680, 0.1160, 0.1707], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,580 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,580 - train - INFO - True
2024-04-06 19:19:02,581 - train - INFO - alphas:tensor([0.6925, 0.0530, 0.0584, 0.0831, 0.1130], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,581 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,581 - train - INFO - True
2024-04-06 19:19:02,582 - train - INFO - alphas:tensor([0.7110, 0.0577, 0.0503, 0.0756, 0.1053], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,583 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,583 - train - INFO - True
2024-04-06 19:19:02,584 - train - INFO - alphas:tensor([0.5569, 0.0495, 0.0613, 0.1237, 0.2086], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,584 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,584 - train - INFO - True
2024-04-06 19:19:02,585 - train - INFO - alphas:tensor([0.5503, 0.0555, 0.0758, 0.1285, 0.1899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,585 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,585 - train - INFO - True
2024-04-06 19:19:02,587 - train - INFO - alphas:tensor([0.7217, 0.0483, 0.0535, 0.0741, 0.1023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,587 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,587 - train - INFO - True
2024-04-06 19:19:02,588 - train - INFO - alphas:tensor([0.7262, 0.0612, 0.0463, 0.0688, 0.0974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,588 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,588 - train - INFO - True
2024-04-06 19:19:02,589 - train - INFO - alphas:tensor([0.5719, 0.0443, 0.0573, 0.1194, 0.2071], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,589 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,589 - train - INFO - True
2024-04-06 19:19:02,591 - train - INFO - alphas:tensor([0.5413, 0.0511, 0.0741, 0.1335, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,591 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,591 - train - INFO - True
2024-04-06 19:19:02,592 - train - INFO - alphas:tensor([0.7055, 0.0488, 0.0545, 0.0764, 0.1149], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,592 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,592 - train - INFO - True
2024-04-06 19:19:02,593 - train - INFO - alphas:tensor([0.7266, 0.0489, 0.0450, 0.0719, 0.1076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,593 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,593 - train - INFO - True
2024-04-06 19:19:02,594 - train - INFO - alphas:tensor([0.5968, 0.0459, 0.0532, 0.1109, 0.1932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,595 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,595 - train - INFO - True
2024-04-06 19:19:02,596 - train - INFO - alphas:tensor([0.5152, 0.0463, 0.0791, 0.1414, 0.2180], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,596 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,596 - train - INFO - True
2024-04-06 19:19:02,597 - train - INFO - alphas:tensor([0.6776, 0.0471, 0.0570, 0.0875, 0.1308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,597 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,597 - train - INFO - True
2024-04-06 19:19:02,598 - train - INFO - alphas:tensor([0.7162, 0.0459, 0.0458, 0.0753, 0.1169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,599 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,599 - train - INFO - True
2024-04-06 19:19:02,600 - train - INFO - alphas:tensor([0.6412, 0.0439, 0.0526, 0.1018, 0.1604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,600 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,600 - train - INFO - True
2024-04-06 19:19:02,601 - train - INFO - alphas:tensor([0.4931, 0.0428, 0.0791, 0.1474, 0.2375], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,601 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,601 - train - INFO - True
2024-04-06 19:19:02,602 - train - INFO - alphas:tensor([0.6301, 0.0481, 0.0618, 0.1008, 0.1593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,602 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,603 - train - INFO - True
2024-04-06 19:19:02,604 - train - INFO - alphas:tensor([0.6917, 0.0497, 0.0469, 0.0845, 0.1272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,604 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,604 - train - INFO - True
2024-04-06 19:19:02,605 - train - INFO - alphas:tensor([0.6402, 0.0441, 0.0554, 0.1029, 0.1573], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,605 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,605 - train - INFO - True
2024-04-06 19:19:02,606 - train - INFO - alphas:tensor([0.6839, 0.0659, 0.1088, 0.1414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:19:02,606 - train - INFO - tau:0.7623427143471035
2024-04-06 19:19:02,606 - train - INFO - avg block size:1.0
2024-04-06 19:19:02,844 - train - INFO - Test: [   0/78]  Time: 0.234 (0.234)  Loss:  0.9185 (0.9185)  Acc@1: 84.3750 (84.3750)  Acc@5: 92.9688 (92.9688)
2024-04-06 19:19:07,431 - train - INFO - Test: [  50/78]  Time: 0.084 (0.095)  Loss:  1.8115 (1.7352)  Acc@1: 59.3750 (59.6507)  Acc@5: 82.0312 (82.4908)
2024-04-06 19:19:09,779 - train - INFO - Test: [  78/78]  Time: 0.053 (0.091)  Loss:  1.9658 (1.7692)  Acc@1: 56.2500 (58.4500)  Acc@5: 93.7500 (82.1200)
2024-04-06 19:19:11,077 - train - INFO - Train: 30 [   0/781 (  0%)]  Loss:  4.363309 (4.3633)  Time: 1.235s,  103.63/s  (1.235s,  103.63/s)  LR: 4.532e-04  Data: 0.200 (0.200)
2024-04-06 19:19:51,879 - train - INFO - Train: 30 [  50/781 (  6%)]  Loss:  4.385243 (3.8778)  Time: 0.778s,  164.50/s  (0.824s,  155.30/s)  LR: 4.532e-04  Data: 0.006 (0.011)
2024-04-06 19:20:32,858 - train - INFO - Train: 30 [ 100/781 ( 13%)]  Loss:  3.774143 (3.9131)  Time: 0.828s,  154.65/s  (0.822s,  155.73/s)  LR: 4.532e-04  Data: 0.008 (0.009)
2024-04-06 19:21:13,575 - train - INFO - Train: 30 [ 150/781 ( 19%)]  Loss:  3.886306 (3.9271)  Time: 0.813s,  157.39/s  (0.819s,  156.21/s)  LR: 4.532e-04  Data: 0.008 (0.008)
2024-04-06 19:21:54,376 - train - INFO - Train: 30 [ 200/781 ( 26%)]  Loss:  3.762855 (3.9031)  Time: 0.792s,  161.61/s  (0.819s,  156.37/s)  LR: 4.532e-04  Data: 0.006 (0.008)
2024-04-06 19:22:34,741 - train - INFO - Train: 30 [ 250/781 ( 32%)]  Loss:  4.146079 (3.9027)  Time: 0.787s,  162.66/s  (0.816s,  156.80/s)  LR: 4.532e-04  Data: 0.006 (0.008)
2024-04-06 19:23:14,331 - train - INFO - Train: 30 [ 300/781 ( 38%)]  Loss:  4.427390 (3.9131)  Time: 0.791s,  161.91/s  (0.812s,  157.59/s)  LR: 4.532e-04  Data: 0.005 (0.007)
2024-04-06 19:23:55,886 - train - INFO - Train: 30 [ 350/781 ( 45%)]  Loss:  3.913868 (3.9017)  Time: 0.780s,  164.21/s  (0.815s,  157.07/s)  LR: 4.532e-04  Data: 0.005 (0.007)
2024-04-06 19:24:36,190 - train - INFO - Train: 30 [ 400/781 ( 51%)]  Loss:  4.007859 (3.9028)  Time: 0.820s,  156.13/s  (0.814s,  157.29/s)  LR: 4.532e-04  Data: 0.009 (0.007)
2024-04-06 19:25:17,359 - train - INFO - Train: 30 [ 450/781 ( 58%)]  Loss:  3.966054 (3.8945)  Time: 0.809s,  158.22/s  (0.815s,  157.08/s)  LR: 4.532e-04  Data: 0.008 (0.007)
2024-04-06 19:25:58,226 - train - INFO - Train: 30 [ 500/781 ( 64%)]  Loss:  4.419422 (3.8990)  Time: 0.779s,  164.33/s  (0.815s,  157.03/s)  LR: 4.532e-04  Data: 0.005 (0.007)
2024-04-06 19:26:39,548 - train - INFO - Train: 30 [ 550/781 ( 71%)]  Loss:  3.935714 (3.8951)  Time: 0.834s,  153.49/s  (0.816s,  156.84/s)  LR: 4.532e-04  Data: 0.008 (0.007)
2024-04-06 19:27:21,897 - train - INFO - Train: 30 [ 600/781 ( 77%)]  Loss:  4.057377 (3.8992)  Time: 0.821s,  155.85/s  (0.819s,  156.35/s)  LR: 4.532e-04  Data: 0.008 (0.007)
2024-04-06 19:28:03,753 - train - INFO - Train: 30 [ 650/781 ( 83%)]  Loss:  3.406967 (3.8977)  Time: 0.824s,  155.27/s  (0.820s,  156.08/s)  LR: 4.532e-04  Data: 0.008 (0.007)
2024-04-06 19:28:45,840 - train - INFO - Train: 30 [ 700/781 ( 90%)]  Loss:  4.354803 (3.8934)  Time: 0.836s,  153.13/s  (0.822s,  155.78/s)  LR: 4.532e-04  Data: 0.008 (0.007)
2024-04-06 19:29:26,607 - train - INFO - Train: 30 [ 750/781 ( 96%)]  Loss:  3.304371 (3.8878)  Time: 0.837s,  152.97/s  (0.821s,  155.86/s)  LR: 4.532e-04  Data: 0.008 (0.007)
2024-04-06 19:29:51,952 - train - INFO - Train: 30 [ 780/781 (100%)]  Loss:  4.121092 (3.8853)  Time: 0.814s,  157.29/s  (0.822s,  155.69/s)  LR: 4.532e-04  Data: 0.000 (0.007)
2024-04-06 19:29:51,952 - train - INFO - True
2024-04-06 19:29:51,954 - train - INFO - alphas:tensor([0.2646, 0.1371, 0.1577, 0.2080, 0.2325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,954 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,954 - train - INFO - True
2024-04-06 19:29:51,955 - train - INFO - alphas:tensor([0.3479, 0.0870, 0.1037, 0.1738, 0.2877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,955 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,955 - train - INFO - True
2024-04-06 19:29:51,956 - train - INFO - alphas:tensor([0.7467, 0.0760, 0.0517, 0.0597, 0.0659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,956 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,956 - train - INFO - True
2024-04-06 19:29:51,957 - train - INFO - alphas:tensor([0.7054, 0.0627, 0.0566, 0.0787, 0.0965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,957 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,958 - train - INFO - True
2024-04-06 19:29:51,958 - train - INFO - alphas:tensor([0.5237, 0.0725, 0.0909, 0.1331, 0.1798], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,959 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,959 - train - INFO - True
2024-04-06 19:29:51,960 - train - INFO - alphas:tensor([0.6652, 0.0702, 0.0631, 0.0881, 0.1135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,960 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,960 - train - INFO - True
2024-04-06 19:29:51,961 - train - INFO - alphas:tensor([0.7782, 0.0596, 0.0402, 0.0540, 0.0680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,961 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,961 - train - INFO - True
2024-04-06 19:29:51,963 - train - INFO - alphas:tensor([0.7269, 0.0671, 0.0482, 0.0695, 0.0883], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,963 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,963 - train - INFO - True
2024-04-06 19:29:51,964 - train - INFO - alphas:tensor([0.5734, 0.0632, 0.0765, 0.1187, 0.1682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,964 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,964 - train - INFO - True
2024-04-06 19:29:51,965 - train - INFO - alphas:tensor([0.6914, 0.0636, 0.0596, 0.0794, 0.1061], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,965 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,965 - train - INFO - True
2024-04-06 19:29:51,966 - train - INFO - alphas:tensor([0.7332, 0.0562, 0.0480, 0.0689, 0.0937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,966 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,967 - train - INFO - True
2024-04-06 19:29:51,967 - train - INFO - alphas:tensor([0.6575, 0.0584, 0.0595, 0.0970, 0.1276], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,968 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,968 - train - INFO - True
2024-04-06 19:29:51,968 - train - INFO - alphas:tensor([0.5924, 0.0571, 0.0685, 0.1151, 0.1669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,969 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,969 - train - INFO - True
2024-04-06 19:29:51,970 - train - INFO - alphas:tensor([0.6892, 0.0539, 0.0582, 0.0831, 0.1157], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,970 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,970 - train - INFO - True
2024-04-06 19:29:51,971 - train - INFO - alphas:tensor([0.6896, 0.0651, 0.0529, 0.0793, 0.1131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,971 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,971 - train - INFO - True
2024-04-06 19:29:51,972 - train - INFO - alphas:tensor([0.5691, 0.0532, 0.0622, 0.1172, 0.1983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,972 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,972 - train - INFO - True
2024-04-06 19:29:51,973 - train - INFO - alphas:tensor([0.5879, 0.0550, 0.0667, 0.1163, 0.1742], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,973 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,973 - train - INFO - True
2024-04-06 19:29:51,974 - train - INFO - alphas:tensor([0.6889, 0.0508, 0.0585, 0.0849, 0.1170], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,974 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,974 - train - INFO - True
2024-04-06 19:29:51,975 - train - INFO - alphas:tensor([0.7038, 0.0567, 0.0503, 0.0781, 0.1112], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,975 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,975 - train - INFO - True
2024-04-06 19:29:51,976 - train - INFO - alphas:tensor([0.5511, 0.0473, 0.0597, 0.1243, 0.2176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,976 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,976 - train - INFO - True
2024-04-06 19:29:51,977 - train - INFO - alphas:tensor([0.5466, 0.0529, 0.0749, 0.1299, 0.1957], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,977 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,977 - train - INFO - True
2024-04-06 19:29:51,978 - train - INFO - alphas:tensor([0.7176, 0.0467, 0.0532, 0.0757, 0.1068], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,978 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,978 - train - INFO - True
2024-04-06 19:29:51,979 - train - INFO - alphas:tensor([0.7254, 0.0594, 0.0455, 0.0692, 0.1005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,979 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,979 - train - INFO - True
2024-04-06 19:29:51,980 - train - INFO - alphas:tensor([0.5680, 0.0421, 0.0548, 0.1197, 0.2154], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,980 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,980 - train - INFO - True
2024-04-06 19:29:51,981 - train - INFO - alphas:tensor([0.5390, 0.0487, 0.0730, 0.1340, 0.2053], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,981 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,981 - train - INFO - True
2024-04-06 19:29:51,982 - train - INFO - alphas:tensor([0.7021, 0.0471, 0.0545, 0.0776, 0.1186], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,982 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,982 - train - INFO - True
2024-04-06 19:29:51,983 - train - INFO - alphas:tensor([0.7214, 0.0480, 0.0449, 0.0735, 0.1123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,983 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,983 - train - INFO - True
2024-04-06 19:29:51,984 - train - INFO - alphas:tensor([0.5876, 0.0445, 0.0520, 0.1126, 0.2033], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,984 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,984 - train - INFO - True
2024-04-06 19:29:51,985 - train - INFO - alphas:tensor([0.5124, 0.0439, 0.0775, 0.1425, 0.2237], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,985 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,985 - train - INFO - True
2024-04-06 19:29:51,986 - train - INFO - alphas:tensor([0.6771, 0.0449, 0.0564, 0.0876, 0.1340], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,986 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,986 - train - INFO - True
2024-04-06 19:29:51,987 - train - INFO - alphas:tensor([0.7142, 0.0446, 0.0446, 0.0761, 0.1205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,987 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,987 - train - INFO - True
2024-04-06 19:29:51,988 - train - INFO - alphas:tensor([0.6346, 0.0421, 0.0517, 0.1034, 0.1682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,988 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,988 - train - INFO - True
2024-04-06 19:29:51,989 - train - INFO - alphas:tensor([0.4885, 0.0408, 0.0782, 0.1480, 0.2445], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,989 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,989 - train - INFO - True
2024-04-06 19:29:51,990 - train - INFO - alphas:tensor([0.6259, 0.0452, 0.0608, 0.1020, 0.1661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,990 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,990 - train - INFO - True
2024-04-06 19:29:51,991 - train - INFO - alphas:tensor([0.6922, 0.0482, 0.0457, 0.0842, 0.1298], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,991 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,991 - train - INFO - True
2024-04-06 19:29:51,992 - train - INFO - alphas:tensor([0.6385, 0.0422, 0.0534, 0.1036, 0.1622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,992 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,992 - train - INFO - True
2024-04-06 19:29:51,993 - train - INFO - alphas:tensor([0.6859, 0.0647, 0.1079, 0.1415], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:29:51,993 - train - INFO - tau:0.7547192872036325
2024-04-06 19:29:51,993 - train - INFO - avg block size:1.0
2024-04-06 19:29:51,993 - train - INFO - lasso_alpha:3.452271214393104e-05
2024-04-06 19:29:52,242 - train - INFO - Test: [   0/78]  Time: 0.245 (0.245)  Loss:  0.9614 (0.9614)  Acc@1: 78.9062 (78.9062)  Acc@5: 93.7500 (93.7500)
2024-04-06 19:29:56,591 - train - INFO - Test: [  50/78]  Time: 0.084 (0.090)  Loss:  1.9531 (1.7100)  Acc@1: 54.6875 (59.8805)  Acc@5: 80.4688 (83.3793)
2024-04-06 19:29:58,999 - train - INFO - Test: [  78/78]  Time: 0.078 (0.089)  Loss:  1.8018 (1.7339)  Acc@1: 62.5000 (59.4700)  Acc@5: 81.2500 (82.6700)
2024-04-06 19:30:00,289 - train - INFO - Train: 31 [   0/781 (  0%)]  Loss:  3.953973 (3.9540)  Time: 1.204s,  106.35/s  (1.204s,  106.35/s)  LR: 4.501e-04  Data: 0.186 (0.186)
2024-04-06 19:30:40,974 - train - INFO - Train: 31 [  50/781 (  6%)]  Loss:  3.550028 (3.8046)  Time: 0.784s,  163.21/s  (0.821s,  155.85/s)  LR: 4.501e-04  Data: 0.005 (0.010)
2024-04-06 19:31:22,369 - train - INFO - Train: 31 [ 100/781 ( 13%)]  Loss:  4.474903 (3.8382)  Time: 0.793s,  161.40/s  (0.825s,  155.23/s)  LR: 4.501e-04  Data: 0.006 (0.009)
2024-04-06 19:32:02,990 - train - INFO - Train: 31 [ 150/781 ( 19%)]  Loss:  3.496051 (3.8301)  Time: 0.822s,  155.75/s  (0.821s,  156.00/s)  LR: 4.501e-04  Data: 0.009 (0.008)
2024-04-06 19:32:44,544 - train - INFO - Train: 31 [ 200/781 ( 26%)]  Loss:  3.519656 (3.8452)  Time: 0.817s,  156.72/s  (0.823s,  155.50/s)  LR: 4.501e-04  Data: 0.007 (0.008)
2024-04-06 19:33:26,496 - train - INFO - Train: 31 [ 250/781 ( 32%)]  Loss:  4.370138 (3.8369)  Time: 0.817s,  156.71/s  (0.826s,  154.91/s)  LR: 4.501e-04  Data: 0.008 (0.008)
2024-04-06 19:34:06,779 - train - INFO - Train: 31 [ 300/781 ( 38%)]  Loss:  4.164946 (3.8534)  Time: 0.831s,  154.09/s  (0.823s,  155.55/s)  LR: 4.501e-04  Data: 0.009 (0.008)
2024-04-06 19:34:46,917 - train - INFO - Train: 31 [ 350/781 ( 45%)]  Loss:  4.489709 (3.8646)  Time: 0.835s,  153.33/s  (0.820s,  156.10/s)  LR: 4.501e-04  Data: 0.009 (0.007)
2024-04-06 19:35:27,898 - train - INFO - Train: 31 [ 400/781 ( 51%)]  Loss:  4.339337 (3.8691)  Time: 0.808s,  158.36/s  (0.820s,  156.11/s)  LR: 4.501e-04  Data: 0.005 (0.007)
2024-04-06 19:36:09,220 - train - INFO - Train: 31 [ 450/781 ( 58%)]  Loss:  4.278811 (3.8668)  Time: 0.873s,  146.61/s  (0.821s,  155.97/s)  LR: 4.501e-04  Data: 0.006 (0.007)
2024-04-06 19:36:50,640 - train - INFO - Train: 31 [ 500/781 ( 64%)]  Loss:  4.133395 (3.8773)  Time: 0.820s,  156.08/s  (0.821s,  155.82/s)  LR: 4.501e-04  Data: 0.008 (0.007)
2024-04-06 19:37:31,494 - train - INFO - Train: 31 [ 550/781 ( 71%)]  Loss:  4.169254 (3.8773)  Time: 0.766s,  167.10/s  (0.821s,  155.90/s)  LR: 4.501e-04  Data: 0.005 (0.007)
2024-04-06 19:38:12,686 - train - INFO - Train: 31 [ 600/781 ( 77%)]  Loss:  3.976192 (3.8740)  Time: 0.778s,  164.55/s  (0.821s,  155.86/s)  LR: 4.501e-04  Data: 0.004 (0.007)
2024-04-06 19:38:53,955 - train - INFO - Train: 31 [ 650/781 ( 83%)]  Loss:  3.306258 (3.8700)  Time: 0.792s,  161.54/s  (0.822s,  155.80/s)  LR: 4.501e-04  Data: 0.005 (0.007)
2024-04-06 19:39:35,571 - train - INFO - Train: 31 [ 700/781 ( 90%)]  Loss:  3.920989 (3.8743)  Time: 0.836s,  153.13/s  (0.822s,  155.65/s)  LR: 4.501e-04  Data: 0.008 (0.007)
2024-04-06 19:40:17,804 - train - INFO - Train: 31 [ 750/781 ( 96%)]  Loss:  4.213736 (3.8742)  Time: 0.835s,  153.34/s  (0.824s,  155.37/s)  LR: 4.501e-04  Data: 0.009 (0.007)
2024-04-06 19:40:42,388 - train - INFO - Train: 31 [ 780/781 (100%)]  Loss:  3.579561 (3.8755)  Time: 0.805s,  158.97/s  (0.824s,  155.40/s)  LR: 4.501e-04  Data: 0.000 (0.007)
2024-04-06 19:40:42,388 - train - INFO - True
2024-04-06 19:40:42,390 - train - INFO - alphas:tensor([0.2569, 0.1336, 0.1588, 0.2125, 0.2383], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,390 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,391 - train - INFO - True
2024-04-06 19:40:42,392 - train - INFO - alphas:tensor([0.3392, 0.0845, 0.1023, 0.1760, 0.2980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,392 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,392 - train - INFO - True
2024-04-06 19:40:42,393 - train - INFO - alphas:tensor([0.7449, 0.0763, 0.0519, 0.0603, 0.0667], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,393 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,394 - train - INFO - True
2024-04-06 19:40:42,395 - train - INFO - alphas:tensor([0.7013, 0.0624, 0.0569, 0.0801, 0.0993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,395 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,395 - train - INFO - True
2024-04-06 19:40:42,396 - train - INFO - alphas:tensor([0.5203, 0.0705, 0.0906, 0.1347, 0.1839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,396 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,396 - train - INFO - True
2024-04-06 19:40:42,398 - train - INFO - alphas:tensor([0.6639, 0.0682, 0.0628, 0.0889, 0.1161], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,398 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,398 - train - INFO - True
2024-04-06 19:40:42,399 - train - INFO - alphas:tensor([0.7768, 0.0591, 0.0402, 0.0546, 0.0692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,399 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,399 - train - INFO - True
2024-04-06 19:40:42,400 - train - INFO - alphas:tensor([0.7198, 0.0667, 0.0486, 0.0719, 0.0930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,401 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,401 - train - INFO - True
2024-04-06 19:40:42,402 - train - INFO - alphas:tensor([0.5716, 0.0616, 0.0759, 0.1193, 0.1716], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,402 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,402 - train - INFO - True
2024-04-06 19:40:42,403 - train - INFO - alphas:tensor([0.6880, 0.0622, 0.0593, 0.0804, 0.1100], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,403 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,404 - train - INFO - True
2024-04-06 19:40:42,405 - train - INFO - alphas:tensor([0.7260, 0.0556, 0.0486, 0.0714, 0.0984], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,405 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,405 - train - INFO - True
2024-04-06 19:40:42,406 - train - INFO - alphas:tensor([0.6452, 0.0575, 0.0598, 0.1011, 0.1365], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,406 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,406 - train - INFO - True
2024-04-06 19:40:42,407 - train - INFO - alphas:tensor([0.5881, 0.0553, 0.0682, 0.1166, 0.1718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,408 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,408 - train - INFO - True
2024-04-06 19:40:42,409 - train - INFO - alphas:tensor([0.6842, 0.0520, 0.0584, 0.0848, 0.1206], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,409 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,409 - train - INFO - True
2024-04-06 19:40:42,410 - train - INFO - alphas:tensor([0.6817, 0.0643, 0.0530, 0.0819, 0.1190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,410 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,410 - train - INFO - True
2024-04-06 19:40:42,411 - train - INFO - alphas:tensor([0.5539, 0.0516, 0.0617, 0.1209, 0.2119], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,412 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,412 - train - INFO - True
2024-04-06 19:40:42,413 - train - INFO - alphas:tensor([0.5809, 0.0538, 0.0666, 0.1183, 0.1804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,413 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,413 - train - INFO - True
2024-04-06 19:40:42,414 - train - INFO - alphas:tensor([0.6845, 0.0489, 0.0584, 0.0865, 0.1218], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,414 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,414 - train - INFO - True
2024-04-06 19:40:42,415 - train - INFO - alphas:tensor([0.6930, 0.0559, 0.0511, 0.0814, 0.1186], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,416 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,416 - train - INFO - True
2024-04-06 19:40:42,417 - train - INFO - alphas:tensor([0.5402, 0.0449, 0.0582, 0.1266, 0.2301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,417 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,417 - train - INFO - True
2024-04-06 19:40:42,418 - train - INFO - alphas:tensor([0.5388, 0.0509, 0.0747, 0.1325, 0.2032], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,418 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,418 - train - INFO - True
2024-04-06 19:40:42,419 - train - INFO - alphas:tensor([0.7088, 0.0466, 0.0545, 0.0779, 0.1122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,420 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,420 - train - INFO - True
2024-04-06 19:40:42,421 - train - INFO - alphas:tensor([0.7163, 0.0589, 0.0462, 0.0720, 0.1065], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,421 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,421 - train - INFO - True
2024-04-06 19:40:42,422 - train - INFO - alphas:tensor([0.5540, 0.0402, 0.0537, 0.1221, 0.2299], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,422 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,422 - train - INFO - True
2024-04-06 19:40:42,423 - train - INFO - alphas:tensor([0.5325, 0.0469, 0.0724, 0.1360, 0.2123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,423 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,423 - train - INFO - True
2024-04-06 19:40:42,424 - train - INFO - alphas:tensor([0.6931, 0.0462, 0.0549, 0.0801, 0.1257], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,425 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,425 - train - INFO - True
2024-04-06 19:40:42,426 - train - INFO - alphas:tensor([0.7149, 0.0467, 0.0450, 0.0755, 0.1178], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,426 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,426 - train - INFO - True
2024-04-06 19:40:42,427 - train - INFO - alphas:tensor([0.5784, 0.0426, 0.0506, 0.1141, 0.2143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,427 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,427 - train - INFO - True
2024-04-06 19:40:42,428 - train - INFO - alphas:tensor([0.5051, 0.0420, 0.0766, 0.1443, 0.2319], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,428 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,428 - train - INFO - True
2024-04-06 19:40:42,429 - train - INFO - alphas:tensor([0.6672, 0.0445, 0.0568, 0.0899, 0.1416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,430 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,430 - train - INFO - True
2024-04-06 19:40:42,431 - train - INFO - alphas:tensor([0.7091, 0.0431, 0.0445, 0.0774, 0.1259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,431 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,431 - train - INFO - True
2024-04-06 19:40:42,432 - train - INFO - alphas:tensor([0.6214, 0.0407, 0.0512, 0.1074, 0.1792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,432 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,432 - train - INFO - True
2024-04-06 19:40:42,433 - train - INFO - alphas:tensor([0.4821, 0.0394, 0.0773, 0.1491, 0.2522], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,433 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,433 - train - INFO - True
2024-04-06 19:40:42,434 - train - INFO - alphas:tensor([0.6214, 0.0431, 0.0601, 0.1029, 0.1725], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,434 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,434 - train - INFO - True
2024-04-06 19:40:42,435 - train - INFO - alphas:tensor([0.6879, 0.0474, 0.0449, 0.0853, 0.1344], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,436 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,436 - train - INFO - True
2024-04-06 19:40:42,437 - train - INFO - alphas:tensor([0.6316, 0.0413, 0.0525, 0.1052, 0.1694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,437 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,437 - train - INFO - True
2024-04-06 19:40:42,438 - train - INFO - alphas:tensor([0.6879, 0.0639, 0.1070, 0.1412], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:40:42,438 - train - INFO - tau:0.7471720943315961
2024-04-06 19:40:42,438 - train - INFO - avg block size:1.0
2024-04-06 19:40:42,671 - train - INFO - Test: [   0/78]  Time: 0.229 (0.229)  Loss:  0.9233 (0.9233)  Acc@1: 81.2500 (81.2500)  Acc@5: 94.5312 (94.5312)
2024-04-06 19:40:47,072 - train - INFO - Test: [  50/78]  Time: 0.084 (0.091)  Loss:  1.8223 (1.7273)  Acc@1: 58.5938 (59.8192)  Acc@5: 82.0312 (82.8278)
2024-04-06 19:40:49,398 - train - INFO - Test: [  78/78]  Time: 0.053 (0.088)  Loss:  1.5479 (1.7547)  Acc@1: 56.2500 (59.2000)  Acc@5: 87.5000 (82.3800)
2024-04-06 19:40:50,606 - train - INFO - Train: 32 [   0/781 (  0%)]  Loss:  3.498553 (3.4986)  Time: 1.142s,  112.08/s  (1.142s,  112.08/s)  LR: 4.470e-04  Data: 0.174 (0.174)
2024-04-06 19:41:31,163 - train - INFO - Train: 32 [  50/781 (  6%)]  Loss:  4.137136 (3.9487)  Time: 0.827s,  154.77/s  (0.818s,  156.56/s)  LR: 4.470e-04  Data: 0.009 (0.010)
2024-04-06 19:42:12,010 - train - INFO - Train: 32 [ 100/781 ( 13%)]  Loss:  3.500677 (3.8900)  Time: 0.782s,  163.75/s  (0.817s,  156.62/s)  LR: 4.470e-04  Data: 0.005 (0.008)
2024-04-06 19:42:53,146 - train - INFO - Train: 32 [ 150/781 ( 19%)]  Loss:  4.610707 (3.8718)  Time: 0.792s,  161.64/s  (0.819s,  156.28/s)  LR: 4.470e-04  Data: 0.006 (0.008)
2024-04-06 19:43:34,911 - train - INFO - Train: 32 [ 200/781 ( 26%)]  Loss:  3.934910 (3.8698)  Time: 0.825s,  155.20/s  (0.823s,  155.51/s)  LR: 4.470e-04  Data: 0.007 (0.008)
2024-04-06 19:44:16,433 - train - INFO - Train: 32 [ 250/781 ( 32%)]  Loss:  4.149975 (3.8825)  Time: 0.818s,  156.43/s  (0.825s,  155.24/s)  LR: 4.470e-04  Data: 0.008 (0.008)
2024-04-06 19:44:58,346 - train - INFO - Train: 32 [ 300/781 ( 38%)]  Loss:  3.932084 (3.8782)  Time: 0.826s,  154.98/s  (0.827s,  154.81/s)  LR: 4.470e-04  Data: 0.010 (0.007)
2024-04-06 19:45:40,095 - train - INFO - Train: 32 [ 350/781 ( 45%)]  Loss:  3.951200 (3.8939)  Time: 1.068s,  119.90/s  (0.828s,  154.59/s)  LR: 4.470e-04  Data: 0.008 (0.007)
2024-04-06 19:46:20,764 - train - INFO - Train: 32 [ 400/781 ( 51%)]  Loss:  4.255532 (3.8932)  Time: 0.829s,  154.32/s  (0.826s,  154.93/s)  LR: 4.470e-04  Data: 0.008 (0.007)
2024-04-06 19:47:01,557 - train - INFO - Train: 32 [ 450/781 ( 58%)]  Loss:  3.659376 (3.8867)  Time: 0.779s,  164.41/s  (0.825s,  155.15/s)  LR: 4.470e-04  Data: 0.005 (0.007)
2024-04-06 19:47:41,223 - train - INFO - Train: 32 [ 500/781 ( 64%)]  Loss:  4.362052 (3.8806)  Time: 0.807s,  158.56/s  (0.822s,  155.75/s)  LR: 4.470e-04  Data: 0.009 (0.007)
2024-04-06 19:48:20,680 - train - INFO - Train: 32 [ 550/781 ( 71%)]  Loss:  4.278568 (3.8898)  Time: 0.776s,  164.93/s  (0.819s,  156.31/s)  LR: 4.470e-04  Data: 0.005 (0.007)
2024-04-06 19:49:01,816 - train - INFO - Train: 32 [ 600/781 ( 77%)]  Loss:  3.283196 (3.8876)  Time: 0.789s,  162.30/s  (0.819s,  156.25/s)  LR: 4.470e-04  Data: 0.006 (0.007)
2024-04-06 19:49:42,248 - train - INFO - Train: 32 [ 650/781 ( 83%)]  Loss:  4.397448 (3.8886)  Time: 0.814s,  157.29/s  (0.818s,  156.41/s)  LR: 4.470e-04  Data: 0.008 (0.007)
2024-04-06 19:50:23,021 - train - INFO - Train: 32 [ 700/781 ( 90%)]  Loss:  4.311796 (3.8888)  Time: 0.820s,  156.02/s  (0.818s,  156.45/s)  LR: 4.470e-04  Data: 0.008 (0.007)
2024-04-06 19:51:04,835 - train - INFO - Train: 32 [ 750/781 ( 96%)]  Loss:  3.688813 (3.8928)  Time: 0.769s,  166.35/s  (0.819s,  156.22/s)  LR: 4.470e-04  Data: 0.005 (0.007)
2024-04-06 19:51:29,349 - train - INFO - Train: 32 [ 780/781 (100%)]  Loss:  4.142947 (3.8892)  Time: 0.774s,  165.47/s  (0.819s,  156.23/s)  LR: 4.470e-04  Data: 0.000 (0.007)
2024-04-06 19:51:29,349 - train - INFO - True
2024-04-06 19:51:29,351 - train - INFO - alphas:tensor([0.2515, 0.1309, 0.1590, 0.2158, 0.2428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,351 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,351 - train - INFO - True
2024-04-06 19:51:29,352 - train - INFO - alphas:tensor([0.3368, 0.0825, 0.1010, 0.1760, 0.3037], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,352 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,352 - train - INFO - True
2024-04-06 19:51:29,353 - train - INFO - alphas:tensor([0.7457, 0.0754, 0.0516, 0.0604, 0.0670], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,353 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,353 - train - INFO - True
2024-04-06 19:51:29,354 - train - INFO - alphas:tensor([0.6985, 0.0619, 0.0568, 0.0813, 0.1015], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,354 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,354 - train - INFO - True
2024-04-06 19:51:29,355 - train - INFO - alphas:tensor([0.5167, 0.0687, 0.0900, 0.1360, 0.1887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,355 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,355 - train - INFO - True
2024-04-06 19:51:29,356 - train - INFO - alphas:tensor([0.6564, 0.0677, 0.0636, 0.0915, 0.1208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,356 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,356 - train - INFO - True
2024-04-06 19:51:29,357 - train - INFO - alphas:tensor([0.7751, 0.0586, 0.0400, 0.0553, 0.0709], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,358 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,358 - train - INFO - True
2024-04-06 19:51:29,359 - train - INFO - alphas:tensor([0.7132, 0.0659, 0.0486, 0.0745, 0.0978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,359 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,359 - train - INFO - True
2024-04-06 19:51:29,360 - train - INFO - alphas:tensor([0.5666, 0.0601, 0.0759, 0.1210, 0.1763], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,360 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,360 - train - INFO - True
2024-04-06 19:51:29,361 - train - INFO - alphas:tensor([0.6865, 0.0609, 0.0589, 0.0813, 0.1125], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,361 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,361 - train - INFO - True
2024-04-06 19:51:29,362 - train - INFO - alphas:tensor([0.7210, 0.0555, 0.0487, 0.0731, 0.1018], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,362 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,362 - train - INFO - True
2024-04-06 19:51:29,363 - train - INFO - alphas:tensor([0.6376, 0.0558, 0.0596, 0.1038, 0.1432], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,363 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,363 - train - INFO - True
2024-04-06 19:51:29,364 - train - INFO - alphas:tensor([0.5849, 0.0536, 0.0675, 0.1178, 0.1762], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,364 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,364 - train - INFO - True
2024-04-06 19:51:29,365 - train - INFO - alphas:tensor([0.6807, 0.0509, 0.0582, 0.0859, 0.1243], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,365 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,365 - train - INFO - True
2024-04-06 19:51:29,366 - train - INFO - alphas:tensor([0.6793, 0.0630, 0.0522, 0.0826, 0.1229], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,366 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,366 - train - INFO - True
2024-04-06 19:51:29,367 - train - INFO - alphas:tensor([0.5497, 0.0484, 0.0599, 0.1221, 0.2200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,367 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,367 - train - INFO - True
2024-04-06 19:51:29,368 - train - INFO - alphas:tensor([0.5769, 0.0522, 0.0656, 0.1195, 0.1858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,368 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,369 - train - INFO - True
2024-04-06 19:51:29,369 - train - INFO - alphas:tensor([0.6798, 0.0477, 0.0582, 0.0879, 0.1264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,370 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,370 - train - INFO - True
2024-04-06 19:51:29,370 - train - INFO - alphas:tensor([0.6901, 0.0544, 0.0504, 0.0826, 0.1225], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,371 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,371 - train - INFO - True
2024-04-06 19:51:29,371 - train - INFO - alphas:tensor([0.5327, 0.0426, 0.0562, 0.1279, 0.2406], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,372 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,372 - train - INFO - True
2024-04-06 19:51:29,373 - train - INFO - alphas:tensor([0.5344, 0.0495, 0.0737, 0.1338, 0.2087], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,373 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,373 - train - INFO - True
2024-04-06 19:51:29,374 - train - INFO - alphas:tensor([0.7024, 0.0459, 0.0543, 0.0799, 0.1175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,374 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,374 - train - INFO - True
2024-04-06 19:51:29,375 - train - INFO - alphas:tensor([0.7122, 0.0582, 0.0454, 0.0734, 0.1108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,375 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,375 - train - INFO - True
2024-04-06 19:51:29,376 - train - INFO - alphas:tensor([0.5496, 0.0383, 0.0514, 0.1220, 0.2386], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,376 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,376 - train - INFO - True
2024-04-06 19:51:29,377 - train - INFO - alphas:tensor([0.5283, 0.0449, 0.0713, 0.1371, 0.2183], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,377 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,377 - train - INFO - True
2024-04-06 19:51:29,378 - train - INFO - alphas:tensor([0.6904, 0.0445, 0.0544, 0.0810, 0.1297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,378 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,378 - train - INFO - True
2024-04-06 19:51:29,379 - train - INFO - alphas:tensor([0.7178, 0.0446, 0.0435, 0.0747, 0.1195], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,379 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,379 - train - INFO - True
2024-04-06 19:51:29,380 - train - INFO - alphas:tensor([0.5781, 0.0403, 0.0479, 0.1140, 0.2197], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,380 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,380 - train - INFO - True
2024-04-06 19:51:29,381 - train - INFO - alphas:tensor([0.4999, 0.0399, 0.0753, 0.1452, 0.2396], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,381 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,381 - train - INFO - True
2024-04-06 19:51:29,382 - train - INFO - alphas:tensor([0.6617, 0.0424, 0.0563, 0.0915, 0.1481], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,382 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,382 - train - INFO - True
2024-04-06 19:51:29,383 - train - INFO - alphas:tensor([0.7069, 0.0418, 0.0437, 0.0776, 0.1300], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,383 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,383 - train - INFO - True
2024-04-06 19:51:29,384 - train - INFO - alphas:tensor([0.6199, 0.0385, 0.0495, 0.1077, 0.1844], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,384 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,384 - train - INFO - True
2024-04-06 19:51:29,385 - train - INFO - alphas:tensor([0.4743, 0.0375, 0.0760, 0.1506, 0.2615], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,385 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,385 - train - INFO - True
2024-04-06 19:51:29,386 - train - INFO - alphas:tensor([0.6129, 0.0415, 0.0599, 0.1043, 0.1815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,386 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,386 - train - INFO - True
2024-04-06 19:51:29,387 - train - INFO - alphas:tensor([0.6839, 0.0460, 0.0444, 0.0866, 0.1391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,387 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,387 - train - INFO - True
2024-04-06 19:51:29,388 - train - INFO - alphas:tensor([0.6226, 0.0400, 0.0520, 0.1074, 0.1780], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,388 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,388 - train - INFO - True
2024-04-06 19:51:29,389 - train - INFO - alphas:tensor([0.6915, 0.0625, 0.1055, 0.1405], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 19:51:29,389 - train - INFO - tau:0.7397003733882802
2024-04-06 19:51:29,389 - train - INFO - avg block size:1.0
2024-04-06 19:51:29,389 - train - INFO - lasso_alpha:3.7974983358324144e-05
2024-04-06 19:51:29,633 - train - INFO - Test: [   0/78]  Time: 0.240 (0.240)  Loss:  0.9683 (0.9683)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-06 19:51:33,997 - train - INFO - Test: [  50/78]  Time: 0.084 (0.090)  Loss:  1.7588 (1.7016)  Acc@1: 57.0312 (60.3094)  Acc@5: 82.8125 (82.7053)
2024-04-06 19:51:36,318 - train - INFO - Test: [  78/78]  Time: 0.055 (0.088)  Loss:  1.8408 (1.7253)  Acc@1: 50.0000 (59.7200)  Acc@5: 93.7500 (82.3100)
2024-04-06 19:51:37,548 - train - INFO - Train: 33 [   0/781 (  0%)]  Loss:  4.223295 (4.2233)  Time: 1.161s,  110.25/s  (1.161s,  110.25/s)  LR: 4.438e-04  Data: 0.179 (0.179)
2024-04-06 19:52:18,809 - train - INFO - Train: 33 [  50/781 (  6%)]  Loss:  4.552877 (3.9290)  Time: 0.783s,  163.55/s  (0.832s,  153.89/s)  LR: 4.438e-04  Data: 0.005 (0.011)
2024-04-06 19:52:59,086 - train - INFO - Train: 33 [ 100/781 ( 13%)]  Loss:  4.527215 (3.8564)  Time: 0.815s,  157.00/s  (0.819s,  156.33/s)  LR: 4.438e-04  Data: 0.008 (0.009)
2024-04-06 19:53:39,975 - train - INFO - Train: 33 [ 150/781 ( 19%)]  Loss:  4.105544 (3.8778)  Time: 0.788s,  162.42/s  (0.818s,  156.39/s)  LR: 4.438e-04  Data: 0.005 (0.008)
2024-04-06 19:54:20,608 - train - INFO - Train: 33 [ 200/781 ( 26%)]  Loss:  4.208964 (3.8654)  Time: 0.791s,  161.72/s  (0.817s,  156.67/s)  LR: 4.438e-04  Data: 0.006 (0.008)
2024-04-06 19:55:01,405 - train - INFO - Train: 33 [ 250/781 ( 32%)]  Loss:  4.037759 (3.8635)  Time: 0.824s,  155.36/s  (0.817s,  156.71/s)  LR: 4.438e-04  Data: 0.007 (0.007)
2024-04-06 19:55:43,412 - train - INFO - Train: 33 [ 300/781 ( 38%)]  Loss:  3.525227 (3.8594)  Time: 0.828s,  154.55/s  (0.821s,  155.97/s)  LR: 4.438e-04  Data: 0.008 (0.007)
2024-04-06 19:56:25,045 - train - INFO - Train: 33 [ 350/781 ( 45%)]  Loss:  3.740163 (3.8616)  Time: 0.842s,  151.97/s  (0.822s,  155.65/s)  LR: 4.438e-04  Data: 0.008 (0.007)
2024-04-06 19:57:05,772 - train - INFO - Train: 33 [ 400/781 ( 51%)]  Loss:  4.378275 (3.8638)  Time: 0.821s,  155.91/s  (0.821s,  155.83/s)  LR: 4.438e-04  Data: 0.009 (0.007)
2024-04-06 19:57:45,762 - train - INFO - Train: 33 [ 450/781 ( 58%)]  Loss:  4.248934 (3.8658)  Time: 0.784s,  163.37/s  (0.819s,  156.29/s)  LR: 4.438e-04  Data: 0.005 (0.007)
2024-04-06 19:58:26,452 - train - INFO - Train: 33 [ 500/781 ( 64%)]  Loss:  3.568642 (3.8748)  Time: 0.776s,  165.01/s  (0.818s,  156.39/s)  LR: 4.438e-04  Data: 0.006 (0.007)
2024-04-06 19:59:08,068 - train - INFO - Train: 33 [ 550/781 ( 71%)]  Loss:  4.170830 (3.8721)  Time: 0.828s,  154.51/s  (0.820s,  156.15/s)  LR: 4.438e-04  Data: 0.008 (0.007)
2024-04-06 19:59:48,426 - train - INFO - Train: 33 [ 600/781 ( 77%)]  Loss:  3.406495 (3.8773)  Time: 0.786s,  162.80/s  (0.819s,  156.35/s)  LR: 4.438e-04  Data: 0.005 (0.007)
2024-04-06 20:00:30,494 - train - INFO - Train: 33 [ 650/781 ( 83%)]  Loss:  3.427814 (3.8847)  Time: 0.821s,  155.92/s  (0.820s,  156.02/s)  LR: 4.438e-04  Data: 0.009 (0.007)
2024-04-06 20:01:11,564 - train - INFO - Train: 33 [ 700/781 ( 90%)]  Loss:  3.890308 (3.8878)  Time: 0.834s,  153.53/s  (0.820s,  156.01/s)  LR: 4.438e-04  Data: 0.008 (0.007)
2024-04-06 20:01:52,304 - train - INFO - Train: 33 [ 750/781 ( 96%)]  Loss:  4.531568 (3.8943)  Time: 0.831s,  153.96/s  (0.820s,  156.08/s)  LR: 4.438e-04  Data: 0.008 (0.007)
2024-04-06 20:02:17,105 - train - INFO - Train: 33 [ 780/781 (100%)]  Loss:  4.017036 (3.8956)  Time: 0.815s,  157.01/s  (0.820s,  156.03/s)  LR: 4.438e-04  Data: 0.000 (0.007)
2024-04-06 20:02:17,105 - train - INFO - True
2024-04-06 20:02:17,107 - train - INFO - alphas:tensor([0.2442, 0.1272, 0.1599, 0.2198, 0.2488], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,108 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,108 - train - INFO - True
2024-04-06 20:02:17,109 - train - INFO - alphas:tensor([0.3307, 0.0798, 0.0997, 0.1774, 0.3123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,109 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,109 - train - INFO - True
2024-04-06 20:02:17,111 - train - INFO - alphas:tensor([0.7449, 0.0755, 0.0516, 0.0607, 0.0674], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,111 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,111 - train - INFO - True
2024-04-06 20:02:17,112 - train - INFO - alphas:tensor([0.6944, 0.0615, 0.0570, 0.0828, 0.1043], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,113 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,113 - train - INFO - True
2024-04-06 20:02:17,114 - train - INFO - alphas:tensor([0.5112, 0.0669, 0.0902, 0.1379, 0.1938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,114 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,114 - train - INFO - True
2024-04-06 20:02:17,116 - train - INFO - alphas:tensor([0.6525, 0.0663, 0.0635, 0.0929, 0.1248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,116 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,116 - train - INFO - True
2024-04-06 20:02:17,117 - train - INFO - alphas:tensor([0.7725, 0.0584, 0.0402, 0.0563, 0.0726], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,118 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,118 - train - INFO - True
2024-04-06 20:02:17,119 - train - INFO - alphas:tensor([0.7019, 0.0658, 0.0498, 0.0781, 0.1043], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,119 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,119 - train - INFO - True
2024-04-06 20:02:17,120 - train - INFO - alphas:tensor([0.5635, 0.0588, 0.0751, 0.1222, 0.1805], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,121 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,121 - train - INFO - True
2024-04-06 20:02:17,122 - train - INFO - alphas:tensor([0.6831, 0.0595, 0.0592, 0.0824, 0.1159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,122 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,122 - train - INFO - True
2024-04-06 20:02:17,124 - train - INFO - alphas:tensor([0.7188, 0.0541, 0.0482, 0.0740, 0.1049], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,124 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,124 - train - INFO - True
2024-04-06 20:02:17,125 - train - INFO - alphas:tensor([0.6282, 0.0544, 0.0596, 0.1068, 0.1510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,125 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,126 - train - INFO - True
2024-04-06 20:02:17,127 - train - INFO - alphas:tensor([0.5823, 0.0521, 0.0669, 0.1185, 0.1803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,127 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,127 - train - INFO - True
2024-04-06 20:02:17,128 - train - INFO - alphas:tensor([0.6744, 0.0496, 0.0584, 0.0876, 0.1301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,128 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,129 - train - INFO - True
2024-04-06 20:02:17,130 - train - INFO - alphas:tensor([0.6685, 0.0628, 0.0529, 0.0858, 0.1301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,130 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,130 - train - INFO - True
2024-04-06 20:02:17,131 - train - INFO - alphas:tensor([0.5360, 0.0467, 0.0589, 0.1256, 0.2328], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,131 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,131 - train - INFO - True
2024-04-06 20:02:17,133 - train - INFO - alphas:tensor([0.5720, 0.0510, 0.0652, 0.1209, 0.1909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,133 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,133 - train - INFO - True
2024-04-06 20:02:17,134 - train - INFO - alphas:tensor([0.6779, 0.0461, 0.0576, 0.0888, 0.1296], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,134 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,134 - train - INFO - True
2024-04-06 20:02:17,136 - train - INFO - alphas:tensor([0.6815, 0.0534, 0.0505, 0.0851, 0.1296], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,136 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,136 - train - INFO - True
2024-04-06 20:02:17,137 - train - INFO - alphas:tensor([0.5225, 0.0411, 0.0544, 0.1293, 0.2527], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,137 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,137 - train - INFO - True
2024-04-06 20:02:17,139 - train - INFO - alphas:tensor([0.5280, 0.0466, 0.0730, 0.1358, 0.2166], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,139 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,139 - train - INFO - True
2024-04-06 20:02:17,140 - train - INFO - alphas:tensor([0.6949, 0.0447, 0.0543, 0.0821, 0.1240], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,140 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,140 - train - INFO - True
2024-04-06 20:02:17,141 - train - INFO - alphas:tensor([0.7012, 0.0573, 0.0458, 0.0769, 0.1189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,141 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,142 - train - INFO - True
2024-04-06 20:02:17,143 - train - INFO - alphas:tensor([0.5354, 0.0368, 0.0503, 0.1242, 0.2533], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,143 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,143 - train - INFO - True
2024-04-06 20:02:17,144 - train - INFO - alphas:tensor([0.5184, 0.0436, 0.0712, 0.1397, 0.2272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,144 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,144 - train - INFO - True
2024-04-06 20:02:17,146 - train - INFO - alphas:tensor([0.6816, 0.0433, 0.0545, 0.0829, 0.1377], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,146 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,146 - train - INFO - True
2024-04-06 20:02:17,147 - train - INFO - alphas:tensor([0.7065, 0.0439, 0.0441, 0.0778, 0.1277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,147 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,147 - train - INFO - True
2024-04-06 20:02:17,148 - train - INFO - alphas:tensor([0.5615, 0.0388, 0.0471, 0.1165, 0.2360], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,149 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,149 - train - INFO - True
2024-04-06 20:02:17,150 - train - INFO - alphas:tensor([0.4941, 0.0380, 0.0741, 0.1467, 0.2471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,150 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,150 - train - INFO - True
2024-04-06 20:02:17,151 - train - INFO - alphas:tensor([0.6545, 0.0406, 0.0560, 0.0934, 0.1556], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,151 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,151 - train - INFO - True
2024-04-06 20:02:17,152 - train - INFO - alphas:tensor([0.7031, 0.0405, 0.0427, 0.0787, 0.1350], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,153 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,153 - train - INFO - True
2024-04-06 20:02:17,154 - train - INFO - alphas:tensor([0.6082, 0.0370, 0.0487, 0.1103, 0.1959], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,154 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,154 - train - INFO - True
2024-04-06 20:02:17,155 - train - INFO - alphas:tensor([0.4680, 0.0353, 0.0750, 0.1516, 0.2702], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,155 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,155 - train - INFO - True
2024-04-06 20:02:17,156 - train - INFO - alphas:tensor([0.6056, 0.0399, 0.0592, 0.1058, 0.1894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,157 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,157 - train - INFO - True
2024-04-06 20:02:17,158 - train - INFO - alphas:tensor([0.6790, 0.0448, 0.0440, 0.0879, 0.1444], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,158 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,158 - train - INFO - True
2024-04-06 20:02:17,159 - train - INFO - alphas:tensor([0.6131, 0.0384, 0.0508, 0.1099, 0.1878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,159 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,159 - train - INFO - True
2024-04-06 20:02:17,160 - train - INFO - alphas:tensor([0.6933, 0.0613, 0.1048, 0.1407], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:02:17,160 - train - INFO - tau:0.7323033696543974
2024-04-06 20:02:17,161 - train - INFO - avg block size:1.4054054054054055
2024-04-06 20:02:17,406 - train - INFO - Test: [   0/78]  Time: 0.242 (0.242)  Loss:  1.0068 (1.0068)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.9688 (92.9688)
2024-04-06 20:02:21,766 - train - INFO - Test: [  50/78]  Time: 0.084 (0.090)  Loss:  1.8398 (1.7302)  Acc@1: 56.2500 (59.6967)  Acc@5: 82.8125 (82.6287)
2024-04-06 20:02:24,096 - train - INFO - Test: [  78/78]  Time: 0.053 (0.088)  Loss:  2.0859 (1.7513)  Acc@1: 43.7500 (59.2800)  Acc@5: 87.5000 (82.2900)
2024-04-06 20:02:25,406 - train - INFO - Train: 34 [   0/781 (  0%)]  Loss:  4.442851 (4.4429)  Time: 1.251s,  102.32/s  (1.251s,  102.32/s)  LR: 4.405e-04  Data: 0.182 (0.182)
2024-04-06 20:03:06,548 - train - INFO - Train: 34 [  50/781 (  6%)]  Loss:  3.627668 (3.9200)  Time: 1.000s,  127.97/s  (0.831s,  153.99/s)  LR: 4.405e-04  Data: 0.005 (0.010)
2024-04-06 20:03:48,400 - train - INFO - Train: 34 [ 100/781 ( 13%)]  Loss:  4.253258 (3.9443)  Time: 0.793s,  161.33/s  (0.834s,  153.46/s)  LR: 4.405e-04  Data: 0.006 (0.009)
2024-04-06 20:04:30,666 - train - INFO - Train: 34 [ 150/781 ( 19%)]  Loss:  3.919961 (3.9245)  Time: 0.812s,  157.55/s  (0.838s,  152.78/s)  LR: 4.405e-04  Data: 0.007 (0.008)
2024-04-06 20:05:11,549 - train - INFO - Train: 34 [ 200/781 ( 26%)]  Loss:  3.671867 (3.9167)  Time: 0.786s,  162.91/s  (0.833s,  153.70/s)  LR: 4.405e-04  Data: 0.006 (0.008)
2024-04-06 20:05:53,603 - train - INFO - Train: 34 [ 250/781 ( 32%)]  Loss:  3.869217 (3.9169)  Time: 1.076s,  118.90/s  (0.834s,  153.40/s)  LR: 4.405e-04  Data: 0.008 (0.008)
2024-04-06 20:06:34,496 - train - INFO - Train: 34 [ 300/781 ( 38%)]  Loss:  3.315952 (3.9223)  Time: 0.780s,  164.14/s  (0.832s,  153.91/s)  LR: 4.405e-04  Data: 0.005 (0.007)
2024-04-06 20:07:16,888 - train - INFO - Train: 34 [ 350/781 ( 45%)]  Loss:  4.171408 (3.9222)  Time: 0.772s,  165.76/s  (0.834s,  153.48/s)  LR: 4.405e-04  Data: 0.006 (0.007)
2024-04-06 20:07:59,277 - train - INFO - Train: 34 [ 400/781 ( 51%)]  Loss:  3.289860 (3.9199)  Time: 0.812s,  157.57/s  (0.836s,  153.17/s)  LR: 4.405e-04  Data: 0.007 (0.007)
2024-04-06 20:08:42,297 - train - INFO - Train: 34 [ 450/781 ( 58%)]  Loss:  4.049716 (3.9232)  Time: 0.780s,  164.11/s  (0.838s,  152.67/s)  LR: 4.405e-04  Data: 0.006 (0.007)
2024-04-06 20:09:23,611 - train - INFO - Train: 34 [ 500/781 ( 64%)]  Loss:  3.353004 (3.9116)  Time: 0.816s,  156.80/s  (0.837s,  152.89/s)  LR: 4.405e-04  Data: 0.008 (0.007)
2024-04-06 20:10:05,631 - train - INFO - Train: 34 [ 550/781 ( 71%)]  Loss:  4.530088 (3.9120)  Time: 0.813s,  157.52/s  (0.837s,  152.84/s)  LR: 4.405e-04  Data: 0.008 (0.007)
2024-04-06 20:10:46,328 - train - INFO - Train: 34 [ 600/781 ( 77%)]  Loss:  4.277515 (3.9175)  Time: 0.778s,  164.43/s  (0.836s,  153.20/s)  LR: 4.405e-04  Data: 0.005 (0.007)
2024-04-06 20:11:26,942 - train - INFO - Train: 34 [ 650/781 ( 83%)]  Loss:  3.514857 (3.9164)  Time: 0.788s,  162.54/s  (0.834s,  153.53/s)  LR: 4.405e-04  Data: 0.005 (0.007)
2024-04-06 20:12:07,903 - train - INFO - Train: 34 [ 700/781 ( 90%)]  Loss:  3.225001 (3.9184)  Time: 0.796s,  160.73/s  (0.833s,  153.72/s)  LR: 4.405e-04  Data: 0.006 (0.007)
2024-04-06 20:12:50,011 - train - INFO - Train: 34 [ 750/781 ( 96%)]  Loss:  4.356874 (3.9179)  Time: 0.775s,  165.14/s  (0.833s,  153.60/s)  LR: 4.405e-04  Data: 0.005 (0.007)
2024-04-06 20:13:14,932 - train - INFO - Train: 34 [ 780/781 (100%)]  Loss:  4.416288 (3.9222)  Time: 0.824s,  155.26/s  (0.833s,  153.62/s)  LR: 4.405e-04  Data: 0.000 (0.007)
2024-04-06 20:13:14,933 - train - INFO - True
2024-04-06 20:13:14,935 - train - INFO - alphas:tensor([0.2369, 0.1244, 0.1603, 0.2239, 0.2545], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,935 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,935 - train - INFO - True
2024-04-06 20:13:14,937 - train - INFO - alphas:tensor([0.3242, 0.0772, 0.0982, 0.1779, 0.3224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,937 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,937 - train - INFO - True
2024-04-06 20:13:14,939 - train - INFO - alphas:tensor([0.7439, 0.0752, 0.0515, 0.0611, 0.0683], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,939 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,939 - train - INFO - True
2024-04-06 20:13:14,941 - train - INFO - alphas:tensor([0.6908, 0.0606, 0.0573, 0.0841, 0.1071], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,941 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,941 - train - INFO - True
2024-04-06 20:13:14,942 - train - INFO - alphas:tensor([0.5052, 0.0650, 0.0904, 0.1400, 0.1995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,943 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,943 - train - INFO - True
2024-04-06 20:13:14,944 - train - INFO - alphas:tensor([0.6491, 0.0646, 0.0636, 0.0941, 0.1286], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,945 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,945 - train - INFO - True
2024-04-06 20:13:14,946 - train - INFO - alphas:tensor([0.7699, 0.0582, 0.0401, 0.0573, 0.0744], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,946 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,947 - train - INFO - True
2024-04-06 20:13:14,948 - train - INFO - alphas:tensor([0.6935, 0.0652, 0.0503, 0.0807, 0.1104], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,948 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,948 - train - INFO - True
2024-04-06 20:13:14,950 - train - INFO - alphas:tensor([0.5577, 0.0575, 0.0751, 0.1238, 0.1859], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,950 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,950 - train - INFO - True
2024-04-06 20:13:14,951 - train - INFO - alphas:tensor([0.6784, 0.0587, 0.0594, 0.0837, 0.1198], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,951 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,952 - train - INFO - True
2024-04-06 20:13:14,953 - train - INFO - alphas:tensor([0.7143, 0.0531, 0.0481, 0.0755, 0.1089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,953 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,953 - train - INFO - True
2024-04-06 20:13:14,955 - train - INFO - alphas:tensor([0.6209, 0.0526, 0.0589, 0.1092, 0.1584], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,955 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,955 - train - INFO - True
2024-04-06 20:13:14,956 - train - INFO - alphas:tensor([0.5759, 0.0505, 0.0666, 0.1207, 0.1863], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,957 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,957 - train - INFO - True
2024-04-06 20:13:14,958 - train - INFO - alphas:tensor([0.6706, 0.0480, 0.0580, 0.0887, 0.1346], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,958 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,958 - train - INFO - True
2024-04-06 20:13:14,960 - train - INFO - alphas:tensor([0.6623, 0.0612, 0.0526, 0.0878, 0.1361], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,960 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,960 - train - INFO - True
2024-04-06 20:13:14,961 - train - INFO - alphas:tensor([0.5308, 0.0445, 0.0570, 0.1261, 0.2416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,961 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,961 - train - INFO - True
2024-04-06 20:13:14,963 - train - INFO - alphas:tensor([0.5676, 0.0489, 0.0642, 0.1225, 0.1967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,963 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,963 - train - INFO - True
2024-04-06 20:13:14,964 - train - INFO - alphas:tensor([0.6712, 0.0452, 0.0577, 0.0903, 0.1356], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,964 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,965 - train - INFO - True
2024-04-06 20:13:14,966 - train - INFO - alphas:tensor([0.6737, 0.0521, 0.0501, 0.0876, 0.1364], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,966 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,966 - train - INFO - True
2024-04-06 20:13:14,967 - train - INFO - alphas:tensor([0.5142, 0.0393, 0.0524, 0.1298, 0.2644], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,968 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,968 - train - INFO - True
2024-04-06 20:13:14,969 - train - INFO - alphas:tensor([0.5248, 0.0446, 0.0716, 0.1365, 0.2224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,969 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,969 - train - INFO - True
2024-04-06 20:13:14,971 - train - INFO - alphas:tensor([0.6911, 0.0426, 0.0540, 0.0832, 0.1291], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,971 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,971 - train - INFO - True
2024-04-06 20:13:14,972 - train - INFO - alphas:tensor([0.6974, 0.0554, 0.0453, 0.0781, 0.1238], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,972 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,972 - train - INFO - True
2024-04-06 20:13:14,974 - train - INFO - alphas:tensor([0.5287, 0.0348, 0.0482, 0.1246, 0.2637], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,974 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,974 - train - INFO - True
2024-04-06 20:13:14,975 - train - INFO - alphas:tensor([0.5121, 0.0417, 0.0702, 0.1410, 0.2350], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,975 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,975 - train - INFO - True
2024-04-06 20:13:14,976 - train - INFO - alphas:tensor([0.6754, 0.0417, 0.0543, 0.0842, 0.1443], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,977 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,977 - train - INFO - True
2024-04-06 20:13:14,978 - train - INFO - alphas:tensor([0.6996, 0.0425, 0.0437, 0.0799, 0.1343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,978 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,978 - train - INFO - True
2024-04-06 20:13:14,979 - train - INFO - alphas:tensor([0.5511, 0.0366, 0.0456, 0.1182, 0.2485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,980 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,980 - train - INFO - True
2024-04-06 20:13:14,981 - train - INFO - alphas:tensor([0.4864, 0.0363, 0.0730, 0.1483, 0.2560], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,981 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,981 - train - INFO - True
2024-04-06 20:13:14,982 - train - INFO - alphas:tensor([0.6434, 0.0391, 0.0564, 0.0960, 0.1650], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,982 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,982 - train - INFO - True
2024-04-06 20:13:14,984 - train - INFO - alphas:tensor([0.6998, 0.0394, 0.0423, 0.0795, 0.1389], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,984 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,984 - train - INFO - True
2024-04-06 20:13:14,985 - train - INFO - alphas:tensor([0.6030, 0.0347, 0.0470, 0.1112, 0.2041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,985 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,985 - train - INFO - True
2024-04-06 20:13:14,987 - train - INFO - alphas:tensor([0.4638, 0.0339, 0.0733, 0.1519, 0.2772], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,987 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,987 - train - INFO - True
2024-04-06 20:13:14,988 - train - INFO - alphas:tensor([0.5996, 0.0379, 0.0580, 0.1071, 0.1975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,988 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,988 - train - INFO - True
2024-04-06 20:13:14,989 - train - INFO - alphas:tensor([0.6773, 0.0435, 0.0426, 0.0881, 0.1485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,989 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,990 - train - INFO - True
2024-04-06 20:13:14,991 - train - INFO - alphas:tensor([0.6099, 0.0366, 0.0494, 0.1102, 0.1940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,991 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,991 - train - INFO - True
2024-04-06 20:13:14,992 - train - INFO - alphas:tensor([0.6951, 0.0602, 0.1040, 0.1408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:13:14,992 - train - INFO - tau:0.7249803359578534
2024-04-06 20:13:14,992 - train - INFO - avg block size:1.4054054054054055
2024-04-06 20:13:14,992 - train - INFO - lasso_alpha:4.177248169415656e-05
2024-04-06 20:13:15,239 - train - INFO - Test: [   0/78]  Time: 0.243 (0.243)  Loss:  1.0811 (1.0811)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.9688 (92.9688)
2024-04-06 20:13:19,616 - train - INFO - Test: [  50/78]  Time: 0.084 (0.091)  Loss:  1.8359 (1.7209)  Acc@1: 58.5938 (60.0950)  Acc@5: 82.8125 (82.8125)
2024-04-06 20:13:21,955 - train - INFO - Test: [  78/78]  Time: 0.055 (0.088)  Loss:  2.0020 (1.7404)  Acc@1: 50.0000 (59.7200)  Acc@5: 81.2500 (82.5000)
2024-04-06 20:13:23,270 - train - INFO - Train: 35 [   0/781 (  0%)]  Loss:  3.689005 (3.6890)  Time: 1.238s,  103.37/s  (1.238s,  103.37/s)  LR: 4.371e-04  Data: 0.170 (0.170)
2024-04-06 20:14:04,774 - train - INFO - Train: 35 [  50/781 (  6%)]  Loss:  4.486332 (3.9212)  Time: 0.786s,  162.87/s  (0.838s,  152.73/s)  LR: 4.371e-04  Data: 0.005 (0.010)
2024-04-06 20:14:45,092 - train - INFO - Train: 35 [ 100/781 ( 13%)]  Loss:  4.027494 (3.8898)  Time: 0.793s,  161.47/s  (0.822s,  155.65/s)  LR: 4.371e-04  Data: 0.005 (0.008)
2024-04-06 20:15:26,311 - train - INFO - Train: 35 [ 150/781 ( 19%)]  Loss:  4.108622 (3.8993)  Time: 0.811s,  157.92/s  (0.823s,  155.53/s)  LR: 4.371e-04  Data: 0.007 (0.008)
2024-04-06 20:16:07,439 - train - INFO - Train: 35 [ 200/781 ( 26%)]  Loss:  3.882895 (3.8976)  Time: 0.807s,  158.68/s  (0.823s,  155.55/s)  LR: 4.371e-04  Data: 0.007 (0.008)
2024-04-06 20:16:48,280 - train - INFO - Train: 35 [ 250/781 ( 32%)]  Loss:  4.413717 (3.9122)  Time: 0.809s,  158.16/s  (0.822s,  155.78/s)  LR: 4.371e-04  Data: 0.008 (0.008)
2024-04-06 20:17:28,949 - train - INFO - Train: 35 [ 300/781 ( 38%)]  Loss:  4.524999 (3.9259)  Time: 0.819s,  156.29/s  (0.820s,  156.04/s)  LR: 4.371e-04  Data: 0.007 (0.008)
2024-04-06 20:18:09,939 - train - INFO - Train: 35 [ 350/781 ( 45%)]  Loss:  3.238825 (3.9286)  Time: 0.809s,  158.28/s  (0.820s,  156.06/s)  LR: 4.371e-04  Data: 0.007 (0.008)
2024-04-06 20:18:51,403 - train - INFO - Train: 35 [ 400/781 ( 51%)]  Loss:  3.816793 (3.9260)  Time: 0.777s,  164.76/s  (0.821s,  155.84/s)  LR: 4.371e-04  Data: 0.005 (0.008)
2024-04-06 20:19:34,009 - train - INFO - Train: 35 [ 450/781 ( 58%)]  Loss:  4.546014 (3.9298)  Time: 0.822s,  155.63/s  (0.825s,  155.20/s)  LR: 4.371e-04  Data: 0.008 (0.007)
2024-04-06 20:20:16,611 - train - INFO - Train: 35 [ 500/781 ( 64%)]  Loss:  3.798789 (3.9323)  Time: 0.825s,  155.09/s  (0.827s,  154.69/s)  LR: 4.371e-04  Data: 0.008 (0.007)
2024-04-06 20:20:57,917 - train - INFO - Train: 35 [ 550/781 ( 71%)]  Loss:  3.774862 (3.9258)  Time: 0.827s,  154.83/s  (0.827s,  154.71/s)  LR: 4.371e-04  Data: 0.007 (0.008)
2024-04-06 20:21:39,201 - train - INFO - Train: 35 [ 600/781 ( 77%)]  Loss:  4.276698 (3.9261)  Time: 0.825s,  155.16/s  (0.827s,  154.74/s)  LR: 4.371e-04  Data: 0.008 (0.007)
2024-04-06 20:22:20,938 - train - INFO - Train: 35 [ 650/781 ( 83%)]  Loss:  4.539512 (3.9243)  Time: 0.815s,  156.97/s  (0.828s,  154.63/s)  LR: 4.371e-04  Data: 0.008 (0.007)
