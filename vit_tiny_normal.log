2024-04-05 17:33:39,099 - train - INFO - Training with a single process on 1 GPUs.
2024-04-05 17:33:46,346 - train - INFO - Model vit_9_12_64 created, param count:2766144
2024-04-05 17:33:46,375 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-04-05 17:33:46,376 - train - INFO - Scheduled epochs: 160
2024-04-05 17:33:46,640 - train - INFO - Verifying teacher model
2024-04-05 17:33:48,284 - train - INFO - Test: [   0/78]  Time: 1.643 (1.643)  Loss:  0.9009 (0.9009)  Acc@1: 82.0312 (82.0312)  Acc@5: 94.5312 (94.5312)
2024-04-05 17:33:50,380 - train - INFO - Test: [  50/78]  Time: 0.041 (0.073)  Loss:  1.7285 (1.6075)  Acc@1: 58.5938 (63.1127)  Acc@5: 83.5938 (84.9112)
2024-04-05 17:33:51,572 - train - INFO - Test: [  78/78]  Time: 0.056 (0.062)  Loss:  1.8408 (1.6375)  Acc@1: 56.2500 (62.6500)  Acc@5: 75.0000 (84.3200)
2024-04-05 17:33:51,572 - train - INFO - Verifying initial model
2024-04-05 17:33:55,072 - train - INFO - Test: [   0/78]  Time: 3.498 (3.498)  Loss:  5.4375 (5.4375)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
2024-04-05 17:36:30,191 - train - INFO - Test: [  50/78]  Time: 3.067 (3.110)  Loss:  5.2812 (5.2446)  Acc@1:  0.0000 ( 1.1489)  Acc@5:  0.0000 ( 3.8297)
2024-04-05 17:37:45,775 - train - INFO - Test: [  78/78]  Time: 2.503 (2.965)  Loss:  5.1250 (5.2604)  Acc@1:  0.0000 ( 0.9400)  Acc@5:  0.0000 ( 3.5700)
2024-04-05 17:37:50,254 - train - INFO - Train: 0 [   0/781 (  0%)]  Loss:  5.343713 (5.3437)  Time: 4.473s,   28.62/s  (4.473s,   28.62/s)  LR: 1.000e-06  Data: 0.544 (0.544)
2024-04-05 17:40:53,579 - train - INFO - Train: 0 [  50/781 (  6%)]  Loss:  5.311959 (5.3341)  Time: 3.600s,   35.55/s  (3.682s,   34.76/s)  LR: 1.000e-06  Data: 0.009 (0.018)
2024-04-05 17:43:57,619 - train - INFO - Train: 0 [ 100/781 ( 13%)]  Loss:  5.329841 (5.3309)  Time: 3.955s,   32.36/s  (3.682s,   34.77/s)  LR: 1.000e-06  Data: 0.006 (0.013)
2024-04-05 17:47:07,083 - train - INFO - Train: 0 [ 150/781 ( 19%)]  Loss:  5.328735 (5.3300)  Time: 4.297s,   29.79/s  (3.717s,   34.43/s)  LR: 1.000e-06  Data: 0.006 (0.011)
2024-04-05 17:50:18,611 - train - INFO - Train: 0 [ 200/781 ( 26%)]  Loss:  5.351994 (5.3303)  Time: 3.588s,   35.67/s  (3.745s,   34.18/s)  LR: 1.000e-06  Data: 0.005 (0.010)
2024-04-05 17:53:20,700 - train - INFO - Train: 0 [ 250/781 ( 32%)]  Loss:  5.330982 (5.3288)  Time: 3.409s,   37.55/s  (3.725s,   34.36/s)  LR: 1.000e-06  Data: 0.006 (0.009)
2024-04-05 17:56:23,358 - train - INFO - Train: 0 [ 300/781 ( 38%)]  Loss:  5.314970 (5.3279)  Time: 3.388s,   37.78/s  (3.713s,   34.47/s)  LR: 1.000e-06  Data: 0.005 (0.009)
2024-04-05 17:59:30,816 - train - INFO - Train: 0 [ 350/781 ( 45%)]  Loss:  5.309794 (5.3274)  Time: 4.176s,   30.65/s  (3.718s,   34.43/s)  LR: 1.000e-06  Data: 0.006 (0.009)
2024-04-05 18:02:35,595 - train - INFO - Train: 0 [ 400/781 ( 51%)]  Loss:  5.319006 (5.3268)  Time: 3.411s,   37.53/s  (3.715s,   34.45/s)  LR: 1.000e-06  Data: 0.005 (0.009)
2024-04-05 18:05:34,860 - train - INFO - Train: 0 [ 450/781 ( 58%)]  Loss:  5.327834 (5.3261)  Time: 3.343s,   38.29/s  (3.701s,   34.59/s)  LR: 1.000e-06  Data: 0.005 (0.008)
2024-04-05 18:08:37,648 - train - INFO - Train: 0 [ 500/781 ( 64%)]  Loss:  5.309596 (5.3253)  Time: 3.636s,   35.20/s  (3.696s,   34.63/s)  LR: 1.000e-06  Data: 0.005 (0.008)
2024-04-05 18:11:51,259 - train - INFO - Train: 0 [ 550/781 ( 71%)]  Loss:  5.326919 (5.3246)  Time: 4.336s,   29.52/s  (3.712s,   34.48/s)  LR: 1.000e-06  Data: 0.007 (0.008)
2024-04-05 18:14:57,424 - train - INFO - Train: 0 [ 600/781 ( 77%)]  Loss:  5.315762 (5.3239)  Time: 3.655s,   35.02/s  (3.713s,   34.47/s)  LR: 1.000e-06  Data: 0.004 (0.008)
2024-04-05 18:17:59,457 - train - INFO - Train: 0 [ 650/781 ( 83%)]  Loss:  5.320270 (5.3230)  Time: 3.403s,   37.62/s  (3.708s,   34.52/s)  LR: 1.000e-06  Data: 0.004 (0.008)
2024-04-05 18:21:02,098 - train - INFO - Train: 0 [ 700/781 ( 90%)]  Loss:  5.308460 (5.3225)  Time: 3.544s,   36.11/s  (3.704s,   34.56/s)  LR: 1.000e-06  Data: 0.005 (0.008)
2024-04-05 18:24:15,138 - train - INFO - Train: 0 [ 750/781 ( 96%)]  Loss:  5.299200 (5.3217)  Time: 4.280s,   29.91/s  (3.714s,   34.46/s)  LR: 1.000e-06  Data: 0.008 (0.008)
2024-04-05 18:26:06,023 - train - INFO - Train: 0 [ 780/781 (100%)]  Loss:  5.311238 (5.3213)  Time: 3.918s,   32.67/s  (3.713s,   34.47/s)  LR: 1.000e-06  Data: 0.000 (0.008)
2024-04-05 18:26:06,024 - train - INFO - True
2024-04-05 18:26:06,031 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,031 - train - INFO - True
2024-04-05 18:26:06,032 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,033 - train - INFO - True
2024-04-05 18:26:06,035 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,035 - train - INFO - True
2024-04-05 18:26:06,037 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,037 - train - INFO - True
2024-04-05 18:26:06,039 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,039 - train - INFO - True
2024-04-05 18:26:06,040 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,041 - train - INFO - True
2024-04-05 18:26:06,042 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,042 - train - INFO - True
2024-04-05 18:26:06,044 - train - INFO - alphas:tensor([0.2001, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,044 - train - INFO - True
2024-04-05 18:26:06,045 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,045 - train - INFO - True
2024-04-05 18:26:06,047 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,047 - train - INFO - True
2024-04-05 18:26:06,048 - train - INFO - alphas:tensor([0.2001, 0.2001, 0.2000, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,048 - train - INFO - True
2024-04-05 18:26:06,050 - train - INFO - alphas:tensor([0.2001, 0.2001, 0.2000, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,050 - train - INFO - True
2024-04-05 18:26:06,051 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,051 - train - INFO - True
2024-04-05 18:26:06,053 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,053 - train - INFO - True
2024-04-05 18:26:06,054 - train - INFO - alphas:tensor([0.2001, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,054 - train - INFO - True
2024-04-05 18:26:06,056 - train - INFO - alphas:tensor([0.2002, 0.2000, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,056 - train - INFO - True
2024-04-05 18:26:06,057 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,057 - train - INFO - True
2024-04-05 18:26:06,059 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,059 - train - INFO - True
2024-04-05 18:26:06,060 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,060 - train - INFO - True
2024-04-05 18:26:06,061 - train - INFO - alphas:tensor([0.2002, 0.2000, 0.1999, 0.1999, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,062 - train - INFO - True
2024-04-05 18:26:06,063 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,063 - train - INFO - True
2024-04-05 18:26:06,064 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,064 - train - INFO - True
2024-04-05 18:26:06,066 - train - INFO - alphas:tensor([0.2001, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,066 - train - INFO - True
2024-04-05 18:26:06,067 - train - INFO - alphas:tensor([0.2001, 0.1999, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,067 - train - INFO - True
2024-04-05 18:26:06,068 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,069 - train - INFO - True
2024-04-05 18:26:06,070 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.2000, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,070 - train - INFO - True
2024-04-05 18:26:06,071 - train - INFO - alphas:tensor([0.2001, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,071 - train - INFO - True
2024-04-05 18:26:06,072 - train - INFO - alphas:tensor([0.2001, 0.1999, 0.1999, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,073 - train - INFO - True
2024-04-05 18:26:06,074 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,074 - train - INFO - True
2024-04-05 18:26:06,075 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,075 - train - INFO - True
2024-04-05 18:26:06,076 - train - INFO - alphas:tensor([0.1999, 0.1999, 0.2000, 0.2001, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,077 - train - INFO - True
2024-04-05 18:26:06,078 - train - INFO - alphas:tensor([0.1999, 0.2001, 0.2000, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,078 - train - INFO - True
2024-04-05 18:26:06,079 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,079 - train - INFO - True
2024-04-05 18:26:06,080 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,080 - train - INFO - True
2024-04-05 18:26:06,082 - train - INFO - alphas:tensor([0.1999, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,082 - train - INFO - True
2024-04-05 18:26:06,083 - train - INFO - alphas:tensor([0.1999, 0.1999, 0.2000, 0.2001, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,083 - train - INFO - True
2024-04-05 18:26:06,084 - train - INFO - alphas:tensor([0.2501, 0.2499, 0.2499, 0.2501], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 18:26:06,084 - train - INFO - avg block size:1.8108108108108107
2024-04-05 18:26:09,362 - train - INFO - Test: [   0/78]  Time: 3.268 (3.268)  Loss:  5.2500 (5.2500)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
2024-04-05 18:28:24,677 - train - INFO - Test: [  50/78]  Time: 2.436 (2.717)  Loss:  5.2773 (5.2279)  Acc@1:  0.0000 ( 1.1489)  Acc@5:  0.0000 ( 5.1471)
2024-04-05 18:29:40,902 - train - INFO - Test: [  78/78]  Time: 3.062 (2.719)  Loss:  5.0430 (5.2273)  Acc@1:  0.0000 ( 0.9300)  Acc@5:  0.0000 ( 4.7900)
2024-04-05 18:29:44,814 - train - INFO - Train: 1 [   0/781 (  0%)]  Loss:  5.320474 (5.3205)  Time: 3.839s,   33.34/s  (3.839s,   33.34/s)  LR: 5.090e-05  Data: 0.155 (0.155)
2024-04-05 18:32:48,100 - train - INFO - Train: 1 [  50/781 (  6%)]  Loss:  5.275960 (5.2932)  Time: 3.679s,   34.79/s  (3.669s,   34.89/s)  LR: 5.090e-05  Data: 0.007 (0.009)
2024-04-05 18:35:51,834 - train - INFO - Train: 1 [ 100/781 ( 13%)]  Loss:  5.237077 (5.2778)  Time: 4.234s,   30.23/s  (3.672s,   34.86/s)  LR: 5.090e-05  Data: 0.025 (0.008)
2024-04-05 18:39:03,511 - train - INFO - Train: 1 [ 150/781 ( 19%)]  Loss:  5.183336 (5.2632)  Time: 3.362s,   38.07/s  (3.725s,   34.36/s)  LR: 5.090e-05  Data: 0.015 (0.008)
2024-04-05 18:42:03,836 - train - INFO - Train: 1 [ 200/781 ( 26%)]  Loss:  5.224649 (5.2483)  Time: 3.655s,   35.02/s  (3.696s,   34.63/s)  LR: 5.090e-05  Data: 0.005 (0.007)
2024-04-05 18:45:01,858 - train - INFO - Train: 1 [ 250/781 ( 32%)]  Loss:  5.152020 (5.2332)  Time: 3.545s,   36.10/s  (3.669s,   34.89/s)  LR: 5.090e-05  Data: 0.007 (0.007)
2024-04-05 18:48:04,744 - train - INFO - Train: 1 [ 300/781 ( 38%)]  Loss:  5.113232 (5.2172)  Time: 4.253s,   30.09/s  (3.667s,   34.91/s)  LR: 5.090e-05  Data: 0.007 (0.007)
2024-04-05 18:51:18,477 - train - INFO - Train: 1 [ 350/781 ( 45%)]  Loss:  5.110762 (5.2024)  Time: 3.440s,   37.21/s  (3.697s,   34.63/s)  LR: 5.090e-05  Data: 0.005 (0.007)
2024-04-05 18:54:23,474 - train - INFO - Train: 1 [ 400/781 ( 51%)]  Loss:  5.158744 (5.1885)  Time: 3.417s,   37.46/s  (3.697s,   34.62/s)  LR: 5.090e-05  Data: 0.005 (0.007)
2024-04-05 18:57:27,264 - train - INFO - Train: 1 [ 450/781 ( 58%)]  Loss:  5.032472 (5.1752)  Time: 3.901s,   32.82/s  (3.695s,   34.64/s)  LR: 5.090e-05  Data: 0.007 (0.007)
2024-04-05 19:00:33,833 - train - INFO - Train: 1 [ 500/781 ( 64%)]  Loss:  4.994842 (5.1620)  Time: 4.293s,   29.82/s  (3.698s,   34.61/s)  LR: 5.090e-05  Data: 0.005 (0.007)
2024-04-05 19:03:46,407 - train - INFO - Train: 1 [ 550/781 ( 71%)]  Loss:  5.000876 (5.1509)  Time: 3.394s,   37.72/s  (3.712s,   34.48/s)  LR: 5.090e-05  Data: 0.005 (0.007)
2024-04-05 19:06:48,824 - train - INFO - Train: 1 [ 600/781 ( 77%)]  Loss:  4.855768 (5.1406)  Time: 3.516s,   36.41/s  (3.707s,   34.53/s)  LR: 5.090e-05  Data: 0.005 (0.007)
2024-04-05 19:09:52,579 - train - INFO - Train: 1 [ 650/781 ( 83%)]  Loss:  5.186976 (5.1307)  Time: 3.789s,   33.78/s  (3.704s,   34.55/s)  LR: 5.090e-05  Data: 0.017 (0.007)
2024-04-05 19:13:00,678 - train - INFO - Train: 1 [ 700/781 ( 90%)]  Loss:  5.129470 (5.1230)  Time: 4.316s,   29.66/s  (3.709s,   34.52/s)  LR: 5.090e-05  Data: 0.007 (0.007)
2024-04-05 19:16:10,042 - train - INFO - Train: 1 [ 750/781 ( 96%)]  Loss:  5.086231 (5.1145)  Time: 4.252s,   30.11/s  (3.714s,   34.47/s)  LR: 5.090e-05  Data: 0.008 (0.007)
2024-04-05 19:17:58,528 - train - INFO - Train: 1 [ 780/781 (100%)]  Loss:  5.063310 (5.1087)  Time: 3.605s,   35.51/s  (3.710s,   34.50/s)  LR: 5.090e-05  Data: 0.000 (0.007)
2024-04-05 19:17:58,529 - train - INFO - True
2024-04-05 19:17:58,531 - train - INFO - alphas:tensor([0.2129, 0.2133, 0.1916, 0.1912, 0.1910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,531 - train - INFO - True
2024-04-05 19:17:58,532 - train - INFO - alphas:tensor([0.2099, 0.2108, 0.1938, 0.1927, 0.1928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,532 - train - INFO - True
2024-04-05 19:17:58,533 - train - INFO - alphas:tensor([0.2150, 0.2141, 0.1906, 0.1904, 0.1899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,533 - train - INFO - True
2024-04-05 19:17:58,534 - train - INFO - alphas:tensor([0.2121, 0.2110, 0.1938, 0.1917, 0.1913], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,534 - train - INFO - True
2024-04-05 19:17:58,535 - train - INFO - alphas:tensor([0.2147, 0.2149, 0.1907, 0.1900, 0.1897], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,535 - train - INFO - True
2024-04-05 19:17:58,536 - train - INFO - alphas:tensor([0.2150, 0.2142, 0.1910, 0.1900, 0.1899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,536 - train - INFO - True
2024-04-05 19:17:58,537 - train - INFO - alphas:tensor([0.2135, 0.2135, 0.1912, 0.1908, 0.1910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,537 - train - INFO - True
2024-04-05 19:17:58,538 - train - INFO - alphas:tensor([0.2116, 0.2095, 0.1928, 0.1929, 0.1932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,538 - train - INFO - True
2024-04-05 19:17:58,539 - train - INFO - alphas:tensor([0.2132, 0.2126, 0.1916, 0.1913, 0.1913], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,539 - train - INFO - True
2024-04-05 19:17:58,540 - train - INFO - alphas:tensor([0.2118, 0.2101, 0.1932, 0.1926, 0.1923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,540 - train - INFO - True
2024-04-05 19:17:58,541 - train - INFO - alphas:tensor([0.2124, 0.2117, 0.1924, 0.1917, 0.1918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,541 - train - INFO - True
2024-04-05 19:17:58,542 - train - INFO - alphas:tensor([0.2093, 0.2054, 0.1948, 0.1948, 0.1956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,542 - train - INFO - True
2024-04-05 19:17:58,542 - train - INFO - alphas:tensor([0.2125, 0.2124, 0.1920, 0.1915, 0.1915], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,543 - train - INFO - True
2024-04-05 19:17:58,543 - train - INFO - alphas:tensor([0.2116, 0.2104, 0.1923, 0.1929, 0.1929], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,543 - train - INFO - True
2024-04-05 19:17:58,544 - train - INFO - alphas:tensor([0.2127, 0.2112, 0.1926, 0.1917, 0.1917], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,544 - train - INFO - True
2024-04-05 19:17:58,545 - train - INFO - alphas:tensor([0.2065, 0.2051, 0.1969, 0.1956, 0.1958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,545 - train - INFO - True
2024-04-05 19:17:58,546 - train - INFO - alphas:tensor([0.2119, 0.2122, 0.1924, 0.1918, 0.1916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,546 - train - INFO - True
2024-04-05 19:17:58,547 - train - INFO - alphas:tensor([0.2130, 0.2110, 0.1915, 0.1921, 0.1924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,547 - train - INFO - True
2024-04-05 19:17:58,548 - train - INFO - alphas:tensor([0.2087, 0.2085, 0.1966, 0.1936, 0.1926], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,548 - train - INFO - True
2024-04-05 19:17:58,549 - train - INFO - alphas:tensor([0.2053, 0.2035, 0.1972, 0.1967, 0.1974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,549 - train - INFO - True
2024-04-05 19:17:58,550 - train - INFO - alphas:tensor([0.2109, 0.2105, 0.1936, 0.1928, 0.1922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,550 - train - INFO - True
2024-04-05 19:17:58,551 - train - INFO - alphas:tensor([0.2099, 0.2087, 0.1939, 0.1939, 0.1935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,551 - train - INFO - True
2024-04-05 19:17:58,551 - train - INFO - alphas:tensor([0.2084, 0.2072, 0.1949, 0.1944, 0.1951], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,552 - train - INFO - True
2024-04-05 19:17:58,552 - train - INFO - alphas:tensor([0.2012, 0.2013, 0.1987, 0.1991, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,552 - train - INFO - True
2024-04-05 19:17:58,553 - train - INFO - alphas:tensor([0.2133, 0.2128, 0.1920, 0.1912, 0.1907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,553 - train - INFO - True
2024-04-05 19:17:58,554 - train - INFO - alphas:tensor([0.2128, 0.2105, 0.1921, 0.1921, 0.1925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,554 - train - INFO - True
2024-04-05 19:17:58,555 - train - INFO - alphas:tensor([0.2078, 0.2077, 0.1959, 0.1946, 0.1941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,555 - train - INFO - True
2024-04-05 19:17:58,556 - train - INFO - alphas:tensor([0.2038, 0.2021, 0.1975, 0.1975, 0.1991], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,556 - train - INFO - True
2024-04-05 19:17:58,557 - train - INFO - alphas:tensor([0.2122, 0.2110, 0.1927, 0.1920, 0.1921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,557 - train - INFO - True
2024-04-05 19:17:58,558 - train - INFO - alphas:tensor([0.2107, 0.2096, 0.1938, 0.1922, 0.1936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,558 - train - INFO - True
2024-04-05 19:17:58,559 - train - INFO - alphas:tensor([0.2045, 0.2064, 0.1965, 0.1966, 0.1960], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,559 - train - INFO - True
2024-04-05 19:17:58,560 - train - INFO - alphas:tensor([0.2089, 0.2051, 0.1959, 0.1946, 0.1955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,560 - train - INFO - True
2024-04-05 19:17:58,561 - train - INFO - alphas:tensor([0.2097, 0.2097, 0.1938, 0.1935, 0.1933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,561 - train - INFO - True
2024-04-05 19:17:58,562 - train - INFO - alphas:tensor([0.2100, 0.2086, 0.1937, 0.1937, 0.1940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,562 - train - INFO - True
2024-04-05 19:17:58,563 - train - INFO - alphas:tensor([0.2077, 0.2081, 0.1965, 0.1943, 0.1933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,563 - train - INFO - True
2024-04-05 19:17:58,564 - train - INFO - alphas:tensor([0.2077, 0.2063, 0.1958, 0.1950, 0.1952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,564 - train - INFO - True
2024-04-05 19:17:58,565 - train - INFO - alphas:tensor([0.2688, 0.2555, 0.2374, 0.2384], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 19:17:58,565 - train - INFO - avg block size:1.2162162162162162
2024-04-05 19:18:01,098 - train - INFO - Test: [   0/78]  Time: 2.522 (2.522)  Loss:  3.5312 (3.5312)  Acc@1: 38.2812 (38.2812)  Acc@5: 73.4375 (73.4375)
2024-04-05 19:20:14,461 - train - INFO - Test: [  50/78]  Time: 2.953 (2.664)  Loss:  4.2109 (4.3212)  Acc@1: 24.2188 (14.1085)  Acc@5: 45.3125 (34.6814)
2024-04-05 19:21:28,379 - train - INFO - Test: [  78/78]  Time: 2.412 (2.656)  Loss:  4.3672 (4.3033)  Acc@1:  0.0000 (14.6800)  Acc@5: 31.2500 (35.2800)
2024-04-05 19:21:32,015 - train - INFO - Train: 2 [   0/781 (  0%)]  Loss:  5.042167 (5.0422)  Time: 3.563s,   35.92/s  (3.563s,   35.92/s)  LR: 1.008e-04  Data: 0.166 (0.166)
2024-04-05 19:24:29,872 - train - INFO - Train: 2 [  50/781 (  6%)]  Loss:  5.083722 (4.9925)  Time: 3.839s,   33.34/s  (3.557s,   35.98/s)  LR: 1.008e-04  Data: 0.008 (0.010)
2024-04-05 19:27:43,779 - train - INFO - Train: 2 [ 100/781 ( 13%)]  Loss:  5.047905 (4.9861)  Time: 4.007s,   31.94/s  (3.716s,   34.44/s)  LR: 1.008e-04  Data: 0.004 (0.008)
2024-04-05 19:30:44,817 - train - INFO - Train: 2 [ 150/781 ( 19%)]  Loss:  4.946809 (4.9698)  Time: 3.966s,   32.28/s  (3.684s,   34.74/s)  LR: 1.008e-04  Data: 0.008 (0.008)
2024-04-05 19:33:47,435 - train - INFO - Train: 2 [ 200/781 ( 26%)]  Loss:  5.041665 (4.9594)  Time: 3.945s,   32.45/s  (3.676s,   34.82/s)  LR: 1.008e-04  Data: 0.010 (0.007)
2024-04-05 19:36:49,080 - train - INFO - Train: 2 [ 250/781 ( 32%)]  Loss:  5.039705 (4.9539)  Time: 3.868s,   33.09/s  (3.668s,   34.90/s)  LR: 1.008e-04  Data: 0.008 (0.007)
2024-04-05 19:40:05,445 - train - INFO - Train: 2 [ 300/781 ( 38%)]  Loss:  4.800320 (4.9489)  Time: 3.290s,   38.91/s  (3.711s,   34.49/s)  LR: 1.008e-04  Data: 0.006 (0.007)
2024-04-05 19:43:08,608 - train - INFO - Train: 2 [ 350/781 ( 45%)]  Loss:  4.651367 (4.9395)  Time: 3.912s,   32.72/s  (3.704s,   34.56/s)  LR: 1.008e-04  Data: 0.008 (0.007)
2024-04-05 19:46:10,132 - train - INFO - Train: 2 [ 400/781 ( 51%)]  Loss:  4.899050 (4.9356)  Time: 3.370s,   37.99/s  (3.695s,   34.64/s)  LR: 1.008e-04  Data: 0.005 (0.007)
2024-04-05 19:49:13,897 - train - INFO - Train: 2 [ 450/781 ( 58%)]  Loss:  4.670424 (4.9298)  Time: 4.317s,   29.65/s  (3.693s,   34.66/s)  LR: 1.008e-04  Data: 0.005 (0.007)
2024-04-05 19:52:30,174 - train - INFO - Train: 2 [ 500/781 ( 64%)]  Loss:  4.676574 (4.9240)  Time: 3.710s,   34.50/s  (3.716s,   34.45/s)  LR: 1.008e-04  Data: 0.008 (0.007)
2024-04-05 19:55:30,177 - train - INFO - Train: 2 [ 550/781 ( 71%)]  Loss:  4.972477 (4.9207)  Time: 3.378s,   37.89/s  (3.705s,   34.54/s)  LR: 1.008e-04  Data: 0.004 (0.007)
2024-04-05 19:58:29,600 - train - INFO - Train: 2 [ 600/781 ( 77%)]  Loss:  4.911891 (4.9155)  Time: 3.359s,   38.10/s  (3.696s,   34.63/s)  LR: 1.008e-04  Data: 0.005 (0.007)
2024-04-05 20:01:31,168 - train - INFO - Train: 2 [ 650/781 ( 83%)]  Loss:  4.823393 (4.9099)  Time: 4.231s,   30.26/s  (3.691s,   34.68/s)  LR: 1.008e-04  Data: 0.014 (0.007)
2024-04-05 20:04:41,820 - train - INFO - Train: 2 [ 700/781 ( 90%)]  Loss:  4.647996 (4.9033)  Time: 3.492s,   36.66/s  (3.699s,   34.60/s)  LR: 1.008e-04  Data: 0.007 (0.007)
2024-04-05 20:07:40,506 - train - INFO - Train: 2 [ 750/781 ( 96%)]  Loss:  4.925534 (4.8994)  Time: 3.446s,   37.14/s  (3.691s,   34.68/s)  LR: 1.008e-04  Data: 0.005 (0.007)
2024-04-05 20:09:29,158 - train - INFO - Train: 2 [ 780/781 (100%)]  Loss:  4.517355 (4.8962)  Time: 3.347s,   38.24/s  (3.688s,   34.70/s)  LR: 1.008e-04  Data: 0.000 (0.007)
2024-04-05 20:09:29,158 - train - INFO - True
2024-04-05 20:09:29,160 - train - INFO - alphas:tensor([0.2207, 0.2202, 0.1853, 0.1867, 0.1871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,160 - train - INFO - True
2024-04-05 20:09:29,161 - train - INFO - alphas:tensor([0.2213, 0.2193, 0.1849, 0.1865, 0.1880], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,161 - train - INFO - True
2024-04-05 20:09:29,162 - train - INFO - alphas:tensor([0.2437, 0.2362, 0.1730, 0.1733, 0.1739], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,163 - train - INFO - True
2024-04-05 20:09:29,164 - train - INFO - alphas:tensor([0.2374, 0.2283, 0.1789, 0.1772, 0.1782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,164 - train - INFO - True
2024-04-05 20:09:29,165 - train - INFO - alphas:tensor([0.2281, 0.2250, 0.1823, 0.1823, 0.1823], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,165 - train - INFO - True
2024-04-05 20:09:29,166 - train - INFO - alphas:tensor([0.2316, 0.2247, 0.1814, 0.1807, 0.1816], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,166 - train - INFO - True
2024-04-05 20:09:29,167 - train - INFO - alphas:tensor([0.2357, 0.2326, 0.1769, 0.1772, 0.1776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,167 - train - INFO - True
2024-04-05 20:09:29,168 - train - INFO - alphas:tensor([0.2300, 0.2241, 0.1829, 0.1811, 0.1820], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,168 - train - INFO - True
2024-04-05 20:09:29,169 - train - INFO - alphas:tensor([0.2314, 0.2255, 0.1788, 0.1812, 0.1831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,169 - train - INFO - True
2024-04-05 20:09:29,170 - train - INFO - alphas:tensor([0.2292, 0.2209, 0.1833, 0.1827, 0.1840], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,170 - train - INFO - True
2024-04-05 20:09:29,171 - train - INFO - alphas:tensor([0.2318, 0.2281, 0.1798, 0.1797, 0.1805], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,171 - train - INFO - True
2024-04-05 20:09:29,172 - train - INFO - alphas:tensor([0.2254, 0.2142, 0.1863, 0.1860, 0.1882], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,172 - train - INFO - True
2024-04-05 20:09:29,172 - train - INFO - alphas:tensor([0.2257, 0.2221, 0.1831, 0.1840, 0.1852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,173 - train - INFO - True
2024-04-05 20:09:29,173 - train - INFO - alphas:tensor([0.2288, 0.2174, 0.1825, 0.1855, 0.1859], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,174 - train - INFO - True
2024-04-05 20:09:29,174 - train - INFO - alphas:tensor([0.2343, 0.2251, 0.1807, 0.1799, 0.1801], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,175 - train - INFO - True
2024-04-05 20:09:29,175 - train - INFO - alphas:tensor([0.2198, 0.2133, 0.1910, 0.1872, 0.1887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,176 - train - INFO - True
2024-04-05 20:09:29,176 - train - INFO - alphas:tensor([0.2256, 0.2219, 0.1838, 0.1838, 0.1848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,176 - train - INFO - True
2024-04-05 20:09:29,177 - train - INFO - alphas:tensor([0.2300, 0.2211, 0.1822, 0.1826, 0.1840], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,177 - train - INFO - True
2024-04-05 20:09:29,178 - train - INFO - alphas:tensor([0.2283, 0.2235, 0.1866, 0.1809, 0.1808], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,178 - train - INFO - True
2024-04-05 20:09:29,179 - train - INFO - alphas:tensor([0.2165, 0.2092, 0.1910, 0.1905, 0.1928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,179 - train - INFO - True
2024-04-05 20:09:29,180 - train - INFO - alphas:tensor([0.2284, 0.2241, 0.1818, 0.1827, 0.1829], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,180 - train - INFO - True
2024-04-05 20:09:29,181 - train - INFO - alphas:tensor([0.2321, 0.2217, 0.1810, 0.1826, 0.1826], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,181 - train - INFO - True
2024-04-05 20:09:29,181 - train - INFO - alphas:tensor([0.2273, 0.2199, 0.1844, 0.1838, 0.1846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,182 - train - INFO - True
2024-04-05 20:09:29,182 - train - INFO - alphas:tensor([0.2090, 0.2062, 0.1931, 0.1944, 0.1973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,182 - train - INFO - True
2024-04-05 20:09:29,183 - train - INFO - alphas:tensor([0.2305, 0.2263, 0.1801, 0.1812, 0.1820], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,183 - train - INFO - True
2024-04-05 20:09:29,184 - train - INFO - alphas:tensor([0.2340, 0.2227, 0.1802, 0.1808, 0.1823], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,184 - train - INFO - True
2024-04-05 20:09:29,185 - train - INFO - alphas:tensor([0.2322, 0.2260, 0.1819, 0.1802, 0.1796], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,185 - train - INFO - True
2024-04-05 20:09:29,186 - train - INFO - alphas:tensor([0.2162, 0.2094, 0.1911, 0.1907, 0.1927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,186 - train - INFO - True
2024-04-05 20:09:29,187 - train - INFO - alphas:tensor([0.2256, 0.2210, 0.1852, 0.1833, 0.1849], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,187 - train - INFO - True
2024-04-05 20:09:29,187 - train - INFO - alphas:tensor([0.2264, 0.2191, 0.1844, 0.1839, 0.1862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,188 - train - INFO - True
2024-04-05 20:09:29,189 - train - INFO - alphas:tensor([0.2321, 0.2298, 0.1806, 0.1792, 0.1782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,189 - train - INFO - True
2024-04-05 20:09:29,190 - train - INFO - alphas:tensor([0.2214, 0.2137, 0.1893, 0.1875, 0.1881], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,190 - train - INFO - True
2024-04-05 20:09:29,191 - train - INFO - alphas:tensor([0.2207, 0.2198, 0.1857, 0.1867, 0.1872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,191 - train - INFO - True
2024-04-05 20:09:29,192 - train - INFO - alphas:tensor([0.2210, 0.2166, 0.1871, 0.1874, 0.1880], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,192 - train - INFO - True
2024-04-05 20:09:29,193 - train - INFO - alphas:tensor([0.2334, 0.2304, 0.1795, 0.1783, 0.1784], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,193 - train - INFO - True
2024-04-05 20:09:29,194 - train - INFO - alphas:tensor([0.2207, 0.2176, 0.1882, 0.1868, 0.1867], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,194 - train - INFO - True
2024-04-05 20:09:29,195 - train - INFO - alphas:tensor([0.2921, 0.2587, 0.2229, 0.2263], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 20:09:29,195 - train - INFO - avg block size:1.0
2024-04-05 20:09:31,650 - train - INFO - Test: [   0/78]  Time: 2.448 (2.448)  Loss:  3.0234 (3.0234)  Acc@1: 51.5625 (51.5625)  Acc@5: 73.4375 (73.4375)
2024-04-05 20:11:42,844 - train - INFO - Test: [  50/78]  Time: 2.232 (2.620)  Loss:  3.6602 (3.8722)  Acc@1: 29.6875 (21.7525)  Acc@5: 51.5625 (45.3585)
2024-04-05 20:12:57,941 - train - INFO - Test: [  78/78]  Time: 3.049 (2.642)  Loss:  4.1250 (3.8472)  Acc@1:  6.2500 (21.9900)  Acc@5: 31.2500 (45.9500)
2024-04-05 20:13:01,941 - train - INFO - Train: 3 [   0/781 (  0%)]  Loss:  4.866340 (4.8663)  Time: 3.926s,   32.60/s  (3.926s,   32.60/s)  LR: 1.507e-04  Data: 0.119 (0.119)
2024-04-05 20:16:17,828 - train - INFO - Train: 3 [  50/781 (  6%)]  Loss:  4.700443 (4.8269)  Time: 3.414s,   37.49/s  (3.918s,   32.67/s)  LR: 1.507e-04  Data: 0.010 (0.009)
2024-04-05 20:19:20,369 - train - INFO - Train: 3 [ 100/781 ( 13%)]  Loss:  4.592492 (4.8417)  Time: 3.586s,   35.70/s  (3.786s,   33.81/s)  LR: 1.507e-04  Data: 0.009 (0.008)
2024-04-05 20:22:23,860 - train - INFO - Train: 3 [ 150/781 ( 19%)]  Loss:  4.815757 (4.8130)  Time: 3.947s,   32.43/s  (3.747s,   34.16/s)  LR: 1.507e-04  Data: 0.006 (0.008)
2024-04-05 20:25:27,040 - train - INFO - Train: 3 [ 200/781 ( 26%)]  Loss:  4.580596 (4.7927)  Time: 4.104s,   31.19/s  (3.726s,   34.35/s)  LR: 1.507e-04  Data: 0.006 (0.007)
2024-04-05 20:28:44,831 - train - INFO - Train: 3 [ 250/781 ( 32%)]  Loss:  4.824648 (4.7889)  Time: 3.621s,   35.35/s  (3.772s,   33.93/s)  LR: 1.507e-04  Data: 0.004 (0.007)
2024-04-05 20:31:47,273 - train - INFO - Train: 3 [ 300/781 ( 38%)]  Loss:  4.525750 (4.7803)  Time: 3.387s,   37.79/s  (3.752s,   34.12/s)  LR: 1.507e-04  Data: 0.005 (0.007)
2024-04-05 20:34:48,069 - train - INFO - Train: 3 [ 350/781 ( 45%)]  Loss:  4.752741 (4.7737)  Time: 3.397s,   37.68/s  (3.732s,   34.30/s)  LR: 1.507e-04  Data: 0.005 (0.007)
2024-04-05 20:37:48,896 - train - INFO - Train: 3 [ 400/781 ( 51%)]  Loss:  4.779700 (4.7619)  Time: 3.717s,   34.43/s  (3.718s,   34.43/s)  LR: 1.507e-04  Data: 0.008 (0.007)
2024-04-05 20:41:01,760 - train - INFO - Train: 3 [ 450/781 ( 58%)]  Loss:  4.601127 (4.7570)  Time: 3.675s,   34.83/s  (3.733s,   34.29/s)  LR: 1.507e-04  Data: 0.012 (0.007)
2024-04-05 20:44:02,968 - train - INFO - Train: 3 [ 500/781 ( 64%)]  Loss:  4.695688 (4.7461)  Time: 3.831s,   33.41/s  (3.722s,   34.39/s)  LR: 1.507e-04  Data: 0.006 (0.007)
2024-04-05 20:47:00,283 - train - INFO - Train: 3 [ 550/781 ( 71%)]  Loss:  4.460424 (4.7402)  Time: 3.498s,   36.60/s  (3.706s,   34.53/s)  LR: 1.507e-04  Data: 0.007 (0.007)
2024-04-05 20:49:56,640 - train - INFO - Train: 3 [ 600/781 ( 77%)]  Loss:  4.850052 (4.7331)  Time: 3.446s,   37.15/s  (3.692s,   34.67/s)  LR: 1.507e-04  Data: 0.005 (0.007)
2024-04-05 20:53:04,909 - train - INFO - Train: 3 [ 650/781 ( 83%)]  Loss:  4.553679 (4.7266)  Time: 3.703s,   34.57/s  (3.697s,   34.62/s)  LR: 1.507e-04  Data: 0.008 (0.007)
2024-04-05 20:56:04,554 - train - INFO - Train: 3 [ 700/781 ( 90%)]  Loss:  4.901913 (4.7257)  Time: 3.944s,   32.45/s  (3.690s,   34.69/s)  LR: 1.507e-04  Data: 0.005 (0.007)
2024-04-05 20:59:04,730 - train - INFO - Train: 3 [ 750/781 ( 96%)]  Loss:  4.879059 (4.7196)  Time: 3.820s,   33.51/s  (3.684s,   34.74/s)  LR: 1.507e-04  Data: 0.007 (0.007)
2024-04-05 21:00:53,333 - train - INFO - Train: 3 [ 780/781 (100%)]  Loss:  4.781514 (4.7175)  Time: 3.373s,   37.94/s  (3.682s,   34.77/s)  LR: 1.507e-04  Data: 0.000 (0.007)
2024-04-05 21:00:53,336 - train - INFO - True
2024-04-05 21:00:53,337 - train - INFO - alphas:tensor([0.2265, 0.2245, 0.1804, 0.1837, 0.1848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,337 - train - INFO - tau:0.99
2024-04-05 21:00:53,338 - train - INFO - True
2024-04-05 21:00:53,338 - train - INFO - alphas:tensor([0.2310, 0.2245, 0.1766, 0.1826, 0.1852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,339 - train - INFO - tau:0.99
2024-04-05 21:00:53,339 - train - INFO - True
2024-04-05 21:00:53,339 - train - INFO - alphas:tensor([0.2840, 0.2594, 0.1498, 0.1522, 0.1546], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,339 - train - INFO - tau:0.99
2024-04-05 21:00:53,340 - train - INFO - True
2024-04-05 21:00:53,340 - train - INFO - alphas:tensor([0.2762, 0.2463, 0.1583, 0.1586, 0.1606], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,340 - train - INFO - tau:0.99
2024-04-05 21:00:53,340 - train - INFO - True
2024-04-05 21:00:53,341 - train - INFO - alphas:tensor([0.2514, 0.2401, 0.1674, 0.1701, 0.1710], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,341 - train - INFO - tau:0.99
2024-04-05 21:00:53,341 - train - INFO - True
2024-04-05 21:00:53,342 - train - INFO - alphas:tensor([0.2585, 0.2375, 0.1678, 0.1666, 0.1695], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,342 - train - INFO - tau:0.99
2024-04-05 21:00:53,342 - train - INFO - True
2024-04-05 21:00:53,343 - train - INFO - alphas:tensor([0.2679, 0.2549, 0.1576, 0.1592, 0.1603], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,343 - train - INFO - tau:0.99
2024-04-05 21:00:53,343 - train - INFO - True
2024-04-05 21:00:53,344 - train - INFO - alphas:tensor([0.2581, 0.2410, 0.1680, 0.1657, 0.1671], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,344 - train - INFO - tau:0.99
2024-04-05 21:00:53,344 - train - INFO - True
2024-04-05 21:00:53,345 - train - INFO - alphas:tensor([0.2630, 0.2446, 0.1598, 0.1644, 0.1681], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,345 - train - INFO - tau:0.99
2024-04-05 21:00:53,345 - train - INFO - True
2024-04-05 21:00:53,346 - train - INFO - alphas:tensor([0.2603, 0.2347, 0.1682, 0.1671, 0.1698], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,346 - train - INFO - tau:0.99
2024-04-05 21:00:53,346 - train - INFO - True
2024-04-05 21:00:53,347 - train - INFO - alphas:tensor([0.2635, 0.2484, 0.1610, 0.1626, 0.1645], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,347 - train - INFO - tau:0.99
2024-04-05 21:00:53,347 - train - INFO - True
2024-04-05 21:00:53,348 - train - INFO - alphas:tensor([0.2499, 0.2251, 0.1739, 0.1736, 0.1776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,348 - train - INFO - tau:0.99
2024-04-05 21:00:53,348 - train - INFO - True
2024-04-05 21:00:53,349 - train - INFO - alphas:tensor([0.2511, 0.2367, 0.1670, 0.1708, 0.1743], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,349 - train - INFO - tau:0.99
2024-04-05 21:00:53,349 - train - INFO - True
2024-04-05 21:00:53,350 - train - INFO - alphas:tensor([0.2592, 0.2269, 0.1684, 0.1721, 0.1733], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,350 - train - INFO - tau:0.99
2024-04-05 21:00:53,350 - train - INFO - True
2024-04-05 21:00:53,350 - train - INFO - alphas:tensor([0.2654, 0.2412, 0.1648, 0.1639, 0.1648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,351 - train - INFO - tau:0.99
2024-04-05 21:00:53,351 - train - INFO - True
2024-04-05 21:00:53,351 - train - INFO - alphas:tensor([0.2404, 0.2233, 0.1813, 0.1759, 0.1790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,351 - train - INFO - tau:0.99
2024-04-05 21:00:53,352 - train - INFO - True
2024-04-05 21:00:53,352 - train - INFO - alphas:tensor([0.2498, 0.2352, 0.1705, 0.1709, 0.1735], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,352 - train - INFO - tau:0.99
2024-04-05 21:00:53,352 - train - INFO - True
2024-04-05 21:00:53,353 - train - INFO - alphas:tensor([0.2602, 0.2312, 0.1683, 0.1688, 0.1715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,353 - train - INFO - tau:0.99
2024-04-05 21:00:53,353 - train - INFO - True
2024-04-05 21:00:53,354 - train - INFO - alphas:tensor([0.2596, 0.2427, 0.1706, 0.1632, 0.1639], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,354 - train - INFO - tau:0.99
2024-04-05 21:00:53,354 - train - INFO - True
2024-04-05 21:00:53,355 - train - INFO - alphas:tensor([0.2353, 0.2156, 0.1820, 0.1815, 0.1856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,355 - train - INFO - tau:0.99
2024-04-05 21:00:53,355 - train - INFO - True
2024-04-05 21:00:53,356 - train - INFO - alphas:tensor([0.2524, 0.2377, 0.1659, 0.1712, 0.1728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,356 - train - INFO - tau:0.99
2024-04-05 21:00:53,356 - train - INFO - True
2024-04-05 21:00:53,357 - train - INFO - alphas:tensor([0.2684, 0.2316, 0.1641, 0.1678, 0.1681], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,357 - train - INFO - tau:0.99
2024-04-05 21:00:53,357 - train - INFO - True
2024-04-05 21:00:53,358 - train - INFO - alphas:tensor([0.2630, 0.2390, 0.1658, 0.1656, 0.1666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,358 - train - INFO - tau:0.99
2024-04-05 21:00:53,358 - train - INFO - True
2024-04-05 21:00:53,359 - train - INFO - alphas:tensor([0.2258, 0.2138, 0.1840, 0.1855, 0.1909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,359 - train - INFO - tau:0.99
2024-04-05 21:00:53,359 - train - INFO - True
2024-04-05 21:00:53,360 - train - INFO - alphas:tensor([0.2536, 0.2388, 0.1654, 0.1696, 0.1726], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,360 - train - INFO - tau:0.99
2024-04-05 21:00:53,360 - train - INFO - True
2024-04-05 21:00:53,361 - train - INFO - alphas:tensor([0.2663, 0.2329, 0.1649, 0.1665, 0.1694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,361 - train - INFO - tau:0.99
2024-04-05 21:00:53,361 - train - INFO - True
2024-04-05 21:00:53,362 - train - INFO - alphas:tensor([0.2750, 0.2502, 0.1584, 0.1581, 0.1582], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,362 - train - INFO - tau:0.99
2024-04-05 21:00:53,362 - train - INFO - True
2024-04-05 21:00:53,362 - train - INFO - alphas:tensor([0.2434, 0.2221, 0.1779, 0.1776, 0.1790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,363 - train - INFO - tau:0.99
2024-04-05 21:00:53,363 - train - INFO - True
2024-04-05 21:00:53,363 - train - INFO - alphas:tensor([0.2488, 0.2342, 0.1716, 0.1710, 0.1743], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,363 - train - INFO - tau:0.99
2024-04-05 21:00:53,364 - train - INFO - True
2024-04-05 21:00:53,364 - train - INFO - alphas:tensor([0.2555, 0.2319, 0.1695, 0.1695, 0.1735], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,364 - train - INFO - tau:0.99
2024-04-05 21:00:53,364 - train - INFO - True
2024-04-05 21:00:53,365 - train - INFO - alphas:tensor([0.2750, 0.2588, 0.1561, 0.1552, 0.1549], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,365 - train - INFO - tau:0.99
2024-04-05 21:00:53,365 - train - INFO - True
2024-04-05 21:00:53,366 - train - INFO - alphas:tensor([0.2508, 0.2305, 0.1747, 0.1721, 0.1719], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,366 - train - INFO - tau:0.99
2024-04-05 21:00:53,366 - train - INFO - True
2024-04-05 21:00:53,367 - train - INFO - alphas:tensor([0.2391, 0.2346, 0.1724, 0.1761, 0.1778], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,367 - train - INFO - tau:0.99
2024-04-05 21:00:53,367 - train - INFO - True
2024-04-05 21:00:53,368 - train - INFO - alphas:tensor([0.2404, 0.2258, 0.1771, 0.1780, 0.1786], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,368 - train - INFO - tau:0.99
2024-04-05 21:00:53,368 - train - INFO - True
2024-04-05 21:00:53,369 - train - INFO - alphas:tensor([0.2736, 0.2588, 0.1545, 0.1558, 0.1573], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,369 - train - INFO - tau:0.99
2024-04-05 21:00:53,369 - train - INFO - True
2024-04-05 21:00:53,370 - train - INFO - alphas:tensor([0.2519, 0.2394, 0.1700, 0.1693, 0.1694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,370 - train - INFO - tau:0.99
2024-04-05 21:00:53,370 - train - INFO - True
2024-04-05 21:00:53,371 - train - INFO - alphas:tensor([0.3262, 0.2553, 0.2062, 0.2123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:00:53,371 - train - INFO - tau:0.99
2024-04-05 21:00:53,371 - train - INFO - avg block size:1.0
2024-04-05 21:00:55,900 - train - INFO - Test: [   0/78]  Time: 2.522 (2.522)  Loss:  2.3691 (2.3691)  Acc@1: 63.2812 (63.2812)  Acc@5: 80.4688 (80.4688)
2024-04-05 21:03:18,862 - train - INFO - Test: [  50/78]  Time: 3.343 (2.853)  Loss:  3.1289 (3.4310)  Acc@1: 41.4062 (29.5343)  Acc@5: 65.6250 (54.2892)
2024-04-05 21:04:44,431 - train - INFO - Test: [  78/78]  Time: 2.478 (2.925)  Loss:  3.4453 (3.3965)  Acc@1: 12.5000 (29.7700)  Acc@5: 43.7500 (55.2400)
2024-04-05 21:04:48,240 - train - INFO - Train: 4 [   0/781 (  0%)]  Loss:  4.751403 (4.7514)  Time: 3.595s,   35.60/s  (3.595s,   35.60/s)  LR: 2.006e-04  Data: 0.132 (0.132)
2024-04-05 21:08:04,795 - train - INFO - Train: 4 [  50/781 (  6%)]  Loss:  4.852729 (4.6437)  Time: 3.463s,   36.96/s  (3.924s,   32.62/s)  LR: 2.006e-04  Data: 0.005 (0.010)
2024-04-05 21:11:11,416 - train - INFO - Train: 4 [ 100/781 ( 13%)]  Loss:  4.326726 (4.6350)  Time: 4.268s,   29.99/s  (3.829s,   33.43/s)  LR: 2.006e-04  Data: 0.006 (0.008)
2024-04-05 21:14:16,556 - train - INFO - Train: 4 [ 150/781 ( 19%)]  Loss:  4.493389 (4.6336)  Time: 4.005s,   31.96/s  (3.787s,   33.80/s)  LR: 2.006e-04  Data: 0.006 (0.008)
2024-04-05 21:17:34,029 - train - INFO - Train: 4 [ 200/781 ( 26%)]  Loss:  4.538417 (4.6289)  Time: 4.156s,   30.80/s  (3.828s,   33.44/s)  LR: 2.006e-04  Data: 0.009 (0.008)
2024-04-05 21:20:37,223 - train - INFO - Train: 4 [ 250/781 ( 32%)]  Loss:  4.371279 (4.6360)  Time: 3.482s,   36.76/s  (3.795s,   33.73/s)  LR: 2.006e-04  Data: 0.005 (0.007)
2024-04-05 21:23:44,301 - train - INFO - Train: 4 [ 300/781 ( 38%)]  Loss:  4.906854 (4.6322)  Time: 3.472s,   36.87/s  (3.786s,   33.81/s)  LR: 2.006e-04  Data: 0.006 (0.007)
2024-04-05 21:26:51,148 - train - INFO - Train: 4 [ 350/781 ( 45%)]  Loss:  4.884330 (4.6319)  Time: 3.782s,   33.85/s  (3.779s,   33.87/s)  LR: 2.006e-04  Data: 0.007 (0.007)
2024-04-05 21:30:09,346 - train - INFO - Train: 4 [ 400/781 ( 51%)]  Loss:  4.273835 (4.6223)  Time: 3.432s,   37.29/s  (3.802s,   33.66/s)  LR: 2.006e-04  Data: 0.004 (0.007)
2024-04-05 21:33:12,875 - train - INFO - Train: 4 [ 450/781 ( 58%)]  Loss:  4.155287 (4.6138)  Time: 3.777s,   33.89/s  (3.788s,   33.79/s)  LR: 2.006e-04  Data: 0.009 (0.007)
2024-04-05 21:36:18,020 - train - INFO - Train: 4 [ 500/781 ( 64%)]  Loss:  4.588205 (4.6110)  Time: 3.640s,   35.17/s  (3.779s,   33.87/s)  LR: 2.006e-04  Data: 0.009 (0.007)
2024-04-05 21:39:23,786 - train - INFO - Train: 4 [ 550/781 ( 71%)]  Loss:  4.659218 (4.5992)  Time: 3.462s,   36.97/s  (3.773s,   33.92/s)  LR: 2.006e-04  Data: 0.004 (0.007)
2024-04-05 21:42:42,498 - train - INFO - Train: 4 [ 600/781 ( 77%)]  Loss:  4.259295 (4.5907)  Time: 3.873s,   33.05/s  (3.790s,   33.77/s)  LR: 2.006e-04  Data: 0.008 (0.007)
2024-04-05 21:45:49,383 - train - INFO - Train: 4 [ 650/781 ( 83%)]  Loss:  4.556545 (4.5814)  Time: 4.152s,   30.83/s  (3.786s,   33.81/s)  LR: 2.006e-04  Data: 0.009 (0.007)
2024-04-05 21:48:54,234 - train - INFO - Train: 4 [ 700/781 ( 90%)]  Loss:  4.699998 (4.5763)  Time: 3.710s,   34.50/s  (3.780s,   33.87/s)  LR: 2.006e-04  Data: 0.007 (0.007)
2024-04-05 21:51:59,144 - train - INFO - Train: 4 [ 750/781 ( 96%)]  Loss:  4.247348 (4.5702)  Time: 3.465s,   36.94/s  (3.774s,   33.91/s)  LR: 2.006e-04  Data: 0.010 (0.007)
2024-04-05 21:54:02,137 - train - INFO - Train: 4 [ 780/781 (100%)]  Loss:  4.237316 (4.5658)  Time: 3.744s,   34.19/s  (3.787s,   33.80/s)  LR: 2.006e-04  Data: 0.000 (0.007)
2024-04-05 21:54:02,138 - train - INFO - True
2024-04-05 21:54:02,139 - train - INFO - alphas:tensor([0.2333, 0.2292, 0.1747, 0.1805, 0.1824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,139 - train - INFO - tau:0.9801
2024-04-05 21:54:02,139 - train - INFO - True
2024-04-05 21:54:02,140 - train - INFO - alphas:tensor([0.2422, 0.2286, 0.1684, 0.1783, 0.1824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,140 - train - INFO - tau:0.9801
2024-04-05 21:54:02,140 - train - INFO - True
2024-04-05 21:54:02,141 - train - INFO - alphas:tensor([0.3368, 0.2726, 0.1264, 0.1301, 0.1340], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,141 - train - INFO - tau:0.9801
2024-04-05 21:54:02,141 - train - INFO - True
2024-04-05 21:54:02,142 - train - INFO - alphas:tensor([0.3301, 0.2531, 0.1364, 0.1387, 0.1417], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,142 - train - INFO - tau:0.9801
2024-04-05 21:54:02,142 - train - INFO - True
2024-04-05 21:54:02,143 - train - INFO - alphas:tensor([0.2856, 0.2563, 0.1480, 0.1537, 0.1564], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,143 - train - INFO - tau:0.9801
2024-04-05 21:54:02,143 - train - INFO - True
2024-04-05 21:54:02,144 - train - INFO - alphas:tensor([0.2975, 0.2465, 0.1497, 0.1504, 0.1558], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,144 - train - INFO - tau:0.9801
2024-04-05 21:54:02,144 - train - INFO - True
2024-04-05 21:54:02,145 - train - INFO - alphas:tensor([0.3129, 0.2710, 0.1361, 0.1390, 0.1410], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,145 - train - INFO - tau:0.9801
2024-04-05 21:54:02,145 - train - INFO - True
2024-04-05 21:54:02,146 - train - INFO - alphas:tensor([0.2994, 0.2555, 0.1477, 0.1477, 0.1497], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,146 - train - INFO - tau:0.9801
2024-04-05 21:54:02,146 - train - INFO - True
2024-04-05 21:54:02,147 - train - INFO - alphas:tensor([0.3107, 0.2618, 0.1364, 0.1430, 0.1480], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,147 - train - INFO - tau:0.9801
2024-04-05 21:54:02,147 - train - INFO - True
2024-04-05 21:54:02,147 - train - INFO - alphas:tensor([0.3123, 0.2455, 0.1456, 0.1463, 0.1503], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,148 - train - INFO - tau:0.9801
2024-04-05 21:54:02,148 - train - INFO - True
2024-04-05 21:54:02,148 - train - INFO - alphas:tensor([0.3119, 0.2656, 0.1376, 0.1410, 0.1439], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,148 - train - INFO - tau:0.9801
2024-04-05 21:54:02,149 - train - INFO - True
2024-04-05 21:54:02,149 - train - INFO - alphas:tensor([0.2896, 0.2375, 0.1552, 0.1558, 0.1618], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,149 - train - INFO - tau:0.9801
2024-04-05 21:54:02,150 - train - INFO - True
2024-04-05 21:54:02,150 - train - INFO - alphas:tensor([0.2989, 0.2574, 0.1415, 0.1481, 0.1540], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,150 - train - INFO - tau:0.9801
2024-04-05 21:54:02,150 - train - INFO - True
2024-04-05 21:54:02,151 - train - INFO - alphas:tensor([0.3152, 0.2340, 0.1466, 0.1511, 0.1530], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,154 - train - INFO - tau:0.9801
2024-04-05 21:54:02,154 - train - INFO - True
2024-04-05 21:54:02,155 - train - INFO - alphas:tensor([0.3117, 0.2543, 0.1443, 0.1438, 0.1459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,155 - train - INFO - tau:0.9801
2024-04-05 21:54:02,155 - train - INFO - True
2024-04-05 21:54:02,156 - train - INFO - alphas:tensor([0.2728, 0.2340, 0.1664, 0.1607, 0.1661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,156 - train - INFO - tau:0.9801
2024-04-05 21:54:02,156 - train - INFO - True
2024-04-05 21:54:02,157 - train - INFO - alphas:tensor([0.2921, 0.2508, 0.1501, 0.1513, 0.1557], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,157 - train - INFO - tau:0.9801
2024-04-05 21:54:02,157 - train - INFO - True
2024-04-05 21:54:02,158 - train - INFO - alphas:tensor([0.3113, 0.2357, 0.1492, 0.1500, 0.1538], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,158 - train - INFO - tau:0.9801
2024-04-05 21:54:02,158 - train - INFO - True
2024-04-05 21:54:02,159 - train - INFO - alphas:tensor([0.3085, 0.2592, 0.1479, 0.1414, 0.1429], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,159 - train - INFO - tau:0.9801
2024-04-05 21:54:02,159 - train - INFO - True
2024-04-05 21:54:02,160 - train - INFO - alphas:tensor([0.2670, 0.2241, 0.1678, 0.1675, 0.1736], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,160 - train - INFO - tau:0.9801
2024-04-05 21:54:02,160 - train - INFO - True
2024-04-05 21:54:02,160 - train - INFO - alphas:tensor([0.2865, 0.2486, 0.1476, 0.1568, 0.1604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,161 - train - INFO - tau:0.9801
2024-04-05 21:54:02,161 - train - INFO - True
2024-04-05 21:54:02,161 - train - INFO - alphas:tensor([0.3215, 0.2316, 0.1448, 0.1507, 0.1515], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,161 - train - INFO - tau:0.9801
2024-04-05 21:54:02,162 - train - INFO - True
2024-04-05 21:54:02,162 - train - INFO - alphas:tensor([0.3150, 0.2547, 0.1426, 0.1431, 0.1447], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,162 - train - INFO - tau:0.9801
2024-04-05 21:54:02,162 - train - INFO - True
2024-04-05 21:54:02,163 - train - INFO - alphas:tensor([0.2557, 0.2227, 0.1703, 0.1720, 0.1793], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,163 - train - INFO - tau:0.9801
2024-04-05 21:54:02,163 - train - INFO - True
2024-04-05 21:54:02,164 - train - INFO - alphas:tensor([0.2868, 0.2481, 0.1478, 0.1561, 0.1612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,164 - train - INFO - tau:0.9801
2024-04-05 21:54:02,164 - train - INFO - True
2024-04-05 21:54:02,165 - train - INFO - alphas:tensor([0.3124, 0.2357, 0.1476, 0.1502, 0.1541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,165 - train - INFO - tau:0.9801
2024-04-05 21:54:02,165 - train - INFO - True
2024-04-05 21:54:02,166 - train - INFO - alphas:tensor([0.3315, 0.2643, 0.1329, 0.1350, 0.1363], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,166 - train - INFO - tau:0.9801
2024-04-05 21:54:02,166 - train - INFO - True
2024-04-05 21:54:02,167 - train - INFO - alphas:tensor([0.2860, 0.2321, 0.1594, 0.1608, 0.1618], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,167 - train - INFO - tau:0.9801
2024-04-05 21:54:02,167 - train - INFO - True
2024-04-05 21:54:02,168 - train - INFO - alphas:tensor([0.2806, 0.2455, 0.1541, 0.1571, 0.1627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,168 - train - INFO - tau:0.9801
2024-04-05 21:54:02,168 - train - INFO - True
2024-04-05 21:54:02,169 - train - INFO - alphas:tensor([0.3006, 0.2397, 0.1502, 0.1519, 0.1576], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,169 - train - INFO - tau:0.9801
2024-04-05 21:54:02,169 - train - INFO - True
2024-04-05 21:54:02,170 - train - INFO - alphas:tensor([0.3291, 0.2731, 0.1317, 0.1327, 0.1334], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,170 - train - INFO - tau:0.9801
2024-04-05 21:54:02,170 - train - INFO - True
2024-04-05 21:54:02,171 - train - INFO - alphas:tensor([0.2951, 0.2460, 0.1544, 0.1524, 0.1522], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,171 - train - INFO - tau:0.9801
2024-04-05 21:54:02,171 - train - INFO - True
2024-04-05 21:54:02,172 - train - INFO - alphas:tensor([0.2662, 0.2490, 0.1553, 0.1630, 0.1666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,172 - train - INFO - tau:0.9801
2024-04-05 21:54:02,172 - train - INFO - True
2024-04-05 21:54:02,172 - train - INFO - alphas:tensor([0.2740, 0.2360, 0.1615, 0.1635, 0.1651], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,173 - train - INFO - tau:0.9801
2024-04-05 21:54:02,173 - train - INFO - True
2024-04-05 21:54:02,173 - train - INFO - alphas:tensor([0.3236, 0.2719, 0.1311, 0.1350, 0.1384], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,174 - train - INFO - tau:0.9801
2024-04-05 21:54:02,174 - train - INFO - True
2024-04-05 21:54:02,174 - train - INFO - alphas:tensor([0.2958, 0.2548, 0.1483, 0.1499, 0.1512], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,174 - train - INFO - tau:0.9801
2024-04-05 21:54:02,175 - train - INFO - True
2024-04-05 21:54:02,175 - train - INFO - alphas:tensor([0.3715, 0.2373, 0.1909, 0.2003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 21:54:02,175 - train - INFO - tau:0.9801
2024-04-05 21:54:02,175 - train - INFO - avg block size:1.0
2024-04-05 21:54:04,758 - train - INFO - Test: [   0/78]  Time: 2.575 (2.575)  Loss:  2.0957 (2.0957)  Acc@1: 57.0312 (57.0312)  Acc@5: 78.9062 (78.9062)
2024-04-05 21:56:19,870 - train - INFO - Test: [  50/78]  Time: 2.678 (2.700)  Loss:  2.6660 (2.9427)  Acc@1: 42.9688 (36.7341)  Acc@5: 72.6562 (63.9553)
2024-04-05 21:57:35,219 - train - INFO - Test: [  78/78]  Time: 2.631 (2.697)  Loss:  3.2344 (2.9310)  Acc@1: 25.0000 (37.0000)  Acc@5: 43.7500 (64.4800)
2024-04-05 21:57:38,784 - train - INFO - Train: 5 [   0/781 (  0%)]  Loss:  4.063563 (4.0636)  Time: 3.483s,   36.75/s  (3.483s,   36.75/s)  LR: 2.505e-04  Data: 0.144 (0.144)
2024-04-05 22:00:42,590 - train - INFO - Train: 5 [  50/781 (  6%)]  Loss:  4.715471 (4.4941)  Time: 3.417s,   37.46/s  (3.672s,   34.86/s)  LR: 2.505e-04  Data: 0.005 (0.009)
2024-04-05 22:03:48,038 - train - INFO - Train: 5 [ 100/781 ( 13%)]  Loss:  4.284019 (4.4784)  Time: 4.178s,   30.64/s  (3.690s,   34.68/s)  LR: 2.505e-04  Data: 0.008 (0.007)
2024-04-05 22:07:07,079 - train - INFO - Train: 5 [ 150/781 ( 19%)]  Loss:  4.231083 (4.4432)  Time: 3.848s,   33.26/s  (3.787s,   33.80/s)  LR: 2.505e-04  Data: 0.005 (0.007)
2024-04-05 22:10:12,768 - train - INFO - Train: 5 [ 200/781 ( 26%)]  Loss:  4.319579 (4.4419)  Time: 4.169s,   30.70/s  (3.768s,   33.97/s)  LR: 2.505e-04  Data: 0.010 (0.007)
2024-04-05 22:13:13,177 - train - INFO - Train: 5 [ 250/781 ( 32%)]  Loss:  4.684003 (4.4290)  Time: 3.558s,   35.97/s  (3.737s,   34.26/s)  LR: 2.505e-04  Data: 0.004 (0.007)
2024-04-05 22:16:09,809 - train - INFO - Train: 5 [ 300/781 ( 38%)]  Loss:  4.493036 (4.4080)  Time: 3.794s,   33.74/s  (3.703s,   34.57/s)  LR: 2.505e-04  Data: 0.008 (0.007)
2024-04-05 22:19:13,699 - train - INFO - Train: 5 [ 350/781 ( 45%)]  Loss:  4.382710 (4.3931)  Time: 3.387s,   37.79/s  (3.699s,   34.60/s)  LR: 2.505e-04  Data: 0.005 (0.007)
2024-04-05 22:22:06,084 - train - INFO - Train: 5 [ 400/781 ( 51%)]  Loss:  4.614661 (4.3872)  Time: 3.399s,   37.65/s  (3.668s,   34.90/s)  LR: 2.505e-04  Data: 0.007 (0.007)
2024-04-05 22:24:59,340 - train - INFO - Train: 5 [ 450/781 ( 58%)]  Loss:  4.470260 (4.3831)  Time: 3.495s,   36.62/s  (3.645s,   35.11/s)  LR: 2.505e-04  Data: 0.010 (0.007)
2024-04-05 22:27:52,518 - train - INFO - Train: 5 [ 500/781 ( 64%)]  Loss:  4.134480 (4.3691)  Time: 3.273s,   39.11/s  (3.627s,   35.29/s)  LR: 2.505e-04  Data: 0.006 (0.007)
2024-04-05 22:31:00,566 - train - INFO - Train: 5 [ 550/781 ( 71%)]  Loss:  3.721717 (4.3594)  Time: 3.332s,   38.41/s  (3.639s,   35.17/s)  LR: 2.505e-04  Data: 0.005 (0.007)
2024-04-05 22:33:57,497 - train - INFO - Train: 5 [ 600/781 ( 77%)]  Loss:  4.431838 (4.3522)  Time: 3.657s,   35.00/s  (3.631s,   35.25/s)  LR: 2.505e-04  Data: 0.008 (0.007)
2024-04-05 22:36:54,540 - train - INFO - Train: 5 [ 650/781 ( 83%)]  Loss:  3.676489 (4.3431)  Time: 3.462s,   36.97/s  (3.624s,   35.32/s)  LR: 2.505e-04  Data: 0.007 (0.007)
2024-04-05 22:39:56,798 - train - INFO - Train: 5 [ 700/781 ( 90%)]  Loss:  4.244102 (4.3365)  Time: 3.908s,   32.75/s  (3.625s,   35.31/s)  LR: 2.505e-04  Data: 0.010 (0.007)
2024-04-05 22:43:09,716 - train - INFO - Train: 5 [ 750/781 ( 96%)]  Loss:  4.235622 (4.3295)  Time: 3.663s,   34.94/s  (3.641s,   35.16/s)  LR: 2.505e-04  Data: 0.010 (0.007)
2024-04-05 22:44:58,189 - train - INFO - Train: 5 [ 780/781 (100%)]  Loss:  4.502498 (4.3284)  Time: 3.378s,   37.89/s  (3.640s,   35.16/s)  LR: 2.505e-04  Data: 0.000 (0.007)
2024-04-05 22:44:58,190 - train - INFO - True
2024-04-05 22:44:58,192 - train - INFO - alphas:tensor([0.2434, 0.2360, 0.1662, 0.1756, 0.1788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,192 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,192 - train - INFO - True
2024-04-05 22:44:58,193 - train - INFO - alphas:tensor([0.2573, 0.2316, 0.1591, 0.1728, 0.1792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,194 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,194 - train - INFO - True
2024-04-05 22:44:58,195 - train - INFO - alphas:tensor([0.4021, 0.2601, 0.1077, 0.1126, 0.1175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,195 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,195 - train - INFO - True
2024-04-05 22:44:58,196 - train - INFO - alphas:tensor([0.3973, 0.2374, 0.1168, 0.1221, 0.1264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,196 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,196 - train - INFO - True
2024-04-05 22:44:58,197 - train - INFO - alphas:tensor([0.3344, 0.2612, 0.1273, 0.1363, 0.1408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,197 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,198 - train - INFO - True
2024-04-05 22:44:58,199 - train - INFO - alphas:tensor([0.3561, 0.2409, 0.1290, 0.1331, 0.1408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,199 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,199 - train - INFO - True
2024-04-05 22:44:58,200 - train - INFO - alphas:tensor([0.3790, 0.2670, 0.1144, 0.1182, 0.1215], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,200 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,200 - train - INFO - True
2024-04-05 22:44:58,201 - train - INFO - alphas:tensor([0.3611, 0.2558, 0.1251, 0.1276, 0.1304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,201 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,201 - train - INFO - True
2024-04-05 22:44:58,202 - train - INFO - alphas:tensor([0.3717, 0.2542, 0.1164, 0.1257, 0.1320], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,202 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,203 - train - INFO - True
2024-04-05 22:44:58,204 - train - INFO - alphas:tensor([0.3865, 0.2348, 0.1221, 0.1255, 0.1310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,204 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,204 - train - INFO - True
2024-04-05 22:44:58,205 - train - INFO - alphas:tensor([0.3909, 0.2610, 0.1119, 0.1165, 0.1198], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,205 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,205 - train - INFO - True
2024-04-05 22:44:58,206 - train - INFO - alphas:tensor([0.3584, 0.2423, 0.1294, 0.1312, 0.1387], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,206 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,206 - train - INFO - True
2024-04-05 22:44:58,207 - train - INFO - alphas:tensor([0.3695, 0.2549, 0.1168, 0.1255, 0.1332], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,207 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,207 - train - INFO - True
2024-04-05 22:44:58,208 - train - INFO - alphas:tensor([0.4032, 0.2207, 0.1213, 0.1261, 0.1287], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,209 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,209 - train - INFO - True
2024-04-05 22:44:58,210 - train - INFO - alphas:tensor([0.3894, 0.2501, 0.1186, 0.1196, 0.1224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,210 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,210 - train - INFO - True
2024-04-05 22:44:58,211 - train - INFO - alphas:tensor([0.3305, 0.2410, 0.1438, 0.1389, 0.1457], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,211 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,211 - train - INFO - True
2024-04-05 22:44:58,212 - train - INFO - alphas:tensor([0.3597, 0.2531, 0.1249, 0.1282, 0.1341], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,212 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,212 - train - INFO - True
2024-04-05 22:44:58,213 - train - INFO - alphas:tensor([0.3912, 0.2240, 0.1254, 0.1274, 0.1321], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,213 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,213 - train - INFO - True
2024-04-05 22:44:58,214 - train - INFO - alphas:tensor([0.3894, 0.2541, 0.1213, 0.1166, 0.1186], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,215 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,215 - train - INFO - True
2024-04-05 22:44:58,216 - train - INFO - alphas:tensor([0.3253, 0.2298, 0.1462, 0.1459, 0.1528], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,216 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,216 - train - INFO - True
2024-04-05 22:44:58,217 - train - INFO - alphas:tensor([0.3398, 0.2508, 0.1267, 0.1384, 0.1443], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,217 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,217 - train - INFO - True
2024-04-05 22:44:58,218 - train - INFO - alphas:tensor([0.3978, 0.2160, 0.1234, 0.1306, 0.1322], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,218 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,218 - train - INFO - True
2024-04-05 22:44:58,219 - train - INFO - alphas:tensor([0.3980, 0.2482, 0.1160, 0.1177, 0.1200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,219 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,219 - train - INFO - True
2024-04-05 22:44:58,220 - train - INFO - alphas:tensor([0.3115, 0.2272, 0.1495, 0.1520, 0.1598], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,220 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,221 - train - INFO - True
2024-04-05 22:44:58,221 - train - INFO - alphas:tensor([0.3397, 0.2489, 0.1267, 0.1390, 0.1457], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,222 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,222 - train - INFO - True
2024-04-05 22:44:58,223 - train - INFO - alphas:tensor([0.3848, 0.2217, 0.1273, 0.1306, 0.1356], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,223 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,223 - train - INFO - True
2024-04-05 22:44:58,224 - train - INFO - alphas:tensor([0.4186, 0.2447, 0.1089, 0.1128, 0.1150], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,224 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,224 - train - INFO - True
2024-04-05 22:44:58,225 - train - INFO - alphas:tensor([0.3524, 0.2338, 0.1358, 0.1385, 0.1395], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,225 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,225 - train - INFO - True
2024-04-05 22:44:58,226 - train - INFO - alphas:tensor([0.3279, 0.2485, 0.1336, 0.1409, 0.1491], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,226 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,226 - train - INFO - True
2024-04-05 22:44:58,227 - train - INFO - alphas:tensor([0.3718, 0.2286, 0.1282, 0.1322, 0.1392], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,227 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,227 - train - INFO - True
2024-04-05 22:44:58,228 - train - INFO - alphas:tensor([0.4109, 0.2509, 0.1108, 0.1129, 0.1145], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,228 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,228 - train - INFO - True
2024-04-05 22:44:58,229 - train - INFO - alphas:tensor([0.3648, 0.2424, 0.1310, 0.1307, 0.1312], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,229 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,230 - train - INFO - True
2024-04-05 22:44:58,230 - train - INFO - alphas:tensor([0.3082, 0.2596, 0.1335, 0.1464, 0.1522], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,231 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,231 - train - INFO - True
2024-04-05 22:44:58,232 - train - INFO - alphas:tensor([0.3319, 0.2372, 0.1404, 0.1440, 0.1464], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,232 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,232 - train - INFO - True
2024-04-05 22:44:58,233 - train - INFO - alphas:tensor([0.4024, 0.2513, 0.1097, 0.1160, 0.1206], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,233 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,233 - train - INFO - True
2024-04-05 22:44:58,234 - train - INFO - alphas:tensor([0.3624, 0.2505, 0.1257, 0.1293, 0.1321], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,234 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,234 - train - INFO - True
2024-04-05 22:44:58,235 - train - INFO - alphas:tensor([0.4321, 0.2052, 0.1751, 0.1876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 22:44:58,235 - train - INFO - tau:0.9702989999999999
2024-04-05 22:44:58,235 - train - INFO - avg block size:1.0
2024-04-05 22:45:01,308 - train - INFO - Test: [   0/78]  Time: 3.063 (3.063)  Loss:  1.4092 (1.4092)  Acc@1: 71.8750 (71.8750)  Acc@5: 86.7188 (86.7188)
2024-04-05 22:47:17,648 - train - INFO - Test: [  50/78]  Time: 2.826 (2.733)  Loss:  2.3535 (2.4175)  Acc@1: 49.2188 (46.8597)  Acc@5: 75.7812 (73.3303)
2024-04-05 22:48:34,025 - train - INFO - Test: [  78/78]  Time: 3.064 (2.731)  Loss:  2.3008 (2.4508)  Acc@1: 37.5000 (45.9000)  Acc@5: 93.7500 (72.6600)
2024-04-05 22:48:38,265 - train - INFO - Train: 6 [   0/781 (  0%)]  Loss:  4.021817 (4.0218)  Time: 4.154s,   30.82/s  (4.154s,   30.82/s)  LR: 3.004e-04  Data: 0.177 (0.177)
2024-04-05 22:51:40,553 - train - INFO - Train: 6 [  50/781 (  6%)]  Loss:  4.422279 (4.1533)  Time: 4.041s,   31.68/s  (3.656s,   35.01/s)  LR: 3.004e-04  Data: 0.004 (0.010)
2024-04-05 22:54:57,912 - train - INFO - Train: 6 [ 100/781 ( 13%)]  Loss:  4.502256 (4.1654)  Time: 3.527s,   36.29/s  (3.800s,   33.68/s)  LR: 3.004e-04  Data: 0.014 (0.008)
2024-04-05 22:58:00,417 - train - INFO - Train: 6 [ 150/781 ( 19%)]  Loss:  4.472070 (4.2164)  Time: 4.006s,   31.95/s  (3.750s,   34.13/s)  LR: 3.004e-04  Data: 0.004 (0.008)
2024-04-05 23:01:02,318 - train - INFO - Train: 6 [ 200/781 ( 26%)]  Loss:  3.812619 (4.2234)  Time: 3.359s,   38.11/s  (3.722s,   34.39/s)  LR: 3.004e-04  Data: 0.011 (0.008)
2024-04-05 23:04:01,003 - train - INFO - Train: 6 [ 250/781 ( 32%)]  Loss:  3.783956 (4.2018)  Time: 3.773s,   33.93/s  (3.693s,   34.66/s)  LR: 3.004e-04  Data: 0.012 (0.008)
2024-04-05 23:07:12,391 - train - INFO - Train: 6 [ 300/781 ( 38%)]  Loss:  4.240291 (4.1910)  Time: 3.313s,   38.64/s  (3.715s,   34.45/s)  LR: 3.004e-04  Data: 0.007 (0.007)
2024-04-05 23:10:10,774 - train - INFO - Train: 6 [ 350/781 ( 45%)]  Loss:  3.547907 (4.1833)  Time: 3.394s,   37.71/s  (3.694s,   34.65/s)  LR: 3.004e-04  Data: 0.017 (0.007)
2024-04-05 23:13:11,073 - train - INFO - Train: 6 [ 400/781 ( 51%)]  Loss:  3.995788 (4.1825)  Time: 3.676s,   34.82/s  (3.683s,   34.75/s)  LR: 3.004e-04  Data: 0.010 (0.007)
2024-04-05 23:16:11,319 - train - INFO - Train: 6 [ 450/781 ( 58%)]  Loss:  4.108856 (4.1793)  Time: 3.410s,   37.54/s  (3.674s,   34.84/s)  LR: 3.004e-04  Data: 0.006 (0.007)
2024-04-05 23:19:23,310 - train - INFO - Train: 6 [ 500/781 ( 64%)]  Loss:  4.358173 (4.1675)  Time: 3.593s,   35.62/s  (3.691s,   34.68/s)  LR: 3.004e-04  Data: 0.007 (0.007)
2024-04-05 23:22:23,964 - train - INFO - Train: 6 [ 550/781 ( 71%)]  Loss:  3.353055 (4.1572)  Time: 3.376s,   37.91/s  (3.684s,   34.75/s)  LR: 3.004e-04  Data: 0.005 (0.007)
2024-04-05 23:25:28,679 - train - INFO - Train: 6 [ 600/781 ( 77%)]  Loss:  4.256398 (4.1555)  Time: 3.466s,   36.93/s  (3.685s,   34.74/s)  LR: 3.004e-04  Data: 0.006 (0.007)
2024-04-05 23:28:31,063 - train - INFO - Train: 6 [ 650/781 ( 83%)]  Loss:  3.661798 (4.1483)  Time: 3.388s,   37.78/s  (3.682s,   34.76/s)  LR: 3.004e-04  Data: 0.011 (0.007)
2024-04-05 23:31:42,767 - train - INFO - Train: 6 [ 700/781 ( 90%)]  Loss:  4.244257 (4.1320)  Time: 3.994s,   32.05/s  (3.693s,   34.66/s)  LR: 3.004e-04  Data: 0.011 (0.007)
2024-04-05 23:34:42,695 - train - INFO - Train: 6 [ 750/781 ( 96%)]  Loss:  3.436416 (4.1266)  Time: 3.530s,   36.26/s  (3.686s,   34.72/s)  LR: 3.004e-04  Data: 0.005 (0.007)
2024-04-05 23:36:27,508 - train - INFO - Train: 6 [ 780/781 (100%)]  Loss:  4.196551 (4.1236)  Time: 3.264s,   39.22/s  (3.679s,   34.79/s)  LR: 3.004e-04  Data: 0.000 (0.007)
2024-04-05 23:36:27,508 - train - INFO - True
2024-04-05 23:36:27,509 - train - INFO - alphas:tensor([0.2569, 0.2437, 0.1563, 0.1692, 0.1739], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,510 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,510 - train - INFO - True
2024-04-05 23:36:27,510 - train - INFO - alphas:tensor([0.2747, 0.2316, 0.1498, 0.1675, 0.1763], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,511 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,511 - train - INFO - True
2024-04-05 23:36:27,511 - train - INFO - alphas:tensor([0.4668, 0.2312, 0.0950, 0.1008, 0.1062], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,512 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,512 - train - INFO - True
2024-04-05 23:36:27,512 - train - INFO - alphas:tensor([0.4591, 0.2119, 0.1024, 0.1104, 0.1162], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,512 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,513 - train - INFO - True
2024-04-05 23:36:27,513 - train - INFO - alphas:tensor([0.3866, 0.2438, 0.1132, 0.1250, 0.1314], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,513 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,513 - train - INFO - True
2024-04-05 23:36:27,514 - train - INFO - alphas:tensor([0.4183, 0.2206, 0.1125, 0.1196, 0.1290], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,514 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,514 - train - INFO - True
2024-04-05 23:36:27,515 - train - INFO - alphas:tensor([0.4613, 0.2362, 0.0964, 0.1010, 0.1050], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,515 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,515 - train - INFO - True
2024-04-05 23:36:27,516 - train - INFO - alphas:tensor([0.4419, 0.2322, 0.1049, 0.1089, 0.1121], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,516 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,516 - train - INFO - True
2024-04-05 23:36:27,517 - train - INFO - alphas:tensor([0.4357, 0.2233, 0.1032, 0.1152, 0.1227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,517 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,517 - train - INFO - True
2024-04-05 23:36:27,518 - train - INFO - alphas:tensor([0.4604, 0.2081, 0.1044, 0.1101, 0.1170], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,518 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,518 - train - INFO - True
2024-04-05 23:36:27,519 - train - INFO - alphas:tensor([0.4874, 0.2208, 0.0929, 0.0977, 0.1011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,519 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,519 - train - INFO - True
2024-04-05 23:36:27,520 - train - INFO - alphas:tensor([0.4437, 0.2226, 0.1068, 0.1095, 0.1174], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,520 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,520 - train - INFO - True
2024-04-05 23:36:27,521 - train - INFO - alphas:tensor([0.4443, 0.2214, 0.1007, 0.1124, 0.1213], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,521 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,521 - train - INFO - True
2024-04-05 23:36:27,522 - train - INFO - alphas:tensor([0.4910, 0.1900, 0.1013, 0.1072, 0.1105], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,522 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,522 - train - INFO - True
2024-04-05 23:36:27,523 - train - INFO - alphas:tensor([0.4857, 0.2199, 0.0956, 0.0977, 0.1011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,523 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,523 - train - INFO - True
2024-04-05 23:36:27,523 - train - INFO - alphas:tensor([0.4099, 0.2319, 0.1197, 0.1160, 0.1225], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,524 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,524 - train - INFO - True
2024-04-05 23:36:27,524 - train - INFO - alphas:tensor([0.4396, 0.2247, 0.1059, 0.1113, 0.1185], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,525 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,525 - train - INFO - True
2024-04-05 23:36:27,525 - train - INFO - alphas:tensor([0.4789, 0.1944, 0.1052, 0.1082, 0.1133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,525 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,525 - train - INFO - True
2024-04-05 23:36:27,526 - train - INFO - alphas:tensor([0.4874, 0.2185, 0.0992, 0.0964, 0.0985], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,526 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,526 - train - INFO - True
2024-04-05 23:36:27,527 - train - INFO - alphas:tensor([0.3994, 0.2205, 0.1235, 0.1245, 0.1321], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,527 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,527 - train - INFO - True
2024-04-05 23:36:27,528 - train - INFO - alphas:tensor([0.4081, 0.2334, 0.1084, 0.1215, 0.1287], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,528 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,528 - train - INFO - True
2024-04-05 23:36:27,529 - train - INFO - alphas:tensor([0.4830, 0.1872, 0.1043, 0.1118, 0.1138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,529 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,529 - train - INFO - True
2024-04-05 23:36:27,530 - train - INFO - alphas:tensor([0.5086, 0.2081, 0.0919, 0.0944, 0.0971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,530 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,530 - train - INFO - True
2024-04-05 23:36:27,531 - train - INFO - alphas:tensor([0.3955, 0.2170, 0.1247, 0.1278, 0.1350], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,531 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,531 - train - INFO - True
2024-04-05 23:36:27,532 - train - INFO - alphas:tensor([0.4050, 0.2311, 0.1085, 0.1237, 0.1317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,532 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,532 - train - INFO - True
2024-04-05 23:36:27,533 - train - INFO - alphas:tensor([0.4697, 0.1917, 0.1081, 0.1123, 0.1182], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,533 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,533 - train - INFO - True
2024-04-05 23:36:27,534 - train - INFO - alphas:tensor([0.5205, 0.2001, 0.0890, 0.0939, 0.0966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,534 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,534 - train - INFO - True
2024-04-05 23:36:27,535 - train - INFO - alphas:tensor([0.4379, 0.2137, 0.1128, 0.1171, 0.1185], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,535 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,535 - train - INFO - True
2024-04-05 23:36:27,535 - train - INFO - alphas:tensor([0.3868, 0.2331, 0.1159, 0.1270, 0.1372], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,536 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,536 - train - INFO - True
2024-04-05 23:36:27,536 - train - INFO - alphas:tensor([0.4579, 0.1973, 0.1084, 0.1144, 0.1220], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,537 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,537 - train - INFO - True
2024-04-05 23:36:27,537 - train - INFO - alphas:tensor([0.5069, 0.2033, 0.0934, 0.0970, 0.0994], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,537 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,538 - train - INFO - True
2024-04-05 23:36:27,538 - train - INFO - alphas:tensor([0.4496, 0.2135, 0.1111, 0.1123, 0.1135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,538 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,538 - train - INFO - True
2024-04-05 23:36:27,539 - train - INFO - alphas:tensor([0.3646, 0.2483, 0.1146, 0.1321, 0.1404], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,539 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,539 - train - INFO - True
2024-04-05 23:36:27,540 - train - INFO - alphas:tensor([0.4165, 0.2136, 0.1184, 0.1238, 0.1277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,540 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,540 - train - INFO - True
2024-04-05 23:36:27,541 - train - INFO - alphas:tensor([0.4967, 0.2053, 0.0923, 0.1001, 0.1055], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,541 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,541 - train - INFO - True
2024-04-05 23:36:27,542 - train - INFO - alphas:tensor([0.4450, 0.2189, 0.1073, 0.1125, 0.1163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,542 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,542 - train - INFO - True
2024-04-05 23:36:27,543 - train - INFO - alphas:tensor([0.4906, 0.1732, 0.1605, 0.1758], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-05 23:36:27,543 - train - INFO - tau:0.96059601
2024-04-05 23:36:27,543 - train - INFO - avg block size:1.0
2024-04-05 23:36:27,543 - train - INFO - lasso_alpha:1.1000000000000001e-05
2024-04-05 23:36:30,277 - train - INFO - Test: [   0/78]  Time: 2.727 (2.727)  Loss:  1.2295 (1.2295)  Acc@1: 75.7812 (75.7812)  Acc@5: 90.6250 (90.6250)
2024-04-05 23:38:38,810 - train - INFO - Test: [  50/78]  Time: 2.574 (2.574)  Loss:  2.2988 (2.0757)  Acc@1: 49.2188 (52.7267)  Acc@5: 74.2188 (78.0484)
2024-04-05 23:39:50,062 - train - INFO - Test: [  78/78]  Time: 2.244 (2.563)  Loss:  2.0117 (2.1097)  Acc@1: 43.7500 (51.9600)  Acc@5: 81.2500 (77.2700)
2024-04-05 23:39:53,862 - train - INFO - Train: 7 [   0/781 (  0%)]  Loss:  4.270944 (4.2709)  Time: 3.720s,   34.41/s  (3.720s,   34.41/s)  LR: 3.503e-04  Data: 0.133 (0.133)
2024-04-05 23:43:03,144 - train - INFO - Train: 7 [  50/781 (  6%)]  Loss:  4.397446 (4.0321)  Time: 3.675s,   34.83/s  (3.784s,   33.82/s)  LR: 3.503e-04  Data: 0.007 (0.008)
2024-04-05 23:46:04,606 - train - INFO - Train: 7 [ 100/781 ( 13%)]  Loss:  4.355062 (3.9997)  Time: 3.464s,   36.95/s  (3.708s,   34.52/s)  LR: 3.503e-04  Data: 0.007 (0.008)
2024-04-05 23:49:06,565 - train - INFO - Train: 7 [ 150/781 ( 19%)]  Loss:  4.526631 (4.0230)  Time: 3.311s,   38.66/s  (3.685s,   34.74/s)  LR: 3.503e-04  Data: 0.004 (0.007)
2024-04-05 23:52:08,548 - train - INFO - Train: 7 [ 200/781 ( 26%)]  Loss:  4.324158 (3.9990)  Time: 3.391s,   37.75/s  (3.674s,   34.84/s)  LR: 3.503e-04  Data: 0.005 (0.007)
2024-04-05 23:55:38,843 - train - INFO - Train: 7 [ 250/781 ( 32%)]  Loss:  3.769188 (3.9944)  Time: 3.855s,   33.21/s  (3.780s,   33.87/s)  LR: 3.503e-04  Data: 0.004 (0.007)
2024-04-05 23:58:44,314 - train - INFO - Train: 7 [ 300/781 ( 38%)]  Loss:  4.065102 (3.9828)  Time: 3.460s,   37.00/s  (3.768s,   33.97/s)  LR: 3.503e-04  Data: 0.006 (0.007)
2024-04-06 00:01:46,627 - train - INFO - Train: 7 [ 350/781 ( 45%)]  Loss:  4.183549 (3.9770)  Time: 3.780s,   33.86/s  (3.751s,   34.13/s)  LR: 3.503e-04  Data: 0.006 (0.007)
2024-04-06 00:04:45,087 - train - INFO - Train: 7 [ 400/781 ( 51%)]  Loss:  3.595874 (3.9794)  Time: 3.988s,   32.10/s  (3.728s,   34.33/s)  LR: 3.503e-04  Data: 0.007 (0.007)
2024-04-06 00:07:55,991 - train - INFO - Train: 7 [ 450/781 ( 58%)]  Loss:  3.568346 (3.9885)  Time: 3.769s,   33.96/s  (3.738s,   34.24/s)  LR: 3.503e-04  Data: 0.005 (0.007)
2024-04-06 00:10:53,754 - train - INFO - Train: 7 [ 500/781 ( 64%)]  Loss:  4.278868 (3.9783)  Time: 3.968s,   32.26/s  (3.720s,   34.41/s)  LR: 3.503e-04  Data: 0.021 (0.007)
2024-04-06 00:13:50,264 - train - INFO - Train: 7 [ 550/781 ( 71%)]  Loss:  4.316473 (3.9763)  Time: 3.242s,   39.49/s  (3.703s,   34.57/s)  LR: 3.503e-04  Data: 0.005 (0.007)
2024-04-06 00:16:43,033 - train - INFO - Train: 7 [ 600/781 ( 77%)]  Loss:  4.454188 (3.9694)  Time: 3.864s,   33.13/s  (3.682s,   34.76/s)  LR: 3.503e-04  Data: 0.007 (0.007)
2024-04-06 00:19:43,493 - train - INFO - Train: 7 [ 650/781 ( 83%)]  Loss:  4.293992 (3.9741)  Time: 3.711s,   34.49/s  (3.676s,   34.82/s)  LR: 3.503e-04  Data: 0.009 (0.007)
2024-04-06 00:22:32,032 - train - INFO - Train: 7 [ 700/781 ( 90%)]  Loss:  3.830838 (3.9668)  Time: 3.246s,   39.44/s  (3.655s,   35.02/s)  LR: 3.503e-04  Data: 0.005 (0.007)
2024-04-06 00:25:21,268 - train - INFO - Train: 7 [ 750/781 ( 96%)]  Loss:  4.360483 (3.9738)  Time: 3.332s,   38.42/s  (3.637s,   35.20/s)  LR: 3.503e-04  Data: 0.012 (0.007)
2024-04-06 00:26:57,352 - train - INFO - Train: 7 [ 780/781 (100%)]  Loss:  3.130757 (3.9723)  Time: 2.893s,   44.24/s  (3.620s,   35.36/s)  LR: 3.503e-04  Data: 0.000 (0.007)
2024-04-06 00:26:57,353 - train - INFO - True
2024-04-06 00:26:57,355 - train - INFO - alphas:tensor([0.2690, 0.2491, 0.1480, 0.1638, 0.1701], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,356 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,356 - train - INFO - True
2024-04-06 00:26:57,357 - train - INFO - alphas:tensor([0.2930, 0.2289, 0.1414, 0.1627, 0.1740], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,358 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,358 - train - INFO - True
2024-04-06 00:26:57,359 - train - INFO - alphas:tensor([0.5191, 0.2040, 0.0860, 0.0925, 0.0985], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,359 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,359 - train - INFO - True
2024-04-06 00:26:57,361 - train - INFO - alphas:tensor([0.5080, 0.1886, 0.0922, 0.1021, 0.1091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,361 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,361 - train - INFO - True
2024-04-06 00:26:57,362 - train - INFO - alphas:tensor([0.4319, 0.2184, 0.1041, 0.1188, 0.1268], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,363 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,363 - train - INFO - True
2024-04-06 00:26:57,364 - train - INFO - alphas:tensor([0.4746, 0.1976, 0.0998, 0.1088, 0.1192], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,364 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,364 - train - INFO - True
2024-04-06 00:26:57,366 - train - INFO - alphas:tensor([0.5375, 0.1991, 0.0830, 0.0880, 0.0923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,366 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,366 - train - INFO - True
2024-04-06 00:26:57,367 - train - INFO - alphas:tensor([0.5235, 0.1977, 0.0884, 0.0934, 0.0970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,368 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,368 - train - INFO - True
2024-04-06 00:26:57,369 - train - INFO - alphas:tensor([0.4839, 0.1933, 0.0948, 0.1093, 0.1187], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,369 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,370 - train - INFO - True
2024-04-06 00:26:57,371 - train - INFO - alphas:tensor([0.5216, 0.1807, 0.0916, 0.0991, 0.1070], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,371 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,371 - train - INFO - True
2024-04-06 00:26:57,372 - train - INFO - alphas:tensor([0.5713, 0.1794, 0.0784, 0.0838, 0.0871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,373 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,373 - train - INFO - True
2024-04-06 00:26:57,374 - train - INFO - alphas:tensor([0.5240, 0.1903, 0.0901, 0.0937, 0.1019], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,374 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,374 - train - INFO - True
2024-04-06 00:26:57,376 - train - INFO - alphas:tensor([0.5020, 0.1883, 0.0905, 0.1043, 0.1149], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,376 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,376 - train - INFO - True
2024-04-06 00:26:57,377 - train - INFO - alphas:tensor([0.5582, 0.1622, 0.0873, 0.0942, 0.0980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,377 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,378 - train - INFO - True
2024-04-06 00:26:57,379 - train - INFO - alphas:tensor([0.5689, 0.1835, 0.0794, 0.0823, 0.0859], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,379 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,379 - train - INFO - True
2024-04-06 00:26:57,380 - train - INFO - alphas:tensor([0.4877, 0.2042, 0.1016, 0.0999, 0.1066], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,380 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,381 - train - INFO - True
2024-04-06 00:26:57,382 - train - INFO - alphas:tensor([0.5017, 0.1916, 0.0941, 0.1019, 0.1107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,382 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,382 - train - INFO - True
2024-04-06 00:26:57,383 - train - INFO - alphas:tensor([0.5536, 0.1642, 0.0894, 0.0938, 0.0990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,383 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,384 - train - INFO - True
2024-04-06 00:26:57,385 - train - INFO - alphas:tensor([0.5777, 0.1770, 0.0816, 0.0806, 0.0831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,385 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,385 - train - INFO - True
2024-04-06 00:26:57,386 - train - INFO - alphas:tensor([0.4749, 0.1959, 0.1050, 0.1079, 0.1164], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,386 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,387 - train - INFO - True
2024-04-06 00:26:57,388 - train - INFO - alphas:tensor([0.4743, 0.2011, 0.0954, 0.1102, 0.1189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,388 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,388 - train - INFO - True
2024-04-06 00:26:57,389 - train - INFO - alphas:tensor([0.5596, 0.1571, 0.0885, 0.0961, 0.0987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,390 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,390 - train - INFO - True
2024-04-06 00:26:57,391 - train - INFO - alphas:tensor([0.6047, 0.1647, 0.0741, 0.0769, 0.0796], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,391 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,391 - train - INFO - True
2024-04-06 00:26:57,392 - train - INFO - alphas:tensor([0.4819, 0.1902, 0.1040, 0.1083, 0.1155], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,392 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,393 - train - INFO - True
2024-04-06 00:26:57,394 - train - INFO - alphas:tensor([0.4682, 0.2017, 0.0951, 0.1128, 0.1222], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,394 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,394 - train - INFO - True
2024-04-06 00:26:57,395 - train - INFO - alphas:tensor([0.5459, 0.1617, 0.0920, 0.0970, 0.1034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,395 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,395 - train - INFO - True
2024-04-06 00:26:57,397 - train - INFO - alphas:tensor([0.6064, 0.1596, 0.0732, 0.0788, 0.0819], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,397 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,397 - train - INFO - True
2024-04-06 00:26:57,398 - train - INFO - alphas:tensor([0.5219, 0.1813, 0.0947, 0.1000, 0.1021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,398 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,398 - train - INFO - True
2024-04-06 00:26:57,399 - train - INFO - alphas:tensor([0.4469, 0.2036, 0.1030, 0.1172, 0.1292], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,400 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,400 - train - INFO - True
2024-04-06 00:26:57,401 - train - INFO - alphas:tensor([0.5360, 0.1654, 0.0921, 0.0993, 0.1071], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,401 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,401 - train - INFO - True
2024-04-06 00:26:57,402 - train - INFO - alphas:tensor([0.5885, 0.1626, 0.0790, 0.0834, 0.0865], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,402 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,402 - train - INFO - True
2024-04-06 00:26:57,403 - train - INFO - alphas:tensor([0.5320, 0.1770, 0.0946, 0.0973, 0.0992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,404 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,404 - train - INFO - True
2024-04-06 00:26:57,405 - train - INFO - alphas:tensor([0.4255, 0.2166, 0.1014, 0.1229, 0.1336], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,405 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,405 - train - INFO - True
2024-04-06 00:26:57,406 - train - INFO - alphas:tensor([0.4998, 0.1802, 0.1001, 0.1075, 0.1124], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,406 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,406 - train - INFO - True
2024-04-06 00:26:57,408 - train - INFO - alphas:tensor([0.5735, 0.1659, 0.0791, 0.0878, 0.0937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,408 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,408 - train - INFO - True
2024-04-06 00:26:57,409 - train - INFO - alphas:tensor([0.5195, 0.1830, 0.0932, 0.0998, 0.1044], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,409 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,409 - train - INFO - True
2024-04-06 00:26:57,410 - train - INFO - alphas:tensor([0.5371, 0.1488, 0.1483, 0.1658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 00:26:57,410 - train - INFO - tau:0.9509900498999999
2024-04-06 00:26:57,411 - train - INFO - avg block size:1.0
2024-04-06 00:26:59,892 - train - INFO - Test: [   0/78]  Time: 2.473 (2.473)  Loss:  1.2588 (1.2588)  Acc@1: 72.6562 (72.6562)  Acc@5: 89.8438 (89.8438)
2024-04-06 00:29:07,084 - train - INFO - Test: [  50/78]  Time: 2.496 (2.542)  Loss:  2.1484 (1.9336)  Acc@1: 51.5625 (55.2390)  Acc@5: 78.9062 (80.0705)
2024-04-06 00:30:11,330 - train - INFO - Test: [  78/78]  Time: 2.437 (2.455)  Loss:  2.1172 (1.9568)  Acc@1: 43.7500 (54.8700)  Acc@5: 81.2500 (79.5200)
2024-04-06 00:30:14,613 - train - INFO - Train: 8 [   0/781 (  0%)]  Loss:  3.698199 (3.6982)  Time: 3.198s,   40.02/s  (3.198s,   40.02/s)  LR: 4.002e-04  Data: 0.141 (0.141)
2024-04-06 00:32:57,121 - train - INFO - Train: 8 [  50/781 (  6%)]  Loss:  4.377000 (3.8286)  Time: 2.960s,   43.25/s  (3.249s,   39.40/s)  LR: 4.002e-04  Data: 0.004 (0.009)
2024-04-06 00:35:48,569 - train - INFO - Train: 8 [ 100/781 ( 13%)]  Loss:  4.204463 (3.8686)  Time: 3.397s,   37.68/s  (3.338s,   38.34/s)  LR: 4.002e-04  Data: 0.010 (0.008)
2024-04-06 00:38:37,625 - train - INFO - Train: 8 [ 150/781 ( 19%)]  Loss:  4.535847 (3.8769)  Time: 3.802s,   33.67/s  (3.352s,   38.18/s)  LR: 4.002e-04  Data: 0.004 (0.007)
2024-04-06 00:41:31,205 - train - INFO - Train: 8 [ 200/781 ( 26%)]  Loss:  3.197022 (3.8835)  Time: 3.580s,   35.76/s  (3.382s,   37.85/s)  LR: 4.002e-04  Data: 0.006 (0.007)
2024-04-06 00:44:13,573 - train - INFO - Train: 8 [ 250/781 ( 32%)]  Loss:  4.403633 (3.8735)  Time: 3.092s,   41.40/s  (3.355s,   38.15/s)  LR: 4.002e-04  Data: 0.005 (0.007)
2024-04-06 00:46:59,008 - train - INFO - Train: 8 [ 300/781 ( 38%)]  Loss:  3.608029 (3.8678)  Time: 4.020s,   31.84/s  (3.347s,   38.24/s)  LR: 4.002e-04  Data: 0.009 (0.007)
2024-04-06 00:50:07,104 - train - INFO - Train: 8 [ 350/781 ( 45%)]  Loss:  3.355777 (3.8694)  Time: 4.383s,   29.20/s  (3.406s,   37.58/s)  LR: 4.002e-04  Data: 0.005 (0.007)
2024-04-06 00:53:22,215 - train - INFO - Train: 8 [ 400/781 ( 51%)]  Loss:  3.366800 (3.8556)  Time: 3.535s,   36.21/s  (3.468s,   36.91/s)  LR: 4.002e-04  Data: 0.005 (0.007)
2024-04-06 00:56:25,470 - train - INFO - Train: 8 [ 450/781 ( 58%)]  Loss:  3.784470 (3.8599)  Time: 3.823s,   33.48/s  (3.490s,   36.68/s)  LR: 4.002e-04  Data: 0.004 (0.007)
2024-04-06 00:59:28,056 - train - INFO - Train: 8 [ 500/781 ( 64%)]  Loss:  4.367904 (3.8676)  Time: 3.559s,   35.97/s  (3.506s,   36.51/s)  LR: 4.002e-04  Data: 0.006 (0.007)
2024-04-06 01:02:34,682 - train - INFO - Train: 8 [ 550/781 ( 71%)]  Loss:  4.187513 (3.8709)  Time: 4.248s,   30.13/s  (3.527s,   36.29/s)  LR: 4.002e-04  Data: 0.004 (0.007)
2024-04-06 01:05:36,802 - train - INFO - Train: 8 [ 600/781 ( 77%)]  Loss:  4.016485 (3.8768)  Time: 3.250s,   39.38/s  (3.536s,   36.20/s)  LR: 4.002e-04  Data: 0.006 (0.007)
2024-04-06 01:08:31,667 - train - INFO - Train: 8 [ 650/781 ( 83%)]  Loss:  3.218724 (3.8775)  Time: 3.926s,   32.60/s  (3.533s,   36.23/s)  LR: 4.002e-04  Data: 0.007 (0.007)
2024-04-06 01:11:34,310 - train - INFO - Train: 8 [ 700/781 ( 90%)]  Loss:  4.260662 (3.8828)  Time: 3.554s,   36.01/s  (3.542s,   36.14/s)  LR: 4.002e-04  Data: 0.009 (0.007)
2024-04-06 01:14:49,788 - train - INFO - Train: 8 [ 750/781 ( 96%)]  Loss:  3.442648 (3.8846)  Time: 4.360s,   29.36/s  (3.566s,   35.89/s)  LR: 4.002e-04  Data: 0.004 (0.007)
2024-04-06 01:16:37,038 - train - INFO - Train: 8 [ 780/781 (100%)]  Loss:  3.340833 (3.8812)  Time: 3.455s,   37.04/s  (3.567s,   35.89/s)  LR: 4.002e-04  Data: 0.000 (0.007)
2024-04-06 01:16:37,038 - train - INFO - True
2024-04-06 01:16:37,039 - train - INFO - alphas:tensor([0.2798, 0.2518, 0.1410, 0.1599, 0.1675], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,040 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,040 - train - INFO - True
2024-04-06 01:16:37,040 - train - INFO - alphas:tensor([0.3112, 0.2231, 0.1338, 0.1587, 0.1731], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,041 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,041 - train - INFO - True
2024-04-06 01:16:37,041 - train - INFO - alphas:tensor([0.5603, 0.1814, 0.0793, 0.0864, 0.0926], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,042 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,042 - train - INFO - True
2024-04-06 01:16:37,042 - train - INFO - alphas:tensor([0.5474, 0.1691, 0.0844, 0.0956, 0.1035], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,042 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,043 - train - INFO - True
2024-04-06 01:16:37,043 - train - INFO - alphas:tensor([0.4658, 0.1952, 0.0984, 0.1155, 0.1251], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,043 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,043 - train - INFO - True
2024-04-06 01:16:37,044 - train - INFO - alphas:tensor([0.5215, 0.1769, 0.0899, 0.1003, 0.1113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,044 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,044 - train - INFO - True
2024-04-06 01:16:37,045 - train - INFO - alphas:tensor([0.5995, 0.1677, 0.0726, 0.0778, 0.0825], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,045 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,045 - train - INFO - True
2024-04-06 01:16:37,046 - train - INFO - alphas:tensor([0.5903, 0.1674, 0.0756, 0.0814, 0.0853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,046 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,046 - train - INFO - True
2024-04-06 01:16:37,047 - train - INFO - alphas:tensor([0.5214, 0.1691, 0.0881, 0.1051, 0.1163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,047 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,047 - train - INFO - True
2024-04-06 01:16:37,048 - train - INFO - alphas:tensor([0.5694, 0.1593, 0.0821, 0.0904, 0.0989], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,048 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,048 - train - INFO - True
2024-04-06 01:16:37,049 - train - INFO - alphas:tensor([0.6327, 0.1486, 0.0679, 0.0736, 0.0772], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,049 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,049 - train - INFO - True
2024-04-06 01:16:37,050 - train - INFO - alphas:tensor([0.5860, 0.1622, 0.0782, 0.0825, 0.0911], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,050 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,050 - train - INFO - True
2024-04-06 01:16:37,051 - train - INFO - alphas:tensor([0.5386, 0.1637, 0.0841, 0.1005, 0.1131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,051 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,051 - train - INFO - True
2024-04-06 01:16:37,052 - train - INFO - alphas:tensor([0.6058, 0.1415, 0.0773, 0.0855, 0.0899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,052 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,052 - train - INFO - True
2024-04-06 01:16:37,053 - train - INFO - alphas:tensor([0.6290, 0.1555, 0.0682, 0.0718, 0.0756], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,053 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,053 - train - INFO - True
2024-04-06 01:16:37,054 - train - INFO - alphas:tensor([0.5468, 0.1798, 0.0886, 0.0888, 0.0960], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,054 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,054 - train - INFO - True
2024-04-06 01:16:37,054 - train - INFO - alphas:tensor([0.5469, 0.1633, 0.0861, 0.0965, 0.1072], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,055 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,055 - train - INFO - True
2024-04-06 01:16:37,055 - train - INFO - alphas:tensor([0.6078, 0.1406, 0.0782, 0.0838, 0.0896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,055 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,056 - train - INFO - True
2024-04-06 01:16:37,056 - train - INFO - alphas:tensor([0.6459, 0.1446, 0.0690, 0.0689, 0.0717], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,056 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,056 - train - INFO - True
2024-04-06 01:16:37,057 - train - INFO - alphas:tensor([0.5381, 0.1700, 0.0912, 0.0956, 0.1050], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,057 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,057 - train - INFO - True
2024-04-06 01:16:37,058 - train - INFO - alphas:tensor([0.5223, 0.1740, 0.0866, 0.1034, 0.1137], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,058 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,058 - train - INFO - True
2024-04-06 01:16:37,059 - train - INFO - alphas:tensor([0.6171, 0.1341, 0.0764, 0.0846, 0.0878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,059 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,059 - train - INFO - True
2024-04-06 01:16:37,060 - train - INFO - alphas:tensor([0.6720, 0.1337, 0.0619, 0.0648, 0.0677], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,060 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,060 - train - INFO - True
2024-04-06 01:16:37,061 - train - INFO - alphas:tensor([0.5549, 0.1616, 0.0881, 0.0937, 0.1017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,061 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,061 - train - INFO - True
2024-04-06 01:16:37,062 - train - INFO - alphas:tensor([0.5152, 0.1748, 0.0864, 0.1063, 0.1174], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,062 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,062 - train - INFO - True
2024-04-06 01:16:37,063 - train - INFO - alphas:tensor([0.6021, 0.1387, 0.0800, 0.0860, 0.0931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,063 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,063 - train - INFO - True
2024-04-06 01:16:37,064 - train - INFO - alphas:tensor([0.6674, 0.1312, 0.0621, 0.0679, 0.0715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,064 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,064 - train - INFO - True
2024-04-06 01:16:37,065 - train - INFO - alphas:tensor([0.5917, 0.1505, 0.0806, 0.0870, 0.0902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,065 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,065 - train - INFO - True
2024-04-06 01:16:37,066 - train - INFO - alphas:tensor([0.4953, 0.1738, 0.0942, 0.1113, 0.1255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,066 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,066 - train - INFO - True
2024-04-06 01:16:37,066 - train - INFO - alphas:tensor([0.5960, 0.1395, 0.0799, 0.0881, 0.0966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,067 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,067 - train - INFO - True
2024-04-06 01:16:37,067 - train - INFO - alphas:tensor([0.6485, 0.1329, 0.0680, 0.0734, 0.0772], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,067 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,068 - train - INFO - True
2024-04-06 01:16:37,068 - train - INFO - alphas:tensor([0.5992, 0.1466, 0.0811, 0.0851, 0.0880], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,068 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,068 - train - INFO - True
2024-04-06 01:16:37,069 - train - INFO - alphas:tensor([0.4745, 0.1832, 0.0924, 0.1181, 0.1318], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,069 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,069 - train - INFO - True
2024-04-06 01:16:37,070 - train - INFO - alphas:tensor([0.5640, 0.1515, 0.0870, 0.0958, 0.1017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,070 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,070 - train - INFO - True
2024-04-06 01:16:37,071 - train - INFO - alphas:tensor([0.6284, 0.1381, 0.0692, 0.0789, 0.0855], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,071 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,071 - train - INFO - True
2024-04-06 01:16:37,072 - train - INFO - alphas:tensor([0.5756, 0.1550, 0.0826, 0.0907, 0.0961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,072 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,072 - train - INFO - True
2024-04-06 01:16:37,073 - train - INFO - alphas:tensor([0.5717, 0.1316, 0.1388, 0.1579], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 01:16:37,073 - train - INFO - tau:0.9414801494009999
2024-04-06 01:16:37,073 - train - INFO - avg block size:1.0
2024-04-06 01:16:39,958 - train - INFO - Test: [   0/78]  Time: 2.878 (2.878)  Loss:  1.1113 (1.1113)  Acc@1: 74.2188 (74.2188)  Acc@5: 91.4062 (91.4062)
2024-04-06 01:18:53,497 - train - INFO - Test: [  50/78]  Time: 2.941 (2.675)  Loss:  2.0117 (1.8202)  Acc@1: 57.0312 (57.5061)  Acc@5: 82.0312 (81.4491)
2024-04-06 01:20:08,128 - train - INFO - Test: [  78/78]  Time: 2.466 (2.671)  Loss:  1.4609 (1.8400)  Acc@1: 50.0000 (57.0900)  Acc@5: 93.7500 (80.9800)
2024-04-06 01:20:11,920 - train - INFO - Train: 9 [   0/781 (  0%)]  Loss:  4.309083 (4.3091)  Time: 3.710s,   34.50/s  (3.710s,   34.50/s)  LR: 4.501e-04  Data: 0.127 (0.127)
2024-04-06 01:23:19,117 - train - INFO - Train: 9 [  50/781 (  6%)]  Loss:  4.394629 (3.8786)  Time: 4.015s,   31.88/s  (3.743s,   34.19/s)  LR: 4.501e-04  Data: 0.005 (0.009)
2024-04-06 01:26:39,071 - train - INFO - Train: 9 [ 100/781 ( 13%)]  Loss:  4.109742 (3.8852)  Time: 4.304s,   29.74/s  (3.870s,   33.08/s)  LR: 4.501e-04  Data: 0.006 (0.008)
2024-04-06 01:29:54,984 - train - INFO - Train: 9 [ 150/781 ( 19%)]  Loss:  3.408885 (3.8847)  Time: 3.755s,   34.09/s  (3.886s,   32.94/s)  LR: 4.501e-04  Data: 0.006 (0.008)
2024-04-06 01:32:56,487 - train - INFO - Train: 9 [ 200/781 ( 26%)]  Loss:  4.191686 (3.9067)  Time: 3.857s,   33.19/s  (3.822s,   33.49/s)  LR: 4.501e-04  Data: 0.007 (0.008)
2024-04-06 01:35:58,111 - train - INFO - Train: 9 [ 250/781 ( 32%)]  Loss:  4.245821 (3.9165)  Time: 3.341s,   38.31/s  (3.784s,   33.82/s)  LR: 4.501e-04  Data: 0.004 (0.008)
2024-04-06 01:39:02,593 - train - INFO - Train: 9 [ 300/781 ( 38%)]  Loss:  3.343513 (3.9008)  Time: 4.157s,   30.79/s  (3.769s,   33.96/s)  LR: 4.501e-04  Data: 0.005 (0.007)
2024-04-06 01:42:02,183 - train - INFO - Train: 9 [ 350/781 ( 45%)]  Loss:  3.362499 (3.8882)  Time: 3.737s,   34.26/s  (3.743s,   34.19/s)  LR: 4.501e-04  Data: 0.006 (0.007)
2024-04-06 01:44:55,183 - train - INFO - Train: 9 [ 400/781 ( 51%)]  Loss:  4.066320 (3.8775)  Time: 3.180s,   40.25/s  (3.708s,   34.52/s)  LR: 4.501e-04  Data: 0.006 (0.007)
2024-04-06 01:47:50,403 - train - INFO - Train: 9 [ 450/781 ( 58%)]  Loss:  3.619598 (3.8746)  Time: 3.942s,   32.47/s  (3.686s,   34.73/s)  LR: 4.501e-04  Data: 0.009 (0.007)
2024-04-06 01:50:57,656 - train - INFO - Train: 9 [ 500/781 ( 64%)]  Loss:  4.208800 (3.8648)  Time: 4.064s,   31.50/s  (3.691s,   34.67/s)  LR: 4.501e-04  Data: 0.005 (0.007)
2024-04-06 01:54:00,250 - train - INFO - Train: 9 [ 550/781 ( 71%)]  Loss:  3.381201 (3.8630)  Time: 3.891s,   32.90/s  (3.688s,   34.71/s)  LR: 4.501e-04  Data: 0.006 (0.007)
2024-04-06 01:57:02,094 - train - INFO - Train: 9 [ 600/781 ( 77%)]  Loss:  3.533931 (3.8747)  Time: 3.576s,   35.79/s  (3.684s,   34.75/s)  LR: 4.501e-04  Data: 0.009 (0.007)
2024-04-06 02:00:04,476 - train - INFO - Train: 9 [ 650/781 ( 83%)]  Loss:  3.778113 (3.8735)  Time: 3.384s,   37.83/s  (3.681s,   34.77/s)  LR: 4.501e-04  Data: 0.006 (0.007)
2024-04-06 02:03:18,604 - train - INFO - Train: 9 [ 700/781 ( 90%)]  Loss:  3.259723 (3.8687)  Time: 4.085s,   31.34/s  (3.695s,   34.64/s)  LR: 4.501e-04  Data: 0.009 (0.007)
2024-04-06 02:06:18,582 - train - INFO - Train: 9 [ 750/781 ( 96%)]  Loss:  3.431127 (3.8710)  Time: 3.371s,   37.97/s  (3.689s,   34.70/s)  LR: 4.501e-04  Data: 0.004 (0.007)
2024-04-06 02:08:06,500 - train - INFO - Train: 9 [ 780/781 (100%)]  Loss:  3.471111 (3.8761)  Time: 3.401s,   37.64/s  (3.685s,   34.73/s)  LR: 4.501e-04  Data: 0.000 (0.007)
2024-04-06 02:08:06,501 - train - INFO - True
2024-04-06 02:08:06,503 - train - INFO - alphas:tensor([0.2905, 0.2522, 0.1349, 0.1567, 0.1656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,503 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,503 - train - INFO - True
2024-04-06 02:08:06,505 - train - INFO - alphas:tensor([0.3308, 0.2145, 0.1261, 0.1554, 0.1732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,505 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,505 - train - INFO - True
2024-04-06 02:08:06,506 - train - INFO - alphas:tensor([0.5933, 0.1642, 0.0737, 0.0812, 0.0876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,506 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,507 - train - INFO - True
2024-04-06 02:08:06,508 - train - INFO - alphas:tensor([0.5816, 0.1511, 0.0779, 0.0904, 0.0990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,508 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,508 - train - INFO - True
2024-04-06 02:08:06,510 - train - INFO - alphas:tensor([0.4937, 0.1758, 0.0935, 0.1129, 0.1242], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,510 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,510 - train - INFO - True
2024-04-06 02:08:06,511 - train - INFO - alphas:tensor([0.5616, 0.1590, 0.0816, 0.0931, 0.1046], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,511 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,511 - train - INFO - True
2024-04-06 02:08:06,513 - train - INFO - alphas:tensor([0.6476, 0.1427, 0.0646, 0.0702, 0.0750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,513 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,513 - train - INFO - True
2024-04-06 02:08:06,514 - train - INFO - alphas:tensor([0.6424, 0.1431, 0.0659, 0.0722, 0.0764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,514 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,515 - train - INFO - True
2024-04-06 02:08:06,516 - train - INFO - alphas:tensor([0.5464, 0.1508, 0.0838, 0.1031, 0.1160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,516 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,516 - train - INFO - True
2024-04-06 02:08:06,517 - train - INFO - alphas:tensor([0.6058, 0.1422, 0.0748, 0.0840, 0.0932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,518 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,518 - train - INFO - True
2024-04-06 02:08:06,519 - train - INFO - alphas:tensor([0.6749, 0.1276, 0.0605, 0.0666, 0.0705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,519 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,519 - train - INFO - True
2024-04-06 02:08:06,521 - train - INFO - alphas:tensor([0.6319, 0.1414, 0.0691, 0.0744, 0.0833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,521 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,521 - train - INFO - True
2024-04-06 02:08:06,522 - train - INFO - alphas:tensor([0.5655, 0.1457, 0.0791, 0.0974, 0.1123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,522 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,522 - train - INFO - True
2024-04-06 02:08:06,523 - train - INFO - alphas:tensor([0.6417, 0.1257, 0.0697, 0.0790, 0.0839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,524 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,524 - train - INFO - True
2024-04-06 02:08:06,525 - train - INFO - alphas:tensor([0.6694, 0.1360, 0.0606, 0.0649, 0.0691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,525 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,525 - train - INFO - True
2024-04-06 02:08:06,526 - train - INFO - alphas:tensor([0.5921, 0.1579, 0.0789, 0.0813, 0.0897], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,527 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,527 - train - INFO - True
2024-04-06 02:08:06,528 - train - INFO - alphas:tensor([0.5741, 0.1441, 0.0811, 0.0940, 0.1067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,528 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,528 - train - INFO - True
2024-04-06 02:08:06,529 - train - INFO - alphas:tensor([0.6457, 0.1239, 0.0702, 0.0770, 0.0833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,530 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,530 - train - INFO - True
2024-04-06 02:08:06,531 - train - INFO - alphas:tensor([0.6920, 0.1228, 0.0601, 0.0610, 0.0642], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,531 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,531 - train - INFO - True
2024-04-06 02:08:06,532 - train - INFO - alphas:tensor([0.5859, 0.1489, 0.0806, 0.0871, 0.0975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,532 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,533 - train - INFO - True
2024-04-06 02:08:06,534 - train - INFO - alphas:tensor([0.5531, 0.1537, 0.0810, 0.0999, 0.1123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,534 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,534 - train - INFO - True
2024-04-06 02:08:06,535 - train - INFO - alphas:tensor([0.6568, 0.1175, 0.0682, 0.0767, 0.0807], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,535 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,535 - train - INFO - True
2024-04-06 02:08:06,537 - train - INFO - alphas:tensor([0.7147, 0.1138, 0.0540, 0.0571, 0.0604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,537 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,537 - train - INFO - True
2024-04-06 02:08:06,538 - train - INFO - alphas:tensor([0.6069, 0.1387, 0.0768, 0.0841, 0.0934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,538 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,538 - train - INFO - True
2024-04-06 02:08:06,539 - train - INFO - alphas:tensor([0.5492, 0.1535, 0.0801, 0.1022, 0.1150], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,539 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,540 - train - INFO - True
2024-04-06 02:08:06,541 - train - INFO - alphas:tensor([0.6456, 0.1208, 0.0708, 0.0776, 0.0852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,541 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,541 - train - INFO - True
2024-04-06 02:08:06,542 - train - INFO - alphas:tensor([0.7072, 0.1120, 0.0547, 0.0611, 0.0651], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,542 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,542 - train - INFO - True
2024-04-06 02:08:06,543 - train - INFO - alphas:tensor([0.6363, 0.1301, 0.0712, 0.0790, 0.0835], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,544 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,544 - train - INFO - True
2024-04-06 02:08:06,545 - train - INFO - alphas:tensor([0.5286, 0.1505, 0.0880, 0.1082, 0.1248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,545 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,545 - train - INFO - True
2024-04-06 02:08:06,546 - train - INFO - alphas:tensor([0.6392, 0.1205, 0.0709, 0.0802, 0.0890], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,546 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,546 - train - INFO - True
2024-04-06 02:08:06,547 - train - INFO - alphas:tensor([0.6878, 0.1132, 0.0605, 0.0669, 0.0716], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,548 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,548 - train - INFO - True
2024-04-06 02:08:06,549 - train - INFO - alphas:tensor([0.6414, 0.1263, 0.0726, 0.0779, 0.0818], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,549 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,549 - train - INFO - True
2024-04-06 02:08:06,550 - train - INFO - alphas:tensor([0.5056, 0.1585, 0.0866, 0.1162, 0.1332], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,550 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,550 - train - INFO - True
2024-04-06 02:08:06,551 - train - INFO - alphas:tensor([0.6083, 0.1310, 0.0777, 0.0880, 0.0951], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,552 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,552 - train - INFO - True
2024-04-06 02:08:06,553 - train - INFO - alphas:tensor([0.6651, 0.1191, 0.0623, 0.0728, 0.0806], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,553 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,553 - train - INFO - True
2024-04-06 02:08:06,554 - train - INFO - alphas:tensor([0.6165, 0.1345, 0.0748, 0.0840, 0.0902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,554 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,554 - train - INFO - True
2024-04-06 02:08:06,555 - train - INFO - alphas:tensor([0.5958, 0.1201, 0.1317, 0.1523], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:08:06,555 - train - INFO - tau:0.9320653479069899
2024-04-06 02:08:06,555 - train - INFO - avg block size:1.0
2024-04-06 02:08:06,556 - train - INFO - lasso_alpha:1.2100000000000003e-05
2024-04-06 02:08:09,624 - train - INFO - Test: [   0/78]  Time: 3.060 (3.060)  Loss:  0.9258 (0.9258)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-06 02:10:22,884 - train - INFO - Test: [  50/78]  Time: 2.998 (2.673)  Loss:  1.9785 (1.8089)  Acc@1: 57.0312 (57.7819)  Acc@5: 78.1250 (81.6176)
2024-04-06 02:11:36,537 - train - INFO - Test: [  78/78]  Time: 2.316 (2.658)  Loss:  1.6650 (1.8237)  Acc@1: 62.5000 (57.6300)  Acc@5: 93.7500 (81.2700)
2024-04-06 02:11:40,080 - train - INFO - Train: 10 [   0/781 (  0%)]  Loss:  3.289637 (3.2896)  Time: 3.461s,   36.99/s  (3.461s,   36.99/s)  LR: 4.946e-04  Data: 0.133 (0.133)
2024-04-06 02:14:41,960 - train - INFO - Train: 10 [  50/781 (  6%)]  Loss:  3.834414 (3.8235)  Time: 3.940s,   32.49/s  (3.634s,   35.22/s)  LR: 4.946e-04  Data: 0.005 (0.010)
2024-04-06 02:17:43,464 - train - INFO - Train: 10 [ 100/781 ( 13%)]  Loss:  3.458311 (3.8281)  Time: 3.265s,   39.21/s  (3.632s,   35.24/s)  LR: 4.946e-04  Data: 0.009 (0.008)
2024-04-06 02:20:35,491 - train - INFO - Train: 10 [ 150/781 ( 19%)]  Loss:  4.142838 (3.8375)  Time: 3.259s,   39.27/s  (3.569s,   35.87/s)  LR: 4.946e-04  Data: 0.005 (0.007)
2024-04-06 02:23:28,354 - train - INFO - Train: 10 [ 200/781 ( 26%)]  Loss:  3.445175 (3.8347)  Time: 3.469s,   36.90/s  (3.541s,   36.15/s)  LR: 4.946e-04  Data: 0.007 (0.007)
2024-04-06 02:26:39,259 - train - INFO - Train: 10 [ 250/781 ( 32%)]  Loss:  3.529197 (3.8336)  Time: 4.275s,   29.94/s  (3.596s,   35.59/s)  LR: 4.946e-04  Data: 0.004 (0.007)
2024-04-06 02:29:44,306 - train - INFO - Train: 10 [ 300/781 ( 38%)]  Loss:  3.758607 (3.8403)  Time: 3.302s,   38.77/s  (3.614s,   35.42/s)  LR: 4.946e-04  Data: 0.006 (0.007)
2024-04-06 02:32:45,977 - train - INFO - Train: 10 [ 350/781 ( 45%)]  Loss:  4.358812 (3.8511)  Time: 3.524s,   36.32/s  (3.616s,   35.39/s)  LR: 4.946e-04  Data: 0.006 (0.007)
2024-04-06 02:35:47,844 - train - INFO - Train: 10 [ 400/781 ( 51%)]  Loss:  4.132136 (3.8601)  Time: 4.117s,   31.09/s  (3.619s,   35.37/s)  LR: 4.946e-04  Data: 0.010 (0.007)
2024-04-06 02:38:59,182 - train - INFO - Train: 10 [ 450/781 ( 58%)]  Loss:  3.524594 (3.8652)  Time: 4.023s,   31.82/s  (3.642s,   35.15/s)  LR: 4.946e-04  Data: 0.005 (0.007)
2024-04-06 02:42:00,920 - train - INFO - Train: 10 [ 500/781 ( 64%)]  Loss:  3.274761 (3.8626)  Time: 3.356s,   38.14/s  (3.641s,   35.15/s)  LR: 4.946e-04  Data: 0.005 (0.007)
2024-04-06 02:45:04,424 - train - INFO - Train: 10 [ 550/781 ( 71%)]  Loss:  3.547518 (3.8616)  Time: 3.482s,   36.76/s  (3.644s,   35.13/s)  LR: 4.946e-04  Data: 0.005 (0.007)
2024-04-06 02:48:03,978 - train - INFO - Train: 10 [ 600/781 ( 77%)]  Loss:  3.844115 (3.8575)  Time: 3.604s,   35.52/s  (3.640s,   35.17/s)  LR: 4.946e-04  Data: 0.004 (0.007)
2024-04-06 02:51:14,434 - train - INFO - Train: 10 [ 650/781 ( 83%)]  Loss:  3.625694 (3.8574)  Time: 3.530s,   36.26/s  (3.653s,   35.04/s)  LR: 4.946e-04  Data: 0.014 (0.007)
2024-04-06 02:54:06,480 - train - INFO - Train: 10 [ 700/781 ( 90%)]  Loss:  4.465322 (3.8603)  Time: 3.185s,   40.19/s  (3.637s,   35.19/s)  LR: 4.946e-04  Data: 0.004 (0.007)
2024-04-06 02:57:00,695 - train - INFO - Train: 10 [ 750/781 ( 96%)]  Loss:  3.279315 (3.8616)  Time: 3.591s,   35.64/s  (3.627s,   35.29/s)  LR: 4.946e-04  Data: 0.008 (0.007)
2024-04-06 02:58:45,394 - train - INFO - Train: 10 [ 780/781 (100%)]  Loss:  4.278302 (3.8617)  Time: 3.474s,   36.84/s  (3.622s,   35.34/s)  LR: 4.946e-04  Data: 0.000 (0.007)
2024-04-06 02:58:45,394 - train - INFO - True
2024-04-06 02:58:45,396 - train - INFO - alphas:tensor([0.2990, 0.2500, 0.1302, 0.1551, 0.1656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,396 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,396 - train - INFO - True
2024-04-06 02:58:45,397 - train - INFO - alphas:tensor([0.3489, 0.2027, 0.1199, 0.1536, 0.1749], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,397 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,397 - train - INFO - True
2024-04-06 02:58:45,398 - train - INFO - alphas:tensor([0.6235, 0.1487, 0.0685, 0.0763, 0.0830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,398 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,398 - train - INFO - True
2024-04-06 02:58:45,399 - train - INFO - alphas:tensor([0.6122, 0.1359, 0.0721, 0.0852, 0.0946], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,399 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,399 - train - INFO - True
2024-04-06 02:58:45,400 - train - INFO - alphas:tensor([0.5157, 0.1585, 0.0898, 0.1114, 0.1246], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,400 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,400 - train - INFO - True
2024-04-06 02:58:45,400 - train - INFO - alphas:tensor([0.5943, 0.1445, 0.0749, 0.0872, 0.0991], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,401 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,401 - train - INFO - True
2024-04-06 02:58:45,401 - train - INFO - alphas:tensor([0.6840, 0.1240, 0.0585, 0.0642, 0.0693], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,402 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,402 - train - INFO - True
2024-04-06 02:58:45,402 - train - INFO - alphas:tensor([0.6840, 0.1243, 0.0578, 0.0646, 0.0693], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,402 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,403 - train - INFO - True
2024-04-06 02:58:45,403 - train - INFO - alphas:tensor([0.5659, 0.1361, 0.0802, 0.1015, 0.1164], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,403 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,403 - train - INFO - True
2024-04-06 02:58:45,404 - train - INFO - alphas:tensor([0.6349, 0.1281, 0.0691, 0.0791, 0.0889], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,404 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,404 - train - INFO - True
2024-04-06 02:58:45,405 - train - INFO - alphas:tensor([0.7058, 0.1121, 0.0551, 0.0614, 0.0657], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,405 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,405 - train - INFO - True
2024-04-06 02:58:45,406 - train - INFO - alphas:tensor([0.6674, 0.1248, 0.0619, 0.0681, 0.0778], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,406 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,406 - train - INFO - True
2024-04-06 02:58:45,407 - train - INFO - alphas:tensor([0.5853, 0.1303, 0.0753, 0.0959, 0.1132], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,407 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,407 - train - INFO - True
2024-04-06 02:58:45,408 - train - INFO - alphas:tensor([0.6648, 0.1147, 0.0648, 0.0750, 0.0806], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,408 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,408 - train - INFO - True
2024-04-06 02:58:45,409 - train - INFO - alphas:tensor([0.7008, 0.1203, 0.0548, 0.0597, 0.0644], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,409 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,409 - train - INFO - True
2024-04-06 02:58:45,410 - train - INFO - alphas:tensor([0.6273, 0.1406, 0.0712, 0.0757, 0.0853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,410 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,410 - train - INFO - True
2024-04-06 02:58:45,411 - train - INFO - alphas:tensor([0.5924, 0.1294, 0.0775, 0.0929, 0.1078], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,411 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,411 - train - INFO - True
2024-04-06 02:58:45,412 - train - INFO - alphas:tensor([0.6718, 0.1119, 0.0644, 0.0723, 0.0796], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,412 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,412 - train - INFO - True
2024-04-06 02:58:45,413 - train - INFO - alphas:tensor([0.7246, 0.1072, 0.0538, 0.0554, 0.0591], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,413 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,413 - train - INFO - True
2024-04-06 02:58:45,413 - train - INFO - alphas:tensor([0.6213, 0.1311, 0.0728, 0.0814, 0.0933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,414 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,414 - train - INFO - True
2024-04-06 02:58:45,414 - train - INFO - alphas:tensor([0.5759, 0.1366, 0.0768, 0.0982, 0.1125], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,414 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,415 - train - INFO - True
2024-04-06 02:58:45,415 - train - INFO - alphas:tensor([0.6889, 0.1038, 0.0612, 0.0706, 0.0755], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,415 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,415 - train - INFO - True
2024-04-06 02:58:45,416 - train - INFO - alphas:tensor([0.7447, 0.0996, 0.0483, 0.0519, 0.0556], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,416 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,416 - train - INFO - True
2024-04-06 02:58:45,417 - train - INFO - alphas:tensor([0.6444, 0.1216, 0.0686, 0.0775, 0.0879], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,417 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,417 - train - INFO - True
2024-04-06 02:58:45,418 - train - INFO - alphas:tensor([0.5705, 0.1369, 0.0763, 0.1008, 0.1156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,418 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,418 - train - INFO - True
2024-04-06 02:58:45,419 - train - INFO - alphas:tensor([0.6763, 0.1077, 0.0642, 0.0719, 0.0800], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,419 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,419 - train - INFO - True
2024-04-06 02:58:45,420 - train - INFO - alphas:tensor([0.7318, 0.0993, 0.0500, 0.0571, 0.0618], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,420 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,420 - train - INFO - True
2024-04-06 02:58:45,421 - train - INFO - alphas:tensor([0.6644, 0.1154, 0.0650, 0.0745, 0.0807], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,421 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,421 - train - INFO - True
2024-04-06 02:58:45,422 - train - INFO - alphas:tensor([0.5511, 0.1337, 0.0834, 0.1062, 0.1256], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,422 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,422 - train - INFO - True
2024-04-06 02:58:45,423 - train - INFO - alphas:tensor([0.6704, 0.1065, 0.0643, 0.0745, 0.0844], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,423 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,423 - train - INFO - True
2024-04-06 02:58:45,424 - train - INFO - alphas:tensor([0.7109, 0.1005, 0.0560, 0.0636, 0.0691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,424 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,424 - train - INFO - True
2024-04-06 02:58:45,424 - train - INFO - alphas:tensor([0.6709, 0.1117, 0.0661, 0.0729, 0.0784], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,425 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,425 - train - INFO - True
2024-04-06 02:58:45,425 - train - INFO - alphas:tensor([0.5275, 0.1389, 0.0822, 0.1154, 0.1360], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,426 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,426 - train - INFO - True
2024-04-06 02:58:45,426 - train - INFO - alphas:tensor([0.6365, 0.1167, 0.0716, 0.0834, 0.0918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,426 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,427 - train - INFO - True
2024-04-06 02:58:45,427 - train - INFO - alphas:tensor([0.6874, 0.1069, 0.0580, 0.0694, 0.0783], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,427 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,427 - train - INFO - True
2024-04-06 02:58:45,428 - train - INFO - alphas:tensor([0.6456, 0.1198, 0.0687, 0.0794, 0.0865], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,428 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,428 - train - INFO - True
2024-04-06 02:58:45,429 - train - INFO - alphas:tensor([0.6148, 0.1115, 0.1260, 0.1477], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 02:58:45,429 - train - INFO - tau:0.92274469442792
2024-04-06 02:58:45,429 - train - INFO - avg block size:1.0
2024-04-06 02:58:47,989 - train - INFO - Test: [   0/78]  Time: 2.551 (2.551)  Loss:  1.0361 (1.0361)  Acc@1: 78.1250 (78.1250)  Acc@5: 91.4062 (91.4062)
2024-04-06 03:01:01,867 - train - INFO - Test: [  50/78]  Time: 2.939 (2.675)  Loss:  1.9902 (1.7872)  Acc@1: 50.7812 (57.7512)  Acc@5: 82.0312 (81.6483)
2024-04-06 03:02:28,415 - train - INFO - Test: [  78/78]  Time: 3.341 (2.823)  Loss:  1.7852 (1.8263)  Acc@1: 62.5000 (56.8600)  Acc@5: 100.0000 (81.2000)
2024-04-06 03:02:32,924 - train - INFO - Train: 11 [   0/781 (  0%)]  Loss:  4.367908 (4.3679)  Time: 4.428s,   28.91/s  (4.428s,   28.91/s)  LR: 4.935e-04  Data: 0.137 (0.137)
2024-04-06 03:05:41,620 - train - INFO - Train: 11 [  50/781 (  6%)]  Loss:  3.627400 (3.8881)  Time: 3.433s,   37.29/s  (3.787s,   33.80/s)  LR: 4.935e-04  Data: 0.004 (0.009)
2024-04-06 03:08:42,916 - train - INFO - Train: 11 [ 100/781 ( 13%)]  Loss:  3.566441 (3.8541)  Time: 3.428s,   37.33/s  (3.707s,   34.53/s)  LR: 4.935e-04  Data: 0.005 (0.008)
2024-04-06 03:11:46,426 - train - INFO - Train: 11 [ 150/781 ( 19%)]  Loss:  4.313818 (3.8403)  Time: 3.418s,   37.44/s  (3.695s,   34.64/s)  LR: 4.935e-04  Data: 0.005 (0.008)
2024-04-06 03:15:01,725 - train - INFO - Train: 11 [ 200/781 ( 26%)]  Loss:  3.786896 (3.8536)  Time: 4.319s,   29.64/s  (3.747s,   34.16/s)  LR: 4.935e-04  Data: 0.007 (0.008)
2024-04-06 03:18:06,748 - train - INFO - Train: 11 [ 250/781 ( 32%)]  Loss:  3.425670 (3.8406)  Time: 3.396s,   37.69/s  (3.738s,   34.24/s)  LR: 4.935e-04  Data: 0.004 (0.008)
2024-04-06 03:21:09,997 - train - INFO - Train: 11 [ 300/781 ( 38%)]  Loss:  4.362849 (3.8501)  Time: 3.562s,   35.93/s  (3.726s,   34.35/s)  LR: 4.935e-04  Data: 0.005 (0.007)
2024-04-06 03:24:11,060 - train - INFO - Train: 11 [ 350/781 ( 45%)]  Loss:  3.653724 (3.8477)  Time: 4.116s,   31.10/s  (3.711s,   34.49/s)  LR: 4.935e-04  Data: 0.011 (0.007)
2024-04-06 03:27:17,861 - train - INFO - Train: 11 [ 400/781 ( 51%)]  Loss:  3.598571 (3.8526)  Time: 3.815s,   33.55/s  (3.714s,   34.46/s)  LR: 4.935e-04  Data: 0.004 (0.007)
2024-04-06 03:30:08,021 - train - INFO - Train: 11 [ 450/781 ( 58%)]  Loss:  3.750959 (3.8474)  Time: 3.094s,   41.37/s  (3.680s,   34.79/s)  LR: 4.935e-04  Data: 0.004 (0.007)
2024-04-06 03:32:48,813 - train - INFO - Train: 11 [ 500/781 ( 64%)]  Loss:  4.045934 (3.8553)  Time: 3.491s,   36.66/s  (3.633s,   35.23/s)  LR: 4.935e-04  Data: 0.008 (0.007)
2024-04-06 03:35:30,218 - train - INFO - Train: 11 [ 550/781 ( 71%)]  Loss:  3.635484 (3.8527)  Time: 3.315s,   38.61/s  (3.597s,   35.59/s)  LR: 4.935e-04  Data: 0.008 (0.007)
2024-04-06 03:38:19,846 - train - INFO - Train: 11 [ 600/781 ( 77%)]  Loss:  3.847831 (3.8507)  Time: 3.189s,   40.14/s  (3.580s,   35.76/s)  LR: 4.935e-04  Data: 0.008 (0.007)
2024-04-06 03:41:01,795 - train - INFO - Train: 11 [ 650/781 ( 83%)]  Loss:  3.931175 (3.8489)  Time: 3.443s,   37.18/s  (3.553s,   36.02/s)  LR: 4.935e-04  Data: 0.009 (0.007)
2024-04-06 03:43:41,402 - train - INFO - Train: 11 [ 700/781 ( 90%)]  Loss:  3.811083 (3.8466)  Time: 3.527s,   36.29/s  (3.528s,   36.28/s)  LR: 4.935e-04  Data: 0.010 (0.007)
2024-04-06 03:46:22,682 - train - INFO - Train: 11 [ 750/781 ( 96%)]  Loss:  4.054505 (3.8436)  Time: 3.025s,   42.32/s  (3.508s,   36.49/s)  LR: 4.935e-04  Data: 0.008 (0.007)
2024-04-06 03:48:00,637 - train - INFO - Train: 11 [ 780/781 (100%)]  Loss:  4.294916 (3.8422)  Time: 3.663s,   34.94/s  (3.498s,   36.59/s)  LR: 4.935e-04  Data: 0.000 (0.007)
2024-04-06 03:48:00,637 - train - INFO - True
2024-04-06 03:48:00,639 - train - INFO - alphas:tensor([0.3061, 0.2477, 0.1266, 0.1539, 0.1657], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,639 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,639 - train - INFO - True
2024-04-06 03:48:00,640 - train - INFO - alphas:tensor([0.3637, 0.1918, 0.1152, 0.1524, 0.1768], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,640 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,640 - train - INFO - True
2024-04-06 03:48:00,641 - train - INFO - alphas:tensor([0.6450, 0.1377, 0.0648, 0.0728, 0.0796], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,641 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,641 - train - INFO - True
2024-04-06 03:48:00,642 - train - INFO - alphas:tensor([0.6349, 0.1250, 0.0675, 0.0813, 0.0912], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,642 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,642 - train - INFO - True
2024-04-06 03:48:00,643 - train - INFO - alphas:tensor([0.5313, 0.1461, 0.0867, 0.1104, 0.1255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,643 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,643 - train - INFO - True
2024-04-06 03:48:00,644 - train - INFO - alphas:tensor([0.6187, 0.1327, 0.0699, 0.0831, 0.0956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,644 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,644 - train - INFO - True
2024-04-06 03:48:00,645 - train - INFO - alphas:tensor([0.7109, 0.1108, 0.0536, 0.0597, 0.0651], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,645 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,645 - train - INFO - True
2024-04-06 03:48:00,646 - train - INFO - alphas:tensor([0.7150, 0.1108, 0.0517, 0.0588, 0.0637], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,646 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,646 - train - INFO - True
2024-04-06 03:48:00,647 - train - INFO - alphas:tensor([0.5799, 0.1251, 0.0772, 0.1007, 0.1171], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,647 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,647 - train - INFO - True
2024-04-06 03:48:00,647 - train - INFO - alphas:tensor([0.6549, 0.1183, 0.0651, 0.0758, 0.0860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,648 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,648 - train - INFO - True
2024-04-06 03:48:00,648 - train - INFO - alphas:tensor([0.7234, 0.1031, 0.0518, 0.0584, 0.0633], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,649 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,649 - train - INFO - True
2024-04-06 03:48:00,649 - train - INFO - alphas:tensor([0.6896, 0.1138, 0.0574, 0.0646, 0.0746], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,649 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,650 - train - INFO - True
2024-04-06 03:48:00,650 - train - INFO - alphas:tensor([0.5976, 0.1202, 0.0725, 0.0951, 0.1147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,650 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,650 - train - INFO - True
2024-04-06 03:48:00,651 - train - INFO - alphas:tensor([0.6842, 0.1057, 0.0607, 0.0715, 0.0779], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,651 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,651 - train - INFO - True
2024-04-06 03:48:00,652 - train - INFO - alphas:tensor([0.7213, 0.1098, 0.0508, 0.0563, 0.0618], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,652 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,652 - train - INFO - True
2024-04-06 03:48:00,653 - train - INFO - alphas:tensor([0.6481, 0.1286, 0.0666, 0.0730, 0.0837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,653 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,653 - train - INFO - True
2024-04-06 03:48:00,654 - train - INFO - alphas:tensor([0.6056, 0.1190, 0.0743, 0.0919, 0.1091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,654 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,654 - train - INFO - True
2024-04-06 03:48:00,655 - train - INFO - alphas:tensor([0.6921, 0.1026, 0.0600, 0.0686, 0.0768], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,655 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,655 - train - INFO - True
2024-04-06 03:48:00,656 - train - INFO - alphas:tensor([0.7428, 0.0982, 0.0501, 0.0524, 0.0566], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,656 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,656 - train - INFO - True
2024-04-06 03:48:00,657 - train - INFO - alphas:tensor([0.6397, 0.1205, 0.0683, 0.0787, 0.0927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,657 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,657 - train - INFO - True
2024-04-06 03:48:00,658 - train - INFO - alphas:tensor([0.5909, 0.1244, 0.0738, 0.0973, 0.1136], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,658 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,658 - train - INFO - True
2024-04-06 03:48:00,659 - train - INFO - alphas:tensor([0.7111, 0.0940, 0.0564, 0.0664, 0.0720], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,659 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,659 - train - INFO - True
2024-04-06 03:48:00,660 - train - INFO - alphas:tensor([0.7624, 0.0907, 0.0447, 0.0489, 0.0533], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,660 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,660 - train - INFO - True
2024-04-06 03:48:00,660 - train - INFO - alphas:tensor([0.6667, 0.1098, 0.0633, 0.0739, 0.0863], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,661 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,661 - train - INFO - True
2024-04-06 03:48:00,661 - train - INFO - alphas:tensor([0.5870, 0.1236, 0.0730, 0.0996, 0.1168], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,661 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,662 - train - INFO - True
2024-04-06 03:48:00,662 - train - INFO - alphas:tensor([0.7002, 0.0972, 0.0589, 0.0673, 0.0763], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,662 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,662 - train - INFO - True
2024-04-06 03:48:00,663 - train - INFO - alphas:tensor([0.7501, 0.0897, 0.0462, 0.0542, 0.0597], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,663 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,663 - train - INFO - True
2024-04-06 03:48:00,664 - train - INFO - alphas:tensor([0.6838, 0.1056, 0.0603, 0.0712, 0.0791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,664 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,664 - train - INFO - True
2024-04-06 03:48:00,665 - train - INFO - alphas:tensor([0.5669, 0.1197, 0.0801, 0.1056, 0.1277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,665 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,665 - train - INFO - True
2024-04-06 03:48:00,666 - train - INFO - alphas:tensor([0.6926, 0.0966, 0.0592, 0.0704, 0.0812], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,666 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,666 - train - INFO - True
2024-04-06 03:48:00,667 - train - INFO - alphas:tensor([0.7256, 0.0913, 0.0528, 0.0618, 0.0686], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,667 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,667 - train - INFO - True
2024-04-06 03:48:00,668 - train - INFO - alphas:tensor([0.6931, 0.1004, 0.0607, 0.0694, 0.0763], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,668 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,668 - train - INFO - True
2024-04-06 03:48:00,669 - train - INFO - alphas:tensor([0.5428, 0.1240, 0.0788, 0.1150, 0.1393], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,669 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,669 - train - INFO - True
2024-04-06 03:48:00,670 - train - INFO - alphas:tensor([0.6598, 0.1056, 0.0660, 0.0794, 0.0892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,670 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,670 - train - INFO - True
2024-04-06 03:48:00,671 - train - INFO - alphas:tensor([0.7001, 0.0986, 0.0552, 0.0680, 0.0782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,671 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,671 - train - INFO - True
2024-04-06 03:48:00,671 - train - INFO - alphas:tensor([0.6673, 0.1080, 0.0639, 0.0761, 0.0847], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,672 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,672 - train - INFO - True
2024-04-06 03:48:00,672 - train - INFO - alphas:tensor([0.6294, 0.1054, 0.1212, 0.1440], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 03:48:00,672 - train - INFO - tau:0.9135172474836407
2024-04-06 03:48:00,673 - train - INFO - avg block size:1.0
2024-04-06 03:48:03,423 - train - INFO - Test: [   0/78]  Time: 2.743 (2.743)  Loss:  0.9375 (0.9375)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-06 03:50:06,236 - train - INFO - Test: [  50/78]  Time: 2.119 (2.462)  Loss:  1.8809 (1.7364)  Acc@1: 53.9062 (59.4822)  Acc@5: 80.4688 (82.7359)
2024-04-06 03:51:09,849 - train - INFO - Test: [  78/78]  Time: 2.380 (2.395)  Loss:  1.7344 (1.7701)  Acc@1: 50.0000 (58.5300)  Acc@5: 87.5000 (82.0800)
2024-04-06 03:51:13,260 - train - INFO - Train: 12 [   0/781 (  0%)]  Loss:  3.378181 (3.3782)  Time: 3.323s,   38.51/s  (3.323s,   38.51/s)  LR: 4.923e-04  Data: 0.135 (0.135)
2024-04-06 03:53:54,698 - train - INFO - Train: 12 [  50/781 (  6%)]  Loss:  4.207656 (3.9611)  Time: 3.077s,   41.60/s  (3.231s,   39.62/s)  LR: 4.923e-04  Data: 0.010 (0.009)
2024-04-06 03:56:38,575 - train - INFO - Train: 12 [ 100/781 ( 13%)]  Loss:  3.964969 (3.9234)  Time: 3.269s,   39.16/s  (3.254s,   39.34/s)  LR: 4.923e-04  Data: 0.005 (0.008)
2024-04-06 03:59:20,745 - train - INFO - Train: 12 [ 150/781 ( 19%)]  Loss:  4.202744 (3.8928)  Time: 3.616s,   35.40/s  (3.250s,   39.38/s)  LR: 4.923e-04  Data: 0.004 (0.007)
2024-04-06 04:02:06,235 - train - INFO - Train: 12 [ 200/781 ( 26%)]  Loss:  3.885733 (3.8892)  Time: 3.054s,   41.91/s  (3.265s,   39.20/s)  LR: 4.923e-04  Data: 0.005 (0.007)
2024-04-06 04:04:46,235 - train - INFO - Train: 12 [ 250/781 ( 32%)]  Loss:  3.668768 (3.8892)  Time: 3.465s,   36.94/s  (3.252s,   39.36/s)  LR: 4.923e-04  Data: 0.008 (0.007)
2024-04-06 04:07:26,828 - train - INFO - Train: 12 [ 300/781 ( 38%)]  Loss:  3.578565 (3.8797)  Time: 3.280s,   39.03/s  (3.245s,   39.44/s)  LR: 4.923e-04  Data: 0.009 (0.007)
2024-04-06 04:10:11,670 - train - INFO - Train: 12 [ 350/781 ( 45%)]  Loss:  3.656194 (3.8709)  Time: 3.725s,   34.37/s  (3.253s,   39.35/s)  LR: 4.923e-04  Data: 0.004 (0.007)
2024-04-06 04:12:59,211 - train - INFO - Train: 12 [ 400/781 ( 51%)]  Loss:  3.611271 (3.8686)  Time: 2.967s,   43.14/s  (3.265s,   39.20/s)  LR: 4.923e-04  Data: 0.005 (0.007)
2024-04-06 04:15:38,846 - train - INFO - Train: 12 [ 450/781 ( 58%)]  Loss:  3.510736 (3.8719)  Time: 3.250s,   39.39/s  (3.257s,   39.30/s)  LR: 4.923e-04  Data: 0.008 (0.007)
2024-04-06 04:18:18,037 - train - INFO - Train: 12 [ 500/781 ( 64%)]  Loss:  4.225279 (3.8688)  Time: 3.085s,   41.49/s  (3.250s,   39.39/s)  LR: 4.923e-04  Data: 0.008 (0.007)
2024-04-06 04:21:01,259 - train - INFO - Train: 12 [ 550/781 ( 71%)]  Loss:  3.220673 (3.8598)  Time: 3.506s,   36.51/s  (3.251s,   39.37/s)  LR: 4.923e-04  Data: 0.005 (0.007)
2024-04-06 04:23:48,903 - train - INFO - Train: 12 [ 600/781 ( 77%)]  Loss:  3.522469 (3.8571)  Time: 3.325s,   38.50/s  (3.259s,   39.27/s)  LR: 4.923e-04  Data: 0.007 (0.007)
2024-04-06 04:26:30,005 - train - INFO - Train: 12 [ 650/781 ( 83%)]  Loss:  3.374480 (3.8541)  Time: 3.118s,   41.05/s  (3.257s,   39.30/s)  LR: 4.923e-04  Data: 0.004 (0.007)
2024-04-06 04:29:11,185 - train - INFO - Train: 12 [ 700/781 ( 90%)]  Loss:  4.040805 (3.8550)  Time: 3.157s,   40.55/s  (3.254s,   39.33/s)  LR: 4.923e-04  Data: 0.007 (0.007)
2024-04-06 04:31:53,195 - train - INFO - Train: 12 [ 750/781 ( 96%)]  Loss:  3.260405 (3.8504)  Time: 3.553s,   36.03/s  (3.253s,   39.34/s)  LR: 4.923e-04  Data: 0.006 (0.007)
2024-04-06 04:33:36,108 - train - INFO - Train: 12 [ 780/781 (100%)]  Loss:  3.799119 (3.8541)  Time: 3.056s,   41.89/s  (3.260s,   39.26/s)  LR: 4.923e-04  Data: 0.000 (0.007)
2024-04-06 04:33:36,109 - train - INFO - True
2024-04-06 04:33:36,110 - train - INFO - alphas:tensor([0.3113, 0.2440, 0.1241, 0.1537, 0.1669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,110 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,110 - train - INFO - True
2024-04-06 04:33:36,111 - train - INFO - alphas:tensor([0.3752, 0.1821, 0.1114, 0.1518, 0.1795], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,111 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,111 - train - INFO - True
2024-04-06 04:33:36,112 - train - INFO - alphas:tensor([0.6653, 0.1278, 0.0612, 0.0693, 0.0764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,112 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,112 - train - INFO - True
2024-04-06 04:33:36,113 - train - INFO - alphas:tensor([0.6551, 0.1159, 0.0634, 0.0776, 0.0879], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,113 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,113 - train - INFO - True
2024-04-06 04:33:36,114 - train - INFO - alphas:tensor([0.5445, 0.1352, 0.0840, 0.1097, 0.1265], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,114 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,114 - train - INFO - True
2024-04-06 04:33:36,115 - train - INFO - alphas:tensor([0.6393, 0.1236, 0.0657, 0.0792, 0.0922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,115 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,115 - train - INFO - True
2024-04-06 04:33:36,116 - train - INFO - alphas:tensor([0.7298, 0.1014, 0.0502, 0.0565, 0.0622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,116 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,116 - train - INFO - True
2024-04-06 04:33:36,117 - train - INFO - alphas:tensor([0.7366, 0.1013, 0.0473, 0.0547, 0.0601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,117 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,117 - train - INFO - True
2024-04-06 04:33:36,118 - train - INFO - alphas:tensor([0.5921, 0.1159, 0.0746, 0.0997, 0.1177], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,118 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,118 - train - INFO - True
2024-04-06 04:33:36,118 - train - INFO - alphas:tensor([0.6727, 0.1100, 0.0614, 0.0726, 0.0833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,119 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,119 - train - INFO - True
2024-04-06 04:33:36,119 - train - INFO - alphas:tensor([0.7410, 0.0941, 0.0486, 0.0556, 0.0608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,119 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,120 - train - INFO - True
2024-04-06 04:33:36,120 - train - INFO - alphas:tensor([0.7106, 0.1035, 0.0532, 0.0610, 0.0717], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,120 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,120 - train - INFO - True
2024-04-06 04:33:36,121 - train - INFO - alphas:tensor([0.6083, 0.1114, 0.0701, 0.0943, 0.1158], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,121 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,121 - train - INFO - True
2024-04-06 04:33:36,122 - train - INFO - alphas:tensor([0.7012, 0.0979, 0.0568, 0.0684, 0.0757], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,122 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,122 - train - INFO - True
2024-04-06 04:33:36,123 - train - INFO - alphas:tensor([0.7354, 0.1026, 0.0477, 0.0542, 0.0601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,123 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,123 - train - INFO - True
2024-04-06 04:33:36,124 - train - INFO - alphas:tensor([0.6636, 0.1194, 0.0626, 0.0711, 0.0833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,124 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,124 - train - INFO - True
2024-04-06 04:33:36,125 - train - INFO - alphas:tensor([0.6173, 0.1095, 0.0716, 0.0913, 0.1102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,125 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,125 - train - INFO - True
2024-04-06 04:33:36,126 - train - INFO - alphas:tensor([0.7078, 0.0957, 0.0561, 0.0657, 0.0746], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,126 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,126 - train - INFO - True
2024-04-06 04:33:36,127 - train - INFO - alphas:tensor([0.7571, 0.0910, 0.0470, 0.0500, 0.0548], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,127 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,127 - train - INFO - True
2024-04-06 04:33:36,128 - train - INFO - alphas:tensor([0.6560, 0.1107, 0.0639, 0.0767, 0.0927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,128 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,128 - train - INFO - True
2024-04-06 04:33:36,128 - train - INFO - alphas:tensor([0.6024, 0.1151, 0.0715, 0.0964, 0.1147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,129 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,129 - train - INFO - True
2024-04-06 04:33:36,129 - train - INFO - alphas:tensor([0.7269, 0.0877, 0.0529, 0.0629, 0.0696], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,129 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,130 - train - INFO - True
2024-04-06 04:33:36,130 - train - INFO - alphas:tensor([0.7733, 0.0846, 0.0425, 0.0474, 0.0523], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,130 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,130 - train - INFO - True
2024-04-06 04:33:36,131 - train - INFO - alphas:tensor([0.6788, 0.1024, 0.0597, 0.0725, 0.0866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,131 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,131 - train - INFO - True
2024-04-06 04:33:36,132 - train - INFO - alphas:tensor([0.5970, 0.1140, 0.0708, 0.0994, 0.1188], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,132 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,132 - train - INFO - True
2024-04-06 04:33:36,133 - train - INFO - alphas:tensor([0.7160, 0.0897, 0.0556, 0.0646, 0.0741], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,133 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,133 - train - INFO - True
2024-04-06 04:33:36,134 - train - INFO - alphas:tensor([0.7614, 0.0831, 0.0439, 0.0526, 0.0591], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,134 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,134 - train - INFO - True
2024-04-06 04:33:36,135 - train - INFO - alphas:tensor([0.6978, 0.0967, 0.0567, 0.0694, 0.0794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,135 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,135 - train - INFO - True
2024-04-06 04:33:36,136 - train - INFO - alphas:tensor([0.5782, 0.1096, 0.0773, 0.1051, 0.1298], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,136 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,136 - train - INFO - True
2024-04-06 04:33:36,137 - train - INFO - alphas:tensor([0.7095, 0.0890, 0.0556, 0.0670, 0.0788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,137 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,137 - train - INFO - True
2024-04-06 04:33:36,138 - train - INFO - alphas:tensor([0.7385, 0.0838, 0.0500, 0.0598, 0.0679], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,138 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,138 - train - INFO - True
2024-04-06 04:33:36,138 - train - INFO - alphas:tensor([0.7088, 0.0923, 0.0568, 0.0668, 0.0753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,139 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,139 - train - INFO - True
2024-04-06 04:33:36,139 - train - INFO - alphas:tensor([0.5564, 0.1125, 0.0756, 0.1140, 0.1416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,139 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,139 - train - INFO - True
2024-04-06 04:33:36,140 - train - INFO - alphas:tensor([0.6764, 0.0971, 0.0623, 0.0765, 0.0877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,140 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,140 - train - INFO - True
2024-04-06 04:33:36,141 - train - INFO - alphas:tensor([0.7114, 0.0904, 0.0526, 0.0667, 0.0788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,141 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,141 - train - INFO - True
2024-04-06 04:33:36,142 - train - INFO - alphas:tensor([0.6820, 0.1001, 0.0601, 0.0739, 0.0838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,142 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,142 - train - INFO - True
2024-04-06 04:33:36,143 - train - INFO - alphas:tensor([0.6401, 0.1007, 0.1176, 0.1416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 04:33:36,143 - train - INFO - tau:0.9043820750088043
2024-04-06 04:33:36,143 - train - INFO - avg block size:1.0
2024-04-06 04:33:36,143 - train - INFO - lasso_alpha:1.3310000000000005e-05
2024-04-06 04:33:38,260 - train - INFO - Test: [   0/78]  Time: 2.108 (2.108)  Loss:  1.0703 (1.0703)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.1875 (92.1875)
2024-04-06 04:35:29,709 - train - INFO - Test: [  50/78]  Time: 2.318 (2.227)  Loss:  1.7227 (1.7549)  Acc@1: 54.6875 (58.8848)  Acc@5: 83.5938 (82.0159)
2024-04-06 04:36:32,444 - train - INFO - Test: [  78/78]  Time: 2.158 (2.232)  Loss:  1.8398 (1.7824)  Acc@1: 56.2500 (58.3400)  Acc@5: 87.5000 (81.5200)
2024-04-06 04:36:35,663 - train - INFO - Train: 13 [   0/781 (  0%)]  Loss:  3.849432 (3.8494)  Time: 3.134s,   40.84/s  (3.134s,   40.84/s)  LR: 4.910e-04  Data: 0.136 (0.136)
2024-04-06 04:39:17,359 - train - INFO - Train: 13 [  50/781 (  6%)]  Loss:  4.269217 (3.8376)  Time: 3.396s,   37.69/s  (3.232s,   39.60/s)  LR: 4.910e-04  Data: 0.008 (0.010)
2024-04-06 04:41:58,256 - train - INFO - Train: 13 [ 100/781 ( 13%)]  Loss:  3.971532 (3.8718)  Time: 3.465s,   36.94/s  (3.225s,   39.69/s)  LR: 4.910e-04  Data: 0.006 (0.008)
2024-04-06 04:44:48,179 - train - INFO - Train: 13 [ 150/781 ( 19%)]  Loss:  3.533423 (3.8737)  Time: 3.148s,   40.66/s  (3.282s,   39.00/s)  LR: 4.910e-04  Data: 0.005 (0.007)
2024-04-06 04:47:29,962 - train - INFO - Train: 13 [ 200/781 ( 26%)]  Loss:  3.366020 (3.8474)  Time: 3.299s,   38.80/s  (3.271s,   39.13/s)  LR: 4.910e-04  Data: 0.005 (0.007)
2024-04-06 04:50:09,562 - train - INFO - Train: 13 [ 250/781 ( 32%)]  Loss:  4.344420 (3.8413)  Time: 3.390s,   37.76/s  (3.255s,   39.32/s)  LR: 4.910e-04  Data: 0.006 (0.007)
2024-04-06 04:52:51,690 - train - INFO - Train: 13 [ 300/781 ( 38%)]  Loss:  3.518386 (3.8403)  Time: 3.369s,   38.00/s  (3.253s,   39.35/s)  LR: 4.910e-04  Data: 0.009 (0.007)
2024-04-06 04:55:40,464 - train - INFO - Train: 13 [ 350/781 ( 45%)]  Loss:  4.133037 (3.8318)  Time: 3.484s,   36.73/s  (3.270s,   39.14/s)  LR: 4.910e-04  Data: 0.008 (0.007)
2024-04-06 04:58:21,557 - train - INFO - Train: 13 [ 400/781 ( 51%)]  Loss:  3.642618 (3.8253)  Time: 3.124s,   40.97/s  (3.264s,   39.21/s)  LR: 4.910e-04  Data: 0.005 (0.007)
2024-04-06 05:01:03,594 - train - INFO - Train: 13 [ 450/781 ( 58%)]  Loss:  3.822987 (3.8279)  Time: 3.269s,   39.16/s  (3.262s,   39.24/s)  LR: 4.910e-04  Data: 0.004 (0.007)
2024-04-06 05:03:44,171 - train - INFO - Train: 13 [ 500/781 ( 64%)]  Loss:  3.320307 (3.8275)  Time: 3.343s,   38.28/s  (3.257s,   39.30/s)  LR: 4.910e-04  Data: 0.012 (0.007)
2024-04-06 05:06:31,421 - train - INFO - Train: 13 [ 550/781 ( 71%)]  Loss:  3.311463 (3.8309)  Time: 3.439s,   37.22/s  (3.265s,   39.21/s)  LR: 4.910e-04  Data: 0.008 (0.007)
2024-04-06 05:09:10,906 - train - INFO - Train: 13 [ 600/781 ( 77%)]  Loss:  3.658498 (3.8328)  Time: 3.391s,   37.75/s  (3.258s,   39.28/s)  LR: 4.910e-04  Data: 0.005 (0.007)
2024-04-06 05:11:51,865 - train - INFO - Train: 13 [ 650/781 ( 83%)]  Loss:  3.319887 (3.8315)  Time: 3.518s,   36.38/s  (3.255s,   39.32/s)  LR: 4.910e-04  Data: 0.008 (0.007)
2024-04-06 05:14:31,483 - train - INFO - Train: 13 [ 700/781 ( 90%)]  Loss:  4.376438 (3.8292)  Time: 3.131s,   40.88/s  (3.251s,   39.37/s)  LR: 4.910e-04  Data: 0.004 (0.007)
2024-04-06 05:17:20,562 - train - INFO - Train: 13 [ 750/781 ( 96%)]  Loss:  3.799387 (3.8335)  Time: 3.051s,   41.95/s  (3.260s,   39.27/s)  LR: 4.910e-04  Data: 0.004 (0.007)
2024-04-06 05:18:57,134 - train - INFO - Train: 13 [ 780/781 (100%)]  Loss:  3.091240 (3.8366)  Time: 2.962s,   43.21/s  (3.258s,   39.29/s)  LR: 4.910e-04  Data: 0.000 (0.007)
2024-04-06 05:18:57,135 - train - INFO - True
2024-04-06 05:18:57,136 - train - INFO - alphas:tensor([0.3165, 0.2395, 0.1221, 0.1537, 0.1682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,136 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,136 - train - INFO - True
2024-04-06 05:18:57,137 - train - INFO - alphas:tensor([0.3850, 0.1709, 0.1086, 0.1523, 0.1832], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,137 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,137 - train - INFO - True
2024-04-06 05:18:57,137 - train - INFO - alphas:tensor([0.6796, 0.1208, 0.0587, 0.0668, 0.0741], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,138 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,138 - train - INFO - True
2024-04-06 05:18:57,138 - train - INFO - alphas:tensor([0.6716, 0.1079, 0.0600, 0.0748, 0.0857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,138 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,138 - train - INFO - True
2024-04-06 05:18:57,139 - train - INFO - alphas:tensor([0.5524, 0.1278, 0.0822, 0.1095, 0.1281], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,139 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,139 - train - INFO - True
2024-04-06 05:18:57,140 - train - INFO - alphas:tensor([0.6536, 0.1166, 0.0627, 0.0768, 0.0903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,140 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,140 - train - INFO - True
2024-04-06 05:18:57,141 - train - INFO - alphas:tensor([0.7441, 0.0945, 0.0475, 0.0540, 0.0599], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,141 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,141 - train - INFO - True
2024-04-06 05:18:57,142 - train - INFO - alphas:tensor([0.7554, 0.0932, 0.0434, 0.0512, 0.0568], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,142 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,142 - train - INFO - True
2024-04-06 05:18:57,142 - train - INFO - alphas:tensor([0.5991, 0.1093, 0.0728, 0.0995, 0.1193], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,143 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,143 - train - INFO - True
2024-04-06 05:18:57,143 - train - INFO - alphas:tensor([0.6857, 0.1036, 0.0584, 0.0704, 0.0818], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,143 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,143 - train - INFO - True
2024-04-06 05:18:57,144 - train - INFO - alphas:tensor([0.7497, 0.0889, 0.0468, 0.0545, 0.0602], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,144 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,144 - train - INFO - True
2024-04-06 05:18:57,145 - train - INFO - alphas:tensor([0.7242, 0.0967, 0.0500, 0.0589, 0.0703], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,145 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,145 - train - INFO - True
2024-04-06 05:18:57,146 - train - INFO - alphas:tensor([0.6193, 0.1027, 0.0677, 0.0934, 0.1169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,146 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,146 - train - INFO - True
2024-04-06 05:18:57,147 - train - INFO - alphas:tensor([0.7108, 0.0928, 0.0548, 0.0668, 0.0748], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,147 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,147 - train - INFO - True
2024-04-06 05:18:57,147 - train - INFO - alphas:tensor([0.7469, 0.0958, 0.0452, 0.0528, 0.0594], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,148 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,148 - train - INFO - True
2024-04-06 05:18:57,148 - train - INFO - alphas:tensor([0.6792, 0.1100, 0.0589, 0.0691, 0.0827], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,148 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,148 - train - INFO - True
2024-04-06 05:18:57,149 - train - INFO - alphas:tensor([0.6244, 0.1023, 0.0700, 0.0912, 0.1120], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,149 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,149 - train - INFO - True
2024-04-06 05:18:57,150 - train - INFO - alphas:tensor([0.7188, 0.0899, 0.0538, 0.0639, 0.0736], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,150 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,150 - train - INFO - True
2024-04-06 05:18:57,151 - train - INFO - alphas:tensor([0.7675, 0.0853, 0.0448, 0.0485, 0.0540], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,151 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,151 - train - INFO - True
2024-04-06 05:18:57,152 - train - INFO - alphas:tensor([0.6657, 0.1041, 0.0610, 0.0755, 0.0937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,152 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,152 - train - INFO - True
2024-04-06 05:18:57,152 - train - INFO - alphas:tensor([0.6098, 0.1075, 0.0696, 0.0964, 0.1168], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,153 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,153 - train - INFO - True
2024-04-06 05:18:57,153 - train - INFO - alphas:tensor([0.7378, 0.0826, 0.0504, 0.0611, 0.0681], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,153 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,153 - train - INFO - True
2024-04-06 05:18:57,154 - train - INFO - alphas:tensor([0.7789, 0.0804, 0.0412, 0.0469, 0.0526], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,154 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,154 - train - INFO - True
2024-04-06 05:18:57,155 - train - INFO - alphas:tensor([0.6858, 0.0965, 0.0571, 0.0720, 0.0886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,155 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,155 - train - INFO - True
2024-04-06 05:18:57,156 - train - INFO - alphas:tensor([0.6051, 0.1062, 0.0687, 0.0992, 0.1208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,156 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,156 - train - INFO - True
2024-04-06 05:18:57,157 - train - INFO - alphas:tensor([0.7311, 0.0825, 0.0521, 0.0621, 0.0723], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,157 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,157 - train - INFO - True
2024-04-06 05:18:57,157 - train - INFO - alphas:tensor([0.7661, 0.0792, 0.0425, 0.0523, 0.0599], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,157 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,158 - train - INFO - True
2024-04-06 05:18:57,158 - train - INFO - alphas:tensor([0.7079, 0.0900, 0.0535, 0.0681, 0.0805], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,158 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,158 - train - INFO - True
2024-04-06 05:18:57,159 - train - INFO - alphas:tensor([0.5822, 0.1023, 0.0760, 0.1059, 0.1336], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,159 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,159 - train - INFO - True
2024-04-06 05:18:57,160 - train - INFO - alphas:tensor([0.7203, 0.0835, 0.0529, 0.0653, 0.0781], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,160 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,160 - train - INFO - True
2024-04-06 05:18:57,161 - train - INFO - alphas:tensor([0.7433, 0.0791, 0.0485, 0.0598, 0.0692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,161 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,161 - train - INFO - True
2024-04-06 05:18:57,161 - train - INFO - alphas:tensor([0.7182, 0.0863, 0.0541, 0.0658, 0.0757], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,162 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,162 - train - INFO - True
2024-04-06 05:18:57,162 - train - INFO - alphas:tensor([0.5633, 0.1036, 0.0734, 0.1143, 0.1454], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,162 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,162 - train - INFO - True
2024-04-06 05:18:57,163 - train - INFO - alphas:tensor([0.6880, 0.0901, 0.0595, 0.0749, 0.0875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,163 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,163 - train - INFO - True
2024-04-06 05:18:57,164 - train - INFO - alphas:tensor([0.7183, 0.0845, 0.0508, 0.0664, 0.0800], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,164 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,164 - train - INFO - True
2024-04-06 05:18:57,165 - train - INFO - alphas:tensor([0.6944, 0.0933, 0.0571, 0.0719, 0.0833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,165 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,165 - train - INFO - True
2024-04-06 05:18:57,166 - train - INFO - alphas:tensor([0.6497, 0.0968, 0.1143, 0.1391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 05:18:57,166 - train - INFO - tau:0.8953382542587163
2024-04-06 05:18:57,166 - train - INFO - avg block size:1.0
2024-04-06 05:18:59,639 - train - INFO - Test: [   0/78]  Time: 2.467 (2.467)  Loss:  0.8218 (0.8218)  Acc@1: 83.5938 (83.5938)  Acc@5: 94.5312 (94.5312)
2024-04-06 05:20:52,219 - train - INFO - Test: [  50/78]  Time: 2.133 (2.256)  Loss:  1.9893 (1.7225)  Acc@1: 53.1250 (60.0337)  Acc@5: 82.0312 (82.3529)
2024-04-06 05:21:55,200 - train - INFO - Test: [  78/78]  Time: 2.027 (2.254)  Loss:  1.8594 (1.7648)  Acc@1: 50.0000 (58.6400)  Acc@5: 87.5000 (81.5600)
2024-04-06 05:21:58,485 - train - INFO - Train: 14 [   0/781 (  0%)]  Loss:  4.182862 (4.1829)  Time: 3.200s,   40.00/s  (3.200s,   40.00/s)  LR: 4.895e-04  Data: 0.148 (0.148)
2024-04-06 05:24:38,228 - train - INFO - Train: 14 [  50/781 (  6%)]  Loss:  3.230773 (3.8073)  Time: 3.235s,   39.57/s  (3.195s,   40.06/s)  LR: 4.895e-04  Data: 0.007 (0.010)
2024-04-06 05:27:27,401 - train - INFO - Train: 14 [ 100/781 ( 13%)]  Loss:  4.488746 (3.8324)  Time: 3.018s,   42.41/s  (3.288s,   38.93/s)  LR: 4.895e-04  Data: 0.005 (0.008)
2024-04-06 05:30:07,059 - train - INFO - Train: 14 [ 150/781 ( 19%)]  Loss:  4.242691 (3.8249)  Time: 3.338s,   38.34/s  (3.257s,   39.30/s)  LR: 4.895e-04  Data: 0.009 (0.007)
2024-04-06 05:32:49,468 - train - INFO - Train: 14 [ 200/781 ( 26%)]  Loss:  3.962338 (3.8195)  Time: 3.377s,   37.90/s  (3.255s,   39.33/s)  LR: 4.895e-04  Data: 0.008 (0.007)
2024-04-06 05:35:31,976 - train - INFO - Train: 14 [ 250/781 ( 32%)]  Loss:  3.296174 (3.8126)  Time: 3.040s,   42.11/s  (3.254s,   39.34/s)  LR: 4.895e-04  Data: 0.004 (0.007)
2024-04-06 05:38:20,170 - train - INFO - Train: 14 [ 300/781 ( 38%)]  Loss:  3.029246 (3.8126)  Time: 3.004s,   42.62/s  (3.272s,   39.12/s)  LR: 4.895e-04  Data: 0.010 (0.007)
2024-04-06 05:41:00,483 - train - INFO - Train: 14 [ 350/781 ( 45%)]  Loss:  3.247060 (3.8142)  Time: 3.226s,   39.68/s  (3.263s,   39.23/s)  LR: 4.895e-04  Data: 0.010 (0.007)
2024-04-06 05:43:43,126 - train - INFO - Train: 14 [ 400/781 ( 51%)]  Loss:  4.512638 (3.8181)  Time: 3.427s,   37.36/s  (3.261s,   39.25/s)  LR: 4.895e-04  Data: 0.006 (0.007)
2024-04-06 05:46:25,274 - train - INFO - Train: 14 [ 450/781 ( 58%)]  Loss:  3.711234 (3.8138)  Time: 3.526s,   36.30/s  (3.259s,   39.27/s)  LR: 4.895e-04  Data: 0.010 (0.007)
2024-04-06 05:49:18,501 - train - INFO - Train: 14 [ 500/781 ( 64%)]  Loss:  3.753816 (3.8150)  Time: 3.272s,   39.12/s  (3.280s,   39.03/s)  LR: 4.895e-04  Data: 0.008 (0.007)
2024-04-06 05:52:00,441 - train - INFO - Train: 14 [ 550/781 ( 71%)]  Loss:  4.008000 (3.8222)  Time: 3.355s,   38.15/s  (3.276s,   39.07/s)  LR: 4.895e-04  Data: 0.007 (0.007)
2024-04-06 05:54:43,575 - train - INFO - Train: 14 [ 600/781 ( 77%)]  Loss:  4.072545 (3.8216)  Time: 3.307s,   38.70/s  (3.275s,   39.08/s)  LR: 4.895e-04  Data: 0.007 (0.007)
2024-04-06 05:57:26,770 - train - INFO - Train: 14 [ 650/781 ( 83%)]  Loss:  3.999859 (3.8279)  Time: 3.007s,   42.56/s  (3.274s,   39.09/s)  LR: 4.895e-04  Data: 0.004 (0.007)
2024-04-06 06:00:17,366 - train - INFO - Train: 14 [ 700/781 ( 90%)]  Loss:  3.461243 (3.8297)  Time: 3.047s,   42.00/s  (3.284s,   38.98/s)  LR: 4.895e-04  Data: 0.014 (0.007)
2024-04-06 06:03:00,551 - train - INFO - Train: 14 [ 750/781 ( 96%)]  Loss:  4.368547 (3.8305)  Time: 3.475s,   36.83/s  (3.283s,   38.99/s)  LR: 4.895e-04  Data: 0.005 (0.007)
2024-04-06 06:04:37,889 - train - INFO - Train: 14 [ 780/781 (100%)]  Loss:  4.255032 (3.8329)  Time: 3.008s,   42.56/s  (3.281s,   39.01/s)  LR: 4.895e-04  Data: 0.000 (0.007)
2024-04-06 06:04:37,890 - train - INFO - True
2024-04-06 06:04:37,891 - train - INFO - alphas:tensor([0.3205, 0.2348, 0.1204, 0.1542, 0.1700], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,892 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,892 - train - INFO - True
2024-04-06 06:04:37,892 - train - INFO - alphas:tensor([0.3932, 0.1615, 0.1057, 0.1528, 0.1868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,893 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,893 - train - INFO - True
2024-04-06 06:04:37,893 - train - INFO - alphas:tensor([0.6938, 0.1141, 0.0560, 0.0644, 0.0717], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,894 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,894 - train - INFO - True
2024-04-06 06:04:37,894 - train - INFO - alphas:tensor([0.6870, 0.1008, 0.0568, 0.0721, 0.0833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,894 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,895 - train - INFO - True
2024-04-06 06:04:37,895 - train - INFO - alphas:tensor([0.5590, 0.1209, 0.0806, 0.1095, 0.1300], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,895 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,895 - train - INFO - True
2024-04-06 06:04:37,896 - train - INFO - alphas:tensor([0.6671, 0.1100, 0.0600, 0.0745, 0.0884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,896 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,896 - train - INFO - True
2024-04-06 06:04:37,897 - train - INFO - alphas:tensor([0.7558, 0.0885, 0.0454, 0.0521, 0.0582], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,897 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,897 - train - INFO - True
2024-04-06 06:04:37,898 - train - INFO - alphas:tensor([0.7673, 0.0880, 0.0410, 0.0489, 0.0549], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,898 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,898 - train - INFO - True
2024-04-06 06:04:37,899 - train - INFO - alphas:tensor([0.6083, 0.1029, 0.0706, 0.0985, 0.1197], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,899 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,899 - train - INFO - True
2024-04-06 06:04:37,900 - train - INFO - alphas:tensor([0.6965, 0.0988, 0.0558, 0.0685, 0.0804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,900 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,900 - train - INFO - True
2024-04-06 06:04:37,901 - train - INFO - alphas:tensor([0.7575, 0.0838, 0.0453, 0.0535, 0.0599], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,901 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,901 - train - INFO - True
2024-04-06 06:04:37,902 - train - INFO - alphas:tensor([0.7333, 0.0923, 0.0476, 0.0573, 0.0695], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,902 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,902 - train - INFO - True
2024-04-06 06:04:37,903 - train - INFO - alphas:tensor([0.6254, 0.0974, 0.0660, 0.0930, 0.1182], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,903 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,903 - train - INFO - True
2024-04-06 06:04:37,904 - train - INFO - alphas:tensor([0.7206, 0.0878, 0.0523, 0.0654, 0.0740], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,904 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,904 - train - INFO - True
2024-04-06 06:04:37,905 - train - INFO - alphas:tensor([0.7539, 0.0914, 0.0437, 0.0519, 0.0591], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,905 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,905 - train - INFO - True
2024-04-06 06:04:37,905 - train - INFO - alphas:tensor([0.6849, 0.1057, 0.0566, 0.0686, 0.0842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,906 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,906 - train - INFO - True
2024-04-06 06:04:37,906 - train - INFO - alphas:tensor([0.6306, 0.0964, 0.0681, 0.0910, 0.1140], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,907 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,907 - train - INFO - True
2024-04-06 06:04:37,907 - train - INFO - alphas:tensor([0.7271, 0.0853, 0.0513, 0.0627, 0.0736], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,907 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,908 - train - INFO - True
2024-04-06 06:04:37,908 - train - INFO - alphas:tensor([0.7754, 0.0811, 0.0428, 0.0473, 0.0534], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,908 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,908 - train - INFO - True
2024-04-06 06:04:37,909 - train - INFO - alphas:tensor([0.6739, 0.0988, 0.0583, 0.0742, 0.0948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,909 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,909 - train - INFO - True
2024-04-06 06:04:37,910 - train - INFO - alphas:tensor([0.6159, 0.1009, 0.0679, 0.0964, 0.1190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,910 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,910 - train - INFO - True
2024-04-06 06:04:37,911 - train - INFO - alphas:tensor([0.7492, 0.0779, 0.0475, 0.0587, 0.0666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,911 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,911 - train - INFO - True
2024-04-06 06:04:37,912 - train - INFO - alphas:tensor([0.7842, 0.0767, 0.0400, 0.0463, 0.0528], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,912 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,912 - train - INFO - True
2024-04-06 06:04:37,913 - train - INFO - alphas:tensor([0.6942, 0.0906, 0.0547, 0.0709, 0.0896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,913 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,913 - train - INFO - True
2024-04-06 06:04:37,914 - train - INFO - alphas:tensor([0.6105, 0.1000, 0.0670, 0.0993, 0.1233], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,914 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,914 - train - INFO - True
2024-04-06 06:04:37,915 - train - INFO - alphas:tensor([0.7394, 0.0784, 0.0500, 0.0606, 0.0716], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,915 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,915 - train - INFO - True
2024-04-06 06:04:37,916 - train - INFO - alphas:tensor([0.7711, 0.0755, 0.0412, 0.0517, 0.0605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,916 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,916 - train - INFO - True
2024-04-06 06:04:37,917 - train - INFO - alphas:tensor([0.7120, 0.0857, 0.0515, 0.0681, 0.0827], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,917 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,917 - train - INFO - True
2024-04-06 06:04:37,917 - train - INFO - alphas:tensor([0.5892, 0.0958, 0.0739, 0.1055, 0.1357], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,918 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,918 - train - INFO - True
2024-04-06 06:04:37,918 - train - INFO - alphas:tensor([0.7307, 0.0790, 0.0501, 0.0633, 0.0769], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,918 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,919 - train - INFO - True
2024-04-06 06:04:37,919 - train - INFO - alphas:tensor([0.7482, 0.0750, 0.0468, 0.0595, 0.0704], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,919 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,919 - train - INFO - True
2024-04-06 06:04:37,920 - train - INFO - alphas:tensor([0.7247, 0.0819, 0.0517, 0.0651, 0.0767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,920 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,920 - train - INFO - True
2024-04-06 06:04:37,921 - train - INFO - alphas:tensor([0.5678, 0.0970, 0.0715, 0.1148, 0.1489], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,921 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,921 - train - INFO - True
2024-04-06 06:04:37,922 - train - INFO - alphas:tensor([0.6980, 0.0851, 0.0569, 0.0730, 0.0871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,922 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,922 - train - INFO - True
2024-04-06 06:04:37,923 - train - INFO - alphas:tensor([0.7251, 0.0793, 0.0489, 0.0657, 0.0809], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,923 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,923 - train - INFO - True
2024-04-06 06:04:37,924 - train - INFO - alphas:tensor([0.7047, 0.0876, 0.0542, 0.0702, 0.0833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,924 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,924 - train - INFO - True
2024-04-06 06:04:37,925 - train - INFO - alphas:tensor([0.6576, 0.0937, 0.1117, 0.1370], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:04:37,925 - train - INFO - tau:0.8863848717161291
2024-04-06 06:04:37,925 - train - INFO - avg block size:1.0
2024-04-06 06:04:40,199 - train - INFO - Test: [   0/78]  Time: 2.268 (2.268)  Loss:  0.8916 (0.8916)  Acc@1: 79.6875 (79.6875)  Acc@5: 95.3125 (95.3125)
2024-04-06 06:06:35,218 - train - INFO - Test: [  50/78]  Time: 2.085 (2.300)  Loss:  1.7871 (1.7354)  Acc@1: 59.3750 (59.2218)  Acc@5: 82.8125 (82.6287)
2024-04-06 06:07:38,762 - train - INFO - Test: [  78/78]  Time: 2.370 (2.289)  Loss:  2.1602 (1.7791)  Acc@1: 50.0000 (58.1900)  Acc@5: 75.0000 (81.8500)
2024-04-06 06:07:42,123 - train - INFO - Train: 15 [   0/781 (  0%)]  Loss:  4.366542 (4.3665)  Time: 3.276s,   39.07/s  (3.276s,   39.07/s)  LR: 4.880e-04  Data: 0.149 (0.149)
2024-04-06 06:10:33,541 - train - INFO - Train: 15 [  50/781 (  6%)]  Loss:  3.247617 (3.7760)  Time: 3.342s,   38.29/s  (3.425s,   37.37/s)  LR: 4.880e-04  Data: 0.005 (0.009)
2024-04-06 06:13:15,791 - train - INFO - Train: 15 [ 100/781 ( 13%)]  Loss:  3.524803 (3.8328)  Time: 3.168s,   40.41/s  (3.336s,   38.37/s)  LR: 4.880e-04  Data: 0.004 (0.007)
2024-04-06 06:15:59,523 - train - INFO - Train: 15 [ 150/781 ( 19%)]  Loss:  3.681883 (3.7988)  Time: 3.239s,   39.52/s  (3.316s,   38.60/s)  LR: 4.880e-04  Data: 0.004 (0.007)
2024-04-06 06:18:41,450 - train - INFO - Train: 15 [ 200/781 ( 26%)]  Loss:  4.038729 (3.8038)  Time: 3.097s,   41.34/s  (3.296s,   38.83/s)  LR: 4.880e-04  Data: 0.005 (0.007)
2024-04-06 06:21:31,889 - train - INFO - Train: 15 [ 250/781 ( 32%)]  Loss:  4.160269 (3.8190)  Time: 3.087s,   41.47/s  (3.319s,   38.57/s)  LR: 4.880e-04  Data: 0.008 (0.007)
2024-04-06 06:24:15,101 - train - INFO - Train: 15 [ 300/781 ( 38%)]  Loss:  4.394609 (3.8341)  Time: 3.563s,   35.92/s  (3.310s,   38.67/s)  LR: 4.880e-04  Data: 0.005 (0.007)
2024-04-06 06:26:57,540 - train - INFO - Train: 15 [ 350/781 ( 45%)]  Loss:  3.306715 (3.8161)  Time: 3.625s,   35.31/s  (3.301s,   38.78/s)  LR: 4.880e-04  Data: 0.013 (0.007)
2024-04-06 06:29:39,841 - train - INFO - Train: 15 [ 400/781 ( 51%)]  Loss:  4.364229 (3.8237)  Time: 3.419s,   37.43/s  (3.294s,   38.86/s)  LR: 4.880e-04  Data: 0.025 (0.007)
2024-04-06 06:32:27,064 - train - INFO - Train: 15 [ 450/781 ( 58%)]  Loss:  3.645058 (3.8265)  Time: 3.286s,   38.95/s  (3.300s,   38.79/s)  LR: 4.880e-04  Data: 0.010 (0.007)
2024-04-06 06:35:08,790 - train - INFO - Train: 15 [ 500/781 ( 64%)]  Loss:  3.945375 (3.8265)  Time: 3.173s,   40.34/s  (3.293s,   38.87/s)  LR: 4.880e-04  Data: 0.005 (0.007)
2024-04-06 06:37:49,610 - train - INFO - Train: 15 [ 550/781 ( 71%)]  Loss:  3.791159 (3.8225)  Time: 3.445s,   37.15/s  (3.286s,   38.95/s)  LR: 4.880e-04  Data: 0.005 (0.007)
2024-04-06 06:40:30,323 - train - INFO - Train: 15 [ 600/781 ( 77%)]  Loss:  3.532042 (3.8212)  Time: 3.263s,   39.23/s  (3.280s,   39.02/s)  LR: 4.880e-04  Data: 0.009 (0.007)
2024-04-06 06:43:19,681 - train - INFO - Train: 15 [ 650/781 ( 83%)]  Loss:  4.089336 (3.8260)  Time: 2.997s,   42.71/s  (3.288s,   38.92/s)  LR: 4.880e-04  Data: 0.015 (0.007)
2024-04-06 06:46:00,703 - train - INFO - Train: 15 [ 700/781 ( 90%)]  Loss:  3.760557 (3.8278)  Time: 3.412s,   37.51/s  (3.284s,   38.98/s)  LR: 4.880e-04  Data: 0.007 (0.007)
2024-04-06 06:48:41,296 - train - INFO - Train: 15 [ 750/781 ( 96%)]  Loss:  3.876058 (3.8274)  Time: 2.994s,   42.75/s  (3.279s,   39.04/s)  LR: 4.880e-04  Data: 0.011 (0.007)
2024-04-06 06:50:16,913 - train - INFO - Train: 15 [ 780/781 (100%)]  Loss:  3.205910 (3.8268)  Time: 3.380s,   37.87/s  (3.275s,   39.08/s)  LR: 4.880e-04  Data: 0.000 (0.007)
2024-04-06 06:50:16,914 - train - INFO - True
2024-04-06 06:50:16,917 - train - INFO - alphas:tensor([0.3233, 0.2307, 0.1192, 0.1548, 0.1720], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,917 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,918 - train - INFO - True
2024-04-06 06:50:16,919 - train - INFO - alphas:tensor([0.4005, 0.1533, 0.1031, 0.1530, 0.1902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,919 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,920 - train - INFO - True
2024-04-06 06:50:16,921 - train - INFO - alphas:tensor([0.7071, 0.1078, 0.0537, 0.0620, 0.0694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,921 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,922 - train - INFO - True
2024-04-06 06:50:16,923 - train - INFO - alphas:tensor([0.7004, 0.0944, 0.0541, 0.0697, 0.0813], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,923 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,923 - train - INFO - True
2024-04-06 06:50:16,925 - train - INFO - alphas:tensor([0.5666, 0.1143, 0.0790, 0.1092, 0.1310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,925 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,925 - train - INFO - True
2024-04-06 06:50:16,927 - train - INFO - alphas:tensor([0.6780, 0.1052, 0.0575, 0.0724, 0.0869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,927 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,927 - train - INFO - True
2024-04-06 06:50:16,928 - train - INFO - alphas:tensor([0.7650, 0.0841, 0.0435, 0.0505, 0.0569], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,929 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,929 - train - INFO - True
2024-04-06 06:50:16,930 - train - INFO - alphas:tensor([0.7804, 0.0822, 0.0381, 0.0465, 0.0529], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,930 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,931 - train - INFO - True
2024-04-06 06:50:16,932 - train - INFO - alphas:tensor([0.6150, 0.0969, 0.0689, 0.0981, 0.1210], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,932 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,932 - train - INFO - True
2024-04-06 06:50:16,934 - train - INFO - alphas:tensor([0.7058, 0.0937, 0.0540, 0.0670, 0.0795], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,934 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,934 - train - INFO - True
2024-04-06 06:50:16,935 - train - INFO - alphas:tensor([0.7657, 0.0788, 0.0436, 0.0524, 0.0594], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,936 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,936 - train - INFO - True
2024-04-06 06:50:16,937 - train - INFO - alphas:tensor([0.7444, 0.0866, 0.0449, 0.0557, 0.0685], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,937 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,937 - train - INFO - True
2024-04-06 06:50:16,939 - train - INFO - alphas:tensor([0.6304, 0.0925, 0.0646, 0.0929, 0.1197], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,939 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,939 - train - INFO - True
2024-04-06 06:50:16,940 - train - INFO - alphas:tensor([0.7287, 0.0832, 0.0506, 0.0641, 0.0734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,941 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,941 - train - INFO - True
2024-04-06 06:50:16,942 - train - INFO - alphas:tensor([0.7582, 0.0876, 0.0425, 0.0517, 0.0600], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,942 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,942 - train - INFO - True
2024-04-06 06:50:16,944 - train - INFO - alphas:tensor([0.6866, 0.1022, 0.0554, 0.0693, 0.0865], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,944 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,944 - train - INFO - True
2024-04-06 06:50:16,945 - train - INFO - alphas:tensor([0.6395, 0.0899, 0.0658, 0.0900, 0.1149], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,945 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,946 - train - INFO - True
2024-04-06 06:50:16,947 - train - INFO - alphas:tensor([0.7355, 0.0809, 0.0493, 0.0613, 0.0729], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,947 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,947 - train - INFO - True
2024-04-06 06:50:16,948 - train - INFO - alphas:tensor([0.7780, 0.0783, 0.0423, 0.0473, 0.0541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,949 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,949 - train - INFO - True
2024-04-06 06:50:16,950 - train - INFO - alphas:tensor([0.6769, 0.0938, 0.0564, 0.0747, 0.0983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,950 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,950 - train - INFO - True
2024-04-06 06:50:16,952 - train - INFO - alphas:tensor([0.6193, 0.0962, 0.0666, 0.0965, 0.1214], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,952 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,952 - train - INFO - True
2024-04-06 06:50:16,953 - train - INFO - alphas:tensor([0.7598, 0.0734, 0.0451, 0.0565, 0.0653], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,953 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,953 - train - INFO - True
2024-04-06 06:50:16,955 - train - INFO - alphas:tensor([0.7891, 0.0737, 0.0386, 0.0457, 0.0529], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,955 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,955 - train - INFO - True
2024-04-06 06:50:16,956 - train - INFO - alphas:tensor([0.7005, 0.0853, 0.0520, 0.0704, 0.0918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,956 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,956 - train - INFO - True
2024-04-06 06:50:16,958 - train - INFO - alphas:tensor([0.6152, 0.0942, 0.0651, 0.0995, 0.1259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,958 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,958 - train - INFO - True
2024-04-06 06:50:16,959 - train - INFO - alphas:tensor([0.7496, 0.0738, 0.0473, 0.0588, 0.0704], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,959 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,959 - train - INFO - True
2024-04-06 06:50:16,961 - train - INFO - alphas:tensor([0.7756, 0.0714, 0.0400, 0.0516, 0.0614], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,961 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,961 - train - INFO - True
2024-04-06 06:50:16,962 - train - INFO - alphas:tensor([0.7155, 0.0813, 0.0496, 0.0684, 0.0852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,962 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,962 - train - INFO - True
2024-04-06 06:50:16,964 - train - INFO - alphas:tensor([0.5937, 0.0894, 0.0723, 0.1060, 0.1387], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,964 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,964 - train - INFO - True
2024-04-06 06:50:16,965 - train - INFO - alphas:tensor([0.7390, 0.0748, 0.0480, 0.0619, 0.0764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,965 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,965 - train - INFO - True
2024-04-06 06:50:16,966 - train - INFO - alphas:tensor([0.7499, 0.0717, 0.0461, 0.0599, 0.0724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,967 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,967 - train - INFO - True
2024-04-06 06:50:16,968 - train - INFO - alphas:tensor([0.7256, 0.0786, 0.0506, 0.0658, 0.0793], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,968 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,968 - train - INFO - True
2024-04-06 06:50:16,969 - train - INFO - alphas:tensor([0.5727, 0.0912, 0.0698, 0.1146, 0.1517], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,969 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,969 - train - INFO - True
2024-04-06 06:50:16,971 - train - INFO - alphas:tensor([0.7033, 0.0817, 0.0548, 0.0722, 0.0879], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,971 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,971 - train - INFO - True
2024-04-06 06:50:16,972 - train - INFO - alphas:tensor([0.7263, 0.0769, 0.0480, 0.0659, 0.0830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,972 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,972 - train - INFO - True
2024-04-06 06:50:16,973 - train - INFO - alphas:tensor([0.7106, 0.0827, 0.0523, 0.0698, 0.0847], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,974 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,974 - train - INFO - True
2024-04-06 06:50:16,975 - train - INFO - alphas:tensor([0.6664, 0.0900, 0.1088, 0.1349], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 06:50:16,975 - train - INFO - tau:0.8775210229989678
2024-04-06 06:50:16,975 - train - INFO - avg block size:1.0
2024-04-06 06:50:16,975 - train - INFO - lasso_alpha:1.4641000000000006e-05
2024-04-06 06:50:19,612 - train - INFO - Test: [   0/78]  Time: 2.628 (2.628)  Loss:  0.9902 (0.9902)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.9688 (92.9688)
2024-04-06 06:52:14,583 - train - INFO - Test: [  50/78]  Time: 2.650 (2.306)  Loss:  1.8506 (1.7421)  Acc@1: 59.3750 (59.3444)  Acc@5: 82.0312 (82.3529)
2024-04-06 06:53:27,883 - train - INFO - Test: [  78/78]  Time: 2.117 (2.416)  Loss:  1.6084 (1.7751)  Acc@1: 62.5000 (58.6700)  Acc@5: 93.7500 (81.8300)
2024-04-06 06:53:31,287 - train - INFO - Train: 16 [   0/781 (  0%)]  Loss:  4.218713 (4.2187)  Time: 3.325s,   38.50/s  (3.325s,   38.50/s)  LR: 4.864e-04  Data: 0.134 (0.134)
2024-04-06 06:56:13,201 - train - INFO - Train: 16 [  50/781 (  6%)]  Loss:  3.598935 (3.7887)  Time: 3.477s,   36.82/s  (3.240s,   39.51/s)  LR: 4.864e-04  Data: 0.009 (0.009)
2024-04-06 06:58:55,818 - train - INFO - Train: 16 [ 100/781 ( 13%)]  Loss:  3.742265 (3.7786)  Time: 3.119s,   41.04/s  (3.246s,   39.43/s)  LR: 4.864e-04  Data: 0.006 (0.008)
2024-04-06 07:01:37,886 - train - INFO - Train: 16 [ 150/781 ( 19%)]  Loss:  3.706771 (3.8147)  Time: 3.439s,   37.22/s  (3.244s,   39.45/s)  LR: 4.864e-04  Data: 0.008 (0.008)
2024-04-06 07:04:26,343 - train - INFO - Train: 16 [ 200/781 ( 26%)]  Loss:  3.550094 (3.8378)  Time: 3.461s,   36.98/s  (3.275s,   39.08/s)  LR: 4.864e-04  Data: 0.011 (0.007)
2024-04-06 07:07:06,971 - train - INFO - Train: 16 [ 250/781 ( 32%)]  Loss:  4.301126 (3.8406)  Time: 3.171s,   40.36/s  (3.263s,   39.23/s)  LR: 4.864e-04  Data: 0.008 (0.007)
2024-04-06 07:09:47,455 - train - INFO - Train: 16 [ 300/781 ( 38%)]  Loss:  4.363911 (3.8420)  Time: 3.040s,   42.11/s  (3.254s,   39.34/s)  LR: 4.864e-04  Data: 0.006 (0.007)
2024-04-06 07:12:29,194 - train - INFO - Train: 16 [ 350/781 ( 45%)]  Loss:  3.773124 (3.8346)  Time: 3.253s,   39.35/s  (3.251s,   39.37/s)  LR: 4.864e-04  Data: 0.005 (0.007)
2024-04-06 07:15:19,086 - train - INFO - Train: 16 [ 400/781 ( 51%)]  Loss:  4.252164 (3.8357)  Time: 3.330s,   38.44/s  (3.270s,   39.15/s)  LR: 4.864e-04  Data: 0.005 (0.007)
2024-04-06 07:18:00,767 - train - INFO - Train: 16 [ 450/781 ( 58%)]  Loss:  3.943688 (3.8355)  Time: 3.027s,   42.28/s  (3.266s,   39.20/s)  LR: 4.864e-04  Data: 0.008 (0.007)
2024-04-06 07:20:43,716 - train - INFO - Train: 16 [ 500/781 ( 64%)]  Loss:  3.542757 (3.8334)  Time: 2.992s,   42.78/s  (3.265s,   39.20/s)  LR: 4.864e-04  Data: 0.005 (0.007)
2024-04-06 07:23:27,687 - train - INFO - Train: 16 [ 550/781 ( 71%)]  Loss:  3.691382 (3.8283)  Time: 3.337s,   38.35/s  (3.266s,   39.19/s)  LR: 4.864e-04  Data: 0.008 (0.007)
2024-04-06 07:26:16,277 - train - INFO - Train: 16 [ 600/781 ( 77%)]  Loss:  4.477411 (3.8312)  Time: 3.564s,   35.91/s  (3.275s,   39.08/s)  LR: 4.864e-04  Data: 0.008 (0.007)
2024-04-06 07:28:57,830 - train - INFO - Train: 16 [ 650/781 ( 83%)]  Loss:  3.056184 (3.8317)  Time: 3.097s,   41.33/s  (3.272s,   39.12/s)  LR: 4.864e-04  Data: 0.007 (0.007)
2024-04-06 07:31:39,007 - train - INFO - Train: 16 [ 700/781 ( 90%)]  Loss:  4.110978 (3.8258)  Time: 3.021s,   42.37/s  (3.268s,   39.17/s)  LR: 4.864e-04  Data: 0.005 (0.007)
2024-04-06 07:34:21,633 - train - INFO - Train: 16 [ 750/781 ( 96%)]  Loss:  4.076234 (3.8278)  Time: 3.059s,   41.85/s  (3.267s,   39.18/s)  LR: 4.864e-04  Data: 0.004 (0.007)
2024-04-06 07:35:59,997 - train - INFO - Train: 16 [ 780/781 (100%)]  Loss:  3.414847 (3.8307)  Time: 3.592s,   35.63/s  (3.268s,   39.17/s)  LR: 4.864e-04  Data: 0.000 (0.007)
2024-04-06 07:35:59,998 - train - INFO - True
2024-04-06 07:35:59,999 - train - INFO - alphas:tensor([0.3254, 0.2269, 0.1179, 0.1556, 0.1742], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:35:59,999 - train - INFO - tau:0.8687458127689781
2024-04-06 07:35:59,999 - train - INFO - True
2024-04-06 07:36:00,000 - train - INFO - alphas:tensor([0.4051, 0.1459, 0.1010, 0.1538, 0.1943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,000 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,000 - train - INFO - True
2024-04-06 07:36:00,001 - train - INFO - alphas:tensor([0.7166, 0.1038, 0.0517, 0.0602, 0.0677], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,001 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,001 - train - INFO - True
2024-04-06 07:36:00,002 - train - INFO - alphas:tensor([0.7103, 0.0901, 0.0519, 0.0679, 0.0798], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,002 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,002 - train - INFO - True
2024-04-06 07:36:00,003 - train - INFO - alphas:tensor([0.5740, 0.1085, 0.0769, 0.1086, 0.1320], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,003 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,003 - train - INFO - True
2024-04-06 07:36:00,003 - train - INFO - alphas:tensor([0.6875, 0.1006, 0.0552, 0.0707, 0.0859], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,004 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,004 - train - INFO - True
2024-04-06 07:36:00,004 - train - INFO - alphas:tensor([0.7733, 0.0798, 0.0419, 0.0492, 0.0559], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,004 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,004 - train - INFO - True
2024-04-06 07:36:00,005 - train - INFO - alphas:tensor([0.7884, 0.0784, 0.0364, 0.0450, 0.0518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,005 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,005 - train - INFO - True
2024-04-06 07:36:00,006 - train - INFO - alphas:tensor([0.6182, 0.0930, 0.0675, 0.0983, 0.1231], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,006 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,006 - train - INFO - True
2024-04-06 07:36:00,007 - train - INFO - alphas:tensor([0.7140, 0.0897, 0.0521, 0.0657, 0.0785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,007 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,007 - train - INFO - True
2024-04-06 07:36:00,008 - train - INFO - alphas:tensor([0.7693, 0.0757, 0.0427, 0.0523, 0.0599], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,008 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,008 - train - INFO - True
2024-04-06 07:36:00,009 - train - INFO - alphas:tensor([0.7500, 0.0830, 0.0432, 0.0551, 0.0688], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,009 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,009 - train - INFO - True
2024-04-06 07:36:00,010 - train - INFO - alphas:tensor([0.6344, 0.0879, 0.0632, 0.0928, 0.1217], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,010 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,010 - train - INFO - True
2024-04-06 07:36:00,011 - train - INFO - alphas:tensor([0.7329, 0.0799, 0.0493, 0.0637, 0.0741], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,011 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,011 - train - INFO - True
2024-04-06 07:36:00,012 - train - INFO - alphas:tensor([0.7610, 0.0847, 0.0415, 0.0517, 0.0610], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,012 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,012 - train - INFO - True
2024-04-06 07:36:00,012 - train - INFO - alphas:tensor([0.6922, 0.0975, 0.0533, 0.0687, 0.0882], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,013 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,013 - train - INFO - True
2024-04-06 07:36:00,013 - train - INFO - alphas:tensor([0.6410, 0.0862, 0.0647, 0.0905, 0.1176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,014 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,014 - train - INFO - True
2024-04-06 07:36:00,014 - train - INFO - alphas:tensor([0.7379, 0.0783, 0.0484, 0.0613, 0.0740], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,014 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,014 - train - INFO - True
2024-04-06 07:36:00,015 - train - INFO - alphas:tensor([0.7815, 0.0754, 0.0413, 0.0470, 0.0548], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,015 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,015 - train - INFO - True
2024-04-06 07:36:00,016 - train - INFO - alphas:tensor([0.6778, 0.0903, 0.0546, 0.0754, 0.1019], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,016 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,016 - train - INFO - True
2024-04-06 07:36:00,017 - train - INFO - alphas:tensor([0.6236, 0.0910, 0.0651, 0.0966, 0.1238], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,017 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,017 - train - INFO - True
2024-04-06 07:36:00,018 - train - INFO - alphas:tensor([0.7649, 0.0705, 0.0436, 0.0556, 0.0653], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,018 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,018 - train - INFO - True
2024-04-06 07:36:00,019 - train - INFO - alphas:tensor([0.7909, 0.0718, 0.0378, 0.0458, 0.0536], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,019 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,019 - train - INFO - True
2024-04-06 07:36:00,020 - train - INFO - alphas:tensor([0.7022, 0.0822, 0.0507, 0.0703, 0.0947], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,020 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,020 - train - INFO - True
2024-04-06 07:36:00,021 - train - INFO - alphas:tensor([0.6205, 0.0885, 0.0634, 0.0995, 0.1281], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,021 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,021 - train - INFO - True
2024-04-06 07:36:00,022 - train - INFO - alphas:tensor([0.7554, 0.0709, 0.0457, 0.0575, 0.0703], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,022 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,022 - train - INFO - True
2024-04-06 07:36:00,022 - train - INFO - alphas:tensor([0.7768, 0.0689, 0.0390, 0.0520, 0.0632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,023 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,023 - train - INFO - True
2024-04-06 07:36:00,023 - train - INFO - alphas:tensor([0.7174, 0.0783, 0.0480, 0.0686, 0.0877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,023 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,024 - train - INFO - True
2024-04-06 07:36:00,024 - train - INFO - alphas:tensor([0.5957, 0.0844, 0.0711, 0.1066, 0.1422], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,024 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,024 - train - INFO - True
2024-04-06 07:36:00,025 - train - INFO - alphas:tensor([0.7426, 0.0715, 0.0469, 0.0615, 0.0776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,025 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,025 - train - INFO - True
2024-04-06 07:36:00,026 - train - INFO - alphas:tensor([0.7553, 0.0679, 0.0444, 0.0593, 0.0730], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,026 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,026 - train - INFO - True
2024-04-06 07:36:00,027 - train - INFO - alphas:tensor([0.7334, 0.0751, 0.0480, 0.0642, 0.0794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,027 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,027 - train - INFO - True
2024-04-06 07:36:00,028 - train - INFO - alphas:tensor([0.5710, 0.0873, 0.0690, 0.1159, 0.1567], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,028 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,028 - train - INFO - True
2024-04-06 07:36:00,029 - train - INFO - alphas:tensor([0.7052, 0.0791, 0.0538, 0.0721, 0.0899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,029 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,029 - train - INFO - True
2024-04-06 07:36:00,030 - train - INFO - alphas:tensor([0.7282, 0.0733, 0.0467, 0.0665, 0.0853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,030 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,030 - train - INFO - True
2024-04-06 07:36:00,031 - train - INFO - alphas:tensor([0.7129, 0.0800, 0.0508, 0.0698, 0.0866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,031 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,031 - train - INFO - True
2024-04-06 07:36:00,032 - train - INFO - alphas:tensor([0.6727, 0.0876, 0.1066, 0.1331], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 07:36:00,032 - train - INFO - tau:0.8687458127689781
2024-04-06 07:36:00,032 - train - INFO - avg block size:1.0
2024-04-06 07:36:02,673 - train - INFO - Test: [   0/78]  Time: 2.634 (2.634)  Loss:  1.0215 (1.0215)  Acc@1: 75.0000 (75.0000)  Acc@5: 91.4062 (91.4062)
2024-04-06 07:38:02,289 - train - INFO - Test: [  50/78]  Time: 2.089 (2.397)  Loss:  1.7480 (1.7325)  Acc@1: 61.7188 (59.1759)  Acc@5: 82.8125 (82.5827)
2024-04-06 07:39:04,437 - train - INFO - Test: [  78/78]  Time: 2.340 (2.334)  Loss:  1.7324 (1.7540)  Acc@1: 56.2500 (58.7100)  Acc@5: 100.0000 (82.2900)
2024-04-06 07:39:08,007 - train - INFO - Train: 17 [   0/781 (  0%)]  Loss:  4.379909 (4.3799)  Time: 3.486s,   36.72/s  (3.486s,   36.72/s)  LR: 4.846e-04  Data: 0.184 (0.184)
2024-04-06 07:41:49,191 - train - INFO - Train: 17 [  50/781 (  6%)]  Loss:  3.224367 (3.9478)  Time: 3.157s,   40.54/s  (3.229s,   39.64/s)  LR: 4.846e-04  Data: 0.008 (0.011)
2024-04-06 07:44:29,774 - train - INFO - Train: 17 [ 100/781 ( 13%)]  Loss:  3.289594 (3.9014)  Time: 3.120s,   41.03/s  (3.220s,   39.75/s)  LR: 4.846e-04  Data: 0.007 (0.009)
2024-04-06 07:47:14,459 - train - INFO - Train: 17 [ 150/781 ( 19%)]  Loss:  3.837216 (3.8964)  Time: 3.585s,   35.71/s  (3.245s,   39.45/s)  LR: 4.846e-04  Data: 0.004 (0.008)
2024-04-06 07:50:00,269 - train - INFO - Train: 17 [ 200/781 ( 26%)]  Loss:  3.751635 (3.8786)  Time: 3.087s,   41.46/s  (3.262s,   39.23/s)  LR: 4.846e-04  Data: 0.005 (0.008)
2024-04-06 07:52:41,536 - train - INFO - Train: 17 [ 250/781 ( 32%)]  Loss:  3.580726 (3.8603)  Time: 3.210s,   39.88/s  (3.255s,   39.32/s)  LR: 4.846e-04  Data: 0.004 (0.007)
2024-04-06 07:55:21,657 - train - INFO - Train: 17 [ 300/781 ( 38%)]  Loss:  2.976339 (3.8401)  Time: 2.988s,   42.83/s  (3.246s,   39.43/s)  LR: 4.846e-04  Data: 0.005 (0.007)
2024-04-06 07:58:05,876 - train - INFO - Train: 17 [ 350/781 ( 45%)]  Loss:  3.389812 (3.8465)  Time: 3.408s,   37.55/s  (3.252s,   39.36/s)  LR: 4.846e-04  Data: 0.005 (0.007)
2024-04-06 08:00:49,203 - train - INFO - Train: 17 [ 400/781 ( 51%)]  Loss:  3.747807 (3.8381)  Time: 3.169s,   40.39/s  (3.254s,   39.34/s)  LR: 4.846e-04  Data: 0.005 (0.007)
2024-04-06 08:03:30,865 - train - INFO - Train: 17 [ 450/781 ( 58%)]  Loss:  3.463639 (3.8367)  Time: 3.365s,   38.04/s  (3.251s,   39.37/s)  LR: 4.846e-04  Data: 0.006 (0.007)
2024-04-06 08:06:11,636 - train - INFO - Train: 17 [ 500/781 ( 64%)]  Loss:  3.260655 (3.8333)  Time: 3.064s,   41.78/s  (3.248s,   39.41/s)  LR: 4.846e-04  Data: 0.005 (0.007)
2024-04-06 08:08:57,424 - train - INFO - Train: 17 [ 550/781 ( 71%)]  Loss:  3.360860 (3.8413)  Time: 3.606s,   35.50/s  (3.254s,   39.34/s)  LR: 4.846e-04  Data: 0.006 (0.007)
2024-04-06 08:11:41,217 - train - INFO - Train: 17 [ 600/781 ( 77%)]  Loss:  4.074487 (3.8402)  Time: 2.998s,   42.69/s  (3.256s,   39.32/s)  LR: 4.846e-04  Data: 0.007 (0.007)
2024-04-06 08:14:24,345 - train - INFO - Train: 17 [ 650/781 ( 83%)]  Loss:  3.504858 (3.8382)  Time: 3.350s,   38.20/s  (3.256s,   39.31/s)  LR: 4.846e-04  Data: 0.010 (0.007)
2024-04-06 08:17:06,880 - train - INFO - Train: 17 [ 700/781 ( 90%)]  Loss:  3.951225 (3.8382)  Time: 3.319s,   38.56/s  (3.256s,   39.31/s)  LR: 4.846e-04  Data: 0.005 (0.007)
2024-04-06 08:19:55,223 - train - INFO - Train: 17 [ 750/781 ( 96%)]  Loss:  4.185102 (3.8399)  Time: 3.846s,   33.28/s  (3.263s,   39.23/s)  LR: 4.846e-04  Data: 0.005 (0.007)
2024-04-06 08:21:35,996 - train - INFO - Train: 17 [ 780/781 (100%)]  Loss:  4.343772 (3.8422)  Time: 3.162s,   40.48/s  (3.267s,   39.18/s)  LR: 4.846e-04  Data: 0.000 (0.007)
2024-04-06 08:21:35,996 - train - INFO - True
2024-04-06 08:21:35,998 - train - INFO - alphas:tensor([0.3273, 0.2243, 0.1165, 0.1560, 0.1759], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:35,998 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:35,998 - train - INFO - True
2024-04-06 08:21:35,999 - train - INFO - alphas:tensor([0.4084, 0.1399, 0.0992, 0.1543, 0.1982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:35,999 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:35,999 - train - INFO - True
2024-04-06 08:21:36,000 - train - INFO - alphas:tensor([0.7261, 0.0992, 0.0499, 0.0585, 0.0661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,000 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,000 - train - INFO - True
2024-04-06 08:21:36,001 - train - INFO - alphas:tensor([0.7184, 0.0868, 0.0501, 0.0662, 0.0785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,001 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,001 - train - INFO - True
2024-04-06 08:21:36,002 - train - INFO - alphas:tensor([0.5750, 0.1055, 0.0760, 0.1091, 0.1344], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,002 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,002 - train - INFO - True
2024-04-06 08:21:36,002 - train - INFO - alphas:tensor([0.6924, 0.0980, 0.0541, 0.0700, 0.0856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,003 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,003 - train - INFO - True
2024-04-06 08:21:36,003 - train - INFO - alphas:tensor([0.7781, 0.0772, 0.0407, 0.0484, 0.0556], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,004 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,004 - train - INFO - True
2024-04-06 08:21:36,004 - train - INFO - alphas:tensor([0.7943, 0.0755, 0.0348, 0.0440, 0.0514], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,005 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,005 - train - INFO - True
2024-04-06 08:21:36,005 - train - INFO - alphas:tensor([0.6237, 0.0892, 0.0659, 0.0976, 0.1237], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,005 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,006 - train - INFO - True
2024-04-06 08:21:36,006 - train - INFO - alphas:tensor([0.7198, 0.0863, 0.0507, 0.0649, 0.0783], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,006 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,006 - train - INFO - True
2024-04-06 08:21:36,007 - train - INFO - alphas:tensor([0.7729, 0.0732, 0.0418, 0.0519, 0.0602], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,007 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,007 - train - INFO - True
2024-04-06 08:21:36,008 - train - INFO - alphas:tensor([0.7568, 0.0794, 0.0413, 0.0539, 0.0686], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,008 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,008 - train - INFO - True
2024-04-06 08:21:36,009 - train - INFO - alphas:tensor([0.6413, 0.0834, 0.0613, 0.0919, 0.1221], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,009 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,009 - train - INFO - True
2024-04-06 08:21:36,010 - train - INFO - alphas:tensor([0.7384, 0.0770, 0.0479, 0.0627, 0.0740], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,010 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,010 - train - INFO - True
2024-04-06 08:21:36,011 - train - INFO - alphas:tensor([0.7659, 0.0811, 0.0403, 0.0511, 0.0616], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,011 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,011 - train - INFO - True
2024-04-06 08:21:36,012 - train - INFO - alphas:tensor([0.6954, 0.0933, 0.0519, 0.0689, 0.0905], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,012 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,012 - train - INFO - True
2024-04-06 08:21:36,013 - train - INFO - alphas:tensor([0.6431, 0.0830, 0.0635, 0.0907, 0.1197], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,013 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,013 - train - INFO - True
2024-04-06 08:21:36,014 - train - INFO - alphas:tensor([0.7426, 0.0750, 0.0471, 0.0607, 0.0746], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,014 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,014 - train - INFO - True
2024-04-06 08:21:36,015 - train - INFO - alphas:tensor([0.7818, 0.0732, 0.0408, 0.0477, 0.0565], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,015 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,015 - train - INFO - True
2024-04-06 08:21:36,016 - train - INFO - alphas:tensor([0.6773, 0.0874, 0.0537, 0.0760, 0.1056], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,016 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,016 - train - INFO - True
2024-04-06 08:21:36,017 - train - INFO - alphas:tensor([0.6273, 0.0869, 0.0637, 0.0964, 0.1256], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,017 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,017 - train - INFO - True
2024-04-06 08:21:36,018 - train - INFO - alphas:tensor([0.7697, 0.0680, 0.0421, 0.0546, 0.0656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,018 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,018 - train - INFO - True
2024-04-06 08:21:36,019 - train - INFO - alphas:tensor([0.7930, 0.0701, 0.0370, 0.0455, 0.0544], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,019 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,019 - train - INFO - True
2024-04-06 08:21:36,019 - train - INFO - alphas:tensor([0.7050, 0.0787, 0.0486, 0.0701, 0.0975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,020 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,020 - train - INFO - True
2024-04-06 08:21:36,020 - train - INFO - alphas:tensor([0.6220, 0.0843, 0.0624, 0.1002, 0.1311], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,021 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,021 - train - INFO - True
2024-04-06 08:21:36,021 - train - INFO - alphas:tensor([0.7618, 0.0681, 0.0440, 0.0562, 0.0699], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,021 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,022 - train - INFO - True
2024-04-06 08:21:36,022 - train - INFO - alphas:tensor([0.7786, 0.0666, 0.0383, 0.0520, 0.0645], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,022 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,023 - train - INFO - True
2024-04-06 08:21:36,023 - train - INFO - alphas:tensor([0.7169, 0.0759, 0.0469, 0.0693, 0.0909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,023 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,023 - train - INFO - True
2024-04-06 08:21:36,024 - train - INFO - alphas:tensor([0.6002, 0.0802, 0.0692, 0.1061, 0.1443], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,024 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,024 - train - INFO - True
2024-04-06 08:21:36,025 - train - INFO - alphas:tensor([0.7483, 0.0682, 0.0451, 0.0603, 0.0781], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,025 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,025 - train - INFO - True
2024-04-06 08:21:36,026 - train - INFO - alphas:tensor([0.7598, 0.0649, 0.0430, 0.0587, 0.0736], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,026 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,026 - train - INFO - True
2024-04-06 08:21:36,027 - train - INFO - alphas:tensor([0.7364, 0.0724, 0.0463, 0.0639, 0.0811], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,027 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,027 - train - INFO - True
2024-04-06 08:21:36,028 - train - INFO - alphas:tensor([0.5770, 0.0822, 0.0667, 0.1151, 0.1590], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,028 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,028 - train - INFO - True
2024-04-06 08:21:36,029 - train - INFO - alphas:tensor([0.7100, 0.0766, 0.0518, 0.0712, 0.0904], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,029 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,029 - train - INFO - True
2024-04-06 08:21:36,030 - train - INFO - alphas:tensor([0.7321, 0.0699, 0.0451, 0.0661, 0.0868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,030 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,030 - train - INFO - True
2024-04-06 08:21:36,031 - train - INFO - alphas:tensor([0.7200, 0.0761, 0.0481, 0.0687, 0.0871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,031 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,031 - train - INFO - True
2024-04-06 08:21:36,032 - train - INFO - alphas:tensor([0.6785, 0.0849, 0.1047, 0.1319], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 08:21:36,032 - train - INFO - tau:0.8600583546412883
2024-04-06 08:21:36,032 - train - INFO - avg block size:1.0
2024-04-06 08:21:38,314 - train - INFO - Test: [   0/78]  Time: 2.276 (2.276)  Loss:  1.0693 (1.0693)  Acc@1: 76.5625 (76.5625)  Acc@5: 91.4062 (91.4062)
2024-04-06 08:23:33,181 - train - INFO - Test: [  50/78]  Time: 2.209 (2.297)  Loss:  1.9551 (1.7322)  Acc@1: 54.6875 (59.3597)  Acc@5: 81.2500 (82.2304)
2024-04-06 08:24:36,959 - train - INFO - Test: [  78/78]  Time: 2.488 (2.290)  Loss:  1.6025 (1.7631)  Acc@1: 56.2500 (58.8100)  Acc@5: 100.0000 (81.7200)
2024-04-06 08:24:40,623 - train - INFO - Train: 18 [   0/781 (  0%)]  Loss:  4.072104 (4.0721)  Time: 3.586s,   35.70/s  (3.586s,   35.70/s)  LR: 4.828e-04  Data: 0.180 (0.180)
2024-04-06 08:27:23,102 - train - INFO - Train: 18 [  50/781 (  6%)]  Loss:  4.172794 (3.8730)  Time: 3.173s,   40.35/s  (3.256s,   39.31/s)  LR: 4.828e-04  Data: 0.010 (0.010)
2024-04-06 08:30:06,322 - train - INFO - Train: 18 [ 100/781 ( 13%)]  Loss:  3.405812 (3.8326)  Time: 3.865s,   33.12/s  (3.260s,   39.26/s)  LR: 4.828e-04  Data: 0.005 (0.008)
2024-04-06 08:32:54,894 - train - INFO - Train: 18 [ 150/781 ( 19%)]  Loss:  3.362574 (3.8200)  Time: 2.984s,   42.90/s  (3.297s,   38.82/s)  LR: 4.828e-04  Data: 0.005 (0.008)
2024-04-06 08:35:38,875 - train - INFO - Train: 18 [ 200/781 ( 26%)]  Loss:  3.682004 (3.8216)  Time: 3.422s,   37.40/s  (3.293s,   38.87/s)  LR: 4.828e-04  Data: 0.006 (0.007)
2024-04-06 08:38:21,237 - train - INFO - Train: 18 [ 250/781 ( 32%)]  Loss:  4.168866 (3.8109)  Time: 3.385s,   37.81/s  (3.284s,   38.98/s)  LR: 4.828e-04  Data: 0.009 (0.007)
2024-04-06 08:41:11,036 - train - INFO - Train: 18 [ 300/781 ( 38%)]  Loss:  4.391130 (3.8121)  Time: 3.600s,   35.55/s  (3.302s,   38.76/s)  LR: 4.828e-04  Data: 0.005 (0.007)
2024-04-06 08:43:55,455 - train - INFO - Train: 18 [ 350/781 ( 45%)]  Loss:  3.828897 (3.8216)  Time: 3.568s,   35.88/s  (3.300s,   38.78/s)  LR: 4.828e-04  Data: 0.008 (0.007)
2024-04-06 08:46:36,615 - train - INFO - Train: 18 [ 400/781 ( 51%)]  Loss:  3.874798 (3.8248)  Time: 3.082s,   41.53/s  (3.291s,   38.90/s)  LR: 4.828e-04  Data: 0.005 (0.007)
2024-04-06 08:49:19,390 - train - INFO - Train: 18 [ 450/781 ( 58%)]  Loss:  4.477525 (3.8403)  Time: 3.524s,   36.32/s  (3.287s,   38.94/s)  LR: 4.828e-04  Data: 0.010 (0.007)
2024-04-06 08:52:10,720 - train - INFO - Train: 18 [ 500/781 ( 64%)]  Loss:  3.398947 (3.8329)  Time: 3.568s,   35.88/s  (3.301s,   38.78/s)  LR: 4.828e-04  Data: 0.012 (0.007)
2024-04-06 08:54:53,733 - train - INFO - Train: 18 [ 550/781 ( 71%)]  Loss:  4.061078 (3.8399)  Time: 3.315s,   38.61/s  (3.297s,   38.82/s)  LR: 4.828e-04  Data: 0.007 (0.007)
2024-04-06 08:57:37,816 - train - INFO - Train: 18 [ 600/781 ( 77%)]  Loss:  3.353904 (3.8389)  Time: 3.550s,   36.05/s  (3.296s,   38.84/s)  LR: 4.828e-04  Data: 0.006 (0.007)
2024-04-06 09:00:19,371 - train - INFO - Train: 18 [ 650/781 ( 83%)]  Loss:  3.450228 (3.8355)  Time: 2.939s,   43.55/s  (3.291s,   38.90/s)  LR: 4.828e-04  Data: 0.005 (0.007)
2024-04-06 09:03:09,701 - train - INFO - Train: 18 [ 700/781 ( 90%)]  Loss:  4.447930 (3.8349)  Time: 3.556s,   35.99/s  (3.299s,   38.80/s)  LR: 4.828e-04  Data: 0.010 (0.007)
2024-04-06 09:05:51,646 - train - INFO - Train: 18 [ 750/781 ( 96%)]  Loss:  3.550065 (3.8311)  Time: 3.137s,   40.80/s  (3.295s,   38.85/s)  LR: 4.828e-04  Data: 0.007 (0.007)
2024-04-06 09:07:29,446 - train - INFO - Train: 18 [ 780/781 (100%)]  Loss:  4.024469 (3.8342)  Time: 3.300s,   38.79/s  (3.294s,   38.86/s)  LR: 4.828e-04  Data: 0.000 (0.007)
2024-04-06 09:07:29,447 - train - INFO - True
2024-04-06 09:07:29,449 - train - INFO - alphas:tensor([0.3280, 0.2202, 0.1157, 0.1573, 0.1787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,449 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,449 - train - INFO - True
2024-04-06 09:07:29,450 - train - INFO - alphas:tensor([0.4112, 0.1333, 0.0978, 0.1550, 0.2026], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,450 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,450 - train - INFO - True
2024-04-06 09:07:29,451 - train - INFO - alphas:tensor([0.7336, 0.0960, 0.0484, 0.0571, 0.0649], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,451 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,451 - train - INFO - True
2024-04-06 09:07:29,451 - train - INFO - alphas:tensor([0.7254, 0.0835, 0.0484, 0.0649, 0.0777], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,452 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,452 - train - INFO - True
2024-04-06 09:07:29,452 - train - INFO - alphas:tensor([0.5794, 0.1007, 0.0748, 0.1091, 0.1360], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,452 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,453 - train - INFO - True
2024-04-06 09:07:29,453 - train - INFO - alphas:tensor([0.7011, 0.0935, 0.0523, 0.0687, 0.0845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,453 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,454 - train - INFO - True
2024-04-06 09:07:29,454 - train - INFO - alphas:tensor([0.7836, 0.0742, 0.0395, 0.0476, 0.0551], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,454 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,454 - train - INFO - True
2024-04-06 09:07:29,455 - train - INFO - alphas:tensor([0.7996, 0.0731, 0.0334, 0.0432, 0.0508], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,455 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,455 - train - INFO - True
2024-04-06 09:07:29,456 - train - INFO - alphas:tensor([0.6266, 0.0861, 0.0646, 0.0975, 0.1252], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,456 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,456 - train - INFO - True
2024-04-06 09:07:29,457 - train - INFO - alphas:tensor([0.7243, 0.0834, 0.0494, 0.0643, 0.0786], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,457 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,457 - train - INFO - True
2024-04-06 09:07:29,458 - train - INFO - alphas:tensor([0.7755, 0.0713, 0.0409, 0.0516, 0.0607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,458 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,458 - train - INFO - True
2024-04-06 09:07:29,459 - train - INFO - alphas:tensor([0.7585, 0.0774, 0.0404, 0.0541, 0.0696], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,459 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,459 - train - INFO - True
2024-04-06 09:07:29,460 - train - INFO - alphas:tensor([0.6422, 0.0807, 0.0606, 0.0921, 0.1244], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,460 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,460 - train - INFO - True
2024-04-06 09:07:29,461 - train - INFO - alphas:tensor([0.7410, 0.0747, 0.0471, 0.0626, 0.0747], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,461 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,461 - train - INFO - True
2024-04-06 09:07:29,462 - train - INFO - alphas:tensor([0.7657, 0.0793, 0.0397, 0.0517, 0.0636], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,462 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,462 - train - INFO - True
2024-04-06 09:07:29,463 - train - INFO - alphas:tensor([0.6944, 0.0906, 0.0508, 0.0701, 0.0940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,463 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,463 - train - INFO - True
2024-04-06 09:07:29,463 - train - INFO - alphas:tensor([0.6448, 0.0800, 0.0623, 0.0908, 0.1220], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,464 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,464 - train - INFO - True
2024-04-06 09:07:29,464 - train - INFO - alphas:tensor([0.7423, 0.0740, 0.0462, 0.0609, 0.0767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,465 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,465 - train - INFO - True
2024-04-06 09:07:29,465 - train - INFO - alphas:tensor([0.7858, 0.0707, 0.0397, 0.0470, 0.0568], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,465 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,465 - train - INFO - True
2024-04-06 09:07:29,466 - train - INFO - alphas:tensor([0.6799, 0.0839, 0.0515, 0.0759, 0.1088], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,466 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,466 - train - INFO - True
2024-04-06 09:07:29,467 - train - INFO - alphas:tensor([0.6287, 0.0838, 0.0626, 0.0967, 0.1282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,467 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,467 - train - INFO - True
2024-04-06 09:07:29,468 - train - INFO - alphas:tensor([0.7735, 0.0659, 0.0410, 0.0538, 0.0659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,468 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,468 - train - INFO - True
2024-04-06 09:07:29,469 - train - INFO - alphas:tensor([0.7939, 0.0683, 0.0363, 0.0459, 0.0556], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,469 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,469 - train - INFO - True
2024-04-06 09:07:29,470 - train - INFO - alphas:tensor([0.7047, 0.0748, 0.0471, 0.0711, 0.1023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,470 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,470 - train - INFO - True
2024-04-06 09:07:29,471 - train - INFO - alphas:tensor([0.6240, 0.0804, 0.0610, 0.1004, 0.1342], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,471 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,471 - train - INFO - True
2024-04-06 09:07:29,472 - train - INFO - alphas:tensor([0.7679, 0.0652, 0.0421, 0.0550, 0.0697], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,472 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,472 - train - INFO - True
2024-04-06 09:07:29,473 - train - INFO - alphas:tensor([0.7798, 0.0648, 0.0375, 0.0521, 0.0657], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,473 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,473 - train - INFO - True
2024-04-06 09:07:29,474 - train - INFO - alphas:tensor([0.7182, 0.0723, 0.0453, 0.0699, 0.0943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,474 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,474 - train - INFO - True
2024-04-06 09:07:29,475 - train - INFO - alphas:tensor([0.6006, 0.0769, 0.0683, 0.1066, 0.1477], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,475 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,475 - train - INFO - True
2024-04-06 09:07:29,476 - train - INFO - alphas:tensor([0.7514, 0.0658, 0.0439, 0.0599, 0.0790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,476 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,476 - train - INFO - True
2024-04-06 09:07:29,476 - train - INFO - alphas:tensor([0.7586, 0.0631, 0.0424, 0.0595, 0.0764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,477 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,477 - train - INFO - True
2024-04-06 09:07:29,477 - train - INFO - alphas:tensor([0.7383, 0.0686, 0.0448, 0.0642, 0.0842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,477 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,478 - train - INFO - True
2024-04-06 09:07:29,478 - train - INFO - alphas:tensor([0.5775, 0.0782, 0.0655, 0.1158, 0.1630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,478 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,478 - train - INFO - True
2024-04-06 09:07:29,479 - train - INFO - alphas:tensor([0.7128, 0.0732, 0.0506, 0.0712, 0.0922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,479 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,479 - train - INFO - True
2024-04-06 09:07:29,480 - train - INFO - alphas:tensor([0.7358, 0.0674, 0.0437, 0.0652, 0.0878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,480 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,480 - train - INFO - True
2024-04-06 09:07:29,481 - train - INFO - alphas:tensor([0.7255, 0.0730, 0.0463, 0.0676, 0.0875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,481 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,481 - train - INFO - True
2024-04-06 09:07:29,482 - train - INFO - alphas:tensor([0.6841, 0.0828, 0.1027, 0.1304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:07:29,482 - train - INFO - tau:0.8514577710948754
2024-04-06 09:07:29,482 - train - INFO - avg block size:1.0
2024-04-06 09:07:29,482 - train - INFO - lasso_alpha:1.610510000000001e-05
2024-04-06 09:07:31,706 - train - INFO - Test: [   0/78]  Time: 2.217 (2.217)  Loss:  1.0889 (1.0889)  Acc@1: 77.3438 (77.3438)  Acc@5: 90.6250 (90.6250)
2024-04-06 09:09:26,158 - train - INFO - Test: [  50/78]  Time: 2.503 (2.288)  Loss:  2.0156 (1.7467)  Acc@1: 52.3438 (59.7273)  Acc@5: 82.0312 (82.1998)
2024-04-06 09:10:30,736 - train - INFO - Test: [  78/78]  Time: 2.480 (2.294)  Loss:  1.6709 (1.7724)  Acc@1: 56.2500 (59.2600)  Acc@5: 93.7500 (81.8700)
2024-04-06 09:10:34,403 - train - INFO - Train: 19 [   0/781 (  0%)]  Loss:  4.340065 (4.3401)  Time: 3.586s,   35.69/s  (3.586s,   35.69/s)  LR: 4.809e-04  Data: 0.166 (0.166)
2024-04-06 09:13:26,492 - train - INFO - Train: 19 [  50/781 (  6%)]  Loss:  3.545168 (3.8962)  Time: 3.478s,   36.80/s  (3.445s,   37.16/s)  LR: 4.809e-04  Data: 0.007 (0.009)
2024-04-06 09:16:08,830 - train - INFO - Train: 19 [ 100/781 ( 13%)]  Loss:  3.101918 (3.8787)  Time: 3.027s,   42.28/s  (3.347s,   38.25/s)  LR: 4.809e-04  Data: 0.005 (0.008)
2024-04-06 09:18:50,456 - train - INFO - Train: 19 [ 150/781 ( 19%)]  Loss:  3.661051 (3.8635)  Time: 3.265s,   39.21/s  (3.309s,   38.68/s)  LR: 4.809e-04  Data: 0.009 (0.007)
2024-04-06 09:21:35,172 - train - INFO - Train: 19 [ 200/781 ( 26%)]  Loss:  3.954963 (3.8484)  Time: 3.333s,   38.40/s  (3.305s,   38.73/s)  LR: 4.809e-04  Data: 0.009 (0.007)
2024-04-06 09:24:36,074 - train - INFO - Train: 19 [ 250/781 ( 32%)]  Loss:  3.508871 (3.8516)  Time: 3.168s,   40.40/s  (3.368s,   38.01/s)  LR: 4.809e-04  Data: 0.004 (0.007)
2024-04-06 09:27:24,336 - train - INFO - Train: 19 [ 300/781 ( 38%)]  Loss:  3.256311 (3.8483)  Time: 3.181s,   40.24/s  (3.367s,   38.01/s)  LR: 4.809e-04  Data: 0.004 (0.007)
2024-04-06 09:30:10,233 - train - INFO - Train: 19 [ 350/781 ( 45%)]  Loss:  4.165662 (3.8397)  Time: 3.105s,   41.22/s  (3.360s,   38.09/s)  LR: 4.809e-04  Data: 0.006 (0.007)
2024-04-06 09:32:52,862 - train - INFO - Train: 19 [ 400/781 ( 51%)]  Loss:  4.394206 (3.8491)  Time: 3.097s,   41.33/s  (3.347s,   38.25/s)  LR: 4.809e-04  Data: 0.005 (0.007)
2024-04-06 09:35:43,546 - train - INFO - Train: 19 [ 450/781 ( 58%)]  Loss:  4.038625 (3.8472)  Time: 3.083s,   41.52/s  (3.354s,   38.16/s)  LR: 4.809e-04  Data: 0.005 (0.007)
2024-04-06 09:38:26,417 - train - INFO - Train: 19 [ 500/781 ( 64%)]  Loss:  3.217561 (3.8400)  Time: 3.260s,   39.26/s  (3.344s,   38.27/s)  LR: 4.809e-04  Data: 0.009 (0.007)
2024-04-06 09:41:08,783 - train - INFO - Train: 19 [ 550/781 ( 71%)]  Loss:  3.350032 (3.8407)  Time: 2.945s,   43.46/s  (3.336s,   38.37/s)  LR: 4.809e-04  Data: 0.005 (0.007)
2024-04-06 09:43:53,945 - train - INFO - Train: 19 [ 600/781 ( 77%)]  Loss:  3.242510 (3.8439)  Time: 3.879s,   33.00/s  (3.333s,   38.40/s)  LR: 4.809e-04  Data: 0.010 (0.007)
2024-04-06 09:46:43,251 - train - INFO - Train: 19 [ 650/781 ( 83%)]  Loss:  4.186344 (3.8496)  Time: 2.978s,   42.99/s  (3.337s,   38.36/s)  LR: 4.809e-04  Data: 0.005 (0.007)
2024-04-06 09:49:24,285 - train - INFO - Train: 19 [ 700/781 ( 90%)]  Loss:  3.817777 (3.8547)  Time: 3.329s,   38.45/s  (3.329s,   38.45/s)  LR: 4.809e-04  Data: 0.009 (0.007)
2024-04-06 09:52:07,328 - train - INFO - Train: 19 [ 750/781 ( 96%)]  Loss:  4.119292 (3.8571)  Time: 3.063s,   41.79/s  (3.324s,   38.51/s)  LR: 4.809e-04  Data: 0.006 (0.007)
2024-04-06 09:53:44,714 - train - INFO - Train: 19 [ 780/781 (100%)]  Loss:  3.306714 (3.8578)  Time: 2.876s,   44.51/s  (3.321s,   38.54/s)  LR: 4.809e-04  Data: 0.000 (0.007)
2024-04-06 09:53:44,715 - train - INFO - True
2024-04-06 09:53:44,716 - train - INFO - alphas:tensor([0.3294, 0.2166, 0.1146, 0.1584, 0.1810], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,716 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,716 - train - INFO - True
2024-04-06 09:53:44,717 - train - INFO - alphas:tensor([0.4127, 0.1286, 0.0959, 0.1558, 0.2070], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,717 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,717 - train - INFO - True
2024-04-06 09:53:44,718 - train - INFO - alphas:tensor([0.7418, 0.0927, 0.0467, 0.0555, 0.0633], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,718 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,718 - train - INFO - True
2024-04-06 09:53:44,719 - train - INFO - alphas:tensor([0.7334, 0.0799, 0.0466, 0.0635, 0.0767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,719 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,719 - train - INFO - True
2024-04-06 09:53:44,720 - train - INFO - alphas:tensor([0.5833, 0.0972, 0.0733, 0.1089, 0.1373], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,720 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,720 - train - INFO - True
2024-04-06 09:53:44,721 - train - INFO - alphas:tensor([0.7065, 0.0910, 0.0509, 0.0676, 0.0841], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,721 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,721 - train - INFO - True
2024-04-06 09:53:44,722 - train - INFO - alphas:tensor([0.7884, 0.0721, 0.0383, 0.0466, 0.0546], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,722 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,722 - train - INFO - True
2024-04-06 09:53:44,723 - train - INFO - alphas:tensor([0.8049, 0.0706, 0.0320, 0.0421, 0.0503], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,723 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,723 - train - INFO - True
2024-04-06 09:53:44,724 - train - INFO - alphas:tensor([0.6305, 0.0827, 0.0633, 0.0971, 0.1264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,724 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,724 - train - INFO - True
2024-04-06 09:53:44,725 - train - INFO - alphas:tensor([0.7286, 0.0811, 0.0482, 0.0634, 0.0786], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,725 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,725 - train - INFO - True
2024-04-06 09:53:44,725 - train - INFO - alphas:tensor([0.7773, 0.0688, 0.0405, 0.0518, 0.0616], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,726 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,726 - train - INFO - True
2024-04-06 09:53:44,726 - train - INFO - alphas:tensor([0.7601, 0.0759, 0.0392, 0.0540, 0.0708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,726 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,727 - train - INFO - True
2024-04-06 09:53:44,727 - train - INFO - alphas:tensor([0.6460, 0.0776, 0.0591, 0.0916, 0.1257], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,727 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,727 - train - INFO - True
2024-04-06 09:53:44,728 - train - INFO - alphas:tensor([0.7443, 0.0720, 0.0459, 0.0624, 0.0756], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,728 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,728 - train - INFO - True
2024-04-06 09:53:44,729 - train - INFO - alphas:tensor([0.7648, 0.0781, 0.0394, 0.0523, 0.0654], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,729 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,729 - train - INFO - True
2024-04-06 09:53:44,730 - train - INFO - alphas:tensor([0.6947, 0.0881, 0.0494, 0.0706, 0.0972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,730 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,730 - train - INFO - True
2024-04-06 09:53:44,731 - train - INFO - alphas:tensor([0.6482, 0.0768, 0.0610, 0.0906, 0.1235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,731 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,731 - train - INFO - True
2024-04-06 09:53:44,732 - train - INFO - alphas:tensor([0.7467, 0.0711, 0.0450, 0.0602, 0.0769], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,732 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,732 - train - INFO - True
2024-04-06 09:53:44,733 - train - INFO - alphas:tensor([0.7850, 0.0692, 0.0394, 0.0477, 0.0587], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,733 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,733 - train - INFO - True
2024-04-06 09:53:44,734 - train - INFO - alphas:tensor([0.6741, 0.0814, 0.0509, 0.0780, 0.1156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,734 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,734 - train - INFO - True
2024-04-06 09:53:44,735 - train - INFO - alphas:tensor([0.6287, 0.0810, 0.0617, 0.0972, 0.1314], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,735 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,735 - train - INFO - True
2024-04-06 09:53:44,735 - train - INFO - alphas:tensor([0.7760, 0.0635, 0.0398, 0.0537, 0.0670], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,736 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,736 - train - INFO - True
2024-04-06 09:53:44,736 - train - INFO - alphas:tensor([0.7953, 0.0664, 0.0355, 0.0462, 0.0566], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,737 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,737 - train - INFO - True
2024-04-06 09:53:44,737 - train - INFO - alphas:tensor([0.6995, 0.0734, 0.0462, 0.0727, 0.1083], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,737 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,737 - train - INFO - True
2024-04-06 09:53:44,738 - train - INFO - alphas:tensor([0.6244, 0.0768, 0.0600, 0.1011, 0.1376], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,738 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,739 - train - INFO - True
2024-04-06 09:53:44,739 - train - INFO - alphas:tensor([0.7724, 0.0624, 0.0410, 0.0542, 0.0699], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,739 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,739 - train - INFO - True
2024-04-06 09:53:44,740 - train - INFO - alphas:tensor([0.7754, 0.0642, 0.0377, 0.0536, 0.0691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,740 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,740 - train - INFO - True
2024-04-06 09:53:44,741 - train - INFO - alphas:tensor([0.7108, 0.0708, 0.0449, 0.0725, 0.1010], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,741 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,741 - train - INFO - True
2024-04-06 09:53:44,742 - train - INFO - alphas:tensor([0.6018, 0.0722, 0.0670, 0.1073, 0.1517], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,742 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,742 - train - INFO - True
2024-04-06 09:53:44,743 - train - INFO - alphas:tensor([0.7485, 0.0654, 0.0439, 0.0607, 0.0815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,743 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,743 - train - INFO - True
2024-04-06 09:53:44,744 - train - INFO - alphas:tensor([0.7591, 0.0614, 0.0414, 0.0596, 0.0784], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,744 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,744 - train - INFO - True
2024-04-06 09:53:44,745 - train - INFO - alphas:tensor([0.7362, 0.0668, 0.0439, 0.0654, 0.0877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,745 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,745 - train - INFO - True
2024-04-06 09:53:44,746 - train - INFO - alphas:tensor([0.5776, 0.0745, 0.0642, 0.1164, 0.1673], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,746 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,746 - train - INFO - True
2024-04-06 09:53:44,747 - train - INFO - alphas:tensor([0.7139, 0.0707, 0.0498, 0.0715, 0.0942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,747 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,747 - train - INFO - True
2024-04-06 09:53:44,747 - train - INFO - alphas:tensor([0.7353, 0.0656, 0.0431, 0.0659, 0.0901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,748 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,748 - train - INFO - True
2024-04-06 09:53:44,748 - train - INFO - alphas:tensor([0.7273, 0.0702, 0.0450, 0.0678, 0.0898], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,749 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,749 - train - INFO - True
2024-04-06 09:53:44,749 - train - INFO - alphas:tensor([0.6897, 0.0806, 0.1008, 0.1289], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 09:53:44,749 - train - INFO - tau:0.8429431933839266
2024-04-06 09:53:44,749 - train - INFO - avg block size:1.0
2024-04-06 09:53:46,810 - train - INFO - Test: [   0/78]  Time: 2.054 (2.054)  Loss:  0.9639 (0.9639)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-06 09:55:52,495 - train - INFO - Test: [  50/78]  Time: 2.495 (2.505)  Loss:  1.8613 (1.7414)  Acc@1: 57.8125 (59.3597)  Acc@5: 82.0312 (82.4295)
2024-04-06 09:56:54,519 - train - INFO - Test: [  78/78]  Time: 2.311 (2.402)  Loss:  2.1543 (1.7736)  Acc@1: 50.0000 (58.8000)  Acc@5: 87.5000 (81.9200)
2024-04-06 09:56:58,089 - train - INFO - Train: 20 [   0/781 (  0%)]  Loss:  3.469356 (3.4694)  Time: 3.486s,   36.72/s  (3.486s,   36.72/s)  LR: 4.788e-04  Data: 0.124 (0.124)
2024-04-06 09:59:47,712 - train - INFO - Train: 20 [  50/781 (  6%)]  Loss:  3.350643 (3.7536)  Time: 3.422s,   37.40/s  (3.394s,   37.71/s)  LR: 4.788e-04  Data: 0.018 (0.010)
2024-04-06 10:02:35,416 - train - INFO - Train: 20 [ 100/781 ( 13%)]  Loss:  3.552532 (3.7816)  Time: 3.524s,   36.32/s  (3.374s,   37.93/s)  LR: 4.788e-04  Data: 0.005 (0.008)
2024-04-06 10:05:21,171 - train - INFO - Train: 20 [ 150/781 ( 19%)]  Loss:  4.282907 (3.8429)  Time: 3.103s,   41.25/s  (3.355s,   38.16/s)  LR: 4.788e-04  Data: 0.005 (0.008)
2024-04-06 10:08:09,350 - train - INFO - Train: 20 [ 200/781 ( 26%)]  Loss:  4.431647 (3.8356)  Time: 3.449s,   37.11/s  (3.357s,   38.13/s)  LR: 4.788e-04  Data: 0.007 (0.007)
2024-04-06 10:10:49,250 - train - INFO - Train: 20 [ 250/781 ( 32%)]  Loss:  3.866727 (3.8474)  Time: 3.075s,   41.63/s  (3.325s,   38.49/s)  LR: 4.788e-04  Data: 0.006 (0.007)
2024-04-06 10:13:28,802 - train - INFO - Train: 20 [ 300/781 ( 38%)]  Loss:  4.335185 (3.8707)  Time: 3.162s,   40.48/s  (3.303s,   38.75/s)  LR: 4.788e-04  Data: 0.009 (0.007)
2024-04-06 10:16:12,181 - train - INFO - Train: 20 [ 350/781 ( 45%)]  Loss:  3.997227 (3.8764)  Time: 3.130s,   40.89/s  (3.298s,   38.81/s)  LR: 4.788e-04  Data: 0.005 (0.007)
2024-04-06 10:19:05,911 - train - INFO - Train: 20 [ 400/781 ( 51%)]  Loss:  4.272721 (3.8631)  Time: 3.335s,   38.38/s  (3.320s,   38.55/s)  LR: 4.788e-04  Data: 0.005 (0.007)
2024-04-06 10:21:49,652 - train - INFO - Train: 20 [ 450/781 ( 58%)]  Loss:  3.779616 (3.8619)  Time: 3.649s,   35.08/s  (3.315s,   38.61/s)  LR: 4.788e-04  Data: 0.007 (0.007)
2024-04-06 10:24:30,339 - train - INFO - Train: 20 [ 500/781 ( 64%)]  Loss:  3.917035 (3.8701)  Time: 3.156s,   40.56/s  (3.305s,   38.73/s)  LR: 4.788e-04  Data: 0.009 (0.007)
2024-04-06 10:27:11,142 - train - INFO - Train: 20 [ 550/781 ( 71%)]  Loss:  3.421327 (3.8714)  Time: 3.084s,   41.51/s  (3.297s,   38.83/s)  LR: 4.788e-04  Data: 0.005 (0.007)
2024-04-06 10:30:02,775 - train - INFO - Train: 20 [ 600/781 ( 77%)]  Loss:  4.062134 (3.8731)  Time: 3.659s,   34.98/s  (3.308s,   38.69/s)  LR: 4.788e-04  Data: 0.012 (0.007)
2024-04-06 10:32:48,897 - train - INFO - Train: 20 [ 650/781 ( 83%)]  Loss:  3.482903 (3.8649)  Time: 4.847s,   26.41/s  (3.309s,   38.68/s)  LR: 4.788e-04  Data: 0.005 (0.007)
2024-04-06 10:35:40,493 - train - INFO - Train: 20 [ 700/781 ( 90%)]  Loss:  3.468518 (3.8612)  Time: 3.214s,   39.82/s  (3.318s,   38.58/s)  LR: 4.788e-04  Data: 0.009 (0.007)
2024-04-06 10:38:32,681 - train - INFO - Train: 20 [ 750/781 ( 96%)]  Loss:  4.148579 (3.8580)  Time: 3.931s,   32.56/s  (3.326s,   38.48/s)  LR: 4.788e-04  Data: 0.005 (0.007)
2024-04-06 10:40:18,205 - train - INFO - Train: 20 [ 780/781 (100%)]  Loss:  4.447033 (3.8538)  Time: 3.092s,   41.39/s  (3.334s,   38.40/s)  LR: 4.788e-04  Data: 0.000 (0.007)
2024-04-06 10:40:18,206 - train - INFO - True
2024-04-06 10:40:18,209 - train - INFO - alphas:tensor([0.3307, 0.2143, 0.1134, 0.1588, 0.1828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,210 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,210 - train - INFO - True
2024-04-06 10:40:18,212 - train - INFO - alphas:tensor([0.4138, 0.1240, 0.0942, 0.1565, 0.2114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,212 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,212 - train - INFO - True
2024-04-06 10:40:18,214 - train - INFO - alphas:tensor([0.7475, 0.0900, 0.0455, 0.0545, 0.0624], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,214 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,214 - train - INFO - True
2024-04-06 10:40:18,215 - train - INFO - alphas:tensor([0.7372, 0.0779, 0.0455, 0.0628, 0.0765], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,216 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,216 - train - INFO - True
2024-04-06 10:40:18,217 - train - INFO - alphas:tensor([0.5850, 0.0937, 0.0725, 0.1093, 0.1395], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,218 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,218 - train - INFO - True
2024-04-06 10:40:18,219 - train - INFO - alphas:tensor([0.7108, 0.0885, 0.0496, 0.0668, 0.0842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,219 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,219 - train - INFO - True
2024-04-06 10:40:18,221 - train - INFO - alphas:tensor([0.7939, 0.0693, 0.0370, 0.0458, 0.0541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,221 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,221 - train - INFO - True
2024-04-06 10:40:18,223 - train - INFO - alphas:tensor([0.8087, 0.0687, 0.0310, 0.0415, 0.0501], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,223 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,223 - train - INFO - True
2024-04-06 10:40:18,225 - train - INFO - alphas:tensor([0.6319, 0.0803, 0.0624, 0.0972, 0.1282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,225 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,225 - train - INFO - True
2024-04-06 10:40:18,226 - train - INFO - alphas:tensor([0.7324, 0.0784, 0.0471, 0.0630, 0.0790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,226 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,227 - train - INFO - True
2024-04-06 10:40:18,228 - train - INFO - alphas:tensor([0.7778, 0.0671, 0.0401, 0.0522, 0.0627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,228 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,228 - train - INFO - True
2024-04-06 10:40:18,230 - train - INFO - alphas:tensor([0.7613, 0.0741, 0.0383, 0.0540, 0.0722], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,230 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,230 - train - INFO - True
2024-04-06 10:40:18,231 - train - INFO - alphas:tensor([0.6471, 0.0748, 0.0581, 0.0919, 0.1281], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,231 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,232 - train - INFO - True
2024-04-06 10:40:18,233 - train - INFO - alphas:tensor([0.7461, 0.0698, 0.0451, 0.0623, 0.0767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,233 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,233 - train - INFO - True
2024-04-06 10:40:18,235 - train - INFO - alphas:tensor([0.7640, 0.0769, 0.0389, 0.0529, 0.0674], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,235 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,235 - train - INFO - True
2024-04-06 10:40:18,236 - train - INFO - alphas:tensor([0.6952, 0.0852, 0.0480, 0.0711, 0.1005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,236 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,237 - train - INFO - True
2024-04-06 10:40:18,238 - train - INFO - alphas:tensor([0.6489, 0.0742, 0.0601, 0.0908, 0.1259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,238 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,238 - train - INFO - True
2024-04-06 10:40:18,239 - train - INFO - alphas:tensor([0.7509, 0.0682, 0.0439, 0.0596, 0.0774], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,240 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,240 - train - INFO - True
2024-04-06 10:40:18,241 - train - INFO - alphas:tensor([0.7858, 0.0676, 0.0388, 0.0477, 0.0600], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,241 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,241 - train - INFO - True
2024-04-06 10:40:18,243 - train - INFO - alphas:tensor([0.6752, 0.0786, 0.0490, 0.0779, 0.1193], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,243 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,243 - train - INFO - True
2024-04-06 10:40:18,244 - train - INFO - alphas:tensor([0.6300, 0.0780, 0.0606, 0.0975, 0.1338], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,244 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,244 - train - INFO - True
2024-04-06 10:40:18,246 - train - INFO - alphas:tensor([0.7790, 0.0616, 0.0389, 0.0530, 0.0675], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,246 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,246 - train - INFO - True
2024-04-06 10:40:18,247 - train - INFO - alphas:tensor([0.7948, 0.0647, 0.0350, 0.0468, 0.0587], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,247 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,248 - train - INFO - True
2024-04-06 10:40:18,249 - train - INFO - alphas:tensor([0.6972, 0.0706, 0.0449, 0.0738, 0.1135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,249 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,249 - train - INFO - True
2024-04-06 10:40:18,250 - train - INFO - alphas:tensor([0.6241, 0.0742, 0.0592, 0.1016, 0.1409], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,250 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,250 - train - INFO - True
2024-04-06 10:40:18,252 - train - INFO - alphas:tensor([0.7721, 0.0620, 0.0404, 0.0542, 0.0713], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,252 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,252 - train - INFO - True
2024-04-06 10:40:18,253 - train - INFO - alphas:tensor([0.7774, 0.0620, 0.0366, 0.0534, 0.0705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,253 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,253 - train - INFO - True
2024-04-06 10:40:18,255 - train - INFO - alphas:tensor([0.7101, 0.0693, 0.0435, 0.0726, 0.1046], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,255 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,255 - train - INFO - True
2024-04-06 10:40:18,256 - train - INFO - alphas:tensor([0.6010, 0.0701, 0.0660, 0.1079, 0.1550], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,256 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,256 - train - INFO - True
2024-04-06 10:40:18,258 - train - INFO - alphas:tensor([0.7532, 0.0624, 0.0424, 0.0598, 0.0821], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,258 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,258 - train - INFO - True
2024-04-06 10:40:18,259 - train - INFO - alphas:tensor([0.7618, 0.0584, 0.0403, 0.0596, 0.0799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,259 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,259 - train - INFO - True
2024-04-06 10:40:18,260 - train - INFO - alphas:tensor([0.7366, 0.0647, 0.0426, 0.0656, 0.0906], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,261 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,261 - train - INFO - True
2024-04-06 10:40:18,262 - train - INFO - alphas:tensor([0.5765, 0.0716, 0.0630, 0.1171, 0.1718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,262 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,262 - train - INFO - True
2024-04-06 10:40:18,263 - train - INFO - alphas:tensor([0.7143, 0.0686, 0.0486, 0.0717, 0.0967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,263 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,263 - train - INFO - True
2024-04-06 10:40:18,265 - train - INFO - alphas:tensor([0.7351, 0.0639, 0.0421, 0.0662, 0.0927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,265 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,265 - train - INFO - True
2024-04-06 10:40:18,266 - train - INFO - alphas:tensor([0.7289, 0.0681, 0.0437, 0.0676, 0.0917], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,266 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,266 - train - INFO - True
2024-04-06 10:40:18,267 - train - INFO - alphas:tensor([0.6938, 0.0789, 0.0993, 0.1280], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 10:40:18,268 - train - INFO - tau:0.8345137614500874
2024-04-06 10:40:18,268 - train - INFO - avg block size:1.0
2024-04-06 10:40:20,760 - train - INFO - Test: [   0/78]  Time: 2.480 (2.480)  Loss:  1.1221 (1.1221)  Acc@1: 75.7812 (75.7812)  Acc@5: 91.4062 (91.4062)
2024-04-06 10:42:13,074 - train - INFO - Test: [  50/78]  Time: 2.093 (2.251)  Loss:  2.0156 (1.7279)  Acc@1: 51.5625 (59.5282)  Acc@5: 77.3438 (82.6134)
2024-04-06 10:43:15,627 - train - INFO - Test: [  78/78]  Time: 2.375 (2.245)  Loss:  1.7871 (1.7505)  Acc@1: 62.5000 (59.2800)  Acc@5: 81.2500 (82.2400)
2024-04-06 10:43:19,020 - train - INFO - Train: 21 [   0/781 (  0%)]  Loss:  4.342682 (4.3427)  Time: 3.309s,   38.69/s  (3.309s,   38.69/s)  LR: 4.767e-04  Data: 0.137 (0.137)
2024-04-06 10:46:01,031 - train - INFO - Train: 21 [  50/781 (  6%)]  Loss:  3.949717 (3.8530)  Time: 2.923s,   43.79/s  (3.242s,   39.49/s)  LR: 4.767e-04  Data: 0.005 (0.010)
2024-04-06 10:48:42,806 - train - INFO - Train: 21 [ 100/781 ( 13%)]  Loss:  4.280313 (3.8183)  Time: 3.212s,   39.86/s  (3.239s,   39.52/s)  LR: 4.767e-04  Data: 0.015 (0.009)
2024-04-06 10:51:33,070 - train - INFO - Train: 21 [ 150/781 ( 19%)]  Loss:  4.262799 (3.8418)  Time: 3.120s,   41.02/s  (3.294s,   38.86/s)  LR: 4.767e-04  Data: 0.005 (0.008)
2024-04-06 10:54:14,633 - train - INFO - Train: 21 [ 200/781 ( 26%)]  Loss:  4.226137 (3.8583)  Time: 3.519s,   36.37/s  (3.278s,   39.05/s)  LR: 4.767e-04  Data: 0.005 (0.007)
2024-04-06 10:56:54,912 - train - INFO - Train: 21 [ 250/781 ( 32%)]  Loss:  4.306605 (3.8733)  Time: 3.462s,   36.98/s  (3.264s,   39.22/s)  LR: 4.767e-04  Data: 0.008 (0.007)
2024-04-06 10:59:34,718 - train - INFO - Train: 21 [ 300/781 ( 38%)]  Loss:  3.332593 (3.8590)  Time: 3.058s,   41.86/s  (3.252s,   39.35/s)  LR: 4.767e-04  Data: 0.005 (0.007)
2024-04-06 11:02:22,638 - train - INFO - Train: 21 [ 350/781 ( 45%)]  Loss:  4.215108 (3.8717)  Time: 3.047s,   42.01/s  (3.268s,   39.17/s)  LR: 4.767e-04  Data: 0.004 (0.007)
2024-04-06 11:05:03,228 - train - INFO - Train: 21 [ 400/781 ( 51%)]  Loss:  3.306105 (3.8726)  Time: 3.375s,   37.92/s  (3.261s,   39.26/s)  LR: 4.767e-04  Data: 0.005 (0.007)
2024-04-06 11:07:46,629 - train - INFO - Train: 21 [ 450/781 ( 58%)]  Loss:  4.341535 (3.8679)  Time: 3.129s,   40.90/s  (3.261s,   39.25/s)  LR: 4.767e-04  Data: 0.004 (0.007)
2024-04-06 11:10:29,753 - train - INFO - Train: 21 [ 500/781 ( 64%)]  Loss:  4.252712 (3.8641)  Time: 3.652s,   35.05/s  (3.262s,   39.25/s)  LR: 4.767e-04  Data: 0.009 (0.007)
2024-04-06 11:13:17,726 - train - INFO - Train: 21 [ 550/781 ( 71%)]  Loss:  4.105091 (3.8565)  Time: 3.156s,   40.56/s  (3.270s,   39.14/s)  LR: 4.767e-04  Data: 0.007 (0.007)
2024-04-06 11:16:08,768 - train - INFO - Train: 21 [ 600/781 ( 77%)]  Loss:  4.317759 (3.8472)  Time: 3.158s,   40.53/s  (3.283s,   38.99/s)  LR: 4.767e-04  Data: 0.005 (0.007)
2024-04-06 11:18:56,475 - train - INFO - Train: 21 [ 650/781 ( 83%)]  Loss:  3.987497 (3.8470)  Time: 3.302s,   38.77/s  (3.288s,   38.92/s)  LR: 4.767e-04  Data: 0.005 (0.007)
2024-04-06 11:21:41,359 - train - INFO - Train: 21 [ 700/781 ( 90%)]  Loss:  3.247460 (3.8466)  Time: 3.523s,   36.33/s  (3.289s,   38.92/s)  LR: 4.767e-04  Data: 0.005 (0.007)
2024-04-06 11:24:44,613 - train - INFO - Train: 21 [ 750/781 ( 96%)]  Loss:  4.244259 (3.8487)  Time: 3.517s,   36.40/s  (3.314s,   38.62/s)  LR: 4.767e-04  Data: 0.004 (0.007)
2024-04-06 11:26:24,955 - train - INFO - Train: 21 [ 780/781 (100%)]  Loss:  4.121272 (3.8489)  Time: 3.386s,   37.81/s  (3.315s,   38.61/s)  LR: 4.767e-04  Data: 0.000 (0.007)
2024-04-06 11:26:24,956 - train - INFO - True
2024-04-06 11:26:24,958 - train - INFO - alphas:tensor([0.3300, 0.2112, 0.1128, 0.1602, 0.1857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,959 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,959 - train - INFO - True
2024-04-06 11:26:24,961 - train - INFO - alphas:tensor([0.4147, 0.1180, 0.0927, 0.1578, 0.2168], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,961 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,961 - train - INFO - True
2024-04-06 11:26:24,963 - train - INFO - alphas:tensor([0.7542, 0.0873, 0.0441, 0.0532, 0.0612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,963 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,963 - train - INFO - True
2024-04-06 11:26:24,964 - train - INFO - alphas:tensor([0.7445, 0.0747, 0.0438, 0.0614, 0.0754], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,965 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,965 - train - INFO - True
2024-04-06 11:26:24,966 - train - INFO - alphas:tensor([0.5883, 0.0909, 0.0710, 0.1087, 0.1410], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,966 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,967 - train - INFO - True
2024-04-06 11:26:24,968 - train - INFO - alphas:tensor([0.7127, 0.0866, 0.0491, 0.0667, 0.0849], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,968 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,968 - train - INFO - True
2024-04-06 11:26:24,970 - train - INFO - alphas:tensor([0.7972, 0.0671, 0.0363, 0.0454, 0.0540], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,970 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,970 - train - INFO - True
2024-04-06 11:26:24,972 - train - INFO - alphas:tensor([0.8097, 0.0679, 0.0304, 0.0414, 0.0507], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,972 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,972 - train - INFO - True
2024-04-06 11:26:24,973 - train - INFO - alphas:tensor([0.6365, 0.0775, 0.0609, 0.0962, 0.1288], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,974 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,974 - train - INFO - True
2024-04-06 11:26:24,975 - train - INFO - alphas:tensor([0.7368, 0.0765, 0.0458, 0.0621, 0.0788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,975 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,976 - train - INFO - True
2024-04-06 11:26:24,977 - train - INFO - alphas:tensor([0.7798, 0.0651, 0.0394, 0.0522, 0.0635], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,977 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,977 - train - INFO - True
2024-04-06 11:26:24,979 - train - INFO - alphas:tensor([0.7657, 0.0715, 0.0369, 0.0533, 0.0726], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,979 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,979 - train - INFO - True
2024-04-06 11:26:24,980 - train - INFO - alphas:tensor([0.6491, 0.0723, 0.0570, 0.0918, 0.1298], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,980 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,981 - train - INFO - True
2024-04-06 11:26:24,982 - train - INFO - alphas:tensor([0.7472, 0.0683, 0.0443, 0.0623, 0.0780], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,982 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,982 - train - INFO - True
2024-04-06 11:26:24,984 - train - INFO - alphas:tensor([0.7630, 0.0757, 0.0387, 0.0535, 0.0692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,984 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,984 - train - INFO - True
2024-04-06 11:26:24,985 - train - INFO - alphas:tensor([0.6946, 0.0825, 0.0467, 0.0719, 0.1043], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,985 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,986 - train - INFO - True
2024-04-06 11:26:24,987 - train - INFO - alphas:tensor([0.6524, 0.0716, 0.0588, 0.0901, 0.1272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,987 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,987 - train - INFO - True
2024-04-06 11:26:24,988 - train - INFO - alphas:tensor([0.7531, 0.0663, 0.0428, 0.0593, 0.0785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,989 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,989 - train - INFO - True
2024-04-06 11:26:24,990 - train - INFO - alphas:tensor([0.7853, 0.0667, 0.0382, 0.0481, 0.0617], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,990 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,990 - train - INFO - True
2024-04-06 11:26:24,992 - train - INFO - alphas:tensor([0.6744, 0.0756, 0.0473, 0.0785, 0.1241], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,992 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,992 - train - INFO - True
2024-04-06 11:26:24,993 - train - INFO - alphas:tensor([0.6320, 0.0751, 0.0594, 0.0974, 0.1361], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,993 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,994 - train - INFO - True
2024-04-06 11:26:24,995 - train - INFO - alphas:tensor([0.7802, 0.0601, 0.0380, 0.0529, 0.0686], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,995 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,995 - train - INFO - True
2024-04-06 11:26:24,996 - train - INFO - alphas:tensor([0.7931, 0.0645, 0.0348, 0.0473, 0.0603], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,996 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,997 - train - INFO - True
2024-04-06 11:26:24,998 - train - INFO - alphas:tensor([0.6937, 0.0676, 0.0442, 0.0750, 0.1195], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,998 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:24,998 - train - INFO - True
2024-04-06 11:26:24,999 - train - INFO - alphas:tensor([0.6241, 0.0716, 0.0582, 0.1020, 0.1441], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:24,999 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:25,000 - train - INFO - True
2024-04-06 11:26:25,001 - train - INFO - alphas:tensor([0.7763, 0.0597, 0.0391, 0.0534, 0.0715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:25,001 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:25,001 - train - INFO - True
2024-04-06 11:26:25,002 - train - INFO - alphas:tensor([0.7789, 0.0601, 0.0359, 0.0533, 0.0718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:25,002 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:25,003 - train - INFO - True
2024-04-06 11:26:25,004 - train - INFO - alphas:tensor([0.7097, 0.0670, 0.0420, 0.0728, 0.1085], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:25,004 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:25,004 - train - INFO - True
2024-04-06 11:26:25,005 - train - INFO - alphas:tensor([0.6003, 0.0670, 0.0649, 0.1085, 0.1593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:25,005 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:25,006 - train - INFO - True
2024-04-06 11:26:25,007 - train - INFO - alphas:tensor([0.7537, 0.0608, 0.0416, 0.0602, 0.0837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:25,007 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:25,007 - train - INFO - True
2024-04-06 11:26:25,008 - train - INFO - alphas:tensor([0.7590, 0.0572, 0.0400, 0.0607, 0.0830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:25,008 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:25,008 - train - INFO - True
2024-04-06 11:26:25,010 - train - INFO - alphas:tensor([0.7355, 0.0632, 0.0417, 0.0660, 0.0936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:25,010 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:25,010 - train - INFO - True
2024-04-06 11:26:25,011 - train - INFO - alphas:tensor([0.5776, 0.0684, 0.0618, 0.1170, 0.1752], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:25,011 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:25,011 - train - INFO - True
2024-04-06 11:26:25,012 - train - INFO - alphas:tensor([0.7126, 0.0677, 0.0478, 0.0722, 0.0997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:25,013 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:25,013 - train - INFO - True
2024-04-06 11:26:25,014 - train - INFO - alphas:tensor([0.7355, 0.0625, 0.0410, 0.0661, 0.0950], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:25,014 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:25,014 - train - INFO - True
2024-04-06 11:26:25,015 - train - INFO - alphas:tensor([0.7286, 0.0664, 0.0426, 0.0679, 0.0945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:25,015 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:25,015 - train - INFO - True
2024-04-06 11:26:25,017 - train - INFO - alphas:tensor([0.6990, 0.0768, 0.0975, 0.1266], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 11:26:25,017 - train - INFO - tau:0.8261686238355865
2024-04-06 11:26:25,017 - train - INFO - avg block size:1.0
2024-04-06 11:26:25,017 - train - INFO - lasso_alpha:1.771561000000001e-05
2024-04-06 11:26:27,895 - train - INFO - Test: [   0/78]  Time: 2.867 (2.867)  Loss:  0.8740 (0.8740)  Acc@1: 81.2500 (81.2500)  Acc@5: 94.5312 (94.5312)
2024-04-06 11:28:24,786 - train - INFO - Test: [  50/78]  Time: 2.090 (2.348)  Loss:  2.0391 (1.7594)  Acc@1: 52.3438 (58.6703)  Acc@5: 76.5625 (82.3836)
2024-04-06 11:29:28,051 - train - INFO - Test: [  78/78]  Time: 2.115 (2.317)  Loss:  2.3379 (1.7858)  Acc@1: 37.5000 (58.1500)  Acc@5: 87.5000 (82.0400)
2024-04-06 11:29:31,566 - train - INFO - Train: 22 [   0/781 (  0%)]  Loss:  3.384968 (3.3850)  Time: 3.439s,   37.22/s  (3.439s,   37.22/s)  LR: 4.744e-04  Data: 0.163 (0.163)
2024-04-06 11:32:13,100 - train - INFO - Train: 22 [  50/781 (  6%)]  Loss:  4.288399 (3.9615)  Time: 3.122s,   41.00/s  (3.235s,   39.57/s)  LR: 4.744e-04  Data: 0.004 (0.010)
2024-04-06 11:35:03,683 - train - INFO - Train: 22 [ 100/781 ( 13%)]  Loss:  4.102452 (3.9406)  Time: 3.566s,   35.89/s  (3.322s,   38.53/s)  LR: 4.744e-04  Data: 0.009 (0.008)
2024-04-06 11:37:45,119 - train - INFO - Train: 22 [ 150/781 ( 19%)]  Loss:  4.352513 (3.9336)  Time: 3.150s,   40.64/s  (3.291s,   38.89/s)  LR: 4.744e-04  Data: 0.012 (0.008)
2024-04-06 11:40:27,359 - train - INFO - Train: 22 [ 200/781 ( 26%)]  Loss:  3.944736 (3.9398)  Time: 2.984s,   42.90/s  (3.280s,   39.03/s)  LR: 4.744e-04  Data: 0.005 (0.007)
2024-04-06 11:43:09,840 - train - INFO - Train: 22 [ 250/781 ( 32%)]  Loss:  4.225550 (3.9278)  Time: 3.553s,   36.03/s  (3.274s,   39.10/s)  LR: 4.744e-04  Data: 0.009 (0.007)
2024-04-06 11:45:59,721 - train - INFO - Train: 22 [ 300/781 ( 38%)]  Loss:  3.245443 (3.9121)  Time: 3.026s,   42.30/s  (3.294s,   38.85/s)  LR: 4.744e-04  Data: 0.009 (0.007)
2024-04-06 11:48:42,854 - train - INFO - Train: 22 [ 350/781 ( 45%)]  Loss:  4.332141 (3.8989)  Time: 3.573s,   35.83/s  (3.290s,   38.91/s)  LR: 4.744e-04  Data: 0.008 (0.007)
2024-04-06 11:51:24,730 - train - INFO - Train: 22 [ 400/781 ( 51%)]  Loss:  3.779387 (3.8919)  Time: 3.047s,   42.00/s  (3.283s,   38.99/s)  LR: 4.744e-04  Data: 0.008 (0.007)
2024-04-06 11:54:09,478 - train - INFO - Train: 22 [ 450/781 ( 58%)]  Loss:  3.835218 (3.8871)  Time: 3.754s,   34.10/s  (3.285s,   38.97/s)  LR: 4.744e-04  Data: 0.005 (0.007)
2024-04-06 11:57:00,251 - train - INFO - Train: 22 [ 500/781 ( 64%)]  Loss:  3.452966 (3.8828)  Time: 3.507s,   36.50/s  (3.298s,   38.82/s)  LR: 4.744e-04  Data: 0.022 (0.007)
2024-04-06 11:59:44,172 - train - INFO - Train: 22 [ 550/781 ( 71%)]  Loss:  3.930182 (3.8773)  Time: 3.552s,   36.04/s  (3.296s,   38.84/s)  LR: 4.744e-04  Data: 0.009 (0.007)
2024-04-06 12:02:26,398 - train - INFO - Train: 22 [ 600/781 ( 77%)]  Loss:  4.303977 (3.8731)  Time: 2.986s,   42.87/s  (3.292s,   38.89/s)  LR: 4.744e-04  Data: 0.004 (0.007)
2024-04-06 12:05:12,527 - train - INFO - Train: 22 [ 650/781 ( 83%)]  Loss:  4.091023 (3.8637)  Time: 3.737s,   34.25/s  (3.294s,   38.86/s)  LR: 4.744e-04  Data: 0.006 (0.007)
2024-04-06 12:07:58,371 - train - INFO - Train: 22 [ 700/781 ( 90%)]  Loss:  4.139904 (3.8623)  Time: 3.190s,   40.13/s  (3.296s,   38.84/s)  LR: 4.744e-04  Data: 0.007 (0.007)
2024-04-06 12:10:42,818 - train - INFO - Train: 22 [ 750/781 ( 96%)]  Loss:  3.622832 (3.8641)  Time: 3.387s,   37.79/s  (3.295s,   38.84/s)  LR: 4.744e-04  Data: 0.009 (0.007)
2024-04-06 12:12:21,600 - train - INFO - Train: 22 [ 780/781 (100%)]  Loss:  4.330485 (3.8660)  Time: 3.534s,   36.22/s  (3.295s,   38.85/s)  LR: 4.744e-04  Data: 0.000 (0.007)
2024-04-06 12:12:21,601 - train - INFO - True
2024-04-06 12:12:21,603 - train - INFO - alphas:tensor([0.3300, 0.2082, 0.1120, 0.1613, 0.1885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,603 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,603 - train - INFO - True
2024-04-06 12:12:21,604 - train - INFO - alphas:tensor([0.4135, 0.1142, 0.0915, 0.1587, 0.2221], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,604 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,604 - train - INFO - True
2024-04-06 12:12:21,605 - train - INFO - alphas:tensor([0.7595, 0.0851, 0.0430, 0.0521, 0.0603], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,605 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,605 - train - INFO - True
2024-04-06 12:12:21,605 - train - INFO - alphas:tensor([0.7489, 0.0729, 0.0427, 0.0605, 0.0750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,606 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,606 - train - INFO - True
2024-04-06 12:12:21,606 - train - INFO - alphas:tensor([0.5869, 0.0894, 0.0705, 0.1096, 0.1437], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,606 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,607 - train - INFO - True
2024-04-06 12:12:21,607 - train - INFO - alphas:tensor([0.7155, 0.0840, 0.0481, 0.0667, 0.0856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,607 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,607 - train - INFO - True
2024-04-06 12:12:21,608 - train - INFO - alphas:tensor([0.7988, 0.0660, 0.0357, 0.0451, 0.0543], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,608 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,608 - train - INFO - True
2024-04-06 12:12:21,609 - train - INFO - alphas:tensor([0.8095, 0.0679, 0.0298, 0.0413, 0.0515], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,609 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,609 - train - INFO - True
2024-04-06 12:12:21,610 - train - INFO - alphas:tensor([0.6351, 0.0758, 0.0604, 0.0969, 0.1317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,610 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,610 - train - INFO - True
2024-04-06 12:12:21,611 - train - INFO - alphas:tensor([0.7376, 0.0748, 0.0452, 0.0623, 0.0801], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,611 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,611 - train - INFO - True
2024-04-06 12:12:21,612 - train - INFO - alphas:tensor([0.7813, 0.0633, 0.0388, 0.0522, 0.0645], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,612 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,612 - train - INFO - True
2024-04-06 12:12:21,613 - train - INFO - alphas:tensor([0.7631, 0.0715, 0.0365, 0.0540, 0.0749], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,613 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,613 - train - INFO - True
2024-04-06 12:12:21,614 - train - INFO - alphas:tensor([0.6526, 0.0696, 0.0558, 0.0909, 0.1310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,614 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,614 - train - INFO - True
2024-04-06 12:12:21,615 - train - INFO - alphas:tensor([0.7485, 0.0667, 0.0437, 0.0621, 0.0791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,615 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,615 - train - INFO - True
2024-04-06 12:12:21,616 - train - INFO - alphas:tensor([0.7605, 0.0745, 0.0384, 0.0546, 0.0720], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,616 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,616 - train - INFO - True
2024-04-06 12:12:21,617 - train - INFO - alphas:tensor([0.6883, 0.0814, 0.0462, 0.0739, 0.1102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,617 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,617 - train - INFO - True
2024-04-06 12:12:21,618 - train - INFO - alphas:tensor([0.6524, 0.0696, 0.0579, 0.0904, 0.1298], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,618 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,618 - train - INFO - True
2024-04-06 12:12:21,618 - train - INFO - alphas:tensor([0.7533, 0.0649, 0.0422, 0.0595, 0.0802], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,619 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,619 - train - INFO - True
2024-04-06 12:12:21,619 - train - INFO - alphas:tensor([0.7823, 0.0663, 0.0381, 0.0491, 0.0641], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,619 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,620 - train - INFO - True
2024-04-06 12:12:21,620 - train - INFO - alphas:tensor([0.6700, 0.0741, 0.0462, 0.0795, 0.1302], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,620 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,620 - train - INFO - True
2024-04-06 12:12:21,621 - train - INFO - alphas:tensor([0.6321, 0.0732, 0.0583, 0.0974, 0.1391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,621 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,621 - train - INFO - True
2024-04-06 12:12:21,622 - train - INFO - alphas:tensor([0.7809, 0.0591, 0.0374, 0.0528, 0.0697], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,622 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,622 - train - INFO - True
2024-04-06 12:12:21,623 - train - INFO - alphas:tensor([0.7902, 0.0641, 0.0346, 0.0483, 0.0628], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,623 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,623 - train - INFO - True
2024-04-06 12:12:21,624 - train - INFO - alphas:tensor([0.6876, 0.0660, 0.0432, 0.0766, 0.1266], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,624 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,624 - train - INFO - True
2024-04-06 12:12:21,625 - train - INFO - alphas:tensor([0.6238, 0.0693, 0.0571, 0.1025, 0.1473], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,625 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,625 - train - INFO - True
2024-04-06 12:12:21,626 - train - INFO - alphas:tensor([0.7753, 0.0588, 0.0388, 0.0540, 0.0732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,626 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,626 - train - INFO - True
2024-04-06 12:12:21,627 - train - INFO - alphas:tensor([0.7794, 0.0583, 0.0351, 0.0536, 0.0736], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,627 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,627 - train - INFO - True
2024-04-06 12:12:21,628 - train - INFO - alphas:tensor([0.7052, 0.0654, 0.0408, 0.0744, 0.1143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,628 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,628 - train - INFO - True
2024-04-06 12:12:21,629 - train - INFO - alphas:tensor([0.5983, 0.0644, 0.0641, 0.1094, 0.1639], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,629 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,629 - train - INFO - True
2024-04-06 12:12:21,629 - train - INFO - alphas:tensor([0.7559, 0.0586, 0.0407, 0.0595, 0.0853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,630 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,630 - train - INFO - True
2024-04-06 12:12:21,630 - train - INFO - alphas:tensor([0.7603, 0.0551, 0.0389, 0.0607, 0.0850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,631 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,631 - train - INFO - True
2024-04-06 12:12:21,631 - train - INFO - alphas:tensor([0.7343, 0.0615, 0.0406, 0.0664, 0.0972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,631 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,632 - train - INFO - True
2024-04-06 12:12:21,632 - train - INFO - alphas:tensor([0.5765, 0.0668, 0.0607, 0.1169, 0.1791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,632 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,632 - train - INFO - True
2024-04-06 12:12:21,633 - train - INFO - alphas:tensor([0.7163, 0.0654, 0.0464, 0.0713, 0.1007], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,633 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,633 - train - INFO - True
2024-04-06 12:12:21,634 - train - INFO - alphas:tensor([0.7367, 0.0609, 0.0398, 0.0657, 0.0969], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,634 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,634 - train - INFO - True
2024-04-06 12:12:21,635 - train - INFO - alphas:tensor([0.7293, 0.0643, 0.0412, 0.0680, 0.0971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,635 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,635 - train - INFO - True
2024-04-06 12:12:21,636 - train - INFO - alphas:tensor([0.7033, 0.0748, 0.0961, 0.1258], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:12:21,636 - train - INFO - tau:0.8179069375972307
2024-04-06 12:12:21,636 - train - INFO - avg block size:1.0
2024-04-06 12:12:24,004 - train - INFO - Test: [   0/78]  Time: 2.361 (2.361)  Loss:  1.0908 (1.0908)  Acc@1: 75.7812 (75.7812)  Acc@5: 91.4062 (91.4062)
2024-04-06 12:14:18,825 - train - INFO - Test: [  50/78]  Time: 2.562 (2.298)  Loss:  2.0430 (1.7634)  Acc@1: 52.3438 (59.2218)  Acc@5: 75.7812 (81.7555)
2024-04-06 12:15:23,347 - train - INFO - Test: [  78/78]  Time: 2.888 (2.300)  Loss:  2.0234 (1.7856)  Acc@1: 56.2500 (58.7800)  Acc@5: 81.2500 (81.6600)
2024-04-06 12:15:27,228 - train - INFO - Train: 23 [   0/781 (  0%)]  Loss:  3.857636 (3.8576)  Time: 3.793s,   33.74/s  (3.793s,   33.74/s)  LR: 4.721e-04  Data: 0.143 (0.143)
2024-04-06 12:18:16,378 - train - INFO - Train: 23 [  50/781 (  6%)]  Loss:  4.256870 (3.8615)  Time: 3.052s,   41.94/s  (3.391s,   37.75/s)  LR: 4.721e-04  Data: 0.009 (0.008)
2024-04-06 12:20:59,191 - train - INFO - Train: 23 [ 100/781 ( 13%)]  Loss:  3.400350 (3.8467)  Time: 3.559s,   35.97/s  (3.324s,   38.50/s)  LR: 4.721e-04  Data: 0.007 (0.008)
2024-04-06 12:23:39,649 - train - INFO - Train: 23 [ 150/781 ( 19%)]  Loss:  3.197459 (3.8344)  Time: 2.939s,   43.55/s  (3.286s,   38.95/s)  LR: 4.721e-04  Data: 0.004 (0.007)
2024-04-06 12:26:27,362 - train - INFO - Train: 23 [ 200/781 ( 26%)]  Loss:  4.011487 (3.8265)  Time: 3.659s,   34.98/s  (3.303s,   38.75/s)  LR: 4.721e-04  Data: 0.005 (0.007)
2024-04-06 12:29:14,871 - train - INFO - Train: 23 [ 250/781 ( 32%)]  Loss:  4.006733 (3.8426)  Time: 3.037s,   42.14/s  (3.312s,   38.64/s)  LR: 4.721e-04  Data: 0.005 (0.007)
2024-04-06 12:31:56,473 - train - INFO - Train: 23 [ 300/781 ( 38%)]  Loss:  3.270780 (3.8214)  Time: 2.994s,   42.75/s  (3.299s,   38.80/s)  LR: 4.721e-04  Data: 0.006 (0.007)
2024-04-06 12:34:39,054 - train - INFO - Train: 23 [ 350/781 ( 45%)]  Loss:  4.209719 (3.8237)  Time: 3.565s,   35.90/s  (3.292s,   38.88/s)  LR: 4.721e-04  Data: 0.007 (0.007)
2024-04-06 12:37:28,397 - train - INFO - Train: 23 [ 400/781 ( 51%)]  Loss:  3.213025 (3.8164)  Time: 3.155s,   40.57/s  (3.304s,   38.74/s)  LR: 4.721e-04  Data: 0.005 (0.006)
2024-04-06 12:40:10,974 - train - INFO - Train: 23 [ 450/781 ( 58%)]  Loss:  3.491366 (3.8236)  Time: 3.268s,   39.17/s  (3.298s,   38.81/s)  LR: 4.721e-04  Data: 0.007 (0.006)
2024-04-06 12:42:52,549 - train - INFO - Train: 23 [ 500/781 ( 64%)]  Loss:  3.656205 (3.8323)  Time: 3.179s,   40.26/s  (3.292s,   38.89/s)  LR: 4.721e-04  Data: 0.009 (0.006)
2024-04-06 12:45:36,681 - train - INFO - Train: 23 [ 550/781 ( 71%)]  Loss:  3.643334 (3.8338)  Time: 3.107s,   41.20/s  (3.291s,   38.90/s)  LR: 4.721e-04  Data: 0.005 (0.006)
2024-04-06 12:48:29,700 - train - INFO - Train: 23 [ 600/781 ( 77%)]  Loss:  4.049351 (3.8389)  Time: 3.160s,   40.50/s  (3.305s,   38.73/s)  LR: 4.721e-04  Data: 0.005 (0.006)
2024-04-06 12:51:10,993 - train - INFO - Train: 23 [ 650/781 ( 83%)]  Loss:  3.847029 (3.8308)  Time: 3.008s,   42.56/s  (3.299s,   38.80/s)  LR: 4.721e-04  Data: 0.005 (0.006)
2024-04-06 12:53:52,611 - train - INFO - Train: 23 [ 700/781 ( 90%)]  Loss:  3.746500 (3.8385)  Time: 3.226s,   39.67/s  (3.294s,   38.86/s)  LR: 4.721e-04  Data: 0.005 (0.006)
2024-04-06 12:56:34,988 - train - INFO - Train: 23 [ 750/781 ( 96%)]  Loss:  4.344341 (3.8408)  Time: 3.076s,   41.61/s  (3.291s,   38.89/s)  LR: 4.721e-04  Data: 0.005 (0.006)
2024-04-06 12:58:22,356 - train - INFO - Train: 23 [ 780/781 (100%)]  Loss:  3.449807 (3.8439)  Time: 3.058s,   41.86/s  (3.302s,   38.76/s)  LR: 4.721e-04  Data: 0.000 (0.006)
2024-04-06 12:58:22,357 - train - INFO - True
2024-04-06 12:58:22,359 - train - INFO - alphas:tensor([0.3293, 0.2057, 0.1112, 0.1625, 0.1913], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,359 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,359 - train - INFO - True
2024-04-06 12:58:22,360 - train - INFO - alphas:tensor([0.4122, 0.1099, 0.0903, 0.1598, 0.2277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,361 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,361 - train - INFO - True
2024-04-06 12:58:22,362 - train - INFO - alphas:tensor([0.7645, 0.0831, 0.0419, 0.0511, 0.0595], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,362 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,362 - train - INFO - True
2024-04-06 12:58:22,363 - train - INFO - alphas:tensor([0.7525, 0.0710, 0.0417, 0.0599, 0.0750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,364 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,364 - train - INFO - True
2024-04-06 12:58:22,365 - train - INFO - alphas:tensor([0.5884, 0.0867, 0.0694, 0.1098, 0.1457], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,365 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,365 - train - INFO - True
2024-04-06 12:58:22,366 - train - INFO - alphas:tensor([0.7149, 0.0829, 0.0478, 0.0672, 0.0872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,366 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,367 - train - INFO - True
2024-04-06 12:58:22,368 - train - INFO - alphas:tensor([0.8019, 0.0644, 0.0348, 0.0447, 0.0542], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,368 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,368 - train - INFO - True
2024-04-06 12:58:22,369 - train - INFO - alphas:tensor([0.8098, 0.0674, 0.0293, 0.0413, 0.0522], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,369 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,369 - train - INFO - True
2024-04-06 12:58:22,371 - train - INFO - alphas:tensor([0.6377, 0.0733, 0.0592, 0.0965, 0.1333], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,371 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,371 - train - INFO - True
2024-04-06 12:58:22,372 - train - INFO - alphas:tensor([0.7415, 0.0728, 0.0440, 0.0617, 0.0801], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,372 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,372 - train - INFO - True
2024-04-06 12:58:22,373 - train - INFO - alphas:tensor([0.7783, 0.0629, 0.0389, 0.0532, 0.0666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,374 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,374 - train - INFO - True
2024-04-06 12:58:22,375 - train - INFO - alphas:tensor([0.7594, 0.0713, 0.0363, 0.0552, 0.0778], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,375 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,375 - train - INFO - True
2024-04-06 12:58:22,376 - train - INFO - alphas:tensor([0.6516, 0.0679, 0.0551, 0.0915, 0.1339], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,376 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,376 - train - INFO - True
2024-04-06 12:58:22,377 - train - INFO - alphas:tensor([0.7497, 0.0647, 0.0428, 0.0622, 0.0805], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,378 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,378 - train - INFO - True
2024-04-06 12:58:22,379 - train - INFO - alphas:tensor([0.7594, 0.0735, 0.0377, 0.0552, 0.0741], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,379 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,379 - train - INFO - True
2024-04-06 12:58:22,380 - train - INFO - alphas:tensor([0.6852, 0.0795, 0.0451, 0.0749, 0.1153], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,380 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,380 - train - INFO - True
2024-04-06 12:58:22,382 - train - INFO - alphas:tensor([0.6522, 0.0675, 0.0568, 0.0907, 0.1328], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,382 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,382 - train - INFO - True
2024-04-06 12:58:22,383 - train - INFO - alphas:tensor([0.7494, 0.0646, 0.0424, 0.0605, 0.0831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,383 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,383 - train - INFO - True
2024-04-06 12:58:22,384 - train - INFO - alphas:tensor([0.7822, 0.0643, 0.0375, 0.0496, 0.0663], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,384 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,384 - train - INFO - True
2024-04-06 12:58:22,385 - train - INFO - alphas:tensor([0.6686, 0.0725, 0.0448, 0.0794, 0.1347], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,386 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,386 - train - INFO - True
2024-04-06 12:58:22,387 - train - INFO - alphas:tensor([0.6298, 0.0708, 0.0576, 0.0985, 0.1433], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,387 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,387 - train - INFO - True
2024-04-06 12:58:22,388 - train - INFO - alphas:tensor([0.7808, 0.0577, 0.0370, 0.0531, 0.0715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,388 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,388 - train - INFO - True
2024-04-06 12:58:22,389 - train - INFO - alphas:tensor([0.7930, 0.0617, 0.0336, 0.0482, 0.0636], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,390 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,390 - train - INFO - True
2024-04-06 12:58:22,391 - train - INFO - alphas:tensor([0.6887, 0.0635, 0.0411, 0.0758, 0.1309], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,391 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,391 - train - INFO - True
2024-04-06 12:58:22,392 - train - INFO - alphas:tensor([0.6197, 0.0680, 0.0566, 0.1038, 0.1518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,392 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,392 - train - INFO - True
2024-04-06 12:58:22,393 - train - INFO - alphas:tensor([0.7733, 0.0580, 0.0384, 0.0547, 0.0755], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,393 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,393 - train - INFO - True
2024-04-06 12:58:22,394 - train - INFO - alphas:tensor([0.7795, 0.0569, 0.0343, 0.0537, 0.0756], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,395 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,395 - train - INFO - True
2024-04-06 12:58:22,396 - train - INFO - alphas:tensor([0.7019, 0.0642, 0.0399, 0.0748, 0.1192], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,396 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,396 - train - INFO - True
2024-04-06 12:58:22,397 - train - INFO - alphas:tensor([0.5996, 0.0625, 0.0625, 0.1089, 0.1665], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,397 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,397 - train - INFO - True
2024-04-06 12:58:22,398 - train - INFO - alphas:tensor([0.7547, 0.0573, 0.0400, 0.0601, 0.0881], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,398 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,398 - train - INFO - True
2024-04-06 12:58:22,399 - train - INFO - alphas:tensor([0.7607, 0.0537, 0.0378, 0.0607, 0.0870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,400 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,400 - train - INFO - True
2024-04-06 12:58:22,401 - train - INFO - alphas:tensor([0.7367, 0.0595, 0.0386, 0.0657, 0.0995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,401 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,401 - train - INFO - True
2024-04-06 12:58:22,402 - train - INFO - alphas:tensor([0.5743, 0.0646, 0.0595, 0.1176, 0.1841], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,402 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,402 - train - INFO - True
2024-04-06 12:58:22,403 - train - INFO - alphas:tensor([0.7128, 0.0637, 0.0461, 0.0725, 0.1050], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,403 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,403 - train - INFO - True
2024-04-06 12:58:22,404 - train - INFO - alphas:tensor([0.7372, 0.0592, 0.0389, 0.0658, 0.0989], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,404 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,405 - train - INFO - True
2024-04-06 12:58:22,406 - train - INFO - alphas:tensor([0.7299, 0.0627, 0.0398, 0.0680, 0.0996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,406 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,406 - train - INFO - True
2024-04-06 12:58:22,407 - train - INFO - alphas:tensor([0.7072, 0.0735, 0.0946, 0.1248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 12:58:22,407 - train - INFO - tau:0.8097278682212583
2024-04-06 12:58:22,407 - train - INFO - avg block size:1.0
2024-04-06 12:58:24,871 - train - INFO - Test: [   0/78]  Time: 2.457 (2.457)  Loss:  0.8652 (0.8652)  Acc@1: 82.0312 (82.0312)  Acc@5: 94.5312 (94.5312)
2024-04-06 13:00:19,148 - train - INFO - Test: [  50/78]  Time: 2.162 (2.289)  Loss:  1.9619 (1.6954)  Acc@1: 56.2500 (60.2328)  Acc@5: 85.1562 (83.2108)
2024-04-06 13:01:23,487 - train - INFO - Test: [  78/78]  Time: 2.094 (2.292)  Loss:  2.2578 (1.7348)  Acc@1: 50.0000 (59.8600)  Acc@5: 75.0000 (82.5100)
2024-04-06 13:01:26,748 - train - INFO - Train: 24 [   0/781 (  0%)]  Loss:  4.432551 (4.4326)  Time: 3.177s,   40.29/s  (3.177s,   40.29/s)  LR: 4.697e-04  Data: 0.144 (0.144)
2024-04-06 13:04:10,625 - train - INFO - Train: 24 [  50/781 (  6%)]  Loss:  3.946307 (3.8590)  Time: 3.038s,   42.13/s  (3.276s,   39.08/s)  LR: 4.697e-04  Data: 0.004 (0.009)
2024-04-06 13:06:55,213 - train - INFO - Train: 24 [ 100/781 ( 13%)]  Loss:  4.359423 (3.8449)  Time: 3.305s,   38.72/s  (3.284s,   38.98/s)  LR: 4.697e-04  Data: 0.005 (0.008)
2024-04-06 13:09:44,699 - train - INFO - Train: 24 [ 150/781 ( 19%)]  Loss:  3.126286 (3.8490)  Time: 3.399s,   37.65/s  (3.319s,   38.57/s)  LR: 4.697e-04  Data: 0.009 (0.007)
2024-04-06 13:12:26,406 - train - INFO - Train: 24 [ 200/781 ( 26%)]  Loss:  4.237012 (3.8211)  Time: 3.006s,   42.59/s  (3.298s,   38.82/s)  LR: 4.697e-04  Data: 0.015 (0.007)
2024-04-06 13:15:07,209 - train - INFO - Train: 24 [ 250/781 ( 32%)]  Loss:  4.070227 (3.8343)  Time: 3.229s,   39.64/s  (3.281s,   39.01/s)  LR: 4.697e-04  Data: 0.007 (0.007)
2024-04-06 13:17:50,686 - train - INFO - Train: 24 [ 300/781 ( 38%)]  Loss:  3.867446 (3.8444)  Time: 3.562s,   35.93/s  (3.279s,   39.03/s)  LR: 4.697e-04  Data: 0.005 (0.007)
2024-04-06 13:20:40,722 - train - INFO - Train: 24 [ 350/781 ( 45%)]  Loss:  3.281721 (3.8355)  Time: 3.033s,   42.20/s  (3.297s,   38.83/s)  LR: 4.697e-04  Data: 0.008 (0.007)
2024-04-06 13:23:23,044 - train - INFO - Train: 24 [ 400/781 ( 51%)]  Loss:  3.130987 (3.8263)  Time: 2.981s,   42.93/s  (3.290s,   38.90/s)  LR: 4.697e-04  Data: 0.005 (0.007)
2024-04-06 13:26:04,713 - train - INFO - Train: 24 [ 450/781 ( 58%)]  Loss:  3.818240 (3.8256)  Time: 3.546s,   36.10/s  (3.284s,   38.98/s)  LR: 4.697e-04  Data: 0.005 (0.007)
2024-04-06 13:28:48,438 - train - INFO - Train: 24 [ 500/781 ( 64%)]  Loss:  4.286536 (3.8275)  Time: 3.600s,   35.56/s  (3.283s,   38.99/s)  LR: 4.697e-04  Data: 0.009 (0.007)
2024-04-06 13:31:39,164 - train - INFO - Train: 24 [ 550/781 ( 71%)]  Loss:  3.459386 (3.8290)  Time: 3.276s,   39.07/s  (3.295s,   38.85/s)  LR: 4.697e-04  Data: 0.004 (0.007)
