2024-04-06 20:30:53,507 - train - INFO - Training with a single process on 1 GPUs.
2024-04-06 20:31:00,309 - train - INFO - Model vit_7_4_32_c100 created, param count:3740147
2024-04-06 20:31:00,329 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-04-06 20:31:00,329 - train - INFO - Scheduled epochs: 160
2024-04-06 20:31:01,825 - train - INFO - Verifying teacher model
2024-04-06 20:31:03,373 - train - INFO - Test: [   0/39]  Time: 1.547 (1.547)  Loss:  1.0146 (1.0146)  Acc@1: 77.3438 (77.3438)  Acc@5: 92.1875 (92.1875)
2024-04-06 20:31:03,848 - train - INFO - Test: [  39/39]  Time: 0.026 (0.051)  Loss:  0.7583 (1.0538)  Acc@1: 87.5000 (74.7700)  Acc@5: 87.5000 (93.6100)
2024-04-06 20:31:03,848 - train - INFO - Verifying initial model
2024-04-06 20:31:03,964 - train - INFO - Test: [   0/39]  Time: 0.115 (0.115)  Loss:  4.4805 (4.4805)  Acc@1:  1.9531 ( 1.9531)  Acc@5: 10.5469 (10.5469)
2024-04-06 20:31:05,859 - train - INFO - Test: [  39/39]  Time: 0.047 (0.050)  Loss:  4.3633 (4.4736)  Acc@1:  0.0000 ( 2.1500)  Acc@5: 12.5000 (11.8800)
2024-04-06 20:31:07,637 - train - INFO - Train: 0 [   0/195 (  0%)]  Loss:  4.629329 (4.6293)  Time: 1.775s,  144.19/s  (1.775s,  144.19/s)  LR: 1.000e-05  Data: 0.416 (0.416)
2024-04-06 20:31:54,382 - train - INFO - Train: 0 [  50/195 ( 26%)]  Loss:  4.575503 (4.6240)  Time: 0.907s,  282.28/s  (0.951s,  269.10/s)  LR: 1.000e-05  Data: 0.005 (0.016)
2024-04-06 20:32:40,126 - train - INFO - Train: 0 [ 100/195 ( 52%)]  Loss:  4.555850 (4.6077)  Time: 0.811s,  315.48/s  (0.933s,  274.31/s)  LR: 1.000e-05  Data: 0.007 (0.012)
2024-04-06 20:33:23,194 - train - INFO - Train: 0 [ 150/195 ( 77%)]  Loss:  4.613431 (4.5955)  Time: 0.811s,  315.56/s  (0.909s,  281.49/s)  LR: 1.000e-05  Data: 0.007 (0.011)
2024-04-06 20:33:58,615 - train - INFO - Train: 0 [ 194/195 (100%)]  Loss:  4.568823 (4.5873)  Time: 0.788s,  324.68/s  (0.886s,  288.98/s)  LR: 1.000e-05  Data: 0.000 (0.010)
2024-04-06 20:33:58,615 - train - INFO - True
2024-04-06 20:33:58,620 - train - INFO - alphas:tensor([0.2004, 0.2004, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:58,651 - train - INFO - True
2024-04-06 20:33:58,652 - train - INFO - alphas:tensor([0.2004, 0.2004, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:58,679 - train - INFO - True
2024-04-06 20:33:58,679 - train - INFO - alphas:tensor([0.2004, 0.2005, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:58,704 - train - INFO - True
2024-04-06 20:33:58,705 - train - INFO - alphas:tensor([0.2005, 0.2004, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:58,740 - train - INFO - True
2024-04-06 20:33:58,741 - train - INFO - alphas:tensor([0.2004, 0.2004, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:58,762 - train - INFO - True
2024-04-06 20:33:58,762 - train - INFO - alphas:tensor([0.2004, 0.2004, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:58,793 - train - INFO - True
2024-04-06 20:33:58,793 - train - INFO - alphas:tensor([0.2005, 0.2005, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:58,823 - train - INFO - True
2024-04-06 20:33:58,823 - train - INFO - alphas:tensor([0.2005, 0.2003, 0.1998, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:58,853 - train - INFO - True
2024-04-06 20:33:58,853 - train - INFO - alphas:tensor([0.2005, 0.2005, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:58,872 - train - INFO - True
2024-04-06 20:33:58,873 - train - INFO - alphas:tensor([0.2005, 0.2004, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:58,902 - train - INFO - True
2024-04-06 20:33:58,903 - train - INFO - alphas:tensor([0.2005, 0.2005, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:58,932 - train - INFO - True
2024-04-06 20:33:58,933 - train - INFO - alphas:tensor([0.2004, 0.2000, 0.1999, 0.1998, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:58,963 - train - INFO - True
2024-04-06 20:33:58,964 - train - INFO - alphas:tensor([0.2005, 0.2005, 0.1997, 0.1997, 0.1996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:58,982 - train - INFO - True
2024-04-06 20:33:58,983 - train - INFO - alphas:tensor([0.2005, 0.2005, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,013 - train - INFO - True
2024-04-06 20:33:59,014 - train - INFO - alphas:tensor([0.2005, 0.2003, 0.1998, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,044 - train - INFO - True
2024-04-06 20:33:59,045 - train - INFO - alphas:tensor([0.2001, 0.1997, 0.1998, 0.2001, 0.2003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,062 - train - INFO - True
2024-04-06 20:33:59,062 - train - INFO - alphas:tensor([0.2005, 0.2005, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,092 - train - INFO - True
2024-04-06 20:33:59,093 - train - INFO - alphas:tensor([0.2005, 0.2005, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,122 - train - INFO - True
2024-04-06 20:33:59,123 - train - INFO - alphas:tensor([0.2004, 0.2004, 0.1998, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,152 - train - INFO - True
2024-04-06 20:33:59,152 - train - INFO - alphas:tensor([0.2000, 0.1997, 0.1998, 0.2002, 0.2003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,167 - train - INFO - True
2024-04-06 20:33:59,168 - train - INFO - alphas:tensor([0.2005, 0.2004, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,197 - train - INFO - True
2024-04-06 20:33:59,198 - train - INFO - alphas:tensor([0.2005, 0.2005, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,227 - train - INFO - True
2024-04-06 20:33:59,228 - train - INFO - alphas:tensor([0.2005, 0.2003, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,257 - train - INFO - True
2024-04-06 20:33:59,258 - train - INFO - alphas:tensor([0.2003, 0.1999, 0.1999, 0.2000, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,287 - train - INFO - True
2024-04-06 20:33:59,288 - train - INFO - alphas:tensor([0.2005, 0.2005, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,306 - train - INFO - True
2024-04-06 20:33:59,307 - train - INFO - alphas:tensor([0.2005, 0.2005, 0.1997, 0.1997, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,325 - train - INFO - True
2024-04-06 20:33:59,326 - train - INFO - alphas:tensor([0.1998, 0.2000, 0.2000, 0.2001, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,341 - train - INFO - True
2024-04-06 20:33:59,341 - train - INFO - alphas:tensor([0.1999, 0.1999, 0.2001, 0.2000, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,356 - train - INFO - True
2024-04-06 20:33:59,357 - train - INFO - alphas:tensor([0.3342, 0.3329, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 20:33:59,362 - train - INFO - avg block size:3.0689655172413794
2024-04-06 20:33:59,362 - train - INFO - current latency ratio:tensor(0.7132)
2024-04-06 20:33:59,577 - train - INFO - Test: [   0/39]  Time: 0.212 (0.212)  Loss:  4.2852 (4.2852)  Acc@1: 11.7188 (11.7188)  Acc@5: 34.3750 (34.3750)
2024-04-06 20:34:01,446 - train - INFO - Test: [  39/39]  Time: 0.040 (0.052)  Loss:  4.2148 (4.2943)  Acc@1: 25.0000 ( 9.4100)  Acc@5: 43.7500 (29.2500)
2024-04-06 20:34:02,961 - train - INFO - Train: 1 [   0/195 (  0%)]  Loss:  4.519648 (4.5196)  Time: 1.449s,  176.70/s  (1.449s,  176.70/s)  LR: 6.400e-05  Data: 0.212 (0.212)
2024-04-06 20:34:44,802 - train - INFO - Train: 1 [  50/195 ( 26%)]  Loss:  4.401536 (4.5276)  Time: 0.791s,  323.67/s  (0.849s,  301.61/s)  LR: 6.400e-05  Data: 0.008 (0.012)
2024-04-06 20:35:26,000 - train - INFO - Train: 1 [ 100/195 ( 52%)]  Loss:  4.398052 (4.4897)  Time: 0.797s,  321.13/s  (0.836s,  306.04/s)  LR: 6.400e-05  Data: 0.007 (0.010)
2024-04-06 20:36:07,532 - train - INFO - Train: 1 [ 150/195 ( 77%)]  Loss:  4.213261 (4.4523)  Time: 0.800s,  319.93/s  (0.835s,  306.76/s)  LR: 6.400e-05  Data: 0.007 (0.010)
2024-04-06 20:36:43,869 - train - INFO - Train: 1 [ 194/195 (100%)]  Loss:  4.156773 (4.4175)  Time: 0.800s,  320.10/s  (0.833s,  307.48/s)  LR: 6.400e-05  Data: 0.000 (0.009)
2024-04-06 20:36:43,869 - train - INFO - True
2024-04-06 20:36:43,871 - train - INFO - alphas:tensor([0.2026, 0.2029, 0.1984, 0.1981, 0.1980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:43,901 - train - INFO - True
2024-04-06 20:36:43,902 - train - INFO - alphas:tensor([0.2020, 0.2021, 0.1987, 0.1986, 0.1985], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:43,929 - train - INFO - True
2024-04-06 20:36:43,930 - train - INFO - alphas:tensor([0.2045, 0.2049, 0.1971, 0.1968, 0.1968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:43,955 - train - INFO - True
2024-04-06 20:36:43,955 - train - INFO - alphas:tensor([0.2046, 0.2041, 0.1972, 0.1971, 0.1970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:43,991 - train - INFO - True
2024-04-06 20:36:43,992 - train - INFO - alphas:tensor([0.2050, 0.2051, 0.1968, 0.1966, 0.1965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,012 - train - INFO - True
2024-04-06 20:36:44,013 - train - INFO - alphas:tensor([0.2043, 0.2040, 0.1972, 0.1973, 0.1972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,045 - train - INFO - True
2024-04-06 20:36:44,046 - train - INFO - alphas:tensor([0.2046, 0.2046, 0.1970, 0.1969, 0.1969], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,065 - train - INFO - True
2024-04-06 20:36:44,065 - train - INFO - alphas:tensor([0.2046, 0.2046, 0.1970, 0.1969, 0.1970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,094 - train - INFO - True
2024-04-06 20:36:44,095 - train - INFO - alphas:tensor([0.2047, 0.2049, 0.1968, 0.1968, 0.1968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,113 - train - INFO - True
2024-04-06 20:36:44,114 - train - INFO - alphas:tensor([0.2045, 0.2034, 0.1976, 0.1972, 0.1973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,143 - train - INFO - True
2024-04-06 20:36:44,144 - train - INFO - alphas:tensor([0.2042, 0.2045, 0.1974, 0.1970, 0.1969], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,162 - train - INFO - True
2024-04-06 20:36:44,163 - train - INFO - alphas:tensor([0.2047, 0.2023, 0.1983, 0.1972, 0.1975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,192 - train - INFO - True
2024-04-06 20:36:44,193 - train - INFO - alphas:tensor([0.2046, 0.2047, 0.1970, 0.1969, 0.1968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,211 - train - INFO - True
2024-04-06 20:36:44,212 - train - INFO - alphas:tensor([0.2044, 0.2039, 0.1976, 0.1971, 0.1970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,241 - train - INFO - True
2024-04-06 20:36:44,241 - train - INFO - alphas:tensor([0.2039, 0.2035, 0.1980, 0.1974, 0.1972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,270 - train - INFO - True
2024-04-06 20:36:44,271 - train - INFO - alphas:tensor([0.2003, 0.1993, 0.1996, 0.2003, 0.2006], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,286 - train - INFO - True
2024-04-06 20:36:44,287 - train - INFO - alphas:tensor([0.2051, 0.2051, 0.1966, 0.1966, 0.1966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,316 - train - INFO - True
2024-04-06 20:36:44,317 - train - INFO - alphas:tensor([0.2047, 0.2046, 0.1969, 0.1969, 0.1969], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,346 - train - INFO - True
2024-04-06 20:36:44,347 - train - INFO - alphas:tensor([0.2027, 0.2027, 0.1986, 0.1980, 0.1979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,378 - train - INFO - True
2024-04-06 20:36:44,379 - train - INFO - alphas:tensor([0.1987, 0.1987, 0.1999, 0.2014, 0.2013], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,396 - train - INFO - True
2024-04-06 20:36:44,397 - train - INFO - alphas:tensor([0.2047, 0.2044, 0.1974, 0.1968, 0.1968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,430 - train - INFO - True
2024-04-06 20:36:44,431 - train - INFO - alphas:tensor([0.2042, 0.2037, 0.1974, 0.1973, 0.1973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,464 - train - INFO - True
2024-04-06 20:36:44,464 - train - INFO - alphas:tensor([0.2028, 0.2023, 0.1985, 0.1983, 0.1981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,497 - train - INFO - True
2024-04-06 20:36:44,497 - train - INFO - alphas:tensor([0.2027, 0.2009, 0.1993, 0.1986, 0.1986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,531 - train - INFO - True
2024-04-06 20:36:44,531 - train - INFO - alphas:tensor([0.2043, 0.2045, 0.1972, 0.1969, 0.1970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,552 - train - INFO - True
2024-04-06 20:36:44,553 - train - INFO - alphas:tensor([0.2040, 0.2040, 0.1973, 0.1973, 0.1974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,573 - train - INFO - True
2024-04-06 20:36:44,573 - train - INFO - alphas:tensor([0.1983, 0.2014, 0.2012, 0.2004, 0.1987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,592 - train - INFO - True
2024-04-06 20:36:44,593 - train - INFO - alphas:tensor([0.2029, 0.2019, 0.1990, 0.1982, 0.1980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,622 - train - INFO - True
2024-04-06 20:36:44,623 - train - INFO - alphas:tensor([0.3410, 0.3297, 0.3292], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 20:36:44,628 - train - INFO - avg block size:2.1379310344827585
2024-04-06 20:36:44,628 - train - INFO - current latency ratio:tensor(0.7304)
2024-04-06 20:36:44,810 - train - INFO - Test: [   0/39]  Time: 0.180 (0.180)  Loss:  3.4805 (3.4805)  Acc@1: 25.3906 (25.3906)  Acc@5: 55.0781 (55.0781)
2024-04-06 20:36:46,473 - train - INFO - Test: [  39/39]  Time: 0.039 (0.046)  Loss:  3.4941 (3.5023)  Acc@1: 50.0000 (23.3400)  Acc@5: 50.0000 (52.6500)
2024-04-06 20:36:47,583 - train - INFO - Train: 2 [   0/195 (  0%)]  Loss:  4.275368 (4.2754)  Time: 1.042s,  245.72/s  (1.042s,  245.72/s)  LR: 1.180e-04  Data: 0.193 (0.193)
2024-04-06 20:37:28,405 - train - INFO - Train: 2 [  50/195 ( 26%)]  Loss:  4.358635 (4.2498)  Time: 0.799s,  320.38/s  (0.821s,  311.88/s)  LR: 1.180e-04  Data: 0.006 (0.011)
2024-04-06 20:38:09,543 - train - INFO - Train: 2 [ 100/195 ( 52%)]  Loss:  4.317437 (4.2047)  Time: 0.821s,  311.93/s  (0.822s,  311.52/s)  LR: 1.180e-04  Data: 0.007 (0.009)
2024-04-06 20:38:50,620 - train - INFO - Train: 2 [ 150/195 ( 77%)]  Loss:  3.787690 (4.1559)  Time: 0.812s,  315.19/s  (0.822s,  311.55/s)  LR: 1.180e-04  Data: 0.007 (0.009)
2024-04-06 20:39:26,528 - train - INFO - Train: 2 [ 194/195 (100%)]  Loss:  3.952912 (4.1378)  Time: 0.862s,  297.08/s  (0.820s,  312.03/s)  LR: 1.180e-04  Data: 0.000 (0.009)
2024-04-06 20:39:26,529 - train - INFO - True
2024-04-06 20:39:26,530 - train - INFO - alphas:tensor([0.2086, 0.2089, 0.1945, 0.1941, 0.1939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,561 - train - INFO - True
2024-04-06 20:39:26,562 - train - INFO - alphas:tensor([0.2067, 0.2060, 0.1960, 0.1958, 0.1956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,604 - train - INFO - True
2024-04-06 20:39:26,605 - train - INFO - alphas:tensor([0.2139, 0.2143, 0.1907, 0.1905, 0.1906], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,628 - train - INFO - True
2024-04-06 20:39:26,629 - train - INFO - alphas:tensor([0.2139, 0.2122, 0.1914, 0.1912, 0.1912], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,664 - train - INFO - True
2024-04-06 20:39:26,664 - train - INFO - alphas:tensor([0.2125, 0.2118, 0.1920, 0.1918, 0.1918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,695 - train - INFO - True
2024-04-06 20:39:26,696 - train - INFO - alphas:tensor([0.2117, 0.2090, 0.1933, 0.1929, 0.1930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,725 - train - INFO - True
2024-04-06 20:39:26,726 - train - INFO - alphas:tensor([0.2125, 0.2121, 0.1919, 0.1917, 0.1918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,755 - train - INFO - True
2024-04-06 20:39:26,755 - train - INFO - alphas:tensor([0.2127, 0.2117, 0.1921, 0.1916, 0.1919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,785 - train - INFO - True
2024-04-06 20:39:26,785 - train - INFO - alphas:tensor([0.2113, 0.2106, 0.1925, 0.1927, 0.1928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,814 - train - INFO - True
2024-04-06 20:39:26,815 - train - INFO - alphas:tensor([0.2114, 0.2073, 0.1939, 0.1936, 0.1938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,843 - train - INFO - True
2024-04-06 20:39:26,844 - train - INFO - alphas:tensor([0.2119, 0.2104, 0.1929, 0.1924, 0.1924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,873 - train - INFO - True
2024-04-06 20:39:26,874 - train - INFO - alphas:tensor([0.2119, 0.2068, 0.1945, 0.1932, 0.1936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,903 - train - INFO - True
2024-04-06 20:39:26,903 - train - INFO - alphas:tensor([0.2102, 0.2100, 0.1930, 0.1934, 0.1935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,932 - train - INFO - True
2024-04-06 20:39:26,933 - train - INFO - alphas:tensor([0.2109, 0.2083, 0.1936, 0.1935, 0.1937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,962 - train - INFO - True
2024-04-06 20:39:26,962 - train - INFO - alphas:tensor([0.2116, 0.2089, 0.1937, 0.1930, 0.1927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:26,991 - train - INFO - True
2024-04-06 20:39:26,992 - train - INFO - alphas:tensor([0.2064, 0.2012, 0.1978, 0.1968, 0.1978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:27,021 - train - INFO - True
2024-04-06 20:39:27,021 - train - INFO - alphas:tensor([0.2102, 0.2092, 0.1929, 0.1937, 0.1939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:27,050 - train - INFO - True
2024-04-06 20:39:27,051 - train - INFO - alphas:tensor([0.2111, 0.2088, 0.1927, 0.1935, 0.1938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:27,080 - train - INFO - True
2024-04-06 20:39:27,081 - train - INFO - alphas:tensor([0.2078, 0.2072, 0.1960, 0.1947, 0.1944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:27,110 - train - INFO - True
2024-04-06 20:39:27,110 - train - INFO - alphas:tensor([0.2009, 0.1989, 0.1991, 0.2005, 0.2007], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:27,139 - train - INFO - True
2024-04-06 20:39:27,140 - train - INFO - alphas:tensor([0.2117, 0.2107, 0.1925, 0.1925, 0.1927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:27,169 - train - INFO - True
2024-04-06 20:39:27,170 - train - INFO - alphas:tensor([0.2119, 0.2095, 0.1928, 0.1930, 0.1928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:27,199 - train - INFO - True
2024-04-06 20:39:27,199 - train - INFO - alphas:tensor([0.2077, 0.2058, 0.1962, 0.1956, 0.1948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:27,228 - train - INFO - True
2024-04-06 20:39:27,229 - train - INFO - alphas:tensor([0.2068, 0.2026, 0.1972, 0.1967, 0.1966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:27,258 - train - INFO - True
2024-04-06 20:39:27,258 - train - INFO - alphas:tensor([0.2097, 0.2097, 0.1935, 0.1935, 0.1937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:27,287 - train - INFO - True
2024-04-06 20:39:27,288 - train - INFO - alphas:tensor([0.2095, 0.2088, 0.1938, 0.1939, 0.1940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:27,317 - train - INFO - True
2024-04-06 20:39:27,318 - train - INFO - alphas:tensor([0.2056, 0.2074, 0.1969, 0.1957, 0.1944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:27,336 - train - INFO - True
2024-04-06 20:39:27,337 - train - INFO - alphas:tensor([0.2077, 0.2053, 0.1964, 0.1955, 0.1952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:27,366 - train - INFO - True
2024-04-06 20:39:27,367 - train - INFO - alphas:tensor([0.3532, 0.3232, 0.3236], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 20:39:27,372 - train - INFO - avg block size:1.103448275862069
2024-04-06 20:39:27,372 - train - INFO - current latency ratio:tensor(0.9429)
2024-04-06 20:39:27,546 - train - INFO - Test: [   0/39]  Time: 0.172 (0.172)  Loss:  2.8516 (2.8516)  Acc@1: 40.2344 (40.2344)  Acc@5: 67.1875 (67.1875)
2024-04-06 20:39:29,275 - train - INFO - Test: [  39/39]  Time: 0.040 (0.048)  Loss:  2.7812 (2.8742)  Acc@1: 56.2500 (36.3000)  Acc@5: 68.7500 (67.5600)
2024-04-06 20:39:30,397 - train - INFO - Train: 3 [   0/195 (  0%)]  Loss:  3.922526 (3.9225)  Time: 1.052s,  243.36/s  (1.052s,  243.36/s)  LR: 1.720e-04  Data: 0.182 (0.182)
2024-04-06 20:40:11,278 - train - INFO - Train: 3 [  50/195 ( 26%)]  Loss:  4.065194 (4.0343)  Time: 0.804s,  318.36/s  (0.822s,  311.36/s)  LR: 1.720e-04  Data: 0.007 (0.011)
2024-04-06 20:40:55,011 - train - INFO - Train: 3 [ 100/195 ( 52%)]  Loss:  4.034271 (3.9812)  Time: 0.814s,  314.56/s  (0.848s,  301.83/s)  LR: 1.720e-04  Data: 0.007 (0.010)
2024-04-06 20:41:35,580 - train - INFO - Train: 3 [ 150/195 ( 77%)]  Loss:  3.671567 (3.9391)  Time: 0.872s,  293.54/s  (0.836s,  306.23/s)  LR: 1.720e-04  Data: 0.012 (0.009)
2024-04-06 20:42:12,262 - train - INFO - Train: 3 [ 194/195 (100%)]  Loss:  4.150752 (3.9211)  Time: 0.795s,  321.95/s  (0.835s,  306.42/s)  LR: 1.720e-04  Data: 0.000 (0.009)
2024-04-06 20:42:12,262 - train - INFO - True
2024-04-06 20:42:12,264 - train - INFO - alphas:tensor([0.2166, 0.2155, 0.1892, 0.1894, 0.1893], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,309 - train - INFO - tau:0.99
2024-04-06 20:42:12,310 - train - INFO - True
2024-04-06 20:42:12,310 - train - INFO - alphas:tensor([0.2136, 0.2096, 0.1919, 0.1924, 0.1925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,349 - train - INFO - tau:0.99
2024-04-06 20:42:12,349 - train - INFO - True
2024-04-06 20:42:12,350 - train - INFO - alphas:tensor([0.2257, 0.2250, 0.1828, 0.1831, 0.1834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,384 - train - INFO - tau:0.99
2024-04-06 20:42:12,384 - train - INFO - True
2024-04-06 20:42:12,385 - train - INFO - alphas:tensor([0.2256, 0.2217, 0.1843, 0.1841, 0.1843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,418 - train - INFO - tau:0.99
2024-04-06 20:42:12,418 - train - INFO - True
2024-04-06 20:42:12,419 - train - INFO - alphas:tensor([0.2222, 0.2197, 0.1859, 0.1860, 0.1862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,450 - train - INFO - tau:0.99
2024-04-06 20:42:12,450 - train - INFO - True
2024-04-06 20:42:12,451 - train - INFO - alphas:tensor([0.2225, 0.2152, 0.1878, 0.1870, 0.1875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,481 - train - INFO - tau:0.99
2024-04-06 20:42:12,481 - train - INFO - True
2024-04-06 20:42:12,482 - train - INFO - alphas:tensor([0.2222, 0.2203, 0.1858, 0.1857, 0.1860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,511 - train - INFO - tau:0.99
2024-04-06 20:42:12,511 - train - INFO - True
2024-04-06 20:42:12,511 - train - INFO - alphas:tensor([0.2227, 0.2188, 0.1866, 0.1857, 0.1863], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,540 - train - INFO - tau:0.99
2024-04-06 20:42:12,540 - train - INFO - True
2024-04-06 20:42:12,541 - train - INFO - alphas:tensor([0.2215, 0.2186, 0.1861, 0.1868, 0.1871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,570 - train - INFO - tau:0.99
2024-04-06 20:42:12,570 - train - INFO - True
2024-04-06 20:42:12,571 - train - INFO - alphas:tensor([0.2223, 0.2126, 0.1881, 0.1885, 0.1885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,600 - train - INFO - tau:0.99
2024-04-06 20:42:12,600 - train - INFO - True
2024-04-06 20:42:12,600 - train - INFO - alphas:tensor([0.2217, 0.2171, 0.1873, 0.1869, 0.1870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,629 - train - INFO - tau:0.99
2024-04-06 20:42:12,629 - train - INFO - True
2024-04-06 20:42:12,630 - train - INFO - alphas:tensor([0.2201, 0.2115, 0.1902, 0.1890, 0.1892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,659 - train - INFO - tau:0.99
2024-04-06 20:42:12,659 - train - INFO - True
2024-04-06 20:42:12,659 - train - INFO - alphas:tensor([0.2176, 0.2161, 0.1880, 0.1890, 0.1894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,688 - train - INFO - tau:0.99
2024-04-06 20:42:12,688 - train - INFO - True
2024-04-06 20:42:12,689 - train - INFO - alphas:tensor([0.2203, 0.2139, 0.1880, 0.1887, 0.1891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,717 - train - INFO - tau:0.99
2024-04-06 20:42:12,717 - train - INFO - True
2024-04-06 20:42:12,718 - train - INFO - alphas:tensor([0.2234, 0.2165, 0.1872, 0.1865, 0.1865], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,746 - train - INFO - tau:0.99
2024-04-06 20:42:12,746 - train - INFO - True
2024-04-06 20:42:12,747 - train - INFO - alphas:tensor([0.2165, 0.2052, 0.1943, 0.1913, 0.1928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,776 - train - INFO - tau:0.99
2024-04-06 20:42:12,776 - train - INFO - True
2024-04-06 20:42:12,776 - train - INFO - alphas:tensor([0.2169, 0.2140, 0.1880, 0.1903, 0.1908], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,806 - train - INFO - tau:0.99
2024-04-06 20:42:12,806 - train - INFO - True
2024-04-06 20:42:12,806 - train - INFO - alphas:tensor([0.2196, 0.2134, 0.1880, 0.1891, 0.1899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,836 - train - INFO - tau:0.99
2024-04-06 20:42:12,836 - train - INFO - True
2024-04-06 20:42:12,837 - train - INFO - alphas:tensor([0.2170, 0.2143, 0.1910, 0.1891, 0.1886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,867 - train - INFO - tau:0.99
2024-04-06 20:42:12,867 - train - INFO - True
2024-04-06 20:42:12,867 - train - INFO - alphas:tensor([0.2082, 0.2007, 0.1971, 0.1968, 0.1972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,897 - train - INFO - tau:0.99
2024-04-06 20:42:12,897 - train - INFO - True
2024-04-06 20:42:12,898 - train - INFO - alphas:tensor([0.2192, 0.2159, 0.1871, 0.1887, 0.1891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,927 - train - INFO - tau:0.99
2024-04-06 20:42:12,927 - train - INFO - True
2024-04-06 20:42:12,927 - train - INFO - alphas:tensor([0.2217, 0.2158, 0.1873, 0.1877, 0.1875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,956 - train - INFO - tau:0.99
2024-04-06 20:42:12,956 - train - INFO - True
2024-04-06 20:42:12,957 - train - INFO - alphas:tensor([0.2191, 0.2137, 0.1904, 0.1892, 0.1876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:12,986 - train - INFO - tau:0.99
2024-04-06 20:42:12,986 - train - INFO - True
2024-04-06 20:42:12,987 - train - INFO - alphas:tensor([0.2155, 0.2062, 0.1930, 0.1929, 0.1924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:13,016 - train - INFO - tau:0.99
2024-04-06 20:42:13,016 - train - INFO - True
2024-04-06 20:42:13,017 - train - INFO - alphas:tensor([0.2166, 0.2155, 0.1886, 0.1894, 0.1899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:13,046 - train - INFO - tau:0.99
2024-04-06 20:42:13,046 - train - INFO - True
2024-04-06 20:42:13,047 - train - INFO - alphas:tensor([0.2173, 0.2148, 0.1889, 0.1894, 0.1896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:13,076 - train - INFO - tau:0.99
2024-04-06 20:42:13,076 - train - INFO - True
2024-04-06 20:42:13,077 - train - INFO - alphas:tensor([0.2200, 0.2172, 0.1876, 0.1875, 0.1877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:13,106 - train - INFO - tau:0.99
2024-04-06 20:42:13,106 - train - INFO - True
2024-04-06 20:42:13,107 - train - INFO - alphas:tensor([0.2153, 0.2108, 0.1919, 0.1911, 0.1909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:13,136 - train - INFO - tau:0.99
2024-04-06 20:42:13,136 - train - INFO - True
2024-04-06 20:42:13,137 - train - INFO - alphas:tensor([0.3690, 0.3148, 0.3162], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 20:42:13,142 - train - INFO - tau:0.99
2024-04-06 20:42:13,142 - train - INFO - avg block size:1.0
2024-04-06 20:42:13,142 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 20:42:13,323 - train - INFO - Test: [   0/39]  Time: 0.178 (0.178)  Loss:  2.4434 (2.4434)  Acc@1: 48.8281 (48.8281)  Acc@5: 74.2188 (74.2188)
2024-04-06 20:42:14,988 - train - INFO - Test: [  39/39]  Time: 0.039 (0.046)  Loss:  2.2969 (2.4785)  Acc@1: 56.2500 (44.3000)  Acc@5: 81.2500 (73.9600)
2024-04-06 20:42:16,050 - train - INFO - Train: 4 [   0/195 (  0%)]  Loss:  3.641964 (3.6420)  Time: 0.995s,  257.17/s  (0.995s,  257.17/s)  LR: 2.260e-04  Data: 0.188 (0.188)
2024-04-06 20:42:57,352 - train - INFO - Train: 4 [  50/195 ( 26%)]  Loss:  3.713911 (3.8058)  Time: 0.811s,  315.50/s  (0.829s,  308.68/s)  LR: 2.260e-04  Data: 0.007 (0.012)
2024-04-06 20:43:39,073 - train - INFO - Train: 4 [ 100/195 ( 52%)]  Loss:  3.626626 (3.8044)  Time: 0.856s,  299.05/s  (0.832s,  307.75/s)  LR: 2.260e-04  Data: 0.011 (0.010)
2024-04-06 20:44:20,879 - train - INFO - Train: 4 [ 150/195 ( 77%)]  Loss:  3.824894 (3.7684)  Time: 0.805s,  317.89/s  (0.833s,  307.23/s)  LR: 2.260e-04  Data: 0.007 (0.010)
2024-04-06 20:44:57,618 - train - INFO - Train: 4 [ 194/195 (100%)]  Loss:  3.325292 (3.7485)  Time: 0.804s,  318.29/s  (0.834s,  307.09/s)  LR: 2.260e-04  Data: 0.000 (0.010)
2024-04-06 20:44:57,618 - train - INFO - True
2024-04-06 20:44:57,620 - train - INFO - alphas:tensor([0.2240, 0.2207, 0.1842, 0.1855, 0.1856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:57,669 - train - INFO - tau:0.9801
2024-04-06 20:44:57,669 - train - INFO - True
2024-04-06 20:44:57,670 - train - INFO - alphas:tensor([0.2207, 0.2125, 0.1876, 0.1891, 0.1900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:57,711 - train - INFO - tau:0.9801
2024-04-06 20:44:57,711 - train - INFO - True
2024-04-06 20:44:57,712 - train - INFO - alphas:tensor([0.2404, 0.2367, 0.1734, 0.1744, 0.1750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:57,748 - train - INFO - tau:0.9801
2024-04-06 20:44:57,748 - train - INFO - True
2024-04-06 20:44:57,749 - train - INFO - alphas:tensor([0.2405, 0.2321, 0.1757, 0.1756, 0.1761], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:57,781 - train - INFO - tau:0.9801
2024-04-06 20:44:57,781 - train - INFO - True
2024-04-06 20:44:57,782 - train - INFO - alphas:tensor([0.2347, 0.2284, 0.1784, 0.1791, 0.1795], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:57,812 - train - INFO - tau:0.9801
2024-04-06 20:44:57,812 - train - INFO - True
2024-04-06 20:44:57,813 - train - INFO - alphas:tensor([0.2366, 0.2226, 0.1805, 0.1798, 0.1805], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:57,842 - train - INFO - tau:0.9801
2024-04-06 20:44:57,842 - train - INFO - True
2024-04-06 20:44:57,843 - train - INFO - alphas:tensor([0.2346, 0.2294, 0.1784, 0.1785, 0.1792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:57,872 - train - INFO - tau:0.9801
2024-04-06 20:44:57,873 - train - INFO - True
2024-04-06 20:44:57,873 - train - INFO - alphas:tensor([0.2349, 0.2257, 0.1804, 0.1791, 0.1800], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:57,903 - train - INFO - tau:0.9801
2024-04-06 20:44:57,903 - train - INFO - True
2024-04-06 20:44:57,903 - train - INFO - alphas:tensor([0.2362, 0.2296, 0.1769, 0.1783, 0.1790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:57,933 - train - INFO - tau:0.9801
2024-04-06 20:44:57,933 - train - INFO - True
2024-04-06 20:44:57,934 - train - INFO - alphas:tensor([0.2386, 0.2203, 0.1795, 0.1808, 0.1807], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:57,963 - train - INFO - tau:0.9801
2024-04-06 20:44:57,963 - train - INFO - True
2024-04-06 20:44:57,964 - train - INFO - alphas:tensor([0.2351, 0.2259, 0.1798, 0.1795, 0.1797], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:57,993 - train - INFO - tau:0.9801
2024-04-06 20:44:57,993 - train - INFO - True
2024-04-06 20:44:57,994 - train - INFO - alphas:tensor([0.2323, 0.2167, 0.1848, 0.1832, 0.1831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,023 - train - INFO - tau:0.9801
2024-04-06 20:44:58,024 - train - INFO - True
2024-04-06 20:44:58,024 - train - INFO - alphas:tensor([0.2279, 0.2232, 0.1814, 0.1833, 0.1842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,054 - train - INFO - tau:0.9801
2024-04-06 20:44:58,054 - train - INFO - True
2024-04-06 20:44:58,055 - train - INFO - alphas:tensor([0.2334, 0.2201, 0.1811, 0.1824, 0.1830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,084 - train - INFO - tau:0.9801
2024-04-06 20:44:58,084 - train - INFO - True
2024-04-06 20:44:58,085 - train - INFO - alphas:tensor([0.2393, 0.2259, 0.1788, 0.1779, 0.1781], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,114 - train - INFO - tau:0.9801
2024-04-06 20:44:58,114 - train - INFO - True
2024-04-06 20:44:58,115 - train - INFO - alphas:tensor([0.2310, 0.2106, 0.1891, 0.1840, 0.1853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,144 - train - INFO - tau:0.9801
2024-04-06 20:44:58,144 - train - INFO - True
2024-04-06 20:44:58,145 - train - INFO - alphas:tensor([0.2270, 0.2208, 0.1811, 0.1850, 0.1861], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,174 - train - INFO - tau:0.9801
2024-04-06 20:44:58,174 - train - INFO - True
2024-04-06 20:44:58,175 - train - INFO - alphas:tensor([0.2317, 0.2200, 0.1813, 0.1828, 0.1842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,205 - train - INFO - tau:0.9801
2024-04-06 20:44:58,205 - train - INFO - True
2024-04-06 20:44:58,205 - train - INFO - alphas:tensor([0.2310, 0.2237, 0.1838, 0.1810, 0.1806], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,235 - train - INFO - tau:0.9801
2024-04-06 20:44:58,235 - train - INFO - True
2024-04-06 20:44:58,236 - train - INFO - alphas:tensor([0.2195, 0.2040, 0.1936, 0.1914, 0.1916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,265 - train - INFO - tau:0.9801
2024-04-06 20:44:58,265 - train - INFO - True
2024-04-06 20:44:58,266 - train - INFO - alphas:tensor([0.2287, 0.2215, 0.1808, 0.1840, 0.1850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,295 - train - INFO - tau:0.9801
2024-04-06 20:44:58,295 - train - INFO - True
2024-04-06 20:44:58,296 - train - INFO - alphas:tensor([0.2341, 0.2222, 0.1810, 0.1814, 0.1812], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,325 - train - INFO - tau:0.9801
2024-04-06 20:44:58,326 - train - INFO - True
2024-04-06 20:44:58,326 - train - INFO - alphas:tensor([0.2374, 0.2255, 0.1808, 0.1791, 0.1773], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,355 - train - INFO - tau:0.9801
2024-04-06 20:44:58,355 - train - INFO - True
2024-04-06 20:44:58,356 - train - INFO - alphas:tensor([0.2297, 0.2112, 0.1865, 0.1867, 0.1859], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,386 - train - INFO - tau:0.9801
2024-04-06 20:44:58,386 - train - INFO - True
2024-04-06 20:44:58,386 - train - INFO - alphas:tensor([0.2252, 0.2215, 0.1829, 0.1848, 0.1856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,416 - train - INFO - tau:0.9801
2024-04-06 20:44:58,416 - train - INFO - True
2024-04-06 20:44:58,417 - train - INFO - alphas:tensor([0.2267, 0.2206, 0.1837, 0.1844, 0.1846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,446 - train - INFO - tau:0.9801
2024-04-06 20:44:58,446 - train - INFO - True
2024-04-06 20:44:58,447 - train - INFO - alphas:tensor([0.2394, 0.2295, 0.1762, 0.1769, 0.1780], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,476 - train - INFO - tau:0.9801
2024-04-06 20:44:58,476 - train - INFO - True
2024-04-06 20:44:58,477 - train - INFO - alphas:tensor([0.2295, 0.2205, 0.1838, 0.1831, 0.1831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,507 - train - INFO - tau:0.9801
2024-04-06 20:44:58,507 - train - INFO - True
2024-04-06 20:44:58,507 - train - INFO - alphas:tensor([0.3872, 0.3046, 0.3082], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 20:44:58,512 - train - INFO - tau:0.9801
2024-04-06 20:44:58,512 - train - INFO - avg block size:1.0
2024-04-06 20:44:58,513 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 20:44:58,718 - train - INFO - Test: [   0/39]  Time: 0.203 (0.203)  Loss:  2.1328 (2.1328)  Acc@1: 55.4688 (55.4688)  Acc@5: 78.1250 (78.1250)
2024-04-06 20:45:00,437 - train - INFO - Test: [  39/39]  Time: 0.040 (0.048)  Loss:  1.8008 (2.1706)  Acc@1: 75.0000 (49.6100)  Acc@5: 87.5000 (78.9800)
2024-04-06 20:45:01,525 - train - INFO - Train: 5 [   0/195 (  0%)]  Loss:  3.653669 (3.6537)  Time: 1.020s,  250.89/s  (1.020s,  250.89/s)  LR: 2.800e-04  Data: 0.213 (0.213)
2024-04-06 20:45:43,544 - train - INFO - Train: 5 [  50/195 ( 26%)]  Loss:  3.834187 (3.6763)  Time: 0.875s,  292.66/s  (0.844s,  303.36/s)  LR: 2.800e-04  Data: 0.013 (0.013)
2024-04-06 20:46:27,283 - train - INFO - Train: 5 [ 100/195 ( 52%)]  Loss:  3.306896 (3.6420)  Time: 0.945s,  271.00/s  (0.859s,  297.96/s)  LR: 2.800e-04  Data: 0.005 (0.011)
2024-04-06 20:47:11,650 - train - INFO - Train: 5 [ 150/195 ( 77%)]  Loss:  3.310325 (3.5945)  Time: 0.809s,  316.58/s  (0.868s,  294.76/s)  LR: 2.800e-04  Data: 0.007 (0.010)
2024-04-06 20:47:48,330 - train - INFO - Train: 5 [ 194/195 (100%)]  Loss:  3.289244 (3.5908)  Time: 0.809s,  316.60/s  (0.861s,  297.46/s)  LR: 2.800e-04  Data: 0.000 (0.010)
2024-04-06 20:47:48,331 - train - INFO - True
2024-04-06 20:47:48,332 - train - INFO - alphas:tensor([0.2317, 0.2251, 0.1789, 0.1818, 0.1824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,381 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,381 - train - INFO - True
2024-04-06 20:47:48,382 - train - INFO - alphas:tensor([0.2298, 0.2150, 0.1821, 0.1855, 0.1876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,423 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,423 - train - INFO - True
2024-04-06 20:47:48,424 - train - INFO - alphas:tensor([0.2579, 0.2478, 0.1631, 0.1651, 0.1661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,460 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,460 - train - INFO - True
2024-04-06 20:47:48,461 - train - INFO - alphas:tensor([0.2591, 0.2410, 0.1659, 0.1667, 0.1674], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,494 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,494 - train - INFO - True
2024-04-06 20:47:48,495 - train - INFO - alphas:tensor([0.2495, 0.2367, 0.1698, 0.1715, 0.1724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,527 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,528 - train - INFO - True
2024-04-06 20:47:48,528 - train - INFO - alphas:tensor([0.2548, 0.2287, 0.1727, 0.1715, 0.1724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,560 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,560 - train - INFO - True
2024-04-06 20:47:48,560 - train - INFO - alphas:tensor([0.2501, 0.2385, 0.1697, 0.1703, 0.1714], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,590 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,590 - train - INFO - True
2024-04-06 20:47:48,591 - train - INFO - alphas:tensor([0.2499, 0.2327, 0.1732, 0.1714, 0.1727], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,621 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,621 - train - INFO - True
2024-04-06 20:47:48,622 - train - INFO - alphas:tensor([0.2555, 0.2409, 0.1658, 0.1683, 0.1694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,651 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,651 - train - INFO - True
2024-04-06 20:47:48,652 - train - INFO - alphas:tensor([0.2612, 0.2281, 0.1691, 0.1708, 0.1709], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,682 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,682 - train - INFO - True
2024-04-06 20:47:48,683 - train - INFO - alphas:tensor([0.2531, 0.2353, 0.1704, 0.1704, 0.1708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,712 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,712 - train - INFO - True
2024-04-06 20:47:48,713 - train - INFO - alphas:tensor([0.2494, 0.2228, 0.1777, 0.1751, 0.1750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,743 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,743 - train - INFO - True
2024-04-06 20:47:48,743 - train - INFO - alphas:tensor([0.2429, 0.2320, 0.1725, 0.1756, 0.1770], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,773 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,774 - train - INFO - True
2024-04-06 20:47:48,774 - train - INFO - alphas:tensor([0.2522, 0.2263, 0.1724, 0.1742, 0.1749], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,804 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,804 - train - INFO - True
2024-04-06 20:47:48,805 - train - INFO - alphas:tensor([0.2593, 0.2344, 0.1689, 0.1685, 0.1689], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,834 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,835 - train - INFO - True
2024-04-06 20:47:48,835 - train - INFO - alphas:tensor([0.2493, 0.2155, 0.1822, 0.1758, 0.1772], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,865 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,865 - train - INFO - True
2024-04-06 20:47:48,865 - train - INFO - alphas:tensor([0.2417, 0.2286, 0.1723, 0.1779, 0.1795], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,895 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,895 - train - INFO - True
2024-04-06 20:47:48,896 - train - INFO - alphas:tensor([0.2490, 0.2273, 0.1725, 0.1748, 0.1765], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,925 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,926 - train - INFO - True
2024-04-06 20:47:48,926 - train - INFO - alphas:tensor([0.2510, 0.2340, 0.1740, 0.1706, 0.1704], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,956 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,956 - train - INFO - True
2024-04-06 20:47:48,957 - train - INFO - alphas:tensor([0.2363, 0.2088, 0.1879, 0.1833, 0.1837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:48,986 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:48,987 - train - INFO - True
2024-04-06 20:47:48,987 - train - INFO - alphas:tensor([0.2411, 0.2278, 0.1731, 0.1783, 0.1797], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:49,017 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:49,017 - train - INFO - True
2024-04-06 20:47:49,018 - train - INFO - alphas:tensor([0.2498, 0.2300, 0.1732, 0.1735, 0.1735], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:49,048 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:49,048 - train - INFO - True
2024-04-06 20:47:49,049 - train - INFO - alphas:tensor([0.2622, 0.2385, 0.1682, 0.1664, 0.1647], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:49,079 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:49,079 - train - INFO - True
2024-04-06 20:47:49,079 - train - INFO - alphas:tensor([0.2509, 0.2172, 0.1773, 0.1780, 0.1766], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:49,110 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:49,110 - train - INFO - True
2024-04-06 20:47:49,110 - train - INFO - alphas:tensor([0.2359, 0.2275, 0.1761, 0.1795, 0.1809], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:49,140 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:49,140 - train - INFO - True
2024-04-06 20:47:49,141 - train - INFO - alphas:tensor([0.2381, 0.2255, 0.1782, 0.1790, 0.1792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:49,171 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:49,171 - train - INFO - True
2024-04-06 20:47:49,172 - train - INFO - alphas:tensor([0.2624, 0.2406, 0.1639, 0.1657, 0.1674], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:49,201 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:49,202 - train - INFO - True
2024-04-06 20:47:49,202 - train - INFO - alphas:tensor([0.2483, 0.2323, 0.1733, 0.1730, 0.1731], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:49,232 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:49,232 - train - INFO - True
2024-04-06 20:47:49,233 - train - INFO - alphas:tensor([0.4065, 0.2935, 0.3000], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 20:47:49,237 - train - INFO - tau:0.9702989999999999
2024-04-06 20:47:49,238 - train - INFO - avg block size:1.0
2024-04-06 20:47:49,238 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 20:47:49,445 - train - INFO - Test: [   0/39]  Time: 0.205 (0.205)  Loss:  1.8350 (1.8350)  Acc@1: 59.7656 (59.7656)  Acc@5: 80.8594 (80.8594)
2024-04-06 20:47:51,569 - train - INFO - Test: [  39/39]  Time: 0.040 (0.058)  Loss:  1.5273 (1.8964)  Acc@1: 62.5000 (54.9600)  Acc@5: 81.2500 (82.6500)
2024-04-06 20:47:52,946 - train - INFO - Train: 6 [   0/195 (  0%)]  Loss:  3.948770 (3.9488)  Time: 1.305s,  196.11/s  (1.305s,  196.11/s)  LR: 3.340e-04  Data: 0.189 (0.189)
2024-04-06 20:48:33,826 - train - INFO - Train: 6 [  50/195 ( 26%)]  Loss:  3.325152 (3.4306)  Time: 0.814s,  314.31/s  (0.827s,  309.50/s)  LR: 3.340e-04  Data: 0.007 (0.011)
2024-04-06 20:49:19,419 - train - INFO - Train: 6 [ 100/195 ( 52%)]  Loss:  3.827916 (3.4555)  Time: 0.917s,  279.13/s  (0.869s,  294.57/s)  LR: 3.340e-04  Data: 0.006 (0.010)
2024-04-06 20:50:04,975 - train - INFO - Train: 6 [ 150/195 ( 77%)]  Loss:  3.164361 (3.4337)  Time: 0.918s,  278.86/s  (0.883s,  289.93/s)  LR: 3.340e-04  Data: 0.011 (0.009)
2024-04-06 20:50:46,421 - train - INFO - Train: 6 [ 194/195 (100%)]  Loss:  3.859307 (3.4247)  Time: 0.833s,  307.49/s  (0.896s,  285.62/s)  LR: 3.340e-04  Data: 0.000 (0.009)
2024-04-06 20:50:46,428 - train - INFO - True
2024-04-06 20:50:46,429 - train - INFO - alphas:tensor([0.2398, 0.2292, 0.1738, 0.1780, 0.1792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:46,467 - train - INFO - tau:0.96059601
2024-04-06 20:50:46,467 - train - INFO - True
2024-04-06 20:50:46,468 - train - INFO - alphas:tensor([0.2389, 0.2160, 0.1767, 0.1825, 0.1859], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:46,506 - train - INFO - tau:0.96059601
2024-04-06 20:50:46,506 - train - INFO - True
2024-04-06 20:50:46,507 - train - INFO - alphas:tensor([0.2771, 0.2559, 0.1530, 0.1562, 0.1578], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:46,545 - train - INFO - tau:0.96059601
2024-04-06 20:50:46,545 - train - INFO - True
2024-04-06 20:50:46,546 - train - INFO - alphas:tensor([0.2809, 0.2453, 0.1564, 0.1581, 0.1593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:46,584 - train - INFO - tau:0.96059601
2024-04-06 20:50:46,585 - train - INFO - True
2024-04-06 20:50:46,585 - train - INFO - alphas:tensor([0.2644, 0.2427, 0.1618, 0.1649, 0.1663], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:46,627 - train - INFO - tau:0.96059601
2024-04-06 20:50:46,627 - train - INFO - True
2024-04-06 20:50:46,628 - train - INFO - alphas:tensor([0.2750, 0.2329, 0.1640, 0.1634, 0.1647], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:46,666 - train - INFO - tau:0.96059601
2024-04-06 20:50:46,666 - train - INFO - True
2024-04-06 20:50:46,667 - train - INFO - alphas:tensor([0.2703, 0.2465, 0.1596, 0.1611, 0.1625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:46,705 - train - INFO - tau:0.96059601
2024-04-06 20:50:46,705 - train - INFO - True
2024-04-06 20:50:46,706 - train - INFO - alphas:tensor([0.2696, 0.2388, 0.1647, 0.1627, 0.1643], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:46,745 - train - INFO - tau:0.96059601
2024-04-06 20:50:46,745 - train - INFO - True
2024-04-06 20:50:46,746 - train - INFO - alphas:tensor([0.2760, 0.2481, 0.1556, 0.1593, 0.1610], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:46,784 - train - INFO - tau:0.96059601
2024-04-06 20:50:46,785 - train - INFO - True
2024-04-06 20:50:46,785 - train - INFO - alphas:tensor([0.2878, 0.2332, 0.1581, 0.1604, 0.1605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:46,826 - train - INFO - tau:0.96059601
2024-04-06 20:50:46,826 - train - INFO - True
2024-04-06 20:50:46,827 - train - INFO - alphas:tensor([0.2751, 0.2425, 0.1601, 0.1609, 0.1614], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:46,865 - train - INFO - tau:0.96059601
2024-04-06 20:50:46,866 - train - INFO - True
2024-04-06 20:50:46,867 - train - INFO - alphas:tensor([0.2706, 0.2284, 0.1692, 0.1660, 0.1659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:46,905 - train - INFO - tau:0.96059601
2024-04-06 20:50:46,905 - train - INFO - True
2024-04-06 20:50:46,906 - train - INFO - alphas:tensor([0.2622, 0.2412, 0.1618, 0.1663, 0.1685], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:46,944 - train - INFO - tau:0.96059601
2024-04-06 20:50:46,944 - train - INFO - True
2024-04-06 20:50:46,945 - train - INFO - alphas:tensor([0.2766, 0.2307, 0.1625, 0.1646, 0.1656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:46,984 - train - INFO - tau:0.96059601
2024-04-06 20:50:46,984 - train - INFO - True
2024-04-06 20:50:46,985 - train - INFO - alphas:tensor([0.2835, 0.2406, 0.1583, 0.1585, 0.1589], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,023 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,023 - train - INFO - True
2024-04-06 20:50:47,024 - train - INFO - alphas:tensor([0.2719, 0.2199, 0.1735, 0.1667, 0.1680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,065 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,065 - train - INFO - True
2024-04-06 20:50:47,066 - train - INFO - alphas:tensor([0.2592, 0.2357, 0.1627, 0.1700, 0.1724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,107 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,107 - train - INFO - True
2024-04-06 20:50:47,108 - train - INFO - alphas:tensor([0.2703, 0.2327, 0.1633, 0.1658, 0.1679], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,146 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,146 - train - INFO - True
2024-04-06 20:50:47,147 - train - INFO - alphas:tensor([0.2783, 0.2422, 0.1620, 0.1588, 0.1588], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,190 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,195 - train - INFO - True
2024-04-06 20:50:47,196 - train - INFO - alphas:tensor([0.2609, 0.2145, 0.1791, 0.1725, 0.1730], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,244 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,244 - train - INFO - True
2024-04-06 20:50:47,245 - train - INFO - alphas:tensor([0.2565, 0.2335, 0.1644, 0.1717, 0.1739], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,285 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,285 - train - INFO - True
2024-04-06 20:50:47,286 - train - INFO - alphas:tensor([0.2687, 0.2350, 0.1650, 0.1656, 0.1657], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,324 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,324 - train - INFO - True
2024-04-06 20:50:47,325 - train - INFO - alphas:tensor([0.2924, 0.2474, 0.1547, 0.1533, 0.1521], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,363 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,363 - train - INFO - True
2024-04-06 20:50:47,364 - train - INFO - alphas:tensor([0.2791, 0.2230, 0.1658, 0.1668, 0.1653], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,402 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,402 - train - INFO - True
2024-04-06 20:50:47,403 - train - INFO - alphas:tensor([0.2496, 0.2336, 0.1682, 0.1733, 0.1753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,441 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,441 - train - INFO - True
2024-04-06 20:50:47,442 - train - INFO - alphas:tensor([0.2522, 0.2310, 0.1714, 0.1725, 0.1728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,483 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,483 - train - INFO - True
2024-04-06 20:50:47,484 - train - INFO - alphas:tensor([0.2896, 0.2465, 0.1520, 0.1548, 0.1571], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,521 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,522 - train - INFO - True
2024-04-06 20:50:47,522 - train - INFO - alphas:tensor([0.2706, 0.2421, 0.1620, 0.1624, 0.1628], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,560 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,560 - train - INFO - True
2024-04-06 20:50:47,561 - train - INFO - alphas:tensor([0.4263, 0.2818, 0.2918], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 20:50:47,567 - train - INFO - tau:0.96059601
2024-04-06 20:50:47,567 - train - INFO - avg block size:1.0
2024-04-06 20:50:47,568 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 20:50:47,568 - train - INFO - lasso_alpha:9.090909090909091e-06
2024-04-06 20:50:47,680 - train - INFO - Test: [   0/39]  Time: 0.110 (0.110)  Loss:  1.5996 (1.5996)  Acc@1: 61.7188 (61.7188)  Acc@5: 85.9375 (85.9375)
2024-04-06 20:50:49,896 - train - INFO - Test: [  39/39]  Time: 0.041 (0.058)  Loss:  1.2910 (1.6348)  Acc@1: 75.0000 (60.1500)  Acc@5: 100.0000 (87.0400)
2024-04-06 20:50:51,022 - train - INFO - Train: 7 [   0/195 (  0%)]  Loss:  3.511839 (3.5118)  Time: 1.046s,  244.68/s  (1.046s,  244.68/s)  LR: 3.880e-04  Data: 0.151 (0.151)
2024-04-06 20:51:38,647 - train - INFO - Train: 7 [  50/195 ( 26%)]  Loss:  3.386276 (3.3565)  Time: 0.952s,  269.00/s  (0.954s,  268.26/s)  LR: 3.880e-04  Data: 0.009 (0.011)
2024-04-06 20:52:28,539 - train - INFO - Train: 7 [ 100/195 ( 52%)]  Loss:  2.712138 (3.3050)  Time: 1.099s,  233.02/s  (0.976s,  262.34/s)  LR: 3.880e-04  Data: 0.006 (0.010)
2024-04-06 20:53:20,460 - train - INFO - Train: 7 [ 150/195 ( 77%)]  Loss:  3.727409 (3.3025)  Time: 0.961s,  266.33/s  (0.997s,  256.88/s)  LR: 3.880e-04  Data: 0.006 (0.010)
2024-04-06 20:54:06,203 - train - INFO - Train: 7 [ 194/195 (100%)]  Loss:  3.394794 (3.2769)  Time: 0.935s,  273.75/s  (1.006s,  254.41/s)  LR: 3.880e-04  Data: 0.000 (0.009)
2024-04-06 20:54:06,204 - train - INFO - True
2024-04-06 20:54:06,205 - train - INFO - alphas:tensor([0.2461, 0.2311, 0.1698, 0.1757, 0.1773], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,243 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,243 - train - INFO - True
2024-04-06 20:54:06,244 - train - INFO - alphas:tensor([0.2481, 0.2165, 0.1712, 0.1796, 0.1846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,324 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,324 - train - INFO - True
2024-04-06 20:54:06,325 - train - INFO - alphas:tensor([0.2993, 0.2599, 0.1433, 0.1477, 0.1499], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,365 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,365 - train - INFO - True
2024-04-06 20:54:06,366 - train - INFO - alphas:tensor([0.3060, 0.2437, 0.1478, 0.1503, 0.1522], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,420 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,420 - train - INFO - True
2024-04-06 20:54:06,421 - train - INFO - alphas:tensor([0.2817, 0.2464, 0.1534, 0.1583, 0.1602], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,484 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,484 - train - INFO - True
2024-04-06 20:54:06,485 - train - INFO - alphas:tensor([0.2988, 0.2335, 0.1553, 0.1554, 0.1571], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,524 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,525 - train - INFO - True
2024-04-06 20:54:06,526 - train - INFO - alphas:tensor([0.2957, 0.2508, 0.1489, 0.1513, 0.1533], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,564 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,564 - train - INFO - True
2024-04-06 20:54:06,565 - train - INFO - alphas:tensor([0.2945, 0.2426, 0.1550, 0.1529, 0.1549], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,603 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,603 - train - INFO - True
2024-04-06 20:54:06,604 - train - INFO - alphas:tensor([0.2976, 0.2482, 0.1472, 0.1523, 0.1546], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,642 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,642 - train - INFO - True
2024-04-06 20:54:06,643 - train - INFO - alphas:tensor([0.3179, 0.2317, 0.1476, 0.1511, 0.1517], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,681 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,681 - train - INFO - True
2024-04-06 20:54:06,682 - train - INFO - alphas:tensor([0.3022, 0.2457, 0.1491, 0.1511, 0.1519], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,721 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,721 - train - INFO - True
2024-04-06 20:54:06,723 - train - INFO - alphas:tensor([0.2967, 0.2309, 0.1599, 0.1563, 0.1562], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,763 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,763 - train - INFO - True
2024-04-06 20:54:06,764 - train - INFO - alphas:tensor([0.2850, 0.2461, 0.1514, 0.1573, 0.1603], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,802 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,802 - train - INFO - True
2024-04-06 20:54:06,803 - train - INFO - alphas:tensor([0.3054, 0.2318, 0.1524, 0.1545, 0.1559], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,841 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,841 - train - INFO - True
2024-04-06 20:54:06,842 - train - INFO - alphas:tensor([0.3137, 0.2427, 0.1470, 0.1480, 0.1486], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,880 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,880 - train - INFO - True
2024-04-06 20:54:06,881 - train - INFO - alphas:tensor([0.3003, 0.2217, 0.1636, 0.1567, 0.1577], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,919 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,919 - train - INFO - True
2024-04-06 20:54:06,920 - train - INFO - alphas:tensor([0.2784, 0.2404, 0.1534, 0.1622, 0.1657], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,958 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,959 - train - INFO - True
2024-04-06 20:54:06,960 - train - INFO - alphas:tensor([0.2960, 0.2329, 0.1540, 0.1573, 0.1598], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:06,998 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:06,998 - train - INFO - True
2024-04-06 20:54:06,999 - train - INFO - alphas:tensor([0.3136, 0.2432, 0.1496, 0.1466, 0.1469], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:07,038 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:07,038 - train - INFO - True
2024-04-06 20:54:07,040 - train - INFO - alphas:tensor([0.2934, 0.2185, 0.1673, 0.1601, 0.1607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:07,078 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:07,078 - train - INFO - True
2024-04-06 20:54:07,079 - train - INFO - alphas:tensor([0.2749, 0.2381, 0.1555, 0.1644, 0.1672], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:07,117 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:07,118 - train - INFO - True
2024-04-06 20:54:07,119 - train - INFO - alphas:tensor([0.2912, 0.2371, 0.1562, 0.1576, 0.1579], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:07,157 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:07,157 - train - INFO - True
2024-04-06 20:54:07,158 - train - INFO - alphas:tensor([0.3278, 0.2462, 0.1425, 0.1422, 0.1414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:07,196 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:07,196 - train - INFO - True
2024-04-06 20:54:07,197 - train - INFO - alphas:tensor([0.3109, 0.2254, 0.1539, 0.1557, 0.1541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:07,235 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:07,236 - train - INFO - True
2024-04-06 20:54:07,237 - train - INFO - alphas:tensor([0.2666, 0.2384, 0.1596, 0.1662, 0.1692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:07,276 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:07,276 - train - INFO - True
2024-04-06 20:54:07,277 - train - INFO - alphas:tensor([0.2693, 0.2368, 0.1638, 0.1649, 0.1653], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:07,316 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:07,316 - train - INFO - True
2024-04-06 20:54:07,317 - train - INFO - alphas:tensor([0.3206, 0.2437, 0.1419, 0.1454, 0.1483], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:07,360 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:07,361 - train - INFO - True
2024-04-06 20:54:07,362 - train - INFO - alphas:tensor([0.2949, 0.2471, 0.1516, 0.1529, 0.1534], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:07,400 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:07,400 - train - INFO - True
2024-04-06 20:54:07,401 - train - INFO - alphas:tensor([0.4450, 0.2709, 0.2841], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 20:54:07,407 - train - INFO - tau:0.9509900498999999
2024-04-06 20:54:07,407 - train - INFO - avg block size:1.0
2024-04-06 20:54:07,408 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 20:54:07,567 - train - INFO - Test: [   0/39]  Time: 0.156 (0.156)  Loss:  1.4609 (1.4609)  Acc@1: 65.6250 (65.6250)  Acc@5: 88.2812 (88.2812)
2024-04-06 20:54:10,494 - train - INFO - Test: [  39/39]  Time: 0.048 (0.077)  Loss:  1.0713 (1.4781)  Acc@1: 81.2500 (63.0900)  Acc@5: 93.7500 (88.4000)
2024-04-06 20:54:11,712 - train - INFO - Train: 8 [   0/195 (  0%)]  Loss:  2.828525 (2.8285)  Time: 1.106s,  231.38/s  (1.106s,  231.38/s)  LR: 4.420e-04  Data: 0.211 (0.211)
2024-04-06 20:54:59,777 - train - INFO - Train: 8 [  50/195 ( 26%)]  Loss:  3.616748 (3.2306)  Time: 0.945s,  271.00/s  (0.964s,  265.53/s)  LR: 4.420e-04  Data: 0.006 (0.012)
2024-04-06 20:55:42,032 - train - INFO - Train: 8 [ 100/195 ( 52%)]  Loss:  3.239958 (3.2655)  Time: 0.827s,  309.49/s  (0.905s,  282.82/s)  LR: 4.420e-04  Data: 0.008 (0.010)
2024-04-06 20:56:24,480 - train - INFO - Train: 8 [ 150/195 ( 77%)]  Loss:  3.398404 (3.2408)  Time: 0.868s,  294.95/s  (0.887s,  288.76/s)  LR: 4.420e-04  Data: 0.012 (0.010)
2024-04-06 20:57:01,461 - train - INFO - Train: 8 [ 194/195 (100%)]  Loss:  3.386787 (3.2357)  Time: 0.856s,  299.16/s  (0.876s,  292.19/s)  LR: 4.420e-04  Data: 0.000 (0.009)
2024-04-06 20:57:01,461 - train - INFO - True
2024-04-06 20:57:01,463 - train - INFO - alphas:tensor([0.2501, 0.2315, 0.1674, 0.1745, 0.1764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,512 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,512 - train - INFO - True
2024-04-06 20:57:01,513 - train - INFO - alphas:tensor([0.2569, 0.2150, 0.1668, 0.1774, 0.1839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,554 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,554 - train - INFO - True
2024-04-06 20:57:01,555 - train - INFO - alphas:tensor([0.3220, 0.2585, 0.1351, 0.1408, 0.1436], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,591 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,591 - train - INFO - True
2024-04-06 20:57:01,592 - train - INFO - alphas:tensor([0.3333, 0.2361, 0.1402, 0.1439, 0.1465], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,624 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,624 - train - INFO - True
2024-04-06 20:57:01,625 - train - INFO - alphas:tensor([0.2972, 0.2450, 0.1475, 0.1539, 0.1564], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,655 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,655 - train - INFO - True
2024-04-06 20:57:01,655 - train - INFO - alphas:tensor([0.3215, 0.2308, 0.1475, 0.1490, 0.1512], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,685 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,685 - train - INFO - True
2024-04-06 20:57:01,686 - train - INFO - alphas:tensor([0.3259, 0.2490, 0.1386, 0.1420, 0.1445], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,715 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,715 - train - INFO - True
2024-04-06 20:57:01,716 - train - INFO - alphas:tensor([0.3246, 0.2412, 0.1452, 0.1433, 0.1457], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,746 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,746 - train - INFO - True
2024-04-06 20:57:01,746 - train - INFO - alphas:tensor([0.3185, 0.2439, 0.1403, 0.1471, 0.1501], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,776 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,776 - train - INFO - True
2024-04-06 20:57:01,777 - train - INFO - alphas:tensor([0.3496, 0.2245, 0.1389, 0.1429, 0.1441], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,807 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,807 - train - INFO - True
2024-04-06 20:57:01,808 - train - INFO - alphas:tensor([0.3338, 0.2422, 0.1389, 0.1420, 0.1432], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,837 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,837 - train - INFO - True
2024-04-06 20:57:01,838 - train - INFO - alphas:tensor([0.3268, 0.2300, 0.1499, 0.1466, 0.1468], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,867 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,867 - train - INFO - True
2024-04-06 20:57:01,868 - train - INFO - alphas:tensor([0.3091, 0.2452, 0.1420, 0.1499, 0.1537], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,898 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,898 - train - INFO - True
2024-04-06 20:57:01,899 - train - INFO - alphas:tensor([0.3386, 0.2252, 0.1432, 0.1457, 0.1473], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,928 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,929 - train - INFO - True
2024-04-06 20:57:01,929 - train - INFO - alphas:tensor([0.3483, 0.2375, 0.1367, 0.1383, 0.1391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,959 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,959 - train - INFO - True
2024-04-06 20:57:01,959 - train - INFO - alphas:tensor([0.3312, 0.2204, 0.1534, 0.1470, 0.1480], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:01,989 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:01,989 - train - INFO - True
2024-04-06 20:57:01,990 - train - INFO - alphas:tensor([0.3002, 0.2407, 0.1446, 0.1550, 0.1595], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:02,020 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:02,020 - train - INFO - True
2024-04-06 20:57:02,020 - train - INFO - alphas:tensor([0.3248, 0.2301, 0.1447, 0.1487, 0.1518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:02,050 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:02,050 - train - INFO - True
2024-04-06 20:57:02,051 - train - INFO - alphas:tensor([0.3569, 0.2344, 0.1375, 0.1352, 0.1360], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:02,080 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:02,080 - train - INFO - True
2024-04-06 20:57:02,081 - train - INFO - alphas:tensor([0.3316, 0.2161, 0.1555, 0.1479, 0.1489], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:02,111 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:02,111 - train - INFO - True
2024-04-06 20:57:02,111 - train - INFO - alphas:tensor([0.2954, 0.2393, 0.1470, 0.1574, 0.1609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:02,141 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:02,141 - train - INFO - True
2024-04-06 20:57:02,142 - train - INFO - alphas:tensor([0.3159, 0.2361, 0.1478, 0.1498, 0.1504], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:02,172 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:02,172 - train - INFO - True
2024-04-06 20:57:02,173 - train - INFO - alphas:tensor([0.3669, 0.2358, 0.1321, 0.1327, 0.1325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:02,202 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:02,202 - train - INFO - True
2024-04-06 20:57:02,203 - train - INFO - alphas:tensor([0.3461, 0.2207, 0.1429, 0.1459, 0.1443], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:02,232 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:02,232 - train - INFO - True
2024-04-06 20:57:02,233 - train - INFO - alphas:tensor([0.2857, 0.2402, 0.1513, 0.1596, 0.1633], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:02,263 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:02,263 - train - INFO - True
2024-04-06 20:57:02,264 - train - INFO - alphas:tensor([0.2889, 0.2395, 0.1563, 0.1574, 0.1579], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:02,294 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:02,294 - train - INFO - True
2024-04-06 20:57:02,294 - train - INFO - alphas:tensor([0.3547, 0.2329, 0.1333, 0.1378, 0.1413], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:02,324 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:02,324 - train - INFO - True
2024-04-06 20:57:02,325 - train - INFO - alphas:tensor([0.3210, 0.2452, 0.1429, 0.1451, 0.1459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:02,354 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:02,355 - train - INFO - True
2024-04-06 20:57:02,355 - train - INFO - alphas:tensor([0.4611, 0.2611, 0.2778], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 20:57:02,360 - train - INFO - tau:0.9414801494009999
2024-04-06 20:57:02,360 - train - INFO - avg block size:1.0
2024-04-06 20:57:02,360 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 20:57:02,360 - train - INFO - lasso_alpha:8.264462809917356e-06
2024-04-06 20:57:02,542 - train - INFO - Test: [   0/39]  Time: 0.179 (0.179)  Loss:  1.3438 (1.3438)  Acc@1: 66.4062 (66.4062)  Acc@5: 90.2344 (90.2344)
2024-04-06 20:57:04,253 - train - INFO - Test: [  39/39]  Time: 0.040 (0.047)  Loss:  1.0859 (1.3888)  Acc@1: 75.0000 (64.9300)  Acc@5: 100.0000 (89.7500)
2024-04-06 20:57:05,384 - train - INFO - Train: 9 [   0/195 (  0%)]  Loss:  3.143287 (3.1433)  Time: 1.057s,  242.12/s  (1.057s,  242.12/s)  LR: 4.960e-04  Data: 0.212 (0.212)
2024-04-06 20:57:46,924 - train - INFO - Train: 9 [  50/195 ( 26%)]  Loss:  3.505043 (3.1775)  Time: 0.815s,  313.94/s  (0.835s,  306.51/s)  LR: 4.960e-04  Data: 0.007 (0.012)
2024-04-06 20:58:28,686 - train - INFO - Train: 9 [ 100/195 ( 52%)]  Loss:  2.632591 (3.1308)  Time: 0.813s,  314.94/s  (0.835s,  306.51/s)  LR: 4.960e-04  Data: 0.007 (0.010)
2024-04-06 20:59:10,349 - train - INFO - Train: 9 [ 150/195 ( 77%)]  Loss:  2.504215 (3.1370)  Time: 1.065s,  240.48/s  (0.835s,  306.75/s)  LR: 4.960e-04  Data: 0.007 (0.010)
2024-04-06 20:59:54,225 - train - INFO - Train: 9 [ 194/195 (100%)]  Loss:  3.156280 (3.1129)  Time: 0.901s,  284.09/s  (0.871s,  293.83/s)  LR: 4.960e-04  Data: 0.000 (0.010)
2024-04-06 20:59:54,225 - train - INFO - True
2024-04-06 20:59:54,227 - train - INFO - alphas:tensor([0.2532, 0.2312, 0.1656, 0.1738, 0.1762], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,265 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,265 - train - INFO - True
2024-04-06 20:59:54,266 - train - INFO - alphas:tensor([0.2656, 0.2124, 0.1628, 0.1756, 0.1835], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,304 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,304 - train - INFO - True
2024-04-06 20:59:54,305 - train - INFO - alphas:tensor([0.3468, 0.2529, 0.1278, 0.1346, 0.1380], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,354 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,355 - train - INFO - True
2024-04-06 20:59:54,355 - train - INFO - alphas:tensor([0.3621, 0.2254, 0.1332, 0.1380, 0.1413], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,396 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,396 - train - INFO - True
2024-04-06 20:59:54,397 - train - INFO - alphas:tensor([0.3111, 0.2418, 0.1428, 0.1506, 0.1537], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,436 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,436 - train - INFO - True
2024-04-06 20:59:54,437 - train - INFO - alphas:tensor([0.3467, 0.2234, 0.1405, 0.1433, 0.1460], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,475 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,475 - train - INFO - True
2024-04-06 20:59:54,475 - train - INFO - alphas:tensor([0.3619, 0.2394, 0.1289, 0.1334, 0.1364], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,514 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,514 - train - INFO - True
2024-04-06 20:59:54,514 - train - INFO - alphas:tensor([0.3598, 0.2344, 0.1354, 0.1339, 0.1365], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,553 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,553 - train - INFO - True
2024-04-06 20:59:54,554 - train - INFO - alphas:tensor([0.3408, 0.2363, 0.1343, 0.1425, 0.1461], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,592 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,592 - train - INFO - True
2024-04-06 20:59:54,593 - train - INFO - alphas:tensor([0.3821, 0.2136, 0.1309, 0.1358, 0.1376], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,631 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,631 - train - INFO - True
2024-04-06 20:59:54,632 - train - INFO - alphas:tensor([0.3718, 0.2319, 0.1287, 0.1331, 0.1345], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,670 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,670 - train - INFO - True
2024-04-06 20:59:54,671 - train - INFO - alphas:tensor([0.3626, 0.2238, 0.1395, 0.1368, 0.1372], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,712 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,712 - train - INFO - True
2024-04-06 20:59:54,713 - train - INFO - alphas:tensor([0.3350, 0.2399, 0.1336, 0.1434, 0.1481], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,751 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,751 - train - INFO - True
2024-04-06 20:59:54,752 - train - INFO - alphas:tensor([0.3744, 0.2146, 0.1341, 0.1374, 0.1394], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,786 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,787 - train - INFO - True
2024-04-06 20:59:54,787 - train - INFO - alphas:tensor([0.3888, 0.2260, 0.1263, 0.1290, 0.1299], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,819 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,819 - train - INFO - True
2024-04-06 20:59:54,820 - train - INFO - alphas:tensor([0.3678, 0.2155, 0.1423, 0.1367, 0.1378], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,856 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,856 - train - INFO - True
2024-04-06 20:59:54,857 - train - INFO - alphas:tensor([0.3225, 0.2372, 0.1369, 0.1490, 0.1543], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,893 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,893 - train - INFO - True
2024-04-06 20:59:54,894 - train - INFO - alphas:tensor([0.3573, 0.2213, 0.1360, 0.1409, 0.1444], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,932 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,932 - train - INFO - True
2024-04-06 20:59:54,933 - train - INFO - alphas:tensor([0.4062, 0.2185, 0.1257, 0.1243, 0.1254], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:54,971 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:54,971 - train - INFO - True
2024-04-06 20:59:54,972 - train - INFO - alphas:tensor([0.3778, 0.2075, 0.1425, 0.1355, 0.1368], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:55,010 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:55,011 - train - INFO - True
2024-04-06 20:59:55,011 - train - INFO - alphas:tensor([0.3165, 0.2375, 0.1392, 0.1513, 0.1554], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:55,051 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:55,052 - train - INFO - True
2024-04-06 20:59:55,052 - train - INFO - alphas:tensor([0.3430, 0.2313, 0.1396, 0.1427, 0.1435], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:55,091 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:55,091 - train - INFO - True
2024-04-06 20:59:55,092 - train - INFO - alphas:tensor([0.4106, 0.2179, 0.1227, 0.1241, 0.1246], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:55,129 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:55,129 - train - INFO - True
2024-04-06 20:59:55,130 - train - INFO - alphas:tensor([0.3836, 0.2119, 0.1328, 0.1366, 0.1352], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:55,165 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:55,166 - train - INFO - True
2024-04-06 20:59:55,166 - train - INFO - alphas:tensor([0.3072, 0.2399, 0.1428, 0.1528, 0.1574], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:55,200 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:55,200 - train - INFO - True
2024-04-06 20:59:55,201 - train - INFO - alphas:tensor([0.3114, 0.2410, 0.1480, 0.1494, 0.1502], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:55,238 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:55,238 - train - INFO - True
2024-04-06 20:59:55,238 - train - INFO - alphas:tensor([0.3925, 0.2170, 0.1254, 0.1306, 0.1346], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:55,271 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:55,271 - train - INFO - True
2024-04-06 20:59:55,272 - train - INFO - alphas:tensor([0.3513, 0.2376, 0.1344, 0.1377, 0.1390], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:55,302 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:55,303 - train - INFO - True
2024-04-06 20:59:55,303 - train - INFO - alphas:tensor([0.4781, 0.2508, 0.2711], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 20:59:55,309 - train - INFO - tau:0.9320653479069899
2024-04-06 20:59:55,310 - train - INFO - avg block size:1.0
2024-04-06 20:59:55,310 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 20:59:55,508 - train - INFO - Test: [   0/39]  Time: 0.195 (0.195)  Loss:  1.2393 (1.2393)  Acc@1: 71.0938 (71.0938)  Acc@5: 91.4062 (91.4062)
2024-04-06 20:59:57,532 - train - INFO - Test: [  39/39]  Time: 0.047 (0.055)  Loss:  0.9434 (1.2908)  Acc@1: 75.0000 (67.1900)  Acc@5: 100.0000 (90.4600)
2024-04-06 20:59:58,967 - train - INFO - Train: 10 [   0/195 (  0%)]  Loss:  3.529084 (3.5291)  Time: 1.357s,  188.66/s  (1.357s,  188.66/s)  LR: 5.441e-04  Data: 0.204 (0.204)
2024-04-06 21:00:46,622 - train - INFO - Train: 10 [  50/195 ( 26%)]  Loss:  3.407576 (3.0820)  Time: 1.041s,  245.81/s  (0.961s,  266.39/s)  LR: 5.441e-04  Data: 0.006 (0.014)
2024-04-06 21:01:42,319 - train - INFO - Train: 10 [ 100/195 ( 52%)]  Loss:  3.623449 (3.0964)  Time: 1.210s,  211.61/s  (1.037s,  246.94/s)  LR: 5.441e-04  Data: 0.039 (0.011)
2024-04-06 21:02:37,132 - train - INFO - Train: 10 [ 150/195 ( 77%)]  Loss:  3.111924 (3.1048)  Time: 1.077s,  237.78/s  (1.056s,  242.33/s)  LR: 5.441e-04  Data: 0.007 (0.011)
2024-04-06 21:03:21,033 - train - INFO - Train: 10 [ 194/195 (100%)]  Loss:  3.530607 (3.1032)  Time: 1.258s,  203.48/s  (1.043s,  245.41/s)  LR: 5.441e-04  Data: 0.000 (0.011)
2024-04-06 21:03:21,033 - train - INFO - True
2024-04-06 21:03:21,037 - train - INFO - alphas:tensor([0.2549, 0.2296, 0.1649, 0.1739, 0.1767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,102 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,102 - train - INFO - True
2024-04-06 21:03:21,104 - train - INFO - alphas:tensor([0.2735, 0.2084, 0.1593, 0.1748, 0.1840], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,154 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,155 - train - INFO - True
2024-04-06 21:03:21,156 - train - INFO - alphas:tensor([0.3692, 0.2447, 0.1222, 0.1300, 0.1339], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,206 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,206 - train - INFO - True
2024-04-06 21:03:21,208 - train - INFO - alphas:tensor([0.3897, 0.2123, 0.1273, 0.1333, 0.1373], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,258 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,258 - train - INFO - True
2024-04-06 21:03:21,259 - train - INFO - alphas:tensor([0.3234, 0.2364, 0.1396, 0.1484, 0.1523], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,309 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,309 - train - INFO - True
2024-04-06 21:03:21,310 - train - INFO - alphas:tensor([0.3678, 0.2166, 0.1347, 0.1388, 0.1421], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,360 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,360 - train - INFO - True
2024-04-06 21:03:21,361 - train - INFO - alphas:tensor([0.3980, 0.2263, 0.1204, 0.1259, 0.1294], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,411 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,411 - train - INFO - True
2024-04-06 21:03:21,412 - train - INFO - alphas:tensor([0.3961, 0.2235, 0.1263, 0.1255, 0.1285], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,462 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,462 - train - INFO - True
2024-04-06 21:03:21,465 - train - INFO - alphas:tensor([0.3590, 0.2264, 0.1304, 0.1398, 0.1444], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,507 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,507 - train - INFO - True
2024-04-06 21:03:21,509 - train - INFO - alphas:tensor([0.4117, 0.2014, 0.1244, 0.1300, 0.1324], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,541 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,542 - train - INFO - True
2024-04-06 21:03:21,543 - train - INFO - alphas:tensor([0.4098, 0.2178, 0.1199, 0.1253, 0.1271], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,573 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,573 - train - INFO - True
2024-04-06 21:03:21,575 - train - INFO - alphas:tensor([0.3982, 0.2149, 0.1302, 0.1280, 0.1288], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,607 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,607 - train - INFO - True
2024-04-06 21:03:21,609 - train - INFO - alphas:tensor([0.3584, 0.2303, 0.1276, 0.1391, 0.1446], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,691 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,691 - train - INFO - True
2024-04-06 21:03:21,693 - train - INFO - alphas:tensor([0.4065, 0.2039, 0.1263, 0.1304, 0.1328], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,745 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,745 - train - INFO - True
2024-04-06 21:03:21,747 - train - INFO - alphas:tensor([0.4299, 0.2110, 0.1170, 0.1205, 0.1215], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,797 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,797 - train - INFO - True
2024-04-06 21:03:21,798 - train - INFO - alphas:tensor([0.4060, 0.2062, 0.1321, 0.1272, 0.1286], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,848 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,849 - train - INFO - True
2024-04-06 21:03:21,850 - train - INFO - alphas:tensor([0.3441, 0.2310, 0.1307, 0.1440, 0.1503], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,900 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,900 - train - INFO - True
2024-04-06 21:03:21,902 - train - INFO - alphas:tensor([0.3895, 0.2095, 0.1287, 0.1341, 0.1381], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:21,952 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:21,952 - train - INFO - True
2024-04-06 21:03:21,953 - train - INFO - alphas:tensor([0.4564, 0.1980, 0.1150, 0.1145, 0.1160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:22,003 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:22,003 - train - INFO - True
2024-04-06 21:03:22,004 - train - INFO - alphas:tensor([0.4251, 0.1939, 0.1307, 0.1244, 0.1259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:22,054 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:22,054 - train - INFO - True
2024-04-06 21:03:22,056 - train - INFO - alphas:tensor([0.3375, 0.2315, 0.1329, 0.1467, 0.1514], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:22,106 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:22,106 - train - INFO - True
2024-04-06 21:03:22,107 - train - INFO - alphas:tensor([0.3717, 0.2221, 0.1323, 0.1362, 0.1377], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:22,157 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:22,157 - train - INFO - True
2024-04-06 21:03:22,159 - train - INFO - alphas:tensor([0.4538, 0.1983, 0.1141, 0.1164, 0.1173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:22,209 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:22,209 - train - INFO - True
2024-04-06 21:03:22,211 - train - INFO - alphas:tensor([0.4215, 0.1984, 0.1241, 0.1285, 0.1275], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:22,261 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:22,261 - train - INFO - True
2024-04-06 21:03:22,263 - train - INFO - alphas:tensor([0.3275, 0.2353, 0.1362, 0.1478, 0.1532], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:22,313 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:22,313 - train - INFO - True
2024-04-06 21:03:22,314 - train - INFO - alphas:tensor([0.3354, 0.2380, 0.1405, 0.1425, 0.1436], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:22,364 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:22,364 - train - INFO - True
2024-04-06 21:03:22,366 - train - INFO - alphas:tensor([0.4303, 0.1998, 0.1178, 0.1238, 0.1283], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:22,416 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:22,417 - train - INFO - True
2024-04-06 21:03:22,419 - train - INFO - alphas:tensor([0.3829, 0.2249, 0.1274, 0.1316, 0.1331], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:22,476 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:22,476 - train - INFO - True
2024-04-06 21:03:22,478 - train - INFO - alphas:tensor([0.4928, 0.2417, 0.2656], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 21:03:22,484 - train - INFO - tau:0.92274469442792
2024-04-06 21:03:22,484 - train - INFO - avg block size:1.0
2024-04-06 21:03:22,485 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 21:03:22,485 - train - INFO - lasso_alpha:7.513148009015777e-06
2024-04-06 21:03:22,705 - train - INFO - Test: [   0/39]  Time: 0.218 (0.218)  Loss:  1.1855 (1.1855)  Acc@1: 71.4844 (71.4844)  Acc@5: 92.1875 (92.1875)
2024-04-06 21:03:27,014 - train - INFO - Test: [  39/39]  Time: 0.382 (0.113)  Loss:  0.7788 (1.2427)  Acc@1: 81.2500 (68.3000)  Acc@5: 100.0000 (91.0900)
2024-04-06 21:03:28,248 - train - INFO - Train: 11 [   0/195 (  0%)]  Loss:  2.504255 (2.5043)  Time: 1.156s,  221.36/s  (1.156s,  221.36/s)  LR: 5.429e-04  Data: 0.196 (0.196)
2024-04-06 21:04:20,569 - train - INFO - Train: 11 [  50/195 ( 26%)]  Loss:  3.170623 (3.1023)  Time: 1.155s,  221.64/s  (1.049s,  244.15/s)  LR: 5.429e-04  Data: 0.005 (0.014)
2024-04-06 21:05:12,490 - train - INFO - Train: 11 [ 100/195 ( 52%)]  Loss:  3.548094 (3.0596)  Time: 0.972s,  263.40/s  (1.044s,  245.32/s)  LR: 5.429e-04  Data: 0.013 (0.012)
2024-04-06 21:06:05,814 - train - INFO - Train: 11 [ 150/195 ( 77%)]  Loss:  3.648212 (3.0231)  Time: 1.138s,  224.98/s  (1.051s,  243.56/s)  LR: 5.429e-04  Data: 0.007 (0.012)
2024-04-06 21:06:51,160 - train - INFO - Train: 11 [ 194/195 (100%)]  Loss:  2.492238 (3.0163)  Time: 1.177s,  217.44/s  (1.046s,  244.64/s)  LR: 5.429e-04  Data: 0.000 (0.012)
2024-04-06 21:06:51,161 - train - INFO - True
2024-04-06 21:06:51,162 - train - INFO - alphas:tensor([0.2570, 0.2285, 0.1640, 0.1737, 0.1768], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,198 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,198 - train - INFO - True
2024-04-06 21:06:51,199 - train - INFO - alphas:tensor([0.2803, 0.2049, 0.1558, 0.1739, 0.1851], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,231 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,231 - train - INFO - True
2024-04-06 21:06:51,232 - train - INFO - alphas:tensor([0.3887, 0.2364, 0.1176, 0.1265, 0.1308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,262 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,262 - train - INFO - True
2024-04-06 21:06:51,262 - train - INFO - alphas:tensor([0.4123, 0.2017, 0.1226, 0.1294, 0.1341], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,292 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,292 - train - INFO - True
2024-04-06 21:06:51,293 - train - INFO - alphas:tensor([0.3334, 0.2316, 0.1371, 0.1468, 0.1511], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,330 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,330 - train - INFO - True
2024-04-06 21:06:51,331 - train - INFO - alphas:tensor([0.3876, 0.2090, 0.1299, 0.1351, 0.1384], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,365 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,365 - train - INFO - True
2024-04-06 21:06:51,365 - train - INFO - alphas:tensor([0.4309, 0.2120, 0.1135, 0.1198, 0.1237], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,397 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,397 - train - INFO - True
2024-04-06 21:06:51,397 - train - INFO - alphas:tensor([0.4288, 0.2118, 0.1189, 0.1186, 0.1218], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,427 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,427 - train - INFO - True
2024-04-06 21:06:51,428 - train - INFO - alphas:tensor([0.3744, 0.2174, 0.1271, 0.1379, 0.1431], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,460 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,460 - train - INFO - True
2024-04-06 21:06:51,461 - train - INFO - alphas:tensor([0.4372, 0.1909, 0.1188, 0.1251, 0.1280], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,497 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,497 - train - INFO - True
2024-04-06 21:06:51,498 - train - INFO - alphas:tensor([0.4456, 0.2031, 0.1122, 0.1185, 0.1206], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,531 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,531 - train - INFO - True
2024-04-06 21:06:51,532 - train - INFO - alphas:tensor([0.4324, 0.2038, 0.1219, 0.1204, 0.1215], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,562 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,562 - train - INFO - True
2024-04-06 21:06:51,563 - train - INFO - alphas:tensor([0.3783, 0.2204, 0.1230, 0.1360, 0.1424], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,600 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,600 - train - INFO - True
2024-04-06 21:06:51,600 - train - INFO - alphas:tensor([0.4354, 0.1926, 0.1198, 0.1247, 0.1275], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,635 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,635 - train - INFO - True
2024-04-06 21:06:51,636 - train - INFO - alphas:tensor([0.4685, 0.1952, 0.1087, 0.1131, 0.1145], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,667 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,667 - train - INFO - True
2024-04-06 21:06:51,670 - train - INFO - alphas:tensor([0.4429, 0.1953, 0.1229, 0.1186, 0.1203], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,702 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,702 - train - INFO - True
2024-04-06 21:06:51,703 - train - INFO - alphas:tensor([0.3642, 0.2221, 0.1257, 0.1405, 0.1476], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,740 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,740 - train - INFO - True
2024-04-06 21:06:51,742 - train - INFO - alphas:tensor([0.4182, 0.1994, 0.1220, 0.1279, 0.1324], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,775 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,775 - train - INFO - True
2024-04-06 21:06:51,776 - train - INFO - alphas:tensor([0.5016, 0.1792, 0.1056, 0.1059, 0.1077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,807 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,807 - train - INFO - True
2024-04-06 21:06:51,808 - train - INFO - alphas:tensor([0.4701, 0.1797, 0.1198, 0.1144, 0.1160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,845 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,845 - train - INFO - True
2024-04-06 21:06:51,846 - train - INFO - alphas:tensor([0.3563, 0.2241, 0.1281, 0.1431, 0.1485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,881 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,881 - train - INFO - True
2024-04-06 21:06:51,882 - train - INFO - alphas:tensor([0.3989, 0.2119, 0.1260, 0.1307, 0.1325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,914 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,914 - train - INFO - True
2024-04-06 21:06:51,916 - train - INFO - alphas:tensor([0.4937, 0.1799, 0.1063, 0.1093, 0.1108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,950 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,950 - train - INFO - True
2024-04-06 21:06:51,950 - train - INFO - alphas:tensor([0.4581, 0.1846, 0.1160, 0.1211, 0.1202], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:51,985 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:51,985 - train - INFO - True
2024-04-06 21:06:51,986 - train - INFO - alphas:tensor([0.3468, 0.2284, 0.1310, 0.1438, 0.1500], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:52,018 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:52,018 - train - INFO - True
2024-04-06 21:06:52,019 - train - INFO - alphas:tensor([0.3573, 0.2327, 0.1344, 0.1371, 0.1385], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:52,049 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:52,049 - train - INFO - True
2024-04-06 21:06:52,050 - train - INFO - alphas:tensor([0.4647, 0.1836, 0.1113, 0.1178, 0.1227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:52,082 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:52,082 - train - INFO - True
2024-04-06 21:06:52,084 - train - INFO - alphas:tensor([0.4126, 0.2120, 0.1212, 0.1261, 0.1280], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:52,119 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:52,119 - train - INFO - True
2024-04-06 21:06:52,120 - train - INFO - alphas:tensor([0.5059, 0.2337, 0.2604], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 21:06:52,125 - train - INFO - tau:0.9135172474836407
2024-04-06 21:06:52,125 - train - INFO - avg block size:1.0
2024-04-06 21:06:52,125 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 21:06:52,400 - train - INFO - Test: [   0/39]  Time: 0.272 (0.272)  Loss:  1.1914 (1.1914)  Acc@1: 70.7031 (70.7031)  Acc@5: 91.4062 (91.4062)
2024-04-06 21:06:55,874 - train - INFO - Test: [  39/39]  Time: 0.041 (0.094)  Loss:  0.9312 (1.1975)  Acc@1: 81.2500 (69.4800)  Acc@5: 93.7500 (91.5300)
2024-04-06 21:06:57,272 - train - INFO - Train: 12 [   0/195 (  0%)]  Loss:  3.513550 (3.5135)  Time: 1.323s,  193.54/s  (1.323s,  193.54/s)  LR: 5.415e-04  Data: 0.196 (0.196)
2024-04-06 21:07:47,480 - train - INFO - Train: 12 [  50/195 ( 26%)]  Loss:  3.311237 (3.0409)  Time: 0.968s,  264.35/s  (1.010s,  253.37/s)  LR: 5.415e-04  Data: 0.007 (0.013)
2024-04-06 21:08:39,368 - train - INFO - Train: 12 [ 100/195 ( 52%)]  Loss:  2.462237 (2.9868)  Time: 0.845s,  303.13/s  (1.024s,  250.02/s)  LR: 5.415e-04  Data: 0.006 (0.012)
2024-04-06 21:09:31,163 - train - INFO - Train: 12 [ 150/195 ( 77%)]  Loss:  3.179904 (2.9644)  Time: 0.982s,  260.59/s  (1.028s,  249.06/s)  LR: 5.415e-04  Data: 0.012 (0.011)
2024-04-06 21:10:16,074 - train - INFO - Train: 12 [ 194/195 (100%)]  Loss:  3.376820 (2.9753)  Time: 1.154s,  221.79/s  (1.026s,  249.45/s)  LR: 5.415e-04  Data: 0.000 (0.011)
2024-04-06 21:10:16,074 - train - INFO - True
2024-04-06 21:10:16,077 - train - INFO - alphas:tensor([0.2578, 0.2270, 0.1639, 0.1739, 0.1773], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,114 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,115 - train - INFO - True
2024-04-06 21:10:16,116 - train - INFO - alphas:tensor([0.2871, 0.2015, 0.1528, 0.1729, 0.1857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,149 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,149 - train - INFO - True
2024-04-06 21:10:16,151 - train - INFO - alphas:tensor([0.4083, 0.2280, 0.1133, 0.1228, 0.1276], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,182 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,182 - train - INFO - True
2024-04-06 21:10:16,195 - train - INFO - alphas:tensor([0.4351, 0.1909, 0.1179, 0.1254, 0.1307], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,231 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,231 - train - INFO - True
2024-04-06 21:10:16,232 - train - INFO - alphas:tensor([0.3407, 0.2258, 0.1358, 0.1464, 0.1514], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,266 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,267 - train - INFO - True
2024-04-06 21:10:16,267 - train - INFO - alphas:tensor([0.4038, 0.2027, 0.1262, 0.1318, 0.1356], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,297 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,297 - train - INFO - True
2024-04-06 21:10:16,298 - train - INFO - alphas:tensor([0.4612, 0.1983, 0.1076, 0.1143, 0.1186], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,335 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,335 - train - INFO - True
2024-04-06 21:10:16,336 - train - INFO - alphas:tensor([0.4600, 0.2001, 0.1120, 0.1122, 0.1157], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,370 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,370 - train - INFO - True
2024-04-06 21:10:16,384 - train - INFO - alphas:tensor([0.3874, 0.2094, 0.1243, 0.1365, 0.1425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,414 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,415 - train - INFO - True
2024-04-06 21:10:16,427 - train - INFO - alphas:tensor([0.4591, 0.1820, 0.1140, 0.1208, 0.1241], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,464 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,464 - train - INFO - True
2024-04-06 21:10:16,465 - train - INFO - alphas:tensor([0.4779, 0.1891, 0.1056, 0.1125, 0.1148], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,499 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,499 - train - INFO - True
2024-04-06 21:10:16,501 - train - INFO - alphas:tensor([0.4645, 0.1925, 0.1145, 0.1136, 0.1150], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,531 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,531 - train - INFO - True
2024-04-06 21:10:16,532 - train - INFO - alphas:tensor([0.3935, 0.2117, 0.1199, 0.1339, 0.1411], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,569 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,569 - train - INFO - True
2024-04-06 21:10:16,570 - train - INFO - alphas:tensor([0.4607, 0.1820, 0.1145, 0.1198, 0.1230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,604 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,604 - train - INFO - True
2024-04-06 21:10:16,605 - train - INFO - alphas:tensor([0.5038, 0.1803, 0.1014, 0.1064, 0.1080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,635 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,635 - train - INFO - True
2024-04-06 21:10:16,637 - train - INFO - alphas:tensor([0.4794, 0.1832, 0.1144, 0.1105, 0.1125], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,673 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,673 - train - INFO - True
2024-04-06 21:10:16,674 - train - INFO - alphas:tensor([0.3805, 0.2143, 0.1219, 0.1377, 0.1456], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,710 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,710 - train - INFO - True
2024-04-06 21:10:16,711 - train - INFO - alphas:tensor([0.4447, 0.1884, 0.1164, 0.1228, 0.1277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,742 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,742 - train - INFO - True
2024-04-06 21:10:16,743 - train - INFO - alphas:tensor([0.5385, 0.1632, 0.0982, 0.0990, 0.1011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,773 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,773 - train - INFO - True
2024-04-06 21:10:16,773 - train - INFO - alphas:tensor([0.5082, 0.1660, 0.1112, 0.1064, 0.1082], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,809 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,809 - train - INFO - True
2024-04-06 21:10:16,810 - train - INFO - alphas:tensor([0.3732, 0.2161, 0.1242, 0.1402, 0.1463], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,843 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,843 - train - INFO - True
2024-04-06 21:10:16,844 - train - INFO - alphas:tensor([0.4229, 0.2020, 0.1210, 0.1260, 0.1281], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,875 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,875 - train - INFO - True
2024-04-06 21:10:16,889 - train - INFO - alphas:tensor([0.5258, 0.1656, 0.0998, 0.1035, 0.1053], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,919 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,919 - train - INFO - True
2024-04-06 21:10:16,931 - train - INFO - alphas:tensor([0.4878, 0.1726, 0.1097, 0.1153, 0.1147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:16,968 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:16,968 - train - INFO - True
2024-04-06 21:10:16,969 - train - INFO - alphas:tensor([0.3623, 0.2203, 0.1273, 0.1415, 0.1486], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:17,003 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:17,003 - train - INFO - True
2024-04-06 21:10:17,005 - train - INFO - alphas:tensor([0.3774, 0.2265, 0.1293, 0.1326, 0.1342], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:17,035 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:17,035 - train - INFO - True
2024-04-06 21:10:17,044 - train - INFO - alphas:tensor([0.4939, 0.1698, 0.1057, 0.1127, 0.1179], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:17,075 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:17,075 - train - INFO - True
2024-04-06 21:10:17,076 - train - INFO - alphas:tensor([0.4405, 0.1992, 0.1158, 0.1212, 0.1233], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:17,113 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:17,113 - train - INFO - True
2024-04-06 21:10:17,117 - train - INFO - alphas:tensor([0.5171, 0.2268, 0.2561], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 21:10:17,122 - train - INFO - tau:0.9043820750088043
2024-04-06 21:10:17,122 - train - INFO - avg block size:1.0
2024-04-06 21:10:17,123 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 21:10:17,123 - train - INFO - lasso_alpha:6.8301345536507055e-06
2024-04-06 21:10:17,309 - train - INFO - Test: [   0/39]  Time: 0.184 (0.184)  Loss:  1.2217 (1.2217)  Acc@1: 68.3594 (68.3594)  Acc@5: 91.4062 (91.4062)
2024-04-06 21:10:20,796 - train - INFO - Test: [  39/39]  Time: 0.060 (0.092)  Loss:  0.9102 (1.1824)  Acc@1: 81.2500 (69.7700)  Acc@5: 87.5000 (91.7100)
2024-04-06 21:10:22,268 - train - INFO - Train: 13 [   0/195 (  0%)]  Loss:  2.487329 (2.4873)  Time: 1.385s,  184.80/s  (1.385s,  184.80/s)  LR: 5.401e-04  Data: 0.203 (0.203)
2024-04-06 21:11:12,223 - train - INFO - Train: 13 [  50/195 ( 26%)]  Loss:  2.333380 (2.9654)  Time: 0.915s,  279.76/s  (1.007s,  254.31/s)  LR: 5.401e-04  Data: 0.016 (0.014)
2024-04-06 21:12:03,202 - train - INFO - Train: 13 [ 100/195 ( 52%)]  Loss:  2.375171 (2.9848)  Time: 1.057s,  242.16/s  (1.013s,  252.71/s)  LR: 5.401e-04  Data: 0.011 (0.012)
2024-04-06 21:12:53,948 - train - INFO - Train: 13 [ 150/195 ( 77%)]  Loss:  3.288318 (2.9882)  Time: 0.860s,  297.56/s  (1.014s,  252.55/s)  LR: 5.401e-04  Data: 0.009 (0.011)
2024-04-06 21:13:40,270 - train - INFO - Train: 13 [ 194/195 (100%)]  Loss:  2.800996 (2.9675)  Time: 1.169s,  219.05/s  (1.022s,  250.38/s)  LR: 5.401e-04  Data: 0.000 (0.011)
2024-04-06 21:13:40,271 - train - INFO - True
2024-04-06 21:13:40,275 - train - INFO - alphas:tensor([0.2580, 0.2248, 0.1639, 0.1748, 0.1784], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:40,351 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:40,351 - train - INFO - True
2024-04-06 21:13:40,352 - train - INFO - alphas:tensor([0.2931, 0.1987, 0.1502, 0.1718, 0.1862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:40,406 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:40,406 - train - INFO - True
2024-04-06 21:13:40,407 - train - INFO - alphas:tensor([0.4257, 0.2192, 0.1098, 0.1200, 0.1252], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:40,457 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:40,457 - train - INFO - True
2024-04-06 21:13:40,470 - train - INFO - alphas:tensor([0.4540, 0.1822, 0.1138, 0.1220, 0.1280], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:40,520 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:40,520 - train - INFO - True
2024-04-06 21:13:40,522 - train - INFO - alphas:tensor([0.3500, 0.2207, 0.1337, 0.1450, 0.1505], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:40,572 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:40,572 - train - INFO - True
2024-04-06 21:13:40,574 - train - INFO - alphas:tensor([0.4199, 0.1962, 0.1225, 0.1285, 0.1328], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:40,624 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:40,624 - train - INFO - True
2024-04-06 21:13:40,626 - train - INFO - alphas:tensor([0.4879, 0.1854, 0.1025, 0.1098, 0.1144], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:40,676 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:40,676 - train - INFO - True
2024-04-06 21:13:40,678 - train - INFO - alphas:tensor([0.4863, 0.1889, 0.1066, 0.1073, 0.1110], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:40,728 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:40,728 - train - INFO - True
2024-04-06 21:13:40,740 - train - INFO - alphas:tensor([0.3982, 0.2016, 0.1224, 0.1355, 0.1423], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:40,791 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:40,791 - train - INFO - True
2024-04-06 21:13:40,792 - train - INFO - alphas:tensor([0.4765, 0.1748, 0.1103, 0.1173, 0.1211], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:40,842 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:40,842 - train - INFO - True
2024-04-06 21:13:40,843 - train - INFO - alphas:tensor([0.5067, 0.1759, 0.0999, 0.1075, 0.1100], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:40,893 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:40,893 - train - INFO - True
2024-04-06 21:13:40,894 - train - INFO - alphas:tensor([0.4921, 0.1820, 0.1084, 0.1080, 0.1095], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:40,945 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:40,945 - train - INFO - True
2024-04-06 21:13:40,947 - train - INFO - alphas:tensor([0.4074, 0.2034, 0.1172, 0.1320, 0.1400], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:40,997 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:40,997 - train - INFO - True
2024-04-06 21:13:41,008 - train - INFO - alphas:tensor([0.4828, 0.1731, 0.1097, 0.1153, 0.1190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,058 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,058 - train - INFO - True
2024-04-06 21:13:41,060 - train - INFO - alphas:tensor([0.5340, 0.1675, 0.0953, 0.1008, 0.1025], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,110 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,110 - train - INFO - True
2024-04-06 21:13:41,111 - train - INFO - alphas:tensor([0.5109, 0.1717, 0.1073, 0.1039, 0.1061], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,159 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,159 - train - INFO - True
2024-04-06 21:13:41,160 - train - INFO - alphas:tensor([0.3957, 0.2062, 0.1187, 0.1354, 0.1440], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,201 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,202 - train - INFO - True
2024-04-06 21:13:41,202 - train - INFO - alphas:tensor([0.4671, 0.1788, 0.1117, 0.1187, 0.1237], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,239 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,239 - train - INFO - True
2024-04-06 21:13:41,239 - train - INFO - alphas:tensor([0.5690, 0.1501, 0.0921, 0.0933, 0.0955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,272 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,272 - train - INFO - True
2024-04-06 21:13:41,273 - train - INFO - alphas:tensor([0.5400, 0.1548, 0.1037, 0.0997, 0.1019], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,303 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,303 - train - INFO - True
2024-04-06 21:13:41,304 - train - INFO - alphas:tensor([0.3875, 0.2079, 0.1212, 0.1384, 0.1449], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,342 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,343 - train - INFO - True
2024-04-06 21:13:41,343 - train - INFO - alphas:tensor([0.4451, 0.1926, 0.1162, 0.1218, 0.1242], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,377 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,377 - train - INFO - True
2024-04-06 21:13:41,378 - train - INFO - alphas:tensor([0.5529, 0.1532, 0.0947, 0.0986, 0.1007], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,408 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,408 - train - INFO - True
2024-04-06 21:13:41,409 - train - INFO - alphas:tensor([0.5128, 0.1629, 0.1042, 0.1102, 0.1100], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,439 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,439 - train - INFO - True
2024-04-06 21:13:41,440 - train - INFO - alphas:tensor([0.3777, 0.2118, 0.1241, 0.1393, 0.1470], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,474 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,474 - train - INFO - True
2024-04-06 21:13:41,475 - train - INFO - alphas:tensor([0.3961, 0.2199, 0.1247, 0.1287, 0.1305], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,510 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,510 - train - INFO - True
2024-04-06 21:13:41,511 - train - INFO - alphas:tensor([0.5184, 0.1581, 0.1011, 0.1084, 0.1139], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,542 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,543 - train - INFO - True
2024-04-06 21:13:41,543 - train - INFO - alphas:tensor([0.4645, 0.1877, 0.1112, 0.1171, 0.1195], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,573 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,573 - train - INFO - True
2024-04-06 21:13:41,574 - train - INFO - alphas:tensor([0.5264, 0.2211, 0.2525], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 21:13:41,578 - train - INFO - tau:0.8953382542587163
2024-04-06 21:13:41,579 - train - INFO - avg block size:1.0
2024-04-06 21:13:41,579 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 21:13:41,828 - train - INFO - Test: [   0/39]  Time: 0.247 (0.247)  Loss:  1.1045 (1.1045)  Acc@1: 73.0469 (73.0469)  Acc@5: 94.1406 (94.1406)
2024-04-06 21:13:45,379 - train - INFO - Test: [  39/39]  Time: 0.045 (0.095)  Loss:  0.9893 (1.1573)  Acc@1: 81.2500 (70.3900)  Acc@5: 87.5000 (92.0900)
2024-04-06 21:13:46,852 - train - INFO - Train: 14 [   0/195 (  0%)]  Loss:  2.415440 (2.4154)  Time: 1.394s,  183.60/s  (1.394s,  183.60/s)  LR: 5.385e-04  Data: 0.198 (0.198)
2024-04-06 21:14:38,143 - train - INFO - Train: 14 [  50/195 ( 26%)]  Loss:  2.282787 (2.8748)  Time: 1.160s,  220.73/s  (1.033s,  247.82/s)  LR: 5.385e-04  Data: 0.007 (0.015)
2024-04-06 21:15:30,617 - train - INFO - Train: 14 [ 100/195 ( 52%)]  Loss:  3.333006 (2.8667)  Time: 0.881s,  290.70/s  (1.041s,  245.88/s)  LR: 5.385e-04  Data: 0.008 (0.012)
2024-04-06 21:16:23,127 - train - INFO - Train: 14 [ 150/195 ( 77%)]  Loss:  3.067064 (2.9136)  Time: 0.913s,  280.48/s  (1.044s,  245.18/s)  LR: 5.385e-04  Data: 0.012 (0.012)
2024-04-06 21:17:08,725 - train - INFO - Train: 14 [ 194/195 (100%)]  Loss:  3.102899 (2.9235)  Time: 1.198s,  213.63/s  (1.042s,  245.60/s)  LR: 5.385e-04  Data: 0.000 (0.011)
2024-04-06 21:17:08,725 - train - INFO - True
2024-04-06 21:17:08,729 - train - INFO - alphas:tensor([0.2585, 0.2234, 0.1637, 0.1752, 0.1792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:08,802 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:08,802 - train - INFO - True
2024-04-06 21:17:08,804 - train - INFO - alphas:tensor([0.2986, 0.1950, 0.1484, 0.1710, 0.1869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:08,856 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:08,856 - train - INFO - True
2024-04-06 21:17:08,858 - train - INFO - alphas:tensor([0.4406, 0.2113, 0.1072, 0.1178, 0.1232], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:08,900 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:08,900 - train - INFO - True
2024-04-06 21:17:08,902 - train - INFO - alphas:tensor([0.4709, 0.1744, 0.1102, 0.1190, 0.1255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:08,940 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:08,940 - train - INFO - True
2024-04-06 21:17:08,942 - train - INFO - alphas:tensor([0.3568, 0.2149, 0.1326, 0.1449, 0.1508], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:08,976 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:08,976 - train - INFO - True
2024-04-06 21:17:08,977 - train - INFO - alphas:tensor([0.4340, 0.1901, 0.1195, 0.1258, 0.1306], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,010 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,010 - train - INFO - True
2024-04-06 21:17:09,013 - train - INFO - alphas:tensor([0.5116, 0.1750, 0.0979, 0.1052, 0.1102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,045 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,045 - train - INFO - True
2024-04-06 21:17:09,046 - train - INFO - alphas:tensor([0.5109, 0.1787, 0.1015, 0.1025, 0.1064], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,084 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,084 - train - INFO - True
2024-04-06 21:17:09,086 - train - INFO - alphas:tensor([0.4079, 0.1954, 0.1204, 0.1345, 0.1418], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,119 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,119 - train - INFO - True
2024-04-06 21:17:09,120 - train - INFO - alphas:tensor([0.4928, 0.1681, 0.1067, 0.1141, 0.1183], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,151 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,151 - train - INFO - True
2024-04-06 21:17:09,152 - train - INFO - alphas:tensor([0.5328, 0.1646, 0.0945, 0.1027, 0.1054], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,182 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,182 - train - INFO - True
2024-04-06 21:17:09,182 - train - INFO - alphas:tensor([0.5185, 0.1718, 0.1026, 0.1027, 0.1044], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,219 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,219 - train - INFO - True
2024-04-06 21:17:09,219 - train - INFO - alphas:tensor([0.4202, 0.1955, 0.1146, 0.1305, 0.1392], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,257 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,257 - train - INFO - True
2024-04-06 21:17:09,258 - train - INFO - alphas:tensor([0.5009, 0.1660, 0.1058, 0.1117, 0.1156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,293 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,293 - train - INFO - True
2024-04-06 21:17:09,294 - train - INFO - alphas:tensor([0.5604, 0.1564, 0.0901, 0.0956, 0.0975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,326 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,326 - train - INFO - True
2024-04-06 21:17:09,327 - train - INFO - alphas:tensor([0.5401, 0.1614, 0.1005, 0.0980, 0.1001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,363 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,363 - train - INFO - True
2024-04-06 21:17:09,364 - train - INFO - alphas:tensor([0.4086, 0.1981, 0.1163, 0.1338, 0.1431], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,398 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,398 - train - INFO - True
2024-04-06 21:17:09,399 - train - INFO - alphas:tensor([0.4876, 0.1699, 0.1075, 0.1149, 0.1202], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,430 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,430 - train - INFO - True
2024-04-06 21:17:09,431 - train - INFO - alphas:tensor([0.5955, 0.1388, 0.0867, 0.0883, 0.0907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,461 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,461 - train - INFO - True
2024-04-06 21:17:09,462 - train - INFO - alphas:tensor([0.5667, 0.1447, 0.0976, 0.0943, 0.0968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,495 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,496 - train - INFO - True
2024-04-06 21:17:09,497 - train - INFO - alphas:tensor([0.4010, 0.2009, 0.1181, 0.1364, 0.1436], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,532 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,532 - train - INFO - True
2024-04-06 21:17:09,533 - train - INFO - alphas:tensor([0.4650, 0.1841, 0.1120, 0.1182, 0.1208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,565 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,565 - train - INFO - True
2024-04-06 21:17:09,566 - train - INFO - alphas:tensor([0.5771, 0.1420, 0.0900, 0.0942, 0.0967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,596 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,596 - train - INFO - True
2024-04-06 21:17:09,598 - train - INFO - alphas:tensor([0.5364, 0.1531, 0.0991, 0.1057, 0.1057], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,628 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,628 - train - INFO - True
2024-04-06 21:17:09,629 - train - INFO - alphas:tensor([0.3898, 0.2035, 0.1217, 0.1382, 0.1468], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,666 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,666 - train - INFO - True
2024-04-06 21:17:09,668 - train - INFO - alphas:tensor([0.4136, 0.2127, 0.1208, 0.1254, 0.1275], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,701 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,701 - train - INFO - True
2024-04-06 21:17:09,702 - train - INFO - alphas:tensor([0.5407, 0.1481, 0.0967, 0.1044, 0.1101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,732 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,732 - train - INFO - True
2024-04-06 21:17:09,733 - train - INFO - alphas:tensor([0.4868, 0.1774, 0.1067, 0.1132, 0.1159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,763 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,763 - train - INFO - True
2024-04-06 21:17:09,764 - train - INFO - alphas:tensor([0.5354, 0.2156, 0.2489], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 21:17:09,768 - train - INFO - tau:0.8863848717161291
2024-04-06 21:17:09,769 - train - INFO - avg block size:1.0
2024-04-06 21:17:09,769 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 21:17:09,769 - train - INFO - lasso_alpha:6.20921323059155e-06
2024-04-06 21:17:10,096 - train - INFO - Test: [   0/39]  Time: 0.325 (0.325)  Loss:  1.0771 (1.0771)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.3594 (93.3594)
2024-04-06 21:17:13,942 - train - INFO - Test: [  39/39]  Time: 0.134 (0.104)  Loss:  0.7642 (1.1377)  Acc@1: 81.2500 (70.8900)  Acc@5: 93.7500 (92.0800)
2024-04-06 21:17:15,341 - train - INFO - Train: 15 [   0/195 (  0%)]  Loss:  2.858928 (2.8589)  Time: 1.322s,  193.69/s  (1.322s,  193.69/s)  LR: 5.368e-04  Data: 0.196 (0.196)
2024-04-06 21:18:07,922 - train - INFO - Train: 15 [  50/195 ( 26%)]  Loss:  2.221515 (2.9751)  Time: 1.007s,  254.31/s  (1.057s,  242.22/s)  LR: 5.368e-04  Data: 0.011 (0.014)
2024-04-06 21:18:59,331 - train - INFO - Train: 15 [ 100/195 ( 52%)]  Loss:  2.517628 (2.9521)  Time: 0.888s,  288.37/s  (1.043s,  245.53/s)  LR: 5.368e-04  Data: 0.006 (0.012)
2024-04-06 21:19:51,897 - train - INFO - Train: 15 [ 150/195 ( 77%)]  Loss:  3.279201 (2.9157)  Time: 1.128s,  226.88/s  (1.046s,  244.86/s)  LR: 5.368e-04  Data: 0.010 (0.012)
2024-04-06 21:20:38,768 - train - INFO - Train: 15 [ 194/195 (100%)]  Loss:  3.130829 (2.9227)  Time: 0.918s,  278.79/s  (1.050s,  243.82/s)  LR: 5.368e-04  Data: 0.000 (0.012)
2024-04-06 21:20:38,770 - train - INFO - True
2024-04-06 21:20:38,773 - train - INFO - alphas:tensor([0.2591, 0.2221, 0.1635, 0.1755, 0.1798], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:38,849 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:38,849 - train - INFO - True
2024-04-06 21:20:38,852 - train - INFO - alphas:tensor([0.3038, 0.1920, 0.1462, 0.1704, 0.1875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:38,905 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:38,905 - train - INFO - True
2024-04-06 21:20:38,906 - train - INFO - alphas:tensor([0.4549, 0.2038, 0.1045, 0.1155, 0.1214], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:38,949 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:38,950 - train - INFO - True
2024-04-06 21:20:38,950 - train - INFO - alphas:tensor([0.4859, 0.1669, 0.1072, 0.1165, 0.1235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:38,988 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:38,988 - train - INFO - True
2024-04-06 21:20:38,989 - train - INFO - alphas:tensor([0.3650, 0.2106, 0.1307, 0.1437, 0.1500], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,022 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,022 - train - INFO - True
2024-04-06 21:20:39,023 - train - INFO - alphas:tensor([0.4481, 0.1846, 0.1163, 0.1231, 0.1279], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,054 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,054 - train - INFO - True
2024-04-06 21:20:39,055 - train - INFO - alphas:tensor([0.5331, 0.1652, 0.0936, 0.1015, 0.1067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,085 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,085 - train - INFO - True
2024-04-06 21:20:39,086 - train - INFO - alphas:tensor([0.5321, 0.1701, 0.0970, 0.0984, 0.1025], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,118 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,118 - train - INFO - True
2024-04-06 21:20:39,119 - train - INFO - alphas:tensor([0.4168, 0.1895, 0.1188, 0.1334, 0.1416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,154 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,154 - train - INFO - True
2024-04-06 21:20:39,168 - train - INFO - alphas:tensor([0.5058, 0.1628, 0.1038, 0.1116, 0.1160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,199 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,199 - train - INFO - True
2024-04-06 21:20:39,200 - train - INFO - alphas:tensor([0.5546, 0.1548, 0.0904, 0.0987, 0.1016], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,230 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,230 - train - INFO - True
2024-04-06 21:20:39,232 - train - INFO - alphas:tensor([0.5407, 0.1629, 0.0978, 0.0984, 0.1002], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,266 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,266 - train - INFO - True
2024-04-06 21:20:39,279 - train - INFO - alphas:tensor([0.4309, 0.1886, 0.1124, 0.1293, 0.1388], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,312 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,312 - train - INFO - True
2024-04-06 21:20:39,317 - train - INFO - alphas:tensor([0.5180, 0.1596, 0.1019, 0.1082, 0.1124], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,347 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,347 - train - INFO - True
2024-04-06 21:20:39,348 - train - INFO - alphas:tensor([0.5822, 0.1471, 0.0857, 0.0914, 0.0936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,378 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,378 - train - INFO - True
2024-04-06 21:20:39,380 - train - INFO - alphas:tensor([0.5633, 0.1526, 0.0953, 0.0932, 0.0956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,414 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,414 - train - INFO - True
2024-04-06 21:20:39,426 - train - INFO - alphas:tensor([0.4204, 0.1913, 0.1137, 0.1323, 0.1423], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,463 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,463 - train - INFO - True
2024-04-06 21:20:39,464 - train - INFO - alphas:tensor([0.5042, 0.1632, 0.1037, 0.1117, 0.1173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,494 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,494 - train - INFO - True
2024-04-06 21:20:39,495 - train - INFO - alphas:tensor([0.6168, 0.1300, 0.0821, 0.0843, 0.0868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,526 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,526 - train - INFO - True
2024-04-06 21:20:39,527 - train - INFO - alphas:tensor([0.5901, 0.1357, 0.0923, 0.0896, 0.0923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,563 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,563 - train - INFO - True
2024-04-06 21:20:39,564 - train - INFO - alphas:tensor([0.4119, 0.1945, 0.1157, 0.1351, 0.1427], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,596 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,596 - train - INFO - True
2024-04-06 21:20:39,597 - train - INFO - alphas:tensor([0.4840, 0.1760, 0.1079, 0.1146, 0.1175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,627 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,627 - train - INFO - True
2024-04-06 21:20:39,628 - train - INFO - alphas:tensor([0.5992, 0.1326, 0.0853, 0.0901, 0.0929], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,658 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,658 - train - INFO - True
2024-04-06 21:20:39,672 - train - INFO - alphas:tensor([0.5575, 0.1446, 0.0947, 0.1015, 0.1017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,708 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,708 - train - INFO - True
2024-04-06 21:20:39,709 - train - INFO - alphas:tensor([0.3999, 0.1967, 0.1197, 0.1372, 0.1465], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,741 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,742 - train - INFO - True
2024-04-06 21:20:39,743 - train - INFO - alphas:tensor([0.4289, 0.2063, 0.1175, 0.1225, 0.1247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,773 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,773 - train - INFO - True
2024-04-06 21:20:39,785 - train - INFO - alphas:tensor([0.5606, 0.1393, 0.0929, 0.1006, 0.1067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,817 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,817 - train - INFO - True
2024-04-06 21:20:39,819 - train - INFO - alphas:tensor([0.5080, 0.1674, 0.1027, 0.1095, 0.1124], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,855 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,855 - train - INFO - True
2024-04-06 21:20:39,857 - train - INFO - alphas:tensor([0.5433, 0.2108, 0.2459], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 21:20:39,862 - train - INFO - tau:0.8775210229989678
2024-04-06 21:20:39,862 - train - INFO - avg block size:1.0
2024-04-06 21:20:39,863 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 21:20:40,053 - train - INFO - Test: [   0/39]  Time: 0.187 (0.187)  Loss:  1.1055 (1.1055)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.5781 (92.5781)
2024-04-06 21:20:43,956 - train - INFO - Test: [  39/39]  Time: 0.100 (0.102)  Loss:  0.8491 (1.1725)  Acc@1: 81.2500 (70.1900)  Acc@5: 87.5000 (91.8700)
2024-04-06 21:20:45,412 - train - INFO - Train: 16 [   0/195 (  0%)]  Loss:  3.457612 (3.4576)  Time: 1.372s,  186.54/s  (1.372s,  186.54/s)  LR: 5.350e-04  Data: 0.180 (0.180)
2024-04-06 21:21:37,350 - train - INFO - Train: 16 [  50/195 ( 26%)]  Loss:  3.437471 (2.9811)  Time: 0.931s,  274.93/s  (1.045s,  244.92/s)  LR: 5.350e-04  Data: 0.007 (0.014)
2024-04-06 21:22:28,260 - train - INFO - Train: 16 [ 100/195 ( 52%)]  Loss:  2.346392 (2.9243)  Time: 0.886s,  289.04/s  (1.032s,  248.10/s)  LR: 5.350e-04  Data: 0.012 (0.013)
2024-04-06 21:23:20,610 - train - INFO - Train: 16 [ 150/195 ( 77%)]  Loss:  2.200504 (2.9243)  Time: 1.189s,  215.31/s  (1.037s,  246.90/s)  LR: 5.350e-04  Data: 0.020 (0.012)
2024-04-06 21:24:07,106 - train - INFO - Train: 16 [ 194/195 (100%)]  Loss:  2.723849 (2.9230)  Time: 0.908s,  281.89/s  (1.041s,  245.84/s)  LR: 5.350e-04  Data: 0.000 (0.012)
2024-04-06 21:24:07,107 - train - INFO - True
2024-04-06 21:24:07,112 - train - INFO - alphas:tensor([0.2592, 0.2208, 0.1635, 0.1760, 0.1805], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,158 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,159 - train - INFO - True
2024-04-06 21:24:07,160 - train - INFO - alphas:tensor([0.3084, 0.1889, 0.1443, 0.1700, 0.1884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,204 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,205 - train - INFO - True
2024-04-06 21:24:07,211 - train - INFO - alphas:tensor([0.4703, 0.1970, 0.1013, 0.1126, 0.1188], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,248 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,248 - train - INFO - True
2024-04-06 21:24:07,261 - train - INFO - alphas:tensor([0.5016, 0.1606, 0.1036, 0.1135, 0.1207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,293 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,293 - train - INFO - True
2024-04-06 21:24:07,294 - train - INFO - alphas:tensor([0.3695, 0.2066, 0.1298, 0.1437, 0.1505], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,324 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,324 - train - INFO - True
2024-04-06 21:24:07,325 - train - INFO - alphas:tensor([0.4592, 0.1799, 0.1139, 0.1209, 0.1261], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,359 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,359 - train - INFO - True
2024-04-06 21:24:07,360 - train - INFO - alphas:tensor([0.5515, 0.1572, 0.0899, 0.0980, 0.1034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,395 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,395 - train - INFO - True
2024-04-06 21:24:07,396 - train - INFO - alphas:tensor([0.5523, 0.1616, 0.0927, 0.0945, 0.0988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,427 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,427 - train - INFO - True
2024-04-06 21:24:07,428 - train - INFO - alphas:tensor([0.4255, 0.1833, 0.1171, 0.1327, 0.1414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,458 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,458 - train - INFO - True
2024-04-06 21:24:07,459 - train - INFO - alphas:tensor([0.5208, 0.1561, 0.1009, 0.1089, 0.1133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,492 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,492 - train - INFO - True
2024-04-06 21:24:07,506 - train - INFO - alphas:tensor([0.5746, 0.1463, 0.0864, 0.0948, 0.0979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,540 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,540 - train - INFO - True
2024-04-06 21:24:07,543 - train - INFO - alphas:tensor([0.5625, 0.1542, 0.0932, 0.0941, 0.0961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,575 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,575 - train - INFO - True
2024-04-06 21:24:07,576 - train - INFO - alphas:tensor([0.4401, 0.1823, 0.1107, 0.1284, 0.1386], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,606 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,606 - train - INFO - True
2024-04-06 21:24:07,607 - train - INFO - alphas:tensor([0.5329, 0.1540, 0.0984, 0.1052, 0.1095], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,645 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,645 - train - INFO - True
2024-04-06 21:24:07,646 - train - INFO - alphas:tensor([0.6020, 0.1387, 0.0818, 0.0876, 0.0899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,679 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,680 - train - INFO - True
2024-04-06 21:24:07,681 - train - INFO - alphas:tensor([0.5862, 0.1441, 0.0901, 0.0885, 0.0911], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,713 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,713 - train - INFO - True
2024-04-06 21:24:07,714 - train - INFO - alphas:tensor([0.4302, 0.1851, 0.1116, 0.1312, 0.1420], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,744 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,744 - train - INFO - True
2024-04-06 21:24:07,746 - train - INFO - alphas:tensor([0.5205, 0.1561, 0.1004, 0.1085, 0.1145], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,779 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,779 - train - INFO - True
2024-04-06 21:24:07,780 - train - INFO - alphas:tensor([0.6351, 0.1222, 0.0785, 0.0808, 0.0834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,816 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,816 - train - INFO - True
2024-04-06 21:24:07,817 - train - INFO - alphas:tensor([0.6105, 0.1282, 0.0875, 0.0854, 0.0884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,850 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,850 - train - INFO - True
2024-04-06 21:24:07,850 - train - INFO - alphas:tensor([0.4235, 0.1880, 0.1135, 0.1333, 0.1417], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,880 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,881 - train - INFO - True
2024-04-06 21:24:07,881 - train - INFO - alphas:tensor([0.5015, 0.1695, 0.1040, 0.1110, 0.1141], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,918 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,918 - train - INFO - True
2024-04-06 21:24:07,919 - train - INFO - alphas:tensor([0.6161, 0.1253, 0.0818, 0.0870, 0.0899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,953 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,953 - train - INFO - True
2024-04-06 21:24:07,953 - train - INFO - alphas:tensor([0.5742, 0.1378, 0.0910, 0.0983, 0.0988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:07,984 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:07,984 - train - INFO - True
2024-04-06 21:24:07,998 - train - INFO - alphas:tensor([0.4097, 0.1900, 0.1176, 0.1364, 0.1463], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:08,048 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:08,048 - train - INFO - True
2024-04-06 21:24:08,050 - train - INFO - alphas:tensor([0.4452, 0.1989, 0.1141, 0.1197, 0.1221], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:08,100 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:08,100 - train - INFO - True
2024-04-06 21:24:08,102 - train - INFO - alphas:tensor([0.5777, 0.1318, 0.0895, 0.0974, 0.1036], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:08,152 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:08,152 - train - INFO - True
2024-04-06 21:24:08,154 - train - INFO - alphas:tensor([0.5266, 0.1586, 0.0991, 0.1063, 0.1093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:08,204 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:08,204 - train - INFO - True
2024-04-06 21:24:08,205 - train - INFO - alphas:tensor([0.5517, 0.2059, 0.2424], device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-06 21:24:08,213 - train - INFO - tau:0.8687458127689781
2024-04-06 21:24:08,213 - train - INFO - avg block size:1.0
2024-04-06 21:24:08,214 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 21:24:08,214 - train - INFO - lasso_alpha:5.644739300537772e-06
2024-04-06 21:24:08,407 - train - INFO - Test: [   0/39]  Time: 0.190 (0.190)  Loss:  1.1211 (1.1211)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
2024-04-06 21:24:12,188 - train - INFO - Test: [  39/39]  Time: 0.043 (0.099)  Loss:  0.9458 (1.1255)  Acc@1: 81.2500 (71.5100)  Acc@5: 87.5000 (92.2100)
2024-04-06 21:24:13,615 - train - INFO - Train: 17 [   0/195 (  0%)]  Loss:  3.190428 (3.1904)  Time: 1.350s,  189.68/s  (1.350s,  189.68/s)  LR: 5.331e-04  Data: 0.175 (0.175)
2024-04-06 21:25:06,823 - train - INFO - Train: 17 [  50/195 ( 26%)]  Loss:  3.314216 (2.9355)  Time: 1.147s,  223.24/s  (1.070s,  239.31/s)  LR: 5.331e-04  Data: 0.012 (0.014)
2024-04-06 21:25:55,732 - train - INFO - Train: 17 [ 100/195 ( 52%)]  Loss:  3.176590 (2.9226)  Time: 1.114s,  229.86/s  (1.024s,  249.90/s)  LR: 5.331e-04  Data: 0.012 (0.012)
