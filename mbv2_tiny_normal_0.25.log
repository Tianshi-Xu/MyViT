2024-04-06 21:27:36,903 - train - INFO - Training with a single process on 1 GPUs.
2024-04-06 21:27:40,688 - train - INFO - Model tiny_nas_mobilenetv2 created, param count:2480233
2024-04-06 21:27:40,724 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-04-06 21:27:40,724 - train - INFO - Scheduled epochs: 160
2024-04-06 21:27:41,061 - train - INFO - Verifying teacher model
2024-04-06 21:27:44,786 - train - INFO - Test: [   0/78]  Time: 3.723 (3.723)  Loss:  0.9487 (0.9487)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-06 21:27:45,705 - train - INFO - Test: [  50/78]  Time: 0.013 (0.091)  Loss:  1.5586 (1.5637)  Acc@1: 67.1875 (66.0846)  Acc@5: 88.2812 (86.4890)
2024-04-06 21:27:47,331 - train - INFO - Test: [  78/78]  Time: 1.113 (0.079)  Loss:  1.8311 (1.5830)  Acc@1: 62.5000 (65.7000)  Acc@5: 93.7500 (86.1300)
2024-04-06 21:27:47,332 - train - INFO - Verifying initial model
2024-04-06 21:27:47,588 - train - INFO - Test: [   0/78]  Time: 0.253 (0.253)  Loss:  8.7656 (8.7656)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
2024-04-06 21:27:53,393 - train - INFO - Test: [  50/78]  Time: 0.659 (0.119)  Loss:  4.4766 (6.2185)  Acc@1:  0.0000 ( 0.7659)  Acc@5: 21.8750 ( 2.7267)
2024-04-06 21:27:56,723 - train - INFO - Test: [  78/78]  Time: 0.046 (0.119)  Loss:  6.9258 (6.2003)  Acc@1:  0.0000 ( 0.5000)  Acc@5:  0.0000 ( 2.5000)
2024-04-06 21:27:59,371 - train - INFO - Train: 0 [   0/781 (  0%)]  Loss:  5.102114 (5.1021)  Time: 2.644s,   48.41/s  (2.644s,   48.41/s)  LR: 1.000e-05  Data: 0.423 (0.423)
2024-04-06 21:28:22,303 - train - INFO - Train: 0 [  50/781 (  6%)]  Loss:  4.947930 (5.0130)  Time: 0.476s,  268.88/s  (0.501s,  255.26/s)  LR: 1.000e-05  Data: 0.010 (0.016)
2024-04-06 21:28:46,163 - train - INFO - Train: 0 [ 100/781 ( 13%)]  Loss:  4.971087 (4.9612)  Time: 0.475s,  269.37/s  (0.489s,  261.53/s)  LR: 1.000e-05  Data: 0.005 (0.012)
2024-04-06 21:29:09,870 - train - INFO - Train: 0 [ 150/781 ( 19%)]  Loss:  4.365621 (4.8892)  Time: 0.467s,  274.17/s  (0.484s,  264.27/s)  LR: 1.000e-05  Data: 0.006 (0.010)
2024-04-06 21:29:34,006 - train - INFO - Train: 0 [ 200/781 ( 26%)]  Loss:  4.735596 (4.8340)  Time: 0.406s,  315.51/s  (0.484s,  264.50/s)  LR: 1.000e-05  Data: 0.005 (0.010)
2024-04-06 21:29:56,844 - train - INFO - Train: 0 [ 250/781 ( 32%)]  Loss:  4.764774 (4.7961)  Time: 0.507s,  252.59/s  (0.479s,  267.49/s)  LR: 1.000e-05  Data: 0.005 (0.009)
2024-04-06 21:30:20,241 - train - INFO - Train: 0 [ 300/781 ( 38%)]  Loss:  4.588773 (4.7642)  Time: 0.476s,  268.86/s  (0.477s,  268.48/s)  LR: 1.000e-05  Data: 0.008 (0.009)
2024-04-06 21:30:43,369 - train - INFO - Train: 0 [ 350/781 ( 45%)]  Loss:  4.288230 (4.7312)  Time: 0.497s,  257.70/s  (0.475s,  269.63/s)  LR: 1.000e-05  Data: 0.009 (0.009)
2024-04-06 21:31:06,642 - train - INFO - Train: 0 [ 400/781 ( 51%)]  Loss:  4.240252 (4.6968)  Time: 0.491s,  260.61/s  (0.474s,  270.29/s)  LR: 1.000e-05  Data: 0.009 (0.009)
2024-04-06 21:31:30,240 - train - INFO - Train: 0 [ 450/781 ( 58%)]  Loss:  4.614221 (4.6699)  Time: 0.490s,  261.24/s  (0.473s,  270.39/s)  LR: 1.000e-05  Data: 0.009 (0.009)
2024-04-06 21:31:53,950 - train - INFO - Train: 0 [ 500/781 ( 64%)]  Loss:  4.669311 (4.6436)  Time: 0.511s,  250.50/s  (0.473s,  270.35/s)  LR: 1.000e-05  Data: 0.011 (0.009)
2024-04-06 21:32:18,361 - train - INFO - Train: 0 [ 550/781 ( 71%)]  Loss:  4.252296 (4.6152)  Time: 0.465s,  275.32/s  (0.475s,  269.59/s)  LR: 1.000e-05  Data: 0.006 (0.009)
2024-04-06 21:32:42,521 - train - INFO - Train: 0 [ 600/781 ( 77%)]  Loss:  4.433740 (4.5951)  Time: 0.520s,  246.09/s  (0.475s,  269.19/s)  LR: 1.000e-05  Data: 0.009 (0.009)
2024-04-06 21:33:06,220 - train - INFO - Train: 0 [ 650/781 ( 83%)]  Loss:  4.272556 (4.5726)  Time: 0.465s,  275.41/s  (0.475s,  269.26/s)  LR: 1.000e-05  Data: 0.005 (0.009)
2024-04-06 21:33:30,090 - train - INFO - Train: 0 [ 700/781 ( 90%)]  Loss:  3.996167 (4.5530)  Time: 0.496s,  258.17/s  (0.476s,  269.18/s)  LR: 1.000e-05  Data: 0.008 (0.009)
2024-04-06 21:33:53,196 - train - INFO - Train: 0 [ 750/781 ( 96%)]  Loss:  4.540871 (4.5314)  Time: 0.395s,  323.92/s  (0.475s,  269.69/s)  LR: 1.000e-05  Data: 0.006 (0.009)
2024-04-06 21:34:06,574 - train - INFO - Train: 0 [ 780/781 (100%)]  Loss:  3.870868 (4.5217)  Time: 0.480s,  266.77/s  (0.474s,  270.31/s)  LR: 1.000e-05  Data: 0.000 (0.009)
2024-04-06 21:34:06,575 - train - INFO - True
2024-04-06 21:34:06,581 - train - INFO - alphas:tensor([0.2017, 0.1996, 0.1995, 0.1996, 0.1996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,582 - train - INFO - True
2024-04-06 21:34:06,584 - train - INFO - alphas:tensor([0.2016, 0.2001, 0.1993, 0.1994, 0.1996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,585 - train - INFO - True
2024-04-06 21:34:06,586 - train - INFO - alphas:tensor([0.2520, 0.2495, 0.2492, 0.2493], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,587 - train - INFO - True
2024-04-06 21:34:06,589 - train - INFO - alphas:tensor([0.2518, 0.2496, 0.2491, 0.2495], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,590 - train - INFO - True
2024-04-06 21:34:06,591 - train - INFO - alphas:tensor([0.2519, 0.2496, 0.2493, 0.2493], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,593 - train - INFO - True
2024-04-06 21:34:06,594 - train - INFO - alphas:tensor([0.2520, 0.2495, 0.2493, 0.2492], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,595 - train - INFO - True
2024-04-06 21:34:06,597 - train - INFO - alphas:tensor([0.2016, 0.2001, 0.1993, 0.1994, 0.1996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,598 - train - INFO - True
2024-04-06 21:34:06,600 - train - INFO - alphas:tensor([0.2010, 0.2000, 0.1995, 0.1995, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,601 - train - INFO - True
2024-04-06 21:34:06,603 - train - INFO - alphas:tensor([0.2013, 0.2001, 0.1995, 0.1995, 0.1996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,605 - train - INFO - True
2024-04-06 21:34:06,606 - train - INFO - alphas:tensor([0.2011, 0.1996, 0.1995, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,607 - train - INFO - True
2024-04-06 21:34:06,609 - train - INFO - alphas:tensor([0.2012, 0.1998, 0.1997, 0.1996, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,610 - train - INFO - True
2024-04-06 21:34:06,612 - train - INFO - alphas:tensor([0.2019, 0.1997, 0.1994, 0.1995, 0.1995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,613 - train - INFO - True
2024-04-06 21:34:06,615 - train - INFO - alphas:tensor([0.2019, 0.1999, 0.1993, 0.1994, 0.1995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,619 - train - INFO - True
2024-04-06 21:34:06,621 - train - INFO - alphas:tensor([0.2008, 0.1999, 0.1996, 0.1997, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,625 - train - INFO - True
2024-04-06 21:34:06,626 - train - INFO - alphas:tensor([0.2013, 0.2000, 0.1995, 0.1995, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,631 - train - INFO - True
2024-04-06 21:34:06,632 - train - INFO - alphas:tensor([0.2009, 0.1998, 0.1996, 0.1998, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,637 - train - INFO - True
2024-04-06 21:34:06,638 - train - INFO - alphas:tensor([0.2010, 0.2001, 0.1994, 0.1997, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,642 - train - INFO - True
2024-04-06 21:34:06,643 - train - INFO - alphas:tensor([0.2010, 0.1996, 0.1997, 0.1998, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,647 - train - INFO - True
2024-04-06 21:34:06,649 - train - INFO - alphas:tensor([0.2009, 0.1997, 0.1995, 0.1997, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,653 - train - INFO - True
2024-04-06 21:34:06,654 - train - INFO - alphas:tensor([0.2021, 0.1997, 0.1993, 0.1993, 0.1996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,658 - train - INFO - True
2024-04-06 21:34:06,659 - train - INFO - alphas:tensor([0.2020, 0.1999, 0.1994, 0.1993, 0.1994], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,667 - train - INFO - True
2024-04-06 21:34:06,668 - train - INFO - alphas:tensor([0.2017, 0.1998, 0.1995, 0.1994, 0.1996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,676 - train - INFO - True
2024-04-06 21:34:06,677 - train - INFO - alphas:tensor([0.2018, 0.1997, 0.1994, 0.1994, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,684 - train - INFO - True
2024-04-06 21:34:06,685 - train - INFO - alphas:tensor([0.2018, 0.1997, 0.1994, 0.1994, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,692 - train - INFO - True
2024-04-06 21:34:06,693 - train - INFO - alphas:tensor([0.2017, 0.1998, 0.1993, 0.1995, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,701 - train - INFO - True
2024-04-06 21:34:06,702 - train - INFO - alphas:tensor([0.2023, 0.1997, 0.1993, 0.1993, 0.1994], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,709 - train - INFO - True
2024-04-06 21:34:06,710 - train - INFO - alphas:tensor([0.2023, 0.1996, 0.1993, 0.1994, 0.1994], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,729 - train - INFO - True
2024-04-06 21:34:06,730 - train - INFO - alphas:tensor([0.2018, 0.1996, 0.1993, 0.1995, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,750 - train - INFO - True
2024-04-06 21:34:06,751 - train - INFO - alphas:tensor([0.2019, 0.1997, 0.1994, 0.1994, 0.1996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,771 - train - INFO - True
2024-04-06 21:34:06,772 - train - INFO - alphas:tensor([0.2018, 0.1997, 0.1992, 0.1994, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,792 - train - INFO - True
2024-04-06 21:34:06,793 - train - INFO - alphas:tensor([0.2016, 0.1995, 0.1995, 0.1996, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,812 - train - INFO - True
2024-04-06 21:34:06,813 - train - INFO - alphas:tensor([0.2024, 0.1995, 0.1993, 0.1994, 0.1994], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,833 - train - INFO - True
2024-04-06 21:34:06,834 - train - INFO - alphas:tensor([0.2024, 0.1996, 0.1993, 0.1993, 0.1994], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:34:06,911 - train - INFO - avg block size:1.0
2024-04-06 21:34:06,912 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 21:34:07,217 - train - INFO - Test: [   0/78]  Time: 0.302 (0.302)  Loss:  1.4990 (1.4990)  Acc@1: 71.8750 (71.8750)  Acc@5: 89.8438 (89.8438)
2024-04-06 21:34:10,586 - train - INFO - Test: [  50/78]  Time: 0.053 (0.072)  Loss:  2.0977 (2.2789)  Acc@1: 51.5625 (48.1924)  Acc@5: 78.1250 (74.6477)
2024-04-06 21:34:12,644 - train - INFO - Test: [  78/78]  Time: 0.049 (0.073)  Loss:  2.1602 (2.2815)  Acc@1: 50.0000 (48.5000)  Acc@5: 81.2500 (74.6800)
2024-04-06 21:34:13,395 - train - INFO - Train: 1 [   0/781 (  0%)]  Loss:  3.862975 (3.8630)  Time: 0.593s,  215.96/s  (0.593s,  215.96/s)  LR: 5.900e-05  Data: 0.176 (0.176)
2024-04-06 21:34:36,210 - train - INFO - Train: 1 [  50/781 (  6%)]  Loss:  4.147385 (4.2092)  Time: 0.429s,  298.61/s  (0.459s,  278.90/s)  LR: 5.900e-05  Data: 0.008 (0.011)
2024-04-06 21:34:58,767 - train - INFO - Train: 1 [ 100/781 ( 13%)]  Loss:  3.805837 (4.1694)  Time: 0.392s,  326.93/s  (0.455s,  281.28/s)  LR: 5.900e-05  Data: 0.006 (0.009)
2024-04-06 21:35:22,031 - train - INFO - Train: 1 [ 150/781 ( 19%)]  Loss:  4.169609 (4.1639)  Time: 0.535s,  239.05/s  (0.458s,  279.21/s)  LR: 5.900e-05  Data: 0.008 (0.009)
2024-04-06 21:35:45,650 - train - INFO - Train: 1 [ 200/781 ( 26%)]  Loss:  3.724601 (4.1447)  Time: 0.513s,  249.36/s  (0.462s,  277.12/s)  LR: 5.900e-05  Data: 0.009 (0.008)
2024-04-06 21:36:09,188 - train - INFO - Train: 1 [ 250/781 ( 32%)]  Loss:  4.094087 (4.1357)  Time: 0.517s,  247.78/s  (0.464s,  276.07/s)  LR: 5.900e-05  Data: 0.008 (0.008)
2024-04-06 21:36:33,350 - train - INFO - Train: 1 [ 300/781 ( 38%)]  Loss:  4.145173 (4.1151)  Time: 0.455s,  281.35/s  (0.467s,  274.15/s)  LR: 5.900e-05  Data: 0.007 (0.008)
2024-04-06 21:36:56,040 - train - INFO - Train: 1 [ 350/781 ( 45%)]  Loss:  4.268988 (4.0984)  Time: 0.487s,  262.86/s  (0.465s,  275.25/s)  LR: 5.900e-05  Data: 0.009 (0.008)
2024-04-06 21:37:19,653 - train - INFO - Train: 1 [ 400/781 ( 51%)]  Loss:  4.361489 (4.0836)  Time: 0.471s,  272.00/s  (0.466s,  274.72/s)  LR: 5.900e-05  Data: 0.007 (0.008)
2024-04-06 21:37:43,228 - train - INFO - Train: 1 [ 450/781 ( 58%)]  Loss:  3.823817 (4.0699)  Time: 0.491s,  260.56/s  (0.467s,  274.36/s)  LR: 5.900e-05  Data: 0.009 (0.008)
2024-04-06 21:38:07,412 - train - INFO - Train: 1 [ 500/781 ( 64%)]  Loss:  4.211586 (4.0562)  Time: 0.479s,  267.01/s  (0.468s,  273.36/s)  LR: 5.900e-05  Data: 0.008 (0.008)
2024-04-06 21:38:31,591 - train - INFO - Train: 1 [ 550/781 ( 71%)]  Loss:  4.314222 (4.0495)  Time: 0.476s,  268.91/s  (0.470s,  272.55/s)  LR: 5.900e-05  Data: 0.008 (0.008)
2024-04-06 21:38:55,084 - train - INFO - Train: 1 [ 600/781 ( 77%)]  Loss:  3.889745 (4.0399)  Time: 0.466s,  274.86/s  (0.470s,  272.54/s)  LR: 5.900e-05  Data: 0.008 (0.008)
2024-04-06 21:39:18,992 - train - INFO - Train: 1 [ 650/781 ( 83%)]  Loss:  3.754151 (4.0283)  Time: 0.382s,  334.72/s  (0.470s,  272.16/s)  LR: 5.900e-05  Data: 0.005 (0.008)
2024-04-06 21:39:43,869 - train - INFO - Train: 1 [ 700/781 ( 90%)]  Loss:  4.212239 (4.0212)  Time: 0.504s,  254.15/s  (0.472s,  271.05/s)  LR: 5.900e-05  Data: 0.006 (0.008)
2024-04-06 21:40:07,849 - train - INFO - Train: 1 [ 750/781 ( 96%)]  Loss:  4.030739 (4.0169)  Time: 0.459s,  278.78/s  (0.473s,  270.77/s)  LR: 5.900e-05  Data: 0.018 (0.008)
2024-04-06 21:40:21,364 - train - INFO - Train: 1 [ 780/781 (100%)]  Loss:  4.204127 (4.0131)  Time: 0.429s,  298.47/s  (0.472s,  271.26/s)  LR: 5.900e-05  Data: 0.000 (0.008)
2024-04-06 21:40:21,365 - train - INFO - True
2024-04-06 21:40:21,368 - train - INFO - alphas:tensor([0.2065, 0.1977, 0.1982, 0.1986, 0.1990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,369 - train - INFO - True
2024-04-06 21:40:21,370 - train - INFO - alphas:tensor([0.2078, 0.1991, 0.1972, 0.1976, 0.1983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,371 - train - INFO - True
2024-04-06 21:40:21,372 - train - INFO - alphas:tensor([0.2586, 0.2472, 0.2466, 0.2476], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,374 - train - INFO - True
2024-04-06 21:40:21,375 - train - INFO - alphas:tensor([0.2596, 0.2472, 0.2458, 0.2474], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,376 - train - INFO - True
2024-04-06 21:40:21,378 - train - INFO - alphas:tensor([0.2585, 0.2475, 0.2466, 0.2473], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,379 - train - INFO - True
2024-04-06 21:40:21,381 - train - INFO - alphas:tensor([0.2599, 0.2472, 0.2460, 0.2469], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,382 - train - INFO - True
2024-04-06 21:40:21,383 - train - INFO - alphas:tensor([0.2071, 0.1993, 0.1973, 0.1980, 0.1984], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,385 - train - INFO - True
2024-04-06 21:40:21,386 - train - INFO - alphas:tensor([0.2073, 0.1992, 0.1972, 0.1975, 0.1988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,388 - train - INFO - True
2024-04-06 21:40:21,390 - train - INFO - alphas:tensor([0.2070, 0.1988, 0.1972, 0.1978, 0.1991], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,391 - train - INFO - True
2024-04-06 21:40:21,393 - train - INFO - alphas:tensor([0.2070, 0.1975, 0.1974, 0.1985, 0.1995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,394 - train - INFO - True
2024-04-06 21:40:21,396 - train - INFO - alphas:tensor([0.2072, 0.1984, 0.1971, 0.1977, 0.1997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,397 - train - INFO - True
2024-04-06 21:40:21,399 - train - INFO - alphas:tensor([0.2095, 0.1982, 0.1970, 0.1973, 0.1980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,400 - train - INFO - True
2024-04-06 21:40:21,401 - train - INFO - alphas:tensor([0.2096, 0.1985, 0.1968, 0.1972, 0.1979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,406 - train - INFO - True
2024-04-06 21:40:21,408 - train - INFO - alphas:tensor([0.2069, 0.1988, 0.1975, 0.1978, 0.1990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,412 - train - INFO - True
2024-04-06 21:40:21,414 - train - INFO - alphas:tensor([0.2075, 0.1984, 0.1969, 0.1976, 0.1996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,418 - train - INFO - True
2024-04-06 21:40:21,419 - train - INFO - alphas:tensor([0.2079, 0.1988, 0.1968, 0.1975, 0.1990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,424 - train - INFO - True
2024-04-06 21:40:21,425 - train - INFO - alphas:tensor([0.2068, 0.1986, 0.1965, 0.1979, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,430 - train - INFO - True
2024-04-06 21:40:21,431 - train - INFO - alphas:tensor([0.2075, 0.1983, 0.1972, 0.1976, 0.1995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,435 - train - INFO - True
2024-04-06 21:40:21,436 - train - INFO - alphas:tensor([0.2066, 0.1985, 0.1970, 0.1982, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,440 - train - INFO - True
2024-04-06 21:40:21,444 - train - INFO - alphas:tensor([0.2112, 0.1980, 0.1964, 0.1969, 0.1975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,453 - train - INFO - True
2024-04-06 21:40:21,461 - train - INFO - alphas:tensor([0.2103, 0.1983, 0.1967, 0.1971, 0.1977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,469 - train - INFO - True
2024-04-06 21:40:21,470 - train - INFO - alphas:tensor([0.2099, 0.1991, 0.1962, 0.1967, 0.1981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,478 - train - INFO - True
2024-04-06 21:40:21,479 - train - INFO - alphas:tensor([0.2099, 0.1985, 0.1964, 0.1973, 0.1980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,486 - train - INFO - True
2024-04-06 21:40:21,487 - train - INFO - alphas:tensor([0.2107, 0.1984, 0.1965, 0.1965, 0.1980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,495 - train - INFO - True
2024-04-06 21:40:21,496 - train - INFO - alphas:tensor([0.2097, 0.1983, 0.1967, 0.1969, 0.1983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,503 - train - INFO - True
2024-04-06 21:40:21,504 - train - INFO - alphas:tensor([0.2120, 0.1975, 0.1967, 0.1967, 0.1971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,511 - train - INFO - True
2024-04-06 21:40:21,512 - train - INFO - alphas:tensor([0.2115, 0.1978, 0.1965, 0.1967, 0.1975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,532 - train - INFO - True
2024-04-06 21:40:21,533 - train - INFO - alphas:tensor([0.2113, 0.1976, 0.1957, 0.1966, 0.1988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,553 - train - INFO - True
2024-04-06 21:40:21,554 - train - INFO - alphas:tensor([0.2120, 0.1973, 0.1960, 0.1964, 0.1983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,574 - train - INFO - True
2024-04-06 21:40:21,575 - train - INFO - alphas:tensor([0.2132, 0.1977, 0.1954, 0.1962, 0.1975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,595 - train - INFO - True
2024-04-06 21:40:21,596 - train - INFO - alphas:tensor([0.2124, 0.1969, 0.1957, 0.1964, 0.1986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,616 - train - INFO - True
2024-04-06 21:40:21,617 - train - INFO - alphas:tensor([0.2138, 0.1969, 0.1962, 0.1965, 0.1967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,636 - train - INFO - True
2024-04-06 21:40:21,637 - train - INFO - alphas:tensor([0.2133, 0.1970, 0.1961, 0.1966, 0.1970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:40:21,715 - train - INFO - avg block size:1.0
2024-04-06 21:40:21,715 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 21:40:21,934 - train - INFO - Test: [   0/78]  Time: 0.215 (0.215)  Loss:  1.1035 (1.1035)  Acc@1: 78.9062 (78.9062)  Acc@5: 92.1875 (92.1875)
2024-04-06 21:40:25,712 - train - INFO - Test: [  50/78]  Time: 0.075 (0.078)  Loss:  1.9355 (1.8081)  Acc@1: 57.8125 (58.4865)  Acc@5: 84.3750 (82.3223)
2024-04-06 21:40:27,672 - train - INFO - Test: [  78/78]  Time: 0.049 (0.075)  Loss:  1.7275 (1.8173)  Acc@1: 56.2500 (58.3000)  Acc@5: 87.5000 (82.1100)
2024-04-06 21:40:28,417 - train - INFO - Train: 2 [   0/781 (  0%)]  Loss:  3.813121 (3.8131)  Time: 0.669s,  191.43/s  (0.669s,  191.43/s)  LR: 1.080e-04  Data: 0.173 (0.173)
2024-04-06 21:40:51,726 - train - INFO - Train: 2 [  50/781 (  6%)]  Loss:  4.165581 (3.9248)  Time: 0.487s,  262.83/s  (0.470s,  272.28/s)  LR: 1.080e-04  Data: 0.007 (0.011)
2024-04-06 21:41:15,481 - train - INFO - Train: 2 [ 100/781 ( 13%)]  Loss:  3.903288 (3.8902)  Time: 0.490s,  261.01/s  (0.473s,  270.86/s)  LR: 1.080e-04  Data: 0.008 (0.010)
2024-04-06 21:41:39,153 - train - INFO - Train: 2 [ 150/781 ( 19%)]  Loss:  3.951270 (3.8888)  Time: 0.439s,  291.68/s  (0.473s,  270.70/s)  LR: 1.080e-04  Data: 0.008 (0.009)
2024-04-06 21:42:02,457 - train - INFO - Train: 2 [ 200/781 ( 26%)]  Loss:  3.676010 (3.8896)  Time: 0.474s,  270.25/s  (0.471s,  271.67/s)  LR: 1.080e-04  Data: 0.009 (0.009)
2024-04-06 21:42:25,861 - train - INFO - Train: 2 [ 250/781 ( 32%)]  Loss:  3.962003 (3.8922)  Time: 0.346s,  369.55/s  (0.471s,  272.03/s)  LR: 1.080e-04  Data: 0.004 (0.009)
2024-04-06 21:42:49,006 - train - INFO - Train: 2 [ 300/781 ( 38%)]  Loss:  4.115287 (3.8866)  Time: 0.538s,  237.84/s  (0.469s,  272.77/s)  LR: 1.080e-04  Data: 0.020 (0.009)
2024-04-06 21:43:12,197 - train - INFO - Train: 2 [ 350/781 ( 45%)]  Loss:  3.941009 (3.8868)  Time: 0.419s,  305.17/s  (0.468s,  273.22/s)  LR: 1.080e-04  Data: 0.006 (0.009)
2024-04-06 21:43:35,911 - train - INFO - Train: 2 [ 400/781 ( 51%)]  Loss:  3.979559 (3.8848)  Time: 0.500s,  255.93/s  (0.469s,  272.80/s)  LR: 1.080e-04  Data: 0.009 (0.008)
2024-04-06 21:44:00,069 - train - INFO - Train: 2 [ 450/781 ( 58%)]  Loss:  3.925059 (3.8748)  Time: 0.503s,  254.46/s  (0.471s,  271.91/s)  LR: 1.080e-04  Data: 0.007 (0.008)
2024-04-06 21:44:24,119 - train - INFO - Train: 2 [ 500/781 ( 64%)]  Loss:  3.851632 (3.8750)  Time: 0.495s,  258.78/s  (0.472s,  271.32/s)  LR: 1.080e-04  Data: 0.009 (0.008)
2024-04-06 21:44:48,757 - train - INFO - Train: 2 [ 550/781 ( 71%)]  Loss:  3.350527 (3.8695)  Time: 0.505s,  253.63/s  (0.474s,  270.23/s)  LR: 1.080e-04  Data: 0.009 (0.008)
2024-04-06 21:45:12,224 - train - INFO - Train: 2 [ 600/781 ( 77%)]  Loss:  3.770782 (3.8680)  Time: 0.464s,  275.63/s  (0.473s,  270.45/s)  LR: 1.080e-04  Data: 0.011 (0.008)
2024-04-06 21:45:35,012 - train - INFO - Train: 2 [ 650/781 ( 83%)]  Loss:  3.908502 (3.8641)  Time: 0.486s,  263.52/s  (0.472s,  271.22/s)  LR: 1.080e-04  Data: 0.014 (0.008)
2024-04-06 21:45:58,824 - train - INFO - Train: 2 [ 700/781 ( 90%)]  Loss:  4.029500 (3.8624)  Time: 0.372s,  344.11/s  (0.472s,  271.04/s)  LR: 1.080e-04  Data: 0.005 (0.008)
2024-04-06 21:46:23,517 - train - INFO - Train: 2 [ 750/781 ( 96%)]  Loss:  3.552975 (3.8560)  Time: 0.503s,  254.69/s  (0.474s,  270.22/s)  LR: 1.080e-04  Data: 0.005 (0.008)
2024-04-06 21:46:38,565 - train - INFO - Train: 2 [ 780/781 (100%)]  Loss:  3.606167 (3.8541)  Time: 0.512s,  250.10/s  (0.475s,  269.61/s)  LR: 1.080e-04  Data: 0.000 (0.008)
2024-04-06 21:46:38,566 - train - INFO - True
2024-04-06 21:46:38,569 - train - INFO - alphas:tensor([0.2113, 0.1955, 0.1964, 0.1979, 0.1989], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,570 - train - INFO - True
2024-04-06 21:46:38,572 - train - INFO - alphas:tensor([0.2163, 0.1968, 0.1940, 0.1958, 0.1971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,572 - train - INFO - True
2024-04-06 21:46:38,574 - train - INFO - alphas:tensor([0.2671, 0.2425, 0.2439, 0.2464], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,575 - train - INFO - True
2024-04-06 21:46:38,577 - train - INFO - alphas:tensor([0.2696, 0.2431, 0.2421, 0.2452], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,579 - train - INFO - True
2024-04-06 21:46:38,580 - train - INFO - alphas:tensor([0.2680, 0.2435, 0.2436, 0.2449], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,581 - train - INFO - True
2024-04-06 21:46:38,584 - train - INFO - alphas:tensor([0.2707, 0.2429, 0.2419, 0.2445], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,586 - train - INFO - True
2024-04-06 21:46:38,587 - train - INFO - alphas:tensor([0.2146, 0.1978, 0.1947, 0.1959, 0.1970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,589 - train - INFO - True
2024-04-06 21:46:38,591 - train - INFO - alphas:tensor([0.2168, 0.1961, 0.1939, 0.1951, 0.1981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,592 - train - INFO - True
2024-04-06 21:46:38,594 - train - INFO - alphas:tensor([0.2151, 0.1961, 0.1935, 0.1952, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,595 - train - INFO - True
2024-04-06 21:46:38,597 - train - INFO - alphas:tensor([0.2156, 0.1940, 0.1938, 0.1965, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,599 - train - INFO - True
2024-04-06 21:46:38,600 - train - INFO - alphas:tensor([0.2154, 0.1950, 0.1934, 0.1956, 0.2005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,602 - train - INFO - True
2024-04-06 21:46:38,603 - train - INFO - alphas:tensor([0.2204, 0.1949, 0.1937, 0.1946, 0.1965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,605 - train - INFO - True
2024-04-06 21:46:38,606 - train - INFO - alphas:tensor([0.2200, 0.1960, 0.1935, 0.1945, 0.1959], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,611 - train - INFO - True
2024-04-06 21:46:38,612 - train - INFO - alphas:tensor([0.2148, 0.1960, 0.1937, 0.1957, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,617 - train - INFO - True
2024-04-06 21:46:38,618 - train - INFO - alphas:tensor([0.2155, 0.1947, 0.1932, 0.1962, 0.2003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,623 - train - INFO - True
2024-04-06 21:46:38,624 - train - INFO - alphas:tensor([0.2186, 0.1960, 0.1925, 0.1940, 0.1990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,629 - train - INFO - True
2024-04-06 21:46:38,630 - train - INFO - alphas:tensor([0.2151, 0.1949, 0.1925, 0.1958, 0.2018], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,635 - train - INFO - True
2024-04-06 21:46:38,636 - train - INFO - alphas:tensor([0.2182, 0.1950, 0.1922, 0.1951, 0.1995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,640 - train - INFO - True
2024-04-06 21:46:38,641 - train - INFO - alphas:tensor([0.2131, 0.1954, 0.1931, 0.1966, 0.2017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,646 - train - INFO - True
2024-04-06 21:46:38,647 - train - INFO - alphas:tensor([0.2247, 0.1949, 0.1920, 0.1936, 0.1948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,651 - train - INFO - True
2024-04-06 21:46:38,652 - train - INFO - alphas:tensor([0.2221, 0.1952, 0.1928, 0.1943, 0.1955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,660 - train - INFO - True
2024-04-06 21:46:38,661 - train - INFO - alphas:tensor([0.2225, 0.1970, 0.1911, 0.1933, 0.1961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,669 - train - INFO - True
2024-04-06 21:46:38,670 - train - INFO - alphas:tensor([0.2218, 0.1960, 0.1923, 0.1939, 0.1961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,678 - train - INFO - True
2024-04-06 21:46:38,679 - train - INFO - alphas:tensor([0.2253, 0.1952, 0.1912, 0.1926, 0.1956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,686 - train - INFO - True
2024-04-06 21:46:38,687 - train - INFO - alphas:tensor([0.2218, 0.1953, 0.1925, 0.1933, 0.1970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,694 - train - INFO - True
2024-04-06 21:46:38,695 - train - INFO - alphas:tensor([0.2267, 0.1932, 0.1923, 0.1931, 0.1947], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,703 - train - INFO - True
2024-04-06 21:46:38,704 - train - INFO - alphas:tensor([0.2254, 0.1940, 0.1922, 0.1932, 0.1952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,723 - train - INFO - True
2024-04-06 21:46:38,725 - train - INFO - alphas:tensor([0.2264, 0.1934, 0.1899, 0.1923, 0.1981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,745 - train - INFO - True
2024-04-06 21:46:38,748 - train - INFO - alphas:tensor([0.2280, 0.1925, 0.1901, 0.1923, 0.1971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,768 - train - INFO - True
2024-04-06 21:46:38,773 - train - INFO - alphas:tensor([0.2324, 0.1924, 0.1891, 0.1909, 0.1952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,793 - train - INFO - True
2024-04-06 21:46:38,797 - train - INFO - alphas:tensor([0.2290, 0.1923, 0.1896, 0.1914, 0.1977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,817 - train - INFO - True
2024-04-06 21:46:38,819 - train - INFO - alphas:tensor([0.2321, 0.1910, 0.1910, 0.1926, 0.1933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,839 - train - INFO - True
2024-04-06 21:46:38,840 - train - INFO - alphas:tensor([0.2304, 0.1921, 0.1911, 0.1927, 0.1938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:46:38,918 - train - INFO - avg block size:1.0
2024-04-06 21:46:38,919 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 21:46:39,147 - train - INFO - Test: [   0/78]  Time: 0.223 (0.223)  Loss:  1.1191 (1.1191)  Acc@1: 78.1250 (78.1250)  Acc@5: 92.1875 (92.1875)
2024-04-06 21:46:43,553 - train - INFO - Test: [  50/78]  Time: 0.113 (0.091)  Loss:  1.9004 (1.7069)  Acc@1: 57.8125 (61.5809)  Acc@5: 83.5938 (84.1452)
2024-04-06 21:46:46,109 - train - INFO - Test: [  78/78]  Time: 0.131 (0.091)  Loss:  1.8174 (1.7313)  Acc@1: 56.2500 (60.8400)  Acc@5: 87.5000 (83.8700)
2024-04-06 21:46:46,882 - train - INFO - Train: 3 [   0/781 (  0%)]  Loss:  4.042222 (4.0422)  Time: 0.696s,  183.78/s  (0.696s,  183.78/s)  LR: 1.570e-04  Data: 0.191 (0.191)
2024-04-06 21:47:11,143 - train - INFO - Train: 3 [  50/781 (  6%)]  Loss:  3.979246 (3.7976)  Time: 0.446s,  287.26/s  (0.489s,  261.58/s)  LR: 1.570e-04  Data: 0.008 (0.011)
2024-04-06 21:47:35,250 - train - INFO - Train: 3 [ 100/781 ( 13%)]  Loss:  3.975431 (3.8073)  Time: 0.444s,  288.51/s  (0.486s,  263.50/s)  LR: 1.570e-04  Data: 0.008 (0.009)
2024-04-06 21:47:59,488 - train - INFO - Train: 3 [ 150/781 ( 19%)]  Loss:  3.994655 (3.8128)  Time: 0.430s,  298.01/s  (0.485s,  263.69/s)  LR: 1.570e-04  Data: 0.006 (0.009)
2024-04-06 21:48:23,007 - train - INFO - Train: 3 [ 200/781 ( 26%)]  Loss:  3.895278 (3.8175)  Time: 0.550s,  232.60/s  (0.482s,  265.74/s)  LR: 1.570e-04  Data: 0.005 (0.008)
2024-04-06 21:48:47,886 - train - INFO - Train: 3 [ 250/781 ( 32%)]  Loss:  3.517732 (3.8118)  Time: 0.500s,  256.04/s  (0.485s,  264.01/s)  LR: 1.570e-04  Data: 0.006 (0.008)
2024-04-06 21:49:12,634 - train - INFO - Train: 3 [ 300/781 ( 38%)]  Loss:  3.967596 (3.8132)  Time: 0.480s,  266.62/s  (0.487s,  263.10/s)  LR: 1.570e-04  Data: 0.006 (0.008)
2024-04-06 21:49:37,187 - train - INFO - Train: 3 [ 350/781 ( 45%)]  Loss:  3.340759 (3.8101)  Time: 0.433s,  295.69/s  (0.487s,  262.75/s)  LR: 1.570e-04  Data: 0.006 (0.008)
2024-04-06 21:50:02,080 - train - INFO - Train: 3 [ 400/781 ( 51%)]  Loss:  4.284603 (3.8087)  Time: 0.434s,  295.07/s  (0.488s,  262.03/s)  LR: 1.570e-04  Data: 0.005 (0.008)
2024-04-06 21:50:27,849 - train - INFO - Train: 3 [ 450/781 ( 58%)]  Loss:  3.951121 (3.8064)  Time: 0.550s,  232.84/s  (0.491s,  260.45/s)  LR: 1.570e-04  Data: 0.010 (0.008)
2024-04-06 21:50:53,248 - train - INFO - Train: 3 [ 500/781 ( 64%)]  Loss:  3.538993 (3.8015)  Time: 0.526s,  243.28/s  (0.493s,  259.58/s)  LR: 1.570e-04  Data: 0.007 (0.008)
2024-04-06 21:51:18,649 - train - INFO - Train: 3 [ 550/781 ( 71%)]  Loss:  3.419681 (3.7950)  Time: 0.515s,  248.58/s  (0.494s,  258.87/s)  LR: 1.570e-04  Data: 0.006 (0.008)
2024-04-06 21:51:43,071 - train - INFO - Train: 3 [ 600/781 ( 77%)]  Loss:  4.046615 (3.7854)  Time: 0.491s,  260.88/s  (0.494s,  259.13/s)  LR: 1.570e-04  Data: 0.008 (0.008)
2024-04-06 21:52:08,591 - train - INFO - Train: 3 [ 650/781 ( 83%)]  Loss:  4.072481 (3.7841)  Time: 0.512s,  249.76/s  (0.495s,  258.47/s)  LR: 1.570e-04  Data: 0.018 (0.008)
2024-04-06 21:52:33,640 - train - INFO - Train: 3 [ 700/781 ( 90%)]  Loss:  3.875117 (3.7810)  Time: 0.479s,  267.30/s  (0.496s,  258.26/s)  LR: 1.570e-04  Data: 0.005 (0.008)
2024-04-06 21:52:59,131 - train - INFO - Train: 3 [ 750/781 ( 96%)]  Loss:  3.497928 (3.7783)  Time: 0.442s,  289.89/s  (0.497s,  257.77/s)  LR: 1.570e-04  Data: 0.005 (0.008)
2024-04-06 21:53:14,088 - train - INFO - Train: 3 [ 780/781 (100%)]  Loss:  3.608088 (3.7789)  Time: 0.514s,  248.80/s  (0.497s,  257.73/s)  LR: 1.570e-04  Data: 0.000 (0.008)
2024-04-06 21:53:14,089 - train - INFO - True
2024-04-06 21:53:14,096 - train - INFO - alphas:tensor([0.2163, 0.1930, 0.1944, 0.1973, 0.1990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,097 - train - INFO - tau:0.99
2024-04-06 21:53:14,097 - train - INFO - True
2024-04-06 21:53:14,103 - train - INFO - alphas:tensor([0.2273, 0.1921, 0.1903, 0.1936, 0.1967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,104 - train - INFO - tau:0.99
2024-04-06 21:53:14,105 - train - INFO - True
2024-04-06 21:53:14,109 - train - INFO - alphas:tensor([0.2775, 0.2374, 0.2399, 0.2451], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,110 - train - INFO - tau:0.99
2024-04-06 21:53:14,110 - train - INFO - True
2024-04-06 21:53:14,115 - train - INFO - alphas:tensor([0.2826, 0.2369, 0.2375, 0.2430], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,116 - train - INFO - tau:0.99
2024-04-06 21:53:14,116 - train - INFO - True
2024-04-06 21:53:14,121 - train - INFO - alphas:tensor([0.2793, 0.2372, 0.2397, 0.2437], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,122 - train - INFO - tau:0.99
2024-04-06 21:53:14,122 - train - INFO - True
2024-04-06 21:53:14,127 - train - INFO - alphas:tensor([0.2841, 0.2368, 0.2370, 0.2422], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,128 - train - INFO - tau:0.99
2024-04-06 21:53:14,129 - train - INFO - True
2024-04-06 21:53:14,136 - train - INFO - alphas:tensor([0.2250, 0.1949, 0.1913, 0.1933, 0.1956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,137 - train - INFO - tau:0.99
2024-04-06 21:53:14,137 - train - INFO - True
2024-04-06 21:53:14,139 - train - INFO - alphas:tensor([0.2272, 0.1905, 0.1892, 0.1932, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,140 - train - INFO - tau:0.99
2024-04-06 21:53:14,140 - train - INFO - True
2024-04-06 21:53:14,142 - train - INFO - alphas:tensor([0.2248, 0.1913, 0.1889, 0.1925, 0.2024], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,143 - train - INFO - tau:0.99
2024-04-06 21:53:14,143 - train - INFO - True
2024-04-06 21:53:14,144 - train - INFO - alphas:tensor([0.2267, 0.1889, 0.1881, 0.1943, 0.2020], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,146 - train - INFO - tau:0.99
2024-04-06 21:53:14,146 - train - INFO - True
2024-04-06 21:53:14,147 - train - INFO - alphas:tensor([0.2249, 0.1897, 0.1886, 0.1935, 0.2034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,149 - train - INFO - tau:0.99
2024-04-06 21:53:14,149 - train - INFO - True
2024-04-06 21:53:14,150 - train - INFO - alphas:tensor([0.2345, 0.1899, 0.1893, 0.1914, 0.1948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,151 - train - INFO - tau:0.99
2024-04-06 21:53:14,152 - train - INFO - True
2024-04-06 21:53:14,153 - train - INFO - alphas:tensor([0.2337, 0.1913, 0.1899, 0.1912, 0.1940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,157 - train - INFO - tau:0.99
2024-04-06 21:53:14,157 - train - INFO - True
2024-04-06 21:53:14,158 - train - INFO - alphas:tensor([0.2248, 0.1905, 0.1879, 0.1938, 0.2030], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,163 - train - INFO - tau:0.99
2024-04-06 21:53:14,163 - train - INFO - True
2024-04-06 21:53:14,164 - train - INFO - alphas:tensor([0.2260, 0.1893, 0.1875, 0.1945, 0.2028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,168 - train - INFO - tau:0.99
2024-04-06 21:53:14,168 - train - INFO - True
2024-04-06 21:53:14,169 - train - INFO - alphas:tensor([0.2317, 0.1901, 0.1870, 0.1908, 0.2004], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,173 - train - INFO - tau:0.99
2024-04-06 21:53:14,173 - train - INFO - True
2024-04-06 21:53:14,174 - train - INFO - alphas:tensor([0.2232, 0.1884, 0.1875, 0.1950, 0.2059], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,178 - train - INFO - tau:0.99
2024-04-06 21:53:14,179 - train - INFO - True
2024-04-06 21:53:14,180 - train - INFO - alphas:tensor([0.2324, 0.1887, 0.1860, 0.1920, 0.2009], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,183 - train - INFO - tau:0.99
2024-04-06 21:53:14,184 - train - INFO - True
2024-04-06 21:53:14,185 - train - INFO - alphas:tensor([0.2214, 0.1890, 0.1880, 0.1952, 0.2063], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,188 - train - INFO - tau:0.99
2024-04-06 21:53:14,189 - train - INFO - True
2024-04-06 21:53:14,189 - train - INFO - alphas:tensor([0.2424, 0.1894, 0.1865, 0.1895, 0.1923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,193 - train - INFO - tau:0.99
2024-04-06 21:53:14,193 - train - INFO - True
2024-04-06 21:53:14,194 - train - INFO - alphas:tensor([0.2379, 0.1905, 0.1874, 0.1906, 0.1935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,202 - train - INFO - tau:0.99
2024-04-06 21:53:14,202 - train - INFO - True
2024-04-06 21:53:14,203 - train - INFO - alphas:tensor([0.2392, 0.1920, 0.1850, 0.1895, 0.1944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,210 - train - INFO - tau:0.99
2024-04-06 21:53:14,210 - train - INFO - True
2024-04-06 21:53:14,211 - train - INFO - alphas:tensor([0.2379, 0.1908, 0.1863, 0.1899, 0.1950], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,219 - train - INFO - tau:0.99
2024-04-06 21:53:14,219 - train - INFO - True
2024-04-06 21:53:14,220 - train - INFO - alphas:tensor([0.2452, 0.1892, 0.1845, 0.1874, 0.1938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,227 - train - INFO - tau:0.99
2024-04-06 21:53:14,227 - train - INFO - True
2024-04-06 21:53:14,228 - train - INFO - alphas:tensor([0.2385, 0.1894, 0.1869, 0.1891, 0.1961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,236 - train - INFO - tau:0.99
2024-04-06 21:53:14,236 - train - INFO - True
2024-04-06 21:53:14,237 - train - INFO - alphas:tensor([0.2467, 0.1861, 0.1861, 0.1890, 0.1921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,244 - train - INFO - tau:0.99
2024-04-06 21:53:14,244 - train - INFO - True
2024-04-06 21:53:14,249 - train - INFO - alphas:tensor([0.2452, 0.1880, 0.1862, 0.1884, 0.1922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,269 - train - INFO - tau:0.99
2024-04-06 21:53:14,269 - train - INFO - True
2024-04-06 21:53:14,271 - train - INFO - alphas:tensor([0.2468, 0.1859, 0.1822, 0.1868, 0.1982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,291 - train - INFO - tau:0.99
2024-04-06 21:53:14,291 - train - INFO - True
2024-04-06 21:53:14,293 - train - INFO - alphas:tensor([0.2485, 0.1846, 0.1822, 0.1868, 0.1979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,313 - train - INFO - tau:0.99
2024-04-06 21:53:14,313 - train - INFO - True
2024-04-06 21:53:14,315 - train - INFO - alphas:tensor([0.2570, 0.1844, 0.1804, 0.1842, 0.1940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,335 - train - INFO - tau:0.99
2024-04-06 21:53:14,335 - train - INFO - True
2024-04-06 21:53:14,336 - train - INFO - alphas:tensor([0.2500, 0.1841, 0.1817, 0.1857, 0.1986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,356 - train - INFO - tau:0.99
2024-04-06 21:53:14,356 - train - INFO - True
2024-04-06 21:53:14,357 - train - INFO - alphas:tensor([0.2580, 0.1816, 0.1839, 0.1872, 0.1894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,376 - train - INFO - tau:0.99
2024-04-06 21:53:14,376 - train - INFO - True
2024-04-06 21:53:14,377 - train - INFO - alphas:tensor([0.2541, 0.1848, 0.1840, 0.1872, 0.1899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:53:14,456 - train - INFO - tau:0.99
2024-04-06 21:53:14,456 - train - INFO - avg block size:1.0
2024-04-06 21:53:14,456 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 21:53:14,749 - train - INFO - Test: [   0/78]  Time: 0.289 (0.289)  Loss:  1.2129 (1.2129)  Acc@1: 75.7812 (75.7812)  Acc@5: 91.4062 (91.4062)
2024-04-06 21:53:19,507 - train - INFO - Test: [  50/78]  Time: 0.057 (0.099)  Loss:  1.6592 (1.6787)  Acc@1: 60.9375 (62.8217)  Acc@5: 84.3750 (84.2831)
2024-04-06 21:53:22,012 - train - INFO - Test: [  78/78]  Time: 0.135 (0.096)  Loss:  2.0117 (1.6969)  Acc@1: 50.0000 (62.4600)  Acc@5: 87.5000 (84.2300)
2024-04-06 21:53:22,861 - train - INFO - Train: 4 [   0/781 (  0%)]  Loss:  3.982140 (3.9821)  Time: 0.761s,  168.24/s  (0.761s,  168.24/s)  LR: 2.060e-04  Data: 0.198 (0.198)
2024-04-06 21:53:46,919 - train - INFO - Train: 4 [  50/781 (  6%)]  Loss:  3.821338 (3.7567)  Time: 0.473s,  270.43/s  (0.487s,  263.05/s)  LR: 2.060e-04  Data: 0.005 (0.011)
2024-04-06 21:54:12,554 - train - INFO - Train: 4 [ 100/781 ( 13%)]  Loss:  3.925512 (3.7417)  Time: 0.506s,  252.73/s  (0.500s,  256.25/s)  LR: 2.060e-04  Data: 0.009 (0.010)
2024-04-06 21:54:37,170 - train - INFO - Train: 4 [ 150/781 ( 19%)]  Loss:  3.732131 (3.7489)  Time: 0.445s,  287.61/s  (0.497s,  257.48/s)  LR: 2.060e-04  Data: 0.009 (0.009)
2024-04-06 21:55:01,570 - train - INFO - Train: 4 [ 200/781 ( 26%)]  Loss:  4.011152 (3.7599)  Time: 0.395s,  323.85/s  (0.495s,  258.67/s)  LR: 2.060e-04  Data: 0.005 (0.009)
2024-04-06 21:55:25,782 - train - INFO - Train: 4 [ 250/781 ( 32%)]  Loss:  3.331480 (3.7491)  Time: 0.481s,  266.19/s  (0.493s,  259.78/s)  LR: 2.060e-04  Data: 0.007 (0.009)
2024-04-06 21:55:50,891 - train - INFO - Train: 4 [ 300/781 ( 38%)]  Loss:  3.724758 (3.7457)  Time: 0.483s,  264.76/s  (0.494s,  258.96/s)  LR: 2.060e-04  Data: 0.006 (0.009)
2024-04-06 21:56:15,411 - train - INFO - Train: 4 [ 350/781 ( 45%)]  Loss:  3.622547 (3.7444)  Time: 0.550s,  232.60/s  (0.494s,  259.25/s)  LR: 2.060e-04  Data: 0.009 (0.008)
2024-04-06 21:56:40,163 - train - INFO - Train: 4 [ 400/781 ( 51%)]  Loss:  3.888778 (3.7476)  Time: 0.535s,  239.08/s  (0.494s,  259.17/s)  LR: 2.060e-04  Data: 0.007 (0.008)
2024-04-06 21:57:04,636 - train - INFO - Train: 4 [ 450/781 ( 58%)]  Loss:  3.952969 (3.7449)  Time: 0.548s,  233.66/s  (0.493s,  259.43/s)  LR: 2.060e-04  Data: 0.005 (0.008)
2024-04-06 21:57:29,055 - train - INFO - Train: 4 [ 500/781 ( 64%)]  Loss:  4.058646 (3.7461)  Time: 0.506s,  253.10/s  (0.493s,  259.69/s)  LR: 2.060e-04  Data: 0.015 (0.008)
2024-04-06 21:57:53,625 - train - INFO - Train: 4 [ 550/781 ( 71%)]  Loss:  3.974776 (3.7494)  Time: 0.427s,  300.05/s  (0.493s,  259.76/s)  LR: 2.060e-04  Data: 0.006 (0.008)
2024-04-06 21:58:18,726 - train - INFO - Train: 4 [ 600/781 ( 77%)]  Loss:  3.578192 (3.7484)  Time: 0.490s,  261.03/s  (0.494s,  259.36/s)  LR: 2.060e-04  Data: 0.007 (0.008)
2024-04-06 21:58:43,081 - train - INFO - Train: 4 [ 650/781 ( 83%)]  Loss:  3.459533 (3.7498)  Time: 0.481s,  265.88/s  (0.493s,  259.62/s)  LR: 2.060e-04  Data: 0.005 (0.008)
2024-04-06 21:59:07,860 - train - INFO - Train: 4 [ 700/781 ( 90%)]  Loss:  3.668148 (3.7511)  Time: 0.446s,  287.27/s  (0.493s,  259.53/s)  LR: 2.060e-04  Data: 0.005 (0.008)
2024-04-06 21:59:33,206 - train - INFO - Train: 4 [ 750/781 ( 96%)]  Loss:  3.869667 (3.7439)  Time: 0.414s,  309.10/s  (0.494s,  259.05/s)  LR: 2.060e-04  Data: 0.009 (0.008)
2024-04-06 21:59:47,540 - train - INFO - Train: 4 [ 780/781 (100%)]  Loss:  3.945998 (3.7455)  Time: 0.510s,  250.85/s  (0.493s,  259.38/s)  LR: 2.060e-04  Data: 0.000 (0.008)
2024-04-06 21:59:47,541 - train - INFO - True
2024-04-06 21:59:47,543 - train - INFO - alphas:tensor([0.2227, 0.1899, 0.1920, 0.1964, 0.1989], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,543 - train - INFO - tau:0.9801
2024-04-06 21:59:47,544 - train - INFO - True
2024-04-06 21:59:47,545 - train - INFO - alphas:tensor([0.2400, 0.1866, 0.1858, 0.1913, 0.1963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,546 - train - INFO - tau:0.9801
2024-04-06 21:59:47,546 - train - INFO - True
2024-04-06 21:59:47,547 - train - INFO - alphas:tensor([0.2908, 0.2307, 0.2349, 0.2437], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,548 - train - INFO - tau:0.9801
2024-04-06 21:59:47,548 - train - INFO - True
2024-04-06 21:59:47,549 - train - INFO - alphas:tensor([0.2974, 0.2299, 0.2319, 0.2407], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,550 - train - INFO - tau:0.9801
2024-04-06 21:59:47,551 - train - INFO - True
2024-04-06 21:59:47,552 - train - INFO - alphas:tensor([0.2933, 0.2300, 0.2350, 0.2417], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,553 - train - INFO - tau:0.9801
2024-04-06 21:59:47,553 - train - INFO - True
2024-04-06 21:59:47,554 - train - INFO - alphas:tensor([0.3007, 0.2284, 0.2315, 0.2394], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,555 - train - INFO - tau:0.9801
2024-04-06 21:59:47,555 - train - INFO - True
2024-04-06 21:59:47,556 - train - INFO - alphas:tensor([0.2395, 0.1901, 0.1866, 0.1899, 0.1939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,558 - train - INFO - tau:0.9801
2024-04-06 21:59:47,558 - train - INFO - True
2024-04-06 21:59:47,559 - train - INFO - alphas:tensor([0.2386, 0.1828, 0.1833, 0.1918, 0.2036], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,561 - train - INFO - tau:0.9801
2024-04-06 21:59:47,561 - train - INFO - True
2024-04-06 21:59:47,562 - train - INFO - alphas:tensor([0.2345, 0.1844, 0.1831, 0.1907, 0.2073], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,563 - train - INFO - tau:0.9801
2024-04-06 21:59:47,564 - train - INFO - True
2024-04-06 21:59:47,565 - train - INFO - alphas:tensor([0.2392, 0.1805, 0.1812, 0.1922, 0.2068], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,566 - train - INFO - tau:0.9801
2024-04-06 21:59:47,566 - train - INFO - True
2024-04-06 21:59:47,567 - train - INFO - alphas:tensor([0.2334, 0.1819, 0.1833, 0.1929, 0.2085], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,569 - train - INFO - tau:0.9801
2024-04-06 21:59:47,569 - train - INFO - True
2024-04-06 21:59:47,570 - train - INFO - alphas:tensor([0.2534, 0.1817, 0.1833, 0.1878, 0.1938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,571 - train - INFO - tau:0.9801
2024-04-06 21:59:47,571 - train - INFO - True
2024-04-06 21:59:47,573 - train - INFO - alphas:tensor([0.2522, 0.1851, 0.1839, 0.1869, 0.1919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,577 - train - INFO - tau:0.9801
2024-04-06 21:59:47,577 - train - INFO - True
2024-04-06 21:59:47,578 - train - INFO - alphas:tensor([0.2350, 0.1821, 0.1814, 0.1918, 0.2098], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,582 - train - INFO - tau:0.9801
2024-04-06 21:59:47,582 - train - INFO - True
2024-04-06 21:59:47,583 - train - INFO - alphas:tensor([0.2364, 0.1814, 0.1816, 0.1934, 0.2073], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,587 - train - INFO - tau:0.9801
2024-04-06 21:59:47,587 - train - INFO - True
2024-04-06 21:59:47,589 - train - INFO - alphas:tensor([0.2461, 0.1814, 0.1795, 0.1879, 0.2051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,592 - train - INFO - tau:0.9801
2024-04-06 21:59:47,593 - train - INFO - True
2024-04-06 21:59:47,594 - train - INFO - alphas:tensor([0.2320, 0.1801, 0.1810, 0.1946, 0.2124], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,598 - train - INFO - tau:0.9801
2024-04-06 21:59:47,598 - train - INFO - True
2024-04-06 21:59:47,599 - train - INFO - alphas:tensor([0.2472, 0.1795, 0.1789, 0.1884, 0.2060], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,602 - train - INFO - tau:0.9801
2024-04-06 21:59:47,602 - train - INFO - True
2024-04-06 21:59:47,603 - train - INFO - alphas:tensor([0.2268, 0.1800, 0.1825, 0.1955, 0.2152], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,607 - train - INFO - tau:0.9801
2024-04-06 21:59:47,607 - train - INFO - True
2024-04-06 21:59:47,608 - train - INFO - alphas:tensor([0.2664, 0.1810, 0.1787, 0.1847, 0.1893], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,612 - train - INFO - tau:0.9801
2024-04-06 21:59:47,612 - train - INFO - True
2024-04-06 21:59:47,613 - train - INFO - alphas:tensor([0.2589, 0.1835, 0.1804, 0.1857, 0.1914], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,620 - train - INFO - tau:0.9801
2024-04-06 21:59:47,620 - train - INFO - True
2024-04-06 21:59:47,621 - train - INFO - alphas:tensor([0.2604, 0.1838, 0.1763, 0.1845, 0.1949], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,629 - train - INFO - tau:0.9801
2024-04-06 21:59:47,630 - train - INFO - True
2024-04-06 21:59:47,631 - train - INFO - alphas:tensor([0.2584, 0.1835, 0.1779, 0.1851, 0.1951], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,639 - train - INFO - tau:0.9801
2024-04-06 21:59:47,639 - train - INFO - True
2024-04-06 21:59:47,641 - train - INFO - alphas:tensor([0.2701, 0.1802, 0.1749, 0.1814, 0.1934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,649 - train - INFO - tau:0.9801
2024-04-06 21:59:47,649 - train - INFO - True
2024-04-06 21:59:47,652 - train - INFO - alphas:tensor([0.2594, 0.1817, 0.1793, 0.1839, 0.1956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,659 - train - INFO - tau:0.9801
2024-04-06 21:59:47,659 - train - INFO - True
2024-04-06 21:59:47,664 - train - INFO - alphas:tensor([0.2733, 0.1758, 0.1783, 0.1836, 0.1890], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,671 - train - INFO - tau:0.9801
2024-04-06 21:59:47,671 - train - INFO - True
2024-04-06 21:59:47,676 - train - INFO - alphas:tensor([0.2722, 0.1792, 0.1786, 0.1822, 0.1878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,696 - train - INFO - tau:0.9801
2024-04-06 21:59:47,696 - train - INFO - True
2024-04-06 21:59:47,700 - train - INFO - alphas:tensor([0.2716, 0.1741, 0.1715, 0.1807, 0.2021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,720 - train - INFO - tau:0.9801
2024-04-06 21:59:47,720 - train - INFO - True
2024-04-06 21:59:47,724 - train - INFO - alphas:tensor([0.2739, 0.1716, 0.1716, 0.1816, 0.2012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,744 - train - INFO - tau:0.9801
2024-04-06 21:59:47,744 - train - INFO - True
2024-04-06 21:59:47,745 - train - INFO - alphas:tensor([0.2881, 0.1717, 0.1699, 0.1766, 0.1937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,765 - train - INFO - tau:0.9801
2024-04-06 21:59:47,765 - train - INFO - True
2024-04-06 21:59:47,766 - train - INFO - alphas:tensor([0.2743, 0.1720, 0.1709, 0.1793, 0.2035], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,786 - train - INFO - tau:0.9801
2024-04-06 21:59:47,786 - train - INFO - True
2024-04-06 21:59:47,787 - train - INFO - alphas:tensor([0.2924, 0.1691, 0.1745, 0.1797, 0.1843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,807 - train - INFO - tau:0.9801
2024-04-06 21:59:47,807 - train - INFO - True
2024-04-06 21:59:47,808 - train - INFO - alphas:tensor([0.2861, 0.1747, 0.1743, 0.1796, 0.1853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:59:47,886 - train - INFO - tau:0.9801
2024-04-06 21:59:47,886 - train - INFO - avg block size:1.0
2024-04-06 21:59:47,886 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 21:59:48,157 - train - INFO - Test: [   0/78]  Time: 0.267 (0.267)  Loss:  1.1094 (1.1094)  Acc@1: 78.1250 (78.1250)  Acc@5: 90.6250 (90.6250)
2024-04-06 21:59:52,639 - train - INFO - Test: [  50/78]  Time: 0.080 (0.093)  Loss:  1.7744 (1.6338)  Acc@1: 56.2500 (62.3468)  Acc@5: 83.5938 (84.2525)
2024-04-06 21:59:55,169 - train - INFO - Test: [  78/78]  Time: 0.053 (0.092)  Loss:  1.5449 (1.6539)  Acc@1: 62.5000 (62.1300)  Acc@5: 100.0000 (84.1300)
2024-04-06 21:59:55,890 - train - INFO - Train: 5 [   0/781 (  0%)]  Loss:  4.000454 (4.0005)  Time: 0.644s,  198.82/s  (0.644s,  198.82/s)  LR: 2.550e-04  Data: 0.188 (0.188)
2024-04-06 22:00:20,116 - train - INFO - Train: 5 [  50/781 (  6%)]  Loss:  3.582671 (3.7476)  Time: 0.601s,  212.83/s  (0.488s,  262.51/s)  LR: 2.550e-04  Data: 0.007 (0.012)
2024-04-06 22:00:45,378 - train - INFO - Train: 5 [ 100/781 ( 13%)]  Loss:  3.774078 (3.7240)  Time: 0.460s,  278.04/s  (0.496s,  257.90/s)  LR: 2.550e-04  Data: 0.009 (0.010)
2024-04-06 22:01:10,802 - train - INFO - Train: 5 [ 150/781 ( 19%)]  Loss:  4.058520 (3.7304)  Time: 0.432s,  296.48/s  (0.500s,  255.83/s)  LR: 2.550e-04  Data: 0.004 (0.009)
2024-04-06 22:01:35,778 - train - INFO - Train: 5 [ 200/781 ( 26%)]  Loss:  4.075260 (3.7299)  Time: 0.514s,  249.11/s  (0.500s,  255.94/s)  LR: 2.550e-04  Data: 0.008 (0.009)
2024-04-06 22:02:00,569 - train - INFO - Train: 5 [ 250/781 ( 32%)]  Loss:  3.948204 (3.7302)  Time: 0.502s,  255.04/s  (0.499s,  256.38/s)  LR: 2.550e-04  Data: 0.006 (0.009)
2024-04-06 22:02:24,578 - train - INFO - Train: 5 [ 300/781 ( 38%)]  Loss:  3.452987 (3.7257)  Time: 0.487s,  262.79/s  (0.496s,  258.02/s)  LR: 2.550e-04  Data: 0.005 (0.009)
2024-04-06 22:02:48,644 - train - INFO - Train: 5 [ 350/781 ( 45%)]  Loss:  3.885690 (3.7336)  Time: 0.397s,  322.30/s  (0.494s,  259.12/s)  LR: 2.550e-04  Data: 0.006 (0.008)
2024-04-06 22:03:13,273 - train - INFO - Train: 5 [ 400/781 ( 51%)]  Loss:  3.471969 (3.7393)  Time: 0.527s,  242.69/s  (0.494s,  259.22/s)  LR: 2.550e-04  Data: 0.007 (0.008)
2024-04-06 22:03:38,915 - train - INFO - Train: 5 [ 450/781 ( 58%)]  Loss:  3.366163 (3.7454)  Time: 0.551s,  232.14/s  (0.496s,  258.11/s)  LR: 2.550e-04  Data: 0.008 (0.008)
2024-04-06 22:04:04,047 - train - INFO - Train: 5 [ 500/781 ( 64%)]  Loss:  3.918471 (3.7403)  Time: 0.545s,  235.04/s  (0.497s,  257.77/s)  LR: 2.550e-04  Data: 0.005 (0.008)
2024-04-06 22:04:28,954 - train - INFO - Train: 5 [ 550/781 ( 71%)]  Loss:  4.015625 (3.7364)  Time: 0.489s,  261.79/s  (0.497s,  257.69/s)  LR: 2.550e-04  Data: 0.007 (0.008)
2024-04-06 22:04:53,056 - train - INFO - Train: 5 [ 600/781 ( 77%)]  Loss:  3.511780 (3.7362)  Time: 0.473s,  270.54/s  (0.495s,  258.33/s)  LR: 2.550e-04  Data: 0.006 (0.008)
2024-04-06 22:05:17,604 - train - INFO - Train: 5 [ 650/781 ( 83%)]  Loss:  4.014064 (3.7379)  Time: 0.516s,  248.29/s  (0.495s,  258.51/s)  LR: 2.550e-04  Data: 0.008 (0.008)
2024-04-06 22:05:42,592 - train - INFO - Train: 5 [ 700/781 ( 90%)]  Loss:  3.164928 (3.7403)  Time: 0.574s,  222.91/s  (0.495s,  258.34/s)  LR: 2.550e-04  Data: 0.008 (0.008)
2024-04-06 22:06:07,306 - train - INFO - Train: 5 [ 750/781 ( 96%)]  Loss:  3.636944 (3.7405)  Time: 0.501s,  255.40/s  (0.495s,  258.38/s)  LR: 2.550e-04  Data: 0.008 (0.008)
2024-04-06 22:06:22,364 - train - INFO - Train: 5 [ 780/781 (100%)]  Loss:  3.514281 (3.7431)  Time: 0.502s,  254.92/s  (0.496s,  258.25/s)  LR: 2.550e-04  Data: 0.000 (0.008)
2024-04-06 22:06:22,366 - train - INFO - True
2024-04-06 22:06:22,370 - train - INFO - alphas:tensor([0.2306, 0.1861, 0.1891, 0.1953, 0.1988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,371 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,371 - train - INFO - True
2024-04-06 22:06:22,377 - train - INFO - alphas:tensor([0.2544, 0.1797, 0.1814, 0.1887, 0.1958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,378 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,378 - train - INFO - True
2024-04-06 22:06:22,383 - train - INFO - alphas:tensor([0.3044, 0.2233, 0.2298, 0.2425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,384 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,384 - train - INFO - True
2024-04-06 22:06:22,387 - train - INFO - alphas:tensor([0.3127, 0.2212, 0.2268, 0.2394], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,388 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,388 - train - INFO - True
2024-04-06 22:06:22,392 - train - INFO - alphas:tensor([0.3091, 0.2211, 0.2288, 0.2411], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,393 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,393 - train - INFO - True
2024-04-06 22:06:22,398 - train - INFO - alphas:tensor([0.3192, 0.2190, 0.2248, 0.2370], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,400 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,400 - train - INFO - True
2024-04-06 22:06:22,405 - train - INFO - alphas:tensor([0.2578, 0.1843, 0.1810, 0.1854, 0.1914], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,406 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,406 - train - INFO - True
2024-04-06 22:06:22,408 - train - INFO - alphas:tensor([0.2483, 0.1731, 0.1765, 0.1906, 0.2114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,410 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,410 - train - INFO - True
2024-04-06 22:06:22,413 - train - INFO - alphas:tensor([0.2449, 0.1755, 0.1770, 0.1880, 0.2147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,414 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,414 - train - INFO - True
2024-04-06 22:06:22,420 - train - INFO - alphas:tensor([0.2499, 0.1707, 0.1737, 0.1908, 0.2149], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,421 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,421 - train - INFO - True
2024-04-06 22:06:22,427 - train - INFO - alphas:tensor([0.2418, 0.1723, 0.1760, 0.1924, 0.2175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,428 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,428 - train - INFO - True
2024-04-06 22:06:22,434 - train - INFO - alphas:tensor([0.2759, 0.1728, 0.1763, 0.1832, 0.1918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,435 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,435 - train - INFO - True
2024-04-06 22:06:22,440 - train - INFO - alphas:tensor([0.2753, 0.1780, 0.1769, 0.1811, 0.1887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,444 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,444 - train - INFO - True
2024-04-06 22:06:22,445 - train - INFO - alphas:tensor([0.2431, 0.1733, 0.1738, 0.1905, 0.2193], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,449 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,449 - train - INFO - True
2024-04-06 22:06:22,457 - train - INFO - alphas:tensor([0.2470, 0.1718, 0.1733, 0.1918, 0.2162], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,461 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,461 - train - INFO - True
2024-04-06 22:06:22,462 - train - INFO - alphas:tensor([0.2598, 0.1708, 0.1713, 0.1849, 0.2133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,465 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,466 - train - INFO - True
2024-04-06 22:06:22,467 - train - INFO - alphas:tensor([0.2390, 0.1699, 0.1728, 0.1933, 0.2251], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,470 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,470 - train - INFO - True
2024-04-06 22:06:22,471 - train - INFO - alphas:tensor([0.2621, 0.1667, 0.1698, 0.1863, 0.2151], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,475 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,475 - train - INFO - True
2024-04-06 22:06:22,476 - train - INFO - alphas:tensor([0.2332, 0.1699, 0.1744, 0.1948, 0.2277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,479 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,479 - train - INFO - True
2024-04-06 22:06:22,480 - train - INFO - alphas:tensor([0.2966, 0.1708, 0.1699, 0.1771, 0.1856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,484 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,484 - train - INFO - True
2024-04-06 22:06:22,485 - train - INFO - alphas:tensor([0.2861, 0.1743, 0.1715, 0.1794, 0.1887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,492 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,492 - train - INFO - True
2024-04-06 22:06:22,493 - train - INFO - alphas:tensor([0.2854, 0.1728, 0.1672, 0.1788, 0.1958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,501 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,501 - train - INFO - True
2024-04-06 22:06:22,502 - train - INFO - alphas:tensor([0.2834, 0.1731, 0.1679, 0.1792, 0.1964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,509 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,509 - train - INFO - True
2024-04-06 22:06:22,510 - train - INFO - alphas:tensor([0.2995, 0.1691, 0.1644, 0.1740, 0.1929], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,517 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,518 - train - INFO - True
2024-04-06 22:06:22,519 - train - INFO - alphas:tensor([0.2842, 0.1715, 0.1694, 0.1779, 0.1971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,526 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,526 - train - INFO - True
2024-04-06 22:06:22,527 - train - INFO - alphas:tensor([0.3056, 0.1635, 0.1683, 0.1764, 0.1861], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,534 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,535 - train - INFO - True
2024-04-06 22:06:22,535 - train - INFO - alphas:tensor([0.3080, 0.1674, 0.1689, 0.1739, 0.1817], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,555 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,555 - train - INFO - True
2024-04-06 22:06:22,556 - train - INFO - alphas:tensor([0.2970, 0.1584, 0.1594, 0.1740, 0.2112], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,576 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,576 - train - INFO - True
2024-04-06 22:06:22,578 - train - INFO - alphas:tensor([0.2996, 0.1572, 0.1593, 0.1742, 0.2097], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,598 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,598 - train - INFO - True
2024-04-06 22:06:22,600 - train - INFO - alphas:tensor([0.3200, 0.1563, 0.1569, 0.1688, 0.1980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,619 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,620 - train - INFO - True
2024-04-06 22:06:22,622 - train - INFO - alphas:tensor([0.2991, 0.1568, 0.1589, 0.1736, 0.2117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,642 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,642 - train - INFO - True
2024-04-06 22:06:22,646 - train - INFO - alphas:tensor([0.3329, 0.1553, 0.1629, 0.1708, 0.1782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,665 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,666 - train - INFO - True
2024-04-06 22:06:22,671 - train - INFO - alphas:tensor([0.3256, 0.1618, 0.1626, 0.1705, 0.1795], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:06:22,749 - train - INFO - tau:0.9702989999999999
2024-04-06 22:06:22,749 - train - INFO - avg block size:1.0
2024-04-06 22:06:22,749 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 22:06:23,011 - train - INFO - Test: [   0/78]  Time: 0.258 (0.258)  Loss:  1.1670 (1.1670)  Acc@1: 77.3438 (77.3438)  Acc@5: 92.9688 (92.9688)
2024-04-06 22:06:27,460 - train - INFO - Test: [  50/78]  Time: 0.056 (0.092)  Loss:  1.9150 (1.7728)  Acc@1: 52.3438 (60.8456)  Acc@5: 82.8125 (83.3793)
2024-04-06 22:06:29,699 - train - INFO - Test: [  78/78]  Time: 0.054 (0.088)  Loss:  2.1738 (1.7822)  Acc@1: 43.7500 (60.7500)  Acc@5: 87.5000 (83.1300)
2024-04-06 22:06:30,531 - train - INFO - Train: 6 [   0/781 (  0%)]  Loss:  3.981679 (3.9817)  Time: 0.752s,  170.22/s  (0.752s,  170.22/s)  LR: 3.040e-04  Data: 0.175 (0.175)
2024-04-06 22:06:57,445 - train - INFO - Train: 6 [  50/781 (  6%)]  Loss:  3.561148 (3.7130)  Time: 0.919s,  139.27/s  (0.542s,  235.96/s)  LR: 3.040e-04  Data: 0.008 (0.011)
2024-04-06 22:07:28,421 - train - INFO - Train: 6 [ 100/781 ( 13%)]  Loss:  3.511306 (3.7161)  Time: 0.513s,  249.46/s  (0.581s,  220.47/s)  LR: 3.040e-04  Data: 0.006 (0.010)
2024-04-06 22:07:59,850 - train - INFO - Train: 6 [ 150/781 ( 19%)]  Loss:  4.081807 (3.7387)  Time: 0.933s,  137.24/s  (0.596s,  214.60/s)  LR: 3.040e-04  Data: 0.005 (0.009)
2024-04-06 22:08:31,543 - train - INFO - Train: 6 [ 200/781 ( 26%)]  Loss:  3.514714 (3.7464)  Time: 0.494s,  258.86/s  (0.606s,  211.30/s)  LR: 3.040e-04  Data: 0.009 (0.009)
2024-04-06 22:09:02,608 - train - INFO - Train: 6 [ 250/781 ( 32%)]  Loss:  3.866540 (3.7515)  Time: 0.426s,  300.54/s  (0.609s,  210.23/s)  LR: 3.040e-04  Data: 0.005 (0.009)
2024-04-06 22:09:26,714 - train - INFO - Train: 6 [ 300/781 ( 38%)]  Loss:  3.766710 (3.7545)  Time: 0.428s,  299.38/s  (0.588s,  217.76/s)  LR: 3.040e-04  Data: 0.007 (0.009)
2024-04-06 22:09:50,275 - train - INFO - Train: 6 [ 350/781 ( 45%)]  Loss:  3.497172 (3.7553)  Time: 0.469s,  272.64/s  (0.571s,  224.10/s)  LR: 3.040e-04  Data: 0.009 (0.009)
2024-04-06 22:10:14,624 - train - INFO - Train: 6 [ 400/781 ( 51%)]  Loss:  4.076853 (3.7544)  Time: 0.505s,  253.68/s  (0.561s,  228.29/s)  LR: 3.040e-04  Data: 0.008 (0.009)
2024-04-06 22:10:38,009 - train - INFO - Train: 6 [ 450/781 ( 58%)]  Loss:  3.434900 (3.7602)  Time: 0.419s,  305.52/s  (0.550s,  232.57/s)  LR: 3.040e-04  Data: 0.006 (0.008)
2024-04-06 22:11:02,282 - train - INFO - Train: 6 [ 500/781 ( 64%)]  Loss:  3.396950 (3.7627)  Time: 0.486s,  263.34/s  (0.544s,  235.34/s)  LR: 3.040e-04  Data: 0.008 (0.008)
2024-04-06 22:11:26,092 - train - INFO - Train: 6 [ 550/781 ( 71%)]  Loss:  4.074582 (3.7662)  Time: 0.419s,  305.78/s  (0.538s,  238.03/s)  LR: 3.040e-04  Data: 0.007 (0.008)
2024-04-06 22:11:50,021 - train - INFO - Train: 6 [ 600/781 ( 77%)]  Loss:  3.523438 (3.7647)  Time: 0.493s,  259.61/s  (0.533s,  240.23/s)  LR: 3.040e-04  Data: 0.007 (0.008)
2024-04-06 22:12:13,059 - train - INFO - Train: 6 [ 650/781 ( 83%)]  Loss:  3.819277 (3.7629)  Time: 0.454s,  281.78/s  (0.527s,  242.75/s)  LR: 3.040e-04  Data: 0.005 (0.008)
2024-04-06 22:12:36,782 - train - INFO - Train: 6 [ 700/781 ( 90%)]  Loss:  3.425792 (3.7600)  Time: 0.503s,  254.39/s  (0.524s,  244.50/s)  LR: 3.040e-04  Data: 0.014 (0.008)
2024-04-06 22:13:00,632 - train - INFO - Train: 6 [ 750/781 ( 96%)]  Loss:  3.796681 (3.7599)  Time: 0.481s,  265.97/s  (0.520s,  245.96/s)  LR: 3.040e-04  Data: 0.016 (0.008)
2024-04-06 22:13:14,928 - train - INFO - Train: 6 [ 780/781 (100%)]  Loss:  3.748559 (3.7603)  Time: 0.502s,  254.82/s  (0.519s,  246.76/s)  LR: 3.040e-04  Data: 0.000 (0.008)
2024-04-06 22:13:14,929 - train - INFO - True
2024-04-06 22:13:14,931 - train - INFO - alphas:tensor([0.2385, 0.1828, 0.1859, 0.1945, 0.1984], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,932 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,932 - train - INFO - True
2024-04-06 22:13:14,934 - train - INFO - alphas:tensor([0.2700, 0.1733, 0.1758, 0.1860, 0.1950], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,934 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,935 - train - INFO - True
2024-04-06 22:13:14,936 - train - INFO - alphas:tensor([0.3194, 0.2155, 0.2245, 0.2406], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,937 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,937 - train - INFO - True
2024-04-06 22:13:14,939 - train - INFO - alphas:tensor([0.3281, 0.2121, 0.2213, 0.2385], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,940 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,940 - train - INFO - True
2024-04-06 22:13:14,941 - train - INFO - alphas:tensor([0.3260, 0.2112, 0.2229, 0.2400], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,942 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,943 - train - INFO - True
2024-04-06 22:13:14,944 - train - INFO - alphas:tensor([0.3390, 0.2097, 0.2172, 0.2341], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,945 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,945 - train - INFO - True
2024-04-06 22:13:14,947 - train - INFO - alphas:tensor([0.2788, 0.1776, 0.1742, 0.1802, 0.1892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,948 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,948 - train - INFO - True
2024-04-06 22:13:14,950 - train - INFO - alphas:tensor([0.2532, 0.1620, 0.1703, 0.1911, 0.2235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,951 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,952 - train - INFO - True
2024-04-06 22:13:14,953 - train - INFO - alphas:tensor([0.2525, 0.1639, 0.1692, 0.1877, 0.2267], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,954 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,955 - train - INFO - True
2024-04-06 22:13:14,956 - train - INFO - alphas:tensor([0.2564, 0.1585, 0.1667, 0.1894, 0.2290], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,958 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,958 - train - INFO - True
2024-04-06 22:13:14,959 - train - INFO - alphas:tensor([0.2463, 0.1610, 0.1686, 0.1930, 0.2310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,960 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,961 - train - INFO - True
2024-04-06 22:13:14,962 - train - INFO - alphas:tensor([0.2996, 0.1635, 0.1692, 0.1784, 0.1893], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,963 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,963 - train - INFO - True
2024-04-06 22:13:14,965 - train - INFO - alphas:tensor([0.3028, 0.1699, 0.1683, 0.1745, 0.1845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,969 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,969 - train - INFO - True
2024-04-06 22:13:14,971 - train - INFO - alphas:tensor([0.2477, 0.1613, 0.1654, 0.1903, 0.2352], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,975 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,975 - train - INFO - True
2024-04-06 22:13:14,977 - train - INFO - alphas:tensor([0.2555, 0.1595, 0.1649, 0.1912, 0.2290], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,981 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,981 - train - INFO - True
2024-04-06 22:13:14,982 - train - INFO - alphas:tensor([0.2704, 0.1582, 0.1629, 0.1826, 0.2259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,987 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,987 - train - INFO - True
2024-04-06 22:13:14,988 - train - INFO - alphas:tensor([0.2447, 0.1578, 0.1638, 0.1908, 0.2428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:14,992 - train - INFO - tau:0.96059601
2024-04-06 22:13:14,992 - train - INFO - True
2024-04-06 22:13:14,993 - train - INFO - alphas:tensor([0.2747, 0.1551, 0.1600, 0.1836, 0.2267], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,005 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,005 - train - INFO - True
2024-04-06 22:13:15,007 - train - INFO - alphas:tensor([0.2358, 0.1595, 0.1656, 0.1941, 0.2450], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,010 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,010 - train - INFO - True
2024-04-06 22:13:15,012 - train - INFO - alphas:tensor([0.3315, 0.1591, 0.1592, 0.1694, 0.1808], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,017 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,018 - train - INFO - True
2024-04-06 22:13:15,019 - train - INFO - alphas:tensor([0.3185, 0.1633, 0.1610, 0.1716, 0.1857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,030 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,030 - train - INFO - True
2024-04-06 22:13:15,031 - train - INFO - alphas:tensor([0.3129, 0.1603, 0.1551, 0.1731, 0.1986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,042 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,042 - train - INFO - True
2024-04-06 22:13:15,043 - train - INFO - alphas:tensor([0.3124, 0.1603, 0.1569, 0.1719, 0.1986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,053 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,053 - train - INFO - True
2024-04-06 22:13:15,054 - train - INFO - alphas:tensor([0.3291, 0.1554, 0.1537, 0.1675, 0.1944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,063 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,063 - train - INFO - True
2024-04-06 22:13:15,064 - train - INFO - alphas:tensor([0.3101, 0.1594, 0.1583, 0.1716, 0.2006], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,073 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,073 - train - INFO - True
2024-04-06 22:13:15,074 - train - INFO - alphas:tensor([0.3426, 0.1502, 0.1568, 0.1677, 0.1826], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,082 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,082 - train - INFO - True
2024-04-06 22:13:15,083 - train - INFO - alphas:tensor([0.3524, 0.1554, 0.1567, 0.1623, 0.1732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,103 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,103 - train - INFO - True
2024-04-06 22:13:15,104 - train - INFO - alphas:tensor([0.3192, 0.1428, 0.1458, 0.1674, 0.2248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,124 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,125 - train - INFO - True
2024-04-06 22:13:15,126 - train - INFO - alphas:tensor([0.3237, 0.1409, 0.1449, 0.1673, 0.2233], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,146 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,146 - train - INFO - True
2024-04-06 22:13:15,147 - train - INFO - alphas:tensor([0.3463, 0.1403, 0.1434, 0.1618, 0.2082], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,167 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,167 - train - INFO - True
2024-04-06 22:13:15,168 - train - INFO - alphas:tensor([0.3180, 0.1410, 0.1461, 0.1661, 0.2288], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,188 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,188 - train - INFO - True
2024-04-06 22:13:15,189 - train - INFO - alphas:tensor([0.3787, 0.1403, 0.1506, 0.1602, 0.1703], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,208 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,209 - train - INFO - True
2024-04-06 22:13:15,210 - train - INFO - alphas:tensor([0.3690, 0.1472, 0.1498, 0.1595, 0.1745], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:13:15,312 - train - INFO - tau:0.96059601
2024-04-06 22:13:15,312 - train - INFO - avg block size:1.4545454545454546
2024-04-06 22:13:15,313 - train - INFO - current latency ratio:tensor(0.9617)
2024-04-06 22:13:15,313 - train - INFO - lasso_alpha:2.2000000000000003e-05
2024-04-06 22:13:15,514 - train - INFO - Test: [   0/78]  Time: 0.195 (0.195)  Loss:  1.1250 (1.1250)  Acc@1: 77.3438 (77.3438)  Acc@5: 91.4062 (91.4062)
2024-04-06 22:13:18,640 - train - INFO - Test: [  50/78]  Time: 0.056 (0.065)  Loss:  2.0117 (1.7178)  Acc@1: 53.9062 (60.7996)  Acc@5: 81.2500 (83.9767)
2024-04-06 22:13:20,639 - train - INFO - Test: [  78/78]  Time: 0.052 (0.067)  Loss:  2.3398 (1.7327)  Acc@1: 43.7500 (60.7100)  Acc@5: 81.2500 (83.5400)
2024-04-06 22:13:21,345 - train - INFO - Train: 7 [   0/781 (  0%)]  Loss:  3.651424 (3.6514)  Time: 0.623s,  205.34/s  (0.623s,  205.34/s)  LR: 3.530e-04  Data: 0.184 (0.184)
2024-04-06 22:13:45,241 - train - INFO - Train: 7 [  50/781 (  6%)]  Loss:  3.432624 (3.7126)  Time: 0.508s,  252.17/s  (0.481s,  266.25/s)  LR: 3.530e-04  Data: 0.008 (0.012)
2024-04-06 22:14:09,683 - train - INFO - Train: 7 [ 100/781 ( 13%)]  Loss:  3.841007 (3.7666)  Time: 0.487s,  262.74/s  (0.485s,  264.06/s)  LR: 3.530e-04  Data: 0.009 (0.010)
2024-04-06 22:14:34,022 - train - INFO - Train: 7 [ 150/781 ( 19%)]  Loss:  3.826560 (3.7958)  Time: 0.507s,  252.38/s  (0.485s,  263.70/s)  LR: 3.530e-04  Data: 0.008 (0.009)
2024-04-06 22:14:58,569 - train - INFO - Train: 7 [ 200/781 ( 26%)]  Loss:  3.806123 (3.7986)  Time: 0.489s,  261.78/s  (0.487s,  262.96/s)  LR: 3.530e-04  Data: 0.008 (0.009)
2024-04-06 22:15:22,745 - train - INFO - Train: 7 [ 250/781 ( 32%)]  Loss:  3.704466 (3.8028)  Time: 0.512s,  249.88/s  (0.486s,  263.31/s)  LR: 3.530e-04  Data: 0.006 (0.009)
2024-04-06 22:15:47,268 - train - INFO - Train: 7 [ 300/781 ( 38%)]  Loss:  3.776403 (3.8043)  Time: 0.439s,  291.51/s  (0.487s,  262.92/s)  LR: 3.530e-04  Data: 0.005 (0.009)
2024-04-06 22:16:11,910 - train - INFO - Train: 7 [ 350/781 ( 45%)]  Loss:  3.680043 (3.8055)  Time: 0.489s,  261.98/s  (0.488s,  262.47/s)  LR: 3.530e-04  Data: 0.008 (0.009)
2024-04-06 22:16:36,759 - train - INFO - Train: 7 [ 400/781 ( 51%)]  Loss:  3.729363 (3.8030)  Time: 0.489s,  261.76/s  (0.489s,  261.85/s)  LR: 3.530e-04  Data: 0.007 (0.008)
2024-04-06 22:17:01,102 - train - INFO - Train: 7 [ 450/781 ( 58%)]  Loss:  3.950856 (3.8028)  Time: 0.427s,  300.01/s  (0.489s,  261.97/s)  LR: 3.530e-04  Data: 0.019 (0.008)
2024-04-06 22:17:25,810 - train - INFO - Train: 7 [ 500/781 ( 64%)]  Loss:  4.021470 (3.8034)  Time: 0.433s,  295.95/s  (0.489s,  261.67/s)  LR: 3.530e-04  Data: 0.008 (0.008)
2024-04-06 22:17:51,159 - train - INFO - Train: 7 [ 550/781 ( 71%)]  Loss:  3.874683 (3.8080)  Time: 0.412s,  310.63/s  (0.491s,  260.81/s)  LR: 3.530e-04  Data: 0.005 (0.008)
2024-04-06 22:18:15,838 - train - INFO - Train: 7 [ 600/781 ( 77%)]  Loss:  3.907325 (3.8077)  Time: 0.474s,  270.12/s  (0.491s,  260.69/s)  LR: 3.530e-04  Data: 0.008 (0.008)
2024-04-06 22:18:41,695 - train - INFO - Train: 7 [ 650/781 ( 83%)]  Loss:  4.008609 (3.8072)  Time: 0.526s,  243.17/s  (0.493s,  259.63/s)  LR: 3.530e-04  Data: 0.019 (0.008)
2024-04-06 22:19:06,066 - train - INFO - Train: 7 [ 700/781 ( 90%)]  Loss:  3.457889 (3.8089)  Time: 0.470s,  272.37/s  (0.493s,  259.84/s)  LR: 3.530e-04  Data: 0.006 (0.008)
2024-04-06 22:19:31,567 - train - INFO - Train: 7 [ 750/781 ( 96%)]  Loss:  3.830674 (3.8090)  Time: 0.492s,  260.13/s  (0.494s,  259.23/s)  LR: 3.530e-04  Data: 0.008 (0.008)
2024-04-06 22:19:46,629 - train - INFO - Train: 7 [ 780/781 (100%)]  Loss:  3.736020 (3.8110)  Time: 0.414s,  309.34/s  (0.494s,  259.07/s)  LR: 3.530e-04  Data: 0.000 (0.008)
2024-04-06 22:19:46,630 - train - INFO - True
2024-04-06 22:19:46,634 - train - INFO - alphas:tensor([0.2480, 0.1799, 0.1821, 0.1926, 0.1974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,635 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,635 - train - INFO - True
2024-04-06 22:19:46,639 - train - INFO - alphas:tensor([0.2860, 0.1669, 0.1705, 0.1828, 0.1937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,640 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,640 - train - INFO - True
2024-04-06 22:19:46,641 - train - INFO - alphas:tensor([0.3356, 0.2051, 0.2185, 0.2408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,642 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,642 - train - INFO - True
2024-04-06 22:19:46,646 - train - INFO - alphas:tensor([0.3439, 0.2031, 0.2148, 0.2382], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,647 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,647 - train - INFO - True
2024-04-06 22:19:46,649 - train - INFO - alphas:tensor([0.3395, 0.2017, 0.2174, 0.2414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,650 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,650 - train - INFO - True
2024-04-06 22:19:46,653 - train - INFO - alphas:tensor([0.3570, 0.2011, 0.2105, 0.2314], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,653 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,654 - train - INFO - True
2024-04-06 22:19:46,655 - train - INFO - alphas:tensor([0.3032, 0.1698, 0.1669, 0.1744, 0.1857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,656 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,657 - train - INFO - True
2024-04-06 22:19:46,661 - train - INFO - alphas:tensor([0.2511, 0.1507, 0.1628, 0.1929, 0.2425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,662 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,662 - train - INFO - True
2024-04-06 22:19:46,663 - train - INFO - alphas:tensor([0.2557, 0.1520, 0.1610, 0.1875, 0.2438], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,664 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,664 - train - INFO - True
2024-04-06 22:19:46,665 - train - INFO - alphas:tensor([0.2569, 0.1464, 0.1581, 0.1883, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,666 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,666 - train - INFO - True
2024-04-06 22:19:46,667 - train - INFO - alphas:tensor([0.2446, 0.1492, 0.1602, 0.1944, 0.2515], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,668 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,668 - train - INFO - True
2024-04-06 22:19:46,669 - train - INFO - alphas:tensor([0.3250, 0.1555, 0.1618, 0.1716, 0.1862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,670 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,670 - train - INFO - True
2024-04-06 22:19:46,671 - train - INFO - alphas:tensor([0.3342, 0.1606, 0.1589, 0.1670, 0.1792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,675 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,675 - train - INFO - True
2024-04-06 22:19:46,676 - train - INFO - alphas:tensor([0.2469, 0.1467, 0.1560, 0.1917, 0.2587], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,678 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,678 - train - INFO - True
2024-04-06 22:19:46,679 - train - INFO - alphas:tensor([0.2561, 0.1461, 0.1549, 0.1926, 0.2502], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,682 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,682 - train - INFO - True
2024-04-06 22:19:46,683 - train - INFO - alphas:tensor([0.2723, 0.1454, 0.1531, 0.1833, 0.2458], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,687 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,687 - train - INFO - True
2024-04-06 22:19:46,688 - train - INFO - alphas:tensor([0.2447, 0.1451, 0.1523, 0.1891, 0.2687], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,690 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,690 - train - INFO - True
2024-04-06 22:19:46,691 - train - INFO - alphas:tensor([0.2796, 0.1419, 0.1496, 0.1820, 0.2469], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,694 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,694 - train - INFO - True
2024-04-06 22:19:46,695 - train - INFO - alphas:tensor([0.2330, 0.1464, 0.1567, 0.1939, 0.2701], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,697 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,697 - train - INFO - True
2024-04-06 22:19:46,698 - train - INFO - alphas:tensor([0.3686, 0.1474, 0.1485, 0.1608, 0.1747], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,702 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,702 - train - INFO - True
2024-04-06 22:19:46,703 - train - INFO - alphas:tensor([0.3543, 0.1513, 0.1494, 0.1625, 0.1824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,710 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,710 - train - INFO - True
2024-04-06 22:19:46,711 - train - INFO - alphas:tensor([0.3338, 0.1468, 0.1447, 0.1671, 0.2076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,719 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,719 - train - INFO - True
2024-04-06 22:19:46,720 - train - INFO - alphas:tensor([0.3384, 0.1469, 0.1446, 0.1654, 0.2047], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,727 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,727 - train - INFO - True
2024-04-06 22:19:46,728 - train - INFO - alphas:tensor([0.3560, 0.1419, 0.1427, 0.1613, 0.1981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,736 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,736 - train - INFO - True
2024-04-06 22:19:46,737 - train - INFO - alphas:tensor([0.3325, 0.1454, 0.1468, 0.1656, 0.2097], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,744 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,744 - train - INFO - True
2024-04-06 22:19:46,745 - train - INFO - alphas:tensor([0.3795, 0.1377, 0.1446, 0.1585, 0.1797], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,752 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,753 - train - INFO - True
2024-04-06 22:19:46,754 - train - INFO - alphas:tensor([0.4017, 0.1409, 0.1426, 0.1506, 0.1642], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,773 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,773 - train - INFO - True
2024-04-06 22:19:46,774 - train - INFO - alphas:tensor([0.3238, 0.1264, 0.1325, 0.1628, 0.2545], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,794 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,794 - train - INFO - True
2024-04-06 22:19:46,798 - train - INFO - alphas:tensor([0.3343, 0.1234, 0.1305, 0.1615, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,818 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,818 - train - INFO - True
2024-04-06 22:19:46,822 - train - INFO - alphas:tensor([0.3626, 0.1229, 0.1290, 0.1556, 0.2298], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,842 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,842 - train - INFO - True
2024-04-06 22:19:46,845 - train - INFO - alphas:tensor([0.3252, 0.1256, 0.1317, 0.1623, 0.2552], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,865 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,865 - train - INFO - True
2024-04-06 22:19:46,868 - train - INFO - alphas:tensor([0.4254, 0.1264, 0.1378, 0.1481, 0.1623], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,888 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,888 - train - INFO - True
2024-04-06 22:19:46,889 - train - INFO - alphas:tensor([0.4141, 0.1317, 0.1353, 0.1478, 0.1711], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:19:46,967 - train - INFO - tau:0.9509900498999999
2024-04-06 22:19:46,967 - train - INFO - avg block size:2.8181818181818183
2024-04-06 22:19:46,967 - train - INFO - current latency ratio:tensor(0.8511)
2024-04-06 22:19:47,198 - train - INFO - Test: [   0/78]  Time: 0.227 (0.227)  Loss:  1.1475 (1.1475)  Acc@1: 77.3438 (77.3438)  Acc@5: 92.9688 (92.9688)
2024-04-06 22:19:51,780 - train - INFO - Test: [  50/78]  Time: 0.133 (0.094)  Loss:  1.8154 (1.7687)  Acc@1: 57.0312 (60.3094)  Acc@5: 82.0312 (82.6593)
2024-04-06 22:19:54,069 - train - INFO - Test: [  78/78]  Time: 0.090 (0.090)  Loss:  1.9590 (1.7870)  Acc@1: 50.0000 (59.8300)  Acc@5: 87.5000 (82.3500)
2024-04-06 22:19:54,881 - train - INFO - Train: 8 [   0/781 (  0%)]  Loss:  3.865490 (3.8655)  Time: 0.640s,  199.93/s  (0.640s,  199.93/s)  LR: 4.020e-04  Data: 0.204 (0.204)
2024-04-06 22:20:19,372 - train - INFO - Train: 8 [  50/781 (  6%)]  Loss:  3.873586 (3.7594)  Time: 0.558s,  229.24/s  (0.493s,  259.77/s)  LR: 4.020e-04  Data: 0.009 (0.012)
2024-04-06 22:20:44,168 - train - INFO - Train: 8 [ 100/781 ( 13%)]  Loss:  3.588291 (3.7651)  Time: 0.501s,  255.26/s  (0.494s,  258.95/s)  LR: 4.020e-04  Data: 0.008 (0.010)
2024-04-06 22:21:09,030 - train - INFO - Train: 8 [ 150/781 ( 19%)]  Loss:  3.796793 (3.7869)  Time: 0.501s,  255.25/s  (0.495s,  258.45/s)  LR: 4.020e-04  Data: 0.018 (0.009)
2024-04-06 22:21:34,622 - train - INFO - Train: 8 [ 200/781 ( 26%)]  Loss:  3.821236 (3.7886)  Time: 0.496s,  257.94/s  (0.499s,  256.32/s)  LR: 4.020e-04  Data: 0.006 (0.009)
2024-04-06 22:21:59,379 - train - INFO - Train: 8 [ 250/781 ( 32%)]  Loss:  3.854680 (3.8012)  Time: 0.593s,  215.68/s  (0.499s,  256.76/s)  LR: 4.020e-04  Data: 0.029 (0.009)
2024-04-06 22:22:24,114 - train - INFO - Train: 8 [ 300/781 ( 38%)]  Loss:  3.500154 (3.7872)  Time: 0.506s,  252.90/s  (0.498s,  257.09/s)  LR: 4.020e-04  Data: 0.008 (0.009)
2024-04-06 22:22:49,384 - train - INFO - Train: 8 [ 350/781 ( 45%)]  Loss:  3.844720 (3.7998)  Time: 0.510s,  251.02/s  (0.499s,  256.54/s)  LR: 4.020e-04  Data: 0.006 (0.009)
2024-04-06 22:23:14,097 - train - INFO - Train: 8 [ 400/781 ( 51%)]  Loss:  4.056640 (3.8038)  Time: 0.512s,  250.11/s  (0.498s,  256.84/s)  LR: 4.020e-04  Data: 0.008 (0.009)
2024-04-06 22:23:39,838 - train - INFO - Train: 8 [ 450/781 ( 58%)]  Loss:  4.121916 (3.8067)  Time: 0.561s,  228.25/s  (0.500s,  255.91/s)  LR: 4.020e-04  Data: 0.008 (0.009)
2024-04-06 22:24:05,153 - train - INFO - Train: 8 [ 500/781 ( 64%)]  Loss:  3.959500 (3.8127)  Time: 0.496s,  257.89/s  (0.501s,  255.60/s)  LR: 4.020e-04  Data: 0.006 (0.008)
2024-04-06 22:24:29,737 - train - INFO - Train: 8 [ 550/781 ( 71%)]  Loss:  4.123267 (3.8141)  Time: 0.496s,  257.97/s  (0.500s,  256.02/s)  LR: 4.020e-04  Data: 0.007 (0.008)
2024-04-06 22:24:54,538 - train - INFO - Train: 8 [ 600/781 ( 77%)]  Loss:  3.969980 (3.8144)  Time: 0.456s,  280.50/s  (0.500s,  256.19/s)  LR: 4.020e-04  Data: 0.007 (0.008)
2024-04-06 22:25:18,890 - train - INFO - Train: 8 [ 650/781 ( 83%)]  Loss:  4.032615 (3.8144)  Time: 0.566s,  226.29/s  (0.499s,  256.69/s)  LR: 4.020e-04  Data: 0.015 (0.008)
2024-04-06 22:25:43,442 - train - INFO - Train: 8 [ 700/781 ( 90%)]  Loss:  3.688418 (3.8126)  Time: 0.487s,  262.97/s  (0.498s,  256.97/s)  LR: 4.020e-04  Data: 0.009 (0.008)
2024-04-06 22:26:08,163 - train - INFO - Train: 8 [ 750/781 ( 96%)]  Loss:  3.618140 (3.8128)  Time: 0.546s,  234.24/s  (0.498s,  257.10/s)  LR: 4.020e-04  Data: 0.006 (0.008)
2024-04-06 22:26:23,093 - train - INFO - Train: 8 [ 780/781 (100%)]  Loss:  3.811352 (3.8106)  Time: 0.435s,  294.35/s  (0.498s,  257.10/s)  LR: 4.020e-04  Data: 0.000 (0.008)
2024-04-06 22:26:23,093 - train - INFO - True
2024-04-06 22:26:23,095 - train - INFO - alphas:tensor([0.2592, 0.1754, 0.1782, 0.1906, 0.1966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,095 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,096 - train - INFO - True
2024-04-06 22:26:23,097 - train - INFO - alphas:tensor([0.3031, 0.1614, 0.1650, 0.1783, 0.1922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,097 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,097 - train - INFO - True
2024-04-06 22:26:23,098 - train - INFO - alphas:tensor([0.3518, 0.1973, 0.2114, 0.2394], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,099 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,099 - train - INFO - True
2024-04-06 22:26:23,100 - train - INFO - alphas:tensor([0.3583, 0.1943, 0.2085, 0.2389], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,101 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,101 - train - INFO - True
2024-04-06 22:26:23,102 - train - INFO - alphas:tensor([0.3538, 0.1924, 0.2114, 0.2423], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,102 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,102 - train - INFO - True
2024-04-06 22:26:23,103 - train - INFO - alphas:tensor([0.3774, 0.1921, 0.2018, 0.2288], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,104 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,104 - train - INFO - True
2024-04-06 22:26:23,105 - train - INFO - alphas:tensor([0.3309, 0.1614, 0.1587, 0.1676, 0.1814], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,106 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,106 - train - INFO - True
2024-04-06 22:26:23,107 - train - INFO - alphas:tensor([0.2497, 0.1398, 0.1522, 0.1925, 0.2658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,108 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,108 - train - INFO - True
2024-04-06 22:26:23,109 - train - INFO - alphas:tensor([0.2572, 0.1395, 0.1508, 0.1865, 0.2661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,109 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,110 - train - INFO - True
2024-04-06 22:26:23,110 - train - INFO - alphas:tensor([0.2564, 0.1337, 0.1482, 0.1891, 0.2726], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,111 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,111 - train - INFO - True
2024-04-06 22:26:23,112 - train - INFO - alphas:tensor([0.2440, 0.1369, 0.1505, 0.1941, 0.2744], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,113 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,113 - train - INFO - True
2024-04-06 22:26:23,114 - train - INFO - alphas:tensor([0.3537, 0.1471, 0.1532, 0.1652, 0.1808], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,115 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,115 - train - INFO - True
2024-04-06 22:26:23,116 - train - INFO - alphas:tensor([0.3677, 0.1522, 0.1490, 0.1580, 0.1731], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,119 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,120 - train - INFO - True
2024-04-06 22:26:23,120 - train - INFO - alphas:tensor([0.2478, 0.1357, 0.1450, 0.1865, 0.2850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,122 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,122 - train - INFO - True
2024-04-06 22:26:23,123 - train - INFO - alphas:tensor([0.2570, 0.1338, 0.1448, 0.1896, 0.2749], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,125 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,125 - train - INFO - True
2024-04-06 22:26:23,126 - train - INFO - alphas:tensor([0.2746, 0.1315, 0.1420, 0.1822, 0.2697], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,130 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,130 - train - INFO - True
2024-04-06 22:26:23,131 - train - INFO - alphas:tensor([0.2436, 0.1318, 0.1416, 0.1859, 0.2970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,133 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,133 - train - INFO - True
2024-04-06 22:26:23,134 - train - INFO - alphas:tensor([0.2804, 0.1284, 0.1401, 0.1797, 0.2714], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,137 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,137 - train - INFO - True
2024-04-06 22:26:23,138 - train - INFO - alphas:tensor([0.2262, 0.1332, 0.1469, 0.1933, 0.3003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,140 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,140 - train - INFO - True
2024-04-06 22:26:23,141 - train - INFO - alphas:tensor([0.4066, 0.1362, 0.1370, 0.1516, 0.1686], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,145 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,145 - train - INFO - True
2024-04-06 22:26:23,146 - train - INFO - alphas:tensor([0.3889, 0.1388, 0.1380, 0.1542, 0.1801], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,153 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,153 - train - INFO - True
2024-04-06 22:26:23,154 - train - INFO - alphas:tensor([0.3537, 0.1342, 0.1355, 0.1606, 0.2159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,161 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,162 - train - INFO - True
2024-04-06 22:26:23,162 - train - INFO - alphas:tensor([0.3586, 0.1350, 0.1341, 0.1590, 0.2133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,170 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,170 - train - INFO - True
2024-04-06 22:26:23,171 - train - INFO - alphas:tensor([0.3786, 0.1282, 0.1308, 0.1558, 0.2065], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,178 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,178 - train - INFO - True
2024-04-06 22:26:23,179 - train - INFO - alphas:tensor([0.3533, 0.1317, 0.1336, 0.1596, 0.2218], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,187 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,187 - train - INFO - True
2024-04-06 22:26:23,188 - train - INFO - alphas:tensor([0.4186, 0.1246, 0.1329, 0.1476, 0.1763], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,195 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,195 - train - INFO - True
2024-04-06 22:26:23,196 - train - INFO - alphas:tensor([0.4533, 0.1264, 0.1290, 0.1371, 0.1542], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,215 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,215 - train - INFO - True
2024-04-06 22:26:23,217 - train - INFO - alphas:tensor([0.3273, 0.1101, 0.1184, 0.1576, 0.2866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,237 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,237 - train - INFO - True
2024-04-06 22:26:23,242 - train - INFO - alphas:tensor([0.3393, 0.1071, 0.1165, 0.1558, 0.2814], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,264 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,264 - train - INFO - True
2024-04-06 22:26:23,269 - train - INFO - alphas:tensor([0.3667, 0.1074, 0.1167, 0.1506, 0.2586], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,288 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,288 - train - INFO - True
2024-04-06 22:26:23,294 - train - INFO - alphas:tensor([0.3284, 0.1101, 0.1177, 0.1574, 0.2864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,314 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,314 - train - INFO - True
2024-04-06 22:26:23,320 - train - INFO - alphas:tensor([0.4760, 0.1144, 0.1236, 0.1341, 0.1519], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,340 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,340 - train - INFO - True
2024-04-06 22:26:23,342 - train - INFO - alphas:tensor([0.4562, 0.1173, 0.1215, 0.1360, 0.1690], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:26:23,419 - train - INFO - tau:0.9414801494009999
2024-04-06 22:26:23,419 - train - INFO - avg block size:4.636363636363637
2024-04-06 22:26:23,420 - train - INFO - current latency ratio:tensor(0.7111)
2024-04-06 22:26:23,420 - train - INFO - lasso_alpha:2.4200000000000005e-05
2024-04-06 22:26:23,619 - train - INFO - Test: [   0/78]  Time: 0.196 (0.196)  Loss:  1.0195 (1.0195)  Acc@1: 80.4688 (80.4688)  Acc@5: 92.9688 (92.9688)
2024-04-06 22:26:28,294 - train - INFO - Test: [  50/78]  Time: 0.089 (0.095)  Loss:  1.8721 (1.7365)  Acc@1: 52.3438 (60.0337)  Acc@5: 79.6875 (82.9963)
2024-04-06 22:26:30,991 - train - INFO - Test: [  78/78]  Time: 0.055 (0.096)  Loss:  2.0430 (1.7687)  Acc@1: 56.2500 (59.5500)  Acc@5: 93.7500 (82.6500)
2024-04-06 22:26:31,818 - train - INFO - Train: 9 [   0/781 (  0%)]  Loss:  3.774521 (3.7745)  Time: 0.745s,  171.74/s  (0.745s,  171.74/s)  LR: 4.510e-04  Data: 0.194 (0.194)
2024-04-06 22:26:56,653 - train - INFO - Train: 9 [  50/781 (  6%)]  Loss:  3.987861 (3.9397)  Time: 0.440s,  290.75/s  (0.502s,  255.20/s)  LR: 4.510e-04  Data: 0.004 (0.011)
2024-04-06 22:27:21,424 - train - INFO - Train: 9 [ 100/781 ( 13%)]  Loss:  3.511454 (3.8967)  Time: 0.576s,  222.28/s  (0.499s,  256.77/s)  LR: 4.510e-04  Data: 0.008 (0.010)
2024-04-06 22:27:46,221 - train - INFO - Train: 9 [ 150/781 ( 19%)]  Loss:  3.962991 (3.8875)  Time: 0.456s,  280.94/s  (0.498s,  257.21/s)  LR: 4.510e-04  Data: 0.006 (0.009)
2024-04-06 22:28:09,777 - train - INFO - Train: 9 [ 200/781 ( 26%)]  Loss:  3.693876 (3.8749)  Time: 0.472s,  271.44/s  (0.491s,  260.67/s)  LR: 4.510e-04  Data: 0.008 (0.009)
2024-04-06 22:28:35,190 - train - INFO - Train: 9 [ 250/781 ( 32%)]  Loss:  3.652664 (3.8735)  Time: 0.530s,  241.64/s  (0.494s,  258.86/s)  LR: 4.510e-04  Data: 0.006 (0.009)
2024-04-06 22:28:59,827 - train - INFO - Train: 9 [ 300/781 ( 38%)]  Loss:  3.467948 (3.8669)  Time: 0.487s,  262.84/s  (0.494s,  259.02/s)  LR: 4.510e-04  Data: 0.006 (0.008)
2024-04-06 22:29:24,045 - train - INFO - Train: 9 [ 350/781 ( 45%)]  Loss:  3.760715 (3.8747)  Time: 0.410s,  312.00/s  (0.493s,  259.75/s)  LR: 4.510e-04  Data: 0.006 (0.008)
2024-04-06 22:29:48,108 - train - INFO - Train: 9 [ 400/781 ( 51%)]  Loss:  3.582504 (3.8642)  Time: 0.518s,  247.32/s  (0.491s,  260.52/s)  LR: 4.510e-04  Data: 0.005 (0.008)
2024-04-06 22:30:12,791 - train - INFO - Train: 9 [ 450/781 ( 58%)]  Loss:  3.868912 (3.8565)  Time: 0.497s,  257.57/s  (0.492s,  260.38/s)  LR: 4.510e-04  Data: 0.007 (0.008)
2024-04-06 22:30:37,500 - train - INFO - Train: 9 [ 500/781 ( 64%)]  Loss:  3.917223 (3.8616)  Time: 0.577s,  221.67/s  (0.492s,  260.25/s)  LR: 4.510e-04  Data: 0.008 (0.008)
2024-04-06 22:31:02,363 - train - INFO - Train: 9 [ 550/781 ( 71%)]  Loss:  3.863353 (3.8669)  Time: 0.439s,  291.73/s  (0.492s,  259.99/s)  LR: 4.510e-04  Data: 0.008 (0.008)
2024-04-06 22:31:26,594 - train - INFO - Train: 9 [ 600/781 ( 77%)]  Loss:  3.606806 (3.8619)  Time: 0.476s,  268.85/s  (0.492s,  260.33/s)  LR: 4.510e-04  Data: 0.008 (0.008)
2024-04-06 22:31:51,013 - train - INFO - Train: 9 [ 650/781 ( 83%)]  Loss:  3.619114 (3.8644)  Time: 0.462s,  277.07/s  (0.491s,  260.46/s)  LR: 4.510e-04  Data: 0.005 (0.008)
2024-04-06 22:32:15,628 - train - INFO - Train: 9 [ 700/781 ( 90%)]  Loss:  3.888326 (3.8650)  Time: 0.424s,  301.91/s  (0.491s,  260.43/s)  LR: 4.510e-04  Data: 0.004 (0.008)
2024-04-06 22:32:39,329 - train - INFO - Train: 9 [ 750/781 ( 96%)]  Loss:  4.001797 (3.8640)  Time: 0.530s,  241.37/s  (0.490s,  261.05/s)  LR: 4.510e-04  Data: 0.015 (0.008)
2024-04-06 22:32:54,071 - train - INFO - Train: 9 [ 780/781 (100%)]  Loss:  4.133459 (3.8653)  Time: 0.534s,  239.60/s  (0.490s,  261.03/s)  LR: 4.510e-04  Data: 0.000 (0.008)
2024-04-06 22:32:54,072 - train - INFO - True
2024-04-06 22:32:54,075 - train - INFO - alphas:tensor([0.2713, 0.1720, 0.1743, 0.1875, 0.1949], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,076 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,076 - train - INFO - True
2024-04-06 22:32:54,078 - train - INFO - alphas:tensor([0.3200, 0.1552, 0.1595, 0.1744, 0.1909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,078 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,079 - train - INFO - True
2024-04-06 22:32:54,080 - train - INFO - alphas:tensor([0.3677, 0.1888, 0.2058, 0.2377], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,082 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,082 - train - INFO - True
2024-04-06 22:32:54,083 - train - INFO - alphas:tensor([0.3671, 0.1877, 0.2030, 0.2421], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,085 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,085 - train - INFO - True
2024-04-06 22:32:54,086 - train - INFO - alphas:tensor([0.3696, 0.1816, 0.2046, 0.2442], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,088 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,088 - train - INFO - True
2024-04-06 22:32:54,089 - train - INFO - alphas:tensor([0.3978, 0.1829, 0.1934, 0.2259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,091 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,091 - train - INFO - True
2024-04-06 22:32:54,092 - train - INFO - alphas:tensor([0.3555, 0.1549, 0.1517, 0.1607, 0.1771], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,094 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,094 - train - INFO - True
2024-04-06 22:32:54,096 - train - INFO - alphas:tensor([0.2414, 0.1273, 0.1429, 0.1912, 0.2973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,097 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,097 - train - INFO - True
2024-04-06 22:32:54,099 - train - INFO - alphas:tensor([0.2543, 0.1268, 0.1420, 0.1834, 0.2935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,100 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,100 - train - INFO - True
2024-04-06 22:32:54,101 - train - INFO - alphas:tensor([0.2507, 0.1206, 0.1367, 0.1883, 0.3037], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,102 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,102 - train - INFO - True
2024-04-06 22:32:54,104 - train - INFO - alphas:tensor([0.2347, 0.1241, 0.1405, 0.1939, 0.3068], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,105 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,105 - train - INFO - True
2024-04-06 22:32:54,106 - train - INFO - alphas:tensor([0.3808, 0.1389, 0.1453, 0.1579, 0.1772], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,108 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,108 - train - INFO - True
2024-04-06 22:32:54,110 - train - INFO - alphas:tensor([0.4040, 0.1414, 0.1388, 0.1486, 0.1672], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,115 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,115 - train - INFO - True
2024-04-06 22:32:54,116 - train - INFO - alphas:tensor([0.2355, 0.1207, 0.1338, 0.1871, 0.3229], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,119 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,119 - train - INFO - True
2024-04-06 22:32:54,120 - train - INFO - alphas:tensor([0.2509, 0.1195, 0.1344, 0.1864, 0.3087], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,123 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,123 - train - INFO - True
2024-04-06 22:32:54,124 - train - INFO - alphas:tensor([0.2735, 0.1173, 0.1304, 0.1797, 0.2992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,127 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,127 - train - INFO - True
2024-04-06 22:32:54,128 - train - INFO - alphas:tensor([0.2346, 0.1207, 0.1302, 0.1820, 0.3325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,131 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,131 - train - INFO - True
2024-04-06 22:32:54,132 - train - INFO - alphas:tensor([0.2750, 0.1161, 0.1289, 0.1767, 0.3033], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,135 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,135 - train - INFO - True
2024-04-06 22:32:54,136 - train - INFO - alphas:tensor([0.2219, 0.1206, 0.1355, 0.1909, 0.3310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,138 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,139 - train - INFO - True
2024-04-06 22:32:54,140 - train - INFO - alphas:tensor([0.4433, 0.1254, 0.1267, 0.1432, 0.1613], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,144 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,144 - train - INFO - True
2024-04-06 22:32:54,145 - train - INFO - alphas:tensor([0.4247, 0.1276, 0.1261, 0.1438, 0.1778], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,154 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,154 - train - INFO - True
2024-04-06 22:32:54,155 - train - INFO - alphas:tensor([0.3662, 0.1203, 0.1247, 0.1575, 0.2315], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,164 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,164 - train - INFO - True
2024-04-06 22:32:54,165 - train - INFO - alphas:tensor([0.3750, 0.1212, 0.1228, 0.1538, 0.2272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,173 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,173 - train - INFO - True
2024-04-06 22:32:54,174 - train - INFO - alphas:tensor([0.3885, 0.1159, 0.1216, 0.1514, 0.2226], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,182 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,182 - train - INFO - True
2024-04-06 22:32:54,183 - train - INFO - alphas:tensor([0.3598, 0.1188, 0.1242, 0.1552, 0.2420], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,191 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,191 - train - INFO - True
2024-04-06 22:32:54,192 - train - INFO - alphas:tensor([0.4551, 0.1124, 0.1207, 0.1378, 0.1741], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,199 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,199 - train - INFO - True
2024-04-06 22:32:54,200 - train - INFO - alphas:tensor([0.4991, 0.1130, 0.1162, 0.1258, 0.1459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,220 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,220 - train - INFO - True
2024-04-06 22:32:54,221 - train - INFO - alphas:tensor([0.3196, 0.0968, 0.1059, 0.1517, 0.3259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,231 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,231 - train - INFO - True
2024-04-06 22:32:54,232 - train - INFO - alphas:tensor([0.3336, 0.0941, 0.1043, 0.1500, 0.3180], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,252 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,252 - train - INFO - True
2024-04-06 22:32:54,254 - train - INFO - alphas:tensor([0.3595, 0.0937, 0.1041, 0.1456, 0.2970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,274 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,274 - train - INFO - True
2024-04-06 22:32:54,278 - train - INFO - alphas:tensor([0.3179, 0.0959, 0.1066, 0.1526, 0.3270], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,289 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,289 - train - INFO - True
2024-04-06 22:32:54,291 - train - INFO - alphas:tensor([0.5236, 0.1022, 0.1102, 0.1213, 0.1427], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,310 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,311 - train - INFO - True
2024-04-06 22:32:54,312 - train - INFO - alphas:tensor([0.4854, 0.1039, 0.1090, 0.1268, 0.1750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:32:54,390 - train - INFO - tau:0.9320653479069899
2024-04-06 22:32:54,390 - train - INFO - avg block size:6.454545454545454
2024-04-06 22:32:54,390 - train - INFO - current latency ratio:tensor(0.5118)
2024-04-06 22:32:54,626 - train - INFO - Test: [   0/78]  Time: 0.232 (0.232)  Loss:  1.0381 (1.0381)  Acc@1: 78.9062 (78.9062)  Acc@5: 94.5312 (94.5312)
2024-04-06 22:32:59,315 - train - INFO - Test: [  50/78]  Time: 0.068 (0.096)  Loss:  1.9414 (1.7844)  Acc@1: 55.4688 (59.1605)  Acc@5: 80.4688 (83.0882)
2024-04-06 22:33:01,566 - train - INFO - Test: [  78/78]  Time: 0.049 (0.091)  Loss:  2.4941 (1.8388)  Acc@1: 37.5000 (58.6900)  Acc@5: 75.0000 (82.2100)
2024-04-06 22:33:02,196 - train - INFO - Train: 10 [   0/781 (  0%)]  Loss:  4.182745 (4.1827)  Time: 0.531s,  241.08/s  (0.531s,  241.08/s)  LR: 4.946e-04  Data: 0.156 (0.156)
2024-04-06 22:33:27,261 - train - INFO - Train: 10 [  50/781 (  6%)]  Loss:  3.546723 (3.9141)  Time: 0.513s,  249.61/s  (0.502s,  255.06/s)  LR: 4.946e-04  Data: 0.009 (0.010)
2024-04-06 22:33:51,553 - train - INFO - Train: 10 [ 100/781 ( 13%)]  Loss:  3.647060 (3.8940)  Time: 0.426s,  300.38/s  (0.494s,  259.16/s)  LR: 4.946e-04  Data: 0.005 (0.009)
2024-04-06 22:34:16,245 - train - INFO - Train: 10 [ 150/781 ( 19%)]  Loss:  3.912053 (3.8788)  Time: 0.563s,  227.26/s  (0.494s,  259.17/s)  LR: 4.946e-04  Data: 0.009 (0.008)
2024-04-06 22:34:41,043 - train - INFO - Train: 10 [ 200/781 ( 26%)]  Loss:  3.792776 (3.8658)  Time: 0.516s,  248.27/s  (0.494s,  258.90/s)  LR: 4.946e-04  Data: 0.008 (0.008)
2024-04-06 22:35:05,973 - train - INFO - Train: 10 [ 250/781 ( 32%)]  Loss:  4.127540 (3.8799)  Time: 0.497s,  257.49/s  (0.495s,  258.47/s)  LR: 4.946e-04  Data: 0.005 (0.008)
2024-04-06 22:35:30,818 - train - INFO - Train: 10 [ 300/781 ( 38%)]  Loss:  4.191291 (3.8870)  Time: 0.471s,  271.55/s  (0.495s,  258.33/s)  LR: 4.946e-04  Data: 0.007 (0.008)
2024-04-06 22:35:55,191 - train - INFO - Train: 10 [ 350/781 ( 45%)]  Loss:  3.751854 (3.8849)  Time: 0.515s,  248.42/s  (0.494s,  258.93/s)  LR: 4.946e-04  Data: 0.007 (0.008)
2024-04-06 22:36:25,972 - train - INFO - Train: 10 [ 400/781 ( 51%)]  Loss:  3.700278 (3.8881)  Time: 0.912s,  140.38/s  (0.509s,  251.24/s)  LR: 4.946e-04  Data: 0.005 (0.008)
2024-04-06 22:36:57,550 - train - INFO - Train: 10 [ 450/781 ( 58%)]  Loss:  4.096143 (3.8882)  Time: 0.477s,  268.14/s  (0.523s,  244.74/s)  LR: 4.946e-04  Data: 0.005 (0.008)
2024-04-06 22:37:27,896 - train - INFO - Train: 10 [ 500/781 ( 64%)]  Loss:  4.130940 (3.8870)  Time: 0.519s,  246.53/s  (0.531s,  240.89/s)  LR: 4.946e-04  Data: 0.009 (0.008)
2024-04-06 22:37:59,035 - train - INFO - Train: 10 [ 550/781 ( 71%)]  Loss:  3.919627 (3.8841)  Time: 0.846s,  151.32/s  (0.540s,  237.19/s)  LR: 4.946e-04  Data: 0.007 (0.008)
2024-04-06 22:38:25,296 - train - INFO - Train: 10 [ 600/781 ( 77%)]  Loss:  3.622539 (3.8833)  Time: 0.517s,  247.47/s  (0.538s,  237.72/s)  LR: 4.946e-04  Data: 0.007 (0.008)
2024-04-06 22:38:48,765 - train - INFO - Train: 10 [ 650/781 ( 83%)]  Loss:  4.102714 (3.8807)  Time: 0.440s,  291.14/s  (0.533s,  240.09/s)  LR: 4.946e-04  Data: 0.008 (0.008)
2024-04-06 22:39:11,936 - train - INFO - Train: 10 [ 700/781 ( 90%)]  Loss:  3.956242 (3.8814)  Time: 0.321s,  399.10/s  (0.528s,  242.35/s)  LR: 4.946e-04  Data: 0.004 (0.008)
2024-04-06 22:39:35,465 - train - INFO - Train: 10 [ 750/781 ( 96%)]  Loss:  4.093030 (3.8831)  Time: 0.469s,  272.81/s  (0.524s,  244.12/s)  LR: 4.946e-04  Data: 0.008 (0.008)
2024-04-06 22:39:49,567 - train - INFO - Train: 10 [ 780/781 (100%)]  Loss:  3.905959 (3.8864)  Time: 0.483s,  264.94/s  (0.522s,  245.10/s)  LR: 4.946e-04  Data: 0.000 (0.008)
2024-04-06 22:39:49,568 - train - INFO - True
2024-04-06 22:39:49,570 - train - INFO - alphas:tensor([0.2853, 0.1675, 0.1692, 0.1846, 0.1935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,570 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,570 - train - INFO - True
2024-04-06 22:39:49,572 - train - INFO - alphas:tensor([0.3396, 0.1488, 0.1542, 0.1686, 0.1888], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,572 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,572 - train - INFO - True
2024-04-06 22:39:49,574 - train - INFO - alphas:tensor([0.3849, 0.1803, 0.1994, 0.2355], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,575 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,575 - train - INFO - True
2024-04-06 22:39:49,576 - train - INFO - alphas:tensor([0.3836, 0.1775, 0.1954, 0.2435], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,577 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,577 - train - INFO - True
2024-04-06 22:39:49,578 - train - INFO - alphas:tensor([0.3791, 0.1749, 0.1982, 0.2478], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,579 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,579 - train - INFO - True
2024-04-06 22:39:49,581 - train - INFO - alphas:tensor([0.4140, 0.1745, 0.1866, 0.2250], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,581 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,582 - train - INFO - True
2024-04-06 22:39:49,583 - train - INFO - alphas:tensor([0.3832, 0.1465, 0.1435, 0.1541, 0.1727], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,584 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,584 - train - INFO - True
2024-04-06 22:39:49,585 - train - INFO - alphas:tensor([0.2367, 0.1167, 0.1330, 0.1873, 0.3263], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,586 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,586 - train - INFO - True
2024-04-06 22:39:49,588 - train - INFO - alphas:tensor([0.2501, 0.1158, 0.1311, 0.1809, 0.3222], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,589 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,589 - train - INFO - True
2024-04-06 22:39:49,590 - train - INFO - alphas:tensor([0.2448, 0.1084, 0.1250, 0.1850, 0.3368], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,591 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,591 - train - INFO - True
2024-04-06 22:39:49,592 - train - INFO - alphas:tensor([0.2312, 0.1129, 0.1297, 0.1892, 0.3371], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,593 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,593 - train - INFO - True
2024-04-06 22:39:49,594 - train - INFO - alphas:tensor([0.4106, 0.1297, 0.1357, 0.1505, 0.1735], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,595 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,595 - train - INFO - True
2024-04-06 22:39:49,596 - train - INFO - alphas:tensor([0.4392, 0.1319, 0.1292, 0.1389, 0.1609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,601 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,601 - train - INFO - True
2024-04-06 22:39:49,602 - train - INFO - alphas:tensor([0.2318, 0.1105, 0.1234, 0.1817, 0.3526], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,604 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,604 - train - INFO - True
2024-04-06 22:39:49,605 - train - INFO - alphas:tensor([0.2479, 0.1092, 0.1221, 0.1818, 0.3391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,607 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,608 - train - INFO - True
2024-04-06 22:39:49,609 - train - INFO - alphas:tensor([0.2667, 0.1044, 0.1191, 0.1781, 0.3317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,611 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,611 - train - INFO - True
2024-04-06 22:39:49,612 - train - INFO - alphas:tensor([0.2273, 0.1093, 0.1207, 0.1770, 0.3657], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,614 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,614 - train - INFO - True
2024-04-06 22:39:49,615 - train - INFO - alphas:tensor([0.2714, 0.1039, 0.1188, 0.1713, 0.3345], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,617 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,617 - train - INFO - True
2024-04-06 22:39:49,618 - train - INFO - alphas:tensor([0.2162, 0.1086, 0.1261, 0.1881, 0.3610], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,620 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,621 - train - INFO - True
2024-04-06 22:39:49,622 - train - INFO - alphas:tensor([0.4767, 0.1144, 0.1158, 0.1353, 0.1577], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,625 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,625 - train - INFO - True
2024-04-06 22:39:49,626 - train - INFO - alphas:tensor([0.4559, 0.1153, 0.1160, 0.1358, 0.1771], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,634 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,634 - train - INFO - True
2024-04-06 22:39:49,635 - train - INFO - alphas:tensor([0.3737, 0.1087, 0.1164, 0.1516, 0.2496], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,642 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,643 - train - INFO - True
2024-04-06 22:39:49,643 - train - INFO - alphas:tensor([0.3843, 0.1091, 0.1134, 0.1485, 0.2448], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,651 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,651 - train - INFO - True
2024-04-06 22:39:49,652 - train - INFO - alphas:tensor([0.4046, 0.1043, 0.1111, 0.1444, 0.2356], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,659 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,660 - train - INFO - True
2024-04-06 22:39:49,661 - train - INFO - alphas:tensor([0.3684, 0.1064, 0.1124, 0.1511, 0.2618], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,668 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,668 - train - INFO - True
2024-04-06 22:39:49,669 - train - INFO - alphas:tensor([0.4850, 0.1013, 0.1100, 0.1287, 0.1750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,676 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,677 - train - INFO - True
2024-04-06 22:39:49,677 - train - INFO - alphas:tensor([0.5424, 0.1010, 0.1035, 0.1151, 0.1380], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,697 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,697 - train - INFO - True
2024-04-06 22:39:49,698 - train - INFO - alphas:tensor([0.3180, 0.0838, 0.0925, 0.1444, 0.3612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,708 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,708 - train - INFO - True
2024-04-06 22:39:49,709 - train - INFO - alphas:tensor([0.3297, 0.0824, 0.0923, 0.1430, 0.3527], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,719 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,719 - train - INFO - True
2024-04-06 22:39:49,720 - train - INFO - alphas:tensor([0.3558, 0.0830, 0.0936, 0.1384, 0.3292], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,740 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,740 - train - INFO - True
2024-04-06 22:39:49,741 - train - INFO - alphas:tensor([0.3146, 0.0839, 0.0960, 0.1470, 0.3585], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,752 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,752 - train - INFO - True
2024-04-06 22:39:49,753 - train - INFO - alphas:tensor([0.5627, 0.0915, 0.0984, 0.1111, 0.1363], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,772 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,772 - train - INFO - True
2024-04-06 22:39:49,773 - train - INFO - alphas:tensor([0.5065, 0.0925, 0.0982, 0.1191, 0.1837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:39:49,851 - train - INFO - tau:0.92274469442792
2024-04-06 22:39:49,851 - train - INFO - avg block size:6.909090909090909
2024-04-06 22:39:49,852 - train - INFO - current latency ratio:tensor(0.4505)
2024-04-06 22:39:49,852 - train - INFO - lasso_alpha:2.662000000000001e-05
2024-04-06 22:39:50,024 - train - INFO - Test: [   0/78]  Time: 0.169 (0.169)  Loss:  1.1553 (1.1553)  Acc@1: 78.1250 (78.1250)  Acc@5: 91.4062 (91.4062)
2024-04-06 22:39:52,840 - train - INFO - Test: [  50/78]  Time: 0.056 (0.059)  Loss:  1.7393 (1.8572)  Acc@1: 58.5938 (57.6746)  Acc@5: 82.0312 (82.0006)
2024-04-06 22:39:54,650 - train - INFO - Test: [  78/78]  Time: 0.052 (0.061)  Loss:  2.1680 (1.8796)  Acc@1: 37.5000 (57.5400)  Acc@5: 75.0000 (81.7100)
2024-04-06 22:39:55,425 - train - INFO - Train: 11 [   0/781 (  0%)]  Loss:  3.975796 (3.9758)  Time: 0.693s,  184.70/s  (0.693s,  184.70/s)  LR: 4.935e-04  Data: 0.196 (0.196)
2024-04-06 22:40:19,559 - train - INFO - Train: 11 [  50/781 (  6%)]  Loss:  3.942880 (3.9048)  Time: 0.473s,  270.60/s  (0.487s,  262.95/s)  LR: 4.935e-04  Data: 0.005 (0.011)
2024-04-06 22:40:43,585 - train - INFO - Train: 11 [ 100/781 ( 13%)]  Loss:  3.931314 (3.8957)  Time: 0.364s,  351.31/s  (0.484s,  264.64/s)  LR: 4.935e-04  Data: 0.005 (0.010)
2024-04-06 22:41:07,525 - train - INFO - Train: 11 [ 150/781 ( 19%)]  Loss:  4.126294 (3.8959)  Time: 0.533s,  240.17/s  (0.482s,  265.54/s)  LR: 4.935e-04  Data: 0.021 (0.009)
2024-04-06 22:41:30,405 - train - INFO - Train: 11 [ 200/781 ( 26%)]  Loss:  3.876275 (3.8950)  Time: 0.419s,  305.74/s  (0.476s,  268.93/s)  LR: 4.935e-04  Data: 0.006 (0.009)
2024-04-06 22:41:54,244 - train - INFO - Train: 11 [ 250/781 ( 32%)]  Loss:  3.878678 (3.8980)  Time: 0.481s,  266.12/s  (0.476s,  268.84/s)  LR: 4.935e-04  Data: 0.014 (0.009)
2024-04-06 22:42:17,941 - train - INFO - Train: 11 [ 300/781 ( 38%)]  Loss:  3.834479 (3.8944)  Time: 0.505s,  253.33/s  (0.476s,  269.05/s)  LR: 4.935e-04  Data: 0.010 (0.008)
2024-04-06 22:42:41,046 - train - INFO - Train: 11 [ 350/781 ( 45%)]  Loss:  4.019874 (3.8966)  Time: 0.499s,  256.56/s  (0.474s,  270.16/s)  LR: 4.935e-04  Data: 0.020 (0.008)
2024-04-06 22:43:03,396 - train - INFO - Train: 11 [ 400/781 ( 51%)]  Loss:  3.727656 (3.8962)  Time: 0.414s,  309.20/s  (0.470s,  272.08/s)  LR: 4.935e-04  Data: 0.004 (0.008)
2024-04-06 22:43:27,665 - train - INFO - Train: 11 [ 450/781 ( 58%)]  Loss:  4.019908 (3.8922)  Time: 0.444s,  288.57/s  (0.472s,  271.13/s)  LR: 4.935e-04  Data: 0.005 (0.008)
2024-04-06 22:43:50,897 - train - INFO - Train: 11 [ 500/781 ( 64%)]  Loss:  3.944438 (3.8955)  Time: 0.523s,  244.71/s  (0.471s,  271.56/s)  LR: 4.935e-04  Data: 0.008 (0.008)
2024-04-06 22:44:14,916 - train - INFO - Train: 11 [ 550/781 ( 71%)]  Loss:  4.239475 (3.8927)  Time: 0.372s,  344.22/s  (0.472s,  271.09/s)  LR: 4.935e-04  Data: 0.004 (0.008)
2024-04-06 22:44:38,440 - train - INFO - Train: 11 [ 600/781 ( 77%)]  Loss:  3.896364 (3.8900)  Time: 0.504s,  254.14/s  (0.472s,  271.17/s)  LR: 4.935e-04  Data: 0.008 (0.008)
2024-04-06 22:45:02,072 - train - INFO - Train: 11 [ 650/781 ( 83%)]  Loss:  3.754718 (3.8931)  Time: 0.513s,  249.51/s  (0.472s,  271.15/s)  LR: 4.935e-04  Data: 0.009 (0.008)
2024-04-06 22:45:25,317 - train - INFO - Train: 11 [ 700/781 ( 90%)]  Loss:  3.643260 (3.8907)  Time: 0.481s,  266.17/s  (0.472s,  271.44/s)  LR: 4.935e-04  Data: 0.008 (0.008)
2024-04-06 22:45:49,021 - train - INFO - Train: 11 [ 750/781 ( 96%)]  Loss:  3.801226 (3.8948)  Time: 0.497s,  257.48/s  (0.472s,  271.35/s)  LR: 4.935e-04  Data: 0.009 (0.008)
2024-04-06 22:46:03,569 - train - INFO - Train: 11 [ 780/781 (100%)]  Loss:  3.995051 (3.8961)  Time: 0.474s,  270.26/s  (0.472s,  271.05/s)  LR: 4.935e-04  Data: 0.000 (0.008)
2024-04-06 22:46:03,571 - train - INFO - True
2024-04-06 22:46:03,573 - train - INFO - alphas:tensor([0.2978, 0.1645, 0.1654, 0.1808, 0.1915], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,574 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,574 - train - INFO - True
2024-04-06 22:46:03,576 - train - INFO - alphas:tensor([0.3554, 0.1424, 0.1475, 0.1655, 0.1891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,577 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,577 - train - INFO - True
2024-04-06 22:46:03,579 - train - INFO - alphas:tensor([0.3975, 0.1731, 0.1934, 0.2360], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,580 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,580 - train - INFO - True
2024-04-06 22:46:03,582 - train - INFO - alphas:tensor([0.3913, 0.1685, 0.1899, 0.2502], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,583 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,583 - train - INFO - True
2024-04-06 22:46:03,585 - train - INFO - alphas:tensor([0.3862, 0.1662, 0.1923, 0.2552], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,586 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,586 - train - INFO - True
2024-04-06 22:46:03,588 - train - INFO - alphas:tensor([0.4276, 0.1663, 0.1797, 0.2264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,589 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,589 - train - INFO - True
2024-04-06 22:46:03,591 - train - INFO - alphas:tensor([0.4050, 0.1401, 0.1367, 0.1483, 0.1699], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,593 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,593 - train - INFO - True
2024-04-06 22:46:03,594 - train - INFO - alphas:tensor([0.2261, 0.1053, 0.1226, 0.1845, 0.3615], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,595 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,595 - train - INFO - True
2024-04-06 22:46:03,597 - train - INFO - alphas:tensor([0.2370, 0.1042, 0.1227, 0.1783, 0.3577], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,598 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,598 - train - INFO - True
2024-04-06 22:46:03,600 - train - INFO - alphas:tensor([0.2355, 0.0983, 0.1155, 0.1790, 0.3718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,601 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,601 - train - INFO - True
2024-04-06 22:46:03,602 - train - INFO - alphas:tensor([0.2206, 0.1016, 0.1198, 0.1870, 0.3710], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,603 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,603 - train - INFO - True
2024-04-06 22:46:03,605 - train - INFO - alphas:tensor([0.4316, 0.1222, 0.1291, 0.1453, 0.1718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,606 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,606 - train - INFO - True
2024-04-06 22:46:03,608 - train - INFO - alphas:tensor([0.4667, 0.1233, 0.1213, 0.1315, 0.1572], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,613 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,613 - train - INFO - True
2024-04-06 22:46:03,614 - train - INFO - alphas:tensor([0.2188, 0.0995, 0.1137, 0.1797, 0.3884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,617 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,617 - train - INFO - True
2024-04-06 22:46:03,618 - train - INFO - alphas:tensor([0.2360, 0.0977, 0.1120, 0.1796, 0.3747], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,621 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,621 - train - INFO - True
2024-04-06 22:46:03,622 - train - INFO - alphas:tensor([0.2568, 0.0942, 0.1109, 0.1728, 0.3653], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,625 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,625 - train - INFO - True
2024-04-06 22:46:03,626 - train - INFO - alphas:tensor([0.2176, 0.0989, 0.1105, 0.1720, 0.4010], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,629 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,629 - train - INFO - True
2024-04-06 22:46:03,630 - train - INFO - alphas:tensor([0.2582, 0.0933, 0.1101, 0.1683, 0.3700], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,633 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,633 - train - INFO - True
2024-04-06 22:46:03,634 - train - INFO - alphas:tensor([0.2054, 0.0967, 0.1163, 0.1829, 0.3986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,636 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,636 - train - INFO - True
2024-04-06 22:46:03,638 - train - INFO - alphas:tensor([0.5021, 0.1059, 0.1084, 0.1286, 0.1551], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,642 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,642 - train - INFO - True
2024-04-06 22:46:03,643 - train - INFO - alphas:tensor([0.4664, 0.1067, 0.1083, 0.1328, 0.1858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,652 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,652 - train - INFO - True
2024-04-06 22:46:03,653 - train - INFO - alphas:tensor([0.3663, 0.0992, 0.1067, 0.1502, 0.2776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,662 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,662 - train - INFO - True
2024-04-06 22:46:03,663 - train - INFO - alphas:tensor([0.3797, 0.0991, 0.1052, 0.1469, 0.2690], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,671 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,671 - train - INFO - True
2024-04-06 22:46:03,672 - train - INFO - alphas:tensor([0.3918, 0.0951, 0.1036, 0.1443, 0.2652], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,680 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,680 - train - INFO - True
2024-04-06 22:46:03,681 - train - INFO - alphas:tensor([0.3572, 0.0958, 0.1054, 0.1479, 0.2936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,688 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,688 - train - INFO - True
2024-04-06 22:46:03,689 - train - INFO - alphas:tensor([0.4997, 0.0935, 0.1020, 0.1225, 0.1823], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,697 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,697 - train - INFO - True
2024-04-06 22:46:03,698 - train - INFO - alphas:tensor([0.5735, 0.0905, 0.0950, 0.1071, 0.1339], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,717 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,717 - train - INFO - True
2024-04-06 22:46:03,718 - train - INFO - alphas:tensor([0.3063, 0.0732, 0.0849, 0.1385, 0.3971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,729 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,729 - train - INFO - True
2024-04-06 22:46:03,730 - train - INFO - alphas:tensor([0.3162, 0.0721, 0.0845, 0.1373, 0.3899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,740 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,741 - train - INFO - True
2024-04-06 22:46:03,741 - train - INFO - alphas:tensor([0.3414, 0.0735, 0.0838, 0.1330, 0.3683], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,752 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,752 - train - INFO - True
2024-04-06 22:46:03,753 - train - INFO - alphas:tensor([0.3001, 0.0744, 0.0860, 0.1419, 0.3976], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,763 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,763 - train - INFO - True
2024-04-06 22:46:03,764 - train - INFO - alphas:tensor([0.5954, 0.0813, 0.0879, 0.1013, 0.1340], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,783 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,783 - train - INFO - True
2024-04-06 22:46:03,784 - train - INFO - alphas:tensor([0.5089, 0.0842, 0.0905, 0.1153, 0.2010], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:46:03,862 - train - INFO - tau:0.9135172474836407
2024-04-06 22:46:03,862 - train - INFO - avg block size:7.363636363636363
2024-04-06 22:46:03,862 - train - INFO - current latency ratio:tensor(0.3892)
2024-04-06 22:46:04,068 - train - INFO - Test: [   0/78]  Time: 0.202 (0.202)  Loss:  1.0371 (1.0371)  Acc@1: 78.9062 (78.9062)  Acc@5: 91.4062 (91.4062)
2024-04-06 22:46:06,991 - train - INFO - Test: [  50/78]  Time: 0.050 (0.061)  Loss:  2.0684 (1.8074)  Acc@1: 53.1250 (58.8848)  Acc@5: 71.0938 (82.1998)
2024-04-06 22:46:08,534 - train - INFO - Test: [  78/78]  Time: 0.053 (0.059)  Loss:  2.0664 (1.8181)  Acc@1: 56.2500 (58.7100)  Acc@5: 87.5000 (82.0900)
2024-04-06 22:46:09,217 - train - INFO - Train: 12 [   0/781 (  0%)]  Loss:  4.005041 (4.0050)  Time: 0.596s,  214.74/s  (0.596s,  214.74/s)  LR: 4.923e-04  Data: 0.153 (0.153)
2024-04-06 22:46:32,253 - train - INFO - Train: 12 [  50/781 (  6%)]  Loss:  3.709410 (3.8959)  Time: 0.394s,  324.92/s  (0.463s,  276.25/s)  LR: 4.923e-04  Data: 0.004 (0.010)
2024-04-06 22:46:54,660 - train - INFO - Train: 12 [ 100/781 ( 13%)]  Loss:  3.850354 (3.8908)  Time: 0.462s,  277.03/s  (0.456s,  280.82/s)  LR: 4.923e-04  Data: 0.005 (0.009)
2024-04-06 22:47:18,622 - train - INFO - Train: 12 [ 150/781 ( 19%)]  Loss:  4.134482 (3.9035)  Time: 0.470s,  272.13/s  (0.464s,  276.13/s)  LR: 4.923e-04  Data: 0.006 (0.009)
2024-04-06 22:47:42,242 - train - INFO - Train: 12 [ 200/781 ( 26%)]  Loss:  3.255656 (3.8920)  Time: 0.484s,  264.34/s  (0.466s,  274.83/s)  LR: 4.923e-04  Data: 0.005 (0.008)
2024-04-06 22:48:05,304 - train - INFO - Train: 12 [ 250/781 ( 32%)]  Loss:  3.919433 (3.8904)  Time: 0.473s,  270.45/s  (0.465s,  275.36/s)  LR: 4.923e-04  Data: 0.006 (0.008)
2024-04-06 22:48:29,380 - train - INFO - Train: 12 [ 300/781 ( 38%)]  Loss:  3.597254 (3.9020)  Time: 0.513s,  249.72/s  (0.468s,  273.74/s)  LR: 4.923e-04  Data: 0.008 (0.008)
2024-04-06 22:48:52,708 - train - INFO - Train: 12 [ 350/781 ( 45%)]  Loss:  3.655203 (3.8977)  Time: 0.503s,  254.40/s  (0.467s,  273.83/s)  LR: 4.923e-04  Data: 0.008 (0.008)
2024-04-06 22:49:16,815 - train - INFO - Train: 12 [ 400/781 ( 51%)]  Loss:  3.531486 (3.8952)  Time: 0.517s,  247.46/s  (0.469s,  272.76/s)  LR: 4.923e-04  Data: 0.009 (0.008)
2024-04-06 22:49:40,196 - train - INFO - Train: 12 [ 450/781 ( 58%)]  Loss:  4.247272 (3.8891)  Time: 0.382s,  334.68/s  (0.469s,  272.87/s)  LR: 4.923e-04  Data: 0.004 (0.008)
2024-04-06 22:50:03,473 - train - INFO - Train: 12 [ 500/781 ( 64%)]  Loss:  3.493541 (3.8936)  Time: 0.464s,  275.99/s  (0.469s,  273.08/s)  LR: 4.923e-04  Data: 0.006 (0.008)
2024-04-06 22:50:26,539 - train - INFO - Train: 12 [ 550/781 ( 71%)]  Loss:  3.678460 (3.8929)  Time: 0.482s,  265.67/s  (0.468s,  273.47/s)  LR: 4.923e-04  Data: 0.008 (0.008)
2024-04-06 22:50:49,892 - train - INFO - Train: 12 [ 600/781 ( 77%)]  Loss:  3.946966 (3.8914)  Time: 0.472s,  271.30/s  (0.468s,  273.52/s)  LR: 4.923e-04  Data: 0.008 (0.008)
2024-04-06 22:51:13,155 - train - INFO - Train: 12 [ 650/781 ( 83%)]  Loss:  3.674411 (3.8914)  Time: 0.455s,  281.36/s  (0.468s,  273.65/s)  LR: 4.923e-04  Data: 0.008 (0.008)
2024-04-06 22:51:36,424 - train - INFO - Train: 12 [ 700/781 ( 90%)]  Loss:  4.057322 (3.8883)  Time: 0.482s,  265.83/s  (0.468s,  273.75/s)  LR: 4.923e-04  Data: 0.013 (0.008)
2024-04-06 22:52:00,182 - train - INFO - Train: 12 [ 750/781 ( 96%)]  Loss:  4.234576 (3.8844)  Time: 0.537s,  238.18/s  (0.468s,  273.45/s)  LR: 4.923e-04  Data: 0.009 (0.008)
2024-04-06 22:52:14,355 - train - INFO - Train: 12 [ 780/781 (100%)]  Loss:  4.182795 (3.8835)  Time: 0.455s,  281.53/s  (0.468s,  273.36/s)  LR: 4.923e-04  Data: 0.000 (0.008)
2024-04-06 22:52:14,355 - train - INFO - True
2024-04-06 22:52:14,357 - train - INFO - alphas:tensor([0.3115, 0.1604, 0.1603, 0.1776, 0.1902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,357 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,357 - train - INFO - True
2024-04-06 22:52:14,358 - train - INFO - alphas:tensor([0.3651, 0.1389, 0.1439, 0.1620, 0.1901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,359 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,359 - train - INFO - True
2024-04-06 22:52:14,360 - train - INFO - alphas:tensor([0.4073, 0.1654, 0.1895, 0.2378], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,361 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,361 - train - INFO - True
2024-04-06 22:52:14,362 - train - INFO - alphas:tensor([0.3931, 0.1620, 0.1862, 0.2587], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,362 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,362 - train - INFO - True
2024-04-06 22:52:14,363 - train - INFO - alphas:tensor([0.3882, 0.1597, 0.1890, 0.2631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,364 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,364 - train - INFO - True
2024-04-06 22:52:14,365 - train - INFO - alphas:tensor([0.4371, 0.1592, 0.1766, 0.2272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,366 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,366 - train - INFO - True
2024-04-06 22:52:14,367 - train - INFO - alphas:tensor([0.4263, 0.1329, 0.1299, 0.1429, 0.1680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,368 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,368 - train - INFO - True
2024-04-06 22:52:14,369 - train - INFO - alphas:tensor([0.2192, 0.0976, 0.1126, 0.1805, 0.3900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,370 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,370 - train - INFO - True
2024-04-06 22:52:14,371 - train - INFO - alphas:tensor([0.2334, 0.0954, 0.1135, 0.1727, 0.3850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,371 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,372 - train - INFO - True
2024-04-06 22:52:14,372 - train - INFO - alphas:tensor([0.2265, 0.0895, 0.1063, 0.1748, 0.4028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,373 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,373 - train - INFO - True
2024-04-06 22:52:14,374 - train - INFO - alphas:tensor([0.2123, 0.0918, 0.1092, 0.1815, 0.4052], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,375 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,375 - train - INFO - True
2024-04-06 22:52:14,376 - train - INFO - alphas:tensor([0.4518, 0.1146, 0.1225, 0.1406, 0.1705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,377 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,377 - train - INFO - True
2024-04-06 22:52:14,378 - train - INFO - alphas:tensor([0.4947, 0.1157, 0.1125, 0.1245, 0.1527], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,381 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,382 - train - INFO - True
2024-04-06 22:52:14,383 - train - INFO - alphas:tensor([0.2169, 0.0918, 0.1042, 0.1747, 0.4125], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,384 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,385 - train - INFO - True
2024-04-06 22:52:14,385 - train - INFO - alphas:tensor([0.2297, 0.0887, 0.1044, 0.1751, 0.4021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,387 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,387 - train - INFO - True
2024-04-06 22:52:14,388 - train - INFO - alphas:tensor([0.2501, 0.0866, 0.1028, 0.1673, 0.3932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,390 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,390 - train - INFO - True
2024-04-06 22:52:14,391 - train - INFO - alphas:tensor([0.2169, 0.0906, 0.1031, 0.1649, 0.4246], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,393 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,393 - train - INFO - True
2024-04-06 22:52:14,394 - train - INFO - alphas:tensor([0.2503, 0.0847, 0.1014, 0.1644, 0.3992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,396 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,396 - train - INFO - True
2024-04-06 22:52:14,397 - train - INFO - alphas:tensor([0.2004, 0.0903, 0.1071, 0.1794, 0.4227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,399 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,399 - train - INFO - True
2024-04-06 22:52:14,400 - train - INFO - alphas:tensor([0.5214, 0.0986, 0.1013, 0.1234, 0.1554], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,404 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,404 - train - INFO - True
2024-04-06 22:52:14,405 - train - INFO - alphas:tensor([0.4792, 0.0979, 0.1015, 0.1283, 0.1931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,412 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,412 - train - INFO - True
2024-04-06 22:52:14,413 - train - INFO - alphas:tensor([0.3623, 0.0885, 0.0992, 0.1461, 0.3040], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,420 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,420 - train - INFO - True
2024-04-06 22:52:14,421 - train - INFO - alphas:tensor([0.3772, 0.0899, 0.0973, 0.1435, 0.2920], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,429 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,429 - train - INFO - True
2024-04-06 22:52:14,430 - train - INFO - alphas:tensor([0.3931, 0.0863, 0.0953, 0.1404, 0.2848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,437 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,437 - train - INFO - True
2024-04-06 22:52:14,438 - train - INFO - alphas:tensor([0.3521, 0.0866, 0.0984, 0.1450, 0.3180], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,446 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,446 - train - INFO - True
2024-04-06 22:52:14,447 - train - INFO - alphas:tensor([0.5088, 0.0862, 0.0957, 0.1192, 0.1900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,454 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,454 - train - INFO - True
2024-04-06 22:52:14,455 - train - INFO - alphas:tensor([0.5982, 0.0824, 0.0875, 0.1003, 0.1316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,475 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,475 - train - INFO - True
2024-04-06 22:52:14,476 - train - INFO - alphas:tensor([0.3016, 0.0656, 0.0781, 0.1319, 0.4227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,486 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,486 - train - INFO - True
2024-04-06 22:52:14,487 - train - INFO - alphas:tensor([0.3146, 0.0642, 0.0771, 0.1291, 0.4150], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,497 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,497 - train - INFO - True
2024-04-06 22:52:14,498 - train - INFO - alphas:tensor([0.3391, 0.0673, 0.0760, 0.1274, 0.3901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,508 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,508 - train - INFO - True
2024-04-06 22:52:14,509 - train - INFO - alphas:tensor([0.3009, 0.0678, 0.0767, 0.1341, 0.4205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,519 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,520 - train - INFO - True
2024-04-06 22:52:14,521 - train - INFO - alphas:tensor([0.6138, 0.0743, 0.0804, 0.0951, 0.1364], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,540 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,540 - train - INFO - True
2024-04-06 22:52:14,541 - train - INFO - alphas:tensor([0.5139, 0.0756, 0.0817, 0.1114, 0.2173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:52:14,619 - train - INFO - tau:0.9043820750088043
2024-04-06 22:52:14,619 - train - INFO - avg block size:7.363636363636363
2024-04-06 22:52:14,619 - train - INFO - current latency ratio:tensor(0.3892)
2024-04-06 22:52:14,619 - train - INFO - lasso_alpha:2.9282000000000012e-05
2024-04-06 22:52:14,857 - train - INFO - Test: [   0/78]  Time: 0.234 (0.234)  Loss:  1.3779 (1.3779)  Acc@1: 70.3125 (70.3125)  Acc@5: 89.8438 (89.8438)
2024-04-06 22:52:18,331 - train - INFO - Test: [  50/78]  Time: 0.056 (0.073)  Loss:  2.0566 (1.8583)  Acc@1: 56.2500 (58.0423)  Acc@5: 76.5625 (80.9896)
2024-04-06 22:52:19,858 - train - INFO - Test: [  78/78]  Time: 0.053 (0.066)  Loss:  2.2012 (1.8648)  Acc@1: 56.2500 (57.7000)  Acc@5: 81.2500 (81.0000)
2024-04-06 22:52:20,530 - train - INFO - Train: 13 [   0/781 (  0%)]  Loss:  3.682652 (3.6827)  Time: 0.590s,  216.92/s  (0.590s,  216.92/s)  LR: 4.910e-04  Data: 0.203 (0.203)
2024-04-06 22:52:44,198 - train - INFO - Train: 13 [  50/781 (  6%)]  Loss:  3.636818 (3.9254)  Time: 0.457s,  280.23/s  (0.476s,  269.11/s)  LR: 4.910e-04  Data: 0.015 (0.011)
2024-04-06 22:53:07,686 - train - INFO - Train: 13 [ 100/781 ( 13%)]  Loss:  3.951977 (3.9021)  Time: 0.404s,  316.87/s  (0.473s,  270.78/s)  LR: 4.910e-04  Data: 0.006 (0.009)
2024-04-06 22:53:30,782 - train - INFO - Train: 13 [ 150/781 ( 19%)]  Loss:  3.492332 (3.8783)  Time: 0.483s,  264.76/s  (0.469s,  272.85/s)  LR: 4.910e-04  Data: 0.009 (0.009)
2024-04-06 22:53:54,375 - train - INFO - Train: 13 [ 200/781 ( 26%)]  Loss:  3.841807 (3.8766)  Time: 0.460s,  278.01/s  (0.470s,  272.46/s)  LR: 4.910e-04  Data: 0.006 (0.009)
2024-04-06 22:54:17,531 - train - INFO - Train: 13 [ 250/781 ( 32%)]  Loss:  4.149150 (3.8829)  Time: 0.500s,  256.19/s  (0.468s,  273.24/s)  LR: 4.910e-04  Data: 0.008 (0.008)
2024-04-06 22:54:41,532 - train - INFO - Train: 13 [ 300/781 ( 38%)]  Loss:  4.031031 (3.8846)  Time: 0.440s,  291.10/s  (0.470s,  272.12/s)  LR: 4.910e-04  Data: 0.005 (0.008)
2024-04-06 22:55:04,175 - train - INFO - Train: 13 [ 350/781 ( 45%)]  Loss:  4.171833 (3.8817)  Time: 0.421s,  303.85/s  (0.468s,  273.58/s)  LR: 4.910e-04  Data: 0.005 (0.008)
2024-04-06 22:55:27,523 - train - INFO - Train: 13 [ 400/781 ( 51%)]  Loss:  3.818370 (3.8828)  Time: 0.484s,  264.45/s  (0.468s,  273.65/s)  LR: 4.910e-04  Data: 0.006 (0.008)
2024-04-06 22:55:50,698 - train - INFO - Train: 13 [ 450/781 ( 58%)]  Loss:  3.808267 (3.8848)  Time: 0.461s,  277.55/s  (0.467s,  273.92/s)  LR: 4.910e-04  Data: 0.009 (0.008)
2024-04-06 22:56:13,944 - train - INFO - Train: 13 [ 500/781 ( 64%)]  Loss:  3.568133 (3.8841)  Time: 0.472s,  271.07/s  (0.467s,  274.06/s)  LR: 4.910e-04  Data: 0.008 (0.008)
2024-04-06 22:56:38,588 - train - INFO - Train: 13 [ 550/781 ( 71%)]  Loss:  3.765670 (3.8810)  Time: 0.490s,  261.18/s  (0.469s,  272.70/s)  LR: 4.910e-04  Data: 0.005 (0.008)
2024-04-06 22:57:01,924 - train - INFO - Train: 13 [ 600/781 ( 77%)]  Loss:  3.669397 (3.8795)  Time: 0.394s,  324.48/s  (0.469s,  272.83/s)  LR: 4.910e-04  Data: 0.004 (0.008)
2024-04-06 22:57:24,825 - train - INFO - Train: 13 [ 650/781 ( 83%)]  Loss:  3.828403 (3.8777)  Time: 0.526s,  243.25/s  (0.468s,  273.33/s)  LR: 4.910e-04  Data: 0.008 (0.008)
2024-04-06 22:57:48,714 - train - INFO - Train: 13 [ 700/781 ( 90%)]  Loss:  4.131897 (3.8779)  Time: 0.457s,  280.03/s  (0.469s,  272.93/s)  LR: 4.910e-04  Data: 0.005 (0.008)
2024-04-06 22:58:12,411 - train - INFO - Train: 13 [ 750/781 ( 96%)]  Loss:  4.140522 (3.8800)  Time: 0.476s,  268.72/s  (0.469s,  272.74/s)  LR: 4.910e-04  Data: 0.007 (0.008)
2024-04-06 22:58:26,269 - train - INFO - Train: 13 [ 780/781 (100%)]  Loss:  4.098360 (3.8804)  Time: 0.475s,  269.30/s  (0.469s,  272.91/s)  LR: 4.910e-04  Data: 0.000 (0.008)
2024-04-06 22:58:26,271 - train - INFO - True
2024-04-06 22:58:26,273 - train - INFO - alphas:tensor([0.3225, 0.1578, 0.1562, 0.1748, 0.1887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,274 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,274 - train - INFO - True
2024-04-06 22:58:26,275 - train - INFO - alphas:tensor([0.3753, 0.1334, 0.1387, 0.1599, 0.1927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,276 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,276 - train - INFO - True
2024-04-06 22:58:26,277 - train - INFO - alphas:tensor([0.4105, 0.1608, 0.1852, 0.2435], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,279 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,279 - train - INFO - True
2024-04-06 22:58:26,280 - train - INFO - alphas:tensor([0.3929, 0.1572, 0.1833, 0.2667], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,281 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,281 - train - INFO - True
2024-04-06 22:58:26,283 - train - INFO - alphas:tensor([0.3892, 0.1520, 0.1860, 0.2727], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,284 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,284 - train - INFO - True
2024-04-06 22:58:26,285 - train - INFO - alphas:tensor([0.4432, 0.1543, 0.1718, 0.2308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,286 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,287 - train - INFO - True
2024-04-06 22:58:26,288 - train - INFO - alphas:tensor([0.4399, 0.1275, 0.1246, 0.1397, 0.1683], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,289 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,290 - train - INFO - True
2024-04-06 22:58:26,291 - train - INFO - alphas:tensor([0.2061, 0.0894, 0.1046, 0.1757, 0.4242], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,292 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,292 - train - INFO - True
2024-04-06 22:58:26,293 - train - INFO - alphas:tensor([0.2203, 0.0854, 0.1044, 0.1677, 0.4222], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,294 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,294 - train - INFO - True
2024-04-06 22:58:26,296 - train - INFO - alphas:tensor([0.2157, 0.0817, 0.0973, 0.1662, 0.4391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,296 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,297 - train - INFO - True
2024-04-06 22:58:26,298 - train - INFO - alphas:tensor([0.1993, 0.0830, 0.1011, 0.1761, 0.4406], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,299 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,299 - train - INFO - True
2024-04-06 22:58:26,300 - train - INFO - alphas:tensor([0.4668, 0.1091, 0.1167, 0.1358, 0.1715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,301 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,302 - train - INFO - True
2024-04-06 22:58:26,303 - train - INFO - alphas:tensor([0.5085, 0.1112, 0.1077, 0.1206, 0.1521], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,307 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,308 - train - INFO - True
2024-04-06 22:58:26,309 - train - INFO - alphas:tensor([0.2052, 0.0848, 0.0974, 0.1693, 0.4432], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,311 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,311 - train - INFO - True
2024-04-06 22:58:26,312 - train - INFO - alphas:tensor([0.2194, 0.0812, 0.0958, 0.1705, 0.4330], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,315 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,315 - train - INFO - True
2024-04-06 22:58:26,316 - train - INFO - alphas:tensor([0.2359, 0.0790, 0.0958, 0.1644, 0.4250], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,318 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,319 - train - INFO - True
2024-04-06 22:58:26,320 - train - INFO - alphas:tensor([0.2067, 0.0837, 0.0951, 0.1602, 0.4543], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,322 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,322 - train - INFO - True
2024-04-06 22:58:26,323 - train - INFO - alphas:tensor([0.2446, 0.0764, 0.0938, 0.1595, 0.4256], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,325 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,326 - train - INFO - True
2024-04-06 22:58:26,327 - train - INFO - alphas:tensor([0.1902, 0.0835, 0.0993, 0.1752, 0.4517], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,329 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,329 - train - INFO - True
2024-04-06 22:58:26,330 - train - INFO - alphas:tensor([0.5310, 0.0924, 0.0963, 0.1200, 0.1603], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,334 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,334 - train - INFO - True
2024-04-06 22:58:26,335 - train - INFO - alphas:tensor([0.4802, 0.0916, 0.0953, 0.1266, 0.2062], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,343 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,343 - train - INFO - True
2024-04-06 22:58:26,344 - train - INFO - alphas:tensor([0.3507, 0.0803, 0.0932, 0.1454, 0.3304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,352 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,352 - train - INFO - True
2024-04-06 22:58:26,353 - train - INFO - alphas:tensor([0.3651, 0.0828, 0.0907, 0.1403, 0.3211], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,361 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,361 - train - INFO - True
2024-04-06 22:58:26,362 - train - INFO - alphas:tensor([0.3757, 0.0795, 0.0901, 0.1394, 0.3153], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,369 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,369 - train - INFO - True
2024-04-06 22:58:26,370 - train - INFO - alphas:tensor([0.3446, 0.0796, 0.0924, 0.1406, 0.3427], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,378 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,378 - train - INFO - True
2024-04-06 22:58:26,379 - train - INFO - alphas:tensor([0.5069, 0.0793, 0.0900, 0.1172, 0.2066], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,386 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,386 - train - INFO - True
2024-04-06 22:58:26,387 - train - INFO - alphas:tensor([0.6107, 0.0760, 0.0818, 0.0966, 0.1348], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,406 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,406 - train - INFO - True
2024-04-06 22:58:26,407 - train - INFO - alphas:tensor([0.2936, 0.0591, 0.0712, 0.1260, 0.4501], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,417 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,418 - train - INFO - True
2024-04-06 22:58:26,418 - train - INFO - alphas:tensor([0.3038, 0.0576, 0.0693, 0.1247, 0.4446], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,429 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,429 - train - INFO - True
2024-04-06 22:58:26,430 - train - INFO - alphas:tensor([0.3272, 0.0595, 0.0685, 0.1235, 0.4213], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,440 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,440 - train - INFO - True
2024-04-06 22:58:26,441 - train - INFO - alphas:tensor([0.2875, 0.0608, 0.0706, 0.1288, 0.4523], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,451 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,451 - train - INFO - True
2024-04-06 22:58:26,452 - train - INFO - alphas:tensor([0.6265, 0.0669, 0.0744, 0.0905, 0.1416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,471 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,471 - train - INFO - True
2024-04-06 22:58:26,472 - train - INFO - alphas:tensor([0.4982, 0.0705, 0.0767, 0.1099, 0.2447], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:58:26,550 - train - INFO - tau:0.8953382542587163
2024-04-06 22:58:26,550 - train - INFO - avg block size:7.363636363636363
2024-04-06 22:58:26,550 - train - INFO - current latency ratio:tensor(0.3892)
2024-04-06 22:58:26,729 - train - INFO - Test: [   0/78]  Time: 0.174 (0.174)  Loss:  1.3232 (1.3232)  Acc@1: 71.0938 (71.0938)  Acc@5: 91.4062 (91.4062)
2024-04-06 22:58:29,716 - train - INFO - Test: [  50/78]  Time: 0.054 (0.062)  Loss:  1.8096 (1.8790)  Acc@1: 61.7188 (58.3640)  Acc@5: 85.1562 (81.9700)
2024-04-06 22:58:31,242 - train - INFO - Test: [  78/78]  Time: 0.047 (0.059)  Loss:  1.9072 (1.8893)  Acc@1: 56.2500 (58.2500)  Acc@5: 87.5000 (81.8800)
2024-04-06 22:58:31,997 - train - INFO - Train: 14 [   0/781 (  0%)]  Loss:  3.927107 (3.9271)  Time: 0.666s,  192.18/s  (0.666s,  192.18/s)  LR: 4.895e-04  Data: 0.194 (0.194)
2024-04-06 22:58:55,682 - train - INFO - Train: 14 [  50/781 (  6%)]  Loss:  3.516783 (3.8778)  Time: 0.491s,  260.43/s  (0.477s,  268.10/s)  LR: 4.895e-04  Data: 0.007 (0.011)
2024-04-06 22:59:18,910 - train - INFO - Train: 14 [ 100/781 ( 13%)]  Loss:  3.780839 (3.8626)  Time: 0.482s,  265.69/s  (0.471s,  271.74/s)  LR: 4.895e-04  Data: 0.006 (0.009)
2024-04-06 22:59:42,625 - train - INFO - Train: 14 [ 150/781 ( 19%)]  Loss:  3.899297 (3.8633)  Time: 0.509s,  251.64/s  (0.472s,  271.12/s)  LR: 4.895e-04  Data: 0.009 (0.009)
2024-04-06 23:00:04,734 - train - INFO - Train: 14 [ 200/781 ( 26%)]  Loss:  3.901707 (3.8766)  Time: 0.458s,  279.71/s  (0.465s,  275.47/s)  LR: 4.895e-04  Data: 0.007 (0.008)
2024-04-06 23:00:28,691 - train - INFO - Train: 14 [ 250/781 ( 32%)]  Loss:  3.779016 (3.8888)  Time: 0.477s,  268.49/s  (0.468s,  273.77/s)  LR: 4.895e-04  Data: 0.008 (0.008)
2024-04-06 23:00:52,213 - train - INFO - Train: 14 [ 300/781 ( 38%)]  Loss:  3.463789 (3.8925)  Time: 0.511s,  250.27/s  (0.468s,  273.50/s)  LR: 4.895e-04  Data: 0.008 (0.008)
2024-04-06 23:01:16,038 - train - INFO - Train: 14 [ 350/781 ( 45%)]  Loss:  4.061937 (3.8908)  Time: 0.529s,  242.02/s  (0.469s,  272.79/s)  LR: 4.895e-04  Data: 0.008 (0.008)
2024-04-06 23:01:40,864 - train - INFO - Train: 14 [ 400/781 ( 51%)]  Loss:  3.443206 (3.8923)  Time: 0.519s,  246.44/s  (0.473s,  270.83/s)  LR: 4.895e-04  Data: 0.009 (0.008)
2024-04-06 23:02:05,578 - train - INFO - Train: 14 [ 450/781 ( 58%)]  Loss:  3.546088 (3.8895)  Time: 0.520s,  246.31/s  (0.475s,  269.46/s)  LR: 4.895e-04  Data: 0.005 (0.008)
2024-04-06 23:02:29,785 - train - INFO - Train: 14 [ 500/781 ( 64%)]  Loss:  3.754130 (3.8893)  Time: 0.492s,  260.23/s  (0.476s,  268.95/s)  LR: 4.895e-04  Data: 0.008 (0.008)
2024-04-06 23:02:55,177 - train - INFO - Train: 14 [ 550/781 ( 71%)]  Loss:  3.921395 (3.8905)  Time: 0.327s,  391.46/s  (0.479s,  267.33/s)  LR: 4.895e-04  Data: 0.004 (0.008)
2024-04-06 23:03:18,923 - train - INFO - Train: 14 [ 600/781 ( 77%)]  Loss:  3.776328 (3.8854)  Time: 0.533s,  240.17/s  (0.478s,  267.51/s)  LR: 4.895e-04  Data: 0.008 (0.008)
2024-04-06 23:03:43,662 - train - INFO - Train: 14 [ 650/781 ( 83%)]  Loss:  4.074683 (3.8869)  Time: 0.513s,  249.36/s  (0.480s,  266.81/s)  LR: 4.895e-04  Data: 0.007 (0.008)
2024-04-06 23:04:08,411 - train - INFO - Train: 14 [ 700/781 ( 90%)]  Loss:  3.772834 (3.8864)  Time: 0.498s,  257.26/s  (0.481s,  266.21/s)  LR: 4.895e-04  Data: 0.007 (0.008)
2024-04-06 23:04:33,168 - train - INFO - Train: 14 [ 750/781 ( 96%)]  Loss:  3.944034 (3.8854)  Time: 0.498s,  257.14/s  (0.482s,  265.68/s)  LR: 4.895e-04  Data: 0.007 (0.008)
2024-04-06 23:04:47,330 - train - INFO - Train: 14 [ 780/781 (100%)]  Loss:  3.606929 (3.8850)  Time: 0.456s,  280.45/s  (0.481s,  265.89/s)  LR: 4.895e-04  Data: 0.000 (0.008)
2024-04-06 23:04:47,331 - train - INFO - True
2024-04-06 23:04:47,333 - train - INFO - alphas:tensor([0.3328, 0.1539, 0.1531, 0.1722, 0.1880], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,334 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,334 - train - INFO - True
2024-04-06 23:04:47,336 - train - INFO - alphas:tensor([0.3857, 0.1279, 0.1353, 0.1575, 0.1936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,336 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,336 - train - INFO - True
2024-04-06 23:04:47,338 - train - INFO - alphas:tensor([0.4190, 0.1546, 0.1816, 0.2448], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,339 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,339 - train - INFO - True
2024-04-06 23:04:47,340 - train - INFO - alphas:tensor([0.3910, 0.1487, 0.1805, 0.2798], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,341 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,341 - train - INFO - True
2024-04-06 23:04:47,343 - train - INFO - alphas:tensor([0.3871, 0.1449, 0.1832, 0.2848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,344 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,344 - train - INFO - True
2024-04-06 23:04:47,345 - train - INFO - alphas:tensor([0.4476, 0.1482, 0.1683, 0.2360], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,346 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,346 - train - INFO - True
2024-04-06 23:04:47,348 - train - INFO - alphas:tensor([0.4524, 0.1224, 0.1201, 0.1365, 0.1687], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,349 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,349 - train - INFO - True
2024-04-06 23:04:47,350 - train - INFO - alphas:tensor([0.1983, 0.0810, 0.0973, 0.1688, 0.4547], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,351 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,352 - train - INFO - True
2024-04-06 23:04:47,353 - train - INFO - alphas:tensor([0.2130, 0.0792, 0.0963, 0.1625, 0.4489], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,354 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,354 - train - INFO - True
2024-04-06 23:04:47,355 - train - INFO - alphas:tensor([0.2091, 0.0750, 0.0900, 0.1595, 0.4665], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,356 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,356 - train - INFO - True
2024-04-06 23:04:47,357 - train - INFO - alphas:tensor([0.1936, 0.0773, 0.0943, 0.1696, 0.4652], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,358 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,358 - train - INFO - True
2024-04-06 23:04:47,359 - train - INFO - alphas:tensor([0.4776, 0.1037, 0.1118, 0.1330, 0.1740], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,361 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,361 - train - INFO - True
2024-04-06 23:04:47,362 - train - INFO - alphas:tensor([0.5222, 0.1055, 0.1027, 0.1169, 0.1526], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,367 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,367 - train - INFO - True
2024-04-06 23:04:47,368 - train - INFO - alphas:tensor([0.1973, 0.0806, 0.0923, 0.1660, 0.4637], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,370 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,370 - train - INFO - True
2024-04-06 23:04:47,371 - train - INFO - alphas:tensor([0.2166, 0.0749, 0.0878, 0.1662, 0.4545], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,374 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,374 - train - INFO - True
2024-04-06 23:04:47,375 - train - INFO - alphas:tensor([0.2337, 0.0721, 0.0884, 0.1583, 0.4476], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,377 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,377 - train - INFO - True
2024-04-06 23:04:47,378 - train - INFO - alphas:tensor([0.2029, 0.0776, 0.0889, 0.1542, 0.4763], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,381 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,381 - train - INFO - True
2024-04-06 23:04:47,382 - train - INFO - alphas:tensor([0.2383, 0.0705, 0.0873, 0.1543, 0.4496], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,384 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,384 - train - INFO - True
2024-04-06 23:04:47,385 - train - INFO - alphas:tensor([0.1848, 0.0778, 0.0937, 0.1671, 0.4767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,387 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,387 - train - INFO - True
2024-04-06 23:04:47,388 - train - INFO - alphas:tensor([0.5431, 0.0872, 0.0897, 0.1162, 0.1638], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,392 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,392 - train - INFO - True
2024-04-06 23:04:47,393 - train - INFO - alphas:tensor([0.4798, 0.0849, 0.0902, 0.1252, 0.2199], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,401 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,401 - train - INFO - True
2024-04-06 23:04:47,402 - train - INFO - alphas:tensor([0.3436, 0.0747, 0.0874, 0.1407, 0.3535], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,406 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,407 - train - INFO - True
2024-04-06 23:04:47,408 - train - INFO - alphas:tensor([0.3583, 0.0759, 0.0854, 0.1368, 0.3437], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,415 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,415 - train - INFO - True
2024-04-06 23:04:47,416 - train - INFO - alphas:tensor([0.3740, 0.0720, 0.0830, 0.1361, 0.3348], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,423 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,423 - train - INFO - True
2024-04-06 23:04:47,424 - train - INFO - alphas:tensor([0.3335, 0.0730, 0.0852, 0.1375, 0.3708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,428 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,428 - train - INFO - True
2024-04-06 23:04:47,429 - train - INFO - alphas:tensor([0.5025, 0.0727, 0.0843, 0.1162, 0.2243], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,436 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,436 - train - INFO - True
2024-04-06 23:04:47,437 - train - INFO - alphas:tensor([0.6197, 0.0705, 0.0769, 0.0938, 0.1391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,454 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,454 - train - INFO - True
2024-04-06 23:04:47,455 - train - INFO - alphas:tensor([0.2865, 0.0541, 0.0666, 0.1243, 0.4684], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,463 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,463 - train - INFO - True
2024-04-06 23:04:47,464 - train - INFO - alphas:tensor([0.2990, 0.0529, 0.0635, 0.1196, 0.4650], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,472 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,472 - train - INFO - True
2024-04-06 23:04:47,473 - train - INFO - alphas:tensor([0.3243, 0.0544, 0.0637, 0.1185, 0.4391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,481 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,481 - train - INFO - True
2024-04-06 23:04:47,482 - train - INFO - alphas:tensor([0.2811, 0.0555, 0.0657, 0.1269, 0.4707], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,490 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,490 - train - INFO - True
2024-04-06 23:04:47,490 - train - INFO - alphas:tensor([0.6292, 0.0629, 0.0695, 0.0883, 0.1500], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,505 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,505 - train - INFO - True
2024-04-06 23:04:47,506 - train - INFO - alphas:tensor([0.4918, 0.0648, 0.0720, 0.1079, 0.2636], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:04:47,563 - train - INFO - tau:0.8863848717161291
2024-04-06 23:04:47,563 - train - INFO - avg block size:8.272727272727273
2024-04-06 23:04:47,563 - train - INFO - current latency ratio:tensor(0.3397)
2024-04-06 23:04:47,564 - train - INFO - lasso_alpha:3.221020000000002e-05
2024-04-06 23:04:47,848 - train - INFO - Test: [   0/78]  Time: 0.281 (0.281)  Loss:  1.1885 (1.1885)  Acc@1: 73.4375 (73.4375)  Acc@5: 91.4062 (91.4062)
2024-04-06 23:04:52,837 - train - INFO - Test: [  50/78]  Time: 0.146 (0.103)  Loss:  1.9648 (1.8337)  Acc@1: 52.3438 (59.0227)  Acc@5: 78.9062 (81.5564)
2024-04-06 23:04:55,309 - train - INFO - Test: [  78/78]  Time: 0.074 (0.098)  Loss:  1.9287 (1.8347)  Acc@1: 62.5000 (59.1800)  Acc@5: 93.7500 (81.6900)
2024-04-06 23:04:56,062 - train - INFO - Train: 15 [   0/781 (  0%)]  Loss:  3.672563 (3.6726)  Time: 0.669s,  191.22/s  (0.669s,  191.22/s)  LR: 4.880e-04  Data: 0.170 (0.170)
2024-04-06 23:05:21,025 - train - INFO - Train: 15 [  50/781 (  6%)]  Loss:  3.856839 (3.8480)  Time: 0.394s,  324.75/s  (0.503s,  254.70/s)  LR: 4.880e-04  Data: 0.004 (0.010)
2024-04-06 23:05:45,680 - train - INFO - Train: 15 [ 100/781 ( 13%)]  Loss:  3.705025 (3.8419)  Time: 0.444s,  288.44/s  (0.498s,  257.10/s)  LR: 4.880e-04  Data: 0.004 (0.009)
2024-04-06 23:06:10,412 - train - INFO - Train: 15 [ 150/781 ( 19%)]  Loss:  3.639515 (3.8572)  Time: 0.497s,  257.41/s  (0.497s,  257.66/s)  LR: 4.880e-04  Data: 0.009 (0.008)
2024-04-06 23:06:36,482 - train - INFO - Train: 15 [ 200/781 ( 26%)]  Loss:  4.043854 (3.8697)  Time: 0.458s,  279.21/s  (0.503s,  254.53/s)  LR: 4.880e-04  Data: 0.009 (0.008)
2024-04-06 23:07:01,530 - train - INFO - Train: 15 [ 250/781 ( 32%)]  Loss:  3.261481 (3.8672)  Time: 0.505s,  253.47/s  (0.503s,  254.72/s)  LR: 4.880e-04  Data: 0.006 (0.008)
2024-04-06 23:07:26,252 - train - INFO - Train: 15 [ 300/781 ( 38%)]  Loss:  4.233056 (3.8786)  Time: 0.507s,  252.50/s  (0.501s,  255.41/s)  LR: 4.880e-04  Data: 0.008 (0.008)
2024-04-06 23:07:51,175 - train - INFO - Train: 15 [ 350/781 ( 45%)]  Loss:  4.017208 (3.8754)  Time: 0.409s,  312.76/s  (0.501s,  255.61/s)  LR: 4.880e-04  Data: 0.009 (0.008)
2024-04-06 23:08:15,281 - train - INFO - Train: 15 [ 400/781 ( 51%)]  Loss:  3.574836 (3.8746)  Time: 0.418s,  306.12/s  (0.498s,  256.80/s)  LR: 4.880e-04  Data: 0.005 (0.008)
2024-04-06 23:08:40,684 - train - INFO - Train: 15 [ 450/781 ( 58%)]  Loss:  3.883403 (3.8839)  Time: 0.527s,  242.82/s  (0.500s,  256.25/s)  LR: 4.880e-04  Data: 0.007 (0.008)
2024-04-06 23:09:05,956 - train - INFO - Train: 15 [ 500/781 ( 64%)]  Loss:  4.092695 (3.8830)  Time: 0.494s,  259.29/s  (0.500s,  255.95/s)  LR: 4.880e-04  Data: 0.010 (0.008)
2024-04-06 23:09:30,918 - train - INFO - Train: 15 [ 550/781 ( 71%)]  Loss:  4.038800 (3.8758)  Time: 0.556s,  230.02/s  (0.500s,  255.99/s)  LR: 4.880e-04  Data: 0.010 (0.008)
2024-04-06 23:09:55,324 - train - INFO - Train: 15 [ 600/781 ( 77%)]  Loss:  3.712741 (3.8770)  Time: 0.529s,  241.74/s  (0.499s,  256.51/s)  LR: 4.880e-04  Data: 0.006 (0.008)
2024-04-06 23:10:19,259 - train - INFO - Train: 15 [ 650/781 ( 83%)]  Loss:  3.507229 (3.8777)  Time: 0.552s,  231.82/s  (0.497s,  257.31/s)  LR: 4.880e-04  Data: 0.008 (0.008)
2024-04-06 23:10:43,630 - train - INFO - Train: 15 [ 700/781 ( 90%)]  Loss:  3.718905 (3.8794)  Time: 0.540s,  237.24/s  (0.497s,  257.69/s)  LR: 4.880e-04  Data: 0.005 (0.008)
2024-04-06 23:11:07,804 - train - INFO - Train: 15 [ 750/781 ( 96%)]  Loss:  3.620989 (3.8778)  Time: 0.374s,  341.98/s  (0.496s,  258.15/s)  LR: 4.880e-04  Data: 0.004 (0.008)
2024-04-06 23:11:22,565 - train - INFO - Train: 15 [ 780/781 (100%)]  Loss:  3.603262 (3.8771)  Time: 0.479s,  267.41/s  (0.496s,  258.22/s)  LR: 4.880e-04  Data: 0.000 (0.008)
2024-04-06 23:11:22,566 - train - INFO - True
2024-04-06 23:11:22,571 - train - INFO - alphas:tensor([0.3442, 0.1503, 0.1489, 0.1695, 0.1871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,572 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,572 - train - INFO - True
2024-04-06 23:11:22,577 - train - INFO - alphas:tensor([0.3888, 0.1232, 0.1322, 0.1557, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,578 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,578 - train - INFO - True
2024-04-06 23:11:22,583 - train - INFO - alphas:tensor([0.4187, 0.1508, 0.1794, 0.2511], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,584 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,584 - train - INFO - True
2024-04-06 23:11:22,589 - train - INFO - alphas:tensor([0.3853, 0.1439, 0.1777, 0.2932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,590 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,590 - train - INFO - True
2024-04-06 23:11:22,595 - train - INFO - alphas:tensor([0.3808, 0.1387, 0.1806, 0.2999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,596 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,596 - train - INFO - True
2024-04-06 23:11:22,601 - train - INFO - alphas:tensor([0.4477, 0.1431, 0.1658, 0.2434], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,602 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,602 - train - INFO - True
2024-04-06 23:11:22,607 - train - INFO - alphas:tensor([0.4598, 0.1176, 0.1166, 0.1344, 0.1715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,608 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,608 - train - INFO - True
2024-04-06 23:11:22,613 - train - INFO - alphas:tensor([0.1900, 0.0741, 0.0900, 0.1619, 0.4839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,614 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,614 - train - INFO - True
2024-04-06 23:11:22,619 - train - INFO - alphas:tensor([0.2046, 0.0722, 0.0889, 0.1559, 0.4784], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,620 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,620 - train - INFO - True
2024-04-06 23:11:22,624 - train - INFO - alphas:tensor([0.1982, 0.0688, 0.0832, 0.1530, 0.4968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,625 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,625 - train - INFO - True
2024-04-06 23:11:22,627 - train - INFO - alphas:tensor([0.1849, 0.0698, 0.0867, 0.1632, 0.4955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,628 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,628 - train - INFO - True
2024-04-06 23:11:22,632 - train - INFO - alphas:tensor([0.4822, 0.0997, 0.1079, 0.1307, 0.1795], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,633 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,633 - train - INFO - True
2024-04-06 23:11:22,637 - train - INFO - alphas:tensor([0.5340, 0.0997, 0.0987, 0.1137, 0.1538], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,641 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,641 - train - INFO - True
2024-04-06 23:11:22,642 - train - INFO - alphas:tensor([0.1911, 0.0744, 0.0853, 0.1620, 0.4872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,644 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,644 - train - INFO - True
2024-04-06 23:11:22,645 - train - INFO - alphas:tensor([0.2073, 0.0691, 0.0819, 0.1611, 0.4806], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,647 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,647 - train - INFO - True
2024-04-06 23:11:22,648 - train - INFO - alphas:tensor([0.2282, 0.0661, 0.0820, 0.1519, 0.4717], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,650 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,650 - train - INFO - True
2024-04-06 23:11:22,651 - train - INFO - alphas:tensor([0.1928, 0.0717, 0.0839, 0.1517, 0.4999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,653 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,653 - train - INFO - True
2024-04-06 23:11:22,654 - train - INFO - alphas:tensor([0.2241, 0.0647, 0.0825, 0.1529, 0.4758], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,656 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,656 - train - INFO - True
2024-04-06 23:11:22,657 - train - INFO - alphas:tensor([0.1765, 0.0735, 0.0884, 0.1634, 0.4982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,659 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,659 - train - INFO - True
2024-04-06 23:11:22,660 - train - INFO - alphas:tensor([0.5466, 0.0822, 0.0849, 0.1141, 0.1722], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,663 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,663 - train - INFO - True
2024-04-06 23:11:22,664 - train - INFO - alphas:tensor([0.4753, 0.0790, 0.0857, 0.1238, 0.2362], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,672 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,672 - train - INFO - True
2024-04-06 23:11:22,673 - train - INFO - alphas:tensor([0.3354, 0.0687, 0.0816, 0.1372, 0.3772], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,677 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,677 - train - INFO - True
2024-04-06 23:11:22,678 - train - INFO - alphas:tensor([0.3481, 0.0700, 0.0798, 0.1326, 0.3695], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,681 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,682 - train - INFO - True
2024-04-06 23:11:22,683 - train - INFO - alphas:tensor([0.3621, 0.0663, 0.0761, 0.1333, 0.3622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,686 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,686 - train - INFO - True
2024-04-06 23:11:22,687 - train - INFO - alphas:tensor([0.3247, 0.0657, 0.0793, 0.1339, 0.3964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,691 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,691 - train - INFO - True
2024-04-06 23:11:22,692 - train - INFO - alphas:tensor([0.4997, 0.0679, 0.0798, 0.1122, 0.2404], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,700 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,700 - train - INFO - True
2024-04-06 23:11:22,701 - train - INFO - alphas:tensor([0.6231, 0.0655, 0.0726, 0.0917, 0.1471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,720 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,720 - train - INFO - True
2024-04-06 23:11:22,721 - train - INFO - alphas:tensor([0.2807, 0.0507, 0.0620, 0.1235, 0.4831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,731 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,731 - train - INFO - True
2024-04-06 23:11:22,732 - train - INFO - alphas:tensor([0.2897, 0.0481, 0.0583, 0.1176, 0.4862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,742 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,742 - train - INFO - True
2024-04-06 23:11:22,743 - train - INFO - alphas:tensor([0.3180, 0.0489, 0.0587, 0.1148, 0.4595], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,753 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,753 - train - INFO - True
2024-04-06 23:11:22,754 - train - INFO - alphas:tensor([0.2734, 0.0510, 0.0607, 0.1240, 0.4910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,764 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,764 - train - INFO - True
2024-04-06 23:11:22,765 - train - INFO - alphas:tensor([0.6289, 0.0575, 0.0654, 0.0862, 0.1620], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,785 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,785 - train - INFO - True
2024-04-06 23:11:22,786 - train - INFO - alphas:tensor([0.4825, 0.0606, 0.0684, 0.1067, 0.2817], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:11:22,864 - train - INFO - tau:0.8775210229989678
2024-04-06 23:11:22,864 - train - INFO - avg block size:9.181818181818182
2024-04-06 23:11:22,865 - train - INFO - current latency ratio:tensor(0.2902)
2024-04-06 23:11:23,168 - train - INFO - Test: [   0/78]  Time: 0.300 (0.300)  Loss:  1.3359 (1.3359)  Acc@1: 72.6562 (72.6562)  Acc@5: 89.0625 (89.0625)
2024-04-06 23:11:27,499 - train - INFO - Test: [  50/78]  Time: 0.108 (0.091)  Loss:  1.9326 (1.8182)  Acc@1: 55.4688 (58.4559)  Acc@5: 82.8125 (82.9810)
2024-04-06 23:11:30,165 - train - INFO - Test: [  78/78]  Time: 0.149 (0.092)  Loss:  2.0312 (1.8507)  Acc@1: 62.5000 (58.2200)  Acc@5: 93.7500 (82.3800)
2024-04-06 23:11:31,004 - train - INFO - Train: 16 [   0/781 (  0%)]  Loss:  4.104187 (4.1042)  Time: 0.699s,  183.06/s  (0.699s,  183.06/s)  LR: 4.864e-04  Data: 0.175 (0.175)
2024-04-06 23:11:55,942 - train - INFO - Train: 16 [  50/781 (  6%)]  Loss:  3.947106 (3.8996)  Time: 0.540s,  236.96/s  (0.503s,  254.65/s)  LR: 4.864e-04  Data: 0.015 (0.011)
2024-04-06 23:12:21,107 - train - INFO - Train: 16 [ 100/781 ( 13%)]  Loss:  4.107423 (3.9022)  Time: 0.526s,  243.41/s  (0.503s,  254.49/s)  LR: 4.864e-04  Data: 0.007 (0.009)
2024-04-06 23:12:45,271 - train - INFO - Train: 16 [ 150/781 ( 19%)]  Loss:  4.034774 (3.9050)  Time: 0.431s,  296.65/s  (0.496s,  257.87/s)  LR: 4.864e-04  Data: 0.007 (0.009)
2024-04-06 23:13:10,143 - train - INFO - Train: 16 [ 200/781 ( 26%)]  Loss:  3.487995 (3.9033)  Time: 0.496s,  257.97/s  (0.497s,  257.74/s)  LR: 4.864e-04  Data: 0.009 (0.008)
2024-04-06 23:13:35,569 - train - INFO - Train: 16 [ 250/781 ( 32%)]  Loss:  3.581851 (3.8889)  Time: 0.461s,  277.51/s  (0.499s,  256.52/s)  LR: 4.864e-04  Data: 0.006 (0.008)
2024-04-06 23:14:00,549 - train - INFO - Train: 16 [ 300/781 ( 38%)]  Loss:  3.854820 (3.8808)  Time: 0.393s,  325.90/s  (0.499s,  256.47/s)  LR: 4.864e-04  Data: 0.004 (0.008)
2024-04-06 23:14:24,389 - train - INFO - Train: 16 [ 350/781 ( 45%)]  Loss:  3.926234 (3.8761)  Time: 0.551s,  232.50/s  (0.496s,  258.11/s)  LR: 4.864e-04  Data: 0.006 (0.008)
2024-04-06 23:14:48,404 - train - INFO - Train: 16 [ 400/781 ( 51%)]  Loss:  4.098746 (3.8777)  Time: 0.470s,  272.33/s  (0.494s,  259.13/s)  LR: 4.864e-04  Data: 0.008 (0.008)
2024-04-06 23:15:12,036 - train - INFO - Train: 16 [ 450/781 ( 58%)]  Loss:  3.820850 (3.8778)  Time: 0.404s,  316.90/s  (0.492s,  260.38/s)  LR: 4.864e-04  Data: 0.006 (0.008)
2024-04-06 23:15:36,457 - train - INFO - Train: 16 [ 500/781 ( 64%)]  Loss:  3.935950 (3.8752)  Time: 0.523s,  244.91/s  (0.491s,  260.55/s)  LR: 4.864e-04  Data: 0.009 (0.008)
2024-04-06 23:16:01,307 - train - INFO - Train: 16 [ 550/781 ( 71%)]  Loss:  3.944623 (3.8781)  Time: 0.545s,  234.91/s  (0.492s,  260.27/s)  LR: 4.864e-04  Data: 0.009 (0.008)
2024-04-06 23:16:25,593 - train - INFO - Train: 16 [ 600/781 ( 77%)]  Loss:  3.757937 (3.8754)  Time: 0.569s,  225.03/s  (0.491s,  260.54/s)  LR: 4.864e-04  Data: 0.009 (0.008)
2024-04-06 23:16:50,199 - train - INFO - Train: 16 [ 650/781 ( 83%)]  Loss:  3.554541 (3.8727)  Time: 0.490s,  261.33/s  (0.491s,  260.51/s)  LR: 4.864e-04  Data: 0.008 (0.008)
2024-04-06 23:17:14,626 - train - INFO - Train: 16 [ 700/781 ( 90%)]  Loss:  3.940737 (3.8704)  Time: 0.444s,  287.99/s  (0.491s,  260.62/s)  LR: 4.864e-04  Data: 0.006 (0.008)
2024-04-06 23:17:40,282 - train - INFO - Train: 16 [ 750/781 ( 96%)]  Loss:  3.756214 (3.8691)  Time: 0.539s,  237.61/s  (0.493s,  259.85/s)  LR: 4.864e-04  Data: 0.008 (0.008)
2024-04-06 23:17:54,970 - train - INFO - Train: 16 [ 780/781 (100%)]  Loss:  3.761606 (3.8678)  Time: 0.388s,  329.91/s  (0.492s,  259.91/s)  LR: 4.864e-04  Data: 0.000 (0.008)
2024-04-06 23:17:54,971 - train - INFO - True
2024-04-06 23:17:54,976 - train - INFO - alphas:tensor([0.3542, 0.1476, 0.1459, 0.1666, 0.1858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:54,976 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:54,976 - train - INFO - True
2024-04-06 23:17:54,982 - train - INFO - alphas:tensor([0.3925, 0.1185, 0.1278, 0.1547, 0.2065], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:54,982 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:54,982 - train - INFO - True
2024-04-06 23:17:54,987 - train - INFO - alphas:tensor([0.4206, 0.1455, 0.1777, 0.2562], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:54,988 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:54,988 - train - INFO - True
2024-04-06 23:17:54,992 - train - INFO - alphas:tensor([0.3790, 0.1384, 0.1743, 0.3083], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:54,993 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:54,993 - train - INFO - True
2024-04-06 23:17:54,999 - train - INFO - alphas:tensor([0.3787, 0.1325, 0.1771, 0.3118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:54,999 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:54,999 - train - INFO - True
2024-04-06 23:17:55,004 - train - INFO - alphas:tensor([0.4493, 0.1381, 0.1623, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,005 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,005 - train - INFO - True
2024-04-06 23:17:55,006 - train - INFO - alphas:tensor([0.4662, 0.1134, 0.1128, 0.1325, 0.1751], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,007 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,007 - train - INFO - True
2024-04-06 23:17:55,008 - train - INFO - alphas:tensor([0.1834, 0.0697, 0.0826, 0.1569, 0.5075], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,009 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,009 - train - INFO - True
2024-04-06 23:17:55,011 - train - INFO - alphas:tensor([0.1991, 0.0665, 0.0828, 0.1493, 0.5022], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,012 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,012 - train - INFO - True
2024-04-06 23:17:55,015 - train - INFO - alphas:tensor([0.1915, 0.0640, 0.0779, 0.1465, 0.5201], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,016 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,016 - train - INFO - True
2024-04-06 23:17:55,021 - train - INFO - alphas:tensor([0.1790, 0.0652, 0.0808, 0.1575, 0.5175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,022 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,022 - train - INFO - True
2024-04-06 23:17:55,026 - train - INFO - alphas:tensor([0.4870, 0.0950, 0.1045, 0.1298, 0.1838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,027 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,027 - train - INFO - True
2024-04-06 23:17:55,028 - train - INFO - alphas:tensor([0.5492, 0.0936, 0.0932, 0.1092, 0.1549], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,031 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,031 - train - INFO - True
2024-04-06 23:17:55,032 - train - INFO - alphas:tensor([0.1846, 0.0712, 0.0809, 0.1584, 0.5050], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,034 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,034 - train - INFO - True
2024-04-06 23:17:55,035 - train - INFO - alphas:tensor([0.2041, 0.0650, 0.0772, 0.1570, 0.4966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,037 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,037 - train - INFO - True
2024-04-06 23:17:55,038 - train - INFO - alphas:tensor([0.2235, 0.0615, 0.0773, 0.1491, 0.4887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,040 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,040 - train - INFO - True
2024-04-06 23:17:55,041 - train - INFO - alphas:tensor([0.1886, 0.0675, 0.0793, 0.1462, 0.5184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,043 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,043 - train - INFO - True
2024-04-06 23:17:55,044 - train - INFO - alphas:tensor([0.2184, 0.0593, 0.0761, 0.1482, 0.4981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,046 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,046 - train - INFO - True
2024-04-06 23:17:55,047 - train - INFO - alphas:tensor([0.1747, 0.0686, 0.0840, 0.1611, 0.5116], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,049 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,049 - train - INFO - True
2024-04-06 23:17:55,050 - train - INFO - alphas:tensor([0.5465, 0.0786, 0.0817, 0.1133, 0.1799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,053 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,053 - train - INFO - True
2024-04-06 23:17:55,054 - train - INFO - alphas:tensor([0.4693, 0.0738, 0.0806, 0.1225, 0.2539], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,062 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,062 - train - INFO - True
2024-04-06 23:17:55,063 - train - INFO - alphas:tensor([0.3281, 0.0635, 0.0772, 0.1332, 0.3979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,067 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,067 - train - INFO - True
2024-04-06 23:17:55,068 - train - INFO - alphas:tensor([0.3386, 0.0650, 0.0744, 0.1310, 0.3911], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,072 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,072 - train - INFO - True
2024-04-06 23:17:55,073 - train - INFO - alphas:tensor([0.3570, 0.0617, 0.0720, 0.1305, 0.3788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,076 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,077 - train - INFO - True
2024-04-06 23:17:55,078 - train - INFO - alphas:tensor([0.3230, 0.0614, 0.0751, 0.1295, 0.4111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,081 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,081 - train - INFO - True
2024-04-06 23:17:55,082 - train - INFO - alphas:tensor([0.4943, 0.0638, 0.0755, 0.1113, 0.2551], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,090 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,090 - train - INFO - True
2024-04-06 23:17:55,091 - train - INFO - alphas:tensor([0.6181, 0.0622, 0.0700, 0.0917, 0.1581], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,110 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,110 - train - INFO - True
2024-04-06 23:17:55,111 - train - INFO - alphas:tensor([0.2738, 0.0469, 0.0576, 0.1214, 0.5003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,121 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,121 - train - INFO - True
2024-04-06 23:17:55,123 - train - INFO - alphas:tensor([0.2868, 0.0446, 0.0552, 0.1148, 0.4986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,133 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,133 - train - INFO - True
2024-04-06 23:17:55,135 - train - INFO - alphas:tensor([0.3092, 0.0456, 0.0542, 0.1118, 0.4792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,145 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,145 - train - INFO - True
2024-04-06 23:17:55,150 - train - INFO - alphas:tensor([0.2697, 0.0480, 0.0568, 0.1202, 0.5052], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,160 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,161 - train - INFO - True
2024-04-06 23:17:55,166 - train - INFO - alphas:tensor([0.6297, 0.0538, 0.0613, 0.0848, 0.1705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,185 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,186 - train - INFO - True
2024-04-06 23:17:55,190 - train - INFO - alphas:tensor([0.4733, 0.0563, 0.0654, 0.1051, 0.2999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:17:55,267 - train - INFO - tau:0.8687458127689781
2024-04-06 23:17:55,267 - train - INFO - avg block size:9.181818181818182
2024-04-06 23:17:55,268 - train - INFO - current latency ratio:tensor(0.2902)
2024-04-06 23:17:55,268 - train - INFO - lasso_alpha:3.543122000000002e-05
2024-04-06 23:17:55,555 - train - INFO - Test: [   0/78]  Time: 0.283 (0.283)  Loss:  1.0391 (1.0391)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
2024-04-06 23:18:00,444 - train - INFO - Test: [  50/78]  Time: 0.119 (0.101)  Loss:  2.0098 (1.7880)  Acc@1: 51.5625 (58.6397)  Acc@5: 76.5625 (82.3683)
2024-04-06 23:18:02,622 - train - INFO - Test: [  78/78]  Time: 0.053 (0.093)  Loss:  1.9893 (1.8073)  Acc@1: 50.0000 (58.8000)  Acc@5: 100.0000 (82.3900)
2024-04-06 23:18:03,453 - train - INFO - Train: 17 [   0/781 (  0%)]  Loss:  3.928792 (3.9288)  Time: 0.656s,  195.25/s  (0.656s,  195.25/s)  LR: 4.846e-04  Data: 0.152 (0.152)
2024-04-06 23:18:28,369 - train - INFO - Train: 17 [  50/781 (  6%)]  Loss:  3.856098 (3.8718)  Time: 0.499s,  256.28/s  (0.501s,  255.30/s)  LR: 4.846e-04  Data: 0.007 (0.010)
2024-04-06 23:18:53,658 - train - INFO - Train: 17 [ 100/781 ( 13%)]  Loss:  3.649552 (3.8334)  Time: 0.496s,  257.89/s  (0.504s,  254.20/s)  LR: 4.846e-04  Data: 0.008 (0.009)
2024-04-06 23:19:17,060 - train - INFO - Train: 17 [ 150/781 ( 19%)]  Loss:  4.086484 (3.8557)  Time: 0.368s,  348.24/s  (0.492s,  260.28/s)  LR: 4.846e-04  Data: 0.004 (0.008)
2024-04-06 23:19:42,031 - train - INFO - Train: 17 [ 200/781 ( 26%)]  Loss:  4.121408 (3.8560)  Time: 0.546s,  234.23/s  (0.494s,  259.28/s)  LR: 4.846e-04  Data: 0.009 (0.008)
2024-04-06 23:20:07,070 - train - INFO - Train: 17 [ 250/781 ( 32%)]  Loss:  4.025758 (3.8611)  Time: 0.476s,  268.88/s  (0.495s,  258.55/s)  LR: 4.846e-04  Data: 0.008 (0.008)
2024-04-06 23:20:31,883 - train - INFO - Train: 17 [ 300/781 ( 38%)]  Loss:  3.577566 (3.8731)  Time: 0.531s,  241.05/s  (0.495s,  258.45/s)  LR: 4.846e-04  Data: 0.009 (0.008)
2024-04-06 23:20:55,836 - train - INFO - Train: 17 [ 350/781 ( 45%)]  Loss:  3.537655 (3.8750)  Time: 0.440s,  291.13/s  (0.493s,  259.66/s)  LR: 4.846e-04  Data: 0.009 (0.008)
2024-04-06 23:21:19,919 - train - INFO - Train: 17 [ 400/781 ( 51%)]  Loss:  4.009137 (3.8875)  Time: 0.636s,  201.39/s  (0.492s,  260.40/s)  LR: 4.846e-04  Data: 0.014 (0.008)
2024-04-06 23:21:43,845 - train - INFO - Train: 17 [ 450/781 ( 58%)]  Loss:  3.456767 (3.8887)  Time: 0.554s,  230.90/s  (0.490s,  261.17/s)  LR: 4.846e-04  Data: 0.008 (0.008)
2024-04-06 23:22:12,985 - train - INFO - Train: 17 [ 500/781 ( 64%)]  Loss:  3.595521 (3.8864)  Time: 1.052s,  121.65/s  (0.499s,  256.33/s)  LR: 4.846e-04  Data: 0.005 (0.008)
2024-04-06 23:22:41,141 - train - INFO - Train: 17 [ 550/781 ( 71%)]  Loss:  3.522051 (3.8886)  Time: 0.385s,  332.72/s  (0.505s,  253.40/s)  LR: 4.846e-04  Data: 0.007 (0.008)
2024-04-06 23:23:11,826 - train - INFO - Train: 17 [ 600/781 ( 77%)]  Loss:  3.936193 (3.8900)  Time: 0.450s,  284.44/s  (0.514s,  248.95/s)  LR: 4.846e-04  Data: 0.007 (0.008)
2024-04-06 23:23:43,859 - train - INFO - Train: 17 [ 650/781 ( 83%)]  Loss:  3.734216 (3.8885)  Time: 0.391s,  327.28/s  (0.524s,  244.33/s)  LR: 4.846e-04  Data: 0.005 (0.008)
2024-04-06 23:24:11,427 - train - INFO - Train: 17 [ 700/781 ( 90%)]  Loss:  3.891293 (3.8912)  Time: 0.444s,  288.60/s  (0.526s,  243.42/s)  LR: 4.846e-04  Data: 0.005 (0.008)
2024-04-06 23:24:34,963 - train - INFO - Train: 17 [ 750/781 ( 96%)]  Loss:  4.115255 (3.8937)  Time: 0.474s,  270.10/s  (0.522s,  245.13/s)  LR: 4.846e-04  Data: 0.026 (0.008)
2024-04-06 23:24:49,114 - train - INFO - Train: 17 [ 780/781 (100%)]  Loss:  3.868064 (3.8946)  Time: 0.543s,  235.91/s  (0.520s,  246.05/s)  LR: 4.846e-04  Data: 0.000 (0.008)
2024-04-06 23:24:49,115 - train - INFO - True
2024-04-06 23:24:49,118 - train - INFO - alphas:tensor([0.3634, 0.1445, 0.1432, 0.1644, 0.1845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,119 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,119 - train - INFO - True
2024-04-06 23:24:49,121 - train - INFO - alphas:tensor([0.3944, 0.1139, 0.1254, 0.1541, 0.2122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,122 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,122 - train - INFO - True
2024-04-06 23:24:49,123 - train - INFO - alphas:tensor([0.4187, 0.1404, 0.1766, 0.2643], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,125 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,125 - train - INFO - True
2024-04-06 23:24:49,127 - train - INFO - alphas:tensor([0.3698, 0.1334, 0.1721, 0.3247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,128 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,128 - train - INFO - True
2024-04-06 23:24:49,130 - train - INFO - alphas:tensor([0.3721, 0.1270, 0.1753, 0.3255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,131 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,132 - train - INFO - True
2024-04-06 23:24:49,133 - train - INFO - alphas:tensor([0.4445, 0.1329, 0.1620, 0.2607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,135 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,135 - train - INFO - True
2024-04-06 23:24:49,136 - train - INFO - alphas:tensor([0.4682, 0.1093, 0.1100, 0.1318, 0.1806], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,138 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,139 - train - INFO - True
2024-04-06 23:24:49,140 - train - INFO - alphas:tensor([0.1768, 0.0645, 0.0769, 0.1510, 0.5307], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,141 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,141 - train - INFO - True
2024-04-06 23:24:49,143 - train - INFO - alphas:tensor([0.1922, 0.0611, 0.0767, 0.1408, 0.5291], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,144 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,144 - train - INFO - True
2024-04-06 23:24:49,146 - train - INFO - alphas:tensor([0.1876, 0.0586, 0.0715, 0.1402, 0.5422], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,147 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,147 - train - INFO - True
2024-04-06 23:24:49,148 - train - INFO - alphas:tensor([0.1736, 0.0603, 0.0750, 0.1498, 0.5413], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,149 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,150 - train - INFO - True
2024-04-06 23:24:49,151 - train - INFO - alphas:tensor([0.4894, 0.0904, 0.1013, 0.1287, 0.1902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,153 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,153 - train - INFO - True
2024-04-06 23:24:49,154 - train - INFO - alphas:tensor([0.5534, 0.0896, 0.0900, 0.1077, 0.1593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,160 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,160 - train - INFO - True
2024-04-06 23:24:49,161 - train - INFO - alphas:tensor([0.1798, 0.0664, 0.0763, 0.1565, 0.5209], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,164 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,164 - train - INFO - True
2024-04-06 23:24:49,166 - train - INFO - alphas:tensor([0.1956, 0.0603, 0.0731, 0.1551, 0.5159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,168 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,169 - train - INFO - True
2024-04-06 23:24:49,170 - train - INFO - alphas:tensor([0.2138, 0.0574, 0.0723, 0.1440, 0.5125], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,173 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,173 - train - INFO - True
2024-04-06 23:24:49,174 - train - INFO - alphas:tensor([0.1841, 0.0636, 0.0745, 0.1433, 0.5345], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,177 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,177 - train - INFO - True
2024-04-06 23:24:49,178 - train - INFO - alphas:tensor([0.2139, 0.0553, 0.0719, 0.1451, 0.5138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,180 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,181 - train - INFO - True
2024-04-06 23:24:49,182 - train - INFO - alphas:tensor([0.1640, 0.0645, 0.0795, 0.1569, 0.5352], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,184 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,184 - train - INFO - True
2024-04-06 23:24:49,186 - train - INFO - alphas:tensor([0.5403, 0.0740, 0.0786, 0.1132, 0.1939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,190 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,190 - train - INFO - True
2024-04-06 23:24:49,191 - train - INFO - alphas:tensor([0.4606, 0.0687, 0.0766, 0.1225, 0.2717], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,201 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,201 - train - INFO - True
2024-04-06 23:24:49,202 - train - INFO - alphas:tensor([0.3186, 0.0593, 0.0720, 0.1300, 0.4201], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,206 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,206 - train - INFO - True
2024-04-06 23:24:49,208 - train - INFO - alphas:tensor([0.3313, 0.0599, 0.0692, 0.1281, 0.4115], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,212 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,212 - train - INFO - True
2024-04-06 23:24:49,213 - train - INFO - alphas:tensor([0.3490, 0.0573, 0.0670, 0.1270, 0.3996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,217 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,218 - train - INFO - True
2024-04-06 23:24:49,219 - train - INFO - alphas:tensor([0.3113, 0.0565, 0.0709, 0.1279, 0.4333], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,223 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,223 - train - INFO - True
2024-04-06 23:24:49,224 - train - INFO - alphas:tensor([0.4873, 0.0594, 0.0715, 0.1085, 0.2732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,232 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,232 - train - INFO - True
2024-04-06 23:24:49,233 - train - INFO - alphas:tensor([0.6195, 0.0583, 0.0664, 0.0897, 0.1662], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,252 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,252 - train - INFO - True
2024-04-06 23:24:49,253 - train - INFO - alphas:tensor([0.2600, 0.0434, 0.0540, 0.1201, 0.5224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,263 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,264 - train - INFO - True
2024-04-06 23:24:49,264 - train - INFO - alphas:tensor([0.2712, 0.0413, 0.0517, 0.1143, 0.5215], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,275 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,275 - train - INFO - True
2024-04-06 23:24:49,276 - train - INFO - alphas:tensor([0.2995, 0.0418, 0.0510, 0.1090, 0.4987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,286 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,286 - train - INFO - True
2024-04-06 23:24:49,287 - train - INFO - alphas:tensor([0.2596, 0.0445, 0.0531, 0.1195, 0.5233], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,297 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,297 - train - INFO - True
2024-04-06 23:24:49,298 - train - INFO - alphas:tensor([0.6255, 0.0494, 0.0575, 0.0842, 0.1834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,317 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,317 - train - INFO - True
2024-04-06 23:24:49,318 - train - INFO - alphas:tensor([0.4657, 0.0525, 0.0618, 0.1032, 0.3168], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:24:49,396 - train - INFO - tau:0.8600583546412883
2024-04-06 23:24:49,396 - train - INFO - avg block size:9.181818181818182
2024-04-06 23:24:49,397 - train - INFO - current latency ratio:tensor(0.2902)
2024-04-06 23:24:49,601 - train - INFO - Test: [   0/78]  Time: 0.200 (0.200)  Loss:  1.0791 (1.0791)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.9688 (92.9688)
2024-04-06 23:24:53,022 - train - INFO - Test: [  50/78]  Time: 0.064 (0.071)  Loss:  1.8311 (1.7868)  Acc@1: 57.8125 (59.1299)  Acc@5: 84.3750 (82.9963)
2024-04-06 23:24:54,578 - train - INFO - Test: [  78/78]  Time: 0.053 (0.066)  Loss:  2.1172 (1.8306)  Acc@1: 50.0000 (58.8600)  Acc@5: 87.5000 (82.6400)
2024-04-06 23:24:55,310 - train - INFO - Train: 18 [   0/781 (  0%)]  Loss:  4.205656 (4.2057)  Time: 0.652s,  196.35/s  (0.652s,  196.35/s)  LR: 4.828e-04  Data: 0.200 (0.200)
2024-04-06 23:25:19,217 - train - INFO - Train: 18 [  50/781 (  6%)]  Loss:  3.822696 (3.8773)  Time: 0.508s,  251.97/s  (0.482s,  265.83/s)  LR: 4.828e-04  Data: 0.010 (0.011)
2024-04-06 23:25:43,330 - train - INFO - Train: 18 [ 100/781 ( 13%)]  Loss:  4.029903 (3.8958)  Time: 0.488s,  262.55/s  (0.482s,  265.63/s)  LR: 4.828e-04  Data: 0.010 (0.009)
2024-04-06 23:26:06,687 - train - INFO - Train: 18 [ 150/781 ( 19%)]  Loss:  4.225656 (3.8889)  Time: 0.467s,  274.32/s  (0.477s,  268.36/s)  LR: 4.828e-04  Data: 0.014 (0.009)
2024-04-06 23:26:29,489 - train - INFO - Train: 18 [ 200/781 ( 26%)]  Loss:  3.804235 (3.8860)  Time: 0.493s,  259.73/s  (0.472s,  271.32/s)  LR: 4.828e-04  Data: 0.008 (0.009)
2024-04-06 23:26:53,262 - train - INFO - Train: 18 [ 250/781 ( 32%)]  Loss:  4.176373 (3.8753)  Time: 0.460s,  278.05/s  (0.472s,  270.90/s)  LR: 4.828e-04  Data: 0.010 (0.008)
2024-04-06 23:27:17,333 - train - INFO - Train: 18 [ 300/781 ( 38%)]  Loss:  3.775174 (3.8741)  Time: 0.521s,  245.75/s  (0.474s,  270.06/s)  LR: 4.828e-04  Data: 0.006 (0.008)
2024-04-06 23:27:40,957 - train - INFO - Train: 18 [ 350/781 ( 45%)]  Loss:  3.846302 (3.8748)  Time: 0.516s,  248.06/s  (0.474s,  270.18/s)  LR: 4.828e-04  Data: 0.008 (0.008)
2024-04-06 23:28:04,917 - train - INFO - Train: 18 [ 400/781 ( 51%)]  Loss:  4.062037 (3.8705)  Time: 0.436s,  293.67/s  (0.474s,  269.80/s)  LR: 4.828e-04  Data: 0.007 (0.008)
2024-04-06 23:28:28,639 - train - INFO - Train: 18 [ 450/781 ( 58%)]  Loss:  3.611848 (3.8707)  Time: 0.524s,  244.46/s  (0.474s,  269.80/s)  LR: 4.828e-04  Data: 0.008 (0.008)
2024-04-06 23:28:52,407 - train - INFO - Train: 18 [ 500/781 ( 64%)]  Loss:  4.087080 (3.8704)  Time: 0.485s,  264.00/s  (0.475s,  269.75/s)  LR: 4.828e-04  Data: 0.008 (0.008)
2024-04-06 23:29:15,754 - train - INFO - Train: 18 [ 550/781 ( 71%)]  Loss:  3.580103 (3.8687)  Time: 0.474s,  270.26/s  (0.474s,  270.14/s)  LR: 4.828e-04  Data: 0.006 (0.008)
2024-04-06 23:29:39,457 - train - INFO - Train: 18 [ 600/781 ( 77%)]  Loss:  3.615618 (3.8697)  Time: 0.451s,  284.04/s  (0.474s,  270.13/s)  LR: 4.828e-04  Data: 0.005 (0.008)
2024-04-06 23:30:02,955 - train - INFO - Train: 18 [ 650/781 ( 83%)]  Loss:  3.995418 (3.8679)  Time: 0.394s,  324.57/s  (0.474s,  270.30/s)  LR: 4.828e-04  Data: 0.006 (0.008)
2024-04-06 23:30:27,329 - train - INFO - Train: 18 [ 700/781 ( 90%)]  Loss:  3.990801 (3.8703)  Time: 0.523s,  244.75/s  (0.475s,  269.74/s)  LR: 4.828e-04  Data: 0.009 (0.008)
2024-04-06 23:30:52,447 - train - INFO - Train: 18 [ 750/781 ( 96%)]  Loss:  3.725956 (3.8695)  Time: 0.495s,  258.83/s  (0.476s,  268.69/s)  LR: 4.828e-04  Data: 0.007 (0.008)
2024-04-06 23:31:06,846 - train - INFO - Train: 18 [ 780/781 (100%)]  Loss:  3.562150 (3.8707)  Time: 0.418s,  306.52/s  (0.477s,  268.61/s)  LR: 4.828e-04  Data: 0.000 (0.008)
2024-04-06 23:31:06,847 - train - INFO - True
2024-04-06 23:31:06,850 - train - INFO - alphas:tensor([0.3715, 0.1416, 0.1402, 0.1622, 0.1845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,851 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,852 - train - INFO - True
2024-04-06 23:31:06,856 - train - INFO - alphas:tensor([0.3973, 0.1094, 0.1216, 0.1524, 0.2193], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,857 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,857 - train - INFO - True
2024-04-06 23:31:06,862 - train - INFO - alphas:tensor([0.4190, 0.1362, 0.1728, 0.2719], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,863 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,864 - train - INFO - True
2024-04-06 23:31:06,868 - train - INFO - alphas:tensor([0.3625, 0.1295, 0.1683, 0.3396], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,880 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,890 - train - INFO - True
2024-04-06 23:31:06,894 - train - INFO - alphas:tensor([0.3658, 0.1215, 0.1712, 0.3414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,895 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,895 - train - INFO - True
2024-04-06 23:31:06,899 - train - INFO - alphas:tensor([0.4398, 0.1277, 0.1596, 0.2728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,900 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,901 - train - INFO - True
2024-04-06 23:31:06,905 - train - INFO - alphas:tensor([0.4705, 0.1055, 0.1069, 0.1309, 0.1862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,907 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,907 - train - INFO - True
2024-04-06 23:31:06,912 - train - INFO - alphas:tensor([0.1733, 0.0607, 0.0714, 0.1454, 0.5491], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,912 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,913 - train - INFO - True
2024-04-06 23:31:06,918 - train - INFO - alphas:tensor([0.1862, 0.0568, 0.0718, 0.1358, 0.5494], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,918 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,918 - train - INFO - True
2024-04-06 23:31:06,923 - train - INFO - alphas:tensor([0.1814, 0.0548, 0.0664, 0.1347, 0.5627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,924 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,924 - train - INFO - True
2024-04-06 23:31:06,929 - train - INFO - alphas:tensor([0.1693, 0.0565, 0.0698, 0.1440, 0.5605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,930 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,930 - train - INFO - True
2024-04-06 23:31:06,932 - train - INFO - alphas:tensor([0.4930, 0.0862, 0.0968, 0.1272, 0.1968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,933 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,933 - train - INFO - True
2024-04-06 23:31:06,936 - train - INFO - alphas:tensor([0.5551, 0.0860, 0.0871, 0.1071, 0.1648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,940 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,940 - train - INFO - True
2024-04-06 23:31:06,941 - train - INFO - alphas:tensor([0.1785, 0.0634, 0.0720, 0.1528, 0.5333], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,944 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,944 - train - INFO - True
2024-04-06 23:31:06,945 - train - INFO - alphas:tensor([0.1894, 0.0567, 0.0693, 0.1521, 0.5325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,947 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,947 - train - INFO - True
2024-04-06 23:31:06,948 - train - INFO - alphas:tensor([0.2079, 0.0532, 0.0685, 0.1414, 0.5290], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,950 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,950 - train - INFO - True
2024-04-06 23:31:06,951 - train - INFO - alphas:tensor([0.1800, 0.0599, 0.0706, 0.1400, 0.5496], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,953 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,953 - train - INFO - True
2024-04-06 23:31:06,954 - train - INFO - alphas:tensor([0.2091, 0.0520, 0.0684, 0.1405, 0.5299], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,956 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,956 - train - INFO - True
2024-04-06 23:31:06,957 - train - INFO - alphas:tensor([0.1622, 0.0625, 0.0768, 0.1543, 0.5441], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,959 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,959 - train - INFO - True
2024-04-06 23:31:06,960 - train - INFO - alphas:tensor([0.5373, 0.0694, 0.0759, 0.1129, 0.2044], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,963 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,963 - train - INFO - True
2024-04-06 23:31:06,964 - train - INFO - alphas:tensor([0.4479, 0.0650, 0.0735, 0.1217, 0.2919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,971 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,972 - train - INFO - True
2024-04-06 23:31:06,973 - train - INFO - alphas:tensor([0.3125, 0.0552, 0.0686, 0.1267, 0.4370], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,976 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,976 - train - INFO - True
2024-04-06 23:31:06,977 - train - INFO - alphas:tensor([0.3233, 0.0562, 0.0651, 0.1251, 0.4303], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,981 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,981 - train - INFO - True
2024-04-06 23:31:06,982 - train - INFO - alphas:tensor([0.3380, 0.0539, 0.0632, 0.1244, 0.4205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,986 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,986 - train - INFO - True
2024-04-06 23:31:06,987 - train - INFO - alphas:tensor([0.3013, 0.0523, 0.0662, 0.1265, 0.4538], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,991 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,991 - train - INFO - True
2024-04-06 23:31:06,992 - train - INFO - alphas:tensor([0.4754, 0.0553, 0.0683, 0.1070, 0.2940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:06,999 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:06,999 - train - INFO - True
2024-04-06 23:31:07,000 - train - INFO - alphas:tensor([0.6157, 0.0555, 0.0634, 0.0893, 0.1760], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:07,020 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:07,020 - train - INFO - True
2024-04-06 23:31:07,021 - train - INFO - alphas:tensor([0.2580, 0.0407, 0.0521, 0.1195, 0.5297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:07,031 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:07,031 - train - INFO - True
2024-04-06 23:31:07,032 - train - INFO - alphas:tensor([0.2714, 0.0386, 0.0494, 0.1107, 0.5299], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:07,042 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:07,042 - train - INFO - True
2024-04-06 23:31:07,043 - train - INFO - alphas:tensor([0.2949, 0.0390, 0.0481, 0.1069, 0.5111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:07,053 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:07,053 - train - INFO - True
2024-04-06 23:31:07,054 - train - INFO - alphas:tensor([0.2570, 0.0422, 0.0505, 0.1172, 0.5330], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:07,064 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:07,064 - train - INFO - True
2024-04-06 23:31:07,065 - train - INFO - alphas:tensor([0.6186, 0.0466, 0.0547, 0.0826, 0.1975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:07,085 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:07,085 - train - INFO - True
2024-04-06 23:31:07,086 - train - INFO - alphas:tensor([0.4627, 0.0491, 0.0586, 0.1010, 0.3287], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:07,163 - train - INFO - tau:0.8514577710948754
2024-04-06 23:31:07,163 - train - INFO - avg block size:9.181818181818182
2024-04-06 23:31:07,164 - train - INFO - current latency ratio:tensor(0.2902)
2024-04-06 23:31:07,164 - train - INFO - lasso_alpha:3.8974342000000026e-05
2024-04-06 23:31:07,446 - train - INFO - Test: [   0/78]  Time: 0.278 (0.278)  Loss:  0.9717 (0.9717)  Acc@1: 79.6875 (79.6875)  Acc@5: 94.5312 (94.5312)
2024-04-06 23:31:12,118 - train - INFO - Test: [  50/78]  Time: 0.064 (0.097)  Loss:  1.7480 (1.7893)  Acc@1: 61.7188 (59.1299)  Acc@5: 82.8125 (82.5061)
2024-04-06 23:31:14,550 - train - INFO - Test: [  78/78]  Time: 0.050 (0.093)  Loss:  2.0195 (1.7782)  Acc@1: 50.0000 (59.6000)  Acc@5: 100.0000 (82.7200)
2024-04-06 23:31:15,317 - train - INFO - Train: 19 [   0/781 (  0%)]  Loss:  3.686033 (3.6860)  Time: 0.596s,  214.63/s  (0.596s,  214.63/s)  LR: 4.809e-04  Data: 0.183 (0.183)
2024-04-06 23:31:40,079 - train - INFO - Train: 19 [  50/781 (  6%)]  Loss:  4.079881 (3.8694)  Time: 0.521s,  245.69/s  (0.497s,  257.45/s)  LR: 4.809e-04  Data: 0.008 (0.011)
2024-04-06 23:32:05,424 - train - INFO - Train: 19 [ 100/781 ( 13%)]  Loss:  3.538364 (3.8964)  Time: 0.520s,  246.09/s  (0.502s,  254.99/s)  LR: 4.809e-04  Data: 0.009 (0.009)
2024-04-06 23:32:30,472 - train - INFO - Train: 19 [ 150/781 ( 19%)]  Loss:  3.869203 (3.8842)  Time: 0.492s,  260.14/s  (0.502s,  255.17/s)  LR: 4.809e-04  Data: 0.006 (0.009)
2024-04-06 23:32:55,307 - train - INFO - Train: 19 [ 200/781 ( 26%)]  Loss:  3.863128 (3.8993)  Time: 0.521s,  245.88/s  (0.500s,  255.80/s)  LR: 4.809e-04  Data: 0.005 (0.008)
2024-04-06 23:33:20,087 - train - INFO - Train: 19 [ 250/781 ( 32%)]  Loss:  3.869465 (3.9001)  Time: 0.565s,  226.61/s  (0.499s,  256.29/s)  LR: 4.809e-04  Data: 0.009 (0.008)
2024-04-06 23:33:44,231 - train - INFO - Train: 19 [ 300/781 ( 38%)]  Loss:  3.839094 (3.9018)  Time: 0.470s,  272.11/s  (0.497s,  257.71/s)  LR: 4.809e-04  Data: 0.005 (0.008)
2024-04-06 23:34:08,903 - train - INFO - Train: 19 [ 350/781 ( 45%)]  Loss:  3.916163 (3.9039)  Time: 0.528s,  242.22/s  (0.496s,  257.97/s)  LR: 4.809e-04  Data: 0.007 (0.008)
2024-04-06 23:34:33,655 - train - INFO - Train: 19 [ 400/781 ( 51%)]  Loss:  3.608174 (3.8969)  Time: 0.488s,  262.29/s  (0.496s,  258.05/s)  LR: 4.809e-04  Data: 0.006 (0.008)
2024-04-06 23:34:58,338 - train - INFO - Train: 19 [ 450/781 ( 58%)]  Loss:  3.854926 (3.8895)  Time: 0.476s,  268.85/s  (0.496s,  258.19/s)  LR: 4.809e-04  Data: 0.008 (0.008)
2024-04-06 23:35:23,321 - train - INFO - Train: 19 [ 500/781 ( 64%)]  Loss:  4.141445 (3.8858)  Time: 0.452s,  283.17/s  (0.496s,  257.98/s)  LR: 4.809e-04  Data: 0.008 (0.008)
2024-04-06 23:35:46,926 - train - INFO - Train: 19 [ 550/781 ( 71%)]  Loss:  3.975151 (3.8830)  Time: 0.499s,  256.51/s  (0.494s,  259.13/s)  LR: 4.809e-04  Data: 0.008 (0.008)
2024-04-06 23:36:11,491 - train - INFO - Train: 19 [ 600/781 ( 77%)]  Loss:  3.676649 (3.8792)  Time: 0.522s,  245.10/s  (0.494s,  259.24/s)  LR: 4.809e-04  Data: 0.009 (0.008)
2024-04-06 23:36:36,454 - train - INFO - Train: 19 [ 650/781 ( 83%)]  Loss:  3.596563 (3.8829)  Time: 0.459s,  278.63/s  (0.494s,  259.02/s)  LR: 4.809e-04  Data: 0.010 (0.008)
2024-04-06 23:37:00,725 - train - INFO - Train: 19 [ 700/781 ( 90%)]  Loss:  3.699354 (3.8835)  Time: 0.513s,  249.44/s  (0.494s,  259.35/s)  LR: 4.809e-04  Data: 0.005 (0.008)
2024-04-06 23:37:26,003 - train - INFO - Train: 19 [ 750/781 ( 96%)]  Loss:  3.732588 (3.8869)  Time: 0.559s,  228.83/s  (0.494s,  258.93/s)  LR: 4.809e-04  Data: 0.007 (0.008)
2024-04-06 23:37:40,626 - train - INFO - Train: 19 [ 780/781 (100%)]  Loss:  4.022613 (3.8898)  Time: 0.460s,  277.96/s  (0.494s,  259.08/s)  LR: 4.809e-04  Data: 0.000 (0.008)
2024-04-06 23:37:40,627 - train - INFO - True
2024-04-06 23:37:40,629 - train - INFO - alphas:tensor([0.3811, 0.1377, 0.1373, 0.1596, 0.1843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,630 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,630 - train - INFO - True
2024-04-06 23:37:40,631 - train - INFO - alphas:tensor([0.3948, 0.1060, 0.1188, 0.1527, 0.2278], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,632 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,632 - train - INFO - True
2024-04-06 23:37:40,633 - train - INFO - alphas:tensor([0.4140, 0.1319, 0.1726, 0.2814], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,635 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,635 - train - INFO - True
2024-04-06 23:37:40,636 - train - INFO - alphas:tensor([0.3536, 0.1232, 0.1649, 0.3584], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,637 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,637 - train - INFO - True
2024-04-06 23:37:40,638 - train - INFO - alphas:tensor([0.3539, 0.1158, 0.1703, 0.3600], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,639 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,639 - train - INFO - True
2024-04-06 23:37:40,640 - train - INFO - alphas:tensor([0.4349, 0.1240, 0.1575, 0.2836], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,641 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,641 - train - INFO - True
2024-04-06 23:37:40,643 - train - INFO - alphas:tensor([0.4697, 0.1019, 0.1054, 0.1305, 0.1926], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,644 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,644 - train - INFO - True
2024-04-06 23:37:40,645 - train - INFO - alphas:tensor([0.1685, 0.0550, 0.0670, 0.1393, 0.5702], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,646 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,647 - train - INFO - True
2024-04-06 23:37:40,648 - train - INFO - alphas:tensor([0.1783, 0.0527, 0.0664, 0.1301, 0.5724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,649 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,649 - train - INFO - True
2024-04-06 23:37:40,650 - train - INFO - alphas:tensor([0.1758, 0.0502, 0.0600, 0.1274, 0.5866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,651 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,651 - train - INFO - True
2024-04-06 23:37:40,652 - train - INFO - alphas:tensor([0.1622, 0.0517, 0.0638, 0.1375, 0.5848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,653 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,653 - train - INFO - True
2024-04-06 23:37:40,654 - train - INFO - alphas:tensor([0.4887, 0.0829, 0.0946, 0.1271, 0.2067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,656 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,656 - train - INFO - True
2024-04-06 23:37:40,657 - train - INFO - alphas:tensor([0.5593, 0.0825, 0.0841, 0.1048, 0.1693], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,661 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,662 - train - INFO - True
2024-04-06 23:37:40,663 - train - INFO - alphas:tensor([0.1694, 0.0596, 0.0681, 0.1519, 0.5510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,665 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,665 - train - INFO - True
2024-04-06 23:37:40,666 - train - INFO - alphas:tensor([0.1831, 0.0534, 0.0653, 0.1488, 0.5495], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,669 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,669 - train - INFO - True
2024-04-06 23:37:40,670 - train - INFO - alphas:tensor([0.2005, 0.0498, 0.0659, 0.1384, 0.5453], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,672 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,672 - train - INFO - True
2024-04-06 23:37:40,673 - train - INFO - alphas:tensor([0.1714, 0.0566, 0.0666, 0.1361, 0.5692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,676 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,676 - train - INFO - True
2024-04-06 23:37:40,677 - train - INFO - alphas:tensor([0.1979, 0.0486, 0.0657, 0.1389, 0.5489], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,679 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,679 - train - INFO - True
2024-04-06 23:37:40,680 - train - INFO - alphas:tensor([0.1535, 0.0592, 0.0727, 0.1509, 0.5637], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,682 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,682 - train - INFO - True
2024-04-06 23:37:40,683 - train - INFO - alphas:tensor([0.5264, 0.0664, 0.0738, 0.1145, 0.2189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,687 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,687 - train - INFO - True
2024-04-06 23:37:40,688 - train - INFO - alphas:tensor([0.4412, 0.0612, 0.0693, 0.1199, 0.3083], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,696 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,696 - train - INFO - True
2024-04-06 23:37:40,704 - train - INFO - alphas:tensor([0.3036, 0.0509, 0.0652, 0.1247, 0.4555], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,708 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,708 - train - INFO - True
2024-04-06 23:37:40,709 - train - INFO - alphas:tensor([0.3135, 0.0534, 0.0621, 0.1227, 0.4483], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,713 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,713 - train - INFO - True
2024-04-06 23:37:40,714 - train - INFO - alphas:tensor([0.3289, 0.0502, 0.0598, 0.1218, 0.4393], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,718 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,718 - train - INFO - True
2024-04-06 23:37:40,722 - train - INFO - alphas:tensor([0.2969, 0.0486, 0.0638, 0.1231, 0.4676], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,726 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,726 - train - INFO - True
2024-04-06 23:37:40,729 - train - INFO - alphas:tensor([0.4686, 0.0526, 0.0646, 0.1055, 0.3088], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,736 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,736 - train - INFO - True
2024-04-06 23:37:40,740 - train - INFO - alphas:tensor([0.6065, 0.0522, 0.0610, 0.0891, 0.1911], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,757 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,757 - train - INFO - True
2024-04-06 23:37:40,762 - train - INFO - alphas:tensor([0.2488, 0.0377, 0.0485, 0.1167, 0.5484], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,770 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,770 - train - INFO - True
2024-04-06 23:37:40,773 - train - INFO - alphas:tensor([0.2591, 0.0362, 0.0470, 0.1118, 0.5460], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,781 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,781 - train - INFO - True
2024-04-06 23:37:40,785 - train - INFO - alphas:tensor([0.2873, 0.0359, 0.0447, 0.1061, 0.5260], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,792 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,792 - train - INFO - True
2024-04-06 23:37:40,796 - train - INFO - alphas:tensor([0.2499, 0.0404, 0.0475, 0.1154, 0.5468], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,803 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,803 - train - INFO - True
2024-04-06 23:37:40,806 - train - INFO - alphas:tensor([0.6066, 0.0438, 0.0525, 0.0826, 0.2144], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,819 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,819 - train - INFO - True
2024-04-06 23:37:40,820 - train - INFO - alphas:tensor([0.4499, 0.0471, 0.0571, 0.0998, 0.3461], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:37:40,873 - train - INFO - tau:0.8429431933839266
2024-04-06 23:37:40,873 - train - INFO - avg block size:9.606060606060606
2024-04-06 23:37:40,873 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-06 23:37:41,111 - train - INFO - Test: [   0/78]  Time: 0.235 (0.235)  Loss:  1.0215 (1.0215)  Acc@1: 77.3438 (77.3438)  Acc@5: 92.1875 (92.1875)
2024-04-06 23:37:45,577 - train - INFO - Test: [  50/78]  Time: 0.076 (0.092)  Loss:  1.9336 (1.7867)  Acc@1: 57.0312 (59.7426)  Acc@5: 79.6875 (83.1955)
2024-04-06 23:37:47,908 - train - INFO - Test: [  78/78]  Time: 0.049 (0.089)  Loss:  1.7803 (1.8234)  Acc@1: 56.2500 (59.4500)  Acc@5: 100.0000 (82.6000)
2024-04-06 23:37:48,663 - train - INFO - Train: 20 [   0/781 (  0%)]  Loss:  3.529018 (3.5290)  Time: 0.671s,  190.84/s  (0.671s,  190.84/s)  LR: 4.788e-04  Data: 0.166 (0.166)
2024-04-06 23:38:13,069 - train - INFO - Train: 20 [  50/781 (  6%)]  Loss:  4.057176 (3.8931)  Time: 0.421s,  304.28/s  (0.492s,  260.34/s)  LR: 4.788e-04  Data: 0.007 (0.010)
2024-04-06 23:38:38,050 - train - INFO - Train: 20 [ 100/781 ( 13%)]  Loss:  3.752952 (3.9061)  Time: 0.498s,  257.23/s  (0.495s,  258.34/s)  LR: 4.788e-04  Data: 0.009 (0.009)
2024-04-06 23:39:01,463 - train - INFO - Train: 20 [ 150/781 ( 19%)]  Loss:  4.110719 (3.8849)  Time: 0.533s,  240.24/s  (0.486s,  263.13/s)  LR: 4.788e-04  Data: 0.007 (0.008)
2024-04-06 23:39:24,931 - train - INFO - Train: 20 [ 200/781 ( 26%)]  Loss:  3.485685 (3.8740)  Time: 0.467s,  274.04/s  (0.482s,  265.45/s)  LR: 4.788e-04  Data: 0.005 (0.008)
2024-04-06 23:39:49,846 - train - INFO - Train: 20 [ 250/781 ( 32%)]  Loss:  4.088723 (3.8698)  Time: 0.496s,  258.32/s  (0.485s,  263.70/s)  LR: 4.788e-04  Data: 0.009 (0.008)
2024-04-06 23:40:15,620 - train - INFO - Train: 20 [ 300/781 ( 38%)]  Loss:  3.707881 (3.8758)  Time: 0.466s,  274.53/s  (0.490s,  261.02/s)  LR: 4.788e-04  Data: 0.008 (0.008)
2024-04-06 23:40:40,601 - train - INFO - Train: 20 [ 350/781 ( 45%)]  Loss:  3.559796 (3.8756)  Time: 0.478s,  267.60/s  (0.492s,  260.32/s)  LR: 4.788e-04  Data: 0.005 (0.008)
2024-04-06 23:41:05,533 - train - INFO - Train: 20 [ 400/781 ( 51%)]  Loss:  3.977134 (3.8763)  Time: 0.545s,  234.76/s  (0.493s,  259.87/s)  LR: 4.788e-04  Data: 0.008 (0.008)
2024-04-06 23:41:30,284 - train - INFO - Train: 20 [ 450/781 ( 58%)]  Loss:  3.497224 (3.8795)  Time: 0.499s,  256.76/s  (0.493s,  259.73/s)  LR: 4.788e-04  Data: 0.009 (0.008)
2024-04-06 23:41:55,556 - train - INFO - Train: 20 [ 500/781 ( 64%)]  Loss:  3.797454 (3.8769)  Time: 0.541s,  236.64/s  (0.494s,  259.07/s)  LR: 4.788e-04  Data: 0.010 (0.008)
2024-04-06 23:42:20,520 - train - INFO - Train: 20 [ 550/781 ( 71%)]  Loss:  3.809315 (3.8807)  Time: 0.383s,  334.13/s  (0.495s,  258.82/s)  LR: 4.788e-04  Data: 0.005 (0.008)
2024-04-06 23:42:45,063 - train - INFO - Train: 20 [ 600/781 ( 77%)]  Loss:  4.240736 (3.8860)  Time: 0.495s,  258.39/s  (0.494s,  258.98/s)  LR: 4.788e-04  Data: 0.006 (0.008)
2024-04-06 23:43:08,376 - train - INFO - Train: 20 [ 650/781 ( 83%)]  Loss:  3.767241 (3.8885)  Time: 0.516s,  248.20/s  (0.492s,  260.12/s)  LR: 4.788e-04  Data: 0.009 (0.008)
2024-04-06 23:43:34,028 - train - INFO - Train: 20 [ 700/781 ( 90%)]  Loss:  4.212075 (3.8868)  Time: 0.542s,  236.19/s  (0.494s,  259.33/s)  LR: 4.788e-04  Data: 0.016 (0.008)
2024-04-06 23:43:58,946 - train - INFO - Train: 20 [ 750/781 ( 96%)]  Loss:  4.322203 (3.8826)  Time: 0.542s,  236.15/s  (0.494s,  259.16/s)  LR: 4.788e-04  Data: 0.008 (0.008)
2024-04-06 23:44:14,376 - train - INFO - Train: 20 [ 780/781 (100%)]  Loss:  3.966754 (3.8843)  Time: 0.525s,  243.77/s  (0.495s,  258.75/s)  LR: 4.788e-04  Data: 0.000 (0.008)
2024-04-06 23:44:14,377 - train - INFO - True
2024-04-06 23:44:14,381 - train - INFO - alphas:tensor([0.3906, 0.1348, 0.1338, 0.1572, 0.1836], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,382 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,382 - train - INFO - True
2024-04-06 23:44:14,386 - train - INFO - alphas:tensor([0.3885, 0.1029, 0.1172, 0.1545, 0.2369], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,387 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,387 - train - INFO - True
2024-04-06 23:44:14,391 - train - INFO - alphas:tensor([0.4093, 0.1283, 0.1715, 0.2908], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,392 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,392 - train - INFO - True
2024-04-06 23:44:14,394 - train - INFO - alphas:tensor([0.3470, 0.1183, 0.1610, 0.3737], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,395 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,395 - train - INFO - True
2024-04-06 23:44:14,398 - train - INFO - alphas:tensor([0.3461, 0.1095, 0.1674, 0.3770], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,399 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,399 - train - INFO - True
2024-04-06 23:44:14,400 - train - INFO - alphas:tensor([0.4270, 0.1207, 0.1554, 0.2968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,401 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,401 - train - INFO - True
2024-04-06 23:44:14,402 - train - INFO - alphas:tensor([0.4692, 0.0985, 0.1025, 0.1301, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,404 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,404 - train - INFO - True
2024-04-06 23:44:14,405 - train - INFO - alphas:tensor([0.1648, 0.0513, 0.0626, 0.1333, 0.5879], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,406 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,406 - train - INFO - True
2024-04-06 23:44:14,407 - train - INFO - alphas:tensor([0.1755, 0.0496, 0.0619, 0.1233, 0.5897], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,408 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,408 - train - INFO - True
2024-04-06 23:44:14,409 - train - INFO - alphas:tensor([0.1716, 0.0469, 0.0574, 0.1247, 0.5995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,410 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,410 - train - INFO - True
2024-04-06 23:44:14,411 - train - INFO - alphas:tensor([0.1584, 0.0486, 0.0600, 0.1318, 0.6012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,412 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,412 - train - INFO - True
2024-04-06 23:44:14,413 - train - INFO - alphas:tensor([0.4846, 0.0793, 0.0914, 0.1258, 0.2189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,414 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,414 - train - INFO - True
2024-04-06 23:44:14,423 - train - INFO - alphas:tensor([0.5562, 0.0796, 0.0818, 0.1045, 0.1779], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,427 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,427 - train - INFO - True
2024-04-06 23:44:14,435 - train - INFO - alphas:tensor([0.1651, 0.0571, 0.0642, 0.1480, 0.5656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,437 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,437 - train - INFO - True
2024-04-06 23:44:14,438 - train - INFO - alphas:tensor([0.1803, 0.0510, 0.0629, 0.1454, 0.5605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,440 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,440 - train - INFO - True
2024-04-06 23:44:14,441 - train - INFO - alphas:tensor([0.1968, 0.0467, 0.0624, 0.1346, 0.5595], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,443 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,443 - train - INFO - True
2024-04-06 23:44:14,444 - train - INFO - alphas:tensor([0.1684, 0.0540, 0.0639, 0.1320, 0.5817], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,446 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,446 - train - INFO - True
2024-04-06 23:44:14,447 - train - INFO - alphas:tensor([0.1941, 0.0467, 0.0631, 0.1356, 0.5604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,449 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,449 - train - INFO - True
2024-04-06 23:44:14,450 - train - INFO - alphas:tensor([0.1477, 0.0565, 0.0699, 0.1482, 0.5777], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,452 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,452 - train - INFO - True
2024-04-06 23:44:14,453 - train - INFO - alphas:tensor([0.5234, 0.0631, 0.0700, 0.1133, 0.2302], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,456 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,456 - train - INFO - True
2024-04-06 23:44:14,457 - train - INFO - alphas:tensor([0.4348, 0.0577, 0.0659, 0.1190, 0.3227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,465 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,465 - train - INFO - True
2024-04-06 23:44:14,466 - train - INFO - alphas:tensor([0.2992, 0.0488, 0.0622, 0.1223, 0.4675], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,470 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,470 - train - INFO - True
2024-04-06 23:44:14,471 - train - INFO - alphas:tensor([0.3102, 0.0498, 0.0593, 0.1213, 0.4594], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,475 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,475 - train - INFO - True
2024-04-06 23:44:14,476 - train - INFO - alphas:tensor([0.3253, 0.0471, 0.0572, 0.1193, 0.4510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,479 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,480 - train - INFO - True
2024-04-06 23:44:14,480 - train - INFO - alphas:tensor([0.2907, 0.0457, 0.0604, 0.1215, 0.4817], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,484 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,484 - train - INFO - True
2024-04-06 23:44:14,485 - train - INFO - alphas:tensor([0.4564, 0.0486, 0.0610, 0.1037, 0.3303], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,493 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,493 - train - INFO - True
2024-04-06 23:44:14,494 - train - INFO - alphas:tensor([0.5961, 0.0494, 0.0591, 0.0895, 0.2059], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,513 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,513 - train - INFO - True
2024-04-06 23:44:14,515 - train - INFO - alphas:tensor([0.2440, 0.0368, 0.0465, 0.1163, 0.5564], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,525 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,525 - train - INFO - True
2024-04-06 23:44:14,530 - train - INFO - alphas:tensor([0.2567, 0.0337, 0.0438, 0.1090, 0.5568], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,540 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,540 - train - INFO - True
2024-04-06 23:44:14,542 - train - INFO - alphas:tensor([0.2823, 0.0338, 0.0426, 0.1054, 0.5359], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,552 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,553 - train - INFO - True
2024-04-06 23:44:14,554 - train - INFO - alphas:tensor([0.2430, 0.0379, 0.0452, 0.1137, 0.5601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,564 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,564 - train - INFO - True
2024-04-06 23:44:14,566 - train - INFO - alphas:tensor([0.6021, 0.0409, 0.0499, 0.0824, 0.2248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,585 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,585 - train - INFO - True
2024-04-06 23:44:14,588 - train - INFO - alphas:tensor([0.4417, 0.0445, 0.0542, 0.0993, 0.3603], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:44:14,670 - train - INFO - tau:0.8345137614500874
2024-04-06 23:44:14,670 - train - INFO - avg block size:9.606060606060606
2024-04-06 23:44:14,670 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-06 23:44:14,671 - train - INFO - lasso_alpha:4.287177620000003e-05
2024-04-06 23:44:14,919 - train - INFO - Test: [   0/78]  Time: 0.244 (0.244)  Loss:  1.0957 (1.0957)  Acc@1: 78.1250 (78.1250)  Acc@5: 89.8438 (89.8438)
2024-04-06 23:44:19,165 - train - INFO - Test: [  50/78]  Time: 0.052 (0.088)  Loss:  2.0352 (1.7937)  Acc@1: 50.0000 (59.4363)  Acc@5: 77.3438 (82.3070)
2024-04-06 23:44:21,354 - train - INFO - Test: [  78/78]  Time: 0.048 (0.085)  Loss:  2.0195 (1.8049)  Acc@1: 50.0000 (59.3800)  Acc@5: 87.5000 (82.0500)
2024-04-06 23:44:21,994 - train - INFO - Train: 21 [   0/781 (  0%)]  Loss:  3.900197 (3.9002)  Time: 0.555s,  230.49/s  (0.555s,  230.49/s)  LR: 4.767e-04  Data: 0.150 (0.150)
2024-04-06 23:44:47,207 - train - INFO - Train: 21 [  50/781 (  6%)]  Loss:  3.537590 (3.9213)  Time: 0.586s,  218.44/s  (0.505s,  253.35/s)  LR: 4.767e-04  Data: 0.009 (0.011)
2024-04-06 23:45:12,294 - train - INFO - Train: 21 [ 100/781 ( 13%)]  Loss:  3.868241 (3.9150)  Time: 0.545s,  235.01/s  (0.503s,  254.23/s)  LR: 4.767e-04  Data: 0.008 (0.009)
2024-04-06 23:45:37,567 - train - INFO - Train: 21 [ 150/781 ( 19%)]  Loss:  3.876530 (3.9025)  Time: 0.436s,  293.79/s  (0.504s,  253.91/s)  LR: 4.767e-04  Data: 0.011 (0.009)
2024-04-06 23:46:02,355 - train - INFO - Train: 21 [ 200/781 ( 26%)]  Loss:  3.920392 (3.9011)  Time: 0.543s,  235.53/s  (0.502s,  254.96/s)  LR: 4.767e-04  Data: 0.008 (0.009)
2024-04-06 23:46:27,785 - train - INFO - Train: 21 [ 250/781 ( 32%)]  Loss:  3.987514 (3.9036)  Time: 0.463s,  276.58/s  (0.503s,  254.30/s)  LR: 4.767e-04  Data: 0.004 (0.008)
2024-04-06 23:46:52,010 - train - INFO - Train: 21 [ 300/781 ( 38%)]  Loss:  3.998128 (3.8936)  Time: 0.515s,  248.74/s  (0.500s,  255.90/s)  LR: 4.767e-04  Data: 0.009 (0.008)
2024-04-06 23:47:16,952 - train - INFO - Train: 21 [ 350/781 ( 45%)]  Loss:  3.814101 (3.8938)  Time: 0.554s,  230.89/s  (0.500s,  256.00/s)  LR: 4.767e-04  Data: 0.005 (0.008)
2024-04-06 23:47:41,667 - train - INFO - Train: 21 [ 400/781 ( 51%)]  Loss:  4.198707 (3.8912)  Time: 0.523s,  244.56/s  (0.499s,  256.36/s)  LR: 4.767e-04  Data: 0.007 (0.008)
2024-04-06 23:48:06,404 - train - INFO - Train: 21 [ 450/781 ( 58%)]  Loss:  4.155542 (3.8857)  Time: 0.532s,  240.47/s  (0.499s,  256.63/s)  LR: 4.767e-04  Data: 0.007 (0.008)
2024-04-06 23:48:31,450 - train - INFO - Train: 21 [ 500/781 ( 64%)]  Loss:  3.709714 (3.8858)  Time: 0.475s,  269.70/s  (0.499s,  256.52/s)  LR: 4.767e-04  Data: 0.009 (0.008)
2024-04-06 23:48:56,781 - train - INFO - Train: 21 [ 550/781 ( 71%)]  Loss:  4.117987 (3.8862)  Time: 0.525s,  243.61/s  (0.500s,  256.16/s)  LR: 4.767e-04  Data: 0.006 (0.008)
2024-04-06 23:49:21,696 - train - INFO - Train: 21 [ 600/781 ( 77%)]  Loss:  4.024554 (3.8856)  Time: 0.486s,  263.59/s  (0.500s,  256.22/s)  LR: 4.767e-04  Data: 0.005 (0.008)
2024-04-06 23:49:46,486 - train - INFO - Train: 21 [ 650/781 ( 83%)]  Loss:  4.064920 (3.8832)  Time: 0.486s,  263.37/s  (0.499s,  256.37/s)  LR: 4.767e-04  Data: 0.007 (0.008)
2024-04-06 23:50:11,374 - train - INFO - Train: 21 [ 700/781 ( 90%)]  Loss:  3.451168 (3.8836)  Time: 0.501s,  255.68/s  (0.499s,  256.43/s)  LR: 4.767e-04  Data: 0.007 (0.008)
2024-04-06 23:50:36,018 - train - INFO - Train: 21 [ 750/781 ( 96%)]  Loss:  3.577636 (3.8859)  Time: 0.467s,  273.92/s  (0.499s,  256.65/s)  LR: 4.767e-04  Data: 0.005 (0.008)
2024-04-06 23:50:51,012 - train - INFO - Train: 21 [ 780/781 (100%)]  Loss:  3.907897 (3.8872)  Time: 0.365s,  350.75/s  (0.499s,  256.63/s)  LR: 4.767e-04  Data: 0.000 (0.008)
2024-04-06 23:50:51,013 - train - INFO - True
2024-04-06 23:50:51,014 - train - INFO - alphas:tensor([0.3951, 0.1319, 0.1326, 0.1564, 0.1840], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,015 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,015 - train - INFO - True
2024-04-06 23:50:51,016 - train - INFO - alphas:tensor([0.3869, 0.0988, 0.1138, 0.1537, 0.2468], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,016 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,016 - train - INFO - True
2024-04-06 23:50:51,021 - train - INFO - alphas:tensor([0.4015, 0.1238, 0.1728, 0.3018], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,022 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,022 - train - INFO - True
2024-04-06 23:50:51,027 - train - INFO - alphas:tensor([0.3350, 0.1133, 0.1591, 0.3925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,028 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,028 - train - INFO - True
2024-04-06 23:50:51,033 - train - INFO - alphas:tensor([0.3348, 0.1045, 0.1637, 0.3970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,033 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,033 - train - INFO - True
2024-04-06 23:50:51,038 - train - INFO - alphas:tensor([0.4189, 0.1172, 0.1535, 0.3104], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,038 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,039 - train - INFO - True
2024-04-06 23:50:51,042 - train - INFO - alphas:tensor([0.4632, 0.0956, 0.1000, 0.1304, 0.2107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,043 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,043 - train - INFO - True
2024-04-06 23:50:51,045 - train - INFO - alphas:tensor([0.1579, 0.0482, 0.0580, 0.1287, 0.6072], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,046 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,046 - train - INFO - True
2024-04-06 23:50:51,050 - train - INFO - alphas:tensor([0.1672, 0.0458, 0.0577, 0.1185, 0.6107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,051 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,051 - train - INFO - True
2024-04-06 23:50:51,056 - train - INFO - alphas:tensor([0.1649, 0.0434, 0.0531, 0.1191, 0.6196], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,056 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,056 - train - INFO - True
2024-04-06 23:50:51,061 - train - INFO - alphas:tensor([0.1519, 0.0459, 0.0564, 0.1278, 0.6181], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,061 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,061 - train - INFO - True
2024-04-06 23:50:51,062 - train - INFO - alphas:tensor([0.4786, 0.0754, 0.0879, 0.1273, 0.2309], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,063 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,064 - train - INFO - True
2024-04-06 23:50:51,064 - train - INFO - alphas:tensor([0.5525, 0.0765, 0.0797, 0.1052, 0.1861], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,068 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,068 - train - INFO - True
2024-04-06 23:50:51,069 - train - INFO - alphas:tensor([0.1568, 0.0544, 0.0617, 0.1441, 0.5830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,071 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,071 - train - INFO - True
2024-04-06 23:50:51,072 - train - INFO - alphas:tensor([0.1721, 0.0479, 0.0594, 0.1446, 0.5759], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,074 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,074 - train - INFO - True
2024-04-06 23:50:51,075 - train - INFO - alphas:tensor([0.1877, 0.0451, 0.0599, 0.1318, 0.5754], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,077 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,077 - train - INFO - True
2024-04-06 23:50:51,078 - train - INFO - alphas:tensor([0.1611, 0.0508, 0.0610, 0.1320, 0.5952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,080 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,080 - train - INFO - True
2024-04-06 23:50:51,081 - train - INFO - alphas:tensor([0.1889, 0.0438, 0.0598, 0.1308, 0.5767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,083 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,083 - train - INFO - True
2024-04-06 23:50:51,084 - train - INFO - alphas:tensor([0.1443, 0.0549, 0.0681, 0.1463, 0.5864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,085 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,086 - train - INFO - True
2024-04-06 23:50:51,087 - train - INFO - alphas:tensor([0.5119, 0.0601, 0.0678, 0.1133, 0.2469], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,090 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,090 - train - INFO - True
2024-04-06 23:50:51,091 - train - INFO - alphas:tensor([0.4226, 0.0540, 0.0630, 0.1173, 0.3431], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,098 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,099 - train - INFO - True
2024-04-06 23:50:51,099 - train - INFO - alphas:tensor([0.2910, 0.0448, 0.0593, 0.1206, 0.4843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,103 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,103 - train - INFO - True
2024-04-06 23:50:51,104 - train - INFO - alphas:tensor([0.3007, 0.0465, 0.0559, 0.1213, 0.4756], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,108 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,108 - train - INFO - True
2024-04-06 23:50:51,109 - train - INFO - alphas:tensor([0.3164, 0.0438, 0.0544, 0.1170, 0.4684], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,113 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,113 - train - INFO - True
2024-04-06 23:50:51,114 - train - INFO - alphas:tensor([0.2825, 0.0437, 0.0578, 0.1199, 0.4961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,118 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,118 - train - INFO - True
2024-04-06 23:50:51,119 - train - INFO - alphas:tensor([0.4442, 0.0454, 0.0587, 0.1032, 0.3484], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,126 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,127 - train - INFO - True
2024-04-06 23:50:51,127 - train - INFO - alphas:tensor([0.5862, 0.0468, 0.0569, 0.0909, 0.2192], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,147 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,147 - train - INFO - True
2024-04-06 23:50:51,148 - train - INFO - alphas:tensor([0.2339, 0.0345, 0.0451, 0.1159, 0.5708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,158 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,158 - train - INFO - True
2024-04-06 23:50:51,159 - train - INFO - alphas:tensor([0.2449, 0.0319, 0.0421, 0.1103, 0.5708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,169 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,169 - train - INFO - True
2024-04-06 23:50:51,170 - train - INFO - alphas:tensor([0.2676, 0.0316, 0.0405, 0.1047, 0.5556], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,180 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,180 - train - INFO - True
2024-04-06 23:50:51,181 - train - INFO - alphas:tensor([0.2320, 0.0357, 0.0425, 0.1141, 0.5757], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,191 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,192 - train - INFO - True
2024-04-06 23:50:51,193 - train - INFO - alphas:tensor([0.5816, 0.0396, 0.0484, 0.0819, 0.2485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,212 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,212 - train - INFO - True
2024-04-06 23:50:51,213 - train - INFO - alphas:tensor([0.4343, 0.0427, 0.0515, 0.0992, 0.3723], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:50:51,291 - train - INFO - tau:0.8261686238355865
2024-04-06 23:50:51,291 - train - INFO - avg block size:9.606060606060606
2024-04-06 23:50:51,291 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-06 23:50:51,467 - train - INFO - Test: [   0/78]  Time: 0.172 (0.172)  Loss:  0.9517 (0.9517)  Acc@1: 82.8125 (82.8125)  Acc@5: 94.5312 (94.5312)
2024-04-06 23:50:55,595 - train - INFO - Test: [  50/78]  Time: 0.134 (0.084)  Loss:  1.9414 (1.8301)  Acc@1: 57.0312 (59.1299)  Acc@5: 82.8125 (82.6440)
2024-04-06 23:50:57,924 - train - INFO - Test: [  78/78]  Time: 0.051 (0.084)  Loss:  2.1621 (1.8355)  Acc@1: 50.0000 (59.0200)  Acc@5: 87.5000 (82.4200)
2024-04-06 23:50:59,339 - train - INFO - Train: 22 [   0/781 (  0%)]  Loss:  3.674353 (3.6744)  Time: 1.241s,  103.13/s  (1.241s,  103.13/s)  LR: 4.744e-04  Data: 0.176 (0.176)
2024-04-06 23:51:30,794 - train - INFO - Train: 22 [  50/781 (  6%)]  Loss:  4.052282 (3.8765)  Time: 0.472s,  271.08/s  (0.641s,  199.67/s)  LR: 4.744e-04  Data: 0.009 (0.011)
2024-04-06 23:52:01,179 - train - INFO - Train: 22 [ 100/781 ( 13%)]  Loss:  4.115426 (3.8637)  Time: 0.412s,  310.76/s  (0.625s,  204.95/s)  LR: 4.744e-04  Data: 0.006 (0.009)
2024-04-06 23:52:32,736 - train - INFO - Train: 22 [ 150/781 ( 19%)]  Loss:  3.984294 (3.8818)  Time: 1.020s,  125.52/s  (0.627s,  204.24/s)  LR: 4.744e-04  Data: 0.010 (0.009)
2024-04-06 23:53:03,155 - train - INFO - Train: 22 [ 200/781 ( 26%)]  Loss:  3.532429 (3.8759)  Time: 0.812s,  157.55/s  (0.622s,  205.74/s)  LR: 4.744e-04  Data: 0.004 (0.008)
2024-04-06 23:53:27,719 - train - INFO - Train: 22 [ 250/781 ( 32%)]  Loss:  3.950379 (3.8781)  Time: 0.472s,  271.39/s  (0.596s,  214.74/s)  LR: 4.744e-04  Data: 0.009 (0.008)
2024-04-06 23:53:51,676 - train - INFO - Train: 22 [ 300/781 ( 38%)]  Loss:  3.866421 (3.8850)  Time: 0.478s,  267.80/s  (0.577s,  221.97/s)  LR: 4.744e-04  Data: 0.007 (0.008)
2024-04-06 23:54:16,122 - train - INFO - Train: 22 [ 350/781 ( 45%)]  Loss:  3.541260 (3.8855)  Time: 0.510s,  250.95/s  (0.564s,  226.89/s)  LR: 4.744e-04  Data: 0.009 (0.008)
2024-04-06 23:54:39,152 - train - INFO - Train: 22 [ 400/781 ( 51%)]  Loss:  3.857690 (3.8890)  Time: 0.512s,  250.17/s  (0.551s,  232.21/s)  LR: 4.744e-04  Data: 0.009 (0.008)
2024-04-06 23:55:02,637 - train - INFO - Train: 22 [ 450/781 ( 58%)]  Loss:  4.130128 (3.8868)  Time: 0.405s,  315.79/s  (0.542s,  236.08/s)  LR: 4.744e-04  Data: 0.007 (0.008)
2024-04-06 23:55:26,094 - train - INFO - Train: 22 [ 500/781 ( 64%)]  Loss:  4.126123 (3.8891)  Time: 0.486s,  263.51/s  (0.535s,  239.30/s)  LR: 4.744e-04  Data: 0.008 (0.008)
2024-04-06 23:55:50,317 - train - INFO - Train: 22 [ 550/781 ( 71%)]  Loss:  3.665809 (3.8913)  Time: 0.451s,  284.11/s  (0.530s,  241.37/s)  LR: 4.744e-04  Data: 0.009 (0.008)
2024-04-06 23:56:13,928 - train - INFO - Train: 22 [ 600/781 ( 77%)]  Loss:  3.924299 (3.8940)  Time: 0.454s,  282.14/s  (0.525s,  243.59/s)  LR: 4.744e-04  Data: 0.005 (0.008)
2024-04-06 23:56:37,486 - train - INFO - Train: 22 [ 650/781 ( 83%)]  Loss:  4.371396 (3.8972)  Time: 0.494s,  259.05/s  (0.521s,  245.54/s)  LR: 4.744e-04  Data: 0.008 (0.008)
2024-04-06 23:57:00,678 - train - INFO - Train: 22 [ 700/781 ( 90%)]  Loss:  3.565661 (3.8962)  Time: 0.461s,  277.63/s  (0.517s,  247.49/s)  LR: 4.744e-04  Data: 0.008 (0.008)
2024-04-06 23:57:23,772 - train - INFO - Train: 22 [ 750/781 ( 96%)]  Loss:  4.011329 (3.8969)  Time: 0.520s,  246.24/s  (0.514s,  249.26/s)  LR: 4.744e-04  Data: 0.021 (0.008)
2024-04-06 23:57:38,421 - train - INFO - Train: 22 [ 780/781 (100%)]  Loss:  3.884244 (3.8954)  Time: 0.526s,  243.36/s  (0.513s,  249.73/s)  LR: 4.744e-04  Data: 0.000 (0.008)
2024-04-06 23:57:38,422 - train - INFO - True
2024-04-06 23:57:38,424 - train - INFO - alphas:tensor([0.4009, 0.1294, 0.1309, 0.1547, 0.1841], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,425 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,425 - train - INFO - True
2024-04-06 23:57:38,427 - train - INFO - alphas:tensor([0.3840, 0.0945, 0.1099, 0.1534, 0.2581], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,428 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,428 - train - INFO - True
2024-04-06 23:57:38,429 - train - INFO - alphas:tensor([0.3972, 0.1196, 0.1706, 0.3126], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,430 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,430 - train - INFO - True
2024-04-06 23:57:38,432 - train - INFO - alphas:tensor([0.3283, 0.1094, 0.1561, 0.4062], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,432 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,433 - train - INFO - True
2024-04-06 23:57:38,434 - train - INFO - alphas:tensor([0.3281, 0.1019, 0.1615, 0.4085], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,435 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,435 - train - INFO - True
2024-04-06 23:57:38,436 - train - INFO - alphas:tensor([0.4138, 0.1139, 0.1509, 0.3214], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,437 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,438 - train - INFO - True
2024-04-06 23:57:38,439 - train - INFO - alphas:tensor([0.4580, 0.0934, 0.0982, 0.1309, 0.2195], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,440 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,441 - train - INFO - True
2024-04-06 23:57:38,442 - train - INFO - alphas:tensor([0.1567, 0.0466, 0.0547, 0.1244, 0.6175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,443 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,443 - train - INFO - True
2024-04-06 23:57:38,444 - train - INFO - alphas:tensor([0.1643, 0.0429, 0.0550, 0.1134, 0.6245], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,445 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,445 - train - INFO - True
2024-04-06 23:57:38,447 - train - INFO - alphas:tensor([0.1632, 0.0415, 0.0506, 0.1142, 0.6305], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,448 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,448 - train - INFO - True
2024-04-06 23:57:38,449 - train - INFO - alphas:tensor([0.1500, 0.0437, 0.0528, 0.1237, 0.6298], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,450 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,450 - train - INFO - True
2024-04-06 23:57:38,451 - train - INFO - alphas:tensor([0.4711, 0.0734, 0.0855, 0.1276, 0.2424], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,453 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,453 - train - INFO - True
2024-04-06 23:57:38,454 - train - INFO - alphas:tensor([0.5482, 0.0734, 0.0776, 0.1047, 0.1961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,459 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,459 - train - INFO - True
2024-04-06 23:57:38,460 - train - INFO - alphas:tensor([0.1544, 0.0524, 0.0609, 0.1453, 0.5869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,463 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,463 - train - INFO - True
2024-04-06 23:57:38,464 - train - INFO - alphas:tensor([0.1697, 0.0461, 0.0569, 0.1431, 0.5842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,466 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,466 - train - INFO - True
2024-04-06 23:57:38,468 - train - INFO - alphas:tensor([0.1845, 0.0430, 0.0571, 0.1284, 0.5870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,470 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,470 - train - INFO - True
2024-04-06 23:57:38,471 - train - INFO - alphas:tensor([0.1555, 0.0491, 0.0590, 0.1307, 0.6056], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,474 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,474 - train - INFO - True
2024-04-06 23:57:38,475 - train - INFO - alphas:tensor([0.1856, 0.0422, 0.0572, 0.1280, 0.5870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,477 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,477 - train - INFO - True
2024-04-06 23:57:38,478 - train - INFO - alphas:tensor([0.1406, 0.0534, 0.0662, 0.1459, 0.5939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,481 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,481 - train - INFO - True
2024-04-06 23:57:38,482 - train - INFO - alphas:tensor([0.5019, 0.0573, 0.0660, 0.1139, 0.2609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,486 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,486 - train - INFO - True
2024-04-06 23:57:38,487 - train - INFO - alphas:tensor([0.4165, 0.0513, 0.0598, 0.1158, 0.3566], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,495 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,495 - train - INFO - True
2024-04-06 23:57:38,496 - train - INFO - alphas:tensor([0.2847, 0.0415, 0.0569, 0.1186, 0.4983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,501 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,501 - train - INFO - True
2024-04-06 23:57:38,502 - train - INFO - alphas:tensor([0.2959, 0.0435, 0.0529, 0.1187, 0.4890], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,506 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,506 - train - INFO - True
2024-04-06 23:57:38,507 - train - INFO - alphas:tensor([0.3114, 0.0415, 0.0512, 0.1152, 0.4807], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,511 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,511 - train - INFO - True
2024-04-06 23:57:38,512 - train - INFO - alphas:tensor([0.2786, 0.0415, 0.0548, 0.1166, 0.5085], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,516 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,516 - train - INFO - True
2024-04-06 23:57:38,517 - train - INFO - alphas:tensor([0.4368, 0.0429, 0.0560, 0.1012, 0.3630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,524 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,524 - train - INFO - True
2024-04-06 23:57:38,525 - train - INFO - alphas:tensor([0.5822, 0.0443, 0.0546, 0.0885, 0.2304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,545 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,545 - train - INFO - True
2024-04-06 23:57:38,546 - train - INFO - alphas:tensor([0.2348, 0.0328, 0.0439, 0.1171, 0.5714], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,556 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,556 - train - INFO - True
2024-04-06 23:57:38,557 - train - INFO - alphas:tensor([0.2439, 0.0303, 0.0400, 0.1095, 0.5763], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,567 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,567 - train - INFO - True
2024-04-06 23:57:38,568 - train - INFO - alphas:tensor([0.2653, 0.0303, 0.0389, 0.1036, 0.5617], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,578 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,578 - train - INFO - True
2024-04-06 23:57:38,579 - train - INFO - alphas:tensor([0.2275, 0.0345, 0.0416, 0.1141, 0.5823], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,589 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,589 - train - INFO - True
2024-04-06 23:57:38,590 - train - INFO - alphas:tensor([0.5849, 0.0364, 0.0445, 0.0795, 0.2548], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,610 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,610 - train - INFO - True
2024-04-06 23:57:38,611 - train - INFO - alphas:tensor([0.4263, 0.0407, 0.0492, 0.0986, 0.3853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:57:38,688 - train - INFO - tau:0.8179069375972307
2024-04-06 23:57:38,689 - train - INFO - avg block size:9.606060606060606
2024-04-06 23:57:38,689 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-06 23:57:38,689 - train - INFO - lasso_alpha:4.715895382000004e-05
2024-04-06 23:57:38,913 - train - INFO - Test: [   0/78]  Time: 0.221 (0.221)  Loss:  1.0312 (1.0312)  Acc@1: 78.1250 (78.1250)  Acc@5: 92.1875 (92.1875)
2024-04-06 23:57:41,853 - train - INFO - Test: [  50/78]  Time: 0.057 (0.062)  Loss:  1.8281 (1.7811)  Acc@1: 57.0312 (59.6048)  Acc@5: 80.4688 (82.8278)
2024-04-06 23:57:43,371 - train - INFO - Test: [  78/78]  Time: 0.050 (0.059)  Loss:  2.1992 (1.7963)  Acc@1: 50.0000 (59.5000)  Acc@5: 81.2500 (82.4000)
2024-04-06 23:57:44,109 - train - INFO - Train: 23 [   0/781 (  0%)]  Loss:  3.755896 (3.7559)  Time: 0.655s,  195.28/s  (0.655s,  195.28/s)  LR: 4.721e-04  Data: 0.177 (0.177)
2024-04-06 23:58:08,103 - train - INFO - Train: 23 [  50/781 (  6%)]  Loss:  3.698483 (3.8911)  Time: 0.535s,  239.37/s  (0.483s,  264.84/s)  LR: 4.721e-04  Data: 0.007 (0.011)
2024-04-06 23:58:31,935 - train - INFO - Train: 23 [ 100/781 ( 13%)]  Loss:  4.096033 (3.9178)  Time: 0.484s,  264.54/s  (0.480s,  266.67/s)  LR: 4.721e-04  Data: 0.008 (0.009)
2024-04-06 23:58:55,603 - train - INFO - Train: 23 [ 150/781 ( 19%)]  Loss:  3.808036 (3.9095)  Time: 0.397s,  322.54/s  (0.478s,  267.90/s)  LR: 4.721e-04  Data: 0.006 (0.009)
2024-04-06 23:59:18,523 - train - INFO - Train: 23 [ 200/781 ( 26%)]  Loss:  4.174066 (3.9148)  Time: 0.386s,  331.47/s  (0.473s,  270.64/s)  LR: 4.721e-04  Data: 0.004 (0.008)
2024-04-06 23:59:41,783 - train - INFO - Train: 23 [ 250/781 ( 32%)]  Loss:  4.116513 (3.9046)  Time: 0.477s,  268.53/s  (0.471s,  271.53/s)  LR: 4.721e-04  Data: 0.008 (0.008)
2024-04-07 00:00:05,966 - train - INFO - Train: 23 [ 300/781 ( 38%)]  Loss:  3.697188 (3.9067)  Time: 0.402s,  318.59/s  (0.473s,  270.36/s)  LR: 4.721e-04  Data: 0.005 (0.008)
2024-04-07 00:00:30,020 - train - INFO - Train: 23 [ 350/781 ( 45%)]  Loss:  4.102845 (3.8964)  Time: 0.505s,  253.22/s  (0.475s,  269.75/s)  LR: 4.721e-04  Data: 0.010 (0.008)
2024-04-07 00:00:54,357 - train - INFO - Train: 23 [ 400/781 ( 51%)]  Loss:  4.017181 (3.8979)  Time: 0.512s,  250.22/s  (0.476s,  268.89/s)  LR: 4.721e-04  Data: 0.008 (0.008)
2024-04-07 00:01:17,924 - train - INFO - Train: 23 [ 450/781 ( 58%)]  Loss:  3.790951 (3.8999)  Time: 0.491s,  260.76/s  (0.476s,  269.18/s)  LR: 4.721e-04  Data: 0.008 (0.008)
2024-04-07 00:01:41,213 - train - INFO - Train: 23 [ 500/781 ( 64%)]  Loss:  4.490226 (3.9013)  Time: 0.483s,  265.17/s  (0.475s,  269.74/s)  LR: 4.721e-04  Data: 0.020 (0.008)
2024-04-07 00:02:04,453 - train - INFO - Train: 23 [ 550/781 ( 71%)]  Loss:  3.833827 (3.8998)  Time: 0.404s,  317.10/s  (0.474s,  270.24/s)  LR: 4.721e-04  Data: 0.005 (0.008)
2024-04-07 00:02:27,213 - train - INFO - Train: 23 [ 600/781 ( 77%)]  Loss:  4.069847 (3.9041)  Time: 0.463s,  276.55/s  (0.472s,  271.12/s)  LR: 4.721e-04  Data: 0.008 (0.008)
2024-04-07 00:02:50,499 - train - INFO - Train: 23 [ 650/781 ( 83%)]  Loss:  3.608660 (3.9031)  Time: 0.486s,  263.38/s  (0.472s,  271.40/s)  LR: 4.721e-04  Data: 0.009 (0.008)
2024-04-07 00:03:14,401 - train - INFO - Train: 23 [ 700/781 ( 90%)]  Loss:  3.982876 (3.9052)  Time: 0.491s,  260.67/s  (0.472s,  271.14/s)  LR: 4.721e-04  Data: 0.010 (0.008)
2024-04-07 00:03:38,443 - train - INFO - Train: 23 [ 750/781 ( 96%)]  Loss:  4.219114 (3.9111)  Time: 0.477s,  268.28/s  (0.473s,  270.81/s)  LR: 4.721e-04  Data: 0.008 (0.008)
2024-04-07 00:03:52,757 - train - INFO - Train: 23 [ 780/781 (100%)]  Loss:  3.670929 (3.9133)  Time: 0.450s,  284.69/s  (0.473s,  270.71/s)  LR: 4.721e-04  Data: 0.000 (0.008)
2024-04-07 00:03:52,758 - train - INFO - True
2024-04-07 00:03:52,759 - train - INFO - alphas:tensor([0.4053, 0.1267, 0.1293, 0.1539, 0.1848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,760 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,760 - train - INFO - True
2024-04-07 00:03:52,761 - train - INFO - alphas:tensor([0.3730, 0.0913, 0.1090, 0.1536, 0.2731], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,762 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,762 - train - INFO - True
2024-04-07 00:03:52,763 - train - INFO - alphas:tensor([0.3888, 0.1168, 0.1694, 0.3250], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,763 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,763 - train - INFO - True
2024-04-07 00:03:52,764 - train - INFO - alphas:tensor([0.3171, 0.1041, 0.1532, 0.4255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,765 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,765 - train - INFO - True
2024-04-07 00:03:52,766 - train - INFO - alphas:tensor([0.3165, 0.0987, 0.1590, 0.4258], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,766 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,766 - train - INFO - True
2024-04-07 00:03:52,767 - train - INFO - alphas:tensor([0.4010, 0.1107, 0.1487, 0.3396], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,768 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,768 - train - INFO - True
2024-04-07 00:03:52,769 - train - INFO - alphas:tensor([0.4517, 0.0896, 0.0960, 0.1307, 0.2320], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,770 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,770 - train - INFO - True
2024-04-07 00:03:52,771 - train - INFO - alphas:tensor([0.1504, 0.0443, 0.0516, 0.1201, 0.6336], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,772 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,772 - train - INFO - True
2024-04-07 00:03:52,773 - train - INFO - alphas:tensor([0.1574, 0.0403, 0.0517, 0.1100, 0.6405], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,774 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,774 - train - INFO - True
2024-04-07 00:03:52,775 - train - INFO - alphas:tensor([0.1578, 0.0384, 0.0483, 0.1102, 0.6453], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,775 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,776 - train - INFO - True
2024-04-07 00:03:52,776 - train - INFO - alphas:tensor([0.1460, 0.0409, 0.0492, 0.1193, 0.6445], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,777 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,777 - train - INFO - True
2024-04-07 00:03:52,778 - train - INFO - alphas:tensor([0.4645, 0.0699, 0.0836, 0.1278, 0.2541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,779 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,779 - train - INFO - True
2024-04-07 00:03:52,780 - train - INFO - alphas:tensor([0.5407, 0.0713, 0.0761, 0.1050, 0.2069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,784 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,784 - train - INFO - True
2024-04-07 00:03:52,785 - train - INFO - alphas:tensor([0.1490, 0.0495, 0.0569, 0.1421, 0.6026], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,787 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,787 - train - INFO - True
2024-04-07 00:03:52,788 - train - INFO - alphas:tensor([0.1612, 0.0431, 0.0541, 0.1403, 0.6013], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,790 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,790 - train - INFO - True
2024-04-07 00:03:52,791 - train - INFO - alphas:tensor([0.1788, 0.0411, 0.0545, 0.1276, 0.5980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,793 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,793 - train - INFO - True
2024-04-07 00:03:52,794 - train - INFO - alphas:tensor([0.1493, 0.0471, 0.0569, 0.1273, 0.6194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,795 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,796 - train - INFO - True
2024-04-07 00:03:52,796 - train - INFO - alphas:tensor([0.1754, 0.0388, 0.0550, 0.1239, 0.6068], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,798 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,798 - train - INFO - True
2024-04-07 00:03:52,799 - train - INFO - alphas:tensor([0.1331, 0.0514, 0.0643, 0.1435, 0.6077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,801 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,801 - train - INFO - True
2024-04-07 00:03:52,802 - train - INFO - alphas:tensor([0.4880, 0.0538, 0.0631, 0.1140, 0.2811], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,806 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,806 - train - INFO - True
2024-04-07 00:03:52,807 - train - INFO - alphas:tensor([0.4049, 0.0486, 0.0573, 0.1141, 0.3751], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,814 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,814 - train - INFO - True
2024-04-07 00:03:52,815 - train - INFO - alphas:tensor([0.2749, 0.0398, 0.0553, 0.1174, 0.5126], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,819 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,819 - train - INFO - True
2024-04-07 00:03:52,820 - train - INFO - alphas:tensor([0.2865, 0.0417, 0.0508, 0.1173, 0.5037], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,824 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,824 - train - INFO - True
2024-04-07 00:03:52,825 - train - INFO - alphas:tensor([0.2964, 0.0393, 0.0493, 0.1139, 0.5011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,829 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,829 - train - INFO - True
2024-04-07 00:03:52,830 - train - INFO - alphas:tensor([0.2685, 0.0391, 0.0517, 0.1135, 0.5272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,834 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,834 - train - INFO - True
2024-04-07 00:03:52,835 - train - INFO - alphas:tensor([0.4278, 0.0407, 0.0535, 0.0996, 0.3784], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,842 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,842 - train - INFO - True
2024-04-07 00:03:52,843 - train - INFO - alphas:tensor([0.5677, 0.0423, 0.0535, 0.0887, 0.2478], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,862 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,863 - train - INFO - True
2024-04-07 00:03:52,863 - train - INFO - alphas:tensor([0.2234, 0.0308, 0.0427, 0.1161, 0.5870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,874 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,874 - train - INFO - True
2024-04-07 00:03:52,875 - train - INFO - alphas:tensor([0.2332, 0.0283, 0.0382, 0.1082, 0.5921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,885 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,885 - train - INFO - True
2024-04-07 00:03:52,886 - train - INFO - alphas:tensor([0.2578, 0.0281, 0.0361, 0.1033, 0.5749], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,896 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,896 - train - INFO - True
2024-04-07 00:03:52,897 - train - INFO - alphas:tensor([0.2205, 0.0327, 0.0399, 0.1158, 0.5911], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,907 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,907 - train - INFO - True
2024-04-07 00:03:52,908 - train - INFO - alphas:tensor([0.5661, 0.0350, 0.0428, 0.0802, 0.2760], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,927 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,927 - train - INFO - True
2024-04-07 00:03:52,928 - train - INFO - alphas:tensor([0.4136, 0.0397, 0.0481, 0.0991, 0.3996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:03:52,994 - train - INFO - tau:0.8097278682212583
2024-04-07 00:03:52,994 - train - INFO - avg block size:9.606060606060606
2024-04-07 00:03:52,995 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 00:03:53,203 - train - INFO - Test: [   0/78]  Time: 0.205 (0.205)  Loss:  0.9292 (0.9292)  Acc@1: 81.2500 (81.2500)  Acc@5: 94.5312 (94.5312)
2024-04-07 00:03:56,774 - train - INFO - Test: [  50/78]  Time: 0.078 (0.074)  Loss:  2.1484 (1.7804)  Acc@1: 54.6875 (59.1452)  Acc@5: 75.0000 (82.8738)
2024-04-07 00:03:58,554 - train - INFO - Test: [  78/78]  Time: 0.047 (0.070)  Loss:  1.8691 (1.7889)  Acc@1: 56.2500 (59.3100)  Acc@5: 87.5000 (82.3900)
2024-04-07 00:03:59,204 - train - INFO - Train: 24 [   0/781 (  0%)]  Loss:  3.954143 (3.9541)  Time: 0.566s,  226.03/s  (0.566s,  226.03/s)  LR: 4.697e-04  Data: 0.182 (0.182)
2024-04-07 00:04:22,738 - train - INFO - Train: 24 [  50/781 (  6%)]  Loss:  3.728199 (3.9020)  Time: 0.425s,  301.12/s  (0.473s,  270.88/s)  LR: 4.697e-04  Data: 0.008 (0.011)
2024-04-07 00:04:46,367 - train - INFO - Train: 24 [ 100/781 ( 13%)]  Loss:  4.072687 (3.9043)  Time: 0.492s,  260.07/s  (0.473s,  270.88/s)  LR: 4.697e-04  Data: 0.008 (0.009)
2024-04-07 00:05:09,922 - train - INFO - Train: 24 [ 150/781 ( 19%)]  Loss:  4.205367 (3.9019)  Time: 0.520s,  246.20/s  (0.472s,  271.16/s)  LR: 4.697e-04  Data: 0.010 (0.009)
2024-04-07 00:05:33,588 - train - INFO - Train: 24 [ 200/781 ( 26%)]  Loss:  3.693645 (3.8890)  Time: 0.412s,  310.77/s  (0.472s,  270.98/s)  LR: 4.697e-04  Data: 0.006 (0.008)
2024-04-07 00:05:56,506 - train - INFO - Train: 24 [ 250/781 ( 32%)]  Loss:  4.111753 (3.8941)  Time: 0.490s,  261.15/s  (0.470s,  272.59/s)  LR: 4.697e-04  Data: 0.007 (0.008)
2024-04-07 00:06:21,746 - train - INFO - Train: 24 [ 300/781 ( 38%)]  Loss:  3.394244 (3.8938)  Time: 0.500s,  256.19/s  (0.475s,  269.24/s)  LR: 4.697e-04  Data: 0.008 (0.008)
2024-04-07 00:06:45,925 - train - INFO - Train: 24 [ 350/781 ( 45%)]  Loss:  4.128758 (3.8903)  Time: 0.437s,  292.66/s  (0.477s,  268.59/s)  LR: 4.697e-04  Data: 0.007 (0.008)
2024-04-07 00:07:09,423 - train - INFO - Train: 24 [ 400/781 ( 51%)]  Loss:  3.909810 (3.8850)  Time: 0.560s,  228.60/s  (0.476s,  269.05/s)  LR: 4.697e-04  Data: 0.009 (0.008)
2024-04-07 00:07:33,316 - train - INFO - Train: 24 [ 450/781 ( 58%)]  Loss:  4.076702 (3.8828)  Time: 0.470s,  272.21/s  (0.476s,  268.92/s)  LR: 4.697e-04  Data: 0.007 (0.008)
2024-04-07 00:07:58,134 - train - INFO - Train: 24 [ 500/781 ( 64%)]  Loss:  3.927341 (3.8869)  Time: 0.406s,  315.34/s  (0.478s,  267.78/s)  LR: 4.697e-04  Data: 0.005 (0.008)
2024-04-07 00:08:21,825 - train - INFO - Train: 24 [ 550/781 ( 71%)]  Loss:  3.862626 (3.8825)  Time: 0.476s,  269.18/s  (0.478s,  267.99/s)  LR: 4.697e-04  Data: 0.008 (0.008)
2024-04-07 00:08:46,462 - train - INFO - Train: 24 [ 600/781 ( 77%)]  Loss:  4.041238 (3.8876)  Time: 0.582s,  219.83/s  (0.479s,  267.29/s)  LR: 4.697e-04  Data: 0.007 (0.008)
2024-04-07 00:09:11,630 - train - INFO - Train: 24 [ 650/781 ( 83%)]  Loss:  4.073452 (3.8902)  Time: 0.368s,  348.12/s  (0.481s,  266.25/s)  LR: 4.697e-04  Data: 0.007 (0.008)
2024-04-07 00:09:35,106 - train - INFO - Train: 24 [ 700/781 ( 90%)]  Loss:  3.483480 (3.8901)  Time: 0.537s,  238.28/s  (0.480s,  266.69/s)  LR: 4.697e-04  Data: 0.009 (0.008)
2024-04-07 00:09:59,464 - train - INFO - Train: 24 [ 750/781 ( 96%)]  Loss:  3.973368 (3.8902)  Time: 0.481s,  266.04/s  (0.480s,  266.43/s)  LR: 4.697e-04  Data: 0.007 (0.008)
2024-04-07 00:10:12,723 - train - INFO - Train: 24 [ 780/781 (100%)]  Loss:  3.652076 (3.8907)  Time: 0.431s,  297.16/s  (0.479s,  267.25/s)  LR: 4.697e-04  Data: 0.000 (0.008)
2024-04-07 00:10:12,725 - train - INFO - True
2024-04-07 00:10:12,732 - train - INFO - alphas:tensor([0.4095, 0.1248, 0.1279, 0.1524, 0.1855], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,732 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,733 - train - INFO - True
2024-04-07 00:10:12,738 - train - INFO - alphas:tensor([0.3670, 0.0876, 0.1055, 0.1534, 0.2865], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,739 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,739 - train - INFO - True
2024-04-07 00:10:12,744 - train - INFO - alphas:tensor([0.3828, 0.1133, 0.1682, 0.3357], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,745 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,745 - train - INFO - True
2024-04-07 00:10:12,750 - train - INFO - alphas:tensor([0.3080, 0.0992, 0.1489, 0.4439], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,751 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,751 - train - INFO - True
2024-04-07 00:10:12,756 - train - INFO - alphas:tensor([0.3081, 0.0932, 0.1574, 0.4413], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,757 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,757 - train - INFO - True
2024-04-07 00:10:12,761 - train - INFO - alphas:tensor([0.3924, 0.1069, 0.1467, 0.3539], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,763 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,763 - train - INFO - True
2024-04-07 00:10:12,764 - train - INFO - alphas:tensor([0.4480, 0.0865, 0.0933, 0.1307, 0.2415], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,766 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,766 - train - INFO - True
2024-04-07 00:10:12,767 - train - INFO - alphas:tensor([0.1453, 0.0412, 0.0486, 0.1151, 0.6498], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,768 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,768 - train - INFO - True
2024-04-07 00:10:12,769 - train - INFO - alphas:tensor([0.1554, 0.0387, 0.0485, 0.1067, 0.6506], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,770 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,771 - train - INFO - True
2024-04-07 00:10:12,772 - train - INFO - alphas:tensor([0.1519, 0.0364, 0.0455, 0.1056, 0.6606], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,773 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,773 - train - INFO - True
2024-04-07 00:10:12,774 - train - INFO - alphas:tensor([0.1417, 0.0382, 0.0460, 0.1133, 0.6608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,775 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,775 - train - INFO - True
2024-04-07 00:10:12,776 - train - INFO - alphas:tensor([0.4568, 0.0668, 0.0811, 0.1272, 0.2682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,778 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,778 - train - INFO - True
2024-04-07 00:10:12,779 - train - INFO - alphas:tensor([0.5358, 0.0680, 0.0743, 0.1046, 0.2172], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,784 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,784 - train - INFO - True
2024-04-07 00:10:12,785 - train - INFO - alphas:tensor([0.1462, 0.0479, 0.0554, 0.1414, 0.6090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,787 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,787 - train - INFO - True
2024-04-07 00:10:12,789 - train - INFO - alphas:tensor([0.1592, 0.0418, 0.0522, 0.1378, 0.6089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,791 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,791 - train - INFO - True
2024-04-07 00:10:12,792 - train - INFO - alphas:tensor([0.1727, 0.0393, 0.0537, 0.1252, 0.6090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,794 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,795 - train - INFO - True
2024-04-07 00:10:12,796 - train - INFO - alphas:tensor([0.1481, 0.0452, 0.0552, 0.1243, 0.6272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,798 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,798 - train - INFO - True
2024-04-07 00:10:12,799 - train - INFO - alphas:tensor([0.1738, 0.0381, 0.0535, 0.1251, 0.6096], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,801 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,802 - train - INFO - True
2024-04-07 00:10:12,803 - train - INFO - alphas:tensor([0.1294, 0.0508, 0.0629, 0.1409, 0.6159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,805 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,805 - train - INFO - True
2024-04-07 00:10:12,806 - train - INFO - alphas:tensor([0.4856, 0.0509, 0.0597, 0.1111, 0.2926], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,810 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,810 - train - INFO - True
2024-04-07 00:10:12,811 - train - INFO - alphas:tensor([0.3968, 0.0456, 0.0541, 0.1125, 0.3910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,819 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,819 - train - INFO - True
2024-04-07 00:10:12,820 - train - INFO - alphas:tensor([0.2726, 0.0378, 0.0524, 0.1133, 0.5238], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,825 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,825 - train - INFO - True
2024-04-07 00:10:12,826 - train - INFO - alphas:tensor([0.2807, 0.0395, 0.0483, 0.1151, 0.5165], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,830 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,830 - train - INFO - True
2024-04-07 00:10:12,831 - train - INFO - alphas:tensor([0.2962, 0.0366, 0.0462, 0.1123, 0.5087], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,835 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,835 - train - INFO - True
2024-04-07 00:10:12,836 - train - INFO - alphas:tensor([0.2673, 0.0373, 0.0492, 0.1127, 0.5335], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,840 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,840 - train - INFO - True
2024-04-07 00:10:12,841 - train - INFO - alphas:tensor([0.4187, 0.0377, 0.0504, 0.0981, 0.3951], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,848 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,848 - train - INFO - True
2024-04-07 00:10:12,849 - train - INFO - alphas:tensor([0.5609, 0.0400, 0.0514, 0.0883, 0.2593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,867 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,867 - train - INFO - True
2024-04-07 00:10:12,868 - train - INFO - alphas:tensor([0.2220, 0.0297, 0.0407, 0.1143, 0.5934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,877 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,877 - train - INFO - True
2024-04-07 00:10:12,879 - train - INFO - alphas:tensor([0.2275, 0.0270, 0.0374, 0.1086, 0.5995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,887 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,887 - train - INFO - True
2024-04-07 00:10:12,889 - train - INFO - alphas:tensor([0.2539, 0.0272, 0.0355, 0.1027, 0.5808], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,897 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,898 - train - INFO - True
2024-04-07 00:10:12,900 - train - INFO - alphas:tensor([0.2187, 0.0315, 0.0389, 0.1135, 0.5974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,908 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,908 - train - INFO - True
2024-04-07 00:10:12,911 - train - INFO - alphas:tensor([0.5620, 0.0325, 0.0405, 0.0779, 0.2871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,925 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,925 - train - INFO - True
2024-04-07 00:10:12,927 - train - INFO - alphas:tensor([0.4049, 0.0383, 0.0465, 0.0973, 0.4130], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:10:12,954 - train - INFO - tau:0.8016305895390458
2024-04-07 00:10:12,954 - train - INFO - avg block size:10.06060606060606
2024-04-07 00:10:12,954 - train - INFO - current latency ratio:tensor(0.2204)
2024-04-07 00:10:12,955 - train - INFO - lasso_alpha:4.287177620000003e-05
2024-04-07 00:10:13,202 - train - INFO - Test: [   0/78]  Time: 0.245 (0.245)  Loss:  1.0342 (1.0342)  Acc@1: 78.1250 (78.1250)  Acc@5: 92.1875 (92.1875)
2024-04-07 00:10:18,287 - train - INFO - Test: [  50/78]  Time: 0.069 (0.104)  Loss:  1.8135 (1.7418)  Acc@1: 59.3750 (59.8192)  Acc@5: 82.8125 (83.1036)
2024-04-07 00:10:20,891 - train - INFO - Test: [  78/78]  Time: 0.124 (0.100)  Loss:  2.1992 (1.7484)  Acc@1: 50.0000 (60.0300)  Acc@5: 81.2500 (82.9800)
2024-04-07 00:10:21,652 - train - INFO - Train: 25 [   0/781 (  0%)]  Loss:  4.032434 (4.0324)  Time: 0.682s,  187.80/s  (0.682s,  187.80/s)  LR: 4.672e-04  Data: 0.134 (0.134)
2024-04-07 00:10:45,121 - train - INFO - Train: 25 [  50/781 (  6%)]  Loss:  4.133403 (3.9006)  Time: 0.465s,  275.32/s  (0.474s,  270.32/s)  LR: 4.672e-04  Data: 0.008 (0.009)
2024-04-07 00:11:08,075 - train - INFO - Train: 25 [ 100/781 ( 13%)]  Loss:  3.938821 (3.8750)  Time: 0.472s,  271.24/s  (0.466s,  274.47/s)  LR: 4.672e-04  Data: 0.008 (0.008)
2024-04-07 00:11:33,221 - train - INFO - Train: 25 [ 150/781 ( 19%)]  Loss:  3.989087 (3.8823)  Time: 0.497s,  257.68/s  (0.478s,  267.53/s)  LR: 4.672e-04  Data: 0.009 (0.008)
2024-04-07 00:11:57,263 - train - INFO - Train: 25 [ 200/781 ( 26%)]  Loss:  3.952929 (3.8903)  Time: 0.419s,  305.25/s  (0.479s,  267.20/s)  LR: 4.672e-04  Data: 0.006 (0.008)
2024-04-07 00:12:21,269 - train - INFO - Train: 25 [ 250/781 ( 32%)]  Loss:  3.765531 (3.8905)  Time: 0.438s,  292.17/s  (0.479s,  267.09/s)  LR: 4.672e-04  Data: 0.005 (0.008)
2024-04-07 00:12:45,466 - train - INFO - Train: 25 [ 300/781 ( 38%)]  Loss:  3.884380 (3.8806)  Time: 0.525s,  243.94/s  (0.480s,  266.65/s)  LR: 4.672e-04  Data: 0.006 (0.008)
2024-04-07 00:13:09,483 - train - INFO - Train: 25 [ 350/781 ( 45%)]  Loss:  3.937448 (3.8709)  Time: 0.512s,  250.21/s  (0.480s,  266.63/s)  LR: 4.672e-04  Data: 0.006 (0.008)
2024-04-07 00:13:34,590 - train - INFO - Train: 25 [ 400/781 ( 51%)]  Loss:  3.979779 (3.8679)  Time: 0.533s,  239.96/s  (0.483s,  265.11/s)  LR: 4.672e-04  Data: 0.007 (0.008)
2024-04-07 00:13:58,104 - train - INFO - Train: 25 [ 450/781 ( 58%)]  Loss:  3.994690 (3.8698)  Time: 0.468s,  273.59/s  (0.481s,  265.88/s)  LR: 4.672e-04  Data: 0.008 (0.008)
2024-04-07 00:14:21,346 - train - INFO - Train: 25 [ 500/781 ( 64%)]  Loss:  4.110569 (3.8723)  Time: 0.531s,  241.04/s  (0.480s,  266.80/s)  LR: 4.672e-04  Data: 0.008 (0.007)
2024-04-07 00:14:45,865 - train - INFO - Train: 25 [ 550/781 ( 71%)]  Loss:  4.133823 (3.8723)  Time: 0.513s,  249.66/s  (0.481s,  266.27/s)  LR: 4.672e-04  Data: 0.005 (0.007)
2024-04-07 00:15:09,797 - train - INFO - Train: 25 [ 600/781 ( 77%)]  Loss:  3.873827 (3.8734)  Time: 0.481s,  265.84/s  (0.481s,  266.36/s)  LR: 4.672e-04  Data: 0.005 (0.007)
2024-04-07 00:15:33,386 - train - INFO - Train: 25 [ 650/781 ( 83%)]  Loss:  3.381490 (3.8741)  Time: 0.382s,  335.21/s  (0.480s,  266.74/s)  LR: 4.672e-04  Data: 0.023 (0.007)
2024-04-07 00:15:57,790 - train - INFO - Train: 25 [ 700/781 ( 90%)]  Loss:  4.154847 (3.8744)  Time: 0.563s,  227.19/s  (0.480s,  266.41/s)  LR: 4.672e-04  Data: 0.007 (0.007)
2024-04-07 00:16:22,052 - train - INFO - Train: 25 [ 750/781 ( 96%)]  Loss:  4.171227 (3.8772)  Time: 0.443s,  288.66/s  (0.481s,  266.24/s)  LR: 4.672e-04  Data: 0.004 (0.007)
2024-04-07 00:16:36,548 - train - INFO - Train: 25 [ 780/781 (100%)]  Loss:  3.630610 (3.8779)  Time: 0.487s,  262.67/s  (0.481s,  266.19/s)  LR: 4.672e-04  Data: 0.000 (0.007)
2024-04-07 00:16:36,549 - train - INFO - True
2024-04-07 00:16:36,551 - train - INFO - alphas:tensor([0.4141, 0.1217, 0.1267, 0.1511, 0.1863], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,551 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,551 - train - INFO - True
2024-04-07 00:16:36,553 - train - INFO - alphas:tensor([0.3637, 0.0845, 0.1028, 0.1523, 0.2968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,554 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,554 - train - INFO - True
2024-04-07 00:16:36,558 - train - INFO - alphas:tensor([0.3785, 0.1104, 0.1655, 0.3456], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,559 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,559 - train - INFO - True
2024-04-07 00:16:36,564 - train - INFO - alphas:tensor([0.3034, 0.0961, 0.1471, 0.4534], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,564 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,565 - train - INFO - True
2024-04-07 00:16:36,566 - train - INFO - alphas:tensor([0.3068, 0.0890, 0.1531, 0.4511], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,567 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,567 - train - INFO - True
2024-04-07 00:16:36,571 - train - INFO - alphas:tensor([0.3905, 0.1025, 0.1440, 0.3630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,572 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,572 - train - INFO - True
2024-04-07 00:16:36,576 - train - INFO - alphas:tensor([0.4423, 0.0842, 0.0913, 0.1305, 0.2518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,577 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,577 - train - INFO - True
2024-04-07 00:16:36,582 - train - INFO - alphas:tensor([0.1470, 0.0406, 0.0469, 0.1113, 0.6541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,582 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,582 - train - INFO - True
2024-04-07 00:16:36,587 - train - INFO - alphas:tensor([0.1578, 0.0373, 0.0468, 0.1029, 0.6552], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,588 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,588 - train - INFO - True
2024-04-07 00:16:36,589 - train - INFO - alphas:tensor([0.1544, 0.0356, 0.0435, 0.1030, 0.6635], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,589 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,590 - train - INFO - True
2024-04-07 00:16:36,591 - train - INFO - alphas:tensor([0.1446, 0.0364, 0.0446, 0.1100, 0.6644], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,592 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,592 - train - INFO - True
2024-04-07 00:16:36,593 - train - INFO - alphas:tensor([0.4531, 0.0647, 0.0775, 0.1260, 0.2788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,594 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,594 - train - INFO - True
2024-04-07 00:16:36,594 - train - INFO - alphas:tensor([0.5343, 0.0646, 0.0717, 0.1041, 0.2253], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,597 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,598 - train - INFO - True
2024-04-07 00:16:36,599 - train - INFO - alphas:tensor([0.1469, 0.0470, 0.0548, 0.1412, 0.6101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,601 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,601 - train - INFO - True
2024-04-07 00:16:36,603 - train - INFO - alphas:tensor([0.1610, 0.0408, 0.0510, 0.1338, 0.6134], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,605 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,605 - train - INFO - True
2024-04-07 00:16:36,606 - train - INFO - alphas:tensor([0.1766, 0.0385, 0.0524, 0.1256, 0.6069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,607 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,608 - train - INFO - True
2024-04-07 00:16:36,608 - train - INFO - alphas:tensor([0.1508, 0.0447, 0.0540, 0.1236, 0.6270], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,610 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,610 - train - INFO - True
2024-04-07 00:16:36,614 - train - INFO - alphas:tensor([0.1768, 0.0381, 0.0528, 0.1231, 0.6092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,615 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,615 - train - INFO - True
2024-04-07 00:16:36,617 - train - INFO - alphas:tensor([0.1303, 0.0503, 0.0615, 0.1411, 0.6167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,618 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,618 - train - INFO - True
2024-04-07 00:16:36,623 - train - INFO - alphas:tensor([0.4783, 0.0488, 0.0579, 0.1108, 0.3042], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,625 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,625 - train - INFO - True
2024-04-07 00:16:36,630 - train - INFO - alphas:tensor([0.3988, 0.0438, 0.0517, 0.1103, 0.3953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,636 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,636 - train - INFO - True
2024-04-07 00:16:36,637 - train - INFO - alphas:tensor([0.2758, 0.0366, 0.0497, 0.1110, 0.5268], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,640 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,640 - train - INFO - True
2024-04-07 00:16:36,643 - train - INFO - alphas:tensor([0.2872, 0.0383, 0.0461, 0.1129, 0.5154], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,646 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,646 - train - INFO - True
2024-04-07 00:16:36,649 - train - INFO - alphas:tensor([0.2991, 0.0355, 0.0445, 0.1088, 0.5121], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,652 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,652 - train - INFO - True
2024-04-07 00:16:36,655 - train - INFO - alphas:tensor([0.2729, 0.0359, 0.0481, 0.1095, 0.5336], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,658 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,658 - train - INFO - True
2024-04-07 00:16:36,659 - train - INFO - alphas:tensor([0.4234, 0.0359, 0.0488, 0.0975, 0.3945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,665 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,665 - train - INFO - True
2024-04-07 00:16:36,666 - train - INFO - alphas:tensor([0.5647, 0.0377, 0.0480, 0.0862, 0.2634], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,681 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,681 - train - INFO - True
2024-04-07 00:16:36,682 - train - INFO - alphas:tensor([0.2255, 0.0291, 0.0402, 0.1130, 0.5922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,689 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,689 - train - INFO - True
2024-04-07 00:16:36,690 - train - INFO - alphas:tensor([0.2371, 0.0263, 0.0368, 0.1074, 0.5924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,697 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,697 - train - INFO - True
2024-04-07 00:16:36,698 - train - INFO - alphas:tensor([0.2599, 0.0265, 0.0345, 0.1012, 0.5780], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,705 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,705 - train - INFO - True
2024-04-07 00:16:36,706 - train - INFO - alphas:tensor([0.2224, 0.0307, 0.0376, 0.1132, 0.5960], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,713 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,713 - train - INFO - True
2024-04-07 00:16:36,714 - train - INFO - alphas:tensor([0.5707, 0.0304, 0.0380, 0.0739, 0.2869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,727 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,727 - train - INFO - True
2024-04-07 00:16:36,728 - train - INFO - alphas:tensor([0.4121, 0.0366, 0.0447, 0.0952, 0.4114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:16:36,779 - train - INFO - tau:0.7936142836436553
2024-04-07 00:16:36,779 - train - INFO - avg block size:9.606060606060606
2024-04-07 00:16:36,779 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 00:16:37,076 - train - INFO - Test: [   0/78]  Time: 0.293 (0.293)  Loss:  0.9722 (0.9722)  Acc@1: 80.4688 (80.4688)  Acc@5: 94.5312 (94.5312)
2024-04-07 00:16:41,810 - train - INFO - Test: [  50/78]  Time: 0.138 (0.099)  Loss:  1.5654 (1.7223)  Acc@1: 64.0625 (60.0950)  Acc@5: 85.9375 (83.5631)
2024-04-07 00:16:44,214 - train - INFO - Test: [  78/78]  Time: 0.129 (0.094)  Loss:  1.8506 (1.7423)  Acc@1: 43.7500 (59.8300)  Acc@5: 93.7500 (83.2800)
2024-04-07 00:16:44,964 - train - INFO - Train: 26 [   0/781 (  0%)]  Loss:  3.578174 (3.5782)  Time: 0.666s,  192.17/s  (0.666s,  192.17/s)  LR: 4.646e-04  Data: 0.140 (0.140)
2024-04-07 00:17:09,512 - train - INFO - Train: 26 [  50/781 (  6%)]  Loss:  3.594615 (3.8873)  Time: 0.511s,  250.51/s  (0.494s,  258.93/s)  LR: 4.646e-04  Data: 0.007 (0.010)
2024-04-07 00:17:34,141 - train - INFO - Train: 26 [ 100/781 ( 13%)]  Loss:  4.300111 (3.8765)  Time: 0.469s,  273.09/s  (0.493s,  259.39/s)  LR: 4.646e-04  Data: 0.008 (0.009)
2024-04-07 00:17:58,810 - train - INFO - Train: 26 [ 150/781 ( 19%)]  Loss:  3.722827 (3.8450)  Time: 0.507s,  252.46/s  (0.493s,  259.41/s)  LR: 4.646e-04  Data: 0.009 (0.008)
2024-04-07 00:18:22,528 - train - INFO - Train: 26 [ 200/781 ( 26%)]  Loss:  4.193933 (3.8509)  Time: 0.475s,  269.65/s  (0.489s,  261.93/s)  LR: 4.646e-04  Data: 0.009 (0.008)
2024-04-07 00:18:45,806 - train - INFO - Train: 26 [ 250/781 ( 32%)]  Loss:  3.890377 (3.8567)  Time: 0.526s,  243.40/s  (0.484s,  264.43/s)  LR: 4.646e-04  Data: 0.006 (0.008)
2024-04-07 00:19:08,535 - train - INFO - Train: 26 [ 300/781 ( 38%)]  Loss:  3.620707 (3.8603)  Time: 0.396s,  322.83/s  (0.479s,  267.13/s)  LR: 4.646e-04  Data: 0.004 (0.008)
2024-04-07 00:19:32,798 - train - INFO - Train: 26 [ 350/781 ( 45%)]  Loss:  3.791787 (3.8604)  Time: 0.451s,  284.01/s  (0.480s,  266.65/s)  LR: 4.646e-04  Data: 0.005 (0.008)
2024-04-07 00:19:56,069 - train - INFO - Train: 26 [ 400/781 ( 51%)]  Loss:  4.026204 (3.8619)  Time: 0.601s,  212.84/s  (0.478s,  267.67/s)  LR: 4.646e-04  Data: 0.009 (0.007)
2024-04-07 00:20:19,786 - train - INFO - Train: 26 [ 450/781 ( 58%)]  Loss:  3.451757 (3.8653)  Time: 0.470s,  272.37/s  (0.478s,  267.91/s)  LR: 4.646e-04  Data: 0.005 (0.007)
2024-04-07 00:20:43,830 - train - INFO - Train: 26 [ 500/781 ( 64%)]  Loss:  4.009989 (3.8662)  Time: 0.521s,  245.48/s  (0.478s,  267.74/s)  LR: 4.646e-04  Data: 0.007 (0.007)
2024-04-07 00:21:07,631 - train - INFO - Train: 26 [ 550/781 ( 71%)]  Loss:  4.002807 (3.8664)  Time: 0.499s,  256.71/s  (0.478s,  267.84/s)  LR: 4.646e-04  Data: 0.005 (0.007)
2024-04-07 00:21:32,778 - train - INFO - Train: 26 [ 600/781 ( 77%)]  Loss:  3.819778 (3.8648)  Time: 0.454s,  281.81/s  (0.480s,  266.68/s)  LR: 4.646e-04  Data: 0.006 (0.007)
2024-04-07 00:21:56,302 - train - INFO - Train: 26 [ 650/781 ( 83%)]  Loss:  3.721874 (3.8651)  Time: 0.489s,  261.91/s  (0.479s,  267.09/s)  LR: 4.646e-04  Data: 0.009 (0.007)
2024-04-07 00:22:21,104 - train - INFO - Train: 26 [ 700/781 ( 90%)]  Loss:  3.671568 (3.8647)  Time: 0.532s,  240.72/s  (0.480s,  266.43/s)  LR: 4.646e-04  Data: 0.005 (0.007)
2024-04-07 00:22:45,701 - train - INFO - Train: 26 [ 750/781 ( 96%)]  Loss:  4.016209 (3.8633)  Time: 0.460s,  278.01/s  (0.481s,  266.00/s)  LR: 4.646e-04  Data: 0.009 (0.007)
2024-04-07 00:22:59,523 - train - INFO - Train: 26 [ 780/781 (100%)]  Loss:  4.199525 (3.8625)  Time: 0.397s,  322.03/s  (0.480s,  266.44/s)  LR: 4.646e-04  Data: 0.000 (0.007)
2024-04-07 00:22:59,526 - train - INFO - True
2024-04-07 00:22:59,529 - train - INFO - alphas:tensor([0.4174, 0.1195, 0.1252, 0.1505, 0.1874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,538 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,538 - train - INFO - True
2024-04-07 00:22:59,540 - train - INFO - alphas:tensor([0.3592, 0.0815, 0.1008, 0.1521, 0.3064], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,540 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,540 - train - INFO - True
2024-04-07 00:22:59,545 - train - INFO - alphas:tensor([0.3761, 0.1067, 0.1631, 0.3541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,545 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,546 - train - INFO - True
2024-04-07 00:22:59,549 - train - INFO - alphas:tensor([0.3007, 0.0937, 0.1420, 0.4636], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,550 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,550 - train - INFO - True
2024-04-07 00:22:59,552 - train - INFO - alphas:tensor([0.3006, 0.0857, 0.1490, 0.4646], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,552 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,552 - train - INFO - True
2024-04-07 00:22:59,557 - train - INFO - alphas:tensor([0.3863, 0.1002, 0.1404, 0.3731], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,558 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,558 - train - INFO - True
2024-04-07 00:22:59,562 - train - INFO - alphas:tensor([0.4400, 0.0813, 0.0890, 0.1295, 0.2603], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,562 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,562 - train - INFO - True
2024-04-07 00:22:59,563 - train - INFO - alphas:tensor([0.1476, 0.0392, 0.0452, 0.1091, 0.6588], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,564 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,564 - train - INFO - True
2024-04-07 00:22:59,564 - train - INFO - alphas:tensor([0.1585, 0.0362, 0.0449, 0.0976, 0.6627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,565 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,565 - train - INFO - True
2024-04-07 00:22:59,566 - train - INFO - alphas:tensor([0.1545, 0.0339, 0.0415, 0.1001, 0.6700], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,566 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,566 - train - INFO - True
2024-04-07 00:22:59,567 - train - INFO - alphas:tensor([0.1443, 0.0354, 0.0430, 0.1062, 0.6712], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,568 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,568 - train - INFO - True
2024-04-07 00:22:59,568 - train - INFO - alphas:tensor([0.4515, 0.0615, 0.0746, 0.1251, 0.2873], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,569 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,569 - train - INFO - True
2024-04-07 00:22:59,570 - train - INFO - alphas:tensor([0.5357, 0.0623, 0.0692, 0.1022, 0.2306], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,572 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,572 - train - INFO - True
2024-04-07 00:22:59,573 - train - INFO - alphas:tensor([0.1493, 0.0468, 0.0539, 0.1395, 0.6105], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,574 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,575 - train - INFO - True
2024-04-07 00:22:59,575 - train - INFO - alphas:tensor([0.1603, 0.0400, 0.0502, 0.1328, 0.6168], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,577 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,577 - train - INFO - True
2024-04-07 00:22:59,577 - train - INFO - alphas:tensor([0.1775, 0.0376, 0.0509, 0.1238, 0.6103], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,579 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,579 - train - INFO - True
2024-04-07 00:22:59,580 - train - INFO - alphas:tensor([0.1510, 0.0431, 0.0524, 0.1228, 0.6306], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,581 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,581 - train - INFO - True
2024-04-07 00:22:59,582 - train - INFO - alphas:tensor([0.1755, 0.0363, 0.0515, 0.1230, 0.6138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,583 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,583 - train - INFO - True
2024-04-07 00:22:59,584 - train - INFO - alphas:tensor([0.1295, 0.0500, 0.0606, 0.1376, 0.6224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,585 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,585 - train - INFO - True
2024-04-07 00:22:59,586 - train - INFO - alphas:tensor([0.4782, 0.0471, 0.0554, 0.1087, 0.3105], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,589 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,589 - train - INFO - True
2024-04-07 00:22:59,589 - train - INFO - alphas:tensor([0.3966, 0.0412, 0.0496, 0.1076, 0.4050], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,592 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,592 - train - INFO - True
2024-04-07 00:22:59,593 - train - INFO - alphas:tensor([0.2761, 0.0352, 0.0482, 0.1098, 0.5307], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,596 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,596 - train - INFO - True
2024-04-07 00:22:59,597 - train - INFO - alphas:tensor([0.2890, 0.0362, 0.0440, 0.1111, 0.5197], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,599 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,599 - train - INFO - True
2024-04-07 00:22:59,600 - train - INFO - alphas:tensor([0.3063, 0.0340, 0.0419, 0.1054, 0.5124], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,603 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,603 - train - INFO - True
2024-04-07 00:22:59,604 - train - INFO - alphas:tensor([0.2705, 0.0341, 0.0466, 0.1094, 0.5394], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,606 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,606 - train - INFO - True
2024-04-07 00:22:59,607 - train - INFO - alphas:tensor([0.4202, 0.0338, 0.0464, 0.0941, 0.4055], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,612 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,612 - train - INFO - True
2024-04-07 00:22:59,613 - train - INFO - alphas:tensor([0.5608, 0.0358, 0.0453, 0.0845, 0.2736], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,627 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,627 - train - INFO - True
2024-04-07 00:22:59,627 - train - INFO - alphas:tensor([0.2248, 0.0280, 0.0392, 0.1136, 0.5945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,635 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,635 - train - INFO - True
2024-04-07 00:22:59,636 - train - INFO - alphas:tensor([0.2395, 0.0255, 0.0354, 0.1073, 0.5923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,643 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,643 - train - INFO - True
2024-04-07 00:22:59,643 - train - INFO - alphas:tensor([0.2606, 0.0253, 0.0339, 0.1008, 0.5794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,651 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,651 - train - INFO - True
2024-04-07 00:22:59,651 - train - INFO - alphas:tensor([0.2243, 0.0299, 0.0367, 0.1113, 0.5978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,658 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,658 - train - INFO - True
2024-04-07 00:22:59,659 - train - INFO - alphas:tensor([0.5632, 0.0293, 0.0367, 0.0740, 0.2969], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,673 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,673 - train - INFO - True
2024-04-07 00:22:59,675 - train - INFO - alphas:tensor([0.4131, 0.0359, 0.0435, 0.0951, 0.4124], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:22:59,729 - train - INFO - tau:0.7856781408072188
2024-04-07 00:22:59,729 - train - INFO - avg block size:10.06060606060606
2024-04-07 00:22:59,730 - train - INFO - current latency ratio:tensor(0.2361)
2024-04-07 00:22:59,730 - train - INFO - lasso_alpha:3.8974342000000026e-05
2024-04-07 00:23:00,031 - train - INFO - Test: [   0/78]  Time: 0.298 (0.298)  Loss:  0.9800 (0.9800)  Acc@1: 78.9062 (78.9062)  Acc@5: 94.5312 (94.5312)
2024-04-07 00:23:04,738 - train - INFO - Test: [  50/78]  Time: 0.105 (0.098)  Loss:  1.8301 (1.7632)  Acc@1: 56.2500 (60.2175)  Acc@5: 83.5938 (82.8738)
2024-04-07 00:23:07,194 - train - INFO - Test: [  78/78]  Time: 0.058 (0.094)  Loss:  2.2480 (1.7766)  Acc@1: 43.7500 (60.0700)  Acc@5: 87.5000 (82.6200)
2024-04-07 00:23:07,863 - train - INFO - Train: 27 [   0/781 (  0%)]  Loss:  3.692261 (3.6923)  Time: 0.584s,  219.02/s  (0.584s,  219.02/s)  LR: 4.619e-04  Data: 0.185 (0.185)
2024-04-07 00:23:30,992 - train - INFO - Train: 27 [  50/781 (  6%)]  Loss:  3.561556 (3.8655)  Time: 0.529s,  242.04/s  (0.465s,  275.31/s)  LR: 4.619e-04  Data: 0.008 (0.011)
2024-04-07 00:23:54,673 - train - INFO - Train: 27 [ 100/781 ( 13%)]  Loss:  3.884701 (3.8760)  Time: 0.364s,  352.02/s  (0.469s,  272.79/s)  LR: 4.619e-04  Data: 0.009 (0.009)
2024-04-07 00:24:22,743 - train - INFO - Train: 27 [ 150/781 ( 19%)]  Loss:  3.980178 (3.8690)  Time: 0.491s,  260.69/s  (0.500s,  256.14/s)  LR: 4.619e-04  Data: 0.006 (0.009)
2024-04-07 00:24:53,749 - train - INFO - Train: 27 [ 200/781 ( 26%)]  Loss:  3.732548 (3.8675)  Time: 0.525s,  243.94/s  (0.530s,  241.66/s)  LR: 4.619e-04  Data: 0.008 (0.008)
2024-04-07 00:25:24,940 - train - INFO - Train: 27 [ 250/781 ( 32%)]  Loss:  4.156653 (3.8631)  Time: 0.439s,  291.37/s  (0.548s,  233.40/s)  LR: 4.619e-04  Data: 0.007 (0.008)
2024-04-07 00:25:56,038 - train - INFO - Train: 27 [ 300/781 ( 38%)]  Loss:  4.176067 (3.8641)  Time: 0.413s,  309.87/s  (0.561s,  228.31/s)  LR: 4.619e-04  Data: 0.006 (0.008)
2024-04-07 00:26:23,441 - train - INFO - Train: 27 [ 350/781 ( 45%)]  Loss:  3.740312 (3.8669)  Time: 0.479s,  267.05/s  (0.559s,  229.05/s)  LR: 4.619e-04  Data: 0.008 (0.008)
2024-04-07 00:26:47,976 - train - INFO - Train: 27 [ 400/781 ( 51%)]  Loss:  4.258961 (3.8651)  Time: 0.486s,  263.63/s  (0.550s,  232.58/s)  LR: 4.619e-04  Data: 0.008 (0.008)
2024-04-07 00:27:11,734 - train - INFO - Train: 27 [ 450/781 ( 58%)]  Loss:  3.487861 (3.8723)  Time: 0.513s,  249.75/s  (0.542s,  236.16/s)  LR: 4.619e-04  Data: 0.009 (0.008)
2024-04-07 00:27:35,918 - train - INFO - Train: 27 [ 500/781 ( 64%)]  Loss:  3.436452 (3.8716)  Time: 0.505s,  253.35/s  (0.536s,  238.73/s)  LR: 4.619e-04  Data: 0.008 (0.008)
2024-04-07 00:27:59,770 - train - INFO - Train: 27 [ 550/781 ( 71%)]  Loss:  4.076099 (3.8732)  Time: 0.501s,  255.36/s  (0.531s,  241.14/s)  LR: 4.619e-04  Data: 0.008 (0.008)
2024-04-07 00:28:23,213 - train - INFO - Train: 27 [ 600/781 ( 77%)]  Loss:  3.938430 (3.8726)  Time: 0.449s,  285.16/s  (0.526s,  243.51/s)  LR: 4.619e-04  Data: 0.005 (0.008)
2024-04-07 00:28:45,708 - train - INFO - Train: 27 [ 650/781 ( 83%)]  Loss:  3.924234 (3.8687)  Time: 0.381s,  335.66/s  (0.520s,  246.23/s)  LR: 4.619e-04  Data: 0.005 (0.008)
2024-04-07 00:29:09,218 - train - INFO - Train: 27 [ 700/781 ( 90%)]  Loss:  4.040481 (3.8658)  Time: 0.500s,  256.07/s  (0.516s,  247.92/s)  LR: 4.619e-04  Data: 0.010 (0.008)
2024-04-07 00:29:33,279 - train - INFO - Train: 27 [ 750/781 ( 96%)]  Loss:  3.468333 (3.8664)  Time: 0.492s,  260.29/s  (0.514s,  249.05/s)  LR: 4.619e-04  Data: 0.008 (0.008)
2024-04-07 00:29:47,592 - train - INFO - Train: 27 [ 780/781 (100%)]  Loss:  3.689344 (3.8667)  Time: 0.485s,  264.07/s  (0.513s,  249.74/s)  LR: 4.619e-04  Data: 0.000 (0.008)
2024-04-07 00:29:47,593 - train - INFO - True
2024-04-07 00:29:47,595 - train - INFO - alphas:tensor([0.4226, 0.1177, 0.1234, 0.1489, 0.1874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,596 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,596 - train - INFO - True
2024-04-07 00:29:47,597 - train - INFO - alphas:tensor([0.3577, 0.0787, 0.0983, 0.1494, 0.3159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,598 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,598 - train - INFO - True
2024-04-07 00:29:47,599 - train - INFO - alphas:tensor([0.3713, 0.1040, 0.1620, 0.3627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,600 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,600 - train - INFO - True
2024-04-07 00:29:47,601 - train - INFO - alphas:tensor([0.2991, 0.0903, 0.1382, 0.4725], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,602 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,602 - train - INFO - True
2024-04-07 00:29:47,603 - train - INFO - alphas:tensor([0.3017, 0.0822, 0.1456, 0.4705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,604 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,604 - train - INFO - True
2024-04-07 00:29:47,605 - train - INFO - alphas:tensor([0.3861, 0.0968, 0.1380, 0.3791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,606 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,606 - train - INFO - True
2024-04-07 00:29:47,607 - train - INFO - alphas:tensor([0.4401, 0.0789, 0.0869, 0.1276, 0.2665], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,608 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,608 - train - INFO - True
2024-04-07 00:29:47,609 - train - INFO - alphas:tensor([0.1525, 0.0384, 0.0443, 0.1081, 0.6568], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,610 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,610 - train - INFO - True
2024-04-07 00:29:47,611 - train - INFO - alphas:tensor([0.1611, 0.0355, 0.0439, 0.0965, 0.6630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,612 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,612 - train - INFO - True
2024-04-07 00:29:47,614 - train - INFO - alphas:tensor([0.1606, 0.0323, 0.0397, 0.0983, 0.6691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,614 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,614 - train - INFO - True
2024-04-07 00:29:47,615 - train - INFO - alphas:tensor([0.1478, 0.0347, 0.0418, 0.1036, 0.6721], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,616 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,616 - train - INFO - True
2024-04-07 00:29:47,617 - train - INFO - alphas:tensor([0.4513, 0.0587, 0.0721, 0.1225, 0.2953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,619 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,619 - train - INFO - True
2024-04-07 00:29:47,620 - train - INFO - alphas:tensor([0.5353, 0.0600, 0.0671, 0.1006, 0.2370], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,624 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,624 - train - INFO - True
2024-04-07 00:29:47,625 - train - INFO - alphas:tensor([0.1516, 0.0458, 0.0529, 0.1400, 0.6097], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,627 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,627 - train - INFO - True
2024-04-07 00:29:47,628 - train - INFO - alphas:tensor([0.1622, 0.0394, 0.0489, 0.1337, 0.6158], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,630 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,630 - train - INFO - True
2024-04-07 00:29:47,631 - train - INFO - alphas:tensor([0.1851, 0.0374, 0.0497, 0.1210, 0.6068], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,633 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,634 - train - INFO - True
2024-04-07 00:29:47,635 - train - INFO - alphas:tensor([0.1542, 0.0427, 0.0507, 0.1202, 0.6322], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,636 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,637 - train - INFO - True
2024-04-07 00:29:47,638 - train - INFO - alphas:tensor([0.1794, 0.0360, 0.0514, 0.1227, 0.6105], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,640 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,640 - train - INFO - True
2024-04-07 00:29:47,641 - train - INFO - alphas:tensor([0.1330, 0.0510, 0.0607, 0.1391, 0.6162], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,643 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,643 - train - INFO - True
2024-04-07 00:29:47,644 - train - INFO - alphas:tensor([0.4789, 0.0453, 0.0536, 0.1066, 0.3156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,647 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,647 - train - INFO - True
2024-04-07 00:29:47,648 - train - INFO - alphas:tensor([0.4016, 0.0392, 0.0467, 0.1048, 0.4077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,652 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,652 - train - INFO - True
2024-04-07 00:29:47,653 - train - INFO - alphas:tensor([0.2838, 0.0348, 0.0477, 0.1097, 0.5241], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,657 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,657 - train - INFO - True
2024-04-07 00:29:47,658 - train - INFO - alphas:tensor([0.2938, 0.0350, 0.0431, 0.1106, 0.5176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,662 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,662 - train - INFO - True
2024-04-07 00:29:47,663 - train - INFO - alphas:tensor([0.3132, 0.0324, 0.0390, 0.1035, 0.5119], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,666 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,667 - train - INFO - True
2024-04-07 00:29:47,668 - train - INFO - alphas:tensor([0.2762, 0.0332, 0.0454, 0.1048, 0.5405], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,671 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,671 - train - INFO - True
2024-04-07 00:29:47,672 - train - INFO - alphas:tensor([0.4241, 0.0323, 0.0450, 0.0898, 0.4088], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,680 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,680 - train - INFO - True
2024-04-07 00:29:47,681 - train - INFO - alphas:tensor([0.5618, 0.0341, 0.0441, 0.0821, 0.2779], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,700 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,700 - train - INFO - True
2024-04-07 00:29:47,701 - train - INFO - alphas:tensor([0.2349, 0.0277, 0.0390, 0.1139, 0.5845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,724 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,724 - train - INFO - True
2024-04-07 00:29:47,725 - train - INFO - alphas:tensor([0.2473, 0.0244, 0.0343, 0.1052, 0.5888], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,735 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,736 - train - INFO - True
2024-04-07 00:29:47,736 - train - INFO - alphas:tensor([0.2674, 0.0247, 0.0334, 0.1018, 0.5727], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,747 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,747 - train - INFO - True
2024-04-07 00:29:47,748 - train - INFO - alphas:tensor([0.2336, 0.0294, 0.0362, 0.1101, 0.5907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,758 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,758 - train - INFO - True
2024-04-07 00:29:47,759 - train - INFO - alphas:tensor([0.5702, 0.0274, 0.0341, 0.0723, 0.2960], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,778 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,778 - train - INFO - True
2024-04-07 00:29:47,779 - train - INFO - alphas:tensor([0.4244, 0.0341, 0.0415, 0.0933, 0.4067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:29:47,857 - train - INFO - tau:0.7778213593991465
2024-04-07 00:29:47,857 - train - INFO - avg block size:10.06060606060606
2024-04-07 00:29:47,857 - train - INFO - current latency ratio:tensor(0.2361)
2024-04-07 00:29:48,074 - train - INFO - Test: [   0/78]  Time: 0.214 (0.214)  Loss:  0.9126 (0.9126)  Acc@1: 80.4688 (80.4688)  Acc@5: 94.5312 (94.5312)
2024-04-07 00:29:51,646 - train - INFO - Test: [  50/78]  Time: 0.056 (0.074)  Loss:  1.7920 (1.7814)  Acc@1: 60.1562 (59.6507)  Acc@5: 85.1562 (82.9350)
2024-04-07 00:29:53,342 - train - INFO - Test: [  78/78]  Time: 0.072 (0.069)  Loss:  2.2734 (1.7845)  Acc@1: 43.7500 (59.8500)  Acc@5: 87.5000 (82.6600)
2024-04-07 00:29:54,099 - train - INFO - Train: 28 [   0/781 (  0%)]  Loss:  3.938729 (3.9387)  Time: 0.657s,  194.91/s  (0.657s,  194.91/s)  LR: 4.591e-04  Data: 0.170 (0.170)
2024-04-07 00:30:17,639 - train - INFO - Train: 28 [  50/781 (  6%)]  Loss:  3.473960 (3.8524)  Time: 0.406s,  315.15/s  (0.474s,  269.81/s)  LR: 4.591e-04  Data: 0.005 (0.011)
2024-04-07 00:30:41,803 - train - INFO - Train: 28 [ 100/781 ( 13%)]  Loss:  4.115586 (3.8669)  Time: 0.483s,  265.12/s  (0.479s,  267.34/s)  LR: 4.591e-04  Data: 0.008 (0.010)
2024-04-07 00:31:04,895 - train - INFO - Train: 28 [ 150/781 ( 19%)]  Loss:  3.706996 (3.8676)  Time: 0.388s,  330.22/s  (0.473s,  270.52/s)  LR: 4.591e-04  Data: 0.004 (0.009)
2024-04-07 00:31:28,328 - train - INFO - Train: 28 [ 200/781 ( 26%)]  Loss:  4.070244 (3.8715)  Time: 0.465s,  275.03/s  (0.472s,  271.17/s)  LR: 4.591e-04  Data: 0.005 (0.009)
2024-04-07 00:31:51,771 - train - INFO - Train: 28 [ 250/781 ( 32%)]  Loss:  3.458988 (3.8631)  Time: 0.497s,  257.45/s  (0.471s,  271.53/s)  LR: 4.591e-04  Data: 0.020 (0.009)
2024-04-07 00:32:16,235 - train - INFO - Train: 28 [ 300/781 ( 38%)]  Loss:  3.546609 (3.8621)  Time: 0.504s,  253.81/s  (0.474s,  269.84/s)  LR: 4.591e-04  Data: 0.009 (0.008)
2024-04-07 00:32:40,458 - train - INFO - Train: 28 [ 350/781 ( 45%)]  Loss:  4.076058 (3.8661)  Time: 0.545s,  234.91/s  (0.476s,  269.02/s)  LR: 4.591e-04  Data: 0.008 (0.008)
2024-04-07 00:33:04,530 - train - INFO - Train: 28 [ 400/781 ( 51%)]  Loss:  3.425497 (3.8637)  Time: 0.528s,  242.31/s  (0.476s,  268.63/s)  LR: 4.591e-04  Data: 0.009 (0.008)
2024-04-07 00:33:28,834 - train - INFO - Train: 28 [ 450/781 ( 58%)]  Loss:  3.475653 (3.8643)  Time: 0.583s,  219.73/s  (0.478s,  268.03/s)  LR: 4.591e-04  Data: 0.009 (0.008)
2024-04-07 00:33:53,157 - train - INFO - Train: 28 [ 500/781 ( 64%)]  Loss:  3.666324 (3.8652)  Time: 0.500s,  256.06/s  (0.478s,  267.54/s)  LR: 4.591e-04  Data: 0.008 (0.008)
2024-04-07 00:34:17,764 - train - INFO - Train: 28 [ 550/781 ( 71%)]  Loss:  3.821163 (3.8627)  Time: 0.495s,  258.37/s  (0.480s,  266.85/s)  LR: 4.591e-04  Data: 0.009 (0.008)
2024-04-07 00:34:42,473 - train - INFO - Train: 28 [ 600/781 ( 77%)]  Loss:  4.057565 (3.8640)  Time: 0.534s,  239.66/s  (0.481s,  266.18/s)  LR: 4.591e-04  Data: 0.008 (0.008)
2024-04-07 00:35:05,568 - train - INFO - Train: 28 [ 650/781 ( 83%)]  Loss:  3.412138 (3.8576)  Time: 0.491s,  260.75/s  (0.479s,  266.99/s)  LR: 4.591e-04  Data: 0.006 (0.008)
2024-04-07 00:35:29,612 - train - INFO - Train: 28 [ 700/781 ( 90%)]  Loss:  3.564253 (3.8571)  Time: 0.490s,  260.96/s  (0.480s,  266.93/s)  LR: 4.591e-04  Data: 0.007 (0.008)
2024-04-07 00:35:53,874 - train - INFO - Train: 28 [ 750/781 ( 96%)]  Loss:  3.476635 (3.8533)  Time: 0.529s,  242.09/s  (0.480s,  266.72/s)  LR: 4.591e-04  Data: 0.013 (0.008)
2024-04-07 00:36:08,531 - train - INFO - Train: 28 [ 780/781 (100%)]  Loss:  4.027833 (3.8536)  Time: 0.419s,  305.71/s  (0.480s,  266.54/s)  LR: 4.591e-04  Data: 0.000 (0.008)
2024-04-07 00:36:08,532 - train - INFO - True
2024-04-07 00:36:08,534 - train - INFO - alphas:tensor([0.4287, 0.1152, 0.1211, 0.1472, 0.1878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,535 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,536 - train - INFO - True
2024-04-07 00:36:08,537 - train - INFO - alphas:tensor([0.3564, 0.0767, 0.0962, 0.1485, 0.3223], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,538 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,538 - train - INFO - True
2024-04-07 00:36:08,540 - train - INFO - alphas:tensor([0.3716, 0.1010, 0.1588, 0.3685], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,541 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,541 - train - INFO - True
2024-04-07 00:36:08,543 - train - INFO - alphas:tensor([0.3016, 0.0877, 0.1352, 0.4755], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,544 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,544 - train - INFO - True
2024-04-07 00:36:08,557 - train - INFO - alphas:tensor([0.3018, 0.0794, 0.1431, 0.4757], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,558 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,558 - train - INFO - True
2024-04-07 00:36:08,565 - train - INFO - alphas:tensor([0.3841, 0.0940, 0.1356, 0.3863], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,566 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,566 - train - INFO - True
2024-04-07 00:36:08,567 - train - INFO - alphas:tensor([0.4403, 0.0759, 0.0841, 0.1267, 0.2731], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,568 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,568 - train - INFO - True
2024-04-07 00:36:08,569 - train - INFO - alphas:tensor([0.1551, 0.0364, 0.0421, 0.1043, 0.6621], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,570 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,570 - train - INFO - True
2024-04-07 00:36:08,571 - train - INFO - alphas:tensor([0.1617, 0.0345, 0.0427, 0.0953, 0.6658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,571 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,571 - train - INFO - True
2024-04-07 00:36:08,572 - train - INFO - alphas:tensor([0.1646, 0.0312, 0.0384, 0.0956, 0.6701], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,573 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,573 - train - INFO - True
2024-04-07 00:36:08,574 - train - INFO - alphas:tensor([0.1513, 0.0338, 0.0398, 0.1021, 0.6731], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,575 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,575 - train - INFO - True
2024-04-07 00:36:08,576 - train - INFO - alphas:tensor([0.4466, 0.0564, 0.0708, 0.1221, 0.3042], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,577 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,577 - train - INFO - True
2024-04-07 00:36:08,578 - train - INFO - alphas:tensor([0.5322, 0.0580, 0.0654, 0.0996, 0.2448], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,581 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,581 - train - INFO - True
2024-04-07 00:36:08,582 - train - INFO - alphas:tensor([0.1502, 0.0441, 0.0507, 0.1356, 0.6194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,584 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,584 - train - INFO - True
2024-04-07 00:36:08,585 - train - INFO - alphas:tensor([0.1663, 0.0383, 0.0480, 0.1329, 0.6145], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,587 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,587 - train - INFO - True
2024-04-07 00:36:08,588 - train - INFO - alphas:tensor([0.1826, 0.0361, 0.0482, 0.1178, 0.6154], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,590 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,590 - train - INFO - True
2024-04-07 00:36:08,591 - train - INFO - alphas:tensor([0.1563, 0.0419, 0.0493, 0.1183, 0.6342], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,593 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,593 - train - INFO - True
2024-04-07 00:36:08,594 - train - INFO - alphas:tensor([0.1789, 0.0352, 0.0501, 0.1201, 0.6157], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,596 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,596 - train - INFO - True
2024-04-07 00:36:08,597 - train - INFO - alphas:tensor([0.1338, 0.0506, 0.0604, 0.1364, 0.6189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,599 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,599 - train - INFO - True
2024-04-07 00:36:08,600 - train - INFO - alphas:tensor([0.4796, 0.0429, 0.0514, 0.1036, 0.3224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,603 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,604 - train - INFO - True
2024-04-07 00:36:08,604 - train - INFO - alphas:tensor([0.4040, 0.0380, 0.0449, 0.1047, 0.4083], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,608 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,608 - train - INFO - True
2024-04-07 00:36:08,609 - train - INFO - alphas:tensor([0.2847, 0.0329, 0.0457, 0.1085, 0.5282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,613 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,613 - train - INFO - True
2024-04-07 00:36:08,614 - train - INFO - alphas:tensor([0.2943, 0.0333, 0.0411, 0.1092, 0.5222], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,618 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,618 - train - INFO - True
2024-04-07 00:36:08,620 - train - INFO - alphas:tensor([0.3086, 0.0316, 0.0376, 0.1003, 0.5219], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,624 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,624 - train - INFO - True
2024-04-07 00:36:08,626 - train - INFO - alphas:tensor([0.2810, 0.0319, 0.0440, 0.1038, 0.5393], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,630 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,630 - train - INFO - True
2024-04-07 00:36:08,632 - train - INFO - alphas:tensor([0.4282, 0.0313, 0.0432, 0.0883, 0.4089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,639 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,639 - train - INFO - True
2024-04-07 00:36:08,643 - train - INFO - alphas:tensor([0.5664, 0.0329, 0.0424, 0.0800, 0.2783], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,663 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,663 - train - INFO - True
2024-04-07 00:36:08,666 - train - INFO - alphas:tensor([0.2337, 0.0278, 0.0381, 0.1158, 0.5846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,676 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,677 - train - INFO - True
2024-04-07 00:36:08,678 - train - INFO - alphas:tensor([0.2459, 0.0235, 0.0326, 0.1018, 0.5961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,688 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,688 - train - INFO - True
2024-04-07 00:36:08,690 - train - INFO - alphas:tensor([0.2701, 0.0239, 0.0323, 0.1007, 0.5731], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,700 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,700 - train - INFO - True
2024-04-07 00:36:08,702 - train - INFO - alphas:tensor([0.2312, 0.0283, 0.0347, 0.1092, 0.5966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,712 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,712 - train - INFO - True
2024-04-07 00:36:08,715 - train - INFO - alphas:tensor([0.5691, 0.0261, 0.0330, 0.0696, 0.3021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,734 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,734 - train - INFO - True
2024-04-07 00:36:08,735 - train - INFO - alphas:tensor([0.4217, 0.0334, 0.0404, 0.0938, 0.4107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:36:08,812 - train - INFO - tau:0.7700431458051551
2024-04-07 00:36:08,812 - train - INFO - avg block size:10.272727272727273
2024-04-07 00:36:08,813 - train - INFO - current latency ratio:tensor(0.2179)
2024-04-07 00:36:08,813 - train - INFO - lasso_alpha:3.543122000000002e-05
2024-04-07 00:36:09,016 - train - INFO - Test: [   0/78]  Time: 0.200 (0.200)  Loss:  1.0264 (1.0264)  Acc@1: 78.1250 (78.1250)  Acc@5: 94.5312 (94.5312)
2024-04-07 00:36:13,521 - train - INFO - Test: [  50/78]  Time: 0.125 (0.092)  Loss:  1.7197 (1.7232)  Acc@1: 59.3750 (61.0754)  Acc@5: 83.5938 (83.8235)
2024-04-07 00:36:16,018 - train - INFO - Test: [  78/78]  Time: 0.054 (0.091)  Loss:  1.7471 (1.7458)  Acc@1: 62.5000 (60.7300)  Acc@5: 93.7500 (83.2100)
2024-04-07 00:36:16,811 - train - INFO - Train: 29 [   0/781 (  0%)]  Loss:  4.087681 (4.0877)  Time: 0.706s,  181.41/s  (0.706s,  181.41/s)  LR: 4.562e-04  Data: 0.165 (0.165)
2024-04-07 00:36:41,508 - train - INFO - Train: 29 [  50/781 (  6%)]  Loss:  3.861230 (3.8098)  Time: 0.517s,  247.69/s  (0.498s,  257.00/s)  LR: 4.562e-04  Data: 0.007 (0.010)
2024-04-07 00:37:05,149 - train - INFO - Train: 29 [ 100/781 ( 13%)]  Loss:  3.792691 (3.8058)  Time: 0.539s,  237.36/s  (0.486s,  263.62/s)  LR: 4.562e-04  Data: 0.009 (0.009)
2024-04-07 00:37:28,775 - train - INFO - Train: 29 [ 150/781 ( 19%)]  Loss:  3.955876 (3.8075)  Time: 0.428s,  298.96/s  (0.481s,  265.99/s)  LR: 4.562e-04  Data: 0.006 (0.008)
2024-04-07 00:37:52,455 - train - INFO - Train: 29 [ 200/781 ( 26%)]  Loss:  4.101316 (3.8170)  Time: 0.435s,  294.40/s  (0.479s,  267.04/s)  LR: 4.562e-04  Data: 0.005 (0.008)
2024-04-07 00:38:16,190 - train - INFO - Train: 29 [ 250/781 ( 32%)]  Loss:  3.891926 (3.8125)  Time: 0.479s,  267.11/s  (0.478s,  267.56/s)  LR: 4.562e-04  Data: 0.007 (0.008)
2024-04-07 00:38:40,444 - train - INFO - Train: 29 [ 300/781 ( 38%)]  Loss:  3.989434 (3.8167)  Time: 0.514s,  249.04/s  (0.480s,  266.94/s)  LR: 4.562e-04  Data: 0.007 (0.008)
2024-04-07 00:39:04,426 - train - INFO - Train: 29 [ 350/781 ( 45%)]  Loss:  3.539389 (3.8165)  Time: 0.505s,  253.23/s  (0.480s,  266.94/s)  LR: 4.562e-04  Data: 0.007 (0.008)
2024-04-07 00:39:28,363 - train - INFO - Train: 29 [ 400/781 ( 51%)]  Loss:  4.027685 (3.8199)  Time: 0.423s,  302.28/s  (0.479s,  266.99/s)  LR: 4.562e-04  Data: 0.007 (0.008)
2024-04-07 00:39:53,419 - train - INFO - Train: 29 [ 450/781 ( 58%)]  Loss:  3.667874 (3.8212)  Time: 0.544s,  235.33/s  (0.482s,  265.66/s)  LR: 4.562e-04  Data: 0.008 (0.008)
2024-04-07 00:40:17,236 - train - INFO - Train: 29 [ 500/781 ( 64%)]  Loss:  3.671442 (3.8253)  Time: 0.573s,  223.40/s  (0.481s,  265.96/s)  LR: 4.562e-04  Data: 0.008 (0.008)
2024-04-07 00:40:41,272 - train - INFO - Train: 29 [ 550/781 ( 71%)]  Loss:  3.683861 (3.8259)  Time: 0.402s,  318.45/s  (0.481s,  265.99/s)  LR: 4.562e-04  Data: 0.008 (0.008)
2024-04-07 00:41:05,440 - train - INFO - Train: 29 [ 600/781 ( 77%)]  Loss:  3.984413 (3.8287)  Time: 0.447s,  286.46/s  (0.481s,  265.90/s)  LR: 4.562e-04  Data: 0.005 (0.008)
2024-04-07 00:41:30,170 - train - INFO - Train: 29 [ 650/781 ( 83%)]  Loss:  3.898455 (3.8291)  Time: 0.538s,  237.73/s  (0.482s,  265.34/s)  LR: 4.562e-04  Data: 0.011 (0.008)
2024-04-07 00:41:55,143 - train - INFO - Train: 29 [ 700/781 ( 90%)]  Loss:  3.833407 (3.8293)  Time: 0.559s,  229.15/s  (0.484s,  264.67/s)  LR: 4.562e-04  Data: 0.009 (0.008)
2024-04-07 00:42:19,365 - train - INFO - Train: 29 [ 750/781 ( 96%)]  Loss:  3.520161 (3.8306)  Time: 0.515s,  248.59/s  (0.484s,  264.64/s)  LR: 4.562e-04  Data: 0.008 (0.008)
2024-04-07 00:42:33,679 - train - INFO - Train: 29 [ 780/781 (100%)]  Loss:  3.860040 (3.8332)  Time: 0.455s,  281.47/s  (0.483s,  264.78/s)  LR: 4.562e-04  Data: 0.000 (0.008)
2024-04-07 00:42:33,680 - train - INFO - True
2024-04-07 00:42:33,686 - train - INFO - alphas:tensor([0.4328, 0.1136, 0.1197, 0.1454, 0.1885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,687 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,687 - train - INFO - True
2024-04-07 00:42:33,692 - train - INFO - alphas:tensor([0.3550, 0.0742, 0.0936, 0.1472, 0.3300], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,693 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,693 - train - INFO - True
2024-04-07 00:42:33,698 - train - INFO - alphas:tensor([0.3711, 0.0988, 0.1559, 0.3742], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,699 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,699 - train - INFO - True
2024-04-07 00:42:33,703 - train - INFO - alphas:tensor([0.3061, 0.0848, 0.1307, 0.4784], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,704 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,704 - train - INFO - True
2024-04-07 00:42:33,709 - train - INFO - alphas:tensor([0.3040, 0.0765, 0.1406, 0.4789], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,710 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,710 - train - INFO - True
2024-04-07 00:42:33,715 - train - INFO - alphas:tensor([0.3881, 0.0911, 0.1322, 0.3886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,716 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,716 - train - INFO - True
2024-04-07 00:42:33,721 - train - INFO - alphas:tensor([0.4399, 0.0736, 0.0819, 0.1252, 0.2794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,722 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,722 - train - INFO - True
2024-04-07 00:42:33,727 - train - INFO - alphas:tensor([0.1559, 0.0357, 0.0411, 0.1027, 0.6646], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,728 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,728 - train - INFO - True
2024-04-07 00:42:33,733 - train - INFO - alphas:tensor([0.1673, 0.0336, 0.0416, 0.0934, 0.6642], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,733 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,734 - train - INFO - True
2024-04-07 00:42:33,738 - train - INFO - alphas:tensor([0.1662, 0.0303, 0.0367, 0.0940, 0.6728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,739 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,739 - train - INFO - True
2024-04-07 00:42:33,743 - train - INFO - alphas:tensor([0.1543, 0.0328, 0.0394, 0.1002, 0.6732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,744 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,744 - train - INFO - True
2024-04-07 00:42:33,745 - train - INFO - alphas:tensor([0.4489, 0.0543, 0.0692, 0.1199, 0.3078], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,747 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,747 - train - INFO - True
2024-04-07 00:42:33,748 - train - INFO - alphas:tensor([0.5332, 0.0561, 0.0637, 0.0985, 0.2485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,751 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,751 - train - INFO - True
2024-04-07 00:42:33,752 - train - INFO - alphas:tensor([0.1554, 0.0448, 0.0502, 0.1356, 0.6139], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,754 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,754 - train - INFO - True
2024-04-07 00:42:33,755 - train - INFO - alphas:tensor([0.1709, 0.0378, 0.0471, 0.1296, 0.6146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,757 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,758 - train - INFO - True
2024-04-07 00:42:33,758 - train - INFO - alphas:tensor([0.1845, 0.0353, 0.0476, 0.1191, 0.6135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,760 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,761 - train - INFO - True
2024-04-07 00:42:33,761 - train - INFO - alphas:tensor([0.1625, 0.0416, 0.0491, 0.1211, 0.6256], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,763 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,763 - train - INFO - True
2024-04-07 00:42:33,764 - train - INFO - alphas:tensor([0.1882, 0.0345, 0.0485, 0.1195, 0.6093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,766 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,766 - train - INFO - True
2024-04-07 00:42:33,767 - train - INFO - alphas:tensor([0.1380, 0.0506, 0.0598, 0.1368, 0.6147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,769 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,769 - train - INFO - True
2024-04-07 00:42:33,770 - train - INFO - alphas:tensor([0.4846, 0.0412, 0.0495, 0.1026, 0.3221], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,774 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,774 - train - INFO - True
2024-04-07 00:42:33,775 - train - INFO - alphas:tensor([0.4081, 0.0366, 0.0429, 0.1037, 0.4087], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,779 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,779 - train - INFO - True
2024-04-07 00:42:33,780 - train - INFO - alphas:tensor([0.2933, 0.0326, 0.0442, 0.1049, 0.5250], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,790 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,790 - train - INFO - True
2024-04-07 00:42:33,791 - train - INFO - alphas:tensor([0.2985, 0.0325, 0.0394, 0.1065, 0.5231], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,802 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,802 - train - INFO - True
2024-04-07 00:42:33,803 - train - INFO - alphas:tensor([0.3158, 0.0302, 0.0367, 0.1015, 0.5158], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,807 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,807 - train - INFO - True
2024-04-07 00:42:33,808 - train - INFO - alphas:tensor([0.2848, 0.0307, 0.0426, 0.1028, 0.5391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,811 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,812 - train - INFO - True
2024-04-07 00:42:33,813 - train - INFO - alphas:tensor([0.4334, 0.0301, 0.0411, 0.0864, 0.4089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,820 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,820 - train - INFO - True
2024-04-07 00:42:33,821 - train - INFO - alphas:tensor([0.5698, 0.0321, 0.0409, 0.0784, 0.2788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,840 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,841 - train - INFO - True
2024-04-07 00:42:33,842 - train - INFO - alphas:tensor([0.2395, 0.0272, 0.0369, 0.1150, 0.5814], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,852 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,852 - train - INFO - True
2024-04-07 00:42:33,857 - train - INFO - alphas:tensor([0.2544, 0.0229, 0.0320, 0.1007, 0.5900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,867 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,867 - train - INFO - True
2024-04-07 00:42:33,871 - train - INFO - alphas:tensor([0.2755, 0.0235, 0.0315, 0.0999, 0.5695], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,881 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,881 - train - INFO - True
2024-04-07 00:42:33,884 - train - INFO - alphas:tensor([0.2400, 0.0274, 0.0336, 0.1083, 0.5907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,894 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,894 - train - INFO - True
2024-04-07 00:42:33,899 - train - INFO - alphas:tensor([0.5730, 0.0252, 0.0315, 0.0680, 0.3023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,918 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,918 - train - INFO - True
2024-04-07 00:42:33,920 - train - INFO - alphas:tensor([0.4284, 0.0330, 0.0395, 0.0921, 0.4070], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:42:33,998 - train - INFO - tau:0.7623427143471035
2024-04-07 00:42:33,998 - train - INFO - avg block size:10.484848484848484
2024-04-07 00:42:33,999 - train - INFO - current latency ratio:tensor(0.2054)
2024-04-07 00:42:34,304 - train - INFO - Test: [   0/78]  Time: 0.302 (0.302)  Loss:  1.0586 (1.0586)  Acc@1: 77.3438 (77.3438)  Acc@5: 92.1875 (92.1875)
2024-04-07 00:42:39,077 - train - INFO - Test: [  50/78]  Time: 0.080 (0.100)  Loss:  1.9307 (1.7367)  Acc@1: 54.6875 (60.6924)  Acc@5: 82.8125 (83.9767)
2024-04-07 00:42:41,713 - train - INFO - Test: [  78/78]  Time: 0.053 (0.098)  Loss:  2.1211 (1.7614)  Acc@1: 50.0000 (60.4600)  Acc@5: 87.5000 (83.5400)
2024-04-07 00:42:42,462 - train - INFO - Train: 30 [   0/781 (  0%)]  Loss:  3.696975 (3.6970)  Time: 0.669s,  191.23/s  (0.669s,  191.23/s)  LR: 4.532e-04  Data: 0.129 (0.129)
2024-04-07 00:43:06,665 - train - INFO - Train: 30 [  50/781 (  6%)]  Loss:  4.154842 (3.8320)  Time: 0.461s,  277.89/s  (0.488s,  262.48/s)  LR: 4.532e-04  Data: 0.008 (0.009)
2024-04-07 00:43:30,823 - train - INFO - Train: 30 [ 100/781 ( 13%)]  Loss:  3.941409 (3.8224)  Time: 0.476s,  268.89/s  (0.485s,  263.70/s)  LR: 4.532e-04  Data: 0.005 (0.008)
2024-04-07 00:43:55,310 - train - INFO - Train: 30 [ 150/781 ( 19%)]  Loss:  3.693673 (3.8217)  Time: 0.496s,  258.27/s  (0.487s,  262.92/s)  LR: 4.532e-04  Data: 0.012 (0.008)
2024-04-07 00:44:19,865 - train - INFO - Train: 30 [ 200/781 ( 26%)]  Loss:  3.921089 (3.8272)  Time: 0.500s,  256.05/s  (0.488s,  262.36/s)  LR: 4.532e-04  Data: 0.009 (0.008)
2024-04-07 00:44:43,590 - train - INFO - Train: 30 [ 250/781 ( 32%)]  Loss:  3.797608 (3.8363)  Time: 0.538s,  237.95/s  (0.485s,  263.80/s)  LR: 4.532e-04  Data: 0.010 (0.008)
2024-04-07 00:45:07,557 - train - INFO - Train: 30 [ 300/781 ( 38%)]  Loss:  4.092010 (3.8418)  Time: 0.430s,  297.45/s  (0.484s,  264.34/s)  LR: 4.532e-04  Data: 0.005 (0.008)
2024-04-07 00:45:31,973 - train - INFO - Train: 30 [ 350/781 ( 45%)]  Loss:  3.733490 (3.8412)  Time: 0.510s,  250.85/s  (0.485s,  264.02/s)  LR: 4.532e-04  Data: 0.009 (0.008)
2024-04-07 00:45:56,367 - train - INFO - Train: 30 [ 400/781 ( 51%)]  Loss:  4.032879 (3.8357)  Time: 0.509s,  251.63/s  (0.485s,  263.82/s)  LR: 4.532e-04  Data: 0.008 (0.008)
2024-04-07 00:46:20,949 - train - INFO - Train: 30 [ 450/781 ( 58%)]  Loss:  3.481419 (3.8339)  Time: 0.414s,  309.27/s  (0.486s,  263.43/s)  LR: 4.532e-04  Data: 0.004 (0.008)
2024-04-07 00:46:44,008 - train - INFO - Train: 30 [ 500/781 ( 64%)]  Loss:  3.532466 (3.8324)  Time: 0.454s,  282.02/s  (0.483s,  264.77/s)  LR: 4.532e-04  Data: 0.005 (0.008)
2024-04-07 00:47:07,572 - train - INFO - Train: 30 [ 550/781 ( 71%)]  Loss:  3.569219 (3.8342)  Time: 0.428s,  299.33/s  (0.482s,  265.38/s)  LR: 4.532e-04  Data: 0.007 (0.008)
2024-04-07 00:47:30,588 - train - INFO - Train: 30 [ 600/781 ( 77%)]  Loss:  3.489037 (3.8375)  Time: 0.477s,  268.41/s  (0.480s,  266.39/s)  LR: 4.532e-04  Data: 0.010 (0.008)
2024-04-07 00:47:55,130 - train - INFO - Train: 30 [ 650/781 ( 83%)]  Loss:  4.150739 (3.8375)  Time: 0.535s,  239.30/s  (0.481s,  265.96/s)  LR: 4.532e-04  Data: 0.012 (0.008)
2024-04-07 00:48:18,986 - train - INFO - Train: 30 [ 700/781 ( 90%)]  Loss:  4.068260 (3.8331)  Time: 0.467s,  274.34/s  (0.481s,  266.12/s)  LR: 4.532e-04  Data: 0.006 (0.008)
2024-04-07 00:48:43,683 - train - INFO - Train: 30 [ 750/781 ( 96%)]  Loss:  4.149398 (3.8335)  Time: 0.432s,  295.99/s  (0.482s,  265.65/s)  LR: 4.532e-04  Data: 0.009 (0.008)
2024-04-07 00:48:58,534 - train - INFO - Train: 30 [ 780/781 (100%)]  Loss:  3.780258 (3.8311)  Time: 0.557s,  229.92/s  (0.482s,  265.37/s)  LR: 4.532e-04  Data: 0.000 (0.008)
2024-04-07 00:48:58,534 - train - INFO - True
2024-04-07 00:48:58,538 - train - INFO - alphas:tensor([0.4371, 0.1111, 0.1185, 0.1447, 0.1886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,539 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,539 - train - INFO - True
2024-04-07 00:48:58,544 - train - INFO - alphas:tensor([0.3543, 0.0724, 0.0916, 0.1449, 0.3368], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,545 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,545 - train - INFO - True
2024-04-07 00:48:58,547 - train - INFO - alphas:tensor([0.3709, 0.0968, 0.1529, 0.3795], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,547 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,547 - train - INFO - True
2024-04-07 00:48:58,552 - train - INFO - alphas:tensor([0.3050, 0.0826, 0.1294, 0.4830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,552 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,552 - train - INFO - True
2024-04-07 00:48:58,556 - train - INFO - alphas:tensor([0.3079, 0.0745, 0.1369, 0.4807], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,557 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,557 - train - INFO - True
2024-04-07 00:48:58,559 - train - INFO - alphas:tensor([0.3872, 0.0886, 0.1302, 0.3939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,559 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,560 - train - INFO - True
2024-04-07 00:48:58,565 - train - INFO - alphas:tensor([0.4398, 0.0712, 0.0801, 0.1233, 0.2856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,566 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,566 - train - INFO - True
2024-04-07 00:48:58,570 - train - INFO - alphas:tensor([0.1581, 0.0357, 0.0401, 0.1001, 0.6660], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,571 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,571 - train - INFO - True
2024-04-07 00:48:58,573 - train - INFO - alphas:tensor([0.1689, 0.0328, 0.0404, 0.0913, 0.6665], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,573 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,573 - train - INFO - True
2024-04-07 00:48:58,578 - train - INFO - alphas:tensor([0.1659, 0.0289, 0.0359, 0.0932, 0.6760], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,579 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,579 - train - INFO - True
2024-04-07 00:48:58,580 - train - INFO - alphas:tensor([0.1550, 0.0325, 0.0380, 0.0991, 0.6753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,580 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,580 - train - INFO - True
2024-04-07 00:48:58,581 - train - INFO - alphas:tensor([0.4503, 0.0519, 0.0671, 0.1176, 0.3131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,583 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,583 - train - INFO - True
2024-04-07 00:48:58,584 - train - INFO - alphas:tensor([0.5333, 0.0538, 0.0617, 0.0970, 0.2542], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,587 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,587 - train - INFO - True
2024-04-07 00:48:58,588 - train - INFO - alphas:tensor([0.1552, 0.0441, 0.0490, 0.1369, 0.6149], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,590 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,590 - train - INFO - True
2024-04-07 00:48:58,591 - train - INFO - alphas:tensor([0.1708, 0.0366, 0.0451, 0.1280, 0.6195], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,593 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,593 - train - INFO - True
2024-04-07 00:48:58,594 - train - INFO - alphas:tensor([0.1885, 0.0344, 0.0460, 0.1183, 0.6128], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,596 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,596 - train - INFO - True
2024-04-07 00:48:58,597 - train - INFO - alphas:tensor([0.1615, 0.0405, 0.0485, 0.1196, 0.6299], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,599 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,599 - train - INFO - True
2024-04-07 00:48:58,600 - train - INFO - alphas:tensor([0.1873, 0.0335, 0.0474, 0.1185, 0.6133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,602 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,602 - train - INFO - True
2024-04-07 00:48:58,603 - train - INFO - alphas:tensor([0.1399, 0.0502, 0.0592, 0.1379, 0.6128], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,605 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,605 - train - INFO - True
2024-04-07 00:48:58,606 - train - INFO - alphas:tensor([0.4859, 0.0399, 0.0479, 0.1004, 0.3259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,609 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,609 - train - INFO - True
2024-04-07 00:48:58,610 - train - INFO - alphas:tensor([0.4092, 0.0352, 0.0415, 0.1018, 0.4123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,614 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,614 - train - INFO - True
2024-04-07 00:48:58,615 - train - INFO - alphas:tensor([0.2908, 0.0308, 0.0436, 0.1043, 0.5305], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,619 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,619 - train - INFO - True
2024-04-07 00:48:58,620 - train - INFO - alphas:tensor([0.3002, 0.0319, 0.0382, 0.1050, 0.5247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,624 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,624 - train - INFO - True
2024-04-07 00:48:58,625 - train - INFO - alphas:tensor([0.3172, 0.0291, 0.0358, 0.0998, 0.5180], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,629 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,629 - train - INFO - True
2024-04-07 00:48:58,630 - train - INFO - alphas:tensor([0.2831, 0.0295, 0.0415, 0.1034, 0.5425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,634 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,634 - train - INFO - True
2024-04-07 00:48:58,635 - train - INFO - alphas:tensor([0.4312, 0.0289, 0.0404, 0.0863, 0.4131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,647 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,648 - train - INFO - True
2024-04-07 00:48:58,649 - train - INFO - alphas:tensor([0.5693, 0.0307, 0.0398, 0.0763, 0.2839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,664 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,664 - train - INFO - True
2024-04-07 00:48:58,665 - train - INFO - alphas:tensor([0.2384, 0.0257, 0.0352, 0.1131, 0.5876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,672 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,672 - train - INFO - True
2024-04-07 00:48:58,673 - train - INFO - alphas:tensor([0.2531, 0.0222, 0.0315, 0.1002, 0.5930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,680 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,680 - train - INFO - True
2024-04-07 00:48:58,681 - train - INFO - alphas:tensor([0.2787, 0.0222, 0.0302, 0.0978, 0.5711], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,688 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,688 - train - INFO - True
2024-04-07 00:48:58,689 - train - INFO - alphas:tensor([0.2416, 0.0266, 0.0332, 0.1081, 0.5905], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,696 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,696 - train - INFO - True
2024-04-07 00:48:58,700 - train - INFO - alphas:tensor([0.5721, 0.0245, 0.0305, 0.0655, 0.3073], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,714 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,714 - train - INFO - True
2024-04-07 00:48:58,715 - train - INFO - alphas:tensor([0.4260, 0.0320, 0.0387, 0.0912, 0.4121], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:48:58,767 - train - INFO - tau:0.7547192872036325
2024-04-07 00:48:58,768 - train - INFO - avg block size:10.484848484848484
2024-04-07 00:48:58,768 - train - INFO - current latency ratio:tensor(0.2054)
2024-04-07 00:48:58,768 - train - INFO - lasso_alpha:3.221020000000002e-05
2024-04-07 00:48:59,066 - train - INFO - Test: [   0/78]  Time: 0.294 (0.294)  Loss:  1.0488 (1.0488)  Acc@1: 78.9062 (78.9062)  Acc@5: 91.4062 (91.4062)
2024-04-07 00:49:03,660 - train - INFO - Test: [  50/78]  Time: 0.054 (0.096)  Loss:  2.1426 (1.7805)  Acc@1: 47.6562 (60.0490)  Acc@5: 77.3438 (83.3793)
2024-04-07 00:49:06,070 - train - INFO - Test: [  78/78]  Time: 0.123 (0.092)  Loss:  1.8193 (1.7961)  Acc@1: 68.7500 (59.9100)  Acc@5: 93.7500 (83.1800)
2024-04-07 00:49:06,864 - train - INFO - Train: 31 [   0/781 (  0%)]  Loss:  3.529914 (3.5299)  Time: 0.708s,  180.68/s  (0.708s,  180.68/s)  LR: 4.501e-04  Data: 0.198 (0.198)
2024-04-07 00:49:30,811 - train - INFO - Train: 31 [  50/781 (  6%)]  Loss:  4.193431 (3.9028)  Time: 0.476s,  268.72/s  (0.483s,  264.79/s)  LR: 4.501e-04  Data: 0.008 (0.011)
2024-04-07 00:49:55,495 - train - INFO - Train: 31 [ 100/781 ( 13%)]  Loss:  3.806598 (3.8701)  Time: 0.517s,  247.54/s  (0.488s,  262.08/s)  LR: 4.501e-04  Data: 0.009 (0.009)
2024-04-07 00:50:19,797 - train - INFO - Train: 31 [ 150/781 ( 19%)]  Loss:  3.515532 (3.8525)  Time: 0.494s,  258.89/s  (0.488s,  262.50/s)  LR: 4.501e-04  Data: 0.008 (0.009)
2024-04-07 00:50:48,544 - train - INFO - Train: 31 [ 200/781 ( 26%)]  Loss:  3.748055 (3.8483)  Time: 0.373s,  342.72/s  (0.509s,  251.31/s)  LR: 4.501e-04  Data: 0.004 (0.008)
2024-04-07 00:51:19,819 - train - INFO - Train: 31 [ 250/781 ( 32%)]  Loss:  4.148059 (3.8452)  Time: 0.469s,  272.79/s  (0.532s,  240.39/s)  LR: 4.501e-04  Data: 0.005 (0.008)
2024-04-07 00:51:50,097 - train - INFO - Train: 31 [ 300/781 ( 38%)]  Loss:  3.763634 (3.8407)  Time: 1.036s,  123.55/s  (0.545s,  235.03/s)  LR: 4.501e-04  Data: 0.008 (0.008)
2024-04-07 00:52:21,288 - train - INFO - Train: 31 [ 350/781 ( 45%)]  Loss:  3.719879 (3.8373)  Time: 1.070s,  119.58/s  (0.556s,  230.26/s)  LR: 4.501e-04  Data: 0.010 (0.008)
2024-04-07 00:52:47,144 - train - INFO - Train: 31 [ 400/781 ( 51%)]  Loss:  3.492766 (3.8297)  Time: 0.378s,  338.69/s  (0.551s,  232.29/s)  LR: 4.501e-04  Data: 0.005 (0.008)
2024-04-07 00:53:11,002 - train - INFO - Train: 31 [ 450/781 ( 58%)]  Loss:  3.782230 (3.8278)  Time: 0.477s,  268.56/s  (0.543s,  235.79/s)  LR: 4.501e-04  Data: 0.009 (0.008)
2024-04-07 00:53:33,906 - train - INFO - Train: 31 [ 500/781 ( 64%)]  Loss:  3.592189 (3.8219)  Time: 0.400s,  319.79/s  (0.534s,  239.53/s)  LR: 4.501e-04  Data: 0.006 (0.008)
2024-04-07 00:53:57,579 - train - INFO - Train: 31 [ 550/781 ( 71%)]  Loss:  4.147158 (3.8221)  Time: 0.526s,  243.43/s  (0.529s,  242.03/s)  LR: 4.501e-04  Data: 0.009 (0.008)
2024-04-07 00:54:21,988 - train - INFO - Train: 31 [ 600/781 ( 77%)]  Loss:  3.696208 (3.8220)  Time: 0.503s,  254.65/s  (0.525s,  243.59/s)  LR: 4.501e-04  Data: 0.009 (0.008)
2024-04-07 00:54:45,774 - train - INFO - Train: 31 [ 650/781 ( 83%)]  Loss:  3.471977 (3.8225)  Time: 0.478s,  267.51/s  (0.522s,  245.38/s)  LR: 4.501e-04  Data: 0.008 (0.008)
2024-04-07 00:55:09,066 - train - INFO - Train: 31 [ 700/781 ( 90%)]  Loss:  3.936163 (3.8202)  Time: 0.484s,  264.57/s  (0.518s,  247.27/s)  LR: 4.501e-04  Data: 0.005 (0.008)
2024-04-07 00:55:32,602 - train - INFO - Train: 31 [ 750/781 ( 96%)]  Loss:  3.910935 (3.8187)  Time: 0.500s,  255.81/s  (0.515s,  248.77/s)  LR: 4.501e-04  Data: 0.010 (0.008)
2024-04-07 00:55:47,087 - train - INFO - Train: 31 [ 780/781 (100%)]  Loss:  4.040161 (3.8180)  Time: 0.484s,  264.41/s  (0.513s,  249.36/s)  LR: 4.501e-04  Data: 0.000 (0.008)
2024-04-07 00:55:47,088 - train - INFO - True
2024-04-07 00:55:47,089 - train - INFO - alphas:tensor([0.4419, 0.1091, 0.1165, 0.1430, 0.1894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,090 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,090 - train - INFO - True
2024-04-07 00:55:47,092 - train - INFO - alphas:tensor([0.3560, 0.0702, 0.0896, 0.1425, 0.3417], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,092 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,092 - train - INFO - True
2024-04-07 00:55:47,094 - train - INFO - alphas:tensor([0.3740, 0.0944, 0.1503, 0.3813], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,094 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,094 - train - INFO - True
2024-04-07 00:55:47,096 - train - INFO - alphas:tensor([0.3084, 0.0801, 0.1253, 0.4862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,096 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,096 - train - INFO - True
2024-04-07 00:55:47,097 - train - INFO - alphas:tensor([0.3116, 0.0724, 0.1346, 0.4814], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,098 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,098 - train - INFO - True
2024-04-07 00:55:47,099 - train - INFO - alphas:tensor([0.3893, 0.0867, 0.1285, 0.3955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,100 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,100 - train - INFO - True
2024-04-07 00:55:47,101 - train - INFO - alphas:tensor([0.4436, 0.0689, 0.0780, 0.1221, 0.2874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,103 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,103 - train - INFO - True
2024-04-07 00:55:47,104 - train - INFO - alphas:tensor([0.1643, 0.0357, 0.0385, 0.0990, 0.6625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,105 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,105 - train - INFO - True
2024-04-07 00:55:47,106 - train - INFO - alphas:tensor([0.1743, 0.0323, 0.0395, 0.0906, 0.6632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,107 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,107 - train - INFO - True
2024-04-07 00:55:47,108 - train - INFO - alphas:tensor([0.1735, 0.0287, 0.0350, 0.0907, 0.6721], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,109 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,109 - train - INFO - True
2024-04-07 00:55:47,110 - train - INFO - alphas:tensor([0.1611, 0.0323, 0.0369, 0.0976, 0.6720], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,111 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,111 - train - INFO - True
2024-04-07 00:55:47,112 - train - INFO - alphas:tensor([0.4522, 0.0499, 0.0648, 0.1147, 0.3183], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,114 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,114 - train - INFO - True
2024-04-07 00:55:47,115 - train - INFO - alphas:tensor([0.5367, 0.0522, 0.0593, 0.0951, 0.2567], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,119 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,119 - train - INFO - True
2024-04-07 00:55:47,120 - train - INFO - alphas:tensor([0.1647, 0.0443, 0.0490, 0.1342, 0.6077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,122 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,122 - train - INFO - True
2024-04-07 00:55:47,124 - train - INFO - alphas:tensor([0.1779, 0.0365, 0.0441, 0.1258, 0.6157], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,126 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,126 - train - INFO - True
2024-04-07 00:55:47,127 - train - INFO - alphas:tensor([0.1969, 0.0336, 0.0439, 0.1149, 0.6106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,129 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,129 - train - INFO - True
2024-04-07 00:55:47,130 - train - INFO - alphas:tensor([0.1690, 0.0406, 0.0480, 0.1197, 0.6226], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,132 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,132 - train - INFO - True
2024-04-07 00:55:47,133 - train - INFO - alphas:tensor([0.1914, 0.0327, 0.0468, 0.1177, 0.6114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,135 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,136 - train - INFO - True
2024-04-07 00:55:47,137 - train - INFO - alphas:tensor([0.1445, 0.0509, 0.0583, 0.1374, 0.6089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,139 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,139 - train - INFO - True
2024-04-07 00:55:47,140 - train - INFO - alphas:tensor([0.4920, 0.0380, 0.0460, 0.0981, 0.3258], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,143 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,143 - train - INFO - True
2024-04-07 00:55:47,144 - train - INFO - alphas:tensor([0.4153, 0.0338, 0.0397, 0.0990, 0.4122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,152 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,152 - train - INFO - True
2024-04-07 00:55:47,153 - train - INFO - alphas:tensor([0.2945, 0.0297, 0.0419, 0.1015, 0.5324], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,157 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,157 - train - INFO - True
2024-04-07 00:55:47,158 - train - INFO - alphas:tensor([0.3111, 0.0311, 0.0367, 0.1027, 0.5184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,162 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,162 - train - INFO - True
2024-04-07 00:55:47,163 - train - INFO - alphas:tensor([0.3283, 0.0281, 0.0346, 0.0972, 0.5118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,167 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,167 - train - INFO - True
2024-04-07 00:55:47,168 - train - INFO - alphas:tensor([0.2962, 0.0292, 0.0406, 0.1035, 0.5304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,172 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,172 - train - INFO - True
2024-04-07 00:55:47,173 - train - INFO - alphas:tensor([0.4354, 0.0281, 0.0389, 0.0847, 0.4130], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,180 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,180 - train - INFO - True
2024-04-07 00:55:47,181 - train - INFO - alphas:tensor([0.5765, 0.0290, 0.0380, 0.0746, 0.2820], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,201 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,201 - train - INFO - True
2024-04-07 00:55:47,202 - train - INFO - alphas:tensor([0.2508, 0.0254, 0.0345, 0.1140, 0.5753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,212 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,212 - train - INFO - True
2024-04-07 00:55:47,213 - train - INFO - alphas:tensor([0.2630, 0.0217, 0.0306, 0.0999, 0.5847], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,223 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,223 - train - INFO - True
2024-04-07 00:55:47,224 - train - INFO - alphas:tensor([0.2902, 0.0220, 0.0300, 0.0974, 0.5604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,234 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,234 - train - INFO - True
2024-04-07 00:55:47,235 - train - INFO - alphas:tensor([0.2511, 0.0263, 0.0328, 0.1054, 0.5845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,245 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,245 - train - INFO - True
2024-04-07 00:55:47,246 - train - INFO - alphas:tensor([0.5798, 0.0234, 0.0294, 0.0646, 0.3028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,266 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,266 - train - INFO - True
2024-04-07 00:55:47,267 - train - INFO - alphas:tensor([0.4373, 0.0313, 0.0375, 0.0893, 0.4046], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:55:47,344 - train - INFO - tau:0.7471720943315961
2024-04-07 00:55:47,345 - train - INFO - avg block size:10.030303030303031
2024-04-07 00:55:47,345 - train - INFO - current latency ratio:tensor(0.2231)
2024-04-07 00:55:47,577 - train - INFO - Test: [   0/78]  Time: 0.229 (0.229)  Loss:  1.1582 (1.1582)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
2024-04-07 00:55:50,467 - train - INFO - Test: [  50/78]  Time: 0.054 (0.061)  Loss:  1.8750 (1.7458)  Acc@1: 57.0312 (60.8150)  Acc@5: 82.0312 (83.7010)
2024-04-07 00:55:52,267 - train - INFO - Test: [  78/78]  Time: 0.050 (0.062)  Loss:  1.8232 (1.7729)  Acc@1: 56.2500 (60.4100)  Acc@5: 93.7500 (83.3200)
2024-04-07 00:55:52,952 - train - INFO - Train: 32 [   0/781 (  0%)]  Loss:  4.056076 (4.0561)  Time: 0.601s,  212.98/s  (0.601s,  212.98/s)  LR: 4.470e-04  Data: 0.158 (0.158)
2024-04-07 00:56:16,961 - train - INFO - Train: 32 [  50/781 (  6%)]  Loss:  3.980447 (3.8492)  Time: 0.463s,  276.63/s  (0.483s,  265.27/s)  LR: 4.470e-04  Data: 0.006 (0.010)
2024-04-07 00:56:39,898 - train - INFO - Train: 32 [ 100/781 ( 13%)]  Loss:  3.785663 (3.8038)  Time: 0.504s,  253.82/s  (0.471s,  271.92/s)  LR: 4.470e-04  Data: 0.008 (0.009)
2024-04-07 00:57:03,560 - train - INFO - Train: 32 [ 150/781 ( 19%)]  Loss:  4.037466 (3.8240)  Time: 0.477s,  268.62/s  (0.472s,  271.44/s)  LR: 4.470e-04  Data: 0.005 (0.008)
2024-04-07 00:57:27,757 - train - INFO - Train: 32 [ 200/781 ( 26%)]  Loss:  3.713053 (3.8245)  Time: 0.469s,  273.10/s  (0.475s,  269.68/s)  LR: 4.470e-04  Data: 0.007 (0.008)
2024-04-07 00:57:51,188 - train - INFO - Train: 32 [ 250/781 ( 32%)]  Loss:  3.582695 (3.8180)  Time: 0.480s,  266.53/s  (0.473s,  270.37/s)  LR: 4.470e-04  Data: 0.007 (0.008)
2024-04-07 00:58:15,333 - train - INFO - Train: 32 [ 300/781 ( 38%)]  Loss:  4.089059 (3.8270)  Time: 0.503s,  254.36/s  (0.475s,  269.48/s)  LR: 4.470e-04  Data: 0.008 (0.008)
2024-04-07 00:58:38,948 - train - INFO - Train: 32 [ 350/781 ( 45%)]  Loss:  3.801143 (3.8214)  Time: 0.443s,  289.15/s  (0.475s,  269.70/s)  LR: 4.470e-04  Data: 0.007 (0.008)
2024-04-07 00:59:03,275 - train - INFO - Train: 32 [ 400/781 ( 51%)]  Loss:  3.581997 (3.8234)  Time: 0.453s,  282.44/s  (0.476s,  268.86/s)  LR: 4.470e-04  Data: 0.006 (0.008)
2024-04-07 00:59:27,233 - train - INFO - Train: 32 [ 450/781 ( 58%)]  Loss:  3.893127 (3.8216)  Time: 0.403s,  317.32/s  (0.476s,  268.67/s)  LR: 4.470e-04  Data: 0.006 (0.008)
2024-04-07 00:59:51,827 - train - INFO - Train: 32 [ 500/781 ( 64%)]  Loss:  3.733647 (3.8223)  Time: 0.489s,  261.61/s  (0.478s,  267.80/s)  LR: 4.470e-04  Data: 0.009 (0.008)
2024-04-07 01:00:16,255 - train - INFO - Train: 32 [ 550/781 ( 71%)]  Loss:  3.730946 (3.8173)  Time: 0.535s,  239.06/s  (0.479s,  267.27/s)  LR: 4.470e-04  Data: 0.007 (0.008)
2024-04-07 01:00:39,946 - train - INFO - Train: 32 [ 600/781 ( 77%)]  Loss:  3.886283 (3.8157)  Time: 0.537s,  238.52/s  (0.478s,  267.51/s)  LR: 4.470e-04  Data: 0.010 (0.008)
2024-04-07 01:01:04,228 - train - INFO - Train: 32 [ 650/781 ( 83%)]  Loss:  3.554189 (3.8160)  Time: 0.483s,  264.80/s  (0.479s,  267.20/s)  LR: 4.470e-04  Data: 0.013 (0.008)
2024-04-07 01:01:29,212 - train - INFO - Train: 32 [ 700/781 ( 90%)]  Loss:  4.033573 (3.8184)  Time: 0.572s,  223.76/s  (0.481s,  266.38/s)  LR: 4.470e-04  Data: 0.008 (0.008)
2024-04-07 01:01:54,519 - train - INFO - Train: 32 [ 750/781 ( 96%)]  Loss:  3.305259 (3.8147)  Time: 0.488s,  262.25/s  (0.482s,  265.45/s)  LR: 4.470e-04  Data: 0.006 (0.008)
2024-04-07 01:02:09,097 - train - INFO - Train: 32 [ 780/781 (100%)]  Loss:  3.819785 (3.8143)  Time: 0.465s,  275.19/s  (0.482s,  265.37/s)  LR: 4.470e-04  Data: 0.000 (0.008)
2024-04-07 01:02:09,098 - train - INFO - True
2024-04-07 01:02:09,103 - train - INFO - alphas:tensor([0.4447, 0.1077, 0.1151, 0.1425, 0.1901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,104 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,104 - train - INFO - True
2024-04-07 01:02:09,110 - train - INFO - alphas:tensor([0.3561, 0.0676, 0.0871, 0.1428, 0.3464], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,111 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,111 - train - INFO - True
2024-04-07 01:02:09,116 - train - INFO - alphas:tensor([0.3753, 0.0919, 0.1475, 0.3852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,117 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,117 - train - INFO - True
2024-04-07 01:02:09,121 - train - INFO - alphas:tensor([0.3098, 0.0788, 0.1248, 0.4866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,122 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,122 - train - INFO - True
2024-04-07 01:02:09,124 - train - INFO - alphas:tensor([0.3141, 0.0705, 0.1315, 0.4839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,125 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,125 - train - INFO - True
2024-04-07 01:02:09,130 - train - INFO - alphas:tensor([0.3916, 0.0836, 0.1263, 0.3986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,130 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,130 - train - INFO - True
2024-04-07 01:02:09,135 - train - INFO - alphas:tensor([0.4465, 0.0667, 0.0753, 0.1195, 0.2919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,136 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,136 - train - INFO - True
2024-04-07 01:02:09,138 - train - INFO - alphas:tensor([0.1645, 0.0351, 0.0372, 0.0974, 0.6659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,139 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,139 - train - INFO - True
2024-04-07 01:02:09,144 - train - INFO - alphas:tensor([0.1761, 0.0311, 0.0379, 0.0886, 0.6662], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,144 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,145 - train - INFO - True
2024-04-07 01:02:09,150 - train - INFO - alphas:tensor([0.1761, 0.0279, 0.0339, 0.0897, 0.6724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,150 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,151 - train - INFO - True
2024-04-07 01:02:09,156 - train - INFO - alphas:tensor([0.1620, 0.0313, 0.0358, 0.0965, 0.6744], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,157 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,157 - train - INFO - True
2024-04-07 01:02:09,159 - train - INFO - alphas:tensor([0.4590, 0.0482, 0.0622, 0.1126, 0.3179], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,160 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,160 - train - INFO - True
2024-04-07 01:02:09,163 - train - INFO - alphas:tensor([0.5371, 0.0512, 0.0579, 0.0933, 0.2605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,167 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,167 - train - INFO - True
2024-04-07 01:02:09,171 - train - INFO - alphas:tensor([0.1623, 0.0436, 0.0475, 0.1327, 0.6139], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,172 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,173 - train - INFO - True
2024-04-07 01:02:09,177 - train - INFO - alphas:tensor([0.1792, 0.0358, 0.0430, 0.1250, 0.6170], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,179 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,179 - train - INFO - True
2024-04-07 01:02:09,183 - train - INFO - alphas:tensor([0.1990, 0.0334, 0.0440, 0.1161, 0.6076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,185 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,186 - train - INFO - True
2024-04-07 01:02:09,186 - train - INFO - alphas:tensor([0.1691, 0.0401, 0.0467, 0.1182, 0.6259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,188 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,188 - train - INFO - True
2024-04-07 01:02:09,194 - train - INFO - alphas:tensor([0.1925, 0.0322, 0.0464, 0.1141, 0.6148], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,196 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,196 - train - INFO - True
2024-04-07 01:02:09,200 - train - INFO - alphas:tensor([0.1445, 0.0506, 0.0569, 0.1334, 0.6146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,202 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,202 - train - INFO - True
2024-04-07 01:02:09,203 - train - INFO - alphas:tensor([0.4924, 0.0369, 0.0451, 0.0961, 0.3295], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,206 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,207 - train - INFO - True
2024-04-07 01:02:09,208 - train - INFO - alphas:tensor([0.4190, 0.0330, 0.0383, 0.0977, 0.4119], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,215 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,215 - train - INFO - True
2024-04-07 01:02:09,216 - train - INFO - alphas:tensor([0.2986, 0.0289, 0.0418, 0.1020, 0.5286], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,220 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,220 - train - INFO - True
2024-04-07 01:02:09,221 - train - INFO - alphas:tensor([0.3125, 0.0303, 0.0360, 0.1019, 0.5192], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,225 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,225 - train - INFO - True
2024-04-07 01:02:09,226 - train - INFO - alphas:tensor([0.3279, 0.0273, 0.0330, 0.0966, 0.5152], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,230 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,230 - train - INFO - True
2024-04-07 01:02:09,231 - train - INFO - alphas:tensor([0.3008, 0.0280, 0.0396, 0.1006, 0.5309], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,235 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,235 - train - INFO - True
2024-04-07 01:02:09,236 - train - INFO - alphas:tensor([0.4430, 0.0272, 0.0380, 0.0834, 0.4084], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,243 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,243 - train - INFO - True
2024-04-07 01:02:09,244 - train - INFO - alphas:tensor([0.5799, 0.0277, 0.0366, 0.0725, 0.2833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,264 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,264 - train - INFO - True
2024-04-07 01:02:09,265 - train - INFO - alphas:tensor([0.2533, 0.0245, 0.0336, 0.1133, 0.5754], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,275 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,275 - train - INFO - True
2024-04-07 01:02:09,276 - train - INFO - alphas:tensor([0.2661, 0.0208, 0.0302, 0.0990, 0.5839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,286 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,286 - train - INFO - True
2024-04-07 01:02:09,287 - train - INFO - alphas:tensor([0.2912, 0.0212, 0.0296, 0.0959, 0.5621], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,297 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,297 - train - INFO - True
2024-04-07 01:02:09,298 - train - INFO - alphas:tensor([0.2515, 0.0257, 0.0319, 0.1056, 0.5853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,309 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,309 - train - INFO - True
2024-04-07 01:02:09,310 - train - INFO - alphas:tensor([0.5852, 0.0223, 0.0280, 0.0621, 0.3024], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,329 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,329 - train - INFO - True
2024-04-07 01:02:09,330 - train - INFO - alphas:tensor([0.4438, 0.0304, 0.0366, 0.0888, 0.4003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:02:09,408 - train - INFO - tau:0.7397003733882802
2024-04-07 01:02:09,408 - train - INFO - avg block size:10.030303030303031
2024-04-07 01:02:09,408 - train - INFO - current latency ratio:tensor(0.2231)
2024-04-07 01:02:09,409 - train - INFO - lasso_alpha:2.9282000000000015e-05
2024-04-07 01:02:09,602 - train - INFO - Test: [   0/78]  Time: 0.189 (0.189)  Loss:  1.2373 (1.2373)  Acc@1: 76.5625 (76.5625)  Acc@5: 89.8438 (89.8438)
2024-04-07 01:02:13,577 - train - INFO - Test: [  50/78]  Time: 0.143 (0.082)  Loss:  1.6025 (1.6926)  Acc@1: 63.2812 (61.3358)  Acc@5: 83.5938 (84.2218)
2024-04-07 01:02:15,575 - train - INFO - Test: [  78/78]  Time: 0.104 (0.078)  Loss:  2.0703 (1.7141)  Acc@1: 50.0000 (61.0900)  Acc@5: 93.7500 (83.8700)
2024-04-07 01:02:16,388 - train - INFO - Train: 33 [   0/781 (  0%)]  Loss:  4.217049 (4.2170)  Time: 0.726s,  176.38/s  (0.726s,  176.38/s)  LR: 4.438e-04  Data: 0.180 (0.180)
2024-04-07 01:02:40,636 - train - INFO - Train: 33 [  50/781 (  6%)]  Loss:  3.966368 (3.7910)  Time: 0.458s,  279.47/s  (0.490s,  261.41/s)  LR: 4.438e-04  Data: 0.006 (0.011)
2024-04-07 01:03:04,836 - train - INFO - Train: 33 [ 100/781 ( 13%)]  Loss:  3.864829 (3.7949)  Time: 0.500s,  256.18/s  (0.487s,  262.92/s)  LR: 4.438e-04  Data: 0.009 (0.009)
2024-04-07 01:03:30,067 - train - INFO - Train: 33 [ 150/781 ( 19%)]  Loss:  3.694055 (3.7856)  Time: 0.567s,  225.61/s  (0.493s,  259.78/s)  LR: 4.438e-04  Data: 0.011 (0.009)
2024-04-07 01:03:54,639 - train - INFO - Train: 33 [ 200/781 ( 26%)]  Loss:  3.939337 (3.7991)  Time: 0.452s,  283.22/s  (0.492s,  259.96/s)  LR: 4.438e-04  Data: 0.006 (0.009)
2024-04-07 01:04:18,740 - train - INFO - Train: 33 [ 250/781 ( 32%)]  Loss:  3.916593 (3.8047)  Time: 0.495s,  258.44/s  (0.490s,  261.05/s)  LR: 4.438e-04  Data: 0.006 (0.008)
2024-04-07 01:04:43,043 - train - INFO - Train: 33 [ 300/781 ( 38%)]  Loss:  3.766893 (3.8017)  Time: 0.495s,  258.37/s  (0.490s,  261.43/s)  LR: 4.438e-04  Data: 0.006 (0.008)
2024-04-07 01:05:08,024 - train - INFO - Train: 33 [ 350/781 ( 45%)]  Loss:  3.650608 (3.8046)  Time: 0.532s,  240.44/s  (0.491s,  260.68/s)  LR: 4.438e-04  Data: 0.008 (0.008)
2024-04-07 01:05:31,833 - train - INFO - Train: 33 [ 400/781 ( 51%)]  Loss:  3.780398 (3.8064)  Time: 0.550s,  232.78/s  (0.489s,  261.67/s)  LR: 4.438e-04  Data: 0.008 (0.008)
2024-04-07 01:05:55,797 - train - INFO - Train: 33 [ 450/781 ( 58%)]  Loss:  3.471148 (3.8003)  Time: 0.461s,  277.58/s  (0.488s,  262.26/s)  LR: 4.438e-04  Data: 0.004 (0.008)
2024-04-07 01:06:20,666 - train - INFO - Train: 33 [ 500/781 ( 64%)]  Loss:  3.971051 (3.7963)  Time: 0.506s,  252.81/s  (0.489s,  261.76/s)  LR: 4.438e-04  Data: 0.005 (0.008)
2024-04-07 01:06:44,999 - train - INFO - Train: 33 [ 550/781 ( 71%)]  Loss:  3.856304 (3.7935)  Time: 0.470s,  272.26/s  (0.489s,  261.88/s)  LR: 4.438e-04  Data: 0.006 (0.008)
2024-04-07 01:07:10,118 - train - INFO - Train: 33 [ 600/781 ( 77%)]  Loss:  3.789891 (3.7926)  Time: 0.518s,  247.07/s  (0.490s,  261.27/s)  LR: 4.438e-04  Data: 0.006 (0.008)
2024-04-07 01:07:33,913 - train - INFO - Train: 33 [ 650/781 ( 83%)]  Loss:  3.911771 (3.7939)  Time: 0.549s,  233.28/s  (0.489s,  261.85/s)  LR: 4.438e-04  Data: 0.010 (0.008)
2024-04-07 01:07:57,019 - train - INFO - Train: 33 [ 700/781 ( 90%)]  Loss:  3.829931 (3.7964)  Time: 0.492s,  260.04/s  (0.487s,  262.87/s)  LR: 4.438e-04  Data: 0.008 (0.008)
2024-04-07 01:08:21,197 - train - INFO - Train: 33 [ 750/781 ( 96%)]  Loss:  3.711746 (3.7990)  Time: 0.422s,  303.32/s  (0.487s,  263.00/s)  LR: 4.438e-04  Data: 0.007 (0.008)
2024-04-07 01:08:35,780 - train - INFO - Train: 33 [ 780/781 (100%)]  Loss:  4.002851 (3.8007)  Time: 0.560s,  228.65/s  (0.487s,  263.01/s)  LR: 4.438e-04  Data: 0.000 (0.008)
2024-04-07 01:08:35,781 - train - INFO - True
2024-04-07 01:08:35,783 - train - INFO - alphas:tensor([0.4487, 0.1062, 0.1141, 0.1411, 0.1899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,784 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,784 - train - INFO - True
2024-04-07 01:08:35,786 - train - INFO - alphas:tensor([0.3608, 0.0653, 0.0854, 0.1398, 0.3487], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,786 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,787 - train - INFO - True
2024-04-07 01:08:35,788 - train - INFO - alphas:tensor([0.3742, 0.0898, 0.1470, 0.3890], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,789 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,789 - train - INFO - True
2024-04-07 01:08:35,790 - train - INFO - alphas:tensor([0.3172, 0.0774, 0.1211, 0.4843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,791 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,791 - train - INFO - True
2024-04-07 01:08:35,792 - train - INFO - alphas:tensor([0.3181, 0.0685, 0.1297, 0.4837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,793 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,793 - train - INFO - True
2024-04-07 01:08:35,795 - train - INFO - alphas:tensor([0.3979, 0.0818, 0.1225, 0.3978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,796 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,796 - train - INFO - True
2024-04-07 01:08:35,797 - train - INFO - alphas:tensor([0.4477, 0.0653, 0.0738, 0.1185, 0.2948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,799 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,799 - train - INFO - True
2024-04-07 01:08:35,800 - train - INFO - alphas:tensor([0.1698, 0.0344, 0.0365, 0.0967, 0.6626], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,801 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,801 - train - INFO - True
2024-04-07 01:08:35,803 - train - INFO - alphas:tensor([0.1815, 0.0303, 0.0365, 0.0871, 0.6647], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,804 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,804 - train - INFO - True
2024-04-07 01:08:35,805 - train - INFO - alphas:tensor([0.1810, 0.0275, 0.0333, 0.0897, 0.6685], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,806 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,806 - train - INFO - True
2024-04-07 01:08:35,807 - train - INFO - alphas:tensor([0.1680, 0.0306, 0.0350, 0.0947, 0.6717], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,808 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,809 - train - INFO - True
2024-04-07 01:08:35,810 - train - INFO - alphas:tensor([0.4603, 0.0466, 0.0605, 0.1121, 0.3205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,811 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,811 - train - INFO - True
2024-04-07 01:08:35,813 - train - INFO - alphas:tensor([0.5395, 0.0497, 0.0565, 0.0923, 0.2620], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,817 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,817 - train - INFO - True
2024-04-07 01:08:35,819 - train - INFO - alphas:tensor([0.1678, 0.0444, 0.0475, 0.1326, 0.6077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,821 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,821 - train - INFO - True
2024-04-07 01:08:35,822 - train - INFO - alphas:tensor([0.1826, 0.0352, 0.0422, 0.1242, 0.6159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,825 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,825 - train - INFO - True
2024-04-07 01:08:35,826 - train - INFO - alphas:tensor([0.2040, 0.0329, 0.0428, 0.1161, 0.6041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,829 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,829 - train - INFO - True
2024-04-07 01:08:35,830 - train - INFO - alphas:tensor([0.1735, 0.0397, 0.0457, 0.1164, 0.6246], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,832 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,832 - train - INFO - True
2024-04-07 01:08:35,833 - train - INFO - alphas:tensor([0.1996, 0.0321, 0.0457, 0.1152, 0.6074], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,836 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,836 - train - INFO - True
2024-04-07 01:08:35,837 - train - INFO - alphas:tensor([0.1533, 0.0511, 0.0570, 0.1327, 0.6059], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,839 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,839 - train - INFO - True
2024-04-07 01:08:35,840 - train - INFO - alphas:tensor([0.4952, 0.0358, 0.0436, 0.0943, 0.3310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,844 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,844 - train - INFO - True
2024-04-07 01:08:35,846 - train - INFO - alphas:tensor([0.4277, 0.0315, 0.0370, 0.0958, 0.4080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,854 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,854 - train - INFO - True
2024-04-07 01:08:35,855 - train - INFO - alphas:tensor([0.3138, 0.0286, 0.0409, 0.1016, 0.5151], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,859 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,859 - train - INFO - True
2024-04-07 01:08:35,860 - train - INFO - alphas:tensor([0.3218, 0.0292, 0.0351, 0.1004, 0.5136], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,864 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,864 - train - INFO - True
2024-04-07 01:08:35,865 - train - INFO - alphas:tensor([0.3345, 0.0257, 0.0326, 0.0963, 0.5110], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,869 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,870 - train - INFO - True
2024-04-07 01:08:35,877 - train - INFO - alphas:tensor([0.3030, 0.0271, 0.0380, 0.0995, 0.5325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,888 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,888 - train - INFO - True
2024-04-07 01:08:35,889 - train - INFO - alphas:tensor([0.4529, 0.0260, 0.0362, 0.0816, 0.4033], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,896 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,896 - train - INFO - True
2024-04-07 01:08:35,897 - train - INFO - alphas:tensor([0.5892, 0.0266, 0.0354, 0.0705, 0.2782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,917 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,917 - train - INFO - True
2024-04-07 01:08:35,918 - train - INFO - alphas:tensor([0.2594, 0.0246, 0.0330, 0.1108, 0.5722], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,928 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,928 - train - INFO - True
2024-04-07 01:08:35,929 - train - INFO - alphas:tensor([0.2748, 0.0207, 0.0292, 0.0982, 0.5771], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,939 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,939 - train - INFO - True
2024-04-07 01:08:35,940 - train - INFO - alphas:tensor([0.3002, 0.0212, 0.0287, 0.0952, 0.5547], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,950 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,950 - train - INFO - True
2024-04-07 01:08:35,951 - train - INFO - alphas:tensor([0.2595, 0.0250, 0.0315, 0.1041, 0.5798], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,961 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,962 - train - INFO - True
2024-04-07 01:08:35,966 - train - INFO - alphas:tensor([0.5912, 0.0214, 0.0268, 0.0614, 0.2992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:35,986 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:35,986 - train - INFO - True
2024-04-07 01:08:35,991 - train - INFO - alphas:tensor([0.4476, 0.0302, 0.0358, 0.0873, 0.3991], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:08:36,069 - train - INFO - tau:0.7323033696543974
2024-04-07 01:08:36,069 - train - INFO - avg block size:9.818181818181818
2024-04-07 01:08:36,069 - train - INFO - current latency ratio:tensor(0.2413)
2024-04-07 01:08:36,279 - train - INFO - Test: [   0/78]  Time: 0.206 (0.206)  Loss:  1.0625 (1.0625)  Acc@1: 78.1250 (78.1250)  Acc@5: 93.7500 (93.7500)
2024-04-07 01:08:40,281 - train - INFO - Test: [  50/78]  Time: 0.072 (0.083)  Loss:  1.8672 (1.7214)  Acc@1: 58.5938 (61.3817)  Acc@5: 82.0312 (84.2065)
2024-04-07 01:08:42,397 - train - INFO - Test: [  78/78]  Time: 0.048 (0.080)  Loss:  1.8975 (1.7534)  Acc@1: 56.2500 (60.9000)  Acc@5: 87.5000 (83.5500)
2024-04-07 01:08:43,131 - train - INFO - Train: 34 [   0/781 (  0%)]  Loss:  3.916925 (3.9169)  Time: 0.653s,  196.06/s  (0.653s,  196.06/s)  LR: 4.405e-04  Data: 0.183 (0.183)
2024-04-07 01:09:06,056 - train - INFO - Train: 34 [  50/781 (  6%)]  Loss:  3.850379 (3.7420)  Time: 0.488s,  262.20/s  (0.462s,  276.89/s)  LR: 4.405e-04  Data: 0.005 (0.011)
2024-04-07 01:09:31,016 - train - INFO - Train: 34 [ 100/781 ( 13%)]  Loss:  3.610638 (3.7591)  Time: 0.459s,  279.13/s  (0.481s,  266.37/s)  LR: 4.405e-04  Data: 0.007 (0.010)
2024-04-07 01:09:55,779 - train - INFO - Train: 34 [ 150/781 ( 19%)]  Loss:  3.494438 (3.7790)  Time: 0.417s,  306.80/s  (0.485s,  263.70/s)  LR: 4.405e-04  Data: 0.006 (0.009)
2024-04-07 01:10:19,626 - train - INFO - Train: 34 [ 200/781 ( 26%)]  Loss:  3.983772 (3.7834)  Time: 0.480s,  266.58/s  (0.483s,  264.85/s)  LR: 4.405e-04  Data: 0.019 (0.009)
2024-04-07 01:10:43,069 - train - INFO - Train: 34 [ 250/781 ( 32%)]  Loss:  3.540997 (3.7908)  Time: 0.396s,  323.51/s  (0.480s,  266.44/s)  LR: 4.405e-04  Data: 0.004 (0.009)
2024-04-07 01:11:07,190 - train - INFO - Train: 34 [ 300/781 ( 38%)]  Loss:  3.677859 (3.8044)  Time: 0.535s,  239.08/s  (0.481s,  266.25/s)  LR: 4.405e-04  Data: 0.014 (0.008)
2024-04-07 01:11:32,094 - train - INFO - Train: 34 [ 350/781 ( 45%)]  Loss:  3.787049 (3.8018)  Time: 0.479s,  267.20/s  (0.483s,  264.90/s)  LR: 4.405e-04  Data: 0.005 (0.008)
2024-04-07 01:11:56,642 - train - INFO - Train: 34 [ 400/781 ( 51%)]  Loss:  4.028940 (3.8057)  Time: 0.406s,  315.44/s  (0.484s,  264.37/s)  LR: 4.405e-04  Data: 0.007 (0.008)
2024-04-07 01:12:21,600 - train - INFO - Train: 34 [ 450/781 ( 58%)]  Loss:  3.674872 (3.8074)  Time: 0.545s,  234.88/s  (0.486s,  263.47/s)  LR: 4.405e-04  Data: 0.008 (0.008)
2024-04-07 01:12:45,084 - train - INFO - Train: 34 [ 500/781 ( 64%)]  Loss:  3.937003 (3.8064)  Time: 0.485s,  263.74/s  (0.484s,  264.35/s)  LR: 4.405e-04  Data: 0.009 (0.008)
2024-04-07 01:13:09,139 - train - INFO - Train: 34 [ 550/781 ( 71%)]  Loss:  3.329399 (3.8059)  Time: 0.501s,  255.67/s  (0.484s,  264.50/s)  LR: 4.405e-04  Data: 0.008 (0.008)
2024-04-07 01:13:33,649 - train - INFO - Train: 34 [ 600/781 ( 77%)]  Loss:  3.550879 (3.8033)  Time: 0.572s,  223.75/s  (0.484s,  264.22/s)  LR: 4.405e-04  Data: 0.010 (0.008)
2024-04-07 01:13:58,669 - train - INFO - Train: 34 [ 650/781 ( 83%)]  Loss:  3.945180 (3.8029)  Time: 0.491s,  260.48/s  (0.486s,  263.55/s)  LR: 4.405e-04  Data: 0.011 (0.008)
2024-04-07 01:14:22,196 - train - INFO - Train: 34 [ 700/781 ( 90%)]  Loss:  3.705593 (3.8002)  Time: 0.501s,  255.51/s  (0.485s,  264.14/s)  LR: 4.405e-04  Data: 0.006 (0.008)
2024-04-07 01:14:46,807 - train - INFO - Train: 34 [ 750/781 ( 96%)]  Loss:  3.801217 (3.7972)  Time: 0.521s,  245.46/s  (0.485s,  263.87/s)  LR: 4.405e-04  Data: 0.007 (0.008)
2024-04-07 01:15:01,948 - train - INFO - Train: 34 [ 780/781 (100%)]  Loss:  3.555063 (3.7979)  Time: 0.474s,  269.92/s  (0.486s,  263.46/s)  LR: 4.405e-04  Data: 0.000 (0.008)
2024-04-07 01:15:01,948 - train - INFO - True
2024-04-07 01:15:01,950 - train - INFO - alphas:tensor([0.4553, 0.1034, 0.1119, 0.1395, 0.1899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,950 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,951 - train - INFO - True
2024-04-07 01:15:01,952 - train - INFO - alphas:tensor([0.3611, 0.0642, 0.0830, 0.1378, 0.3539], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,952 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,952 - train - INFO - True
2024-04-07 01:15:01,953 - train - INFO - alphas:tensor([0.3749, 0.0877, 0.1443, 0.3931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,954 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,954 - train - INFO - True
2024-04-07 01:15:01,955 - train - INFO - alphas:tensor([0.3178, 0.0750, 0.1202, 0.4870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,955 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,955 - train - INFO - True
2024-04-07 01:15:01,956 - train - INFO - alphas:tensor([0.3221, 0.0673, 0.1282, 0.4824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,957 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,957 - train - INFO - True
2024-04-07 01:15:01,958 - train - INFO - alphas:tensor([0.4008, 0.0803, 0.1193, 0.3996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,958 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,958 - train - INFO - True
2024-04-07 01:15:01,959 - train - INFO - alphas:tensor([0.4522, 0.0626, 0.0714, 0.1167, 0.2971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,960 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,961 - train - INFO - True
2024-04-07 01:15:01,961 - train - INFO - alphas:tensor([0.1713, 0.0336, 0.0350, 0.0972, 0.6629], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,962 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,962 - train - INFO - True
2024-04-07 01:15:01,963 - train - INFO - alphas:tensor([0.1823, 0.0294, 0.0364, 0.0854, 0.6665], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,964 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,964 - train - INFO - True
2024-04-07 01:15:01,965 - train - INFO - alphas:tensor([0.1829, 0.0263, 0.0319, 0.0876, 0.6713], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,966 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,966 - train - INFO - True
2024-04-07 01:15:01,967 - train - INFO - alphas:tensor([0.1704, 0.0293, 0.0338, 0.0939, 0.6725], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,967 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,967 - train - INFO - True
2024-04-07 01:15:01,968 - train - INFO - alphas:tensor([0.4642, 0.0448, 0.0584, 0.1091, 0.3235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,969 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,969 - train - INFO - True
2024-04-07 01:15:01,970 - train - INFO - alphas:tensor([0.5447, 0.0481, 0.0546, 0.0906, 0.2619], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,974 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,974 - train - INFO - True
2024-04-07 01:15:01,975 - train - INFO - alphas:tensor([0.1725, 0.0439, 0.0468, 0.1310, 0.6058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,977 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,977 - train - INFO - True
2024-04-07 01:15:01,978 - train - INFO - alphas:tensor([0.1872, 0.0342, 0.0410, 0.1249, 0.6128], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,980 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,980 - train - INFO - True
2024-04-07 01:15:01,981 - train - INFO - alphas:tensor([0.2047, 0.0320, 0.0415, 0.1139, 0.6080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,983 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,983 - train - INFO - True
2024-04-07 01:15:01,984 - train - INFO - alphas:tensor([0.1769, 0.0393, 0.0449, 0.1160, 0.6229], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,985 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,986 - train - INFO - True
2024-04-07 01:15:01,986 - train - INFO - alphas:tensor([0.2058, 0.0313, 0.0448, 0.1135, 0.6045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,988 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,988 - train - INFO - True
2024-04-07 01:15:01,989 - train - INFO - alphas:tensor([0.1549, 0.0498, 0.0561, 0.1322, 0.6069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,991 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,991 - train - INFO - True
2024-04-07 01:15:01,992 - train - INFO - alphas:tensor([0.5022, 0.0346, 0.0417, 0.0918, 0.3297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:01,996 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:01,996 - train - INFO - True
2024-04-07 01:15:01,997 - train - INFO - alphas:tensor([0.4322, 0.0302, 0.0353, 0.0944, 0.4080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:02,004 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:02,004 - train - INFO - True
2024-04-07 01:15:02,005 - train - INFO - alphas:tensor([0.3105, 0.0273, 0.0398, 0.1009, 0.5215], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:02,009 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:02,009 - train - INFO - True
2024-04-07 01:15:02,010 - train - INFO - alphas:tensor([0.3233, 0.0280, 0.0338, 0.0996, 0.5153], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:02,014 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:02,014 - train - INFO - True
2024-04-07 01:15:02,015 - train - INFO - alphas:tensor([0.3389, 0.0257, 0.0320, 0.0938, 0.5095], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:02,019 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:02,019 - train - INFO - True
2024-04-07 01:15:02,020 - train - INFO - alphas:tensor([0.3036, 0.0261, 0.0373, 0.0987, 0.5343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:02,024 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:02,024 - train - INFO - True
2024-04-07 01:15:02,025 - train - INFO - alphas:tensor([0.4514, 0.0254, 0.0358, 0.0793, 0.4082], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:02,032 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:02,032 - train - INFO - True
2024-04-07 01:15:02,033 - train - INFO - alphas:tensor([0.5938, 0.0257, 0.0342, 0.0695, 0.2767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:02,052 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:02,052 - train - INFO - True
2024-04-07 01:15:02,053 - train - INFO - alphas:tensor([0.2643, 0.0238, 0.0327, 0.1107, 0.5685], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:02,064 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:02,064 - train - INFO - True
2024-04-07 01:15:02,065 - train - INFO - alphas:tensor([0.2748, 0.0202, 0.0284, 0.0985, 0.5781], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:02,075 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:02,075 - train - INFO - True
2024-04-07 01:15:02,076 - train - INFO - alphas:tensor([0.3027, 0.0207, 0.0277, 0.0921, 0.5569], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:02,086 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:02,086 - train - INFO - True
2024-04-07 01:15:02,087 - train - INFO - alphas:tensor([0.2604, 0.0244, 0.0306, 0.1037, 0.5808], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:02,097 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:02,097 - train - INFO - True
2024-04-07 01:15:02,098 - train - INFO - alphas:tensor([0.5923, 0.0205, 0.0261, 0.0602, 0.3008], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:02,117 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:02,118 - train - INFO - True
2024-04-07 01:15:02,119 - train - INFO - alphas:tensor([0.4523, 0.0292, 0.0352, 0.0878, 0.3955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:15:02,196 - train - INFO - tau:0.7249803359578534
2024-04-07 01:15:02,196 - train - INFO - avg block size:9.818181818181818
2024-04-07 01:15:02,197 - train - INFO - current latency ratio:tensor(0.2413)
2024-04-07 01:15:02,197 - train - INFO - lasso_alpha:2.6620000000000013e-05
2024-04-07 01:15:02,424 - train - INFO - Test: [   0/78]  Time: 0.224 (0.224)  Loss:  1.0146 (1.0146)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.1875 (92.1875)
2024-04-07 01:15:06,287 - train - INFO - Test: [  50/78]  Time: 0.086 (0.080)  Loss:  1.9131 (1.7294)  Acc@1: 57.0312 (61.3205)  Acc@5: 80.4688 (83.7776)
2024-04-07 01:15:08,483 - train - INFO - Test: [  78/78]  Time: 0.125 (0.080)  Loss:  2.1348 (1.7521)  Acc@1: 43.7500 (60.9700)  Acc@5: 81.2500 (83.2400)
2024-04-07 01:15:09,138 - train - INFO - Train: 35 [   0/781 (  0%)]  Loss:  4.160993 (4.1610)  Time: 0.575s,  222.77/s  (0.575s,  222.77/s)  LR: 4.371e-04  Data: 0.174 (0.174)
2024-04-07 01:15:34,192 - train - INFO - Train: 35 [  50/781 (  6%)]  Loss:  4.064089 (3.7620)  Time: 0.492s,  260.03/s  (0.502s,  254.73/s)  LR: 4.371e-04  Data: 0.009 (0.011)
2024-04-07 01:15:59,087 - train - INFO - Train: 35 [ 100/781 ( 13%)]  Loss:  3.661772 (3.7798)  Time: 0.546s,  234.36/s  (0.500s,  255.89/s)  LR: 4.371e-04  Data: 0.008 (0.009)
2024-04-07 01:16:24,019 - train - INFO - Train: 35 [ 150/781 ( 19%)]  Loss:  3.723866 (3.7609)  Time: 0.366s,  349.66/s  (0.500s,  256.16/s)  LR: 4.371e-04  Data: 0.004 (0.009)
2024-04-07 01:16:48,532 - train - INFO - Train: 35 [ 200/781 ( 26%)]  Loss:  3.921525 (3.7748)  Time: 0.544s,  235.12/s  (0.497s,  257.38/s)  LR: 4.371e-04  Data: 0.005 (0.008)
2024-04-07 01:17:12,325 - train - INFO - Train: 35 [ 250/781 ( 32%)]  Loss:  3.834951 (3.7800)  Time: 0.449s,  284.85/s  (0.493s,  259.61/s)  LR: 4.371e-04  Data: 0.005 (0.008)
2024-04-07 01:17:36,764 - train - INFO - Train: 35 [ 300/781 ( 38%)]  Loss:  4.313019 (3.7768)  Time: 0.456s,  280.78/s  (0.492s,  259.99/s)  LR: 4.371e-04  Data: 0.005 (0.008)
2024-04-07 01:18:01,397 - train - INFO - Train: 35 [ 350/781 ( 45%)]  Loss:  3.559112 (3.7799)  Time: 0.485s,  263.70/s  (0.492s,  259.97/s)  LR: 4.371e-04  Data: 0.005 (0.008)
2024-04-07 01:18:26,573 - train - INFO - Train: 35 [ 400/781 ( 51%)]  Loss:  3.733418 (3.7802)  Time: 0.492s,  259.95/s  (0.494s,  259.24/s)  LR: 4.371e-04  Data: 0.006 (0.008)
2024-04-07 01:18:51,600 - train - INFO - Train: 35 [ 450/781 ( 58%)]  Loss:  3.781557 (3.7810)  Time: 0.536s,  238.91/s  (0.495s,  258.84/s)  LR: 4.371e-04  Data: 0.006 (0.008)
2024-04-07 01:19:15,423 - train - INFO - Train: 35 [ 500/781 ( 64%)]  Loss:  3.524728 (3.7782)  Time: 0.391s,  327.53/s  (0.493s,  259.79/s)  LR: 4.371e-04  Data: 0.010 (0.008)
2024-04-07 01:19:38,792 - train - INFO - Train: 35 [ 550/781 ( 71%)]  Loss:  3.713366 (3.7810)  Time: 0.529s,  242.17/s  (0.490s,  261.01/s)  LR: 4.371e-04  Data: 0.008 (0.008)
2024-04-07 01:20:03,123 - train - INFO - Train: 35 [ 600/781 ( 77%)]  Loss:  3.981586 (3.7837)  Time: 0.393s,  325.90/s  (0.490s,  261.18/s)  LR: 4.371e-04  Data: 0.005 (0.008)
2024-04-07 01:20:27,401 - train - INFO - Train: 35 [ 650/781 ( 83%)]  Loss:  4.057607 (3.7827)  Time: 0.490s,  261.12/s  (0.490s,  261.37/s)  LR: 4.371e-04  Data: 0.006 (0.008)
2024-04-07 01:20:52,561 - train - INFO - Train: 35 [ 700/781 ( 90%)]  Loss:  3.679389 (3.7813)  Time: 0.462s,  277.07/s  (0.491s,  260.86/s)  LR: 4.371e-04  Data: 0.007 (0.008)
2024-04-07 01:21:16,790 - train - INFO - Train: 35 [ 750/781 ( 96%)]  Loss:  3.270922 (3.7806)  Time: 0.492s,  260.27/s  (0.490s,  261.07/s)  LR: 4.371e-04  Data: 0.008 (0.008)
2024-04-07 01:21:31,629 - train - INFO - Train: 35 [ 780/781 (100%)]  Loss:  3.814733 (3.7786)  Time: 0.485s,  263.92/s  (0.490s,  260.99/s)  LR: 4.371e-04  Data: 0.000 (0.008)
2024-04-07 01:21:31,630 - train - INFO - True
2024-04-07 01:21:31,634 - train - INFO - alphas:tensor([0.4610, 0.1013, 0.1110, 0.1376, 0.1891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,641 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,642 - train - INFO - True
2024-04-07 01:21:31,643 - train - INFO - alphas:tensor([0.3630, 0.0625, 0.0821, 0.1364, 0.3560], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,644 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,644 - train - INFO - True
2024-04-07 01:21:31,645 - train - INFO - alphas:tensor([0.3833, 0.0846, 0.1407, 0.3913], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,646 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,646 - train - INFO - True
2024-04-07 01:21:31,647 - train - INFO - alphas:tensor([0.3226, 0.0727, 0.1182, 0.4866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,648 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,648 - train - INFO - True
2024-04-07 01:21:31,650 - train - INFO - alphas:tensor([0.3286, 0.0651, 0.1241, 0.4821], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,650 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,650 - train - INFO - True
2024-04-07 01:21:31,652 - train - INFO - alphas:tensor([0.4068, 0.0783, 0.1170, 0.3979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,653 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,653 - train - INFO - True
2024-04-07 01:21:31,654 - train - INFO - alphas:tensor([0.4568, 0.0613, 0.0703, 0.1153, 0.2962], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,656 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,656 - train - INFO - True
2024-04-07 01:21:31,657 - train - INFO - alphas:tensor([0.1779, 0.0325, 0.0342, 0.0960, 0.6593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,658 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,658 - train - INFO - True
2024-04-07 01:21:31,659 - train - INFO - alphas:tensor([0.1902, 0.0292, 0.0354, 0.0844, 0.6607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,660 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,660 - train - INFO - True
2024-04-07 01:21:31,662 - train - INFO - alphas:tensor([0.1883, 0.0261, 0.0314, 0.0873, 0.6668], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,663 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,663 - train - INFO - True
2024-04-07 01:21:31,664 - train - INFO - alphas:tensor([0.1759, 0.0292, 0.0332, 0.0922, 0.6695], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,665 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,665 - train - INFO - True
2024-04-07 01:21:31,666 - train - INFO - alphas:tensor([0.4654, 0.0435, 0.0575, 0.1078, 0.3258], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,668 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,668 - train - INFO - True
2024-04-07 01:21:31,669 - train - INFO - alphas:tensor([0.5491, 0.0463, 0.0532, 0.0886, 0.2629], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,673 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,673 - train - INFO - True
2024-04-07 01:21:31,675 - train - INFO - alphas:tensor([0.1760, 0.0437, 0.0461, 0.1315, 0.6027], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,677 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,677 - train - INFO - True
2024-04-07 01:21:31,678 - train - INFO - alphas:tensor([0.1907, 0.0340, 0.0410, 0.1243, 0.6101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,681 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,681 - train - INFO - True
2024-04-07 01:21:31,682 - train - INFO - alphas:tensor([0.2133, 0.0312, 0.0415, 0.1147, 0.5993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,684 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,684 - train - INFO - True
2024-04-07 01:21:31,685 - train - INFO - alphas:tensor([0.1852, 0.0392, 0.0443, 0.1160, 0.6153], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,688 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,688 - train - INFO - True
2024-04-07 01:21:31,689 - train - INFO - alphas:tensor([0.2093, 0.0303, 0.0440, 0.1125, 0.6039], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,691 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,691 - train - INFO - True
2024-04-07 01:21:31,692 - train - INFO - alphas:tensor([0.1590, 0.0499, 0.0562, 0.1329, 0.6019], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,694 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,695 - train - INFO - True
2024-04-07 01:21:31,696 - train - INFO - alphas:tensor([0.5064, 0.0334, 0.0412, 0.0905, 0.3285], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,700 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,700 - train - INFO - True
2024-04-07 01:21:31,701 - train - INFO - alphas:tensor([0.4379, 0.0292, 0.0341, 0.0911, 0.4077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,709 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,709 - train - INFO - True
2024-04-07 01:21:31,710 - train - INFO - alphas:tensor([0.3128, 0.0267, 0.0394, 0.1004, 0.5207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,714 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,714 - train - INFO - True
2024-04-07 01:21:31,715 - train - INFO - alphas:tensor([0.3294, 0.0271, 0.0332, 0.0995, 0.5108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,719 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,719 - train - INFO - True
2024-04-07 01:21:31,720 - train - INFO - alphas:tensor([0.3422, 0.0244, 0.0306, 0.0931, 0.5097], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,724 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,724 - train - INFO - True
2024-04-07 01:21:31,725 - train - INFO - alphas:tensor([0.3130, 0.0256, 0.0363, 0.0963, 0.5289], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,729 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,729 - train - INFO - True
2024-04-07 01:21:31,730 - train - INFO - alphas:tensor([0.4597, 0.0246, 0.0340, 0.0774, 0.4043], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,737 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,737 - train - INFO - True
2024-04-07 01:21:31,738 - train - INFO - alphas:tensor([0.5982, 0.0244, 0.0328, 0.0680, 0.2766], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,756 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,756 - train - INFO - True
2024-04-07 01:21:31,757 - train - INFO - alphas:tensor([0.2664, 0.0233, 0.0318, 0.1096, 0.5689], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,765 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,766 - train - INFO - True
2024-04-07 01:21:31,766 - train - INFO - alphas:tensor([0.2827, 0.0202, 0.0285, 0.0999, 0.5687], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,775 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,775 - train - INFO - True
2024-04-07 01:21:31,776 - train - INFO - alphas:tensor([0.3068, 0.0200, 0.0268, 0.0917, 0.5546], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,784 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,784 - train - INFO - True
2024-04-07 01:21:31,785 - train - INFO - alphas:tensor([0.2700, 0.0237, 0.0297, 0.1014, 0.5751], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,793 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,793 - train - INFO - True
2024-04-07 01:21:31,794 - train - INFO - alphas:tensor([0.6040, 0.0196, 0.0247, 0.0581, 0.2935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,808 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,808 - train - INFO - True
2024-04-07 01:21:31,811 - train - INFO - alphas:tensor([0.4555, 0.0287, 0.0347, 0.0875, 0.3936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:31,868 - train - INFO - tau:0.7177305325982748
2024-04-07 01:21:31,868 - train - INFO - avg block size:9.818181818181818
2024-04-07 01:21:31,869 - train - INFO - current latency ratio:tensor(0.2413)
2024-04-07 01:21:32,059 - train - INFO - Test: [   0/78]  Time: 0.187 (0.187)  Loss:  1.1455 (1.1455)  Acc@1: 78.9062 (78.9062)  Acc@5: 93.7500 (93.7500)
2024-04-07 01:21:35,916 - train - INFO - Test: [  50/78]  Time: 0.075 (0.079)  Loss:  1.6982 (1.7310)  Acc@1: 60.1562 (60.9375)  Acc@5: 83.5938 (83.5631)
2024-04-07 01:21:38,288 - train - INFO - Test: [  78/78]  Time: 0.072 (0.081)  Loss:  1.5215 (1.7253)  Acc@1: 62.5000 (61.3200)  Acc@5: 100.0000 (83.4000)
2024-04-07 01:21:39,098 - train - INFO - Train: 36 [   0/781 (  0%)]  Loss:  3.850879 (3.8509)  Time: 0.694s,  184.49/s  (0.694s,  184.49/s)  LR: 4.336e-04  Data: 0.196 (0.196)
2024-04-07 01:22:03,835 - train - INFO - Train: 36 [  50/781 (  6%)]  Loss:  3.534148 (3.7808)  Time: 0.496s,  258.04/s  (0.499s,  256.71/s)  LR: 4.336e-04  Data: 0.008 (0.012)
2024-04-07 01:22:27,731 - train - INFO - Train: 36 [ 100/781 ( 13%)]  Loss:  3.481441 (3.7703)  Time: 0.477s,  268.09/s  (0.488s,  262.11/s)  LR: 4.336e-04  Data: 0.006 (0.010)
2024-04-07 01:22:51,752 - train - INFO - Train: 36 [ 150/781 ( 19%)]  Loss:  3.512704 (3.7759)  Time: 0.513s,  249.66/s  (0.486s,  263.53/s)  LR: 4.336e-04  Data: 0.005 (0.009)
2024-04-07 01:23:15,196 - train - INFO - Train: 36 [ 200/781 ( 26%)]  Loss:  4.002570 (3.7773)  Time: 0.441s,  290.57/s  (0.482s,  265.83/s)  LR: 4.336e-04  Data: 0.005 (0.008)
2024-04-07 01:23:39,511 - train - INFO - Train: 36 [ 250/781 ( 32%)]  Loss:  3.539717 (3.7895)  Time: 0.484s,  264.33/s  (0.482s,  265.30/s)  LR: 4.336e-04  Data: 0.006 (0.008)
2024-04-07 01:24:03,272 - train - INFO - Train: 36 [ 300/781 ( 38%)]  Loss:  3.943161 (3.7960)  Time: 0.435s,  293.99/s  (0.481s,  265.97/s)  LR: 4.336e-04  Data: 0.005 (0.008)
2024-04-07 01:24:26,508 - train - INFO - Train: 36 [ 350/781 ( 45%)]  Loss:  3.588262 (3.7933)  Time: 0.514s,  248.89/s  (0.479s,  267.28/s)  LR: 4.336e-04  Data: 0.005 (0.008)
2024-04-07 01:24:50,202 - train - INFO - Train: 36 [ 400/781 ( 51%)]  Loss:  3.601351 (3.7854)  Time: 0.617s,  207.62/s  (0.478s,  267.63/s)  LR: 4.336e-04  Data: 0.009 (0.008)
2024-04-07 01:25:14,394 - train - INFO - Train: 36 [ 450/781 ( 58%)]  Loss:  3.875537 (3.7822)  Time: 0.494s,  259.10/s  (0.479s,  267.29/s)  LR: 4.336e-04  Data: 0.009 (0.008)
2024-04-07 01:25:39,447 - train - INFO - Train: 36 [ 500/781 ( 64%)]  Loss:  3.716506 (3.7819)  Time: 0.567s,  225.65/s  (0.481s,  266.06/s)  LR: 4.336e-04  Data: 0.010 (0.008)
2024-04-07 01:26:04,270 - train - INFO - Train: 36 [ 550/781 ( 71%)]  Loss:  3.802502 (3.7876)  Time: 0.410s,  312.03/s  (0.482s,  265.29/s)  LR: 4.336e-04  Data: 0.009 (0.008)
2024-04-07 01:26:27,795 - train - INFO - Train: 36 [ 600/781 ( 77%)]  Loss:  3.800381 (3.7857)  Time: 0.384s,  333.26/s  (0.481s,  265.84/s)  LR: 4.336e-04  Data: 0.009 (0.008)
2024-04-07 01:26:52,377 - train - INFO - Train: 36 [ 650/781 ( 83%)]  Loss:  3.766051 (3.7887)  Time: 0.528s,  242.22/s  (0.482s,  265.42/s)  LR: 4.336e-04  Data: 0.009 (0.008)
2024-04-07 01:27:20,282 - train - INFO - Train: 36 [ 700/781 ( 90%)]  Loss:  3.669001 (3.7894)  Time: 0.445s,  287.41/s  (0.488s,  262.47/s)  LR: 4.336e-04  Data: 0.009 (0.008)
2024-04-07 01:27:49,481 - train - INFO - Train: 36 [ 750/781 ( 96%)]  Loss:  3.872562 (3.7863)  Time: 0.532s,  240.59/s  (0.494s,  259.07/s)  LR: 4.336e-04  Data: 0.015 (0.008)
2024-04-07 01:28:07,795 - train - INFO - Train: 36 [ 780/781 (100%)]  Loss:  3.546198 (3.7852)  Time: 0.511s,  250.56/s  (0.499s,  256.75/s)  LR: 4.336e-04  Data: 0.000 (0.008)
2024-04-07 01:28:07,796 - train - INFO - True
2024-04-07 01:28:07,797 - train - INFO - alphas:tensor([0.4648, 0.0993, 0.1097, 0.1365, 0.1897], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,798 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,798 - train - INFO - True
2024-04-07 01:28:07,799 - train - INFO - alphas:tensor([0.3682, 0.0601, 0.0795, 0.1338, 0.3585], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,800 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,800 - train - INFO - True
2024-04-07 01:28:07,801 - train - INFO - alphas:tensor([0.3846, 0.0829, 0.1390, 0.3936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,801 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,801 - train - INFO - True
2024-04-07 01:28:07,802 - train - INFO - alphas:tensor([0.3271, 0.0709, 0.1158, 0.4862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,803 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,803 - train - INFO - True
2024-04-07 01:28:07,804 - train - INFO - alphas:tensor([0.3296, 0.0641, 0.1228, 0.4835], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,805 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,805 - train - INFO - True
2024-04-07 01:28:07,806 - train - INFO - alphas:tensor([0.4112, 0.0762, 0.1147, 0.3980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,807 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,807 - train - INFO - True
2024-04-07 01:28:07,808 - train - INFO - alphas:tensor([0.4571, 0.0599, 0.0685, 0.1136, 0.3009], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,809 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,809 - train - INFO - True
2024-04-07 01:28:07,811 - train - INFO - alphas:tensor([0.1808, 0.0315, 0.0332, 0.0952, 0.6593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,812 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,812 - train - INFO - True
2024-04-07 01:28:07,813 - train - INFO - alphas:tensor([0.1892, 0.0281, 0.0345, 0.0838, 0.6644], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,813 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,814 - train - INFO - True
2024-04-07 01:28:07,815 - train - INFO - alphas:tensor([0.1899, 0.0254, 0.0307, 0.0846, 0.6694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,815 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,815 - train - INFO - True
2024-04-07 01:28:07,816 - train - INFO - alphas:tensor([0.1767, 0.0285, 0.0322, 0.0913, 0.6714], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,817 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,817 - train - INFO - True
2024-04-07 01:28:07,818 - train - INFO - alphas:tensor([0.4657, 0.0424, 0.0558, 0.1060, 0.3301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,819 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,819 - train - INFO - True
2024-04-07 01:28:07,820 - train - INFO - alphas:tensor([0.5489, 0.0447, 0.0518, 0.0880, 0.2666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,824 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,824 - train - INFO - True
2024-04-07 01:28:07,825 - train - INFO - alphas:tensor([0.1805, 0.0443, 0.0442, 0.1314, 0.5995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,827 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,827 - train - INFO - True
2024-04-07 01:28:07,828 - train - INFO - alphas:tensor([0.1945, 0.0333, 0.0403, 0.1211, 0.6108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,830 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,830 - train - INFO - True
2024-04-07 01:28:07,831 - train - INFO - alphas:tensor([0.2116, 0.0299, 0.0397, 0.1137, 0.6051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,833 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,833 - train - INFO - True
2024-04-07 01:28:07,834 - train - INFO - alphas:tensor([0.1845, 0.0381, 0.0442, 0.1160, 0.6172], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,836 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,836 - train - INFO - True
2024-04-07 01:28:07,837 - train - INFO - alphas:tensor([0.2133, 0.0297, 0.0433, 0.1116, 0.6021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,839 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,839 - train - INFO - True
2024-04-07 01:28:07,840 - train - INFO - alphas:tensor([0.1591, 0.0490, 0.0557, 0.1311, 0.6051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,841 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,842 - train - INFO - True
2024-04-07 01:28:07,849 - train - INFO - alphas:tensor([0.5074, 0.0318, 0.0398, 0.0900, 0.3310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,853 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,853 - train - INFO - True
2024-04-07 01:28:07,860 - train - INFO - alphas:tensor([0.4381, 0.0282, 0.0330, 0.0908, 0.4099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,868 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,868 - train - INFO - True
2024-04-07 01:28:07,869 - train - INFO - alphas:tensor([0.3146, 0.0267, 0.0388, 0.0990, 0.5209], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,872 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,873 - train - INFO - True
2024-04-07 01:28:07,873 - train - INFO - alphas:tensor([0.3313, 0.0264, 0.0322, 0.0985, 0.5117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,877 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,877 - train - INFO - True
2024-04-07 01:28:07,878 - train - INFO - alphas:tensor([0.3452, 0.0240, 0.0292, 0.0923, 0.5093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,882 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,882 - train - INFO - True
2024-04-07 01:28:07,883 - train - INFO - alphas:tensor([0.3143, 0.0248, 0.0355, 0.0949, 0.5305], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,887 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,887 - train - INFO - True
2024-04-07 01:28:07,888 - train - INFO - alphas:tensor([0.4666, 0.0237, 0.0329, 0.0753, 0.4014], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,895 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,896 - train - INFO - True
2024-04-07 01:28:07,897 - train - INFO - alphas:tensor([0.5988, 0.0239, 0.0320, 0.0664, 0.2789], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,916 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,916 - train - INFO - True
2024-04-07 01:28:07,917 - train - INFO - alphas:tensor([0.2703, 0.0228, 0.0310, 0.1099, 0.5659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,927 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,927 - train - INFO - True
2024-04-07 01:28:07,928 - train - INFO - alphas:tensor([0.2816, 0.0192, 0.0278, 0.0995, 0.5719], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,938 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,938 - train - INFO - True
2024-04-07 01:28:07,939 - train - INFO - alphas:tensor([0.3090, 0.0196, 0.0265, 0.0918, 0.5532], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,949 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,949 - train - INFO - True
2024-04-07 01:28:07,950 - train - INFO - alphas:tensor([0.2723, 0.0232, 0.0292, 0.1014, 0.5738], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,960 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,961 - train - INFO - True
2024-04-07 01:28:07,962 - train - INFO - alphas:tensor([0.6038, 0.0185, 0.0240, 0.0579, 0.2958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:07,981 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:07,981 - train - INFO - True
2024-04-07 01:28:07,982 - train - INFO - alphas:tensor([0.4572, 0.0283, 0.0341, 0.0859, 0.3945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:28:08,060 - train - INFO - tau:0.7105532272722921
2024-04-07 01:28:08,060 - train - INFO - avg block size:9.818181818181818
2024-04-07 01:28:08,060 - train - INFO - current latency ratio:tensor(0.2413)
2024-04-07 01:28:08,060 - train - INFO - lasso_alpha:2.420000000000001e-05
2024-04-07 01:28:08,274 - train - INFO - Test: [   0/78]  Time: 0.210 (0.210)  Loss:  1.1748 (1.1748)  Acc@1: 73.4375 (73.4375)  Acc@5: 90.6250 (90.6250)
2024-04-07 01:28:13,825 - train - INFO - Test: [  50/78]  Time: 0.075 (0.113)  Loss:  1.8926 (1.7072)  Acc@1: 51.5625 (60.8456)  Acc@5: 79.6875 (83.6550)
2024-04-07 01:28:16,843 - train - INFO - Test: [  78/78]  Time: 0.073 (0.111)  Loss:  1.7637 (1.7174)  Acc@1: 50.0000 (60.9000)  Acc@5: 93.7500 (83.5000)
2024-04-07 01:28:17,529 - train - INFO - Train: 37 [   0/781 (  0%)]  Loss:  4.082834 (4.0828)  Time: 0.590s,  216.85/s  (0.590s,  216.85/s)  LR: 4.300e-04  Data: 0.134 (0.134)
2024-04-07 01:28:48,530 - train - INFO - Train: 37 [  50/781 (  6%)]  Loss:  4.043447 (3.7763)  Time: 0.464s,  275.79/s  (0.619s,  206.65/s)  LR: 4.300e-04  Data: 0.006 (0.010)
2024-04-07 01:29:18,184 - train - INFO - Train: 37 [ 100/781 ( 13%)]  Loss:  4.007327 (3.7856)  Time: 0.508s,  251.86/s  (0.606s,  211.10/s)  LR: 4.300e-04  Data: 0.008 (0.009)
2024-04-07 01:29:41,581 - train - INFO - Train: 37 [ 150/781 ( 19%)]  Loss:  3.780458 (3.7721)  Time: 0.441s,  290.16/s  (0.561s,  228.36/s)  LR: 4.300e-04  Data: 0.005 (0.008)
2024-04-07 01:30:05,055 - train - INFO - Train: 37 [ 200/781 ( 26%)]  Loss:  4.121916 (3.7661)  Time: 0.360s,  355.35/s  (0.538s,  237.98/s)  LR: 4.300e-04  Data: 0.005 (0.008)
2024-04-07 01:30:27,503 - train - INFO - Train: 37 [ 250/781 ( 32%)]  Loss:  4.183441 (3.7639)  Time: 0.440s,  291.18/s  (0.520s,  246.09/s)  LR: 4.300e-04  Data: 0.005 (0.008)
2024-04-07 01:30:50,459 - train - INFO - Train: 37 [ 300/781 ( 38%)]  Loss:  3.516578 (3.7603)  Time: 0.432s,  296.01/s  (0.510s,  250.98/s)  LR: 4.300e-04  Data: 0.005 (0.008)
2024-04-07 01:31:13,599 - train - INFO - Train: 37 [ 350/781 ( 45%)]  Loss:  3.753983 (3.7665)  Time: 0.509s,  251.37/s  (0.503s,  254.33/s)  LR: 4.300e-04  Data: 0.013 (0.008)
2024-04-07 01:31:37,315 - train - INFO - Train: 37 [ 400/781 ( 51%)]  Loss:  3.605914 (3.7662)  Time: 0.498s,  256.77/s  (0.500s,  256.17/s)  LR: 4.300e-04  Data: 0.008 (0.008)
2024-04-07 01:32:01,258 - train - INFO - Train: 37 [ 450/781 ( 58%)]  Loss:  3.992243 (3.7764)  Time: 0.496s,  258.20/s  (0.497s,  257.36/s)  LR: 4.300e-04  Data: 0.008 (0.008)
2024-04-07 01:32:25,325 - train - INFO - Train: 37 [ 500/781 ( 64%)]  Loss:  3.982824 (3.7759)  Time: 0.504s,  253.81/s  (0.496s,  258.20/s)  LR: 4.300e-04  Data: 0.009 (0.008)
2024-04-07 01:32:48,971 - train - INFO - Train: 37 [ 550/781 ( 71%)]  Loss:  3.966705 (3.7737)  Time: 0.400s,  320.15/s  (0.494s,  259.28/s)  LR: 4.300e-04  Data: 0.006 (0.008)
2024-04-07 01:33:12,170 - train - INFO - Train: 37 [ 600/781 ( 77%)]  Loss:  3.891204 (3.7766)  Time: 0.499s,  256.31/s  (0.491s,  260.59/s)  LR: 4.300e-04  Data: 0.009 (0.008)
2024-04-07 01:33:35,148 - train - INFO - Train: 37 [ 650/781 ( 83%)]  Loss:  3.254058 (3.7800)  Time: 0.443s,  288.87/s  (0.489s,  261.88/s)  LR: 4.300e-04  Data: 0.005 (0.008)
2024-04-07 01:33:59,132 - train - INFO - Train: 37 [ 700/781 ( 90%)]  Loss:  3.746682 (3.7792)  Time: 0.428s,  299.27/s  (0.488s,  262.23/s)  LR: 4.300e-04  Data: 0.006 (0.008)
2024-04-07 01:34:22,970 - train - INFO - Train: 37 [ 750/781 ( 96%)]  Loss:  4.246098 (3.7784)  Time: 0.487s,  262.73/s  (0.487s,  262.64/s)  LR: 4.300e-04  Data: 0.008 (0.008)
2024-04-07 01:34:36,812 - train - INFO - Train: 37 [ 780/781 (100%)]  Loss:  3.852214 (3.7773)  Time: 0.456s,  280.46/s  (0.486s,  263.18/s)  LR: 4.300e-04  Data: 0.000 (0.008)
2024-04-07 01:34:36,812 - train - INFO - True
2024-04-07 01:34:36,814 - train - INFO - alphas:tensor([0.4710, 0.0976, 0.1073, 0.1349, 0.1893], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,814 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,814 - train - INFO - True
2024-04-07 01:34:36,815 - train - INFO - alphas:tensor([0.3672, 0.0587, 0.0785, 0.1324, 0.3633], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,816 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,816 - train - INFO - True
2024-04-07 01:34:36,817 - train - INFO - alphas:tensor([0.3898, 0.0804, 0.1357, 0.3941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,817 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,817 - train - INFO - True
2024-04-07 01:34:36,818 - train - INFO - alphas:tensor([0.3305, 0.0701, 0.1142, 0.4852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,819 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,819 - train - INFO - True
2024-04-07 01:34:36,820 - train - INFO - alphas:tensor([0.3357, 0.0627, 0.1212, 0.4804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,820 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,821 - train - INFO - True
2024-04-07 01:34:36,821 - train - INFO - alphas:tensor([0.4130, 0.0749, 0.1128, 0.3993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,822 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,822 - train - INFO - True
2024-04-07 01:34:36,823 - train - INFO - alphas:tensor([0.4630, 0.0578, 0.0670, 0.1112, 0.3011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,824 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,824 - train - INFO - True
2024-04-07 01:34:36,825 - train - INFO - alphas:tensor([0.1835, 0.0308, 0.0322, 0.0935, 0.6599], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,826 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,826 - train - INFO - True
2024-04-07 01:34:36,827 - train - INFO - alphas:tensor([0.1939, 0.0278, 0.0341, 0.0829, 0.6614], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,828 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,828 - train - INFO - True
2024-04-07 01:34:36,829 - train - INFO - alphas:tensor([0.1950, 0.0249, 0.0297, 0.0839, 0.6665], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,830 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,830 - train - INFO - True
2024-04-07 01:34:36,831 - train - INFO - alphas:tensor([0.1813, 0.0284, 0.0317, 0.0906, 0.6680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,831 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,831 - train - INFO - True
2024-04-07 01:34:36,832 - train - INFO - alphas:tensor([0.4754, 0.0409, 0.0540, 0.1033, 0.3264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,833 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,833 - train - INFO - True
2024-04-07 01:34:36,834 - train - INFO - alphas:tensor([0.5567, 0.0430, 0.0498, 0.0855, 0.2650], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,838 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,838 - train - INFO - True
2024-04-07 01:34:36,839 - train - INFO - alphas:tensor([0.1811, 0.0432, 0.0439, 0.1299, 0.6018], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,841 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,841 - train - INFO - True
2024-04-07 01:34:36,842 - train - INFO - alphas:tensor([0.2022, 0.0332, 0.0396, 0.1204, 0.6045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,844 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,844 - train - INFO - True
2024-04-07 01:34:36,845 - train - INFO - alphas:tensor([0.2216, 0.0297, 0.0385, 0.1136, 0.5965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,847 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,847 - train - INFO - True
2024-04-07 01:34:36,848 - train - INFO - alphas:tensor([0.1910, 0.0378, 0.0429, 0.1139, 0.6144], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,850 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,850 - train - INFO - True
2024-04-07 01:34:36,851 - train - INFO - alphas:tensor([0.2187, 0.0288, 0.0421, 0.1107, 0.5997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,853 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,853 - train - INFO - True
2024-04-07 01:34:36,854 - train - INFO - alphas:tensor([0.1684, 0.0500, 0.0536, 0.1291, 0.5989], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,855 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,856 - train - INFO - True
2024-04-07 01:34:36,857 - train - INFO - alphas:tensor([0.5112, 0.0307, 0.0384, 0.0889, 0.3309], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,860 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,860 - train - INFO - True
2024-04-07 01:34:36,861 - train - INFO - alphas:tensor([0.4492, 0.0270, 0.0312, 0.0881, 0.4045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,868 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,869 - train - INFO - True
2024-04-07 01:34:36,869 - train - INFO - alphas:tensor([0.3251, 0.0254, 0.0384, 0.0972, 0.5139], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,873 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,873 - train - INFO - True
2024-04-07 01:34:36,874 - train - INFO - alphas:tensor([0.3402, 0.0261, 0.0312, 0.0982, 0.5043], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,878 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,878 - train - INFO - True
2024-04-07 01:34:36,879 - train - INFO - alphas:tensor([0.3540, 0.0235, 0.0285, 0.0908, 0.5033], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,883 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,883 - train - INFO - True
2024-04-07 01:34:36,884 - train - INFO - alphas:tensor([0.3231, 0.0241, 0.0350, 0.0941, 0.5237], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,888 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,888 - train - INFO - True
2024-04-07 01:34:36,889 - train - INFO - alphas:tensor([0.4741, 0.0231, 0.0321, 0.0745, 0.3962], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,896 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,896 - train - INFO - True
2024-04-07 01:34:36,897 - train - INFO - alphas:tensor([0.6097, 0.0230, 0.0308, 0.0645, 0.2719], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,917 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,917 - train - INFO - True
2024-04-07 01:34:36,918 - train - INFO - alphas:tensor([0.2827, 0.0229, 0.0312, 0.1075, 0.5557], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,928 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,928 - train - INFO - True
2024-04-07 01:34:36,929 - train - INFO - alphas:tensor([0.2903, 0.0191, 0.0280, 0.0982, 0.5645], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,939 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,939 - train - INFO - True
2024-04-07 01:34:36,940 - train - INFO - alphas:tensor([0.3180, 0.0188, 0.0257, 0.0922, 0.5454], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,950 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,950 - train - INFO - True
2024-04-07 01:34:36,951 - train - INFO - alphas:tensor([0.2823, 0.0227, 0.0291, 0.1029, 0.5629], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,961 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,961 - train - INFO - True
2024-04-07 01:34:36,962 - train - INFO - alphas:tensor([0.6158, 0.0176, 0.0229, 0.0547, 0.2891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:36,983 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:36,983 - train - INFO - True
2024-04-07 01:34:36,984 - train - INFO - alphas:tensor([0.4622, 0.0277, 0.0334, 0.0848, 0.3919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:37,062 - train - INFO - tau:0.7034476949995692
2024-04-07 01:34:37,062 - train - INFO - avg block size:9.818181818181818
2024-04-07 01:34:37,063 - train - INFO - current latency ratio:tensor(0.2413)
2024-04-07 01:34:37,265 - train - INFO - Test: [   0/78]  Time: 0.199 (0.199)  Loss:  1.0635 (1.0635)  Acc@1: 78.9062 (78.9062)  Acc@5: 90.6250 (90.6250)
2024-04-07 01:34:40,304 - train - INFO - Test: [  50/78]  Time: 0.054 (0.063)  Loss:  1.6787 (1.6942)  Acc@1: 64.0625 (62.3009)  Acc@5: 86.7188 (84.3903)
2024-04-07 01:34:41,813 - train - INFO - Test: [  78/78]  Time: 0.047 (0.060)  Loss:  2.1309 (1.7190)  Acc@1: 50.0000 (61.8400)  Acc@5: 87.5000 (83.9700)
2024-04-07 01:34:42,559 - train - INFO - Train: 38 [   0/781 (  0%)]  Loss:  3.587669 (3.5877)  Time: 0.657s,  194.86/s  (0.657s,  194.86/s)  LR: 4.264e-04  Data: 0.186 (0.186)
2024-04-07 01:35:05,984 - train - INFO - Train: 38 [  50/781 (  6%)]  Loss:  3.639426 (3.7464)  Time: 0.410s,  312.27/s  (0.472s,  271.09/s)  LR: 4.264e-04  Data: 0.006 (0.011)
2024-04-07 01:35:30,211 - train - INFO - Train: 38 [ 100/781 ( 13%)]  Loss:  3.515354 (3.7519)  Time: 0.468s,  273.51/s  (0.478s,  267.63/s)  LR: 4.264e-04  Data: 0.009 (0.009)
2024-04-07 01:35:54,419 - train - INFO - Train: 38 [ 150/781 ( 19%)]  Loss:  3.492759 (3.7649)  Time: 0.507s,  252.30/s  (0.480s,  266.55/s)  LR: 4.264e-04  Data: 0.009 (0.008)
2024-04-07 01:36:18,248 - train - INFO - Train: 38 [ 200/781 ( 26%)]  Loss:  3.843693 (3.7672)  Time: 0.494s,  259.27/s  (0.479s,  267.06/s)  LR: 4.264e-04  Data: 0.005 (0.008)
2024-04-07 01:36:42,985 - train - INFO - Train: 38 [ 250/781 ( 32%)]  Loss:  4.090274 (3.7733)  Time: 0.483s,  264.87/s  (0.482s,  265.36/s)  LR: 4.264e-04  Data: 0.009 (0.008)
2024-04-07 01:37:06,501 - train - INFO - Train: 38 [ 300/781 ( 38%)]  Loss:  4.178655 (3.7875)  Time: 0.463s,  276.56/s  (0.480s,  266.47/s)  LR: 4.264e-04  Data: 0.005 (0.008)
2024-04-07 01:37:29,447 - train - INFO - Train: 38 [ 350/781 ( 45%)]  Loss:  3.686155 (3.7769)  Time: 0.457s,  280.14/s  (0.477s,  268.18/s)  LR: 4.264e-04  Data: 0.005 (0.008)
2024-04-07 01:37:52,945 - train - INFO - Train: 38 [ 400/781 ( 51%)]  Loss:  4.028533 (3.7728)  Time: 0.494s,  259.14/s  (0.476s,  268.70/s)  LR: 4.264e-04  Data: 0.008 (0.008)
2024-04-07 01:38:16,936 - train - INFO - Train: 38 [ 450/781 ( 58%)]  Loss:  4.039783 (3.7742)  Time: 0.501s,  255.69/s  (0.477s,  268.48/s)  LR: 4.264e-04  Data: 0.007 (0.008)
2024-04-07 01:38:39,854 - train - INFO - Train: 38 [ 500/781 ( 64%)]  Loss:  4.018023 (3.7765)  Time: 0.504s,  254.11/s  (0.475s,  269.52/s)  LR: 4.264e-04  Data: 0.008 (0.008)
2024-04-07 01:39:02,947 - train - INFO - Train: 38 [ 550/781 ( 71%)]  Loss:  3.728044 (3.7773)  Time: 0.490s,  261.35/s  (0.474s,  270.20/s)  LR: 4.264e-04  Data: 0.007 (0.008)
2024-04-07 01:39:26,121 - train - INFO - Train: 38 [ 600/781 ( 77%)]  Loss:  4.295501 (3.7764)  Time: 0.489s,  261.87/s  (0.473s,  270.68/s)  LR: 4.264e-04  Data: 0.007 (0.008)
2024-04-07 01:39:49,537 - train - INFO - Train: 38 [ 650/781 ( 83%)]  Loss:  3.357585 (3.7755)  Time: 0.493s,  259.81/s  (0.473s,  270.89/s)  LR: 4.264e-04  Data: 0.006 (0.007)
2024-04-07 01:40:13,204 - train - INFO - Train: 38 [ 700/781 ( 90%)]  Loss:  3.867516 (3.7790)  Time: 0.428s,  298.96/s  (0.473s,  270.85/s)  LR: 4.264e-04  Data: 0.006 (0.008)
2024-04-07 01:40:36,475 - train - INFO - Train: 38 [ 750/781 ( 96%)]  Loss:  3.875447 (3.7783)  Time: 0.485s,  263.96/s  (0.472s,  271.13/s)  LR: 4.264e-04  Data: 0.006 (0.007)
2024-04-07 01:40:50,894 - train - INFO - Train: 38 [ 780/781 (100%)]  Loss:  3.749842 (3.7798)  Time: 0.421s,  303.93/s  (0.472s,  270.94/s)  LR: 4.264e-04  Data: 0.000 (0.007)
2024-04-07 01:40:50,895 - train - INFO - True
2024-04-07 01:40:50,898 - train - INFO - alphas:tensor([0.4741, 0.0964, 0.1064, 0.1337, 0.1894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,899 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,899 - train - INFO - True
2024-04-07 01:40:50,900 - train - INFO - alphas:tensor([0.3737, 0.0571, 0.0765, 0.1303, 0.3623], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,901 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,901 - train - INFO - True
2024-04-07 01:40:50,903 - train - INFO - alphas:tensor([0.3922, 0.0794, 0.1334, 0.3950], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,904 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,904 - train - INFO - True
2024-04-07 01:40:50,905 - train - INFO - alphas:tensor([0.3363, 0.0687, 0.1114, 0.4836], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,906 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,906 - train - INFO - True
2024-04-07 01:40:50,908 - train - INFO - alphas:tensor([0.3385, 0.0606, 0.1192, 0.4817], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,909 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,909 - train - INFO - True
2024-04-07 01:40:50,910 - train - INFO - alphas:tensor([0.4154, 0.0734, 0.1113, 0.3999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,911 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,912 - train - INFO - True
2024-04-07 01:40:50,913 - train - INFO - alphas:tensor([0.4673, 0.0559, 0.0653, 0.1098, 0.3017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,915 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,915 - train - INFO - True
2024-04-07 01:40:50,916 - train - INFO - alphas:tensor([0.1873, 0.0302, 0.0315, 0.0913, 0.6597], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,917 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,917 - train - INFO - True
2024-04-07 01:40:50,919 - train - INFO - alphas:tensor([0.1969, 0.0271, 0.0335, 0.0810, 0.6615], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,920 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,920 - train - INFO - True
2024-04-07 01:40:50,921 - train - INFO - alphas:tensor([0.1980, 0.0240, 0.0292, 0.0832, 0.6655], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,922 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,922 - train - INFO - True
2024-04-07 01:40:50,924 - train - INFO - alphas:tensor([0.1834, 0.0275, 0.0310, 0.0905, 0.6676], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,925 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,925 - train - INFO - True
2024-04-07 01:40:50,926 - train - INFO - alphas:tensor([0.4756, 0.0401, 0.0529, 0.1015, 0.3299], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,928 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,928 - train - INFO - True
2024-04-07 01:40:50,936 - train - INFO - alphas:tensor([0.5627, 0.0412, 0.0475, 0.0833, 0.2653], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,946 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,946 - train - INFO - True
2024-04-07 01:40:50,947 - train - INFO - alphas:tensor([0.1833, 0.0427, 0.0429, 0.1287, 0.6024], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,949 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,949 - train - INFO - True
2024-04-07 01:40:50,950 - train - INFO - alphas:tensor([0.2040, 0.0322, 0.0392, 0.1203, 0.6043], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,952 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,952 - train - INFO - True
2024-04-07 01:40:50,953 - train - INFO - alphas:tensor([0.2238, 0.0293, 0.0381, 0.1127, 0.5962], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,954 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,955 - train - INFO - True
2024-04-07 01:40:50,955 - train - INFO - alphas:tensor([0.1944, 0.0377, 0.0423, 0.1142, 0.6114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,957 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,957 - train - INFO - True
2024-04-07 01:40:50,958 - train - INFO - alphas:tensor([0.2212, 0.0286, 0.0420, 0.1095, 0.5987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,960 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,960 - train - INFO - True
2024-04-07 01:40:50,961 - train - INFO - alphas:tensor([0.1701, 0.0494, 0.0533, 0.1288, 0.5983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,963 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,963 - train - INFO - True
2024-04-07 01:40:50,964 - train - INFO - alphas:tensor([0.5203, 0.0299, 0.0371, 0.0861, 0.3266], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,968 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,968 - train - INFO - True
2024-04-07 01:40:50,969 - train - INFO - alphas:tensor([0.4510, 0.0263, 0.0307, 0.0878, 0.4042], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,976 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,976 - train - INFO - True
2024-04-07 01:40:50,977 - train - INFO - alphas:tensor([0.3256, 0.0244, 0.0375, 0.0974, 0.5151], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,981 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,981 - train - INFO - True
2024-04-07 01:40:50,982 - train - INFO - alphas:tensor([0.3436, 0.0246, 0.0304, 0.0972, 0.5041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,986 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,986 - train - INFO - True
2024-04-07 01:40:50,987 - train - INFO - alphas:tensor([0.3596, 0.0230, 0.0278, 0.0906, 0.4990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,991 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,991 - train - INFO - True
2024-04-07 01:40:50,992 - train - INFO - alphas:tensor([0.3266, 0.0236, 0.0343, 0.0933, 0.5222], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:50,995 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:50,996 - train - INFO - True
2024-04-07 01:40:50,996 - train - INFO - alphas:tensor([0.4787, 0.0220, 0.0309, 0.0722, 0.3962], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:51,004 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:51,004 - train - INFO - True
2024-04-07 01:40:51,005 - train - INFO - alphas:tensor([0.6122, 0.0221, 0.0299, 0.0642, 0.2716], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:51,024 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:51,024 - train - INFO - True
2024-04-07 01:40:51,025 - train - INFO - alphas:tensor([0.2789, 0.0219, 0.0304, 0.1073, 0.5616], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:51,035 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:51,035 - train - INFO - True
2024-04-07 01:40:51,036 - train - INFO - alphas:tensor([0.2921, 0.0183, 0.0270, 0.0977, 0.5648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:51,046 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:51,046 - train - INFO - True
2024-04-07 01:40:51,047 - train - INFO - alphas:tensor([0.3237, 0.0183, 0.0246, 0.0917, 0.5417], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:51,057 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:51,057 - train - INFO - True
2024-04-07 01:40:51,058 - train - INFO - alphas:tensor([0.2788, 0.0219, 0.0279, 0.1013, 0.5700], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:51,068 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:51,069 - train - INFO - True
2024-04-07 01:40:51,069 - train - INFO - alphas:tensor([0.6227, 0.0169, 0.0220, 0.0537, 0.2847], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:51,089 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:51,089 - train - INFO - True
2024-04-07 01:40:51,090 - train - INFO - alphas:tensor([0.4656, 0.0270, 0.0331, 0.0851, 0.3891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:40:51,167 - train - INFO - tau:0.6964132180495735
2024-04-07 01:40:51,167 - train - INFO - avg block size:9.818181818181818
2024-04-07 01:40:51,168 - train - INFO - current latency ratio:tensor(0.2413)
2024-04-07 01:40:51,168 - train - INFO - lasso_alpha:2.2000000000000006e-05
2024-04-07 01:40:51,396 - train - INFO - Test: [   0/78]  Time: 0.225 (0.225)  Loss:  1.0020 (1.0020)  Acc@1: 78.9062 (78.9062)  Acc@5: 91.4062 (91.4062)
2024-04-07 01:40:54,811 - train - INFO - Test: [  50/78]  Time: 0.078 (0.071)  Loss:  1.5117 (1.7276)  Acc@1: 64.8438 (61.3664)  Acc@5: 89.0625 (84.0227)
2024-04-07 01:40:56,618 - train - INFO - Test: [  78/78]  Time: 0.050 (0.069)  Loss:  1.6865 (1.7305)  Acc@1: 62.5000 (61.7100)  Acc@5: 93.7500 (83.8300)
2024-04-07 01:40:57,372 - train - INFO - Train: 39 [   0/781 (  0%)]  Loss:  3.194513 (3.1945)  Time: 0.676s,  189.47/s  (0.676s,  189.47/s)  LR: 4.227e-04  Data: 0.174 (0.174)
2024-04-07 01:41:19,723 - train - INFO - Train: 39 [  50/781 (  6%)]  Loss:  3.675454 (3.7413)  Time: 0.384s,  333.60/s  (0.451s,  283.51/s)  LR: 4.227e-04  Data: 0.004 (0.010)
2024-04-07 01:41:43,133 - train - INFO - Train: 39 [ 100/781 ( 13%)]  Loss:  3.757161 (3.7686)  Time: 0.509s,  251.60/s  (0.460s,  278.42/s)  LR: 4.227e-04  Data: 0.009 (0.009)
2024-04-07 01:42:07,202 - train - INFO - Train: 39 [ 150/781 ( 19%)]  Loss:  3.770625 (3.7702)  Time: 0.470s,  272.26/s  (0.467s,  274.15/s)  LR: 4.227e-04  Data: 0.005 (0.009)
2024-04-07 01:42:29,281 - train - INFO - Train: 39 [ 200/781 ( 26%)]  Loss:  3.780644 (3.7749)  Time: 0.489s,  261.68/s  (0.461s,  277.90/s)  LR: 4.227e-04  Data: 0.006 (0.008)
2024-04-07 01:42:51,668 - train - INFO - Train: 39 [ 250/781 ( 32%)]  Loss:  3.930195 (3.7869)  Time: 0.398s,  321.65/s  (0.458s,  279.46/s)  LR: 4.227e-04  Data: 0.005 (0.008)
2024-04-07 01:43:14,319 - train - INFO - Train: 39 [ 300/781 ( 38%)]  Loss:  3.934075 (3.7871)  Time: 0.456s,  280.96/s  (0.457s,  279.97/s)  LR: 4.227e-04  Data: 0.005 (0.008)
2024-04-07 01:43:38,132 - train - INFO - Train: 39 [ 350/781 ( 45%)]  Loss:  4.062194 (3.7763)  Time: 0.367s,  348.81/s  (0.460s,  278.32/s)  LR: 4.227e-04  Data: 0.009 (0.008)
2024-04-07 01:44:01,984 - train - INFO - Train: 39 [ 400/781 ( 51%)]  Loss:  3.795031 (3.7735)  Time: 0.452s,  283.34/s  (0.462s,  277.04/s)  LR: 4.227e-04  Data: 0.008 (0.008)
2024-04-07 01:44:26,159 - train - INFO - Train: 39 [ 450/781 ( 58%)]  Loss:  3.742292 (3.7710)  Time: 0.547s,  234.12/s  (0.464s,  275.62/s)  LR: 4.227e-04  Data: 0.010 (0.008)
2024-04-07 01:44:49,699 - train - INFO - Train: 39 [ 500/781 ( 64%)]  Loss:  3.760444 (3.7726)  Time: 0.441s,  290.05/s  (0.465s,  275.24/s)  LR: 4.227e-04  Data: 0.005 (0.008)
2024-04-07 01:45:13,556 - train - INFO - Train: 39 [ 550/781 ( 71%)]  Loss:  3.387560 (3.7720)  Time: 0.476s,  268.82/s  (0.466s,  274.60/s)  LR: 4.227e-04  Data: 0.005 (0.008)
2024-04-07 01:45:37,612 - train - INFO - Train: 39 [ 600/781 ( 77%)]  Loss:  3.979346 (3.7686)  Time: 0.497s,  257.80/s  (0.467s,  273.87/s)  LR: 4.227e-04  Data: 0.005 (0.008)
2024-04-07 01:46:01,202 - train - INFO - Train: 39 [ 650/781 ( 83%)]  Loss:  3.961985 (3.7673)  Time: 0.499s,  256.70/s  (0.468s,  273.67/s)  LR: 4.227e-04  Data: 0.007 (0.008)
2024-04-07 01:46:24,797 - train - INFO - Train: 39 [ 700/781 ( 90%)]  Loss:  4.006007 (3.7693)  Time: 0.478s,  267.85/s  (0.468s,  273.50/s)  LR: 4.227e-04  Data: 0.014 (0.008)
2024-04-07 01:46:49,420 - train - INFO - Train: 39 [ 750/781 ( 96%)]  Loss:  3.941683 (3.7708)  Time: 0.497s,  257.56/s  (0.470s,  272.55/s)  LR: 4.227e-04  Data: 0.008 (0.008)
2024-04-07 01:47:04,265 - train - INFO - Train: 39 [ 780/781 (100%)]  Loss:  3.519632 (3.7679)  Time: 0.500s,  256.03/s  (0.471s,  272.00/s)  LR: 4.227e-04  Data: 0.000 (0.008)
2024-04-07 01:47:04,266 - train - INFO - True
2024-04-07 01:47:04,268 - train - INFO - alphas:tensor([0.4810, 0.0938, 0.1046, 0.1319, 0.1886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,269 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,269 - train - INFO - True
2024-04-07 01:47:04,271 - train - INFO - alphas:tensor([0.3752, 0.0557, 0.0751, 0.1289, 0.3651], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,272 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,272 - train - INFO - True
2024-04-07 01:47:04,274 - train - INFO - alphas:tensor([0.3976, 0.0779, 0.1297, 0.3948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,275 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,275 - train - INFO - True
2024-04-07 01:47:04,276 - train - INFO - alphas:tensor([0.3441, 0.0677, 0.1096, 0.4785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,277 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,277 - train - INFO - True
2024-04-07 01:47:04,279 - train - INFO - alphas:tensor([0.3468, 0.0597, 0.1167, 0.4768], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,280 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,280 - train - INFO - True
2024-04-07 01:47:04,292 - train - INFO - alphas:tensor([0.4261, 0.0720, 0.1084, 0.3934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,293 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,303 - train - INFO - True
2024-04-07 01:47:04,304 - train - INFO - alphas:tensor([0.4692, 0.0546, 0.0638, 0.1090, 0.3034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,306 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,306 - train - INFO - True
2024-04-07 01:47:04,307 - train - INFO - alphas:tensor([0.1915, 0.0294, 0.0305, 0.0909, 0.6578], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,308 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,308 - train - INFO - True
2024-04-07 01:47:04,309 - train - INFO - alphas:tensor([0.2033, 0.0269, 0.0328, 0.0806, 0.6564], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,310 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,310 - train - INFO - True
2024-04-07 01:47:04,312 - train - INFO - alphas:tensor([0.2034, 0.0236, 0.0290, 0.0827, 0.6613], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,313 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,313 - train - INFO - True
2024-04-07 01:47:04,314 - train - INFO - alphas:tensor([0.1902, 0.0274, 0.0301, 0.0902, 0.6622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,315 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,315 - train - INFO - True
2024-04-07 01:47:04,316 - train - INFO - alphas:tensor([0.4781, 0.0386, 0.0511, 0.1004, 0.3317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,317 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,318 - train - INFO - True
2024-04-07 01:47:04,319 - train - INFO - alphas:tensor([0.5655, 0.0404, 0.0462, 0.0818, 0.2660], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,323 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,323 - train - INFO - True
2024-04-07 01:47:04,324 - train - INFO - alphas:tensor([0.1889, 0.0421, 0.0433, 0.1285, 0.5972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,327 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,327 - train - INFO - True
2024-04-07 01:47:04,328 - train - INFO - alphas:tensor([0.2097, 0.0319, 0.0390, 0.1189, 0.6005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,330 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,330 - train - INFO - True
2024-04-07 01:47:04,332 - train - INFO - alphas:tensor([0.2305, 0.0287, 0.0375, 0.1102, 0.5932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,334 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,334 - train - INFO - True
2024-04-07 01:47:04,335 - train - INFO - alphas:tensor([0.2022, 0.0373, 0.0412, 0.1124, 0.6069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,337 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,337 - train - INFO - True
2024-04-07 01:47:04,338 - train - INFO - alphas:tensor([0.2310, 0.0280, 0.0408, 0.1094, 0.5909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,341 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,341 - train - INFO - True
2024-04-07 01:47:04,342 - train - INFO - alphas:tensor([0.1737, 0.0483, 0.0525, 0.1274, 0.5981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,344 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,344 - train - INFO - True
2024-04-07 01:47:04,345 - train - INFO - alphas:tensor([0.5257, 0.0290, 0.0365, 0.0857, 0.3232], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,349 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,349 - train - INFO - True
2024-04-07 01:47:04,350 - train - INFO - alphas:tensor([0.4582, 0.0254, 0.0294, 0.0859, 0.4011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,358 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,358 - train - INFO - True
2024-04-07 01:47:04,359 - train - INFO - alphas:tensor([0.3345, 0.0242, 0.0371, 0.0964, 0.5078], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,363 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,363 - train - INFO - True
2024-04-07 01:47:04,364 - train - INFO - alphas:tensor([0.3532, 0.0241, 0.0297, 0.0953, 0.4977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,368 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,368 - train - INFO - True
2024-04-07 01:47:04,369 - train - INFO - alphas:tensor([0.3612, 0.0222, 0.0269, 0.0898, 0.4999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,373 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,373 - train - INFO - True
2024-04-07 01:47:04,374 - train - INFO - alphas:tensor([0.3301, 0.0226, 0.0335, 0.0924, 0.5214], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,378 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,378 - train - INFO - True
2024-04-07 01:47:04,380 - train - INFO - alphas:tensor([0.4824, 0.0212, 0.0301, 0.0719, 0.3944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,387 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,387 - train - INFO - True
2024-04-07 01:47:04,391 - train - INFO - alphas:tensor([0.6203, 0.0211, 0.0286, 0.0623, 0.2677], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,411 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,411 - train - INFO - True
2024-04-07 01:47:04,413 - train - INFO - alphas:tensor([0.2889, 0.0216, 0.0291, 0.1049, 0.5554], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,424 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,424 - train - INFO - True
2024-04-07 01:47:04,425 - train - INFO - alphas:tensor([0.3010, 0.0180, 0.0261, 0.0952, 0.5597], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,435 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,435 - train - INFO - True
2024-04-07 01:47:04,439 - train - INFO - alphas:tensor([0.3273, 0.0181, 0.0241, 0.0909, 0.5397], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,449 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,450 - train - INFO - True
2024-04-07 01:47:04,452 - train - INFO - alphas:tensor([0.2918, 0.0211, 0.0273, 0.1006, 0.5591], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,462 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,463 - train - INFO - True
2024-04-07 01:47:04,464 - train - INFO - alphas:tensor([0.6232, 0.0165, 0.0212, 0.0528, 0.2864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,484 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,484 - train - INFO - True
2024-04-07 01:47:04,485 - train - INFO - alphas:tensor([0.4757, 0.0265, 0.0324, 0.0838, 0.3816], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:47:04,562 - train - INFO - tau:0.6894490858690777
2024-04-07 01:47:04,562 - train - INFO - avg block size:9.606060606060606
2024-04-07 01:47:04,563 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 01:47:04,790 - train - INFO - Test: [   0/78]  Time: 0.224 (0.224)  Loss:  1.2305 (1.2305)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
2024-04-07 01:47:09,454 - train - INFO - Test: [  50/78]  Time: 0.135 (0.096)  Loss:  1.8047 (1.7250)  Acc@1: 58.5938 (61.2132)  Acc@5: 82.8125 (83.8388)
2024-04-07 01:47:12,010 - train - INFO - Test: [  78/78]  Time: 0.142 (0.094)  Loss:  2.1602 (1.7441)  Acc@1: 43.7500 (61.0700)  Acc@5: 87.5000 (83.5700)
2024-04-07 01:47:12,828 - train - INFO - Train: 40 [   0/781 (  0%)]  Loss:  3.520017 (3.5200)  Time: 0.705s,  181.45/s  (0.705s,  181.45/s)  LR: 4.189e-04  Data: 0.157 (0.157)
2024-04-07 01:47:37,726 - train - INFO - Train: 40 [  50/781 (  6%)]  Loss:  4.042662 (3.7451)  Time: 0.488s,  262.46/s  (0.502s,  254.98/s)  LR: 4.189e-04  Data: 0.006 (0.010)
2024-04-07 01:48:01,365 - train - INFO - Train: 40 [ 100/781 ( 13%)]  Loss:  3.886888 (3.7366)  Time: 0.539s,  237.56/s  (0.488s,  262.56/s)  LR: 4.189e-04  Data: 0.006 (0.009)
2024-04-07 01:48:24,634 - train - INFO - Train: 40 [ 150/781 ( 19%)]  Loss:  3.953436 (3.7474)  Time: 0.434s,  294.99/s  (0.480s,  266.57/s)  LR: 4.189e-04  Data: 0.014 (0.008)
2024-04-07 01:48:48,684 - train - INFO - Train: 40 [ 200/781 ( 26%)]  Loss:  3.757119 (3.7552)  Time: 0.518s,  247.08/s  (0.480s,  266.46/s)  LR: 4.189e-04  Data: 0.005 (0.008)
2024-04-07 01:49:12,685 - train - INFO - Train: 40 [ 250/781 ( 32%)]  Loss:  3.426564 (3.7643)  Time: 0.557s,  229.62/s  (0.480s,  266.50/s)  LR: 4.189e-04  Data: 0.010 (0.008)
2024-04-07 01:49:35,067 - train - INFO - Train: 40 [ 300/781 ( 38%)]  Loss:  3.771796 (3.7651)  Time: 0.487s,  262.94/s  (0.475s,  269.55/s)  LR: 4.189e-04  Data: 0.005 (0.008)
2024-04-07 01:49:59,389 - train - INFO - Train: 40 [ 350/781 ( 45%)]  Loss:  3.378093 (3.7678)  Time: 0.396s,  323.07/s  (0.477s,  268.62/s)  LR: 4.189e-04  Data: 0.004 (0.008)
2024-04-07 01:50:23,060 - train - INFO - Train: 40 [ 400/781 ( 51%)]  Loss:  3.981369 (3.7675)  Time: 0.565s,  226.40/s  (0.476s,  268.84/s)  LR: 4.189e-04  Data: 0.012 (0.008)
2024-04-07 01:50:46,428 - train - INFO - Train: 40 [ 450/781 ( 58%)]  Loss:  3.685139 (3.7680)  Time: 0.378s,  338.54/s  (0.475s,  269.39/s)  LR: 4.189e-04  Data: 0.005 (0.008)
2024-04-07 01:51:10,879 - train - INFO - Train: 40 [ 500/781 ( 64%)]  Loss:  3.347074 (3.7718)  Time: 0.365s,  351.10/s  (0.477s,  268.61/s)  LR: 4.189e-04  Data: 0.005 (0.008)
2024-04-07 01:51:34,228 - train - INFO - Train: 40 [ 550/781 ( 71%)]  Loss:  3.448537 (3.7661)  Time: 0.548s,  233.48/s  (0.476s,  269.10/s)  LR: 4.189e-04  Data: 0.008 (0.008)
2024-04-07 01:51:59,239 - train - INFO - Train: 40 [ 600/781 ( 77%)]  Loss:  3.702224 (3.7655)  Time: 0.506s,  252.96/s  (0.478s,  267.95/s)  LR: 4.189e-04  Data: 0.008 (0.008)
2024-04-07 01:52:23,285 - train - INFO - Train: 40 [ 650/781 ( 83%)]  Loss:  3.793748 (3.7639)  Time: 0.512s,  249.88/s  (0.478s,  267.81/s)  LR: 4.189e-04  Data: 0.005 (0.008)
2024-04-07 01:52:47,637 - train - INFO - Train: 40 [ 700/781 ( 90%)]  Loss:  3.862779 (3.7679)  Time: 0.395s,  324.33/s  (0.479s,  267.45/s)  LR: 4.189e-04  Data: 0.004 (0.008)
2024-04-07 01:53:11,799 - train - INFO - Train: 40 [ 750/781 ( 96%)]  Loss:  4.129253 (3.7675)  Time: 0.402s,  318.70/s  (0.479s,  267.28/s)  LR: 4.189e-04  Data: 0.004 (0.008)
2024-04-07 01:53:25,681 - train - INFO - Train: 40 [ 780/781 (100%)]  Loss:  3.888314 (3.7674)  Time: 0.533s,  240.36/s  (0.478s,  267.63/s)  LR: 4.189e-04  Data: 0.000 (0.008)
2024-04-07 01:53:25,682 - train - INFO - True
2024-04-07 01:53:25,687 - train - INFO - alphas:tensor([0.4846, 0.0926, 0.1035, 0.1305, 0.1889], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,687 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,687 - train - INFO - True
2024-04-07 01:53:25,692 - train - INFO - alphas:tensor([0.3788, 0.0543, 0.0745, 0.1265, 0.3659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,693 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,693 - train - INFO - True
2024-04-07 01:53:25,694 - train - INFO - alphas:tensor([0.4006, 0.0757, 0.1294, 0.3944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,695 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,695 - train - INFO - True
2024-04-07 01:53:25,699 - train - INFO - alphas:tensor([0.3505, 0.0657, 0.1074, 0.4764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,700 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,700 - train - INFO - True
2024-04-07 01:53:25,705 - train - INFO - alphas:tensor([0.3468, 0.0582, 0.1158, 0.4792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,705 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,705 - train - INFO - True
2024-04-07 01:53:25,707 - train - INFO - alphas:tensor([0.4258, 0.0705, 0.1069, 0.3967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,707 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,707 - train - INFO - True
2024-04-07 01:53:25,711 - train - INFO - alphas:tensor([0.4745, 0.0533, 0.0624, 0.1067, 0.3031], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,712 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,713 - train - INFO - True
2024-04-07 01:53:25,716 - train - INFO - alphas:tensor([0.1946, 0.0293, 0.0303, 0.0907, 0.6550], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,717 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,717 - train - INFO - True
2024-04-07 01:53:25,718 - train - INFO - alphas:tensor([0.2036, 0.0261, 0.0320, 0.0782, 0.6601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,719 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,719 - train - INFO - True
2024-04-07 01:53:25,720 - train - INFO - alphas:tensor([0.2051, 0.0227, 0.0277, 0.0817, 0.6629], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,721 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,721 - train - INFO - True
2024-04-07 01:53:25,722 - train - INFO - alphas:tensor([0.1921, 0.0260, 0.0293, 0.0886, 0.6640], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,722 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,722 - train - INFO - True
2024-04-07 01:53:25,723 - train - INFO - alphas:tensor([0.4857, 0.0371, 0.0497, 0.0984, 0.3291], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,724 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,724 - train - INFO - True
2024-04-07 01:53:25,725 - train - INFO - alphas:tensor([0.5691, 0.0391, 0.0451, 0.0806, 0.2662], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,729 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,729 - train - INFO - True
2024-04-07 01:53:25,730 - train - INFO - alphas:tensor([0.1946, 0.0418, 0.0418, 0.1267, 0.5951], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,732 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,732 - train - INFO - True
2024-04-07 01:53:25,733 - train - INFO - alphas:tensor([0.2124, 0.0313, 0.0380, 0.1185, 0.5997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,735 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,735 - train - INFO - True
2024-04-07 01:53:25,736 - train - INFO - alphas:tensor([0.2326, 0.0276, 0.0367, 0.1104, 0.5927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,738 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,738 - train - INFO - True
2024-04-07 01:53:25,739 - train - INFO - alphas:tensor([0.2013, 0.0366, 0.0407, 0.1123, 0.6091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,740 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,741 - train - INFO - True
2024-04-07 01:53:25,741 - train - INFO - alphas:tensor([0.2288, 0.0270, 0.0401, 0.1072, 0.5969], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,743 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,743 - train - INFO - True
2024-04-07 01:53:25,744 - train - INFO - alphas:tensor([0.1789, 0.0478, 0.0527, 0.1281, 0.5925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,746 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,746 - train - INFO - True
2024-04-07 01:53:25,747 - train - INFO - alphas:tensor([0.5336, 0.0282, 0.0352, 0.0836, 0.3195], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,751 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,751 - train - INFO - True
2024-04-07 01:53:25,752 - train - INFO - alphas:tensor([0.4592, 0.0250, 0.0292, 0.0854, 0.4013], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,759 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,759 - train - INFO - True
2024-04-07 01:53:25,760 - train - INFO - alphas:tensor([0.3340, 0.0234, 0.0362, 0.0962, 0.5101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,764 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,764 - train - INFO - True
2024-04-07 01:53:25,765 - train - INFO - alphas:tensor([0.3511, 0.0238, 0.0284, 0.0937, 0.5031], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,769 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,769 - train - INFO - True
2024-04-07 01:53:25,770 - train - INFO - alphas:tensor([0.3670, 0.0217, 0.0261, 0.0879, 0.4973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,774 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,774 - train - INFO - True
2024-04-07 01:53:25,775 - train - INFO - alphas:tensor([0.3357, 0.0221, 0.0326, 0.0912, 0.5184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,779 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,779 - train - INFO - True
2024-04-07 01:53:25,780 - train - INFO - alphas:tensor([0.4840, 0.0208, 0.0293, 0.0720, 0.3938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,787 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,787 - train - INFO - True
2024-04-07 01:53:25,788 - train - INFO - alphas:tensor([0.6238, 0.0206, 0.0280, 0.0617, 0.2659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,807 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,808 - train - INFO - True
2024-04-07 01:53:25,809 - train - INFO - alphas:tensor([0.2911, 0.0213, 0.0293, 0.1053, 0.5530], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,819 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,819 - train - INFO - True
2024-04-07 01:53:25,820 - train - INFO - alphas:tensor([0.3018, 0.0173, 0.0253, 0.0975, 0.5582], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,830 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,831 - train - INFO - True
2024-04-07 01:53:25,832 - train - INFO - alphas:tensor([0.3288, 0.0174, 0.0236, 0.0897, 0.5405], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,842 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,842 - train - INFO - True
2024-04-07 01:53:25,844 - train - INFO - alphas:tensor([0.2898, 0.0209, 0.0274, 0.1010, 0.5609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,854 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,854 - train - INFO - True
2024-04-07 01:53:25,856 - train - INFO - alphas:tensor([0.6304, 0.0157, 0.0205, 0.0510, 0.2824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,875 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,875 - train - INFO - True
2024-04-07 01:53:25,879 - train - INFO - alphas:tensor([0.4765, 0.0262, 0.0322, 0.0836, 0.3816], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:53:25,957 - train - INFO - tau:0.682554595010387
2024-04-07 01:53:25,957 - train - INFO - avg block size:9.606060606060606
2024-04-07 01:53:25,957 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 01:53:25,957 - train - INFO - lasso_alpha:2.420000000000001e-05
2024-04-07 01:53:26,202 - train - INFO - Test: [   0/78]  Time: 0.240 (0.240)  Loss:  1.0771 (1.0771)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.1875 (92.1875)
2024-04-07 01:53:30,627 - train - INFO - Test: [  50/78]  Time: 0.058 (0.091)  Loss:  1.6201 (1.7022)  Acc@1: 60.1562 (60.8762)  Acc@5: 88.2812 (84.0380)
2024-04-07 01:53:33,333 - train - INFO - Test: [  78/78]  Time: 0.066 (0.093)  Loss:  1.6006 (1.6959)  Acc@1: 75.0000 (61.2600)  Acc@5: 93.7500 (83.8700)
2024-04-07 01:53:34,014 - train - INFO - Train: 41 [   0/781 (  0%)]  Loss:  3.988166 (3.9882)  Time: 0.600s,  213.42/s  (0.600s,  213.42/s)  LR: 4.151e-04  Data: 0.168 (0.168)
2024-04-07 01:53:58,867 - train - INFO - Train: 41 [  50/781 (  6%)]  Loss:  3.826702 (3.8110)  Time: 0.477s,  268.52/s  (0.499s,  256.49/s)  LR: 4.151e-04  Data: 0.008 (0.011)
2024-04-07 01:54:22,357 - train - INFO - Train: 41 [ 100/781 ( 13%)]  Loss:  3.507630 (3.7860)  Time: 0.466s,  274.77/s  (0.485s,  264.16/s)  LR: 4.151e-04  Data: 0.005 (0.009)
2024-04-07 01:54:46,662 - train - INFO - Train: 41 [ 150/781 ( 19%)]  Loss:  3.980953 (3.7715)  Time: 0.578s,  221.52/s  (0.485s,  263.89/s)  LR: 4.151e-04  Data: 0.009 (0.008)
2024-04-07 01:55:11,956 - train - INFO - Train: 41 [ 200/781 ( 26%)]  Loss:  3.728329 (3.7661)  Time: 0.415s,  308.49/s  (0.490s,  261.10/s)  LR: 4.151e-04  Data: 0.005 (0.008)
2024-04-07 01:55:35,924 - train - INFO - Train: 41 [ 250/781 ( 32%)]  Loss:  3.529744 (3.7659)  Time: 0.485s,  264.01/s  (0.488s,  262.27/s)  LR: 4.151e-04  Data: 0.009 (0.008)
2024-04-07 01:56:00,414 - train - INFO - Train: 41 [ 300/781 ( 38%)]  Loss:  3.860658 (3.7673)  Time: 0.387s,  330.85/s  (0.488s,  262.11/s)  LR: 4.151e-04  Data: 0.004 (0.008)
2024-04-07 01:56:23,450 - train - INFO - Train: 41 [ 350/781 ( 45%)]  Loss:  3.714113 (3.7671)  Time: 0.416s,  307.87/s  (0.484s,  264.24/s)  LR: 4.151e-04  Data: 0.007 (0.008)
2024-04-07 01:56:47,924 - train - INFO - Train: 41 [ 400/781 ( 51%)]  Loss:  3.362710 (3.7664)  Time: 0.414s,  309.13/s  (0.485s,  263.90/s)  LR: 4.151e-04  Data: 0.013 (0.008)
2024-04-07 01:57:12,059 - train - INFO - Train: 41 [ 450/781 ( 58%)]  Loss:  3.995747 (3.7672)  Time: 0.549s,  233.36/s  (0.485s,  264.04/s)  LR: 4.151e-04  Data: 0.009 (0.008)
2024-04-07 01:57:35,964 - train - INFO - Train: 41 [ 500/781 ( 64%)]  Loss:  3.810576 (3.7672)  Time: 0.535s,  239.45/s  (0.484s,  264.41/s)  LR: 4.151e-04  Data: 0.007 (0.008)
2024-04-07 01:58:00,186 - train - INFO - Train: 41 [ 550/781 ( 71%)]  Loss:  3.741226 (3.7669)  Time: 0.439s,  291.46/s  (0.484s,  264.39/s)  LR: 4.151e-04  Data: 0.008 (0.008)
2024-04-07 01:58:23,143 - train - INFO - Train: 41 [ 600/781 ( 77%)]  Loss:  3.853536 (3.7657)  Time: 0.401s,  319.10/s  (0.482s,  265.53/s)  LR: 4.151e-04  Data: 0.009 (0.008)
2024-04-07 01:58:48,143 - train - INFO - Train: 41 [ 650/781 ( 83%)]  Loss:  3.868014 (3.7637)  Time: 0.500s,  256.05/s  (0.483s,  264.78/s)  LR: 4.151e-04  Data: 0.005 (0.008)
2024-04-07 01:59:12,026 - train - INFO - Train: 41 [ 700/781 ( 90%)]  Loss:  3.808810 (3.7660)  Time: 0.513s,  249.31/s  (0.483s,  265.00/s)  LR: 4.151e-04  Data: 0.007 (0.008)
2024-04-07 01:59:36,445 - train - INFO - Train: 41 [ 750/781 ( 96%)]  Loss:  3.945781 (3.7654)  Time: 0.453s,  282.42/s  (0.483s,  264.81/s)  LR: 4.151e-04  Data: 0.007 (0.008)
2024-04-07 01:59:53,512 - train - INFO - Train: 41 [ 780/781 (100%)]  Loss:  3.841884 (3.7641)  Time: 0.498s,  256.92/s  (0.487s,  263.02/s)  LR: 4.151e-04  Data: 0.000 (0.008)
2024-04-07 01:59:53,514 - train - INFO - True
2024-04-07 01:59:53,516 - train - INFO - alphas:tensor([0.4898, 0.0909, 0.1018, 0.1289, 0.1886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,517 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,517 - train - INFO - True
2024-04-07 01:59:53,519 - train - INFO - alphas:tensor([0.3810, 0.0529, 0.0728, 0.1258, 0.3675], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,520 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,520 - train - INFO - True
2024-04-07 01:59:53,522 - train - INFO - alphas:tensor([0.4022, 0.0737, 0.1278, 0.3964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,523 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,523 - train - INFO - True
2024-04-07 01:59:53,525 - train - INFO - alphas:tensor([0.3496, 0.0642, 0.1054, 0.4807], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,526 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,526 - train - INFO - True
2024-04-07 01:59:53,527 - train - INFO - alphas:tensor([0.3497, 0.0571, 0.1142, 0.4790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,528 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,528 - train - INFO - True
2024-04-07 01:59:53,530 - train - INFO - alphas:tensor([0.4288, 0.0688, 0.1054, 0.3970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,531 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,531 - train - INFO - True
2024-04-07 01:59:53,533 - train - INFO - alphas:tensor([0.4735, 0.0521, 0.0608, 0.1061, 0.3074], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,535 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,535 - train - INFO - True
2024-04-07 01:59:53,536 - train - INFO - alphas:tensor([0.1921, 0.0284, 0.0291, 0.0894, 0.6610], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,537 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,538 - train - INFO - True
2024-04-07 01:59:53,539 - train - INFO - alphas:tensor([0.2013, 0.0251, 0.0313, 0.0770, 0.6653], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,540 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,540 - train - INFO - True
2024-04-07 01:59:53,542 - train - INFO - alphas:tensor([0.2007, 0.0222, 0.0276, 0.0811, 0.6684], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,543 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,543 - train - INFO - True
2024-04-07 01:59:53,544 - train - INFO - alphas:tensor([0.1870, 0.0251, 0.0280, 0.0881, 0.6718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,545 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,545 - train - INFO - True
2024-04-07 01:59:53,549 - train - INFO - alphas:tensor([0.4815, 0.0360, 0.0489, 0.0981, 0.3356], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,550 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,551 - train - INFO - True
2024-04-07 01:59:53,562 - train - INFO - alphas:tensor([0.5702, 0.0387, 0.0437, 0.0790, 0.2683], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,575 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,575 - train - INFO - True
2024-04-07 01:59:53,576 - train - INFO - alphas:tensor([0.1939, 0.0410, 0.0413, 0.1276, 0.5961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,579 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,579 - train - INFO - True
2024-04-07 01:59:53,580 - train - INFO - alphas:tensor([0.2092, 0.0307, 0.0376, 0.1188, 0.6037], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,583 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,583 - train - INFO - True
2024-04-07 01:59:53,584 - train - INFO - alphas:tensor([0.2296, 0.0267, 0.0360, 0.1099, 0.5977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,586 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,586 - train - INFO - True
2024-04-07 01:59:53,587 - train - INFO - alphas:tensor([0.1982, 0.0356, 0.0396, 0.1106, 0.6160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,590 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,590 - train - INFO - True
2024-04-07 01:59:53,591 - train - INFO - alphas:tensor([0.2307, 0.0260, 0.0393, 0.1057, 0.5982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,593 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,593 - train - INFO - True
2024-04-07 01:59:53,594 - train - INFO - alphas:tensor([0.1739, 0.0463, 0.0517, 0.1267, 0.6015], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,596 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,597 - train - INFO - True
2024-04-07 01:59:53,598 - train - INFO - alphas:tensor([0.5320, 0.0275, 0.0341, 0.0829, 0.3235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,602 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,602 - train - INFO - True
2024-04-07 01:59:53,603 - train - INFO - alphas:tensor([0.4596, 0.0244, 0.0286, 0.0853, 0.4021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,611 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,611 - train - INFO - True
2024-04-07 01:59:53,612 - train - INFO - alphas:tensor([0.3321, 0.0227, 0.0358, 0.0977, 0.5118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,616 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,616 - train - INFO - True
2024-04-07 01:59:53,617 - train - INFO - alphas:tensor([0.3490, 0.0229, 0.0277, 0.0917, 0.5087], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,621 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,621 - train - INFO - True
2024-04-07 01:59:53,622 - train - INFO - alphas:tensor([0.3699, 0.0210, 0.0256, 0.0872, 0.4963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,626 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,626 - train - INFO - True
2024-04-07 01:59:53,627 - train - INFO - alphas:tensor([0.3270, 0.0211, 0.0317, 0.0921, 0.5282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,631 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,631 - train - INFO - True
2024-04-07 01:59:53,632 - train - INFO - alphas:tensor([0.4843, 0.0200, 0.0289, 0.0711, 0.3956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,639 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,640 - train - INFO - True
2024-04-07 01:59:53,640 - train - INFO - alphas:tensor([0.6229, 0.0197, 0.0269, 0.0608, 0.2697], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,660 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,660 - train - INFO - True
2024-04-07 01:59:53,661 - train - INFO - alphas:tensor([0.2884, 0.0206, 0.0288, 0.1046, 0.5577], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,671 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,671 - train - INFO - True
2024-04-07 01:59:53,672 - train - INFO - alphas:tensor([0.3005, 0.0167, 0.0247, 0.0951, 0.5630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,682 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,682 - train - INFO - True
2024-04-07 01:59:53,683 - train - INFO - alphas:tensor([0.3242, 0.0169, 0.0229, 0.0905, 0.5455], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,693 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,693 - train - INFO - True
2024-04-07 01:59:53,694 - train - INFO - alphas:tensor([0.2863, 0.0203, 0.0265, 0.0986, 0.5682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,704 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,704 - train - INFO - True
2024-04-07 01:59:53,705 - train - INFO - alphas:tensor([0.6251, 0.0153, 0.0203, 0.0517, 0.2876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,725 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,725 - train - INFO - True
2024-04-07 01:59:53,726 - train - INFO - alphas:tensor([0.4702, 0.0254, 0.0321, 0.0825, 0.3898], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:59:53,803 - train - INFO - tau:0.6757290490602831
2024-04-07 01:59:53,803 - train - INFO - avg block size:9.606060606060606
2024-04-07 01:59:53,804 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 01:59:54,015 - train - INFO - Test: [   0/78]  Time: 0.208 (0.208)  Loss:  1.2686 (1.2686)  Acc@1: 74.2188 (74.2188)  Acc@5: 91.4062 (91.4062)
2024-04-07 01:59:59,475 - train - INFO - Test: [  50/78]  Time: 0.054 (0.111)  Loss:  1.8047 (1.7102)  Acc@1: 60.9375 (61.6268)  Acc@5: 82.0312 (83.9308)
2024-04-07 02:00:02,349 - train - INFO - Test: [  78/78]  Time: 0.051 (0.108)  Loss:  2.1621 (1.7109)  Acc@1: 50.0000 (61.5900)  Acc@5: 87.5000 (83.6300)
2024-04-07 02:00:03,082 - train - INFO - Train: 42 [   0/781 (  0%)]  Loss:  3.856163 (3.8562)  Time: 0.653s,  196.04/s  (0.653s,  196.04/s)  LR: 4.112e-04  Data: 0.182 (0.182)
2024-04-07 02:00:33,219 - train - INFO - Train: 42 [  50/781 (  6%)]  Loss:  3.849087 (3.7789)  Time: 0.639s,  200.39/s  (0.604s,  212.03/s)  LR: 4.112e-04  Data: 0.004 (0.010)
2024-04-07 02:01:04,165 - train - INFO - Train: 42 [ 100/781 ( 13%)]  Loss:  3.596863 (3.7484)  Time: 0.747s,  171.43/s  (0.611s,  209.42/s)  LR: 4.112e-04  Data: 0.010 (0.009)
2024-04-07 02:01:35,558 - train - INFO - Train: 42 [ 150/781 ( 19%)]  Loss:  4.010659 (3.7708)  Time: 0.493s,  259.72/s  (0.617s,  207.55/s)  LR: 4.112e-04  Data: 0.007 (0.008)
2024-04-07 02:02:01,761 - train - INFO - Train: 42 [ 200/781 ( 26%)]  Loss:  3.703568 (3.7583)  Time: 0.484s,  264.70/s  (0.594s,  215.61/s)  LR: 4.112e-04  Data: 0.007 (0.008)
2024-04-07 02:02:25,458 - train - INFO - Train: 42 [ 250/781 ( 32%)]  Loss:  3.958307 (3.7653)  Time: 0.469s,  272.70/s  (0.570s,  224.64/s)  LR: 4.112e-04  Data: 0.008 (0.008)
2024-04-07 02:02:48,797 - train - INFO - Train: 42 [ 300/781 ( 38%)]  Loss:  3.908297 (3.7663)  Time: 0.504s,  253.77/s  (0.553s,  231.60/s)  LR: 4.112e-04  Data: 0.007 (0.008)
2024-04-07 02:03:11,870 - train - INFO - Train: 42 [ 350/781 ( 45%)]  Loss:  3.753689 (3.7678)  Time: 0.493s,  259.55/s  (0.540s,  237.17/s)  LR: 4.112e-04  Data: 0.006 (0.008)
2024-04-07 02:03:36,229 - train - INFO - Train: 42 [ 400/781 ( 51%)]  Loss:  3.932172 (3.7690)  Time: 0.460s,  277.97/s  (0.533s,  240.09/s)  LR: 4.112e-04  Data: 0.007 (0.008)
2024-04-07 02:03:59,285 - train - INFO - Train: 42 [ 450/781 ( 58%)]  Loss:  3.779261 (3.7708)  Time: 0.465s,  275.54/s  (0.525s,  243.74/s)  LR: 4.112e-04  Data: 0.006 (0.008)
2024-04-07 02:04:23,207 - train - INFO - Train: 42 [ 500/781 ( 64%)]  Loss:  3.937280 (3.7720)  Time: 0.472s,  271.34/s  (0.520s,  245.93/s)  LR: 4.112e-04  Data: 0.008 (0.008)
2024-04-07 02:04:46,877 - train - INFO - Train: 42 [ 550/781 ( 71%)]  Loss:  3.489391 (3.7711)  Time: 0.423s,  302.85/s  (0.516s,  247.96/s)  LR: 4.112e-04  Data: 0.008 (0.008)
2024-04-07 02:05:10,668 - train - INFO - Train: 42 [ 600/781 ( 77%)]  Loss:  3.673516 (3.7709)  Time: 0.399s,  320.77/s  (0.513s,  249.59/s)  LR: 4.112e-04  Data: 0.005 (0.008)
2024-04-07 02:05:33,943 - train - INFO - Train: 42 [ 650/781 ( 83%)]  Loss:  3.443720 (3.7728)  Time: 0.484s,  264.59/s  (0.509s,  251.37/s)  LR: 4.112e-04  Data: 0.007 (0.008)
2024-04-07 02:05:57,215 - train - INFO - Train: 42 [ 700/781 ( 90%)]  Loss:  4.011150 (3.7695)  Time: 0.484s,  264.46/s  (0.506s,  252.93/s)  LR: 4.112e-04  Data: 0.008 (0.008)
2024-04-07 02:06:20,914 - train - INFO - Train: 42 [ 750/781 ( 96%)]  Loss:  3.869435 (3.7703)  Time: 0.390s,  327.92/s  (0.504s,  254.00/s)  LR: 4.112e-04  Data: 0.005 (0.008)
2024-04-07 02:06:35,010 - train - INFO - Train: 42 [ 780/781 (100%)]  Loss:  3.774160 (3.7683)  Time: 0.356s,  359.55/s  (0.503s,  254.66/s)  LR: 4.112e-04  Data: 0.000 (0.008)
2024-04-07 02:06:35,010 - train - INFO - True
2024-04-07 02:06:35,012 - train - INFO - alphas:tensor([0.4924, 0.0891, 0.1010, 0.1283, 0.1892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,012 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,012 - train - INFO - True
2024-04-07 02:06:35,013 - train - INFO - alphas:tensor([0.3831, 0.0515, 0.0706, 0.1230, 0.3718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,014 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,014 - train - INFO - True
2024-04-07 02:06:35,014 - train - INFO - alphas:tensor([0.4025, 0.0724, 0.1269, 0.3982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,015 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,015 - train - INFO - True
2024-04-07 02:06:35,016 - train - INFO - alphas:tensor([0.3490, 0.0629, 0.1045, 0.4836], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,016 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,017 - train - INFO - True
2024-04-07 02:06:35,017 - train - INFO - alphas:tensor([0.3503, 0.0555, 0.1118, 0.4823], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,018 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,018 - train - INFO - True
2024-04-07 02:06:35,019 - train - INFO - alphas:tensor([0.4335, 0.0675, 0.1038, 0.3952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,019 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,019 - train - INFO - True
2024-04-07 02:06:35,020 - train - INFO - alphas:tensor([0.4775, 0.0505, 0.0593, 0.1044, 0.3083], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,021 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,021 - train - INFO - True
2024-04-07 02:06:35,022 - train - INFO - alphas:tensor([0.1904, 0.0277, 0.0281, 0.0897, 0.6640], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,023 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,023 - train - INFO - True
2024-04-07 02:06:35,024 - train - INFO - alphas:tensor([0.2011, 0.0247, 0.0302, 0.0758, 0.6683], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,024 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,024 - train - INFO - True
2024-04-07 02:06:35,025 - train - INFO - alphas:tensor([0.2000, 0.0214, 0.0267, 0.0788, 0.6730], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,026 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,026 - train - INFO - True
2024-04-07 02:06:35,026 - train - INFO - alphas:tensor([0.1840, 0.0250, 0.0273, 0.0870, 0.6767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,027 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,027 - train - INFO - True
2024-04-07 02:06:35,028 - train - INFO - alphas:tensor([0.4852, 0.0347, 0.0470, 0.0965, 0.3367], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,029 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,029 - train - INFO - True
2024-04-07 02:06:35,030 - train - INFO - alphas:tensor([0.5715, 0.0377, 0.0428, 0.0772, 0.2707], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,032 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,033 - train - INFO - True
2024-04-07 02:06:35,033 - train - INFO - alphas:tensor([0.1917, 0.0396, 0.0397, 0.1255, 0.6035], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,035 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,035 - train - INFO - True
2024-04-07 02:06:35,036 - train - INFO - alphas:tensor([0.2079, 0.0297, 0.0363, 0.1174, 0.6086], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,037 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,037 - train - INFO - True
2024-04-07 02:06:35,038 - train - INFO - alphas:tensor([0.2268, 0.0255, 0.0348, 0.1080, 0.6049], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,040 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,040 - train - INFO - True
2024-04-07 02:06:35,040 - train - INFO - alphas:tensor([0.1983, 0.0351, 0.0388, 0.1091, 0.6186], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,042 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,042 - train - INFO - True
2024-04-07 02:06:35,043 - train - INFO - alphas:tensor([0.2240, 0.0251, 0.0375, 0.1063, 0.6071], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,044 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,044 - train - INFO - True
2024-04-07 02:06:35,045 - train - INFO - alphas:tensor([0.1746, 0.0449, 0.0507, 0.1269, 0.6029], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,047 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,047 - train - INFO - True
2024-04-07 02:06:35,048 - train - INFO - alphas:tensor([0.5322, 0.0266, 0.0330, 0.0814, 0.3267], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,050 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,050 - train - INFO - True
2024-04-07 02:06:35,051 - train - INFO - alphas:tensor([0.4579, 0.0237, 0.0275, 0.0837, 0.4072], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,057 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,057 - train - INFO - True
2024-04-07 02:06:35,057 - train - INFO - alphas:tensor([0.3299, 0.0220, 0.0354, 0.0971, 0.5156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,060 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,060 - train - INFO - True
2024-04-07 02:06:35,061 - train - INFO - alphas:tensor([0.3464, 0.0220, 0.0270, 0.0913, 0.5134], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,064 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,064 - train - INFO - True
2024-04-07 02:06:35,065 - train - INFO - alphas:tensor([0.3653, 0.0198, 0.0250, 0.0882, 0.5016], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,068 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,068 - train - INFO - True
2024-04-07 02:06:35,068 - train - INFO - alphas:tensor([0.3327, 0.0207, 0.0313, 0.0906, 0.5248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,071 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,071 - train - INFO - True
2024-04-07 02:06:35,072 - train - INFO - alphas:tensor([0.4846, 0.0193, 0.0279, 0.0703, 0.3980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,078 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,078 - train - INFO - True
2024-04-07 02:06:35,079 - train - INFO - alphas:tensor([0.6184, 0.0194, 0.0267, 0.0602, 0.2753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,093 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,093 - train - INFO - True
2024-04-07 02:06:35,094 - train - INFO - alphas:tensor([0.2814, 0.0196, 0.0284, 0.1038, 0.5669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,101 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,102 - train - INFO - True
2024-04-07 02:06:35,103 - train - INFO - alphas:tensor([0.2959, 0.0164, 0.0243, 0.0952, 0.5682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,110 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,110 - train - INFO - True
2024-04-07 02:06:35,111 - train - INFO - alphas:tensor([0.3224, 0.0163, 0.0221, 0.0906, 0.5486], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,118 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,118 - train - INFO - True
2024-04-07 02:06:35,119 - train - INFO - alphas:tensor([0.2893, 0.0198, 0.0263, 0.0978, 0.5669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,126 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,126 - train - INFO - True
2024-04-07 02:06:35,126 - train - INFO - alphas:tensor([0.6257, 0.0147, 0.0196, 0.0510, 0.2890], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,140 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,140 - train - INFO - True
2024-04-07 02:06:35,140 - train - INFO - alphas:tensor([0.4700, 0.0254, 0.0324, 0.0836, 0.3886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:06:35,190 - train - INFO - tau:0.6689717585696803
2024-04-07 02:06:35,190 - train - INFO - avg block size:9.606060606060606
2024-04-07 02:06:35,190 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 02:06:35,190 - train - INFO - lasso_alpha:2.6620000000000013e-05
2024-04-07 02:06:35,350 - train - INFO - Test: [   0/78]  Time: 0.157 (0.157)  Loss:  1.2051 (1.2051)  Acc@1: 77.3438 (77.3438)  Acc@5: 89.8438 (89.8438)
2024-04-07 02:06:38,363 - train - INFO - Test: [  50/78]  Time: 0.057 (0.062)  Loss:  1.7334 (1.7066)  Acc@1: 57.0312 (61.6728)  Acc@5: 84.3750 (84.2984)
2024-04-07 02:06:40,013 - train - INFO - Test: [  78/78]  Time: 0.048 (0.061)  Loss:  1.7861 (1.7056)  Acc@1: 56.2500 (61.7400)  Acc@5: 93.7500 (84.1200)
2024-04-07 02:06:40,711 - train - INFO - Train: 43 [   0/781 (  0%)]  Loss:  4.027959 (4.0280)  Time: 0.618s,  207.22/s  (0.618s,  207.22/s)  LR: 4.072e-04  Data: 0.151 (0.151)
2024-04-07 02:07:03,875 - train - INFO - Train: 43 [  50/781 (  6%)]  Loss:  3.799807 (3.7439)  Time: 0.487s,  262.92/s  (0.466s,  274.51/s)  LR: 4.072e-04  Data: 0.008 (0.010)
2024-04-07 02:07:27,955 - train - INFO - Train: 43 [ 100/781 ( 13%)]  Loss:  3.879622 (3.7602)  Time: 0.489s,  261.83/s  (0.474s,  270.13/s)  LR: 4.072e-04  Data: 0.006 (0.009)
2024-04-07 02:07:52,003 - train - INFO - Train: 43 [ 150/781 ( 19%)]  Loss:  3.603495 (3.7461)  Time: 0.516s,  248.07/s  (0.476s,  268.80/s)  LR: 4.072e-04  Data: 0.005 (0.009)
2024-04-07 02:08:15,902 - train - INFO - Train: 43 [ 200/781 ( 26%)]  Loss:  3.973571 (3.7669)  Time: 0.483s,  265.25/s  (0.477s,  268.55/s)  LR: 4.072e-04  Data: 0.005 (0.008)
2024-04-07 02:08:38,917 - train - INFO - Train: 43 [ 250/781 ( 32%)]  Loss:  3.511773 (3.7606)  Time: 0.501s,  255.62/s  (0.473s,  270.40/s)  LR: 4.072e-04  Data: 0.007 (0.008)
2024-04-07 02:09:02,690 - train - INFO - Train: 43 [ 300/781 ( 38%)]  Loss:  3.926234 (3.7554)  Time: 0.507s,  252.25/s  (0.474s,  270.21/s)  LR: 4.072e-04  Data: 0.009 (0.008)
2024-04-07 02:09:26,564 - train - INFO - Train: 43 [ 350/781 ( 45%)]  Loss:  3.915346 (3.7643)  Time: 0.469s,  272.88/s  (0.474s,  269.90/s)  LR: 4.072e-04  Data: 0.009 (0.008)
2024-04-07 02:09:49,045 - train - INFO - Train: 43 [ 400/781 ( 51%)]  Loss:  3.912018 (3.7671)  Time: 0.495s,  258.42/s  (0.471s,  271.66/s)  LR: 4.072e-04  Data: 0.007 (0.008)
2024-04-07 02:10:12,057 - train - INFO - Train: 43 [ 450/781 ( 58%)]  Loss:  3.807641 (3.7657)  Time: 0.495s,  258.33/s  (0.470s,  272.37/s)  LR: 4.072e-04  Data: 0.009 (0.008)
2024-04-07 02:10:35,525 - train - INFO - Train: 43 [ 500/781 ( 64%)]  Loss:  4.007056 (3.7615)  Time: 0.464s,  275.68/s  (0.470s,  272.40/s)  LR: 4.072e-04  Data: 0.007 (0.008)
2024-04-07 02:10:58,839 - train - INFO - Train: 43 [ 550/781 ( 71%)]  Loss:  3.710070 (3.7623)  Time: 0.593s,  215.97/s  (0.470s,  272.60/s)  LR: 4.072e-04  Data: 0.005 (0.008)
2024-04-07 02:11:22,749 - train - INFO - Train: 43 [ 600/781 ( 77%)]  Loss:  3.816047 (3.7637)  Time: 0.446s,  286.92/s  (0.470s,  272.18/s)  LR: 4.072e-04  Data: 0.009 (0.008)
2024-04-07 02:11:46,482 - train - INFO - Train: 43 [ 650/781 ( 83%)]  Loss:  3.399704 (3.7663)  Time: 0.405s,  316.18/s  (0.471s,  271.99/s)  LR: 4.072e-04  Data: 0.004 (0.008)
2024-04-07 02:12:10,167 - train - INFO - Train: 43 [ 700/781 ( 90%)]  Loss:  3.535341 (3.7659)  Time: 0.435s,  294.31/s  (0.471s,  271.86/s)  LR: 4.072e-04  Data: 0.008 (0.008)
2024-04-07 02:12:34,063 - train - INFO - Train: 43 [ 750/781 ( 96%)]  Loss:  3.735094 (3.7627)  Time: 0.477s,  268.42/s  (0.471s,  271.59/s)  LR: 4.072e-04  Data: 0.008 (0.008)
2024-04-07 02:12:48,347 - train - INFO - Train: 43 [ 780/781 (100%)]  Loss:  3.560229 (3.7589)  Time: 0.459s,  279.12/s  (0.471s,  271.48/s)  LR: 4.072e-04  Data: 0.000 (0.008)
2024-04-07 02:12:48,348 - train - INFO - True
2024-04-07 02:12:48,350 - train - INFO - alphas:tensor([0.4964, 0.0879, 0.1002, 0.1269, 0.1886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,351 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,351 - train - INFO - True
2024-04-07 02:12:48,353 - train - INFO - alphas:tensor([0.3807, 0.0500, 0.0695, 0.1223, 0.3774], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,353 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,353 - train - INFO - True
2024-04-07 02:12:48,355 - train - INFO - alphas:tensor([0.3998, 0.0710, 0.1245, 0.4047], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,355 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,355 - train - INFO - True
2024-04-07 02:12:48,357 - train - INFO - alphas:tensor([0.3460, 0.0617, 0.1029, 0.4894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,357 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,358 - train - INFO - True
2024-04-07 02:12:48,359 - train - INFO - alphas:tensor([0.3487, 0.0539, 0.1089, 0.4885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,359 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,360 - train - INFO - True
2024-04-07 02:12:48,361 - train - INFO - alphas:tensor([0.4259, 0.0659, 0.1029, 0.4053], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,362 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,362 - train - INFO - True
2024-04-07 02:12:48,363 - train - INFO - alphas:tensor([0.4737, 0.0489, 0.0584, 0.1033, 0.3157], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,365 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,365 - train - INFO - True
2024-04-07 02:12:48,366 - train - INFO - alphas:tensor([0.1868, 0.0270, 0.0271, 0.0878, 0.6713], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,367 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,367 - train - INFO - True
2024-04-07 02:12:48,368 - train - INFO - alphas:tensor([0.1953, 0.0237, 0.0290, 0.0751, 0.6769], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,369 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,369 - train - INFO - True
2024-04-07 02:12:48,370 - train - INFO - alphas:tensor([0.1935, 0.0203, 0.0257, 0.0780, 0.6825], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,371 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,371 - train - INFO - True
2024-04-07 02:12:48,373 - train - INFO - alphas:tensor([0.1822, 0.0243, 0.0264, 0.0861, 0.6810], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,373 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,374 - train - INFO - True
2024-04-07 02:12:48,375 - train - INFO - alphas:tensor([0.4811, 0.0337, 0.0457, 0.0963, 0.3432], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,376 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,376 - train - INFO - True
2024-04-07 02:12:48,377 - train - INFO - alphas:tensor([0.5683, 0.0364, 0.0418, 0.0776, 0.2760], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,382 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,382 - train - INFO - True
2024-04-07 02:12:48,383 - train - INFO - alphas:tensor([0.1843, 0.0378, 0.0385, 0.1242, 0.6152], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,385 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,385 - train - INFO - True
2024-04-07 02:12:48,386 - train - INFO - alphas:tensor([0.2013, 0.0291, 0.0355, 0.1164, 0.6176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,389 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,389 - train - INFO - True
2024-04-07 02:12:48,390 - train - INFO - alphas:tensor([0.2203, 0.0250, 0.0341, 0.1055, 0.6151], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,392 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,392 - train - INFO - True
2024-04-07 02:12:48,393 - train - INFO - alphas:tensor([0.1907, 0.0331, 0.0373, 0.1087, 0.6302], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,396 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,396 - train - INFO - True
2024-04-07 02:12:48,397 - train - INFO - alphas:tensor([0.2185, 0.0245, 0.0371, 0.1063, 0.6136], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,399 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,399 - train - INFO - True
2024-04-07 02:12:48,400 - train - INFO - alphas:tensor([0.1712, 0.0435, 0.0492, 0.1239, 0.6122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,402 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,402 - train - INFO - True
2024-04-07 02:12:48,403 - train - INFO - alphas:tensor([0.5267, 0.0257, 0.0322, 0.0822, 0.3332], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,407 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,407 - train - INFO - True
2024-04-07 02:12:48,408 - train - INFO - alphas:tensor([0.4513, 0.0232, 0.0269, 0.0846, 0.4140], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,416 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,416 - train - INFO - True
2024-04-07 02:12:48,417 - train - INFO - alphas:tensor([0.3169, 0.0215, 0.0346, 0.0973, 0.5297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,421 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,421 - train - INFO - True
2024-04-07 02:12:48,422 - train - INFO - alphas:tensor([0.3394, 0.0212, 0.0262, 0.0922, 0.5210], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,426 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,426 - train - INFO - True
2024-04-07 02:12:48,427 - train - INFO - alphas:tensor([0.3588, 0.0190, 0.0246, 0.0876, 0.5099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,431 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,431 - train - INFO - True
2024-04-07 02:12:48,432 - train - INFO - alphas:tensor([0.3207, 0.0201, 0.0310, 0.0928, 0.5354], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,436 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,436 - train - INFO - True
2024-04-07 02:12:48,437 - train - INFO - alphas:tensor([0.4741, 0.0186, 0.0272, 0.0694, 0.4107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,444 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,444 - train - INFO - True
2024-04-07 02:12:48,445 - train - INFO - alphas:tensor([0.6164, 0.0187, 0.0263, 0.0598, 0.2787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,464 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,465 - train - INFO - True
2024-04-07 02:12:48,465 - train - INFO - alphas:tensor([0.2777, 0.0185, 0.0271, 0.1033, 0.5734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,476 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,476 - train - INFO - True
2024-04-07 02:12:48,477 - train - INFO - alphas:tensor([0.2872, 0.0162, 0.0234, 0.0933, 0.5799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,487 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,487 - train - INFO - True
2024-04-07 02:12:48,488 - train - INFO - alphas:tensor([0.3148, 0.0155, 0.0216, 0.0904, 0.5577], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,498 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,498 - train - INFO - True
2024-04-07 02:12:48,499 - train - INFO - alphas:tensor([0.2755, 0.0192, 0.0256, 0.0970, 0.5827], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,509 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,509 - train - INFO - True
2024-04-07 02:12:48,510 - train - INFO - alphas:tensor([0.6228, 0.0145, 0.0189, 0.0507, 0.2931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,529 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,529 - train - INFO - True
2024-04-07 02:12:48,530 - train - INFO - alphas:tensor([0.4591, 0.0253, 0.0321, 0.0856, 0.3979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:12:48,608 - train - INFO - tau:0.6622820409839835
2024-04-07 02:12:48,608 - train - INFO - avg block size:9.818181818181818
2024-04-07 02:12:48,608 - train - INFO - current latency ratio:tensor(0.2413)
2024-04-07 02:12:48,751 - train - INFO - Test: [   0/78]  Time: 0.139 (0.139)  Loss:  1.1572 (1.1572)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.1875 (92.1875)
2024-04-07 02:12:51,934 - train - INFO - Test: [  50/78]  Time: 0.061 (0.065)  Loss:  1.8506 (1.6923)  Acc@1: 59.3750 (61.9332)  Acc@5: 82.0312 (84.1452)
2024-04-07 02:12:53,665 - train - INFO - Test: [  78/78]  Time: 0.058 (0.064)  Loss:  2.1074 (1.7070)  Acc@1: 62.5000 (61.5800)  Acc@5: 87.5000 (83.7200)
2024-04-07 02:12:54,370 - train - INFO - Train: 44 [   0/781 (  0%)]  Loss:  3.986289 (3.9863)  Time: 0.624s,  205.04/s  (0.624s,  205.04/s)  LR: 4.031e-04  Data: 0.161 (0.161)
2024-04-07 02:13:18,507 - train - INFO - Train: 44 [  50/781 (  6%)]  Loss:  3.639984 (3.7953)  Time: 0.464s,  275.78/s  (0.485s,  263.66/s)  LR: 4.031e-04  Data: 0.012 (0.011)
2024-04-07 02:13:41,366 - train - INFO - Train: 44 [ 100/781 ( 13%)]  Loss:  3.711100 (3.7712)  Time: 0.502s,  254.85/s  (0.471s,  271.50/s)  LR: 4.031e-04  Data: 0.008 (0.009)
2024-04-07 02:14:05,349 - train - INFO - Train: 44 [ 150/781 ( 19%)]  Loss:  3.789234 (3.7682)  Time: 0.502s,  255.12/s  (0.474s,  269.95/s)  LR: 4.031e-04  Data: 0.008 (0.009)
2024-04-07 02:14:28,709 - train - INFO - Train: 44 [ 200/781 ( 26%)]  Loss:  3.832240 (3.7652)  Time: 0.466s,  274.91/s  (0.472s,  270.95/s)  LR: 4.031e-04  Data: 0.005 (0.008)
2024-04-07 02:14:52,259 - train - INFO - Train: 44 [ 250/781 ( 32%)]  Loss:  3.802202 (3.7650)  Time: 0.503s,  254.32/s  (0.472s,  271.11/s)  LR: 4.031e-04  Data: 0.008 (0.008)
2024-04-07 02:15:16,604 - train - INFO - Train: 44 [ 300/781 ( 38%)]  Loss:  3.576629 (3.7629)  Time: 0.513s,  249.58/s  (0.475s,  269.71/s)  LR: 4.031e-04  Data: 0.008 (0.008)
2024-04-07 02:15:40,414 - train - INFO - Train: 44 [ 350/781 ( 45%)]  Loss:  3.709387 (3.7570)  Time: 0.475s,  269.54/s  (0.475s,  269.58/s)  LR: 4.031e-04  Data: 0.008 (0.008)
2024-04-07 02:16:04,137 - train - INFO - Train: 44 [ 400/781 ( 51%)]  Loss:  3.940941 (3.7529)  Time: 0.455s,  281.32/s  (0.475s,  269.61/s)  LR: 4.031e-04  Data: 0.004 (0.008)
2024-04-07 02:16:27,345 - train - INFO - Train: 44 [ 450/781 ( 58%)]  Loss:  3.938535 (3.7508)  Time: 0.498s,  256.98/s  (0.474s,  270.28/s)  LR: 4.031e-04  Data: 0.008 (0.008)
2024-04-07 02:16:51,544 - train - INFO - Train: 44 [ 500/781 ( 64%)]  Loss:  3.594551 (3.7499)  Time: 0.443s,  288.99/s  (0.475s,  269.69/s)  LR: 4.031e-04  Data: 0.008 (0.008)
2024-04-07 02:17:14,857 - train - INFO - Train: 44 [ 550/781 ( 71%)]  Loss:  3.819213 (3.7533)  Time: 0.455s,  281.05/s  (0.474s,  270.13/s)  LR: 4.031e-04  Data: 0.006 (0.008)
2024-04-07 02:17:39,381 - train - INFO - Train: 44 [ 600/781 ( 77%)]  Loss:  3.934364 (3.7542)  Time: 0.522s,  245.30/s  (0.475s,  269.34/s)  LR: 4.031e-04  Data: 0.009 (0.008)
2024-04-07 02:18:03,217 - train - INFO - Train: 44 [ 650/781 ( 83%)]  Loss:  3.586880 (3.7574)  Time: 0.490s,  261.32/s  (0.475s,  269.28/s)  LR: 4.031e-04  Data: 0.007 (0.008)
2024-04-07 02:18:27,343 - train - INFO - Train: 44 [ 700/781 ( 90%)]  Loss:  3.726645 (3.7571)  Time: 0.488s,  262.54/s  (0.476s,  268.99/s)  LR: 4.031e-04  Data: 0.009 (0.008)
2024-04-07 02:18:49,889 - train - INFO - Train: 44 [ 750/781 ( 96%)]  Loss:  3.717685 (3.7592)  Time: 0.479s,  266.99/s  (0.474s,  269.93/s)  LR: 4.031e-04  Data: 0.007 (0.008)
2024-04-07 02:19:04,897 - train - INFO - Train: 44 [ 780/781 (100%)]  Loss:  3.766555 (3.7614)  Time: 0.520s,  246.29/s  (0.475s,  269.37/s)  LR: 4.031e-04  Data: 0.000 (0.008)
2024-04-07 02:19:04,898 - train - INFO - True
2024-04-07 02:19:04,906 - train - INFO - alphas:tensor([0.4983, 0.0863, 0.0991, 0.1266, 0.1897], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,907 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,907 - train - INFO - True
2024-04-07 02:19:04,915 - train - INFO - alphas:tensor([0.3808, 0.0491, 0.0689, 0.1199, 0.3813], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,915 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,916 - train - INFO - True
2024-04-07 02:19:04,924 - train - INFO - alphas:tensor([0.3998, 0.0689, 0.1223, 0.4089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,925 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,925 - train - INFO - True
2024-04-07 02:19:04,926 - train - INFO - alphas:tensor([0.3432, 0.0614, 0.1023, 0.4930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,927 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,927 - train - INFO - True
2024-04-07 02:19:04,928 - train - INFO - alphas:tensor([0.3454, 0.0520, 0.1083, 0.4943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,928 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,928 - train - INFO - True
2024-04-07 02:19:04,929 - train - INFO - alphas:tensor([0.4286, 0.0648, 0.1011, 0.4054], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,930 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,930 - train - INFO - True
2024-04-07 02:19:04,931 - train - INFO - alphas:tensor([0.4720, 0.0482, 0.0572, 0.1023, 0.3202], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,932 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,933 - train - INFO - True
2024-04-07 02:19:04,934 - train - INFO - alphas:tensor([0.1825, 0.0260, 0.0260, 0.0855, 0.6800], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,934 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,934 - train - INFO - True
2024-04-07 02:19:04,935 - train - INFO - alphas:tensor([0.1949, 0.0229, 0.0280, 0.0736, 0.6806], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,936 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,936 - train - INFO - True
2024-04-07 02:19:04,937 - train - INFO - alphas:tensor([0.1912, 0.0194, 0.0249, 0.0777, 0.6868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,938 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,938 - train - INFO - True
2024-04-07 02:19:04,939 - train - INFO - alphas:tensor([0.1791, 0.0237, 0.0260, 0.0852, 0.6860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,940 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,940 - train - INFO - True
2024-04-07 02:19:04,941 - train - INFO - alphas:tensor([0.4775, 0.0328, 0.0451, 0.0957, 0.3489], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,942 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,942 - train - INFO - True
2024-04-07 02:19:04,943 - train - INFO - alphas:tensor([0.5704, 0.0348, 0.0406, 0.0768, 0.2773], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,947 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,947 - train - INFO - True
2024-04-07 02:19:04,948 - train - INFO - alphas:tensor([0.1816, 0.0379, 0.0383, 0.1238, 0.6184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,950 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,950 - train - INFO - True
2024-04-07 02:19:04,951 - train - INFO - alphas:tensor([0.1987, 0.0280, 0.0344, 0.1176, 0.6213], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,953 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,953 - train - INFO - True
2024-04-07 02:19:04,954 - train - INFO - alphas:tensor([0.2184, 0.0239, 0.0332, 0.1046, 0.6199], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,955 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,956 - train - INFO - True
2024-04-07 02:19:04,956 - train - INFO - alphas:tensor([0.1888, 0.0328, 0.0371, 0.1084, 0.6329], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,958 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,958 - train - INFO - True
2024-04-07 02:19:04,959 - train - INFO - alphas:tensor([0.2204, 0.0239, 0.0367, 0.1062, 0.6128], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,961 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,961 - train - INFO - True
2024-04-07 02:19:04,962 - train - INFO - alphas:tensor([0.1680, 0.0428, 0.0488, 0.1230, 0.6174], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,964 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,964 - train - INFO - True
2024-04-07 02:19:04,965 - train - INFO - alphas:tensor([0.5261, 0.0250, 0.0318, 0.0818, 0.3353], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,969 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,969 - train - INFO - True
2024-04-07 02:19:04,977 - train - INFO - alphas:tensor([0.4498, 0.0224, 0.0260, 0.0843, 0.4176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,984 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,984 - train - INFO - True
2024-04-07 02:19:04,991 - train - INFO - alphas:tensor([0.3227, 0.0210, 0.0342, 0.0974, 0.5247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:04,995 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:04,995 - train - INFO - True
2024-04-07 02:19:05,003 - train - INFO - alphas:tensor([0.3378, 0.0209, 0.0260, 0.0927, 0.5227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:05,006 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:05,006 - train - INFO - True
2024-04-07 02:19:05,014 - train - INFO - alphas:tensor([0.3522, 0.0183, 0.0243, 0.0860, 0.5192], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:05,018 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:05,018 - train - INFO - True
2024-04-07 02:19:05,019 - train - INFO - alphas:tensor([0.3196, 0.0199, 0.0299, 0.0923, 0.5383], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:05,023 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:05,023 - train - INFO - True
2024-04-07 02:19:05,024 - train - INFO - alphas:tensor([0.4742, 0.0182, 0.0261, 0.0692, 0.4123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:05,031 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:05,031 - train - INFO - True
2024-04-07 02:19:05,032 - train - INFO - alphas:tensor([0.6109, 0.0181, 0.0254, 0.0606, 0.2850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:05,052 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:05,052 - train - INFO - True
2024-04-07 02:19:05,053 - train - INFO - alphas:tensor([0.2725, 0.0184, 0.0269, 0.1038, 0.5784], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:05,063 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:05,063 - train - INFO - True
2024-04-07 02:19:05,070 - train - INFO - alphas:tensor([0.2836, 0.0155, 0.0228, 0.0936, 0.5846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:05,080 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:05,080 - train - INFO - True
2024-04-07 02:19:05,088 - train - INFO - alphas:tensor([0.3153, 0.0155, 0.0213, 0.0907, 0.5572], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:05,098 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:05,098 - train - INFO - True
2024-04-07 02:19:05,103 - train - INFO - alphas:tensor([0.2745, 0.0183, 0.0249, 0.0965, 0.5858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:05,113 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:05,113 - train - INFO - True
2024-04-07 02:19:05,114 - train - INFO - alphas:tensor([0.6227, 0.0139, 0.0183, 0.0495, 0.2957], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:05,133 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:05,133 - train - INFO - True
2024-04-07 02:19:05,134 - train - INFO - alphas:tensor([0.4557, 0.0249, 0.0316, 0.0861, 0.4017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:19:05,212 - train - INFO - tau:0.6556592205741436
2024-04-07 02:19:05,212 - train - INFO - avg block size:10.272727272727273
2024-04-07 02:19:05,212 - train - INFO - current latency ratio:tensor(0.2324)
2024-04-07 02:19:05,213 - train - INFO - lasso_alpha:2.420000000000001e-05
2024-04-07 02:19:05,486 - train - INFO - Test: [   0/78]  Time: 0.270 (0.270)  Loss:  1.1592 (1.1592)  Acc@1: 75.7812 (75.7812)  Acc@5: 91.4062 (91.4062)
2024-04-07 02:19:10,866 - train - INFO - Test: [  50/78]  Time: 0.168 (0.111)  Loss:  1.8115 (1.6698)  Acc@1: 55.4688 (61.5962)  Acc@5: 84.3750 (84.5129)
2024-04-07 02:19:14,019 - train - INFO - Test: [  78/78]  Time: 0.077 (0.111)  Loss:  1.9170 (1.6964)  Acc@1: 56.2500 (60.9700)  Acc@5: 93.7500 (83.9700)
2024-04-07 02:19:14,753 - train - INFO - Train: 45 [   0/781 (  0%)]  Loss:  4.123375 (4.1234)  Time: 0.650s,  196.89/s  (0.650s,  196.89/s)  LR: 3.990e-04  Data: 0.192 (0.192)
2024-04-07 02:19:40,996 - train - INFO - Train: 45 [  50/781 (  6%)]  Loss:  4.003452 (3.7067)  Time: 0.542s,  236.17/s  (0.527s,  242.75/s)  LR: 3.990e-04  Data: 0.008 (0.011)
2024-04-07 02:20:07,110 - train - INFO - Train: 45 [ 100/781 ( 13%)]  Loss:  3.334844 (3.7018)  Time: 0.522s,  245.37/s  (0.525s,  243.91/s)  LR: 3.990e-04  Data: 0.006 (0.009)
2024-04-07 02:20:34,518 - train - INFO - Train: 45 [ 150/781 ( 19%)]  Loss:  3.366991 (3.7232)  Time: 0.579s,  221.05/s  (0.533s,  240.37/s)  LR: 3.990e-04  Data: 0.009 (0.009)
2024-04-07 02:21:00,788 - train - INFO - Train: 45 [ 200/781 ( 26%)]  Loss:  3.731001 (3.7264)  Time: 0.538s,  238.05/s  (0.531s,  241.17/s)  LR: 3.990e-04  Data: 0.007 (0.009)
2024-04-07 02:21:27,845 - train - INFO - Train: 45 [ 250/781 ( 32%)]  Loss:  4.017096 (3.7355)  Time: 0.454s,  282.21/s  (0.533s,  240.24/s)  LR: 3.990e-04  Data: 0.006 (0.008)
2024-04-07 02:21:54,160 - train - INFO - Train: 45 [ 300/781 ( 38%)]  Loss:  3.780498 (3.7441)  Time: 0.509s,  251.24/s  (0.532s,  240.73/s)  LR: 3.990e-04  Data: 0.007 (0.008)
2024-04-07 02:22:20,322 - train - INFO - Train: 45 [ 350/781 ( 45%)]  Loss:  3.947022 (3.7386)  Time: 0.442s,  289.51/s  (0.531s,  241.28/s)  LR: 3.990e-04  Data: 0.005 (0.008)
2024-04-07 02:22:46,688 - train - INFO - Train: 45 [ 400/781 ( 51%)]  Loss:  3.975720 (3.7461)  Time: 0.408s,  313.54/s  (0.530s,  241.46/s)  LR: 3.990e-04  Data: 0.006 (0.008)
2024-04-07 02:23:12,717 - train - INFO - Train: 45 [ 450/781 ( 58%)]  Loss:  3.477888 (3.7395)  Time: 0.467s,  274.30/s  (0.529s,  241.94/s)  LR: 3.990e-04  Data: 0.008 (0.008)
2024-04-07 02:23:38,911 - train - INFO - Train: 45 [ 500/781 ( 64%)]  Loss:  3.806973 (3.7369)  Time: 0.542s,  236.37/s  (0.529s,  242.18/s)  LR: 3.990e-04  Data: 0.008 (0.008)
2024-04-07 02:24:05,930 - train - INFO - Train: 45 [ 550/781 ( 71%)]  Loss:  4.059590 (3.7383)  Time: 0.472s,  270.91/s  (0.530s,  241.69/s)  LR: 3.990e-04  Data: 0.007 (0.008)
2024-04-07 02:24:32,891 - train - INFO - Train: 45 [ 600/781 ( 77%)]  Loss:  3.339134 (3.7354)  Time: 0.465s,  275.39/s  (0.530s,  241.33/s)  LR: 3.990e-04  Data: 0.005 (0.008)
2024-04-07 02:24:58,213 - train - INFO - Train: 45 [ 650/781 ( 83%)]  Loss:  3.371390 (3.7325)  Time: 0.543s,  235.72/s  (0.529s,  242.17/s)  LR: 3.990e-04  Data: 0.008 (0.008)
2024-04-07 02:25:23,970 - train - INFO - Train: 45 [ 700/781 ( 90%)]  Loss:  3.969791 (3.7336)  Time: 0.501s,  255.72/s  (0.528s,  242.61/s)  LR: 3.990e-04  Data: 0.007 (0.008)
2024-04-07 02:25:50,699 - train - INFO - Train: 45 [ 750/781 ( 96%)]  Loss:  3.468528 (3.7313)  Time: 0.583s,  219.43/s  (0.528s,  242.40/s)  LR: 3.990e-04  Data: 0.007 (0.008)
2024-04-07 02:26:07,193 - train - INFO - Train: 45 [ 780/781 (100%)]  Loss:  3.960342 (3.7323)  Time: 0.559s,  229.10/s  (0.529s,  242.01/s)  LR: 3.990e-04  Data: 0.000 (0.008)
2024-04-07 02:26:07,194 - train - INFO - True
2024-04-07 02:26:07,196 - train - INFO - alphas:tensor([0.5027, 0.0848, 0.0978, 0.1248, 0.1899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,197 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,198 - train - INFO - True
2024-04-07 02:26:07,199 - train - INFO - alphas:tensor([0.3804, 0.0480, 0.0672, 0.1199, 0.3845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,200 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,200 - train - INFO - True
2024-04-07 02:26:07,202 - train - INFO - alphas:tensor([0.4006, 0.0677, 0.1212, 0.4105], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,202 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,203 - train - INFO - True
2024-04-07 02:26:07,204 - train - INFO - alphas:tensor([0.3491, 0.0599, 0.0999, 0.4910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,205 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,205 - train - INFO - True
2024-04-07 02:26:07,206 - train - INFO - alphas:tensor([0.3466, 0.0506, 0.1073, 0.4955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,207 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,207 - train - INFO - True
2024-04-07 02:26:07,214 - train - INFO - alphas:tensor([0.4279, 0.0635, 0.0993, 0.4093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,215 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,215 - train - INFO - True
2024-04-07 02:26:07,224 - train - INFO - alphas:tensor([0.4718, 0.0468, 0.0558, 0.1011, 0.3244], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,225 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,225 - train - INFO - True
2024-04-07 02:26:07,233 - train - INFO - alphas:tensor([0.1851, 0.0256, 0.0252, 0.0849, 0.6791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,234 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,234 - train - INFO - True
2024-04-07 02:26:07,242 - train - INFO - alphas:tensor([0.1978, 0.0223, 0.0277, 0.0730, 0.6791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,243 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,243 - train - INFO - True
2024-04-07 02:26:07,252 - train - INFO - alphas:tensor([0.1942, 0.0185, 0.0240, 0.0748, 0.6885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,253 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,253 - train - INFO - True
2024-04-07 02:26:07,260 - train - INFO - alphas:tensor([0.1812, 0.0229, 0.0252, 0.0840, 0.6867], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,260 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,260 - train - INFO - True
2024-04-07 02:26:07,262 - train - INFO - alphas:tensor([0.4789, 0.0317, 0.0438, 0.0938, 0.3518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,263 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,263 - train - INFO - True
2024-04-07 02:26:07,264 - train - INFO - alphas:tensor([0.5716, 0.0342, 0.0393, 0.0755, 0.2794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,268 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,268 - train - INFO - True
2024-04-07 02:26:07,269 - train - INFO - alphas:tensor([0.1851, 0.0373, 0.0372, 0.1245, 0.6159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,271 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,272 - train - INFO - True
2024-04-07 02:26:07,273 - train - INFO - alphas:tensor([0.2004, 0.0274, 0.0338, 0.1159, 0.6225], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,275 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,275 - train - INFO - True
2024-04-07 02:26:07,276 - train - INFO - alphas:tensor([0.2226, 0.0237, 0.0329, 0.1045, 0.6163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,278 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,278 - train - INFO - True
2024-04-07 02:26:07,279 - train - INFO - alphas:tensor([0.1945, 0.0331, 0.0372, 0.1086, 0.6266], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,281 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,281 - train - INFO - True
2024-04-07 02:26:07,282 - train - INFO - alphas:tensor([0.2202, 0.0235, 0.0360, 0.1049, 0.6154], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,284 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,285 - train - INFO - True
2024-04-07 02:26:07,286 - train - INFO - alphas:tensor([0.1686, 0.0427, 0.0484, 0.1229, 0.6174], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,288 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,288 - train - INFO - True
2024-04-07 02:26:07,289 - train - INFO - alphas:tensor([0.5215, 0.0241, 0.0311, 0.0819, 0.3414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,292 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,292 - train - INFO - True
2024-04-07 02:26:07,293 - train - INFO - alphas:tensor([0.4510, 0.0214, 0.0249, 0.0821, 0.4205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,301 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,301 - train - INFO - True
2024-04-07 02:26:07,302 - train - INFO - alphas:tensor([0.3264, 0.0201, 0.0328, 0.0947, 0.5260], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,306 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,306 - train - INFO - True
2024-04-07 02:26:07,307 - train - INFO - alphas:tensor([0.3442, 0.0203, 0.0249, 0.0918, 0.5188], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,311 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,311 - train - INFO - True
2024-04-07 02:26:07,312 - train - INFO - alphas:tensor([0.3575, 0.0180, 0.0235, 0.0872, 0.5137], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,315 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,316 - train - INFO - True
2024-04-07 02:26:07,316 - train - INFO - alphas:tensor([0.3253, 0.0195, 0.0295, 0.0910, 0.5346], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,320 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,320 - train - INFO - True
2024-04-07 02:26:07,321 - train - INFO - alphas:tensor([0.4734, 0.0179, 0.0255, 0.0677, 0.4156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,329 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,329 - train - INFO - True
2024-04-07 02:26:07,330 - train - INFO - alphas:tensor([0.6150, 0.0176, 0.0251, 0.0596, 0.2828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,349 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,349 - train - INFO - True
2024-04-07 02:26:07,357 - train - INFO - alphas:tensor([0.2802, 0.0178, 0.0264, 0.1031, 0.5725], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,367 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,367 - train - INFO - True
2024-04-07 02:26:07,374 - train - INFO - alphas:tensor([0.2907, 0.0153, 0.0227, 0.0942, 0.5771], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,384 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,384 - train - INFO - True
2024-04-07 02:26:07,387 - train - INFO - alphas:tensor([0.3197, 0.0151, 0.0206, 0.0901, 0.5545], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,397 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,397 - train - INFO - True
2024-04-07 02:26:07,398 - train - INFO - alphas:tensor([0.2838, 0.0182, 0.0243, 0.0955, 0.5782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,408 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,408 - train - INFO - True
2024-04-07 02:26:07,409 - train - INFO - alphas:tensor([0.6202, 0.0135, 0.0177, 0.0492, 0.2995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,428 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,428 - train - INFO - True
2024-04-07 02:26:07,429 - train - INFO - alphas:tensor([0.4660, 0.0247, 0.0308, 0.0837, 0.3949], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:26:07,508 - train - INFO - tau:0.6491026283684022
2024-04-07 02:26:07,508 - train - INFO - avg block size:10.272727272727273
2024-04-07 02:26:07,508 - train - INFO - current latency ratio:tensor(0.2324)
2024-04-07 02:26:07,779 - train - INFO - Test: [   0/78]  Time: 0.267 (0.267)  Loss:  1.0996 (1.0996)  Acc@1: 76.5625 (76.5625)  Acc@5: 93.7500 (93.7500)
2024-04-07 02:26:13,226 - train - INFO - Test: [  50/78]  Time: 0.155 (0.112)  Loss:  1.8389 (1.6832)  Acc@1: 57.0312 (62.3009)  Acc@5: 79.6875 (85.2175)
2024-04-07 02:26:16,030 - train - INFO - Test: [  78/78]  Time: 0.099 (0.108)  Loss:  2.1328 (1.7056)  Acc@1: 50.0000 (62.2500)  Acc@5: 81.2500 (84.6200)
2024-04-07 02:26:16,808 - train - INFO - Train: 46 [   0/781 (  0%)]  Loss:  3.317683 (3.3177)  Time: 0.697s,  183.57/s  (0.697s,  183.57/s)  LR: 3.948e-04  Data: 0.184 (0.184)
2024-04-07 02:26:43,319 - train - INFO - Train: 46 [  50/781 (  6%)]  Loss:  3.273749 (3.7367)  Time: 0.619s,  206.87/s  (0.533s,  239.94/s)  LR: 3.948e-04  Data: 0.009 (0.011)
2024-04-07 02:27:11,036 - train - INFO - Train: 46 [ 100/781 ( 13%)]  Loss:  3.658277 (3.7445)  Time: 0.536s,  238.88/s  (0.544s,  235.39/s)  LR: 3.948e-04  Data: 0.009 (0.009)
2024-04-07 02:27:37,802 - train - INFO - Train: 46 [ 150/781 ( 19%)]  Loss:  3.781477 (3.7569)  Time: 0.534s,  239.92/s  (0.541s,  236.61/s)  LR: 3.948e-04  Data: 0.007 (0.009)
2024-04-07 02:28:04,328 - train - INFO - Train: 46 [ 200/781 ( 26%)]  Loss:  3.171648 (3.7500)  Time: 0.538s,  237.83/s  (0.538s,  237.76/s)  LR: 3.948e-04  Data: 0.007 (0.009)
2024-04-07 02:28:30,380 - train - INFO - Train: 46 [ 250/781 ( 32%)]  Loss:  3.768833 (3.7543)  Time: 0.451s,  283.60/s  (0.535s,  239.29/s)  LR: 3.948e-04  Data: 0.009 (0.008)
2024-04-07 02:28:56,930 - train - INFO - Train: 46 [ 300/781 ( 38%)]  Loss:  3.480560 (3.7440)  Time: 0.464s,  275.60/s  (0.534s,  239.59/s)  LR: 3.948e-04  Data: 0.008 (0.008)
2024-04-07 02:29:23,571 - train - INFO - Train: 46 [ 350/781 ( 45%)]  Loss:  3.893097 (3.7451)  Time: 0.551s,  232.21/s  (0.534s,  239.68/s)  LR: 3.948e-04  Data: 0.008 (0.008)
2024-04-07 02:29:50,360 - train - INFO - Train: 46 [ 400/781 ( 51%)]  Loss:  3.584425 (3.7436)  Time: 0.596s,  214.78/s  (0.534s,  239.59/s)  LR: 3.948e-04  Data: 0.009 (0.008)
2024-04-07 02:30:16,984 - train - INFO - Train: 46 [ 450/781 ( 58%)]  Loss:  3.887271 (3.7428)  Time: 0.449s,  284.99/s  (0.534s,  239.68/s)  LR: 3.948e-04  Data: 0.005 (0.008)
2024-04-07 02:30:43,501 - train - INFO - Train: 46 [ 500/781 ( 64%)]  Loss:  4.064974 (3.7459)  Time: 0.451s,  283.83/s  (0.534s,  239.84/s)  LR: 3.948e-04  Data: 0.006 (0.008)
2024-04-07 02:31:09,987 - train - INFO - Train: 46 [ 550/781 ( 71%)]  Loss:  3.885479 (3.7511)  Time: 0.599s,  213.54/s  (0.533s,  240.01/s)  LR: 3.948e-04  Data: 0.010 (0.008)
2024-04-07 02:31:35,795 - train - INFO - Train: 46 [ 600/781 ( 77%)]  Loss:  3.574036 (3.7553)  Time: 0.433s,  295.80/s  (0.532s,  240.65/s)  LR: 3.948e-04  Data: 0.006 (0.008)
2024-04-07 02:32:02,018 - train - INFO - Train: 46 [ 650/781 ( 83%)]  Loss:  4.050876 (3.7562)  Time: 0.489s,  261.63/s  (0.531s,  240.91/s)  LR: 3.948e-04  Data: 0.007 (0.008)
2024-04-07 02:32:29,167 - train - INFO - Train: 46 [ 700/781 ( 90%)]  Loss:  3.677510 (3.7549)  Time: 0.575s,  222.54/s  (0.532s,  240.54/s)  LR: 3.948e-04  Data: 0.008 (0.008)
2024-04-07 02:32:55,412 - train - INFO - Train: 46 [ 750/781 ( 96%)]  Loss:  3.670789 (3.7534)  Time: 0.538s,  237.92/s  (0.532s,  240.76/s)  LR: 3.948e-04  Data: 0.005 (0.008)
2024-04-07 02:33:12,132 - train - INFO - Train: 46 [ 780/781 (100%)]  Loss:  3.760350 (3.7519)  Time: 0.543s,  235.89/s  (0.533s,  240.31/s)  LR: 3.948e-04  Data: 0.000 (0.008)
2024-04-07 02:33:12,133 - train - INFO - True
2024-04-07 02:33:12,135 - train - INFO - alphas:tensor([0.5056, 0.0836, 0.0967, 0.1239, 0.1903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,136 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,136 - train - INFO - True
2024-04-07 02:33:12,137 - train - INFO - alphas:tensor([0.3802, 0.0465, 0.0658, 0.1182, 0.3894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,137 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,137 - train - INFO - True
2024-04-07 02:33:12,138 - train - INFO - alphas:tensor([0.4013, 0.0665, 0.1205, 0.4117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,139 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,139 - train - INFO - True
2024-04-07 02:33:12,140 - train - INFO - alphas:tensor([0.3481, 0.0586, 0.0982, 0.4951], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,141 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,141 - train - INFO - True
2024-04-07 02:33:12,142 - train - INFO - alphas:tensor([0.3480, 0.0500, 0.1056, 0.4964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,142 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,142 - train - INFO - True
2024-04-07 02:33:12,143 - train - INFO - alphas:tensor([0.4280, 0.0621, 0.0972, 0.4127], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,144 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,144 - train - INFO - True
2024-04-07 02:33:12,145 - train - INFO - alphas:tensor([0.4708, 0.0457, 0.0548, 0.1006, 0.3281], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,147 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,147 - train - INFO - True
2024-04-07 02:33:12,148 - train - INFO - alphas:tensor([0.1871, 0.0251, 0.0248, 0.0830, 0.6801], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,149 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,149 - train - INFO - True
2024-04-07 02:33:12,150 - train - INFO - alphas:tensor([0.1961, 0.0215, 0.0267, 0.0719, 0.6838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,150 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,151 - train - INFO - True
2024-04-07 02:33:12,152 - train - INFO - alphas:tensor([0.1947, 0.0183, 0.0234, 0.0752, 0.6883], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,152 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,152 - train - INFO - True
2024-04-07 02:33:12,153 - train - INFO - alphas:tensor([0.1831, 0.0226, 0.0242, 0.0808, 0.6893], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,154 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,154 - train - INFO - True
2024-04-07 02:33:12,155 - train - INFO - alphas:tensor([0.4818, 0.0305, 0.0427, 0.0925, 0.3525], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,157 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,157 - train - INFO - True
2024-04-07 02:33:12,158 - train - INFO - alphas:tensor([0.5694, 0.0336, 0.0389, 0.0746, 0.2834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,161 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,161 - train - INFO - True
2024-04-07 02:33:12,162 - train - INFO - alphas:tensor([0.1879, 0.0369, 0.0366, 0.1218, 0.6169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,164 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,164 - train - INFO - True
2024-04-07 02:33:12,165 - train - INFO - alphas:tensor([0.2003, 0.0267, 0.0333, 0.1145, 0.6253], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,167 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,167 - train - INFO - True
2024-04-07 02:33:12,174 - train - INFO - alphas:tensor([0.2216, 0.0230, 0.0318, 0.1054, 0.6183], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,176 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,176 - train - INFO - True
2024-04-07 02:33:12,183 - train - INFO - alphas:tensor([0.1932, 0.0317, 0.0356, 0.1048, 0.6348], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,185 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,185 - train - INFO - True
2024-04-07 02:33:12,193 - train - INFO - alphas:tensor([0.2221, 0.0234, 0.0359, 0.1050, 0.6136], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,194 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,195 - train - INFO - True
2024-04-07 02:33:12,202 - train - INFO - alphas:tensor([0.1712, 0.0423, 0.0481, 0.1218, 0.6166], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,204 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,204 - train - INFO - True
2024-04-07 02:33:12,211 - train - INFO - alphas:tensor([0.5217, 0.0232, 0.0305, 0.0808, 0.3438], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,215 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,215 - train - INFO - True
2024-04-07 02:33:12,219 - train - INFO - alphas:tensor([0.4516, 0.0207, 0.0245, 0.0815, 0.4217], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,226 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,226 - train - INFO - True
2024-04-07 02:33:12,227 - train - INFO - alphas:tensor([0.3255, 0.0193, 0.0313, 0.0931, 0.5309], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,231 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,231 - train - INFO - True
2024-04-07 02:33:12,232 - train - INFO - alphas:tensor([0.3420, 0.0199, 0.0244, 0.0913, 0.5225], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,236 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,236 - train - INFO - True
2024-04-07 02:33:12,237 - train - INFO - alphas:tensor([0.3556, 0.0177, 0.0235, 0.0881, 0.5151], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,241 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,241 - train - INFO - True
2024-04-07 02:33:12,242 - train - INFO - alphas:tensor([0.3214, 0.0188, 0.0284, 0.0900, 0.5414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,246 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,246 - train - INFO - True
2024-04-07 02:33:12,247 - train - INFO - alphas:tensor([0.4763, 0.0172, 0.0247, 0.0672, 0.4147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,254 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,254 - train - INFO - True
2024-04-07 02:33:12,255 - train - INFO - alphas:tensor([0.6111, 0.0170, 0.0248, 0.0603, 0.2868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,276 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,276 - train - INFO - True
2024-04-07 02:33:12,283 - train - INFO - alphas:tensor([0.2827, 0.0172, 0.0257, 0.1000, 0.5744], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,293 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,293 - train - INFO - True
2024-04-07 02:33:12,300 - train - INFO - alphas:tensor([0.2937, 0.0148, 0.0224, 0.0931, 0.5760], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,310 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,310 - train - INFO - True
2024-04-07 02:33:12,318 - train - INFO - alphas:tensor([0.3171, 0.0146, 0.0204, 0.0896, 0.5584], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,328 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,328 - train - INFO - True
2024-04-07 02:33:12,329 - train - INFO - alphas:tensor([0.2817, 0.0174, 0.0233, 0.0939, 0.5837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,339 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,339 - train - INFO - True
2024-04-07 02:33:12,340 - train - INFO - alphas:tensor([0.6268, 0.0133, 0.0171, 0.0482, 0.2946], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,359 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,359 - train - INFO - True
2024-04-07 02:33:12,360 - train - INFO - alphas:tensor([0.4660, 0.0245, 0.0303, 0.0837, 0.3955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:33:12,439 - train - INFO - tau:0.6426116020847181
2024-04-07 02:33:12,439 - train - INFO - avg block size:10.272727272727273
2024-04-07 02:33:12,439 - train - INFO - current latency ratio:tensor(0.2324)
2024-04-07 02:33:12,440 - train - INFO - lasso_alpha:2.2000000000000006e-05
2024-04-07 02:33:12,711 - train - INFO - Test: [   0/78]  Time: 0.267 (0.267)  Loss:  0.9644 (0.9644)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.9688 (92.9688)
2024-04-07 02:33:17,956 - train - INFO - Test: [  50/78]  Time: 0.101 (0.108)  Loss:  1.8037 (1.6911)  Acc@1: 60.1562 (61.6422)  Acc@5: 81.2500 (83.9767)
2024-04-07 02:33:20,310 - train - INFO - Test: [  78/78]  Time: 0.047 (0.100)  Loss:  2.0195 (1.6955)  Acc@1: 50.0000 (61.5400)  Acc@5: 100.0000 (83.7600)
2024-04-07 02:33:21,659 - train - INFO - Train: 47 [   0/781 (  0%)]  Loss:  3.874908 (3.8749)  Time: 1.268s,  100.98/s  (1.268s,  100.98/s)  LR: 3.906e-04  Data: 0.155 (0.155)
2024-04-07 02:33:48,698 - train - INFO - Train: 47 [  50/781 (  6%)]  Loss:  3.416718 (3.7069)  Time: 0.557s,  229.85/s  (0.555s,  230.63/s)  LR: 3.906e-04  Data: 0.009 (0.011)
2024-04-07 02:34:16,160 - train - INFO - Train: 47 [ 100/781 ( 13%)]  Loss:  3.507986 (3.7038)  Time: 0.571s,  224.27/s  (0.552s,  231.83/s)  LR: 3.906e-04  Data: 0.009 (0.009)
2024-04-07 02:34:42,426 - train - INFO - Train: 47 [ 150/781 ( 19%)]  Loss:  3.898450 (3.7094)  Time: 0.514s,  249.04/s  (0.543s,  235.62/s)  LR: 3.906e-04  Data: 0.005 (0.009)
2024-04-07 02:35:09,472 - train - INFO - Train: 47 [ 200/781 ( 26%)]  Loss:  3.917269 (3.7101)  Time: 0.590s,  216.97/s  (0.543s,  235.88/s)  LR: 3.906e-04  Data: 0.006 (0.008)
2024-04-07 02:35:36,558 - train - INFO - Train: 47 [ 250/781 ( 32%)]  Loss:  3.918451 (3.7191)  Time: 0.576s,  222.37/s  (0.542s,  235.96/s)  LR: 3.906e-04  Data: 0.008 (0.008)
2024-04-07 02:36:04,389 - train - INFO - Train: 47 [ 300/781 ( 38%)]  Loss:  3.946534 (3.7191)  Time: 0.606s,  211.34/s  (0.545s,  234.95/s)  LR: 3.906e-04  Data: 0.009 (0.008)
2024-04-07 02:36:30,232 - train - INFO - Train: 47 [ 350/781 ( 45%)]  Loss:  4.066061 (3.7212)  Time: 0.502s,  255.12/s  (0.541s,  236.68/s)  LR: 3.906e-04  Data: 0.007 (0.008)
2024-04-07 02:36:57,798 - train - INFO - Train: 47 [ 400/781 ( 51%)]  Loss:  3.657188 (3.7224)  Time: 0.557s,  229.99/s  (0.542s,  236.11/s)  LR: 3.906e-04  Data: 0.007 (0.008)
2024-04-07 02:37:24,191 - train - INFO - Train: 47 [ 450/781 ( 58%)]  Loss:  3.516436 (3.7214)  Time: 0.539s,  237.55/s  (0.541s,  236.80/s)  LR: 3.906e-04  Data: 0.008 (0.008)
2024-04-07 02:37:51,315 - train - INFO - Train: 47 [ 500/781 ( 64%)]  Loss:  3.881719 (3.7239)  Time: 0.596s,  214.67/s  (0.541s,  236.72/s)  LR: 3.906e-04  Data: 0.008 (0.008)
2024-04-07 02:38:18,195 - train - INFO - Train: 47 [ 550/781 ( 71%)]  Loss:  3.573979 (3.7184)  Time: 0.480s,  266.84/s  (0.540s,  236.84/s)  LR: 3.906e-04  Data: 0.009 (0.008)
2024-04-07 02:38:44,568 - train - INFO - Train: 47 [ 600/781 ( 77%)]  Loss:  3.777854 (3.7248)  Time: 0.390s,  328.40/s  (0.539s,  237.32/s)  LR: 3.906e-04  Data: 0.005 (0.008)
2024-04-07 02:39:11,478 - train - INFO - Train: 47 [ 650/781 ( 83%)]  Loss:  3.869834 (3.7233)  Time: 0.450s,  284.33/s  (0.539s,  237.36/s)  LR: 3.906e-04  Data: 0.006 (0.008)
2024-04-07 02:39:38,096 - train - INFO - Train: 47 [ 700/781 ( 90%)]  Loss:  3.605975 (3.7210)  Time: 0.480s,  266.45/s  (0.539s,  237.58/s)  LR: 3.906e-04  Data: 0.009 (0.008)
2024-04-07 02:40:05,242 - train - INFO - Train: 47 [ 750/781 ( 96%)]  Loss:  3.665496 (3.7225)  Time: 0.547s,  233.81/s  (0.539s,  237.46/s)  LR: 3.906e-04  Data: 0.009 (0.008)
2024-04-07 02:40:21,185 - train - INFO - Train: 47 [ 780/781 (100%)]  Loss:  3.774532 (3.7246)  Time: 0.521s,  245.81/s  (0.539s,  237.58/s)  LR: 3.906e-04  Data: 0.000 (0.008)
2024-04-07 02:40:21,186 - train - INFO - True
2024-04-07 02:40:21,195 - train - INFO - alphas:tensor([0.5084, 0.0818, 0.0954, 0.1235, 0.1909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,195 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,196 - train - INFO - True
2024-04-07 02:40:21,204 - train - INFO - alphas:tensor([0.3804, 0.0453, 0.0649, 0.1176, 0.3918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,205 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,205 - train - INFO - True
2024-04-07 02:40:21,206 - train - INFO - alphas:tensor([0.4033, 0.0655, 0.1174, 0.4138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,207 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,207 - train - INFO - True
2024-04-07 02:40:21,208 - train - INFO - alphas:tensor([0.3492, 0.0573, 0.0968, 0.4967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,208 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,208 - train - INFO - True
2024-04-07 02:40:21,209 - train - INFO - alphas:tensor([0.3530, 0.0486, 0.1037, 0.4947], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,210 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,210 - train - INFO - True
2024-04-07 02:40:21,211 - train - INFO - alphas:tensor([0.4309, 0.0606, 0.0951, 0.4134], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,212 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,212 - train - INFO - True
2024-04-07 02:40:21,213 - train - INFO - alphas:tensor([0.4757, 0.0448, 0.0539, 0.0989, 0.3267], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,214 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,214 - train - INFO - True
2024-04-07 02:40:21,215 - train - INFO - alphas:tensor([0.1899, 0.0242, 0.0242, 0.0815, 0.6803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,216 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,216 - train - INFO - True
2024-04-07 02:40:21,217 - train - INFO - alphas:tensor([0.2013, 0.0210, 0.0258, 0.0711, 0.6807], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,218 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,218 - train - INFO - True
2024-04-07 02:40:21,219 - train - INFO - alphas:tensor([0.1996, 0.0178, 0.0228, 0.0753, 0.6846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,219 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,219 - train - INFO - True
2024-04-07 02:40:21,220 - train - INFO - alphas:tensor([0.1873, 0.0225, 0.0241, 0.0814, 0.6847], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,221 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,221 - train - INFO - True
2024-04-07 02:40:21,222 - train - INFO - alphas:tensor([0.4849, 0.0294, 0.0412, 0.0909, 0.3535], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,223 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,223 - train - INFO - True
2024-04-07 02:40:21,224 - train - INFO - alphas:tensor([0.5730, 0.0326, 0.0377, 0.0733, 0.2834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,228 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,228 - train - INFO - True
2024-04-07 02:40:21,229 - train - INFO - alphas:tensor([0.1906, 0.0357, 0.0360, 0.1208, 0.6170], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,231 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,231 - train - INFO - True
2024-04-07 02:40:21,232 - train - INFO - alphas:tensor([0.2064, 0.0267, 0.0320, 0.1145, 0.6204], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,234 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,234 - train - INFO - True
2024-04-07 02:40:21,235 - train - INFO - alphas:tensor([0.2275, 0.0223, 0.0306, 0.1045, 0.6151], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,237 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,237 - train - INFO - True
2024-04-07 02:40:21,238 - train - INFO - alphas:tensor([0.1995, 0.0317, 0.0355, 0.1045, 0.6289], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,240 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,240 - train - INFO - True
2024-04-07 02:40:21,241 - train - INFO - alphas:tensor([0.2270, 0.0226, 0.0347, 0.1039, 0.6118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,243 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,243 - train - INFO - True
2024-04-07 02:40:21,244 - train - INFO - alphas:tensor([0.1757, 0.0423, 0.0481, 0.1228, 0.6111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,246 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,246 - train - INFO - True
2024-04-07 02:40:21,247 - train - INFO - alphas:tensor([0.5266, 0.0224, 0.0295, 0.0793, 0.3422], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,250 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,250 - train - INFO - True
2024-04-07 02:40:21,257 - train - INFO - alphas:tensor([0.4556, 0.0202, 0.0242, 0.0797, 0.4203], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,264 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,264 - train - INFO - True
2024-04-07 02:40:21,271 - train - INFO - alphas:tensor([0.3328, 0.0189, 0.0306, 0.0933, 0.5244], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,275 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,275 - train - INFO - True
2024-04-07 02:40:21,283 - train - INFO - alphas:tensor([0.3462, 0.0193, 0.0239, 0.0912, 0.5194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,287 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,287 - train - INFO - True
2024-04-07 02:40:21,295 - train - INFO - alphas:tensor([0.3586, 0.0169, 0.0225, 0.0863, 0.5156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,299 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,299 - train - INFO - True
2024-04-07 02:40:21,300 - train - INFO - alphas:tensor([0.3325, 0.0187, 0.0279, 0.0899, 0.5310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,304 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,304 - train - INFO - True
2024-04-07 02:40:21,305 - train - INFO - alphas:tensor([0.4797, 0.0165, 0.0242, 0.0659, 0.4136], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,312 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,312 - train - INFO - True
2024-04-07 02:40:21,313 - train - INFO - alphas:tensor([0.6145, 0.0164, 0.0241, 0.0591, 0.2860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,336 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,337 - train - INFO - True
2024-04-07 02:40:21,338 - train - INFO - alphas:tensor([0.2878, 0.0167, 0.0256, 0.1001, 0.5698], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,348 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,348 - train - INFO - True
2024-04-07 02:40:21,355 - train - INFO - alphas:tensor([0.2993, 0.0144, 0.0220, 0.0931, 0.5711], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,365 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,365 - train - INFO - True
2024-04-07 02:40:21,372 - train - INFO - alphas:tensor([0.3257, 0.0141, 0.0197, 0.0882, 0.5522], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,382 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,382 - train - INFO - True
2024-04-07 02:40:21,389 - train - INFO - alphas:tensor([0.2955, 0.0172, 0.0229, 0.0936, 0.5708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,399 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,399 - train - INFO - True
2024-04-07 02:40:21,400 - train - INFO - alphas:tensor([0.6257, 0.0127, 0.0166, 0.0483, 0.2967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,420 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,420 - train - INFO - True
2024-04-07 02:40:21,421 - train - INFO - alphas:tensor([0.4697, 0.0240, 0.0306, 0.0835, 0.3922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:40:21,498 - train - INFO - tau:0.6361854860638709
2024-04-07 02:40:21,498 - train - INFO - avg block size:10.272727272727273
2024-04-07 02:40:21,499 - train - INFO - current latency ratio:tensor(0.2324)
2024-04-07 02:40:21,716 - train - INFO - Test: [   0/78]  Time: 0.213 (0.213)  Loss:  1.0029 (1.0029)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.1875 (92.1875)
2024-04-07 02:40:26,812 - train - INFO - Test: [  50/78]  Time: 0.075 (0.104)  Loss:  1.6006 (1.6518)  Acc@1: 66.4062 (62.8983)  Acc@5: 84.3750 (85.0031)
2024-04-07 02:40:29,973 - train - INFO - Test: [  78/78]  Time: 0.095 (0.107)  Loss:  1.9541 (1.6712)  Acc@1: 43.7500 (62.8400)  Acc@5: 100.0000 (84.6200)
2024-04-07 02:40:30,851 - train - INFO - Train: 48 [   0/781 (  0%)]  Loss:  4.032961 (4.0330)  Time: 0.747s,  171.31/s  (0.747s,  171.31/s)  LR: 3.863e-04  Data: 0.176 (0.176)
2024-04-07 02:40:57,268 - train - INFO - Train: 48 [  50/781 (  6%)]  Loss:  3.997955 (3.7281)  Time: 0.546s,  234.46/s  (0.533s,  240.34/s)  LR: 3.863e-04  Data: 0.008 (0.011)
2024-04-07 02:41:25,008 - train - INFO - Train: 48 [ 100/781 ( 13%)]  Loss:  3.586171 (3.7358)  Time: 0.568s,  225.48/s  (0.544s,  235.48/s)  LR: 3.863e-04  Data: 0.006 (0.009)
2024-04-07 02:41:51,506 - train - INFO - Train: 48 [ 150/781 ( 19%)]  Loss:  3.950407 (3.7220)  Time: 0.403s,  317.82/s  (0.539s,  237.45/s)  LR: 3.863e-04  Data: 0.004 (0.009)
2024-04-07 02:42:18,381 - train - INFO - Train: 48 [ 200/781 ( 26%)]  Loss:  3.680809 (3.7333)  Time: 0.420s,  304.88/s  (0.539s,  237.63/s)  LR: 3.863e-04  Data: 0.004 (0.008)
2024-04-07 02:42:44,325 - train - INFO - Train: 48 [ 250/781 ( 32%)]  Loss:  4.015023 (3.7234)  Time: 0.504s,  253.95/s  (0.535s,  239.39/s)  LR: 3.863e-04  Data: 0.012 (0.008)
2024-04-07 02:43:11,271 - train - INFO - Train: 48 [ 300/781 ( 38%)]  Loss:  3.623576 (3.7232)  Time: 0.580s,  220.83/s  (0.535s,  239.08/s)  LR: 3.863e-04  Data: 0.006 (0.008)
2024-04-07 02:43:37,732 - train - INFO - Train: 48 [ 350/781 ( 45%)]  Loss:  3.981626 (3.7358)  Time: 0.410s,  311.95/s  (0.535s,  239.47/s)  LR: 3.863e-04  Data: 0.007 (0.008)
2024-04-07 02:44:04,500 - train - INFO - Train: 48 [ 400/781 ( 51%)]  Loss:  3.931451 (3.7387)  Time: 0.589s,  217.41/s  (0.535s,  239.43/s)  LR: 3.863e-04  Data: 0.008 (0.008)
2024-04-07 02:44:29,838 - train - INFO - Train: 48 [ 450/781 ( 58%)]  Loss:  3.964813 (3.7394)  Time: 0.525s,  244.01/s  (0.532s,  240.82/s)  LR: 3.863e-04  Data: 0.009 (0.008)
2024-04-07 02:44:57,117 - train - INFO - Train: 48 [ 500/781 ( 64%)]  Loss:  3.954264 (3.7419)  Time: 0.691s,  185.12/s  (0.533s,  240.19/s)  LR: 3.863e-04  Data: 0.007 (0.008)
2024-04-07 02:45:24,180 - train - INFO - Train: 48 [ 550/781 ( 71%)]  Loss:  3.874234 (3.7411)  Time: 0.523s,  244.56/s  (0.534s,  239.85/s)  LR: 3.863e-04  Data: 0.009 (0.008)
2024-04-07 02:45:51,028 - train - INFO - Train: 48 [ 600/781 ( 77%)]  Loss:  3.790977 (3.7406)  Time: 0.537s,  238.14/s  (0.534s,  239.73/s)  LR: 3.863e-04  Data: 0.009 (0.008)
2024-04-07 02:46:17,543 - train - INFO - Train: 48 [ 650/781 ( 83%)]  Loss:  3.624860 (3.7365)  Time: 0.520s,  246.38/s  (0.534s,  239.85/s)  LR: 3.863e-04  Data: 0.005 (0.008)
2024-04-07 02:46:44,238 - train - INFO - Train: 48 [ 700/781 ( 90%)]  Loss:  3.920573 (3.7342)  Time: 0.545s,  234.83/s  (0.534s,  239.85/s)  LR: 3.863e-04  Data: 0.006 (0.008)
2024-04-07 02:47:09,872 - train - INFO - Train: 48 [ 750/781 ( 96%)]  Loss:  3.951310 (3.7352)  Time: 0.476s,  268.97/s  (0.532s,  240.48/s)  LR: 3.863e-04  Data: 0.006 (0.008)
2024-04-07 02:47:26,092 - train - INFO - Train: 48 [ 780/781 (100%)]  Loss:  3.768605 (3.7323)  Time: 0.539s,  237.66/s  (0.533s,  240.33/s)  LR: 3.863e-04  Data: 0.000 (0.008)
2024-04-07 02:47:26,093 - train - INFO - True
2024-04-07 02:47:26,102 - train - INFO - alphas:tensor([0.5112, 0.0803, 0.0951, 0.1225, 0.1909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,102 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,102 - train - INFO - True
2024-04-07 02:47:26,121 - train - INFO - alphas:tensor([0.3802, 0.0440, 0.0637, 0.1168, 0.3953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,122 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,122 - train - INFO - True
2024-04-07 02:47:26,131 - train - INFO - alphas:tensor([0.4066, 0.0637, 0.1152, 0.4145], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,131 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,131 - train - INFO - True
2024-04-07 02:47:26,133 - train - INFO - alphas:tensor([0.3498, 0.0564, 0.0948, 0.4990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,133 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,133 - train - INFO - True
2024-04-07 02:47:26,134 - train - INFO - alphas:tensor([0.3523, 0.0478, 0.1026, 0.4973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,135 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,135 - train - INFO - True
2024-04-07 02:47:26,136 - train - INFO - alphas:tensor([0.4325, 0.0592, 0.0940, 0.4143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,136 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,137 - train - INFO - True
2024-04-07 02:47:26,138 - train - INFO - alphas:tensor([0.4781, 0.0437, 0.0529, 0.0970, 0.3284], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,139 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,139 - train - INFO - True
2024-04-07 02:47:26,140 - train - INFO - alphas:tensor([0.1919, 0.0241, 0.0234, 0.0808, 0.6797], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,140 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,140 - train - INFO - True
2024-04-07 02:47:26,141 - train - INFO - alphas:tensor([0.2015, 0.0204, 0.0249, 0.0701, 0.6831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,142 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,142 - train - INFO - True
2024-04-07 02:47:26,143 - train - INFO - alphas:tensor([0.2006, 0.0172, 0.0224, 0.0739, 0.6859], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,144 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,144 - train - INFO - True
2024-04-07 02:47:26,145 - train - INFO - alphas:tensor([0.1867, 0.0219, 0.0237, 0.0805, 0.6873], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,145 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,146 - train - INFO - True
2024-04-07 02:47:26,146 - train - INFO - alphas:tensor([0.4852, 0.0287, 0.0406, 0.0906, 0.3550], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,148 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,148 - train - INFO - True
2024-04-07 02:47:26,149 - train - INFO - alphas:tensor([0.5768, 0.0316, 0.0365, 0.0714, 0.2837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,152 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,152 - train - INFO - True
2024-04-07 02:47:26,153 - train - INFO - alphas:tensor([0.1933, 0.0352, 0.0355, 0.1216, 0.6143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,155 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,155 - train - INFO - True
2024-04-07 02:47:26,156 - train - INFO - alphas:tensor([0.2078, 0.0264, 0.0315, 0.1135, 0.6208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,158 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,158 - train - INFO - True
2024-04-07 02:47:26,159 - train - INFO - alphas:tensor([0.2292, 0.0218, 0.0298, 0.1043, 0.6149], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,161 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,161 - train - INFO - True
2024-04-07 02:47:26,162 - train - INFO - alphas:tensor([0.2003, 0.0309, 0.0348, 0.1030, 0.6310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,164 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,164 - train - INFO - True
2024-04-07 02:47:26,165 - train - INFO - alphas:tensor([0.2272, 0.0222, 0.0345, 0.1044, 0.6118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,167 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,167 - train - INFO - True
2024-04-07 02:47:26,168 - train - INFO - alphas:tensor([0.1791, 0.0422, 0.0479, 0.1228, 0.6079], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,170 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,170 - train - INFO - True
2024-04-07 02:47:26,171 - train - INFO - alphas:tensor([0.5315, 0.0216, 0.0289, 0.0784, 0.3396], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,175 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,175 - train - INFO - True
2024-04-07 02:47:26,181 - train - INFO - alphas:tensor([0.4588, 0.0197, 0.0236, 0.0791, 0.4188], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,189 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,189 - train - INFO - True
2024-04-07 02:47:26,196 - train - INFO - alphas:tensor([0.3369, 0.0184, 0.0296, 0.0908, 0.5244], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,200 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,200 - train - INFO - True
2024-04-07 02:47:26,207 - train - INFO - alphas:tensor([0.3495, 0.0186, 0.0230, 0.0899, 0.5190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,211 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,211 - train - INFO - True
2024-04-07 02:47:26,219 - train - INFO - alphas:tensor([0.3658, 0.0164, 0.0216, 0.0855, 0.5106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,223 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,223 - train - INFO - True
2024-04-07 02:47:26,224 - train - INFO - alphas:tensor([0.3304, 0.0180, 0.0272, 0.0898, 0.5346], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,228 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,228 - train - INFO - True
2024-04-07 02:47:26,229 - train - INFO - alphas:tensor([0.4766, 0.0161, 0.0238, 0.0664, 0.4170], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,236 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,236 - train - INFO - True
2024-04-07 02:47:26,237 - train - INFO - alphas:tensor([0.6237, 0.0160, 0.0233, 0.0574, 0.2796], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,257 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,257 - train - INFO - True
2024-04-07 02:47:26,258 - train - INFO - alphas:tensor([0.2922, 0.0168, 0.0254, 0.0999, 0.5658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,269 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,269 - train - INFO - True
2024-04-07 02:47:26,277 - train - INFO - alphas:tensor([0.3036, 0.0141, 0.0213, 0.0916, 0.5694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,287 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,288 - train - INFO - True
2024-04-07 02:47:26,295 - train - INFO - alphas:tensor([0.3304, 0.0138, 0.0194, 0.0889, 0.5475], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,305 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,305 - train - INFO - True
2024-04-07 02:47:26,312 - train - INFO - alphas:tensor([0.2947, 0.0167, 0.0223, 0.0924, 0.5739], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,322 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,322 - train - INFO - True
2024-04-07 02:47:26,323 - train - INFO - alphas:tensor([0.6275, 0.0122, 0.0161, 0.0477, 0.2966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,342 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,343 - train - INFO - True
2024-04-07 02:47:26,344 - train - INFO - alphas:tensor([0.4693, 0.0235, 0.0300, 0.0834, 0.3937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:47:26,421 - train - INFO - tau:0.6298236312032323
2024-04-07 02:47:26,421 - train - INFO - avg block size:10.272727272727273
2024-04-07 02:47:26,422 - train - INFO - current latency ratio:tensor(0.2324)
2024-04-07 02:47:26,422 - train - INFO - lasso_alpha:2.0000000000000005e-05
2024-04-07 02:47:26,697 - train - INFO - Test: [   0/78]  Time: 0.272 (0.272)  Loss:  1.0527 (1.0527)  Acc@1: 80.4688 (80.4688)  Acc@5: 94.5312 (94.5312)
2024-04-07 02:47:31,831 - train - INFO - Test: [  50/78]  Time: 0.101 (0.106)  Loss:  1.5332 (1.6536)  Acc@1: 66.4062 (63.5110)  Acc@5: 88.2812 (85.0950)
2024-04-07 02:47:34,248 - train - INFO - Test: [  78/78]  Time: 0.048 (0.099)  Loss:  2.0039 (1.6736)  Acc@1: 43.7500 (63.0400)  Acc@5: 81.2500 (84.7000)
2024-04-07 02:47:34,972 - train - INFO - Train: 49 [   0/781 (  0%)]  Loss:  3.965706 (3.9657)  Time: 0.644s,  198.70/s  (0.644s,  198.70/s)  LR: 3.819e-04  Data: 0.178 (0.178)
2024-04-07 02:48:02,008 - train - INFO - Train: 49 [  50/781 (  6%)]  Loss:  3.865904 (3.7378)  Time: 0.550s,  232.85/s  (0.543s,  235.85/s)  LR: 3.819e-04  Data: 0.008 (0.011)
2024-04-07 02:48:27,774 - train - INFO - Train: 49 [ 100/781 ( 13%)]  Loss:  3.467002 (3.7156)  Time: 0.479s,  267.13/s  (0.529s,  241.90/s)  LR: 3.819e-04  Data: 0.009 (0.009)
2024-04-07 02:48:54,933 - train - INFO - Train: 49 [ 150/781 ( 19%)]  Loss:  3.961763 (3.7334)  Time: 0.548s,  233.74/s  (0.534s,  239.80/s)  LR: 3.819e-04  Data: 0.008 (0.009)
2024-04-07 02:49:21,964 - train - INFO - Train: 49 [ 200/781 ( 26%)]  Loss:  4.079023 (3.7251)  Time: 0.505s,  253.66/s  (0.535s,  239.04/s)  LR: 3.819e-04  Data: 0.009 (0.009)
2024-04-07 02:49:49,256 - train - INFO - Train: 49 [ 250/781 ( 32%)]  Loss:  3.975603 (3.7139)  Time: 0.471s,  271.88/s  (0.538s,  238.13/s)  LR: 3.819e-04  Data: 0.008 (0.008)
2024-04-07 02:50:15,623 - train - INFO - Train: 49 [ 300/781 ( 38%)]  Loss:  4.079437 (3.7130)  Time: 0.469s,  273.08/s  (0.536s,  238.88/s)  LR: 3.819e-04  Data: 0.009 (0.008)
2024-04-07 02:50:41,272 - train - INFO - Train: 49 [ 350/781 ( 45%)]  Loss:  3.799429 (3.7112)  Time: 0.527s,  242.67/s  (0.533s,  240.34/s)  LR: 3.819e-04  Data: 0.008 (0.008)
2024-04-07 02:51:07,039 - train - INFO - Train: 49 [ 400/781 ( 51%)]  Loss:  4.059213 (3.7182)  Time: 0.468s,  273.62/s  (0.530s,  241.32/s)  LR: 3.819e-04  Data: 0.005 (0.008)
2024-04-07 02:51:31,484 - train - INFO - Train: 49 [ 450/781 ( 58%)]  Loss:  3.402843 (3.7146)  Time: 0.557s,  229.88/s  (0.526s,  243.43/s)  LR: 3.819e-04  Data: 0.005 (0.008)
2024-04-07 02:51:58,325 - train - INFO - Train: 49 [ 500/781 ( 64%)]  Loss:  3.467262 (3.7222)  Time: 0.591s,  216.52/s  (0.527s,  242.93/s)  LR: 3.819e-04  Data: 0.008 (0.008)
2024-04-07 02:52:25,947 - train - INFO - Train: 49 [ 550/781 ( 71%)]  Loss:  3.849569 (3.7267)  Time: 0.545s,  234.78/s  (0.529s,  241.87/s)  LR: 3.819e-04  Data: 0.008 (0.008)
2024-04-07 02:52:51,021 - train - INFO - Train: 49 [ 600/781 ( 77%)]  Loss:  3.767571 (3.7298)  Time: 0.535s,  239.46/s  (0.527s,  242.93/s)  LR: 3.819e-04  Data: 0.005 (0.008)
2024-04-07 02:53:18,252 - train - INFO - Train: 49 [ 650/781 ( 83%)]  Loss:  3.705046 (3.7275)  Time: 0.415s,  308.26/s  (0.528s,  242.30/s)  LR: 3.819e-04  Data: 0.004 (0.008)
2024-04-07 02:53:43,723 - train - INFO - Train: 49 [ 700/781 ( 90%)]  Loss:  3.860083 (3.7256)  Time: 0.457s,  279.80/s  (0.527s,  242.92/s)  LR: 3.819e-04  Data: 0.007 (0.008)
2024-04-07 02:54:10,748 - train - INFO - Train: 49 [ 750/781 ( 96%)]  Loss:  3.646494 (3.7220)  Time: 1.130s,  113.32/s  (0.528s,  242.51/s)  LR: 3.819e-04  Data: 0.009 (0.008)
2024-04-07 02:54:25,801 - train - INFO - Train: 49 [ 780/781 (100%)]  Loss:  3.984397 (3.7224)  Time: 0.552s,  232.04/s  (0.527s,  242.97/s)  LR: 3.819e-04  Data: 0.000 (0.008)
2024-04-07 02:54:25,802 - train - INFO - True
2024-04-07 02:54:25,811 - train - INFO - alphas:tensor([0.5161, 0.0790, 0.0929, 0.1214, 0.1907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,812 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,812 - train - INFO - True
2024-04-07 02:54:25,821 - train - INFO - alphas:tensor([0.3844, 0.0432, 0.0624, 0.1151, 0.3948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,821 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,821 - train - INFO - True
2024-04-07 02:54:25,830 - train - INFO - alphas:tensor([0.4110, 0.0625, 0.1141, 0.4124], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,831 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,831 - train - INFO - True
2024-04-07 02:54:25,832 - train - INFO - alphas:tensor([0.3520, 0.0555, 0.0930, 0.4995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,833 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,833 - train - INFO - True
2024-04-07 02:54:25,835 - train - INFO - alphas:tensor([0.3581, 0.0468, 0.1010, 0.4941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,835 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,835 - train - INFO - True
2024-04-07 02:54:25,837 - train - INFO - alphas:tensor([0.4343, 0.0587, 0.0927, 0.4143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,838 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,838 - train - INFO - True
2024-04-07 02:54:25,839 - train - INFO - alphas:tensor([0.4797, 0.0425, 0.0515, 0.0961, 0.3301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,841 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,841 - train - INFO - True
2024-04-07 02:54:25,842 - train - INFO - alphas:tensor([0.1945, 0.0237, 0.0227, 0.0806, 0.6785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,843 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,844 - train - INFO - True
2024-04-07 02:54:25,845 - train - INFO - alphas:tensor([0.2083, 0.0201, 0.0245, 0.0686, 0.6785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,846 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,846 - train - INFO - True
2024-04-07 02:54:25,847 - train - INFO - alphas:tensor([0.2077, 0.0169, 0.0220, 0.0713, 0.6820], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,848 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,848 - train - INFO - True
2024-04-07 02:54:25,849 - train - INFO - alphas:tensor([0.1907, 0.0213, 0.0232, 0.0802, 0.6845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,850 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,851 - train - INFO - True
2024-04-07 02:54:25,852 - train - INFO - alphas:tensor([0.4878, 0.0280, 0.0399, 0.0895, 0.3548], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,853 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,853 - train - INFO - True
2024-04-07 02:54:25,855 - train - INFO - alphas:tensor([0.5771, 0.0311, 0.0357, 0.0704, 0.2858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,859 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,859 - train - INFO - True
2024-04-07 02:54:25,861 - train - INFO - alphas:tensor([0.1987, 0.0347, 0.0354, 0.1214, 0.6099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,863 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,863 - train - INFO - True
2024-04-07 02:54:25,864 - train - INFO - alphas:tensor([0.2151, 0.0264, 0.0317, 0.1149, 0.6118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,867 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,867 - train - INFO - True
2024-04-07 02:54:25,868 - train - INFO - alphas:tensor([0.2385, 0.0218, 0.0295, 0.1040, 0.6061], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,870 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,870 - train - INFO - True
2024-04-07 02:54:25,871 - train - INFO - alphas:tensor([0.2061, 0.0310, 0.0347, 0.1033, 0.6248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,874 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,874 - train - INFO - True
2024-04-07 02:54:25,875 - train - INFO - alphas:tensor([0.2348, 0.0217, 0.0336, 0.1025, 0.6073], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,877 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,877 - train - INFO - True
2024-04-07 02:54:25,885 - train - INFO - alphas:tensor([0.1837, 0.0420, 0.0478, 0.1215, 0.6050], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,887 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,887 - train - INFO - True
2024-04-07 02:54:25,894 - train - INFO - alphas:tensor([0.5371, 0.0208, 0.0276, 0.0763, 0.3382], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,898 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,898 - train - INFO - True
2024-04-07 02:54:25,906 - train - INFO - alphas:tensor([0.4624, 0.0192, 0.0233, 0.0774, 0.4177], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,914 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,914 - train - INFO - True
2024-04-07 02:54:25,921 - train - INFO - alphas:tensor([0.3405, 0.0177, 0.0295, 0.0908, 0.5213], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,925 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,925 - train - INFO - True
2024-04-07 02:54:25,926 - train - INFO - alphas:tensor([0.3567, 0.0180, 0.0224, 0.0887, 0.5142], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,930 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,930 - train - INFO - True
2024-04-07 02:54:25,931 - train - INFO - alphas:tensor([0.3707, 0.0160, 0.0214, 0.0848, 0.5070], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,935 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,935 - train - INFO - True
2024-04-07 02:54:25,936 - train - INFO - alphas:tensor([0.3373, 0.0176, 0.0267, 0.0884, 0.5301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,940 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,940 - train - INFO - True
2024-04-07 02:54:25,941 - train - INFO - alphas:tensor([0.4872, 0.0158, 0.0235, 0.0656, 0.4079], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,948 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,948 - train - INFO - True
2024-04-07 02:54:25,949 - train - INFO - alphas:tensor([0.6261, 0.0152, 0.0228, 0.0565, 0.2795], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,969 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,969 - train - INFO - True
2024-04-07 02:54:25,970 - train - INFO - alphas:tensor([0.2975, 0.0164, 0.0249, 0.1010, 0.5601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,980 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,980 - train - INFO - True
2024-04-07 02:54:25,981 - train - INFO - alphas:tensor([0.3125, 0.0138, 0.0209, 0.0904, 0.5623], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:25,991 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:25,992 - train - INFO - True
2024-04-07 02:54:25,993 - train - INFO - alphas:tensor([0.3352, 0.0135, 0.0189, 0.0875, 0.5449], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:26,003 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:26,003 - train - INFO - True
2024-04-07 02:54:26,004 - train - INFO - alphas:tensor([0.2975, 0.0161, 0.0216, 0.0912, 0.5737], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:26,014 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:26,014 - train - INFO - True
2024-04-07 02:54:26,015 - train - INFO - alphas:tensor([0.6329, 0.0119, 0.0156, 0.0462, 0.2934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:26,035 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:26,035 - train - INFO - True
2024-04-07 02:54:26,036 - train - INFO - alphas:tensor([0.4764, 0.0230, 0.0292, 0.0818, 0.3896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:54:26,114 - train - INFO - tau:0.6235253948912
2024-04-07 02:54:26,114 - train - INFO - avg block size:10.272727272727273
2024-04-07 02:54:26,114 - train - INFO - current latency ratio:tensor(0.2324)
2024-04-07 02:54:26,302 - train - INFO - Test: [   0/78]  Time: 0.184 (0.184)  Loss:  0.9717 (0.9717)  Acc@1: 81.2500 (81.2500)  Acc@5: 92.9688 (92.9688)
2024-04-07 02:54:32,117 - train - INFO - Test: [  50/78]  Time: 0.104 (0.118)  Loss:  1.7363 (1.6705)  Acc@1: 59.3750 (63.0362)  Acc@5: 82.8125 (84.3903)
2024-04-07 02:54:35,151 - train - INFO - Test: [  78/78]  Time: 0.099 (0.114)  Loss:  2.1074 (1.6991)  Acc@1: 56.2500 (62.3100)  Acc@5: 93.7500 (83.9500)
2024-04-07 02:54:35,941 - train - INFO - Train: 50 [   0/781 (  0%)]  Loss:  4.006600 (4.0066)  Time: 0.706s,  181.31/s  (0.706s,  181.31/s)  LR: 3.775e-04  Data: 0.173 (0.173)
2024-04-07 02:55:03,849 - train - INFO - Train: 50 [  50/781 (  6%)]  Loss:  3.735349 (3.7362)  Time: 1.084s,  118.10/s  (0.561s,  228.16/s)  LR: 3.775e-04  Data: 0.008 (0.011)
2024-04-07 02:55:29,601 - train - INFO - Train: 50 [ 100/781 ( 13%)]  Loss:  3.853758 (3.7284)  Time: 0.457s,  280.34/s  (0.538s,  237.81/s)  LR: 3.775e-04  Data: 0.007 (0.009)
2024-04-07 02:55:57,313 - train - INFO - Train: 50 [ 150/781 ( 19%)]  Loss:  3.988155 (3.7308)  Time: 1.129s,  113.42/s  (0.544s,  235.50/s)  LR: 3.775e-04  Data: 0.008 (0.009)
2024-04-07 02:56:23,558 - train - INFO - Train: 50 [ 200/781 ( 26%)]  Loss:  3.976477 (3.7419)  Time: 0.535s,  239.46/s  (0.539s,  237.53/s)  LR: 3.775e-04  Data: 0.006 (0.009)
2024-04-07 02:56:49,260 - train - INFO - Train: 50 [ 250/781 ( 32%)]  Loss:  4.011124 (3.7236)  Time: 0.309s,  414.69/s  (0.534s,  239.73/s)  LR: 3.775e-04  Data: 0.004 (0.008)
2024-04-07 02:57:15,556 - train - INFO - Train: 50 [ 300/781 ( 38%)]  Loss:  4.056668 (3.7232)  Time: 0.452s,  283.24/s  (0.533s,  240.33/s)  LR: 3.775e-04  Data: 0.005 (0.008)
2024-04-07 02:57:42,804 - train - INFO - Train: 50 [ 350/781 ( 45%)]  Loss:  3.936431 (3.7167)  Time: 0.493s,  259.40/s  (0.534s,  239.54/s)  LR: 3.775e-04  Data: 0.007 (0.008)
2024-04-07 02:58:10,195 - train - INFO - Train: 50 [ 400/781 ( 51%)]  Loss:  3.474465 (3.7141)  Time: 0.579s,  221.11/s  (0.536s,  238.79/s)  LR: 3.775e-04  Data: 0.006 (0.008)
2024-04-07 02:58:37,551 - train - INFO - Train: 50 [ 450/781 ( 58%)]  Loss:  3.812045 (3.7134)  Time: 0.897s,  142.65/s  (0.537s,  238.25/s)  LR: 3.775e-04  Data: 0.007 (0.008)
2024-04-07 02:59:03,356 - train - INFO - Train: 50 [ 500/781 ( 64%)]  Loss:  4.064867 (3.7121)  Time: 0.536s,  238.90/s  (0.535s,  239.19/s)  LR: 3.775e-04  Data: 0.008 (0.008)
2024-04-07 02:59:29,843 - train - INFO - Train: 50 [ 550/781 ( 71%)]  Loss:  3.624486 (3.7128)  Time: 0.512s,  249.76/s  (0.535s,  239.41/s)  LR: 3.775e-04  Data: 0.009 (0.008)
2024-04-07 02:59:55,982 - train - INFO - Train: 50 [ 600/781 ( 77%)]  Loss:  3.713291 (3.7169)  Time: 0.404s,  316.85/s  (0.534s,  239.86/s)  LR: 3.775e-04  Data: 0.007 (0.008)
2024-04-07 03:00:21,929 - train - INFO - Train: 50 [ 650/781 ( 83%)]  Loss:  3.462111 (3.7144)  Time: 0.557s,  229.80/s  (0.533s,  240.37/s)  LR: 3.775e-04  Data: 0.007 (0.008)
2024-04-07 03:00:49,121 - train - INFO - Train: 50 [ 700/781 ( 90%)]  Loss:  3.891809 (3.7165)  Time: 0.542s,  236.16/s  (0.533s,  240.00/s)  LR: 3.775e-04  Data: 0.008 (0.008)
2024-04-07 03:01:14,384 - train - INFO - Train: 50 [ 750/781 ( 96%)]  Loss:  3.947476 (3.7171)  Time: 0.530s,  241.62/s  (0.531s,  240.85/s)  LR: 3.775e-04  Data: 0.009 (0.008)
2024-04-07 03:01:29,152 - train - INFO - Train: 50 [ 780/781 (100%)]  Loss:  3.971016 (3.7184)  Time: 0.518s,  247.32/s  (0.530s,  241.53/s)  LR: 3.775e-04  Data: 0.000 (0.008)
2024-04-07 03:01:29,153 - train - INFO - True
2024-04-07 03:01:29,161 - train - INFO - alphas:tensor([0.5210, 0.0773, 0.0920, 0.1197, 0.1900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,162 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,162 - train - INFO - True
2024-04-07 03:01:29,166 - train - INFO - alphas:tensor([0.3831, 0.0426, 0.0622, 0.1145, 0.3977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,166 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,167 - train - INFO - True
2024-04-07 03:01:29,168 - train - INFO - alphas:tensor([0.4091, 0.0612, 0.1133, 0.4164], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,169 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,169 - train - INFO - True
2024-04-07 03:01:29,170 - train - INFO - alphas:tensor([0.3584, 0.0542, 0.0913, 0.4962], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,171 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,171 - train - INFO - True
2024-04-07 03:01:29,173 - train - INFO - alphas:tensor([0.3567, 0.0460, 0.0995, 0.4978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,174 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,174 - train - INFO - True
2024-04-07 03:01:29,175 - train - INFO - alphas:tensor([0.4375, 0.0569, 0.0916, 0.4140], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,176 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,176 - train - INFO - True
2024-04-07 03:01:29,178 - train - INFO - alphas:tensor([0.4852, 0.0411, 0.0502, 0.0933, 0.3301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,179 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,180 - train - INFO - True
2024-04-07 03:01:29,181 - train - INFO - alphas:tensor([0.1972, 0.0235, 0.0226, 0.0799, 0.6767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,182 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,182 - train - INFO - True
2024-04-07 03:01:29,184 - train - INFO - alphas:tensor([0.2081, 0.0196, 0.0240, 0.0674, 0.6809], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,185 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,185 - train - INFO - True
2024-04-07 03:01:29,186 - train - INFO - alphas:tensor([0.2077, 0.0168, 0.0218, 0.0713, 0.6825], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,187 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,187 - train - INFO - True
2024-04-07 03:01:29,188 - train - INFO - alphas:tensor([0.1966, 0.0209, 0.0228, 0.0786, 0.6812], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,189 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,189 - train - INFO - True
2024-04-07 03:01:29,191 - train - INFO - alphas:tensor([0.4890, 0.0271, 0.0387, 0.0874, 0.3578], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,192 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,192 - train - INFO - True
2024-04-07 03:01:29,194 - train - INFO - alphas:tensor([0.5796, 0.0303, 0.0348, 0.0689, 0.2865], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,198 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,199 - train - INFO - True
2024-04-07 03:01:29,200 - train - INFO - alphas:tensor([0.1993, 0.0341, 0.0349, 0.1216, 0.6100], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,202 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,203 - train - INFO - True
2024-04-07 03:01:29,204 - train - INFO - alphas:tensor([0.2135, 0.0253, 0.0307, 0.1129, 0.6176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,206 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,206 - train - INFO - True
2024-04-07 03:01:29,208 - train - INFO - alphas:tensor([0.2362, 0.0215, 0.0293, 0.1034, 0.6096], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,210 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,210 - train - INFO - True
2024-04-07 03:01:29,218 - train - INFO - alphas:tensor([0.2078, 0.0303, 0.0343, 0.1028, 0.6248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,220 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,220 - train - INFO - True
2024-04-07 03:01:29,227 - train - INFO - alphas:tensor([0.2344, 0.0209, 0.0331, 0.0998, 0.6119], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,229 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,230 - train - INFO - True
2024-04-07 03:01:29,236 - train - INFO - alphas:tensor([0.1861, 0.0408, 0.0470, 0.1185, 0.6075], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,238 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,239 - train - INFO - True
2024-04-07 03:01:29,245 - train - INFO - alphas:tensor([0.5397, 0.0202, 0.0271, 0.0755, 0.3376], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,249 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,249 - train - INFO - True
2024-04-07 03:01:29,257 - train - INFO - alphas:tensor([0.4681, 0.0186, 0.0221, 0.0754, 0.4158], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,264 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,264 - train - INFO - True
2024-04-07 03:01:29,265 - train - INFO - alphas:tensor([0.3424, 0.0170, 0.0287, 0.0893, 0.5226], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,269 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,269 - train - INFO - True
2024-04-07 03:01:29,270 - train - INFO - alphas:tensor([0.3623, 0.0177, 0.0220, 0.0870, 0.5111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,274 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,274 - train - INFO - True
2024-04-07 03:01:29,275 - train - INFO - alphas:tensor([0.3696, 0.0154, 0.0210, 0.0852, 0.5087], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,279 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,279 - train - INFO - True
2024-04-07 03:01:29,280 - train - INFO - alphas:tensor([0.3377, 0.0172, 0.0264, 0.0885, 0.5302], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,284 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,284 - train - INFO - True
2024-04-07 03:01:29,285 - train - INFO - alphas:tensor([0.4865, 0.0151, 0.0228, 0.0643, 0.4113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,292 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,292 - train - INFO - True
2024-04-07 03:01:29,293 - train - INFO - alphas:tensor([0.6325, 0.0146, 0.0218, 0.0552, 0.2759], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,313 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,313 - train - INFO - True
2024-04-07 03:01:29,321 - train - INFO - alphas:tensor([0.2978, 0.0158, 0.0243, 0.0987, 0.5634], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,331 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,331 - train - INFO - True
2024-04-07 03:01:29,339 - train - INFO - alphas:tensor([0.3132, 0.0135, 0.0205, 0.0910, 0.5618], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,349 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,349 - train - INFO - True
2024-04-07 03:01:29,350 - train - INFO - alphas:tensor([0.3367, 0.0130, 0.0183, 0.0844, 0.5477], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,360 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,360 - train - INFO - True
2024-04-07 03:01:29,361 - train - INFO - alphas:tensor([0.2997, 0.0161, 0.0216, 0.0919, 0.5707], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,371 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,371 - train - INFO - True
2024-04-07 03:01:29,372 - train - INFO - alphas:tensor([0.6373, 0.0118, 0.0153, 0.0454, 0.2902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,391 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,392 - train - INFO - True
2024-04-07 03:01:29,400 - train - INFO - alphas:tensor([0.4717, 0.0227, 0.0292, 0.0828, 0.3935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:01:29,480 - train - INFO - tau:0.617290140942288
2024-04-07 03:01:29,480 - train - INFO - avg block size:10.272727272727273
2024-04-07 03:01:29,481 - train - INFO - current latency ratio:tensor(0.2324)
2024-04-07 03:01:29,481 - train - INFO - lasso_alpha:1.8181818181818185e-05
2024-04-07 03:01:29,690 - train - INFO - Test: [   0/78]  Time: 0.205 (0.205)  Loss:  1.1631 (1.1631)  Acc@1: 75.7812 (75.7812)  Acc@5: 90.6250 (90.6250)
2024-04-07 03:01:34,140 - train - INFO - Test: [  50/78]  Time: 0.053 (0.091)  Loss:  1.6357 (1.6427)  Acc@1: 63.2812 (62.2702)  Acc@5: 84.3750 (84.6507)
2024-04-07 03:01:37,501 - train - INFO - Test: [  78/78]  Time: 0.093 (0.101)  Loss:  1.9756 (1.6572)  Acc@1: 62.5000 (62.1800)  Acc@5: 87.5000 (84.1500)
2024-04-07 03:01:38,292 - train - INFO - Train: 51 [   0/781 (  0%)]  Loss:  4.074693 (4.0747)  Time: 0.710s,  180.17/s  (0.710s,  180.17/s)  LR: 3.730e-04  Data: 0.183 (0.183)
2024-04-07 03:02:05,110 - train - INFO - Train: 51 [  50/781 (  6%)]  Loss:  3.676815 (3.7244)  Time: 0.567s,  225.74/s  (0.540s,  237.14/s)  LR: 3.730e-04  Data: 0.010 (0.011)
2024-04-07 03:02:31,724 - train - INFO - Train: 51 [ 100/781 ( 13%)]  Loss:  3.765976 (3.7172)  Time: 0.442s,  289.70/s  (0.536s,  238.79/s)  LR: 3.730e-04  Data: 0.007 (0.010)
2024-04-07 03:02:57,312 - train - INFO - Train: 51 [ 150/781 ( 19%)]  Loss:  4.010839 (3.6947)  Time: 0.565s,  226.45/s  (0.528s,  242.43/s)  LR: 3.730e-04  Data: 0.006 (0.009)
2024-04-07 03:03:23,774 - train - INFO - Train: 51 [ 200/781 ( 26%)]  Loss:  3.679763 (3.6975)  Time: 0.393s,  326.03/s  (0.528s,  242.29/s)  LR: 3.730e-04  Data: 0.007 (0.008)
2024-04-07 03:03:49,714 - train - INFO - Train: 51 [ 250/781 ( 32%)]  Loss:  3.996642 (3.7031)  Time: 0.574s,  223.00/s  (0.526s,  243.16/s)  LR: 3.730e-04  Data: 0.008 (0.008)
2024-04-07 03:04:15,540 - train - INFO - Train: 51 [ 300/781 ( 38%)]  Loss:  3.846146 (3.7022)  Time: 0.493s,  259.53/s  (0.525s,  243.93/s)  LR: 3.730e-04  Data: 0.009 (0.008)
2024-04-07 03:04:41,998 - train - INFO - Train: 51 [ 350/781 ( 45%)]  Loss:  3.903190 (3.7058)  Time: 0.535s,  239.20/s  (0.525s,  243.64/s)  LR: 3.730e-04  Data: 0.007 (0.008)
2024-04-07 03:05:08,488 - train - INFO - Train: 51 [ 400/781 ( 51%)]  Loss:  3.594558 (3.7008)  Time: 0.591s,  216.51/s  (0.526s,  243.38/s)  LR: 3.730e-04  Data: 0.009 (0.008)
2024-04-07 03:05:35,376 - train - INFO - Train: 51 [ 450/781 ( 58%)]  Loss:  3.544142 (3.7036)  Time: 0.453s,  282.48/s  (0.527s,  242.78/s)  LR: 3.730e-04  Data: 0.006 (0.008)
2024-04-07 03:06:01,435 - train - INFO - Train: 51 [ 500/781 ( 64%)]  Loss:  3.782367 (3.7033)  Time: 0.534s,  239.63/s  (0.527s,  243.06/s)  LR: 3.730e-04  Data: 0.007 (0.008)
2024-04-07 03:06:27,852 - train - INFO - Train: 51 [ 550/781 ( 71%)]  Loss:  3.275259 (3.7023)  Time: 0.637s,  201.07/s  (0.527s,  242.99/s)  LR: 3.730e-04  Data: 0.011 (0.008)
2024-04-07 03:06:55,090 - train - INFO - Train: 51 [ 600/781 ( 77%)]  Loss:  3.385333 (3.7069)  Time: 0.558s,  229.57/s  (0.528s,  242.30/s)  LR: 3.730e-04  Data: 0.007 (0.008)
2024-04-07 03:07:21,301 - train - INFO - Train: 51 [ 650/781 ( 83%)]  Loss:  3.428222 (3.7040)  Time: 0.532s,  240.76/s  (0.528s,  242.45/s)  LR: 3.730e-04  Data: 0.005 (0.008)
2024-04-07 03:07:46,638 - train - INFO - Train: 51 [ 700/781 ( 90%)]  Loss:  3.471403 (3.7006)  Time: 0.555s,  230.54/s  (0.526s,  243.14/s)  LR: 3.730e-04  Data: 0.009 (0.008)
2024-04-07 03:08:13,610 - train - INFO - Train: 51 [ 750/781 ( 96%)]  Loss:  3.899867 (3.7018)  Time: 0.544s,  235.50/s  (0.527s,  242.74/s)  LR: 3.730e-04  Data: 0.005 (0.008)
2024-04-07 03:08:29,725 - train - INFO - Train: 51 [ 780/781 (100%)]  Loss:  3.826466 (3.7011)  Time: 0.463s,  276.63/s  (0.528s,  242.57/s)  LR: 3.730e-04  Data: 0.000 (0.008)
2024-04-07 03:08:29,727 - train - INFO - True
2024-04-07 03:08:29,729 - train - INFO - alphas:tensor([0.5225, 0.0764, 0.0907, 0.1190, 0.1913], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,730 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,730 - train - INFO - True
2024-04-07 03:08:29,732 - train - INFO - alphas:tensor([0.3888, 0.0414, 0.0604, 0.1128, 0.3966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,733 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,733 - train - INFO - True
2024-04-07 03:08:29,734 - train - INFO - alphas:tensor([0.4151, 0.0607, 0.1113, 0.4128], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,736 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,736 - train - INFO - True
2024-04-07 03:08:29,738 - train - INFO - alphas:tensor([0.3617, 0.0528, 0.0898, 0.4956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,738 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,739 - train - INFO - True
2024-04-07 03:08:29,740 - train - INFO - alphas:tensor([0.3667, 0.0453, 0.0979, 0.4901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,741 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,741 - train - INFO - True
2024-04-07 03:08:29,743 - train - INFO - alphas:tensor([0.4445, 0.0566, 0.0898, 0.4090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,744 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,744 - train - INFO - True
2024-04-07 03:08:29,746 - train - INFO - alphas:tensor([0.4889, 0.0406, 0.0491, 0.0920, 0.3293], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,747 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,748 - train - INFO - True
2024-04-07 03:08:29,749 - train - INFO - alphas:tensor([0.1975, 0.0229, 0.0223, 0.0794, 0.6780], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,750 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,750 - train - INFO - True
2024-04-07 03:08:29,752 - train - INFO - alphas:tensor([0.2143, 0.0194, 0.0237, 0.0662, 0.6764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,753 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,753 - train - INFO - True
2024-04-07 03:08:29,754 - train - INFO - alphas:tensor([0.2128, 0.0163, 0.0213, 0.0708, 0.6787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,755 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,756 - train - INFO - True
2024-04-07 03:08:29,764 - train - INFO - alphas:tensor([0.1998, 0.0202, 0.0222, 0.0788, 0.6790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,765 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,765 - train - INFO - True
2024-04-07 03:08:29,773 - train - INFO - alphas:tensor([0.4928, 0.0262, 0.0378, 0.0849, 0.3582], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,774 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,775 - train - INFO - True
2024-04-07 03:08:29,782 - train - INFO - alphas:tensor([0.5793, 0.0295, 0.0341, 0.0682, 0.2889], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,787 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,787 - train - INFO - True
2024-04-07 03:08:29,794 - train - INFO - alphas:tensor([0.2036, 0.0336, 0.0350, 0.1200, 0.6077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,796 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,796 - train - INFO - True
2024-04-07 03:08:29,804 - train - INFO - alphas:tensor([0.2192, 0.0249, 0.0302, 0.1126, 0.6131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,806 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,806 - train - INFO - True
2024-04-07 03:08:29,807 - train - INFO - alphas:tensor([0.2419, 0.0214, 0.0289, 0.1014, 0.6063], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,810 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,810 - train - INFO - True
2024-04-07 03:08:29,811 - train - INFO - alphas:tensor([0.2143, 0.0301, 0.0340, 0.1014, 0.6203], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,813 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,813 - train - INFO - True
2024-04-07 03:08:29,814 - train - INFO - alphas:tensor([0.2419, 0.0212, 0.0328, 0.1018, 0.6023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,816 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,816 - train - INFO - True
2024-04-07 03:08:29,817 - train - INFO - alphas:tensor([0.1889, 0.0403, 0.0462, 0.1164, 0.6082], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,819 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,820 - train - INFO - True
2024-04-07 03:08:29,821 - train - INFO - alphas:tensor([0.5459, 0.0196, 0.0264, 0.0739, 0.3342], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,824 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,824 - train - INFO - True
2024-04-07 03:08:29,825 - train - INFO - alphas:tensor([0.4746, 0.0180, 0.0214, 0.0743, 0.4116], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,833 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,833 - train - INFO - True
2024-04-07 03:08:29,834 - train - INFO - alphas:tensor([0.3455, 0.0166, 0.0284, 0.0893, 0.5201], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,838 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,838 - train - INFO - True
2024-04-07 03:08:29,839 - train - INFO - alphas:tensor([0.3651, 0.0172, 0.0211, 0.0860, 0.5106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,843 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,843 - train - INFO - True
2024-04-07 03:08:29,844 - train - INFO - alphas:tensor([0.3819, 0.0150, 0.0200, 0.0831, 0.5001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,848 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,848 - train - INFO - True
2024-04-07 03:08:29,849 - train - INFO - alphas:tensor([0.3424, 0.0170, 0.0255, 0.0879, 0.5273], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,853 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,853 - train - INFO - True
2024-04-07 03:08:29,860 - train - INFO - alphas:tensor([0.4967, 0.0147, 0.0223, 0.0641, 0.4022], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,868 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,868 - train - INFO - True
2024-04-07 03:08:29,875 - train - INFO - alphas:tensor([0.6351, 0.0140, 0.0209, 0.0544, 0.2756], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,896 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,896 - train - INFO - True
2024-04-07 03:08:29,897 - train - INFO - alphas:tensor([0.3051, 0.0159, 0.0242, 0.0986, 0.5562], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,907 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,907 - train - INFO - True
2024-04-07 03:08:29,908 - train - INFO - alphas:tensor([0.3162, 0.0130, 0.0204, 0.0891, 0.5613], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,918 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,918 - train - INFO - True
2024-04-07 03:08:29,919 - train - INFO - alphas:tensor([0.3501, 0.0126, 0.0176, 0.0833, 0.5363], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,929 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,929 - train - INFO - True
2024-04-07 03:08:29,930 - train - INFO - alphas:tensor([0.3106, 0.0157, 0.0214, 0.0902, 0.5621], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,940 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,940 - train - INFO - True
2024-04-07 03:08:29,947 - train - INFO - alphas:tensor([0.6409, 0.0114, 0.0146, 0.0444, 0.2887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:29,967 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:29,967 - train - INFO - True
2024-04-07 03:08:29,974 - train - INFO - alphas:tensor([0.4814, 0.0225, 0.0288, 0.0822, 0.3851], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:08:30,052 - train - INFO - tau:0.6111172395328651
2024-04-07 03:08:30,052 - train - INFO - avg block size:10.06060606060606
2024-04-07 03:08:30,052 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 03:08:30,290 - train - INFO - Test: [   0/78]  Time: 0.234 (0.234)  Loss:  1.0449 (1.0449)  Acc@1: 77.3438 (77.3438)  Acc@5: 92.9688 (92.9688)
2024-04-07 03:08:35,438 - train - INFO - Test: [  50/78]  Time: 0.100 (0.106)  Loss:  1.7529 (1.6677)  Acc@1: 60.9375 (62.4847)  Acc@5: 85.1562 (84.6048)
2024-04-07 03:08:38,087 - train - INFO - Test: [  78/78]  Time: 0.096 (0.102)  Loss:  1.9805 (1.6827)  Acc@1: 43.7500 (62.4500)  Acc@5: 100.0000 (84.2200)
2024-04-07 03:08:38,941 - train - INFO - Train: 52 [   0/781 (  0%)]  Loss:  3.823397 (3.8234)  Time: 0.774s,  165.47/s  (0.774s,  165.47/s)  LR: 3.685e-04  Data: 0.194 (0.194)
2024-04-07 03:09:05,935 - train - INFO - Train: 52 [  50/781 (  6%)]  Loss:  4.026726 (3.7469)  Time: 0.534s,  239.77/s  (0.544s,  235.10/s)  LR: 3.685e-04  Data: 0.009 (0.012)
2024-04-07 03:09:32,680 - train - INFO - Train: 52 [ 100/781 ( 13%)]  Loss:  3.806694 (3.7293)  Time: 0.537s,  238.39/s  (0.540s,  237.17/s)  LR: 3.685e-04  Data: 0.010 (0.010)
2024-04-07 03:09:59,286 - train - INFO - Train: 52 [ 150/781 ( 19%)]  Loss:  3.530149 (3.7246)  Time: 0.367s,  349.16/s  (0.537s,  238.28/s)  LR: 3.685e-04  Data: 0.005 (0.009)
2024-04-07 03:10:25,030 - train - INFO - Train: 52 [ 200/781 ( 26%)]  Loss:  3.759403 (3.7296)  Time: 0.523s,  244.68/s  (0.532s,  240.77/s)  LR: 3.685e-04  Data: 0.012 (0.009)
2024-04-07 03:10:51,685 - train - INFO - Train: 52 [ 250/781 ( 32%)]  Loss:  3.575486 (3.7278)  Time: 0.490s,  261.20/s  (0.532s,  240.64/s)  LR: 3.685e-04  Data: 0.008 (0.009)
2024-04-07 03:11:17,833 - train - INFO - Train: 52 [ 300/781 ( 38%)]  Loss:  3.791970 (3.7285)  Time: 0.464s,  276.15/s  (0.530s,  241.32/s)  LR: 3.685e-04  Data: 0.007 (0.008)
2024-04-07 03:11:44,341 - train - INFO - Train: 52 [ 350/781 ( 45%)]  Loss:  3.337869 (3.7193)  Time: 0.641s,  199.55/s  (0.530s,  241.34/s)  LR: 3.685e-04  Data: 0.007 (0.008)
2024-04-07 03:12:10,233 - train - INFO - Train: 52 [ 400/781 ( 51%)]  Loss:  3.473440 (3.7154)  Time: 0.383s,  334.06/s  (0.529s,  242.05/s)  LR: 3.685e-04  Data: 0.007 (0.008)
2024-04-07 03:12:36,939 - train - INFO - Train: 52 [ 450/781 ( 58%)]  Loss:  3.598075 (3.7145)  Time: 0.765s,  167.29/s  (0.529s,  241.78/s)  LR: 3.685e-04  Data: 0.010 (0.008)
2024-04-07 03:13:04,058 - train - INFO - Train: 52 [ 500/781 ( 64%)]  Loss:  3.945014 (3.7148)  Time: 0.494s,  259.26/s  (0.531s,  241.20/s)  LR: 3.685e-04  Data: 0.008 (0.008)
2024-04-07 03:13:31,190 - train - INFO - Train: 52 [ 550/781 ( 71%)]  Loss:  3.083265 (3.7158)  Time: 1.152s,  111.11/s  (0.532s,  240.71/s)  LR: 3.685e-04  Data: 0.005 (0.008)
2024-04-07 03:13:58,336 - train - INFO - Train: 52 [ 600/781 ( 77%)]  Loss:  3.447221 (3.7129)  Time: 0.558s,  229.49/s  (0.533s,  240.29/s)  LR: 3.685e-04  Data: 0.009 (0.008)
2024-04-07 03:14:24,919 - train - INFO - Train: 52 [ 650/781 ( 83%)]  Loss:  3.458666 (3.7111)  Time: 1.056s,  121.18/s  (0.533s,  240.32/s)  LR: 3.685e-04  Data: 0.005 (0.008)
2024-04-07 03:14:51,758 - train - INFO - Train: 52 [ 700/781 ( 90%)]  Loss:  3.531492 (3.7107)  Time: 0.586s,  218.50/s  (0.533s,  240.19/s)  LR: 3.685e-04  Data: 0.009 (0.008)
2024-04-07 03:15:18,967 - train - INFO - Train: 52 [ 750/781 ( 96%)]  Loss:  3.973484 (3.7113)  Time: 0.478s,  267.68/s  (0.534s,  239.85/s)  LR: 3.685e-04  Data: 0.008 (0.008)
2024-04-07 03:15:34,613 - train - INFO - Train: 52 [ 780/781 (100%)]  Loss:  3.933388 (3.7092)  Time: 0.483s,  265.05/s  (0.533s,  240.06/s)  LR: 3.685e-04  Data: 0.000 (0.008)
2024-04-07 03:15:34,614 - train - INFO - True
2024-04-07 03:15:34,616 - train - INFO - alphas:tensor([0.5255, 0.0750, 0.0900, 0.1182, 0.1913], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,617 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,618 - train - INFO - True
2024-04-07 03:15:34,619 - train - INFO - alphas:tensor([0.3908, 0.0403, 0.0587, 0.1113, 0.3988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,620 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,620 - train - INFO - True
2024-04-07 03:15:34,621 - train - INFO - alphas:tensor([0.4168, 0.0596, 0.1106, 0.4130], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,622 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,623 - train - INFO - True
2024-04-07 03:15:34,624 - train - INFO - alphas:tensor([0.3639, 0.0524, 0.0879, 0.4958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,625 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,625 - train - INFO - True
2024-04-07 03:15:34,626 - train - INFO - alphas:tensor([0.3665, 0.0445, 0.0965, 0.4924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,627 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,627 - train - INFO - True
2024-04-07 03:15:34,629 - train - INFO - alphas:tensor([0.4464, 0.0553, 0.0881, 0.4102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,630 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,630 - train - INFO - True
2024-04-07 03:15:34,631 - train - INFO - alphas:tensor([0.4920, 0.0396, 0.0479, 0.0902, 0.3303], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,633 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,633 - train - INFO - True
2024-04-07 03:15:34,634 - train - INFO - alphas:tensor([0.2046, 0.0231, 0.0224, 0.0789, 0.6710], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,635 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,636 - train - INFO - True
2024-04-07 03:15:34,637 - train - INFO - alphas:tensor([0.2158, 0.0188, 0.0230, 0.0652, 0.6771], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,638 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,638 - train - INFO - True
2024-04-07 03:15:34,639 - train - INFO - alphas:tensor([0.2141, 0.0160, 0.0206, 0.0702, 0.6791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,640 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,640 - train - INFO - True
2024-04-07 03:15:34,642 - train - INFO - alphas:tensor([0.2027, 0.0198, 0.0216, 0.0786, 0.6773], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,643 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,643 - train - INFO - True
2024-04-07 03:15:34,644 - train - INFO - alphas:tensor([0.4952, 0.0254, 0.0367, 0.0835, 0.3592], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,646 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,646 - train - INFO - True
2024-04-07 03:15:34,647 - train - INFO - alphas:tensor([0.5864, 0.0285, 0.0331, 0.0668, 0.2853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,652 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,652 - train - INFO - True
2024-04-07 03:15:34,653 - train - INFO - alphas:tensor([0.2067, 0.0335, 0.0340, 0.1168, 0.6090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,656 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,656 - train - INFO - True
2024-04-07 03:15:34,657 - train - INFO - alphas:tensor([0.2244, 0.0244, 0.0302, 0.1111, 0.6099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,659 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,660 - train - INFO - True
2024-04-07 03:15:34,661 - train - INFO - alphas:tensor([0.2438, 0.0211, 0.0285, 0.1013, 0.6053], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,663 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,663 - train - INFO - True
2024-04-07 03:15:34,664 - train - INFO - alphas:tensor([0.2171, 0.0291, 0.0336, 0.1006, 0.6196], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,667 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,667 - train - INFO - True
2024-04-07 03:15:34,668 - train - INFO - alphas:tensor([0.2410, 0.0209, 0.0329, 0.1008, 0.6044], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,670 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,670 - train - INFO - True
2024-04-07 03:15:34,672 - train - INFO - alphas:tensor([0.1949, 0.0405, 0.0456, 0.1168, 0.6022], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,674 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,674 - train - INFO - True
2024-04-07 03:15:34,675 - train - INFO - alphas:tensor([0.5483, 0.0191, 0.0260, 0.0719, 0.3347], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,679 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,679 - train - INFO - True
2024-04-07 03:15:34,680 - train - INFO - alphas:tensor([0.4774, 0.0174, 0.0207, 0.0737, 0.4108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,689 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,689 - train - INFO - True
2024-04-07 03:15:34,690 - train - INFO - alphas:tensor([0.3542, 0.0164, 0.0278, 0.0882, 0.5135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,694 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,694 - train - INFO - True
2024-04-07 03:15:34,695 - train - INFO - alphas:tensor([0.3718, 0.0168, 0.0207, 0.0860, 0.5046], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,699 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,699 - train - INFO - True
2024-04-07 03:15:34,700 - train - INFO - alphas:tensor([0.3850, 0.0143, 0.0191, 0.0819, 0.4997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,704 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,705 - train - INFO - True
2024-04-07 03:15:34,705 - train - INFO - alphas:tensor([0.3463, 0.0165, 0.0251, 0.0882, 0.5238], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,709 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,710 - train - INFO - True
2024-04-07 03:15:34,710 - train - INFO - alphas:tensor([0.5016, 0.0145, 0.0221, 0.0628, 0.3990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,718 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,718 - train - INFO - True
2024-04-07 03:15:34,719 - train - INFO - alphas:tensor([0.6346, 0.0136, 0.0209, 0.0549, 0.2761], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,738 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,738 - train - INFO - True
2024-04-07 03:15:34,739 - train - INFO - alphas:tensor([0.3113, 0.0157, 0.0235, 0.0985, 0.5510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,750 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,750 - train - INFO - True
2024-04-07 03:15:34,751 - train - INFO - alphas:tensor([0.3203, 0.0128, 0.0201, 0.0896, 0.5572], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,761 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,761 - train - INFO - True
2024-04-07 03:15:34,762 - train - INFO - alphas:tensor([0.3526, 0.0124, 0.0172, 0.0838, 0.5341], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,772 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,772 - train - INFO - True
2024-04-07 03:15:34,773 - train - INFO - alphas:tensor([0.3116, 0.0155, 0.0209, 0.0895, 0.5626], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,783 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,783 - train - INFO - True
2024-04-07 03:15:34,784 - train - INFO - alphas:tensor([0.6428, 0.0109, 0.0144, 0.0445, 0.2874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,803 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,803 - train - INFO - True
2024-04-07 03:15:34,804 - train - INFO - alphas:tensor([0.4870, 0.0219, 0.0284, 0.0816, 0.3811], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:15:34,902 - train - INFO - tau:0.6050060671375365
2024-04-07 03:15:34,902 - train - INFO - avg block size:10.06060606060606
2024-04-07 03:15:34,903 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 03:15:34,903 - train - INFO - lasso_alpha:1.652892561983471e-05
2024-04-07 03:15:35,093 - train - INFO - Test: [   0/78]  Time: 0.183 (0.183)  Loss:  0.8843 (0.8843)  Acc@1: 82.8125 (82.8125)  Acc@5: 94.5312 (94.5312)
2024-04-07 03:15:40,956 - train - INFO - Test: [  50/78]  Time: 0.119 (0.119)  Loss:  1.7178 (1.6484)  Acc@1: 61.7188 (62.3468)  Acc@5: 83.5938 (84.8499)
2024-04-07 03:15:43,763 - train - INFO - Test: [  78/78]  Time: 0.095 (0.112)  Loss:  2.0098 (1.6591)  Acc@1: 50.0000 (62.1000)  Acc@5: 100.0000 (84.6700)
2024-04-07 03:15:44,616 - train - INFO - Train: 53 [   0/781 (  0%)]  Loss:  3.693230 (3.6932)  Time: 0.685s,  186.78/s  (0.685s,  186.78/s)  LR: 3.639e-04  Data: 0.181 (0.181)
2024-04-07 03:16:11,696 - train - INFO - Train: 53 [  50/781 (  6%)]  Loss:  3.389806 (3.7254)  Time: 1.067s,  119.96/s  (0.544s,  235.13/s)  LR: 3.639e-04  Data: 0.007 (0.011)
2024-04-07 03:16:39,104 - train - INFO - Train: 53 [ 100/781 ( 13%)]  Loss:  3.859375 (3.7267)  Time: 0.545s,  235.04/s  (0.546s,  234.33/s)  LR: 3.639e-04  Data: 0.009 (0.010)
2024-04-07 03:17:05,544 - train - INFO - Train: 53 [ 150/781 ( 19%)]  Loss:  3.514483 (3.7116)  Time: 0.498s,  256.94/s  (0.540s,  236.84/s)  LR: 3.639e-04  Data: 0.009 (0.009)
2024-04-07 03:17:30,989 - train - INFO - Train: 53 [ 200/781 ( 26%)]  Loss:  3.782875 (3.7111)  Time: 0.535s,  239.04/s  (0.533s,  240.33/s)  LR: 3.639e-04  Data: 0.006 (0.008)
2024-04-07 03:17:56,791 - train - INFO - Train: 53 [ 250/781 ( 32%)]  Loss:  3.504500 (3.7077)  Time: 0.475s,  269.27/s  (0.529s,  241.83/s)  LR: 3.639e-04  Data: 0.012 (0.008)
2024-04-07 03:18:22,266 - train - INFO - Train: 53 [ 300/781 ( 38%)]  Loss:  3.495903 (3.7012)  Time: 0.469s,  273.20/s  (0.526s,  243.35/s)  LR: 3.639e-04  Data: 0.013 (0.008)
2024-04-07 03:18:49,395 - train - INFO - Train: 53 [ 350/781 ( 45%)]  Loss:  3.589612 (3.6957)  Time: 0.535s,  239.15/s  (0.528s,  242.26/s)  LR: 3.639e-04  Data: 0.008 (0.008)
2024-04-07 03:19:15,957 - train - INFO - Train: 53 [ 400/781 ( 51%)]  Loss:  3.387088 (3.6988)  Time: 0.524s,  244.48/s  (0.529s,  242.10/s)  LR: 3.639e-04  Data: 0.006 (0.008)
2024-04-07 03:19:42,339 - train - INFO - Train: 53 [ 450/781 ( 58%)]  Loss:  3.775826 (3.7021)  Time: 0.559s,  229.14/s  (0.529s,  242.15/s)  LR: 3.639e-04  Data: 0.007 (0.008)
2024-04-07 03:20:09,712 - train - INFO - Train: 53 [ 500/781 ( 64%)]  Loss:  3.643831 (3.7034)  Time: 0.527s,  243.00/s  (0.530s,  241.30/s)  LR: 3.639e-04  Data: 0.008 (0.008)
2024-04-07 03:20:36,011 - train - INFO - Train: 53 [ 550/781 ( 71%)]  Loss:  3.505322 (3.6997)  Time: 0.542s,  236.18/s  (0.530s,  241.48/s)  LR: 3.639e-04  Data: 0.009 (0.008)
2024-04-07 03:21:02,438 - train - INFO - Train: 53 [ 600/781 ( 77%)]  Loss:  3.948372 (3.7007)  Time: 0.504s,  254.06/s  (0.530s,  241.54/s)  LR: 3.639e-04  Data: 0.009 (0.008)
2024-04-07 03:21:27,551 - train - INFO - Train: 53 [ 650/781 ( 83%)]  Loss:  3.759065 (3.7031)  Time: 0.413s,  310.14/s  (0.528s,  242.51/s)  LR: 3.639e-04  Data: 0.004 (0.008)
2024-04-07 03:21:54,028 - train - INFO - Train: 53 [ 700/781 ( 90%)]  Loss:  3.525480 (3.7016)  Time: 0.545s,  234.68/s  (0.528s,  242.46/s)  LR: 3.639e-04  Data: 0.005 (0.008)
2024-04-07 03:22:20,925 - train - INFO - Train: 53 [ 750/781 ( 96%)]  Loss:  3.659904 (3.7023)  Time: 0.524s,  244.44/s  (0.529s,  242.15/s)  LR: 3.639e-04  Data: 0.007 (0.008)
2024-04-07 03:22:36,270 - train - INFO - Train: 53 [ 780/781 (100%)]  Loss:  3.759595 (3.7025)  Time: 0.521s,  245.82/s  (0.528s,  242.46/s)  LR: 3.639e-04  Data: 0.000 (0.008)
2024-04-07 03:22:36,271 - train - INFO - True
2024-04-07 03:22:36,273 - train - INFO - alphas:tensor([0.5290, 0.0739, 0.0891, 0.1169, 0.1911], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,274 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,274 - train - INFO - True
2024-04-07 03:22:36,276 - train - INFO - alphas:tensor([0.3902, 0.0393, 0.0583, 0.1109, 0.4012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,276 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,277 - train - INFO - True
2024-04-07 03:22:36,278 - train - INFO - alphas:tensor([0.4205, 0.0584, 0.1087, 0.4123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,279 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,279 - train - INFO - True
2024-04-07 03:22:36,280 - train - INFO - alphas:tensor([0.3696, 0.0514, 0.0867, 0.4923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,281 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,281 - train - INFO - True
2024-04-07 03:22:36,283 - train - INFO - alphas:tensor([0.3722, 0.0438, 0.0952, 0.4887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,283 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,283 - train - INFO - True
2024-04-07 03:22:36,285 - train - INFO - alphas:tensor([0.4496, 0.0551, 0.0866, 0.4088], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,286 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,286 - train - INFO - True
2024-04-07 03:22:36,287 - train - INFO - alphas:tensor([0.4957, 0.0385, 0.0468, 0.0888, 0.3303], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,289 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,289 - train - INFO - True
2024-04-07 03:22:36,290 - train - INFO - alphas:tensor([0.2102, 0.0226, 0.0223, 0.0787, 0.6661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,291 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,291 - train - INFO - True
2024-04-07 03:22:36,293 - train - INFO - alphas:tensor([0.2204, 0.0185, 0.0225, 0.0650, 0.6737], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,293 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,294 - train - INFO - True
2024-04-07 03:22:36,295 - train - INFO - alphas:tensor([0.2193, 0.0153, 0.0200, 0.0683, 0.6771], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,296 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,296 - train - INFO - True
2024-04-07 03:22:36,297 - train - INFO - alphas:tensor([0.2073, 0.0196, 0.0213, 0.0781, 0.6737], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,298 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,298 - train - INFO - True
2024-04-07 03:22:36,299 - train - INFO - alphas:tensor([0.5003, 0.0246, 0.0359, 0.0829, 0.3564], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,301 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,301 - train - INFO - True
2024-04-07 03:22:36,302 - train - INFO - alphas:tensor([0.5915, 0.0276, 0.0320, 0.0651, 0.2838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,307 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,307 - train - INFO - True
2024-04-07 03:22:36,308 - train - INFO - alphas:tensor([0.2126, 0.0335, 0.0339, 0.1151, 0.6049], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,310 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,310 - train - INFO - True
2024-04-07 03:22:36,312 - train - INFO - alphas:tensor([0.2301, 0.0239, 0.0296, 0.1102, 0.6063], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,314 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,314 - train - INFO - True
2024-04-07 03:22:36,315 - train - INFO - alphas:tensor([0.2536, 0.0208, 0.0283, 0.1023, 0.5950], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,317 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,318 - train - INFO - True
2024-04-07 03:22:36,325 - train - INFO - alphas:tensor([0.2221, 0.0287, 0.0332, 0.0998, 0.6162], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,327 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,328 - train - INFO - True
2024-04-07 03:22:36,335 - train - INFO - alphas:tensor([0.2485, 0.0213, 0.0325, 0.1002, 0.5975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,337 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,337 - train - INFO - True
2024-04-07 03:22:36,346 - train - INFO - alphas:tensor([0.1992, 0.0393, 0.0445, 0.1153, 0.6017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,348 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,349 - train - INFO - True
2024-04-07 03:22:36,356 - train - INFO - alphas:tensor([0.5505, 0.0186, 0.0255, 0.0718, 0.3337], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,360 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,360 - train - INFO - True
2024-04-07 03:22:36,366 - train - INFO - alphas:tensor([0.4827, 0.0169, 0.0204, 0.0737, 0.4062], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,374 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,374 - train - INFO - True
2024-04-07 03:22:36,375 - train - INFO - alphas:tensor([0.3602, 0.0156, 0.0273, 0.0862, 0.5108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,379 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,379 - train - INFO - True
2024-04-07 03:22:36,380 - train - INFO - alphas:tensor([0.3738, 0.0164, 0.0202, 0.0852, 0.5044], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,383 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,384 - train - INFO - True
2024-04-07 03:22:36,384 - train - INFO - alphas:tensor([0.3948, 0.0138, 0.0187, 0.0799, 0.4928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,388 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,388 - train - INFO - True
2024-04-07 03:22:36,389 - train - INFO - alphas:tensor([0.3583, 0.0162, 0.0251, 0.0867, 0.5137], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,393 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,393 - train - INFO - True
2024-04-07 03:22:36,394 - train - INFO - alphas:tensor([0.5034, 0.0144, 0.0215, 0.0625, 0.3982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,402 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,402 - train - INFO - True
2024-04-07 03:22:36,403 - train - INFO - alphas:tensor([0.6447, 0.0130, 0.0198, 0.0526, 0.2699], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,422 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,422 - train - INFO - True
2024-04-07 03:22:36,431 - train - INFO - alphas:tensor([0.3120, 0.0152, 0.0229, 0.0972, 0.5526], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,441 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,441 - train - INFO - True
2024-04-07 03:22:36,448 - train - INFO - alphas:tensor([0.3276, 0.0122, 0.0198, 0.0886, 0.5518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,459 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,459 - train - INFO - True
2024-04-07 03:22:36,460 - train - INFO - alphas:tensor([0.3579, 0.0119, 0.0165, 0.0821, 0.5317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,470 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,470 - train - INFO - True
2024-04-07 03:22:36,471 - train - INFO - alphas:tensor([0.3189, 0.0148, 0.0201, 0.0863, 0.5600], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,481 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,482 - train - INFO - True
2024-04-07 03:22:36,482 - train - INFO - alphas:tensor([0.6458, 0.0106, 0.0138, 0.0437, 0.2861], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,502 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,502 - train - INFO - True
2024-04-07 03:22:36,503 - train - INFO - alphas:tensor([0.4923, 0.0214, 0.0273, 0.0803, 0.3787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:22:36,581 - train - INFO - tau:0.5989560064661611
2024-04-07 03:22:36,581 - train - INFO - avg block size:10.06060606060606
2024-04-07 03:22:36,581 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 03:22:36,860 - train - INFO - Test: [   0/78]  Time: 0.275 (0.275)  Loss:  1.0000 (1.0000)  Acc@1: 78.9062 (78.9062)  Acc@5: 91.4062 (91.4062)
2024-04-07 03:22:42,483 - train - INFO - Test: [  50/78]  Time: 0.171 (0.116)  Loss:  1.8115 (1.6499)  Acc@1: 62.5000 (62.2549)  Acc@5: 79.6875 (84.4210)
2024-04-07 03:22:45,421 - train - INFO - Test: [  78/78]  Time: 0.139 (0.112)  Loss:  1.9229 (1.6617)  Acc@1: 62.5000 (62.2600)  Acc@5: 87.5000 (84.0600)
2024-04-07 03:22:46,295 - train - INFO - Train: 54 [   0/781 (  0%)]  Loss:  3.996064 (3.9961)  Time: 0.757s,  169.09/s  (0.757s,  169.09/s)  LR: 3.593e-04  Data: 0.190 (0.190)
2024-04-07 03:23:13,263 - train - INFO - Train: 54 [  50/781 (  6%)]  Loss:  3.259518 (3.6992)  Time: 0.534s,  239.74/s  (0.544s,  235.47/s)  LR: 3.593e-04  Data: 0.009 (0.012)
2024-04-07 03:23:39,085 - train - INFO - Train: 54 [ 100/781 ( 13%)]  Loss:  4.144187 (3.6914)  Time: 1.049s,  122.01/s  (0.530s,  241.45/s)  LR: 3.593e-04  Data: 0.008 (0.009)
2024-04-07 03:24:04,962 - train - INFO - Train: 54 [ 150/781 ( 19%)]  Loss:  3.702269 (3.6992)  Time: 0.429s,  298.45/s  (0.526s,  243.37/s)  LR: 3.593e-04  Data: 0.004 (0.009)
2024-04-07 03:24:32,552 - train - INFO - Train: 54 [ 200/781 ( 26%)]  Loss:  3.450043 (3.6922)  Time: 0.896s,  142.78/s  (0.532s,  240.43/s)  LR: 3.593e-04  Data: 0.008 (0.009)
2024-04-07 03:24:58,827 - train - INFO - Train: 54 [ 250/781 ( 32%)]  Loss:  3.831252 (3.6834)  Time: 0.543s,  235.75/s  (0.531s,  241.06/s)  LR: 3.593e-04  Data: 0.010 (0.008)
2024-04-07 03:25:24,428 - train - INFO - Train: 54 [ 300/781 ( 38%)]  Loss:  3.543297 (3.6851)  Time: 0.512s,  249.77/s  (0.528s,  242.50/s)  LR: 3.593e-04  Data: 0.009 (0.008)
2024-04-07 03:25:51,193 - train - INFO - Train: 54 [ 350/781 ( 45%)]  Loss:  3.796682 (3.6840)  Time: 0.537s,  238.35/s  (0.529s,  242.01/s)  LR: 3.593e-04  Data: 0.005 (0.008)
2024-04-07 03:26:17,033 - train - INFO - Train: 54 [ 400/781 ( 51%)]  Loss:  4.016375 (3.6924)  Time: 0.540s,  236.98/s  (0.527s,  242.71/s)  LR: 3.593e-04  Data: 0.012 (0.008)
2024-04-07 03:26:44,345 - train - INFO - Train: 54 [ 450/781 ( 58%)]  Loss:  4.092936 (3.6953)  Time: 0.472s,  271.40/s  (0.529s,  241.75/s)  LR: 3.593e-04  Data: 0.009 (0.008)
2024-04-07 03:27:10,527 - train - INFO - Train: 54 [ 500/781 ( 64%)]  Loss:  3.969344 (3.6945)  Time: 0.368s,  348.04/s  (0.529s,  242.02/s)  LR: 3.593e-04  Data: 0.004 (0.008)
2024-04-07 03:27:37,757 - train - INFO - Train: 54 [ 550/781 ( 71%)]  Loss:  4.022069 (3.6977)  Time: 0.489s,  261.78/s  (0.530s,  241.37/s)  LR: 3.593e-04  Data: 0.005 (0.008)
2024-04-07 03:28:04,152 - train - INFO - Train: 54 [ 600/781 ( 77%)]  Loss:  3.758376 (3.6937)  Time: 0.496s,  258.04/s  (0.530s,  241.46/s)  LR: 3.593e-04  Data: 0.006 (0.008)
2024-04-07 03:28:31,680 - train - INFO - Train: 54 [ 650/781 ( 83%)]  Loss:  4.113683 (3.6968)  Time: 0.556s,  230.21/s  (0.532s,  240.75/s)  LR: 3.593e-04  Data: 0.007 (0.008)
2024-04-07 03:28:58,318 - train - INFO - Train: 54 [ 700/781 ( 90%)]  Loss:  3.439296 (3.6981)  Time: 0.482s,  265.66/s  (0.532s,  240.71/s)  LR: 3.593e-04  Data: 0.010 (0.008)
2024-04-07 03:29:24,832 - train - INFO - Train: 54 [ 750/781 ( 96%)]  Loss:  3.590095 (3.7001)  Time: 0.539s,  237.62/s  (0.532s,  240.76/s)  LR: 3.593e-04  Data: 0.010 (0.008)
2024-04-07 03:29:41,108 - train - INFO - Train: 54 [ 780/781 (100%)]  Loss:  3.424788 (3.7008)  Time: 0.537s,  238.52/s  (0.532s,  240.57/s)  LR: 3.593e-04  Data: 0.000 (0.008)
2024-04-07 03:29:41,109 - train - INFO - True
2024-04-07 03:29:41,111 - train - INFO - alphas:tensor([0.5335, 0.0727, 0.0877, 0.1157, 0.1905], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,112 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,112 - train - INFO - True
2024-04-07 03:29:41,113 - train - INFO - alphas:tensor([0.3966, 0.0385, 0.0570, 0.1085, 0.3995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,114 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,114 - train - INFO - True
2024-04-07 03:29:41,115 - train - INFO - alphas:tensor([0.4278, 0.0569, 0.1060, 0.4093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,116 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,116 - train - INFO - True
2024-04-07 03:29:41,118 - train - INFO - alphas:tensor([0.3736, 0.0509, 0.0861, 0.4894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,118 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,118 - train - INFO - True
2024-04-07 03:29:41,120 - train - INFO - alphas:tensor([0.3753, 0.0431, 0.0950, 0.4866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,120 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,120 - train - INFO - True
2024-04-07 03:29:41,122 - train - INFO - alphas:tensor([0.4541, 0.0534, 0.0848, 0.4077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,123 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,123 - train - INFO - True
2024-04-07 03:29:41,124 - train - INFO - alphas:tensor([0.4976, 0.0377, 0.0458, 0.0877, 0.3312], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,126 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,126 - train - INFO - True
2024-04-07 03:29:41,127 - train - INFO - alphas:tensor([0.2098, 0.0220, 0.0216, 0.0773, 0.6693], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,128 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,128 - train - INFO - True
2024-04-07 03:29:41,129 - train - INFO - alphas:tensor([0.2253, 0.0181, 0.0220, 0.0640, 0.6707], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,130 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,130 - train - INFO - True
2024-04-07 03:29:41,132 - train - INFO - alphas:tensor([0.2227, 0.0151, 0.0199, 0.0678, 0.6745], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,132 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,133 - train - INFO - True
2024-04-07 03:29:41,134 - train - INFO - alphas:tensor([0.2069, 0.0195, 0.0209, 0.0768, 0.6760], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,135 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,135 - train - INFO - True
2024-04-07 03:29:41,136 - train - INFO - alphas:tensor([0.5085, 0.0238, 0.0349, 0.0807, 0.3521], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,137 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,137 - train - INFO - True
2024-04-07 03:29:41,139 - train - INFO - alphas:tensor([0.5937, 0.0268, 0.0314, 0.0644, 0.2837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,143 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,143 - train - INFO - True
2024-04-07 03:29:41,144 - train - INFO - alphas:tensor([0.2131, 0.0329, 0.0335, 0.1156, 0.6049], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,147 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,147 - train - INFO - True
2024-04-07 03:29:41,148 - train - INFO - alphas:tensor([0.2324, 0.0234, 0.0287, 0.1084, 0.6071], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,150 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,150 - train - INFO - True
2024-04-07 03:29:41,151 - train - INFO - alphas:tensor([0.2529, 0.0202, 0.0267, 0.1015, 0.5986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,154 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,154 - train - INFO - True
2024-04-07 03:29:41,155 - train - INFO - alphas:tensor([0.2236, 0.0276, 0.0325, 0.0986, 0.6177], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,157 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,157 - train - INFO - True
2024-04-07 03:29:41,158 - train - INFO - alphas:tensor([0.2544, 0.0206, 0.0322, 0.0995, 0.5933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,160 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,161 - train - INFO - True
2024-04-07 03:29:41,162 - train - INFO - alphas:tensor([0.1997, 0.0383, 0.0439, 0.1150, 0.6032], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,164 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,164 - train - INFO - True
2024-04-07 03:29:41,165 - train - INFO - alphas:tensor([0.5572, 0.0180, 0.0249, 0.0704, 0.3294], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,169 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,169 - train - INFO - True
2024-04-07 03:29:41,170 - train - INFO - alphas:tensor([0.4883, 0.0162, 0.0195, 0.0715, 0.4045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,178 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,178 - train - INFO - True
2024-04-07 03:29:41,179 - train - INFO - alphas:tensor([0.3609, 0.0154, 0.0265, 0.0859, 0.5113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,183 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,183 - train - INFO - True
2024-04-07 03:29:41,184 - train - INFO - alphas:tensor([0.3797, 0.0161, 0.0199, 0.0853, 0.4989], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,188 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,188 - train - INFO - True
2024-04-07 03:29:41,191 - train - INFO - alphas:tensor([0.3938, 0.0135, 0.0180, 0.0791, 0.4957], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,195 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,195 - train - INFO - True
2024-04-07 03:29:41,201 - train - INFO - alphas:tensor([0.3595, 0.0158, 0.0247, 0.0856, 0.5144], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,205 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,205 - train - INFO - True
2024-04-07 03:29:41,212 - train - INFO - alphas:tensor([0.5042, 0.0137, 0.0207, 0.0621, 0.3994], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,220 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,220 - train - INFO - True
2024-04-07 03:29:41,227 - train - INFO - alphas:tensor([0.6489, 0.0126, 0.0193, 0.0512, 0.2680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,246 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,246 - train - INFO - True
2024-04-07 03:29:41,247 - train - INFO - alphas:tensor([0.3183, 0.0150, 0.0224, 0.0951, 0.5491], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,257 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,257 - train - INFO - True
2024-04-07 03:29:41,258 - train - INFO - alphas:tensor([0.3305, 0.0117, 0.0190, 0.0861, 0.5526], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,268 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,268 - train - INFO - True
2024-04-07 03:29:41,269 - train - INFO - alphas:tensor([0.3593, 0.0118, 0.0164, 0.0826, 0.5299], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,279 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,279 - train - INFO - True
2024-04-07 03:29:41,280 - train - INFO - alphas:tensor([0.3235, 0.0146, 0.0198, 0.0875, 0.5547], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,290 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,291 - train - INFO - True
2024-04-07 03:29:41,298 - train - INFO - alphas:tensor([0.6508, 0.0102, 0.0133, 0.0428, 0.2829], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,317 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,317 - train - INFO - True
2024-04-07 03:29:41,324 - train - INFO - alphas:tensor([0.4903, 0.0211, 0.0270, 0.0798, 0.3818], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:29:41,402 - train - INFO - tau:0.5929664464014994
2024-04-07 03:29:41,402 - train - INFO - avg block size:10.06060606060606
2024-04-07 03:29:41,402 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 03:29:41,402 - train - INFO - lasso_alpha:1.5026296018031554e-05
2024-04-07 03:29:41,633 - train - INFO - Test: [   0/78]  Time: 0.228 (0.228)  Loss:  1.0488 (1.0488)  Acc@1: 78.9062 (78.9062)  Acc@5: 92.9688 (92.9688)
2024-04-07 03:29:47,816 - train - INFO - Test: [  50/78]  Time: 0.101 (0.126)  Loss:  1.5068 (1.6229)  Acc@1: 66.4062 (63.7868)  Acc@5: 86.7188 (85.0643)
2024-04-07 03:29:50,571 - train - INFO - Test: [  78/78]  Time: 0.094 (0.116)  Loss:  1.9053 (1.6503)  Acc@1: 62.5000 (62.8500)  Acc@5: 93.7500 (84.7000)
2024-04-07 03:29:51,193 - train - INFO - Train: 55 [   0/781 (  0%)]  Loss:  3.891119 (3.8911)  Time: 0.532s,  240.55/s  (0.532s,  240.55/s)  LR: 3.547e-04  Data: 0.161 (0.161)
2024-04-07 03:30:17,636 - train - INFO - Train: 55 [  50/781 (  6%)]  Loss:  3.381728 (3.7105)  Time: 0.555s,  230.82/s  (0.529s,  242.01/s)  LR: 3.547e-04  Data: 0.007 (0.011)
2024-04-07 03:30:44,032 - train - INFO - Train: 55 [ 100/781 ( 13%)]  Loss:  3.717046 (3.6957)  Time: 0.512s,  250.14/s  (0.528s,  242.24/s)  LR: 3.547e-04  Data: 0.009 (0.009)
2024-04-07 03:31:11,624 - train - INFO - Train: 55 [ 150/781 ( 19%)]  Loss:  3.576189 (3.6801)  Time: 0.549s,  233.28/s  (0.536s,  238.74/s)  LR: 3.547e-04  Data: 0.007 (0.009)
2024-04-07 03:31:38,360 - train - INFO - Train: 55 [ 200/781 ( 26%)]  Loss:  3.744070 (3.6759)  Time: 0.548s,  233.42/s  (0.536s,  238.90/s)  LR: 3.547e-04  Data: 0.005 (0.008)
2024-04-07 03:32:05,181 - train - INFO - Train: 55 [ 250/781 ( 32%)]  Loss:  3.970333 (3.6784)  Time: 0.535s,  239.32/s  (0.536s,  238.85/s)  LR: 3.547e-04  Data: 0.008 (0.008)
2024-04-07 03:32:32,509 - train - INFO - Train: 55 [ 300/781 ( 38%)]  Loss:  3.726918 (3.6742)  Time: 0.576s,  222.29/s  (0.538s,  238.06/s)  LR: 3.547e-04  Data: 0.007 (0.008)
2024-04-07 03:32:59,785 - train - INFO - Train: 55 [ 350/781 ( 45%)]  Loss:  4.153701 (3.6811)  Time: 0.489s,  261.61/s  (0.539s,  237.57/s)  LR: 3.547e-04  Data: 0.008 (0.008)
2024-04-07 03:33:26,360 - train - INFO - Train: 55 [ 400/781 ( 51%)]  Loss:  3.998030 (3.6880)  Time: 0.428s,  298.73/s  (0.538s,  237.97/s)  LR: 3.547e-04  Data: 0.007 (0.008)
2024-04-07 03:33:53,151 - train - INFO - Train: 55 [ 450/781 ( 58%)]  Loss:  3.959367 (3.6924)  Time: 0.433s,  295.31/s  (0.538s,  238.08/s)  LR: 3.547e-04  Data: 0.007 (0.008)
2024-04-07 03:34:18,956 - train - INFO - Train: 55 [ 500/781 ( 64%)]  Loss:  3.609565 (3.6907)  Time: 0.519s,  246.75/s  (0.535s,  239.03/s)  LR: 3.547e-04  Data: 0.005 (0.008)
2024-04-07 03:34:45,414 - train - INFO - Train: 55 [ 550/781 ( 71%)]  Loss:  3.611037 (3.6904)  Time: 0.525s,  243.66/s  (0.535s,  239.29/s)  LR: 3.547e-04  Data: 0.007 (0.008)
2024-04-07 03:35:11,065 - train - INFO - Train: 55 [ 600/781 ( 77%)]  Loss:  3.633769 (3.6894)  Time: 0.545s,  234.92/s  (0.533s,  240.11/s)  LR: 3.547e-04  Data: 0.008 (0.008)
2024-04-07 03:35:38,194 - train - INFO - Train: 55 [ 650/781 ( 83%)]  Loss:  3.382049 (3.6855)  Time: 0.518s,  246.92/s  (0.534s,  239.78/s)  LR: 3.547e-04  Data: 0.004 (0.008)
2024-04-07 03:36:04,527 - train - INFO - Train: 55 [ 700/781 ( 90%)]  Loss:  3.627041 (3.6868)  Time: 0.586s,  218.27/s  (0.533s,  240.01/s)  LR: 3.547e-04  Data: 0.007 (0.008)
2024-04-07 03:36:30,975 - train - INFO - Train: 55 [ 750/781 ( 96%)]  Loss:  3.844102 (3.6870)  Time: 0.580s,  220.57/s  (0.533s,  240.15/s)  LR: 3.547e-04  Data: 0.008 (0.008)
2024-04-07 03:36:47,450 - train - INFO - Train: 55 [ 780/781 (100%)]  Loss:  3.852468 (3.6866)  Time: 0.543s,  235.77/s  (0.534s,  239.87/s)  LR: 3.547e-04  Data: 0.000 (0.008)
2024-04-07 03:36:47,451 - train - INFO - True
2024-04-07 03:36:47,460 - train - INFO - alphas:tensor([0.5385, 0.0708, 0.0863, 0.1142, 0.1902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,461 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,461 - train - INFO - True
2024-04-07 03:36:47,469 - train - INFO - alphas:tensor([0.3999, 0.0377, 0.0561, 0.1071, 0.3993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,470 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,470 - train - INFO - True
2024-04-07 03:36:47,477 - train - INFO - alphas:tensor([0.4306, 0.0556, 0.1051, 0.4087], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,478 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,478 - train - INFO - True
2024-04-07 03:36:47,479 - train - INFO - alphas:tensor([0.3805, 0.0506, 0.0839, 0.4850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,480 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,480 - train - INFO - True
2024-04-07 03:36:47,481 - train - INFO - alphas:tensor([0.3790, 0.0420, 0.0939, 0.4852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,482 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,482 - train - INFO - True
2024-04-07 03:36:47,483 - train - INFO - alphas:tensor([0.4589, 0.0519, 0.0841, 0.4051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,484 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,484 - train - INFO - True
2024-04-07 03:36:47,486 - train - INFO - alphas:tensor([0.5028, 0.0369, 0.0449, 0.0865, 0.3289], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,487 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,487 - train - INFO - True
2024-04-07 03:36:47,489 - train - INFO - alphas:tensor([0.2172, 0.0216, 0.0211, 0.0765, 0.6637], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,489 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,490 - train - INFO - True
2024-04-07 03:36:47,491 - train - INFO - alphas:tensor([0.2289, 0.0176, 0.0217, 0.0640, 0.6678], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,492 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,492 - train - INFO - True
2024-04-07 03:36:47,493 - train - INFO - alphas:tensor([0.2277, 0.0149, 0.0198, 0.0676, 0.6700], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,494 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,494 - train - INFO - True
2024-04-07 03:36:47,495 - train - INFO - alphas:tensor([0.2130, 0.0193, 0.0206, 0.0763, 0.6708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,496 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,496 - train - INFO - True
2024-04-07 03:36:47,497 - train - INFO - alphas:tensor([0.5070, 0.0231, 0.0344, 0.0802, 0.3553], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,499 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,499 - train - INFO - True
2024-04-07 03:36:47,500 - train - INFO - alphas:tensor([0.5950, 0.0260, 0.0306, 0.0631, 0.2853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,504 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,505 - train - INFO - True
2024-04-07 03:36:47,507 - train - INFO - alphas:tensor([0.2182, 0.0333, 0.0342, 0.1167, 0.5975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,509 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,510 - train - INFO - True
2024-04-07 03:36:47,511 - train - INFO - alphas:tensor([0.2351, 0.0230, 0.0279, 0.1078, 0.6061], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,513 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,513 - train - INFO - True
2024-04-07 03:36:47,514 - train - INFO - alphas:tensor([0.2567, 0.0203, 0.0266, 0.1019, 0.5945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,517 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,517 - train - INFO - True
2024-04-07 03:36:47,518 - train - INFO - alphas:tensor([0.2310, 0.0269, 0.0316, 0.0977, 0.6129], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,520 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,520 - train - INFO - True
2024-04-07 03:36:47,528 - train - INFO - alphas:tensor([0.2597, 0.0202, 0.0325, 0.0977, 0.5898], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,530 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,530 - train - INFO - True
2024-04-07 03:36:47,537 - train - INFO - alphas:tensor([0.2068, 0.0379, 0.0426, 0.1145, 0.5982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,539 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,539 - train - INFO - True
2024-04-07 03:36:47,547 - train - INFO - alphas:tensor([0.5583, 0.0175, 0.0241, 0.0693, 0.3308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,550 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,550 - train - INFO - True
2024-04-07 03:36:47,558 - train - INFO - alphas:tensor([0.4938, 0.0158, 0.0190, 0.0709, 0.4006], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,566 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,566 - train - INFO - True
2024-04-07 03:36:47,568 - train - INFO - alphas:tensor([0.3737, 0.0151, 0.0260, 0.0855, 0.4997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,572 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,572 - train - INFO - True
2024-04-07 03:36:47,573 - train - INFO - alphas:tensor([0.3854, 0.0154, 0.0194, 0.0838, 0.4960], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,577 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,577 - train - INFO - True
2024-04-07 03:36:47,578 - train - INFO - alphas:tensor([0.4023, 0.0131, 0.0177, 0.0771, 0.4898], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,581 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,582 - train - INFO - True
2024-04-07 03:36:47,582 - train - INFO - alphas:tensor([0.3641, 0.0152, 0.0239, 0.0840, 0.5128], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,586 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,586 - train - INFO - True
2024-04-07 03:36:47,587 - train - INFO - alphas:tensor([0.5092, 0.0130, 0.0202, 0.0602, 0.3972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,595 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,595 - train - INFO - True
2024-04-07 03:36:47,596 - train - INFO - alphas:tensor([0.6514, 0.0121, 0.0188, 0.0508, 0.2669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,615 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,615 - train - INFO - True
2024-04-07 03:36:47,624 - train - INFO - alphas:tensor([0.3267, 0.0147, 0.0216, 0.0950, 0.5420], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,634 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,634 - train - INFO - True
2024-04-07 03:36:47,641 - train - INFO - alphas:tensor([0.3410, 0.0115, 0.0185, 0.0853, 0.5436], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,651 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,651 - train - INFO - True
2024-04-07 03:36:47,655 - train - INFO - alphas:tensor([0.3672, 0.0115, 0.0158, 0.0811, 0.5243], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,665 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,665 - train - INFO - True
2024-04-07 03:36:47,666 - train - INFO - alphas:tensor([0.3307, 0.0142, 0.0194, 0.0865, 0.5491], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,676 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,676 - train - INFO - True
2024-04-07 03:36:47,677 - train - INFO - alphas:tensor([0.6558, 0.0099, 0.0127, 0.0417, 0.2799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,697 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,697 - train - INFO - True
2024-04-07 03:36:47,706 - train - INFO - alphas:tensor([0.5014, 0.0206, 0.0264, 0.0791, 0.3725], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:36:47,784 - train - INFO - tau:0.5870367819374844
2024-04-07 03:36:47,784 - train - INFO - avg block size:9.606060606060606
2024-04-07 03:36:47,785 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 03:36:48,103 - train - INFO - Test: [   0/78]  Time: 0.314 (0.314)  Loss:  1.0693 (1.0693)  Acc@1: 78.1250 (78.1250)  Acc@5: 92.1875 (92.1875)
2024-04-07 03:36:53,464 - train - INFO - Test: [  50/78]  Time: 0.120 (0.111)  Loss:  1.6484 (1.6552)  Acc@1: 60.1562 (63.0362)  Acc@5: 85.1562 (84.5588)
2024-04-07 03:36:56,638 - train - INFO - Test: [  78/78]  Time: 0.095 (0.112)  Loss:  1.9131 (1.6559)  Acc@1: 62.5000 (63.1700)  Acc@5: 93.7500 (84.4600)
2024-04-07 03:36:57,429 - train - INFO - Train: 56 [   0/781 (  0%)]  Loss:  3.670325 (3.6703)  Time: 0.711s,  180.09/s  (0.711s,  180.09/s)  LR: 3.499e-04  Data: 0.189 (0.189)
2024-04-07 03:37:24,584 - train - INFO - Train: 56 [  50/781 (  6%)]  Loss:  3.528130 (3.6569)  Time: 0.526s,  243.57/s  (0.546s,  234.28/s)  LR: 3.499e-04  Data: 0.009 (0.011)
2024-04-07 03:37:50,010 - train - INFO - Train: 56 [ 100/781 ( 13%)]  Loss:  3.797572 (3.6537)  Time: 0.537s,  238.44/s  (0.528s,  242.60/s)  LR: 3.499e-04  Data: 0.008 (0.009)
2024-04-07 03:38:16,794 - train - INFO - Train: 56 [ 150/781 ( 19%)]  Loss:  4.045825 (3.6607)  Time: 0.561s,  228.17/s  (0.530s,  241.38/s)  LR: 3.499e-04  Data: 0.009 (0.008)
2024-04-07 03:38:43,228 - train - INFO - Train: 56 [ 200/781 ( 26%)]  Loss:  3.526893 (3.6601)  Time: 0.520s,  246.25/s  (0.530s,  241.57/s)  LR: 3.499e-04  Data: 0.007 (0.008)
2024-04-07 03:39:10,094 - train - INFO - Train: 56 [ 250/781 ( 32%)]  Loss:  3.545506 (3.6695)  Time: 0.441s,  290.30/s  (0.531s,  240.90/s)  LR: 3.499e-04  Data: 0.005 (0.008)
2024-04-07 03:39:36,292 - train - INFO - Train: 56 [ 300/781 ( 38%)]  Loss:  3.148283 (3.6696)  Time: 0.526s,  243.34/s  (0.530s,  241.46/s)  LR: 3.499e-04  Data: 0.007 (0.008)
2024-04-07 03:40:02,690 - train - INFO - Train: 56 [ 350/781 ( 45%)]  Loss:  3.855531 (3.6747)  Time: 0.376s,  340.62/s  (0.530s,  241.60/s)  LR: 3.499e-04  Data: 0.004 (0.008)
2024-04-07 03:40:28,618 - train - INFO - Train: 56 [ 400/781 ( 51%)]  Loss:  3.498897 (3.6747)  Time: 0.493s,  259.86/s  (0.528s,  242.24/s)  LR: 3.499e-04  Data: 0.005 (0.008)
2024-04-07 03:40:54,860 - train - INFO - Train: 56 [ 450/781 ( 58%)]  Loss:  3.998842 (3.6741)  Time: 0.442s,  289.35/s  (0.528s,  242.42/s)  LR: 3.499e-04  Data: 0.004 (0.008)
2024-04-07 03:41:21,026 - train - INFO - Train: 56 [ 500/781 ( 64%)]  Loss:  3.616246 (3.6713)  Time: 0.565s,  226.43/s  (0.528s,  242.64/s)  LR: 3.499e-04  Data: 0.007 (0.008)
2024-04-07 03:41:47,956 - train - INFO - Train: 56 [ 550/781 ( 71%)]  Loss:  3.457987 (3.6724)  Time: 0.465s,  275.41/s  (0.529s,  242.18/s)  LR: 3.499e-04  Data: 0.007 (0.008)
2024-04-07 03:42:14,296 - train - INFO - Train: 56 [ 600/781 ( 77%)]  Loss:  3.990674 (3.6778)  Time: 0.566s,  226.23/s  (0.528s,  242.25/s)  LR: 3.499e-04  Data: 0.010 (0.008)
2024-04-07 03:42:40,876 - train - INFO - Train: 56 [ 650/781 ( 83%)]  Loss:  3.830832 (3.6769)  Time: 0.512s,  250.14/s  (0.529s,  242.14/s)  LR: 3.499e-04  Data: 0.006 (0.008)
2024-04-07 03:43:06,835 - train - INFO - Train: 56 [ 700/781 ( 90%)]  Loss:  4.038341 (3.6749)  Time: 0.455s,  281.13/s  (0.528s,  242.45/s)  LR: 3.499e-04  Data: 0.005 (0.008)
2024-04-07 03:43:34,182 - train - INFO - Train: 56 [ 750/781 ( 96%)]  Loss:  3.636078 (3.6761)  Time: 0.786s,  162.80/s  (0.529s,  241.87/s)  LR: 3.499e-04  Data: 0.009 (0.008)
2024-04-07 03:43:49,678 - train - INFO - Train: 56 [ 780/781 (100%)]  Loss:  3.596465 (3.6775)  Time: 0.555s,  230.51/s  (0.529s,  242.09/s)  LR: 3.499e-04  Data: 0.000 (0.008)
2024-04-07 03:43:49,679 - train - INFO - True
2024-04-07 03:43:49,682 - train - INFO - alphas:tensor([0.5428, 0.0697, 0.0851, 0.1128, 0.1896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,683 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,683 - train - INFO - True
2024-04-07 03:43:49,685 - train - INFO - alphas:tensor([0.4030, 0.0367, 0.0544, 0.1056, 0.4003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,686 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,686 - train - INFO - True
2024-04-07 03:43:49,687 - train - INFO - alphas:tensor([0.4364, 0.0548, 0.1032, 0.4056], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,689 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,689 - train - INFO - True
2024-04-07 03:43:49,691 - train - INFO - alphas:tensor([0.3832, 0.0494, 0.0831, 0.4842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,691 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,692 - train - INFO - True
2024-04-07 03:43:49,693 - train - INFO - alphas:tensor([0.3843, 0.0407, 0.0922, 0.4828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,694 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,694 - train - INFO - True
2024-04-07 03:43:49,696 - train - INFO - alphas:tensor([0.4629, 0.0512, 0.0828, 0.4030], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,697 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,697 - train - INFO - True
2024-04-07 03:43:49,699 - train - INFO - alphas:tensor([0.5079, 0.0358, 0.0435, 0.0848, 0.3280], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,700 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,701 - train - INFO - True
2024-04-07 03:43:49,702 - train - INFO - alphas:tensor([0.2186, 0.0209, 0.0203, 0.0759, 0.6642], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,703 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,703 - train - INFO - True
2024-04-07 03:43:49,705 - train - INFO - alphas:tensor([0.2299, 0.0174, 0.0210, 0.0630, 0.6686], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,706 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,706 - train - INFO - True
2024-04-07 03:43:49,707 - train - INFO - alphas:tensor([0.2316, 0.0143, 0.0191, 0.0662, 0.6687], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,708 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,708 - train - INFO - True
2024-04-07 03:43:49,710 - train - INFO - alphas:tensor([0.2159, 0.0188, 0.0199, 0.0763, 0.6692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,711 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,711 - train - INFO - True
2024-04-07 03:43:49,712 - train - INFO - alphas:tensor([0.5145, 0.0225, 0.0335, 0.0783, 0.3512], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,714 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,714 - train - INFO - True
2024-04-07 03:43:49,716 - train - INFO - alphas:tensor([0.6008, 0.0251, 0.0296, 0.0616, 0.2828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,721 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,721 - train - INFO - True
2024-04-07 03:43:49,722 - train - INFO - alphas:tensor([0.2200, 0.0324, 0.0328, 0.1151, 0.5997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,725 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,725 - train - INFO - True
2024-04-07 03:43:49,726 - train - INFO - alphas:tensor([0.2399, 0.0224, 0.0270, 0.1073, 0.6033], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,729 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,729 - train - INFO - True
2024-04-07 03:43:49,730 - train - INFO - alphas:tensor([0.2586, 0.0196, 0.0257, 0.0992, 0.5969], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,733 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,733 - train - INFO - True
2024-04-07 03:43:49,734 - train - INFO - alphas:tensor([0.2315, 0.0264, 0.0310, 0.0979, 0.6133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,737 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,737 - train - INFO - True
2024-04-07 03:43:49,738 - train - INFO - alphas:tensor([0.2632, 0.0197, 0.0308, 0.0968, 0.5895], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,740 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,740 - train - INFO - True
2024-04-07 03:43:49,741 - train - INFO - alphas:tensor([0.2076, 0.0372, 0.0424, 0.1170, 0.5958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,744 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,744 - train - INFO - True
2024-04-07 03:43:49,745 - train - INFO - alphas:tensor([0.5647, 0.0171, 0.0232, 0.0685, 0.3265], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,749 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,750 - train - INFO - True
2024-04-07 03:43:49,751 - train - INFO - alphas:tensor([0.4942, 0.0153, 0.0187, 0.0701, 0.4017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,759 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,760 - train - INFO - True
2024-04-07 03:43:49,761 - train - INFO - alphas:tensor([0.3660, 0.0147, 0.0260, 0.0858, 0.5076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,765 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,765 - train - INFO - True
2024-04-07 03:43:49,766 - train - INFO - alphas:tensor([0.3849, 0.0149, 0.0187, 0.0824, 0.4992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,770 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,771 - train - INFO - True
2024-04-07 03:43:49,772 - train - INFO - alphas:tensor([0.4018, 0.0128, 0.0174, 0.0777, 0.4902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,776 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,776 - train - INFO - True
2024-04-07 03:43:49,777 - train - INFO - alphas:tensor([0.3699, 0.0150, 0.0234, 0.0840, 0.5077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,781 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,781 - train - INFO - True
2024-04-07 03:43:49,782 - train - INFO - alphas:tensor([0.5102, 0.0129, 0.0198, 0.0596, 0.3975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,790 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,790 - train - INFO - True
2024-04-07 03:43:49,791 - train - INFO - alphas:tensor([0.6546, 0.0116, 0.0183, 0.0497, 0.2659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,810 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,810 - train - INFO - True
2024-04-07 03:43:49,811 - train - INFO - alphas:tensor([0.3290, 0.0146, 0.0213, 0.0959, 0.5392], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,821 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,821 - train - INFO - True
2024-04-07 03:43:49,822 - train - INFO - alphas:tensor([0.3401, 0.0112, 0.0179, 0.0850, 0.5458], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,832 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,833 - train - INFO - True
2024-04-07 03:43:49,833 - train - INFO - alphas:tensor([0.3656, 0.0112, 0.0152, 0.0829, 0.5252], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,844 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,844 - train - INFO - True
2024-04-07 03:43:49,845 - train - INFO - alphas:tensor([0.3297, 0.0136, 0.0190, 0.0847, 0.5530], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,855 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,855 - train - INFO - True
2024-04-07 03:43:49,856 - train - INFO - alphas:tensor([0.6595, 0.0096, 0.0123, 0.0410, 0.2776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,875 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,875 - train - INFO - True
2024-04-07 03:43:49,876 - train - INFO - alphas:tensor([0.4998, 0.0205, 0.0266, 0.0787, 0.3743], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:43:49,954 - train - INFO - tau:0.5811664141181095
2024-04-07 03:43:49,954 - train - INFO - avg block size:9.606060606060606
2024-04-07 03:43:49,954 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 03:43:49,954 - train - INFO - lasso_alpha:1.652892561983471e-05
2024-04-07 03:43:50,152 - train - INFO - Test: [   0/78]  Time: 0.194 (0.194)  Loss:  0.9453 (0.9453)  Acc@1: 79.6875 (79.6875)  Acc@5: 94.5312 (94.5312)
2024-04-07 03:43:55,732 - train - INFO - Test: [  50/78]  Time: 0.052 (0.113)  Loss:  1.6748 (1.6433)  Acc@1: 66.4062 (63.0668)  Acc@5: 82.8125 (85.0031)
2024-04-07 03:43:58,709 - train - INFO - Test: [  78/78]  Time: 0.096 (0.111)  Loss:  1.6768 (1.6563)  Acc@1: 56.2500 (62.7900)  Acc@5: 100.0000 (84.5900)
2024-04-07 03:43:59,485 - train - INFO - Train: 57 [   0/781 (  0%)]  Loss:  3.848413 (3.8484)  Time: 0.699s,  183.04/s  (0.699s,  183.04/s)  LR: 3.452e-04  Data: 0.170 (0.170)
2024-04-07 03:44:25,779 - train - INFO - Train: 57 [  50/781 (  6%)]  Loss:  3.318635 (3.6810)  Time: 0.509s,  251.44/s  (0.529s,  241.85/s)  LR: 3.452e-04  Data: 0.008 (0.011)
2024-04-07 03:44:52,975 - train - INFO - Train: 57 [ 100/781 ( 13%)]  Loss:  4.041631 (3.6665)  Time: 0.491s,  260.74/s  (0.536s,  238.59/s)  LR: 3.452e-04  Data: 0.007 (0.009)
2024-04-07 03:45:20,481 - train - INFO - Train: 57 [ 150/781 ( 19%)]  Loss:  3.508580 (3.6600)  Time: 1.127s,  113.57/s  (0.541s,  236.60/s)  LR: 3.452e-04  Data: 0.006 (0.009)
2024-04-07 03:45:47,417 - train - INFO - Train: 57 [ 200/781 ( 26%)]  Loss:  3.619966 (3.6741)  Time: 0.572s,  223.96/s  (0.540s,  236.85/s)  LR: 3.452e-04  Data: 0.009 (0.009)
2024-04-07 03:46:14,781 - train - INFO - Train: 57 [ 250/781 ( 32%)]  Loss:  3.717914 (3.6702)  Time: 0.466s,  274.86/s  (0.542s,  236.26/s)  LR: 3.452e-04  Data: 0.007 (0.008)
2024-04-07 03:46:41,262 - train - INFO - Train: 57 [ 300/781 ( 38%)]  Loss:  3.998652 (3.6683)  Time: 0.543s,  235.83/s  (0.540s,  237.14/s)  LR: 3.452e-04  Data: 0.009 (0.008)
2024-04-07 03:47:07,021 - train - INFO - Train: 57 [ 350/781 ( 45%)]  Loss:  3.506493 (3.6641)  Time: 0.368s,  347.93/s  (0.536s,  238.69/s)  LR: 3.452e-04  Data: 0.004 (0.008)
2024-04-07 03:47:33,816 - train - INFO - Train: 57 [ 400/781 ( 51%)]  Loss:  3.692889 (3.6697)  Time: 0.452s,  282.89/s  (0.536s,  238.72/s)  LR: 3.452e-04  Data: 0.005 (0.008)
2024-04-07 03:48:00,560 - train - INFO - Train: 57 [ 450/781 ( 58%)]  Loss:  3.610961 (3.6732)  Time: 0.490s,  260.97/s  (0.536s,  238.78/s)  LR: 3.452e-04  Data: 0.010 (0.008)
2024-04-07 03:48:28,145 - train - INFO - Train: 57 [ 500/781 ( 64%)]  Loss:  3.932031 (3.6803)  Time: 0.528s,  242.57/s  (0.538s,  238.09/s)  LR: 3.452e-04  Data: 0.008 (0.008)
2024-04-07 03:48:54,214 - train - INFO - Train: 57 [ 550/781 ( 71%)]  Loss:  3.602940 (3.6844)  Time: 0.492s,  260.11/s  (0.536s,  238.75/s)  LR: 3.452e-04  Data: 0.008 (0.008)
2024-04-07 03:49:22,076 - train - INFO - Train: 57 [ 600/781 ( 77%)]  Loss:  3.878278 (3.6859)  Time: 0.541s,  236.71/s  (0.538s,  237.97/s)  LR: 3.452e-04  Data: 0.008 (0.008)
2024-04-07 03:49:47,079 - train - INFO - Train: 57 [ 650/781 ( 83%)]  Loss:  3.602886 (3.6891)  Time: 0.426s,  300.27/s  (0.535s,  239.26/s)  LR: 3.452e-04  Data: 0.007 (0.008)
2024-04-07 03:50:13,556 - train - INFO - Train: 57 [ 700/781 ( 90%)]  Loss:  3.525511 (3.6870)  Time: 0.534s,  239.63/s  (0.535s,  239.44/s)  LR: 3.452e-04  Data: 0.007 (0.008)
2024-04-07 03:50:40,370 - train - INFO - Train: 57 [ 750/781 ( 96%)]  Loss:  3.847249 (3.6838)  Time: 0.508s,  251.87/s  (0.535s,  239.39/s)  LR: 3.452e-04  Data: 0.009 (0.008)
2024-04-07 03:50:55,953 - train - INFO - Train: 57 [ 780/781 (100%)]  Loss:  3.993040 (3.6839)  Time: 0.411s,  311.21/s  (0.534s,  239.65/s)  LR: 3.452e-04  Data: 0.000 (0.008)
2024-04-07 03:50:55,954 - train - INFO - True
2024-04-07 03:50:55,956 - train - INFO - alphas:tensor([0.5470, 0.0682, 0.0840, 0.1116, 0.1891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:55,957 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:55,957 - train - INFO - True
2024-04-07 03:50:55,958 - train - INFO - alphas:tensor([0.4056, 0.0361, 0.0540, 0.1048, 0.3995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:55,959 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:55,959 - train - INFO - True
2024-04-07 03:50:55,961 - train - INFO - alphas:tensor([0.4304, 0.0540, 0.1025, 0.4131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:55,962 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:55,962 - train - INFO - True
2024-04-07 03:50:55,963 - train - INFO - alphas:tensor([0.3823, 0.0489, 0.0819, 0.4868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:55,964 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:55,964 - train - INFO - True
2024-04-07 03:50:55,965 - train - INFO - alphas:tensor([0.3793, 0.0401, 0.0918, 0.4888], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:55,966 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:55,966 - train - INFO - True
2024-04-07 03:50:55,967 - train - INFO - alphas:tensor([0.4659, 0.0501, 0.0817, 0.4023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:55,968 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:55,969 - train - INFO - True
2024-04-07 03:50:55,970 - train - INFO - alphas:tensor([0.5071, 0.0353, 0.0428, 0.0838, 0.3310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:55,972 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:55,972 - train - INFO - True
2024-04-07 03:50:55,973 - train - INFO - alphas:tensor([0.2163, 0.0204, 0.0199, 0.0760, 0.6674], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:55,974 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:55,974 - train - INFO - True
2024-04-07 03:50:55,975 - train - INFO - alphas:tensor([0.2274, 0.0169, 0.0205, 0.0624, 0.6728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:55,976 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:55,976 - train - INFO - True
2024-04-07 03:50:55,978 - train - INFO - alphas:tensor([0.2272, 0.0141, 0.0187, 0.0664, 0.6736], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:55,978 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:55,979 - train - INFO - True
2024-04-07 03:50:55,987 - train - INFO - alphas:tensor([0.2133, 0.0182, 0.0193, 0.0750, 0.6742], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:55,988 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:55,988 - train - INFO - True
2024-04-07 03:50:55,997 - train - INFO - alphas:tensor([0.5115, 0.0217, 0.0328, 0.0779, 0.3561], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:55,998 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:55,998 - train - INFO - True
2024-04-07 03:50:56,006 - train - INFO - alphas:tensor([0.6040, 0.0243, 0.0289, 0.0605, 0.2823], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,010 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,010 - train - INFO - True
2024-04-07 03:50:56,018 - train - INFO - alphas:tensor([0.2240, 0.0317, 0.0326, 0.1130, 0.5987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,020 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,020 - train - INFO - True
2024-04-07 03:50:56,028 - train - INFO - alphas:tensor([0.2384, 0.0222, 0.0267, 0.1074, 0.6054], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,030 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,030 - train - INFO - True
2024-04-07 03:50:56,031 - train - INFO - alphas:tensor([0.2620, 0.0194, 0.0253, 0.0984, 0.5949], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,033 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,033 - train - INFO - True
2024-04-07 03:50:56,034 - train - INFO - alphas:tensor([0.2260, 0.0257, 0.0306, 0.0978, 0.6199], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,036 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,036 - train - INFO - True
2024-04-07 03:50:56,037 - train - INFO - alphas:tensor([0.2615, 0.0190, 0.0303, 0.0983, 0.5910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,039 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,039 - train - INFO - True
2024-04-07 03:50:56,040 - train - INFO - alphas:tensor([0.2105, 0.0363, 0.0416, 0.1160, 0.5956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,042 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,042 - train - INFO - True
2024-04-07 03:50:56,043 - train - INFO - alphas:tensor([0.5603, 0.0167, 0.0228, 0.0680, 0.3321], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,046 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,046 - train - INFO - True
2024-04-07 03:50:56,047 - train - INFO - alphas:tensor([0.4950, 0.0150, 0.0183, 0.0699, 0.4017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,054 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,054 - train - INFO - True
2024-04-07 03:50:56,055 - train - INFO - alphas:tensor([0.3656, 0.0143, 0.0253, 0.0849, 0.5100], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,059 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,059 - train - INFO - True
2024-04-07 03:50:56,060 - train - INFO - alphas:tensor([0.3880, 0.0144, 0.0184, 0.0818, 0.4974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,063 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,063 - train - INFO - True
2024-04-07 03:50:56,064 - train - INFO - alphas:tensor([0.3958, 0.0123, 0.0173, 0.0787, 0.4959], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,068 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,068 - train - INFO - True
2024-04-07 03:50:56,069 - train - INFO - alphas:tensor([0.3643, 0.0145, 0.0226, 0.0848, 0.5138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,072 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,072 - train - INFO - True
2024-04-07 03:50:56,073 - train - INFO - alphas:tensor([0.5163, 0.0126, 0.0196, 0.0595, 0.3920], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,080 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,080 - train - INFO - True
2024-04-07 03:50:56,085 - train - INFO - alphas:tensor([0.6545, 0.0111, 0.0179, 0.0489, 0.2676], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,101 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,101 - train - INFO - True
2024-04-07 03:50:56,108 - train - INFO - alphas:tensor([0.3278, 0.0145, 0.0208, 0.0956, 0.5413], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,115 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,115 - train - INFO - True
2024-04-07 03:50:56,119 - train - INFO - alphas:tensor([0.3365, 0.0108, 0.0176, 0.0837, 0.5514], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,127 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,127 - train - INFO - True
2024-04-07 03:50:56,128 - train - INFO - alphas:tensor([0.3643, 0.0108, 0.0150, 0.0814, 0.5285], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,135 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,135 - train - INFO - True
2024-04-07 03:50:56,136 - train - INFO - alphas:tensor([0.3270, 0.0133, 0.0192, 0.0855, 0.5550], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,143 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,143 - train - INFO - True
2024-04-07 03:50:56,144 - train - INFO - alphas:tensor([0.6590, 0.0094, 0.0120, 0.0405, 0.2792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,157 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,157 - train - INFO - True
2024-04-07 03:50:56,158 - train - INFO - alphas:tensor([0.4958, 0.0203, 0.0269, 0.0788, 0.3783], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:50:56,213 - train - INFO - tau:0.5753547499769285
2024-04-07 03:50:56,213 - train - INFO - avg block size:9.606060606060606
2024-04-07 03:50:56,214 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 03:50:56,444 - train - INFO - Test: [   0/78]  Time: 0.228 (0.228)  Loss:  1.0332 (1.0332)  Acc@1: 81.2500 (81.2500)  Acc@5: 91.4062 (91.4062)
2024-04-07 03:51:01,940 - train - INFO - Test: [  50/78]  Time: 0.103 (0.112)  Loss:  1.6758 (1.6130)  Acc@1: 60.9375 (63.3119)  Acc@5: 84.3750 (85.2175)
2024-04-07 03:51:04,759 - train - INFO - Test: [  78/78]  Time: 0.099 (0.108)  Loss:  1.7139 (1.6436)  Acc@1: 62.5000 (62.7300)  Acc@5: 93.7500 (84.6500)
2024-04-07 03:51:05,533 - train - INFO - Train: 58 [   0/781 (  0%)]  Loss:  3.354861 (3.3549)  Time: 0.691s,  185.16/s  (0.691s,  185.16/s)  LR: 3.404e-04  Data: 0.184 (0.184)
2024-04-07 03:51:31,659 - train - INFO - Train: 58 [  50/781 (  6%)]  Loss:  3.359459 (3.6756)  Time: 0.493s,  259.51/s  (0.526s,  243.44/s)  LR: 3.404e-04  Data: 0.008 (0.011)
2024-04-07 03:51:58,002 - train - INFO - Train: 58 [ 100/781 ( 13%)]  Loss:  3.707107 (3.6715)  Time: 0.574s,  222.83/s  (0.526s,  243.20/s)  LR: 3.404e-04  Data: 0.010 (0.009)
2024-04-07 03:52:24,871 - train - INFO - Train: 58 [ 150/781 ( 19%)]  Loss:  3.830827 (3.6787)  Time: 0.566s,  226.17/s  (0.530s,  241.53/s)  LR: 3.404e-04  Data: 0.009 (0.009)
2024-04-07 03:52:52,364 - train - INFO - Train: 58 [ 200/781 ( 26%)]  Loss:  3.770258 (3.6810)  Time: 0.546s,  234.63/s  (0.535s,  239.30/s)  LR: 3.404e-04  Data: 0.009 (0.009)
2024-04-07 03:53:19,134 - train - INFO - Train: 58 [ 250/781 ( 32%)]  Loss:  3.613168 (3.6784)  Time: 0.596s,  214.78/s  (0.535s,  239.26/s)  LR: 3.404e-04  Data: 0.010 (0.008)
2024-04-07 03:53:46,711 - train - INFO - Train: 58 [ 300/781 ( 38%)]  Loss:  3.637168 (3.6885)  Time: 0.560s,  228.63/s  (0.538s,  238.04/s)  LR: 3.404e-04  Data: 0.009 (0.008)
2024-04-07 03:54:13,909 - train - INFO - Train: 58 [ 350/781 ( 45%)]  Loss:  4.073294 (3.6856)  Time: 0.436s,  293.79/s  (0.539s,  237.65/s)  LR: 3.404e-04  Data: 0.008 (0.008)
2024-04-07 03:54:40,688 - train - INFO - Train: 58 [ 400/781 ( 51%)]  Loss:  3.845337 (3.6891)  Time: 0.544s,  235.16/s  (0.538s,  237.81/s)  LR: 3.404e-04  Data: 0.010 (0.008)
2024-04-07 03:55:07,165 - train - INFO - Train: 58 [ 450/781 ( 58%)]  Loss:  3.292015 (3.6810)  Time: 0.504s,  254.17/s  (0.537s,  238.24/s)  LR: 3.404e-04  Data: 0.005 (0.008)
2024-04-07 03:55:33,670 - train - INFO - Train: 58 [ 500/781 ( 64%)]  Loss:  3.229195 (3.6761)  Time: 0.534s,  239.86/s  (0.537s,  238.56/s)  LR: 3.404e-04  Data: 0.008 (0.008)
2024-04-07 03:56:00,346 - train - INFO - Train: 58 [ 550/781 ( 71%)]  Loss:  3.921986 (3.6740)  Time: 0.535s,  239.11/s  (0.536s,  238.69/s)  LR: 3.404e-04  Data: 0.005 (0.008)
2024-04-07 03:56:28,171 - train - INFO - Train: 58 [ 600/781 ( 77%)]  Loss:  3.910823 (3.6718)  Time: 0.485s,  264.02/s  (0.538s,  237.94/s)  LR: 3.404e-04  Data: 0.006 (0.008)
2024-04-07 03:56:54,823 - train - INFO - Train: 58 [ 650/781 ( 83%)]  Loss:  3.795975 (3.6732)  Time: 0.384s,  333.24/s  (0.538s,  238.11/s)  LR: 3.404e-04  Data: 0.004 (0.008)
2024-04-07 03:57:21,542 - train - INFO - Train: 58 [ 700/781 ( 90%)]  Loss:  3.749274 (3.6738)  Time: 0.552s,  231.93/s  (0.537s,  238.21/s)  LR: 3.404e-04  Data: 0.011 (0.008)
2024-04-07 03:57:47,925 - train - INFO - Train: 58 [ 750/781 ( 96%)]  Loss:  3.870480 (3.6749)  Time: 0.481s,  266.16/s  (0.537s,  238.50/s)  LR: 3.404e-04  Data: 0.008 (0.008)
2024-04-07 03:58:03,773 - train - INFO - Train: 58 [ 780/781 (100%)]  Loss:  3.927186 (3.6733)  Time: 0.502s,  254.89/s  (0.536s,  238.64/s)  LR: 3.404e-04  Data: 0.000 (0.008)
2024-04-07 03:58:03,773 - train - INFO - True
2024-04-07 03:58:03,782 - train - INFO - alphas:tensor([0.5484, 0.0674, 0.0835, 0.1109, 0.1899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,783 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,783 - train - INFO - True
2024-04-07 03:58:03,789 - train - INFO - alphas:tensor([0.4048, 0.0350, 0.0529, 0.1041, 0.4033], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,790 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,790 - train - INFO - True
2024-04-07 03:58:03,793 - train - INFO - alphas:tensor([0.4314, 0.0524, 0.1014, 0.4147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,794 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,794 - train - INFO - True
2024-04-07 03:58:03,795 - train - INFO - alphas:tensor([0.3834, 0.0481, 0.0809, 0.4876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,795 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,795 - train - INFO - True
2024-04-07 03:58:03,796 - train - INFO - alphas:tensor([0.3842, 0.0394, 0.0907, 0.4857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,796 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,796 - train - INFO - True
2024-04-07 03:58:03,797 - train - INFO - alphas:tensor([0.4665, 0.0492, 0.0810, 0.4032], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,797 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,797 - train - INFO - True
2024-04-07 03:58:03,798 - train - INFO - alphas:tensor([0.5064, 0.0343, 0.0421, 0.0829, 0.3343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,799 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,799 - train - INFO - True
2024-04-07 03:58:03,799 - train - INFO - alphas:tensor([0.2122, 0.0200, 0.0191, 0.0745, 0.6742], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,800 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,800 - train - INFO - True
2024-04-07 03:58:03,801 - train - INFO - alphas:tensor([0.2253, 0.0166, 0.0200, 0.0613, 0.6769], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,801 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,801 - train - INFO - True
2024-04-07 03:58:03,802 - train - INFO - alphas:tensor([0.2242, 0.0135, 0.0181, 0.0651, 0.6790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,802 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,802 - train - INFO - True
2024-04-07 03:58:03,803 - train - INFO - alphas:tensor([0.2118, 0.0178, 0.0188, 0.0751, 0.6765], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,804 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,804 - train - INFO - True
2024-04-07 03:58:03,804 - train - INFO - alphas:tensor([0.5140, 0.0210, 0.0321, 0.0764, 0.3564], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,805 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,805 - train - INFO - True
2024-04-07 03:58:03,806 - train - INFO - alphas:tensor([0.6018, 0.0240, 0.0284, 0.0606, 0.2852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,809 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,809 - train - INFO - True
2024-04-07 03:58:03,809 - train - INFO - alphas:tensor([0.2217, 0.0307, 0.0318, 0.1139, 0.6019], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,811 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,811 - train - INFO - True
2024-04-07 03:58:03,812 - train - INFO - alphas:tensor([0.2349, 0.0218, 0.0266, 0.1075, 0.6093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,813 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,813 - train - INFO - True
2024-04-07 03:58:03,814 - train - INFO - alphas:tensor([0.2538, 0.0185, 0.0249, 0.0977, 0.6051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,815 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,815 - train - INFO - True
2024-04-07 03:58:03,816 - train - INFO - alphas:tensor([0.2268, 0.0253, 0.0299, 0.0978, 0.6201], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,818 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,818 - train - INFO - True
2024-04-07 03:58:03,818 - train - INFO - alphas:tensor([0.2584, 0.0185, 0.0292, 0.0975, 0.5964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,820 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,820 - train - INFO - True
2024-04-07 03:58:03,821 - train - INFO - alphas:tensor([0.2065, 0.0353, 0.0403, 0.1147, 0.6032], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,822 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,822 - train - INFO - True
2024-04-07 03:58:03,823 - train - INFO - alphas:tensor([0.5583, 0.0163, 0.0224, 0.0675, 0.3354], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,826 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,826 - train - INFO - True
2024-04-07 03:58:03,826 - train - INFO - alphas:tensor([0.4977, 0.0146, 0.0176, 0.0689, 0.4012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,832 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,832 - train - INFO - True
2024-04-07 03:58:03,833 - train - INFO - alphas:tensor([0.3713, 0.0139, 0.0247, 0.0839, 0.5062], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,835 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,836 - train - INFO - True
2024-04-07 03:58:03,836 - train - INFO - alphas:tensor([0.3789, 0.0141, 0.0178, 0.0810, 0.5083], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,839 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,839 - train - INFO - True
2024-04-07 03:58:03,844 - train - INFO - alphas:tensor([0.3951, 0.0120, 0.0166, 0.0777, 0.4986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,846 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,847 - train - INFO - True
2024-04-07 03:58:03,853 - train - INFO - alphas:tensor([0.3597, 0.0141, 0.0220, 0.0844, 0.5198], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,856 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,856 - train - INFO - True
2024-04-07 03:58:03,862 - train - INFO - alphas:tensor([0.5188, 0.0120, 0.0189, 0.0580, 0.3922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,867 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,867 - train - INFO - True
2024-04-07 03:58:03,874 - train - INFO - alphas:tensor([0.6544, 0.0108, 0.0173, 0.0486, 0.2688], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,887 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,887 - train - INFO - True
2024-04-07 03:58:03,887 - train - INFO - alphas:tensor([0.3234, 0.0139, 0.0201, 0.0943, 0.5483], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,894 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,894 - train - INFO - True
2024-04-07 03:58:03,895 - train - INFO - alphas:tensor([0.3334, 0.0106, 0.0172, 0.0815, 0.5572], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,902 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,902 - train - INFO - True
2024-04-07 03:58:03,902 - train - INFO - alphas:tensor([0.3584, 0.0104, 0.0148, 0.0816, 0.5350], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,909 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,909 - train - INFO - True
2024-04-07 03:58:03,910 - train - INFO - alphas:tensor([0.3261, 0.0129, 0.0185, 0.0849, 0.5576], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,916 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,916 - train - INFO - True
2024-04-07 03:58:03,917 - train - INFO - alphas:tensor([0.6577, 0.0091, 0.0117, 0.0401, 0.2814], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,930 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,931 - train - INFO - True
2024-04-07 03:58:03,935 - train - INFO - alphas:tensor([0.5009, 0.0200, 0.0259, 0.0771, 0.3762], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:58:03,990 - train - INFO - tau:0.5696012024771592
2024-04-07 03:58:03,990 - train - INFO - avg block size:9.606060606060606
2024-04-07 03:58:03,991 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 03:58:03,991 - train - INFO - lasso_alpha:1.8181818181818185e-05
2024-04-07 03:58:04,288 - train - INFO - Test: [   0/78]  Time: 0.294 (0.294)  Loss:  1.1748 (1.1748)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
2024-04-07 03:58:08,924 - train - INFO - Test: [  50/78]  Time: 0.082 (0.097)  Loss:  1.6523 (1.6515)  Acc@1: 62.5000 (62.2855)  Acc@5: 85.1562 (84.8958)
2024-04-07 03:58:11,716 - train - INFO - Test: [  78/78]  Time: 0.095 (0.098)  Loss:  1.8750 (1.6584)  Acc@1: 56.2500 (62.2700)  Acc@5: 93.7500 (84.4900)
2024-04-07 03:58:12,538 - train - INFO - Train: 59 [   0/781 (  0%)]  Loss:  3.744776 (3.7448)  Time: 0.733s,  174.51/s  (0.733s,  174.51/s)  LR: 3.356e-04  Data: 0.188 (0.188)
2024-04-07 03:58:40,044 - train - INFO - Train: 59 [  50/781 (  6%)]  Loss:  3.824009 (3.7387)  Time: 0.455s,  281.35/s  (0.554s,  231.17/s)  LR: 3.356e-04  Data: 0.005 (0.011)
2024-04-07 03:59:06,854 - train - INFO - Train: 59 [ 100/781 ( 13%)]  Loss:  3.790621 (3.6917)  Time: 0.528s,  242.58/s  (0.545s,  234.85/s)  LR: 3.356e-04  Data: 0.007 (0.009)
2024-04-07 03:59:34,295 - train - INFO - Train: 59 [ 150/781 ( 19%)]  Loss:  3.760291 (3.6921)  Time: 0.522s,  245.13/s  (0.546s,  234.32/s)  LR: 3.356e-04  Data: 0.008 (0.009)
2024-04-07 04:00:01,227 - train - INFO - Train: 59 [ 200/781 ( 26%)]  Loss:  3.789793 (3.6842)  Time: 0.542s,  235.98/s  (0.544s,  235.14/s)  LR: 3.356e-04  Data: 0.008 (0.009)
2024-04-07 04:00:27,051 - train - INFO - Train: 59 [ 250/781 ( 32%)]  Loss:  3.138950 (3.6792)  Time: 0.442s,  289.85/s  (0.539s,  237.56/s)  LR: 3.356e-04  Data: 0.005 (0.008)
2024-04-07 04:00:53,710 - train - INFO - Train: 59 [ 300/781 ( 38%)]  Loss:  3.802632 (3.6832)  Time: 0.545s,  234.80/s  (0.538s,  237.98/s)  LR: 3.356e-04  Data: 0.007 (0.008)
2024-04-07 04:01:20,395 - train - INFO - Train: 59 [ 350/781 ( 45%)]  Loss:  3.712655 (3.6937)  Time: 0.461s,  277.44/s  (0.537s,  238.24/s)  LR: 3.356e-04  Data: 0.008 (0.008)
2024-04-07 04:01:46,591 - train - INFO - Train: 59 [ 400/781 ( 51%)]  Loss:  3.780811 (3.6931)  Time: 0.543s,  235.61/s  (0.536s,  238.99/s)  LR: 3.356e-04  Data: 0.007 (0.008)
2024-04-07 04:02:13,321 - train - INFO - Train: 59 [ 450/781 ( 58%)]  Loss:  3.771838 (3.6924)  Time: 0.446s,  286.71/s  (0.535s,  239.04/s)  LR: 3.356e-04  Data: 0.006 (0.008)
2024-04-07 04:02:40,800 - train - INFO - Train: 59 [ 500/781 ( 64%)]  Loss:  3.672193 (3.6932)  Time: 0.559s,  228.83/s  (0.537s,  238.41/s)  LR: 3.356e-04  Data: 0.005 (0.008)
2024-04-07 04:03:06,712 - train - INFO - Train: 59 [ 550/781 ( 71%)]  Loss:  3.182092 (3.6926)  Time: 0.535s,  239.09/s  (0.535s,  239.17/s)  LR: 3.356e-04  Data: 0.006 (0.008)
2024-04-07 04:03:33,775 - train - INFO - Train: 59 [ 600/781 ( 77%)]  Loss:  3.311370 (3.6917)  Time: 0.546s,  234.41/s  (0.536s,  238.94/s)  LR: 3.356e-04  Data: 0.006 (0.008)
2024-04-07 04:04:00,258 - train - INFO - Train: 59 [ 650/781 ( 83%)]  Loss:  3.988509 (3.6951)  Time: 0.543s,  235.64/s  (0.535s,  239.15/s)  LR: 3.356e-04  Data: 0.008 (0.008)
2024-04-07 04:04:28,298 - train - INFO - Train: 59 [ 700/781 ( 90%)]  Loss:  3.972320 (3.6999)  Time: 0.508s,  251.86/s  (0.537s,  238.34/s)  LR: 3.356e-04  Data: 0.005 (0.008)
2024-04-07 04:04:55,302 - train - INFO - Train: 59 [ 750/781 ( 96%)]  Loss:  3.944516 (3.6974)  Time: 0.503s,  254.59/s  (0.537s,  238.25/s)  LR: 3.356e-04  Data: 0.006 (0.008)
2024-04-07 04:05:11,348 - train - INFO - Train: 59 [ 780/781 (100%)]  Loss:  4.117173 (3.6978)  Time: 0.559s,  228.88/s  (0.537s,  238.29/s)  LR: 3.356e-04  Data: 0.000 (0.008)
2024-04-07 04:05:11,349 - train - INFO - True
2024-04-07 04:05:11,357 - train - INFO - alphas:tensor([0.5526, 0.0662, 0.0823, 0.1096, 0.1892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,358 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,358 - train - INFO - True
2024-04-07 04:05:11,366 - train - INFO - alphas:tensor([0.4061, 0.0338, 0.0515, 0.1035, 0.4051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,367 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,367 - train - INFO - True
2024-04-07 04:05:11,369 - train - INFO - alphas:tensor([0.4347, 0.0513, 0.0999, 0.4141], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,370 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,370 - train - INFO - True
2024-04-07 04:05:11,371 - train - INFO - alphas:tensor([0.3778, 0.0475, 0.0815, 0.4931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,372 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,372 - train - INFO - True
2024-04-07 04:05:11,373 - train - INFO - alphas:tensor([0.3836, 0.0383, 0.0896, 0.4884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,374 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,374 - train - INFO - True
2024-04-07 04:05:11,375 - train - INFO - alphas:tensor([0.4615, 0.0484, 0.0811, 0.4090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,376 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,376 - train - INFO - True
2024-04-07 04:05:11,378 - train - INFO - alphas:tensor([0.5042, 0.0337, 0.0413, 0.0822, 0.3386], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,379 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,379 - train - INFO - True
2024-04-07 04:05:11,381 - train - INFO - alphas:tensor([0.2109, 0.0188, 0.0180, 0.0728, 0.6795], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,381 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,382 - train - INFO - True
2024-04-07 04:05:11,383 - train - INFO - alphas:tensor([0.2194, 0.0159, 0.0197, 0.0608, 0.6841], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,384 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,384 - train - INFO - True
2024-04-07 04:05:11,385 - train - INFO - alphas:tensor([0.2188, 0.0129, 0.0178, 0.0646, 0.6859], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,386 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,386 - train - INFO - True
2024-04-07 04:05:11,387 - train - INFO - alphas:tensor([0.2036, 0.0172, 0.0182, 0.0741, 0.6869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,388 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,388 - train - INFO - True
2024-04-07 04:05:11,389 - train - INFO - alphas:tensor([0.5129, 0.0206, 0.0314, 0.0755, 0.3596], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,391 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,391 - train - INFO - True
2024-04-07 04:05:11,392 - train - INFO - alphas:tensor([0.6000, 0.0230, 0.0276, 0.0601, 0.2893], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,397 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,397 - train - INFO - True
2024-04-07 04:05:11,398 - train - INFO - alphas:tensor([0.2168, 0.0294, 0.0306, 0.1121, 0.6111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,400 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,400 - train - INFO - True
2024-04-07 04:05:11,401 - train - INFO - alphas:tensor([0.2292, 0.0211, 0.0261, 0.1062, 0.6174], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,404 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,404 - train - INFO - True
2024-04-07 04:05:11,405 - train - INFO - alphas:tensor([0.2563, 0.0179, 0.0243, 0.0969, 0.6047], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,407 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,407 - train - INFO - True
2024-04-07 04:05:11,408 - train - INFO - alphas:tensor([0.2204, 0.0241, 0.0296, 0.0975, 0.6284], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,410 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,411 - train - INFO - True
2024-04-07 04:05:11,412 - train - INFO - alphas:tensor([0.2487, 0.0176, 0.0286, 0.0964, 0.6087], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,414 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,414 - train - INFO - True
2024-04-07 04:05:11,415 - train - INFO - alphas:tensor([0.1996, 0.0344, 0.0390, 0.1138, 0.6132], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,417 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,417 - train - INFO - True
2024-04-07 04:05:11,426 - train - INFO - alphas:tensor([0.5611, 0.0158, 0.0220, 0.0666, 0.3346], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,429 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,429 - train - INFO - True
2024-04-07 04:05:11,438 - train - INFO - alphas:tensor([0.4840, 0.0142, 0.0175, 0.0694, 0.4149], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,445 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,445 - train - INFO - True
2024-04-07 04:05:11,453 - train - INFO - alphas:tensor([0.3578, 0.0133, 0.0242, 0.0840, 0.5207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,456 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,457 - train - INFO - True
2024-04-07 04:05:11,465 - train - INFO - alphas:tensor([0.3731, 0.0136, 0.0175, 0.0816, 0.5142], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,469 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,469 - train - INFO - True
2024-04-07 04:05:11,470 - train - INFO - alphas:tensor([0.3896, 0.0118, 0.0164, 0.0794, 0.5028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,473 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,473 - train - INFO - True
2024-04-07 04:05:11,478 - train - INFO - alphas:tensor([0.3519, 0.0137, 0.0223, 0.0858, 0.5263], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,481 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,482 - train - INFO - True
2024-04-07 04:05:11,482 - train - INFO - alphas:tensor([0.5125, 0.0117, 0.0185, 0.0587, 0.3986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,490 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,490 - train - INFO - True
2024-04-07 04:05:11,491 - train - INFO - alphas:tensor([0.6560, 0.0104, 0.0169, 0.0489, 0.2678], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,510 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,510 - train - INFO - True
2024-04-07 04:05:11,511 - train - INFO - alphas:tensor([0.3153, 0.0135, 0.0197, 0.0936, 0.5578], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,521 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,522 - train - INFO - True
2024-04-07 04:05:11,529 - train - INFO - alphas:tensor([0.3239, 0.0101, 0.0171, 0.0832, 0.5658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,539 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,539 - train - INFO - True
2024-04-07 04:05:11,544 - train - INFO - alphas:tensor([0.3514, 0.0103, 0.0145, 0.0835, 0.5403], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,554 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,554 - train - INFO - True
2024-04-07 04:05:11,561 - train - INFO - alphas:tensor([0.3184, 0.0127, 0.0184, 0.0860, 0.5645], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,571 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,572 - train - INFO - True
2024-04-07 04:05:11,572 - train - INFO - alphas:tensor([0.6570, 0.0088, 0.0115, 0.0400, 0.2827], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,592 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,592 - train - INFO - True
2024-04-07 04:05:11,593 - train - INFO - alphas:tensor([0.4916, 0.0199, 0.0261, 0.0792, 0.3833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:05:11,671 - train - INFO - tau:0.5639051904523876
2024-04-07 04:05:11,671 - train - INFO - avg block size:9.606060606060606
2024-04-07 04:05:11,672 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 04:05:11,952 - train - INFO - Test: [   0/78]  Time: 0.276 (0.276)  Loss:  1.0146 (1.0146)  Acc@1: 78.9062 (78.9062)  Acc@5: 93.7500 (93.7500)
2024-04-07 04:05:16,919 - train - INFO - Test: [  50/78]  Time: 0.101 (0.103)  Loss:  1.5244 (1.6090)  Acc@1: 65.6250 (64.0472)  Acc@5: 85.9375 (85.4167)
2024-04-07 04:05:19,675 - train - INFO - Test: [  78/78]  Time: 0.076 (0.101)  Loss:  2.1660 (1.6556)  Acc@1: 43.7500 (63.0300)  Acc@5: 93.7500 (84.5900)
2024-04-07 04:05:20,460 - train - INFO - Train: 60 [   0/781 (  0%)]  Loss:  3.708033 (3.7080)  Time: 0.703s,  182.07/s  (0.703s,  182.07/s)  LR: 3.307e-04  Data: 0.185 (0.185)
2024-04-07 04:05:47,688 - train - INFO - Train: 60 [  50/781 (  6%)]  Loss:  3.842464 (3.6952)  Time: 0.435s,  294.22/s  (0.548s,  233.74/s)  LR: 3.307e-04  Data: 0.004 (0.011)
2024-04-07 04:06:15,091 - train - INFO - Train: 60 [ 100/781 ( 13%)]  Loss:  3.303843 (3.6735)  Time: 0.534s,  239.62/s  (0.548s,  233.65/s)  LR: 3.307e-04  Data: 0.007 (0.010)
2024-04-07 04:06:41,983 - train - INFO - Train: 60 [ 150/781 ( 19%)]  Loss:  3.370436 (3.6913)  Time: 0.572s,  223.96/s  (0.545s,  235.07/s)  LR: 3.307e-04  Data: 0.006 (0.009)
2024-04-07 04:07:09,897 - train - INFO - Train: 60 [ 200/781 ( 26%)]  Loss:  3.465338 (3.6840)  Time: 0.528s,  242.52/s  (0.548s,  233.61/s)  LR: 3.307e-04  Data: 0.010 (0.009)
2024-04-07 04:07:36,445 - train - INFO - Train: 60 [ 250/781 ( 32%)]  Loss:  3.707736 (3.6989)  Time: 0.512s,  249.87/s  (0.545s,  235.06/s)  LR: 3.307e-04  Data: 0.009 (0.009)
2024-04-07 04:08:02,746 - train - INFO - Train: 60 [ 300/781 ( 38%)]  Loss:  3.829273 (3.6913)  Time: 0.522s,  245.32/s  (0.541s,  236.40/s)  LR: 3.307e-04  Data: 0.009 (0.009)
2024-04-07 04:08:29,356 - train - INFO - Train: 60 [ 350/781 ( 45%)]  Loss:  3.802354 (3.6878)  Time: 0.564s,  226.93/s  (0.540s,  236.98/s)  LR: 3.307e-04  Data: 0.005 (0.008)
2024-04-07 04:08:56,035 - train - INFO - Train: 60 [ 400/781 ( 51%)]  Loss:  3.434180 (3.6851)  Time: 0.392s,  326.92/s  (0.539s,  237.34/s)  LR: 3.307e-04  Data: 0.008 (0.008)
2024-04-07 04:09:22,430 - train - INFO - Train: 60 [ 450/781 ( 58%)]  Loss:  3.881874 (3.6904)  Time: 0.529s,  241.95/s  (0.538s,  237.90/s)  LR: 3.307e-04  Data: 0.012 (0.008)
2024-04-07 04:09:49,646 - train - INFO - Train: 60 [ 500/781 ( 64%)]  Loss:  3.849946 (3.6939)  Time: 0.536s,  238.68/s  (0.539s,  237.62/s)  LR: 3.307e-04  Data: 0.009 (0.008)
2024-04-07 04:10:16,861 - train - INFO - Train: 60 [ 550/781 ( 71%)]  Loss:  3.474026 (3.6934)  Time: 0.504s,  254.02/s  (0.539s,  237.40/s)  LR: 3.307e-04  Data: 0.007 (0.008)
2024-04-07 04:10:44,004 - train - INFO - Train: 60 [ 600/781 ( 77%)]  Loss:  3.569063 (3.6883)  Time: 0.565s,  226.43/s  (0.539s,  237.27/s)  LR: 3.307e-04  Data: 0.007 (0.008)
2024-04-07 04:11:10,984 - train - INFO - Train: 60 [ 650/781 ( 83%)]  Loss:  3.716891 (3.6873)  Time: 0.513s,  249.57/s  (0.539s,  237.26/s)  LR: 3.307e-04  Data: 0.008 (0.008)
2024-04-07 04:11:37,504 - train - INFO - Train: 60 [ 700/781 ( 90%)]  Loss:  3.915796 (3.6859)  Time: 0.565s,  226.65/s  (0.539s,  237.55/s)  LR: 3.307e-04  Data: 0.006 (0.008)
2024-04-07 04:12:03,343 - train - INFO - Train: 60 [ 750/781 ( 96%)]  Loss:  3.644928 (3.6846)  Time: 0.439s,  291.89/s  (0.537s,  238.20/s)  LR: 3.307e-04  Data: 0.005 (0.008)
2024-04-07 04:12:19,391 - train - INFO - Train: 60 [ 780/781 (100%)]  Loss:  3.716821 (3.6877)  Time: 0.450s,  284.40/s  (0.537s,  238.24/s)  LR: 3.307e-04  Data: 0.000 (0.008)
2024-04-07 04:12:19,392 - train - INFO - True
2024-04-07 04:12:19,396 - train - INFO - alphas:tensor([0.5534, 0.0655, 0.0819, 0.1090, 0.1902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,397 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,397 - train - INFO - True
2024-04-07 04:12:19,398 - train - INFO - alphas:tensor([0.4059, 0.0329, 0.0506, 0.1016, 0.4089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,399 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,399 - train - INFO - True
2024-04-07 04:12:19,400 - train - INFO - alphas:tensor([0.4338, 0.0504, 0.0991, 0.4167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,401 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,401 - train - INFO - True
2024-04-07 04:12:19,402 - train - INFO - alphas:tensor([0.3784, 0.0466, 0.0803, 0.4946], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,403 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,403 - train - INFO - True
2024-04-07 04:12:19,404 - train - INFO - alphas:tensor([0.3787, 0.0375, 0.0878, 0.4961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,404 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,404 - train - INFO - True
2024-04-07 04:12:19,406 - train - INFO - alphas:tensor([0.4619, 0.0472, 0.0801, 0.4107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,406 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,407 - train - INFO - True
2024-04-07 04:12:19,408 - train - INFO - alphas:tensor([0.5035, 0.0332, 0.0406, 0.0814, 0.3413], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,409 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,409 - train - INFO - True
2024-04-07 04:12:19,410 - train - INFO - alphas:tensor([0.2081, 0.0185, 0.0180, 0.0732, 0.6822], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,411 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,411 - train - INFO - True
2024-04-07 04:12:19,412 - train - INFO - alphas:tensor([0.2174, 0.0155, 0.0190, 0.0597, 0.6884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,413 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,413 - train - INFO - True
2024-04-07 04:12:19,414 - train - INFO - alphas:tensor([0.2170, 0.0126, 0.0173, 0.0644, 0.6887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,415 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,415 - train - INFO - True
2024-04-07 04:12:19,416 - train - INFO - alphas:tensor([0.2042, 0.0169, 0.0181, 0.0740, 0.6868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,417 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,417 - train - INFO - True
2024-04-07 04:12:19,418 - train - INFO - alphas:tensor([0.5145, 0.0199, 0.0310, 0.0752, 0.3595], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,419 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,419 - train - INFO - True
2024-04-07 04:12:19,420 - train - INFO - alphas:tensor([0.5989, 0.0226, 0.0273, 0.0593, 0.2918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,424 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,424 - train - INFO - True
2024-04-07 04:12:19,425 - train - INFO - alphas:tensor([0.2107, 0.0288, 0.0305, 0.1128, 0.6172], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,427 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,427 - train - INFO - True
2024-04-07 04:12:19,428 - train - INFO - alphas:tensor([0.2285, 0.0206, 0.0259, 0.1064, 0.6186], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,430 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,430 - train - INFO - True
2024-04-07 04:12:19,431 - train - INFO - alphas:tensor([0.2521, 0.0175, 0.0238, 0.0956, 0.6109], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,433 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,433 - train - INFO - True
2024-04-07 04:12:19,434 - train - INFO - alphas:tensor([0.2221, 0.0236, 0.0289, 0.0969, 0.6285], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,436 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,436 - train - INFO - True
2024-04-07 04:12:19,437 - train - INFO - alphas:tensor([0.2486, 0.0175, 0.0286, 0.0950, 0.6103], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,439 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,439 - train - INFO - True
2024-04-07 04:12:19,446 - train - INFO - alphas:tensor([0.1987, 0.0335, 0.0385, 0.1126, 0.6166], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,448 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,448 - train - INFO - True
2024-04-07 04:12:19,455 - train - INFO - alphas:tensor([0.5564, 0.0153, 0.0217, 0.0668, 0.3398], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,459 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,459 - train - INFO - True
2024-04-07 04:12:19,464 - train - INFO - alphas:tensor([0.4869, 0.0138, 0.0169, 0.0684, 0.4140], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,471 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,471 - train - INFO - True
2024-04-07 04:12:19,481 - train - INFO - alphas:tensor([0.3570, 0.0130, 0.0231, 0.0834, 0.5234], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,490 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,490 - train - INFO - True
2024-04-07 04:12:19,491 - train - INFO - alphas:tensor([0.3677, 0.0131, 0.0172, 0.0819, 0.5201], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,494 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,494 - train - INFO - True
2024-04-07 04:12:19,495 - train - INFO - alphas:tensor([0.3825, 0.0114, 0.0163, 0.0789, 0.5108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,498 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,498 - train - INFO - True
2024-04-07 04:12:19,499 - train - INFO - alphas:tensor([0.3505, 0.0130, 0.0216, 0.0837, 0.5312], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,502 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,502 - train - INFO - True
2024-04-07 04:12:19,503 - train - INFO - alphas:tensor([0.5092, 0.0114, 0.0186, 0.0581, 0.4027], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,509 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,509 - train - INFO - True
2024-04-07 04:12:19,510 - train - INFO - alphas:tensor([0.6559, 0.0101, 0.0166, 0.0485, 0.2690], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,524 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,524 - train - INFO - True
2024-04-07 04:12:19,525 - train - INFO - alphas:tensor([0.3111, 0.0131, 0.0190, 0.0917, 0.5650], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,532 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,533 - train - INFO - True
2024-04-07 04:12:19,538 - train - INFO - alphas:tensor([0.3198, 0.0097, 0.0168, 0.0820, 0.5718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,545 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,546 - train - INFO - True
2024-04-07 04:12:19,553 - train - INFO - alphas:tensor([0.3496, 0.0100, 0.0142, 0.0827, 0.5435], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,560 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,560 - train - INFO - True
2024-04-07 04:12:19,564 - train - INFO - alphas:tensor([0.3145, 0.0123, 0.0179, 0.0865, 0.5687], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,571 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,571 - train - INFO - True
2024-04-07 04:12:19,576 - train - INFO - alphas:tensor([0.6548, 0.0085, 0.0112, 0.0397, 0.2858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,589 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,589 - train - INFO - True
2024-04-07 04:12:19,590 - train - INFO - alphas:tensor([0.4899, 0.0197, 0.0262, 0.0781, 0.3861], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:12:19,645 - train - INFO - tau:0.5582661385478638
2024-04-07 04:12:19,645 - train - INFO - avg block size:10.06060606060606
2024-04-07 04:12:19,645 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 04:12:19,645 - train - INFO - lasso_alpha:1.652892561983471e-05
2024-04-07 04:12:19,845 - train - INFO - Test: [   0/78]  Time: 0.196 (0.196)  Loss:  1.1211 (1.1211)  Acc@1: 78.9062 (78.9062)  Acc@5: 92.1875 (92.1875)
2024-04-07 04:12:24,926 - train - INFO - Test: [  50/78]  Time: 0.100 (0.103)  Loss:  1.5654 (1.6167)  Acc@1: 64.0625 (63.6795)  Acc@5: 89.0625 (85.8150)
2024-04-07 04:12:27,675 - train - INFO - Test: [  78/78]  Time: 0.075 (0.102)  Loss:  1.8779 (1.6471)  Acc@1: 62.5000 (63.1900)  Acc@5: 87.5000 (85.1000)
2024-04-07 04:12:28,472 - train - INFO - Train: 61 [   0/781 (  0%)]  Loss:  3.150465 (3.1505)  Time: 0.711s,  180.06/s  (0.711s,  180.06/s)  LR: 3.258e-04  Data: 0.205 (0.205)
2024-04-07 04:12:55,071 - train - INFO - Train: 61 [  50/781 (  6%)]  Loss:  3.900870 (3.6871)  Time: 0.460s,  278.55/s  (0.535s,  239.04/s)  LR: 3.258e-04  Data: 0.007 (0.012)
2024-04-07 04:13:21,678 - train - INFO - Train: 61 [ 100/781 ( 13%)]  Loss:  3.732265 (3.6820)  Time: 0.470s,  272.08/s  (0.534s,  239.79/s)  LR: 3.258e-04  Data: 0.007 (0.010)
2024-04-07 04:13:47,793 - train - INFO - Train: 61 [ 150/781 ( 19%)]  Loss:  3.408416 (3.6749)  Time: 0.535s,  239.21/s  (0.530s,  241.52/s)  LR: 3.258e-04  Data: 0.007 (0.009)
2024-04-07 04:14:15,521 - train - INFO - Train: 61 [ 200/781 ( 26%)]  Loss:  3.490224 (3.6749)  Time: 0.559s,  229.16/s  (0.536s,  238.77/s)  LR: 3.258e-04  Data: 0.007 (0.009)
2024-04-07 04:14:42,594 - train - INFO - Train: 61 [ 250/781 ( 32%)]  Loss:  3.801842 (3.6773)  Time: 0.564s,  226.82/s  (0.537s,  238.29/s)  LR: 3.258e-04  Data: 0.008 (0.009)
2024-04-07 04:15:09,302 - train - INFO - Train: 61 [ 300/781 ( 38%)]  Loss:  3.959968 (3.6728)  Time: 0.582s,  220.00/s  (0.537s,  238.52/s)  LR: 3.258e-04  Data: 0.012 (0.009)
2024-04-07 04:15:35,459 - train - INFO - Train: 61 [ 350/781 ( 45%)]  Loss:  3.475885 (3.6716)  Time: 0.554s,  231.21/s  (0.535s,  239.38/s)  LR: 3.258e-04  Data: 0.009 (0.008)
2024-04-07 04:16:01,929 - train - INFO - Train: 61 [ 400/781 ( 51%)]  Loss:  3.872351 (3.6730)  Time: 0.445s,  287.55/s  (0.534s,  239.68/s)  LR: 3.258e-04  Data: 0.015 (0.008)
2024-04-07 04:16:28,429 - train - INFO - Train: 61 [ 450/781 ( 58%)]  Loss:  3.823387 (3.6735)  Time: 0.547s,  234.14/s  (0.534s,  239.88/s)  LR: 3.258e-04  Data: 0.010 (0.008)
2024-04-07 04:16:56,002 - train - INFO - Train: 61 [ 500/781 ( 64%)]  Loss:  3.733944 (3.6760)  Time: 0.577s,  221.85/s  (0.535s,  239.08/s)  LR: 3.258e-04  Data: 0.009 (0.008)
2024-04-07 04:17:21,987 - train - INFO - Train: 61 [ 550/781 ( 71%)]  Loss:  3.673008 (3.6729)  Time: 0.518s,  247.06/s  (0.534s,  239.72/s)  LR: 3.258e-04  Data: 0.015 (0.008)
2024-04-07 04:17:49,577 - train - INFO - Train: 61 [ 600/781 ( 77%)]  Loss:  3.387940 (3.6737)  Time: 0.547s,  233.98/s  (0.535s,  239.06/s)  LR: 3.258e-04  Data: 0.011 (0.008)
2024-04-07 04:18:16,900 - train - INFO - Train: 61 [ 650/781 ( 83%)]  Loss:  3.774715 (3.6727)  Time: 0.551s,  232.44/s  (0.536s,  238.68/s)  LR: 3.258e-04  Data: 0.008 (0.008)
2024-04-07 04:18:44,485 - train - INFO - Train: 61 [ 700/781 ( 90%)]  Loss:  3.659336 (3.6702)  Time: 0.544s,  235.21/s  (0.537s,  238.19/s)  LR: 3.258e-04  Data: 0.006 (0.008)
2024-04-07 04:19:10,928 - train - INFO - Train: 61 [ 750/781 ( 96%)]  Loss:  3.533332 (3.6652)  Time: 0.460s,  278.14/s  (0.537s,  238.45/s)  LR: 3.258e-04  Data: 0.006 (0.008)
2024-04-07 04:19:27,403 - train - INFO - Train: 61 [ 780/781 (100%)]  Loss:  3.728662 (3.6663)  Time: 0.548s,  233.41/s  (0.537s,  238.24/s)  LR: 3.258e-04  Data: 0.000 (0.008)
2024-04-07 04:19:27,404 - train - INFO - True
2024-04-07 04:19:27,406 - train - INFO - alphas:tensor([0.5539, 0.0644, 0.0811, 0.1087, 0.1920], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,407 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,407 - train - INFO - True
2024-04-07 04:19:27,409 - train - INFO - alphas:tensor([0.4041, 0.0324, 0.0504, 0.1008, 0.4122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,410 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,410 - train - INFO - True
2024-04-07 04:19:27,411 - train - INFO - alphas:tensor([0.4317, 0.0494, 0.0983, 0.4206], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,413 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,413 - train - INFO - True
2024-04-07 04:19:27,414 - train - INFO - alphas:tensor([0.3809, 0.0452, 0.0792, 0.4947], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,415 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,415 - train - INFO - True
2024-04-07 04:19:27,417 - train - INFO - alphas:tensor([0.3803, 0.0365, 0.0866, 0.4966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,417 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,418 - train - INFO - True
2024-04-07 04:19:27,419 - train - INFO - alphas:tensor([0.4605, 0.0469, 0.0792, 0.4134], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,420 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,420 - train - INFO - True
2024-04-07 04:19:27,422 - train - INFO - alphas:tensor([0.5069, 0.0323, 0.0396, 0.0804, 0.3408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,423 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,424 - train - INFO - True
2024-04-07 04:19:27,425 - train - INFO - alphas:tensor([0.2094, 0.0182, 0.0177, 0.0718, 0.6829], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,426 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,426 - train - INFO - True
2024-04-07 04:19:27,428 - train - INFO - alphas:tensor([0.2192, 0.0152, 0.0188, 0.0601, 0.6867], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,429 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,429 - train - INFO - True
2024-04-07 04:19:27,430 - train - INFO - alphas:tensor([0.2190, 0.0121, 0.0168, 0.0634, 0.6886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,431 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,431 - train - INFO - True
2024-04-07 04:19:27,433 - train - INFO - alphas:tensor([0.2038, 0.0164, 0.0176, 0.0733, 0.6889], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,434 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,434 - train - INFO - True
2024-04-07 04:19:27,435 - train - INFO - alphas:tensor([0.5116, 0.0193, 0.0298, 0.0743, 0.3649], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,437 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,437 - train - INFO - True
2024-04-07 04:19:27,438 - train - INFO - alphas:tensor([0.6015, 0.0221, 0.0264, 0.0584, 0.2917], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,443 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,443 - train - INFO - True
2024-04-07 04:19:27,450 - train - INFO - alphas:tensor([0.2184, 0.0287, 0.0308, 0.1122, 0.6099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,452 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,453 - train - INFO - True
2024-04-07 04:19:27,461 - train - INFO - alphas:tensor([0.2347, 0.0202, 0.0255, 0.1063, 0.6133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,464 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,464 - train - INFO - True
2024-04-07 04:19:27,471 - train - INFO - alphas:tensor([0.2538, 0.0171, 0.0230, 0.0959, 0.6102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,473 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,474 - train - INFO - True
2024-04-07 04:19:27,483 - train - INFO - alphas:tensor([0.2243, 0.0226, 0.0283, 0.0949, 0.6299], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,485 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,485 - train - INFO - True
2024-04-07 04:19:27,492 - train - INFO - alphas:tensor([0.2491, 0.0172, 0.0279, 0.0952, 0.6106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,494 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,494 - train - INFO - True
2024-04-07 04:19:27,495 - train - INFO - alphas:tensor([0.1975, 0.0323, 0.0383, 0.1127, 0.6192], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,497 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,497 - train - INFO - True
2024-04-07 04:19:27,498 - train - INFO - alphas:tensor([0.5633, 0.0149, 0.0209, 0.0659, 0.3350], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,502 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,502 - train - INFO - True
2024-04-07 04:19:27,503 - train - INFO - alphas:tensor([0.4879, 0.0132, 0.0165, 0.0682, 0.4142], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,511 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,511 - train - INFO - True
2024-04-07 04:19:27,512 - train - INFO - alphas:tensor([0.3617, 0.0127, 0.0232, 0.0826, 0.5198], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,516 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,516 - train - INFO - True
2024-04-07 04:19:27,517 - train - INFO - alphas:tensor([0.3730, 0.0127, 0.0168, 0.0811, 0.5164], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,520 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,521 - train - INFO - True
2024-04-07 04:19:27,521 - train - INFO - alphas:tensor([0.3905, 0.0111, 0.0159, 0.0778, 0.5047], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,525 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,525 - train - INFO - True
2024-04-07 04:19:27,526 - train - INFO - alphas:tensor([0.3552, 0.0128, 0.0212, 0.0833, 0.5275], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,530 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,530 - train - INFO - True
2024-04-07 04:19:27,531 - train - INFO - alphas:tensor([0.5070, 0.0111, 0.0181, 0.0579, 0.4059], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,539 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,539 - train - INFO - True
2024-04-07 04:19:27,547 - train - INFO - alphas:tensor([0.6567, 0.0098, 0.0162, 0.0476, 0.2697], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,566 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,566 - train - INFO - True
2024-04-07 04:19:27,572 - train - INFO - alphas:tensor([0.3153, 0.0131, 0.0184, 0.0923, 0.5608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,582 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,582 - train - INFO - True
2024-04-07 04:19:27,584 - train - INFO - alphas:tensor([0.3253, 0.0095, 0.0162, 0.0811, 0.5679], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,594 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,594 - train - INFO - True
2024-04-07 04:19:27,595 - train - INFO - alphas:tensor([0.3614, 0.0099, 0.0141, 0.0814, 0.5332], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,605 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,605 - train - INFO - True
2024-04-07 04:19:27,606 - train - INFO - alphas:tensor([0.3145, 0.0120, 0.0179, 0.0862, 0.5695], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,616 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,616 - train - INFO - True
2024-04-07 04:19:27,617 - train - INFO - alphas:tensor([0.6566, 0.0083, 0.0111, 0.0395, 0.2845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,637 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,637 - train - INFO - True
2024-04-07 04:19:27,645 - train - INFO - alphas:tensor([0.4903, 0.0197, 0.0260, 0.0786, 0.3853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:19:27,722 - train - INFO - tau:0.5526834771623851
2024-04-07 04:19:27,722 - train - INFO - avg block size:10.06060606060606
2024-04-07 04:19:27,723 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 04:19:27,959 - train - INFO - Test: [   0/78]  Time: 0.232 (0.232)  Loss:  1.1250 (1.1250)  Acc@1: 78.1250 (78.1250)  Acc@5: 92.1875 (92.1875)
2024-04-07 04:19:33,212 - train - INFO - Test: [  50/78]  Time: 0.100 (0.108)  Loss:  1.7773 (1.6284)  Acc@1: 57.8125 (63.4651)  Acc@5: 84.3750 (85.8456)
2024-04-07 04:19:35,985 - train - INFO - Test: [  78/78]  Time: 0.098 (0.105)  Loss:  1.9658 (1.6470)  Acc@1: 50.0000 (63.0300)  Acc@5: 87.5000 (85.3200)
2024-04-07 04:19:36,842 - train - INFO - Train: 62 [   0/781 (  0%)]  Loss:  3.904569 (3.9046)  Time: 0.775s,  165.25/s  (0.775s,  165.25/s)  LR: 3.209e-04  Data: 0.183 (0.183)
2024-04-07 04:20:03,853 - train - INFO - Train: 62 [  50/781 (  6%)]  Loss:  3.618025 (3.6666)  Time: 0.472s,  271.04/s  (0.545s,  234.96/s)  LR: 3.209e-04  Data: 0.005 (0.012)
2024-04-07 04:20:31,128 - train - INFO - Train: 62 [ 100/781 ( 13%)]  Loss:  3.462888 (3.6775)  Time: 0.527s,  243.03/s  (0.545s,  234.81/s)  LR: 3.209e-04  Data: 0.007 (0.010)
2024-04-07 04:20:58,244 - train - INFO - Train: 62 [ 150/781 ( 19%)]  Loss:  3.789047 (3.6798)  Time: 0.491s,  260.88/s  (0.544s,  235.21/s)  LR: 3.209e-04  Data: 0.009 (0.009)
2024-04-07 04:21:25,367 - train - INFO - Train: 62 [ 200/781 ( 26%)]  Loss:  3.484500 (3.6865)  Time: 0.506s,  252.93/s  (0.544s,  235.40/s)  LR: 3.209e-04  Data: 0.005 (0.009)
2024-04-07 04:21:51,271 - train - INFO - Train: 62 [ 250/781 ( 32%)]  Loss:  3.641057 (3.6812)  Time: 0.398s,  321.55/s  (0.539s,  237.64/s)  LR: 3.209e-04  Data: 0.005 (0.008)
2024-04-07 04:22:18,397 - train - INFO - Train: 62 [ 300/781 ( 38%)]  Loss:  3.882620 (3.6887)  Time: 0.514s,  248.90/s  (0.539s,  237.36/s)  LR: 3.209e-04  Data: 0.009 (0.008)
2024-04-07 04:22:44,879 - train - INFO - Train: 62 [ 350/781 ( 45%)]  Loss:  3.532185 (3.6826)  Time: 0.499s,  256.56/s  (0.538s,  237.97/s)  LR: 3.209e-04  Data: 0.005 (0.008)
2024-04-07 04:23:12,496 - train - INFO - Train: 62 [ 400/781 ( 51%)]  Loss:  3.889435 (3.6785)  Time: 0.534s,  239.75/s  (0.540s,  237.17/s)  LR: 3.209e-04  Data: 0.005 (0.008)
2024-04-07 04:23:38,192 - train - INFO - Train: 62 [ 450/781 ( 58%)]  Loss:  3.869753 (3.6774)  Time: 0.558s,  229.54/s  (0.537s,  238.44/s)  LR: 3.209e-04  Data: 0.006 (0.008)
2024-04-07 04:24:05,326 - train - INFO - Train: 62 [ 500/781 ( 64%)]  Loss:  3.577710 (3.6792)  Time: 0.558s,  229.24/s  (0.537s,  238.18/s)  LR: 3.209e-04  Data: 0.008 (0.008)
2024-04-07 04:24:32,064 - train - INFO - Train: 62 [ 550/781 ( 71%)]  Loss:  3.748013 (3.6811)  Time: 0.522s,  245.17/s  (0.537s,  238.29/s)  LR: 3.209e-04  Data: 0.009 (0.008)
2024-04-07 04:25:00,127 - train - INFO - Train: 62 [ 600/781 ( 77%)]  Loss:  3.703878 (3.6836)  Time: 0.572s,  223.78/s  (0.539s,  237.40/s)  LR: 3.209e-04  Data: 0.009 (0.008)
2024-04-07 04:25:26,634 - train - INFO - Train: 62 [ 650/781 ( 83%)]  Loss:  3.575738 (3.6864)  Time: 0.491s,  260.76/s  (0.538s,  237.71/s)  LR: 3.209e-04  Data: 0.009 (0.008)
2024-04-07 04:25:54,271 - train - INFO - Train: 62 [ 700/781 ( 90%)]  Loss:  3.862537 (3.6857)  Time: 0.576s,  222.04/s  (0.539s,  237.26/s)  LR: 3.209e-04  Data: 0.018 (0.008)
2024-04-07 04:26:20,275 - train - INFO - Train: 62 [ 750/781 ( 96%)]  Loss:  3.773563 (3.6812)  Time: 0.437s,  293.18/s  (0.538s,  237.83/s)  LR: 3.209e-04  Data: 0.005 (0.008)
2024-04-07 04:26:36,993 - train - INFO - Train: 62 [ 780/781 (100%)]  Loss:  3.542219 (3.6808)  Time: 0.537s,  238.46/s  (0.539s,  237.51/s)  LR: 3.209e-04  Data: 0.000 (0.008)
2024-04-07 04:26:36,995 - train - INFO - True
2024-04-07 04:26:36,997 - train - INFO - alphas:tensor([0.5585, 0.0634, 0.0797, 0.1074, 0.1910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:36,998 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:36,998 - train - INFO - True
2024-04-07 04:26:37,000 - train - INFO - alphas:tensor([0.4052, 0.0316, 0.0497, 0.0999, 0.4137], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,000 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,001 - train - INFO - True
2024-04-07 04:26:37,002 - train - INFO - alphas:tensor([0.4352, 0.0482, 0.0962, 0.4205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,002 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,002 - train - INFO - True
2024-04-07 04:26:37,003 - train - INFO - alphas:tensor([0.3815, 0.0440, 0.0780, 0.4965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,004 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,004 - train - INFO - True
2024-04-07 04:26:37,005 - train - INFO - alphas:tensor([0.3823, 0.0356, 0.0864, 0.4956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,005 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,005 - train - INFO - True
2024-04-07 04:26:37,006 - train - INFO - alphas:tensor([0.4634, 0.0458, 0.0780, 0.4128], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,007 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,007 - train - INFO - True
2024-04-07 04:26:37,008 - train - INFO - alphas:tensor([0.5067, 0.0316, 0.0389, 0.0797, 0.3431], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,009 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,009 - train - INFO - True
2024-04-07 04:26:37,010 - train - INFO - alphas:tensor([0.2083, 0.0178, 0.0171, 0.0711, 0.6858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,011 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,011 - train - INFO - True
2024-04-07 04:26:37,012 - train - INFO - alphas:tensor([0.2187, 0.0147, 0.0183, 0.0585, 0.6897], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,013 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,013 - train - INFO - True
2024-04-07 04:26:37,014 - train - INFO - alphas:tensor([0.2180, 0.0115, 0.0161, 0.0617, 0.6927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,015 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,015 - train - INFO - True
2024-04-07 04:26:37,016 - train - INFO - alphas:tensor([0.2033, 0.0161, 0.0171, 0.0722, 0.6913], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,016 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,016 - train - INFO - True
2024-04-07 04:26:37,017 - train - INFO - alphas:tensor([0.5139, 0.0190, 0.0291, 0.0731, 0.3649], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,019 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,019 - train - INFO - True
2024-04-07 04:26:37,020 - train - INFO - alphas:tensor([0.6028, 0.0215, 0.0257, 0.0575, 0.2925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,023 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,023 - train - INFO - True
2024-04-07 04:26:37,032 - train - INFO - alphas:tensor([0.2176, 0.0281, 0.0292, 0.1126, 0.6125], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,034 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,034 - train - INFO - True
2024-04-07 04:26:37,042 - train - INFO - alphas:tensor([0.2291, 0.0196, 0.0246, 0.1067, 0.6200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,044 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,044 - train - INFO - True
2024-04-07 04:26:37,051 - train - INFO - alphas:tensor([0.2492, 0.0168, 0.0224, 0.0947, 0.6169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,053 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,053 - train - INFO - True
2024-04-07 04:26:37,061 - train - INFO - alphas:tensor([0.2239, 0.0221, 0.0275, 0.0939, 0.6326], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,063 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,063 - train - INFO - True
2024-04-07 04:26:37,070 - train - INFO - alphas:tensor([0.2489, 0.0169, 0.0274, 0.0942, 0.6127], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,072 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,072 - train - INFO - True
2024-04-07 04:26:37,075 - train - INFO - alphas:tensor([0.2046, 0.0320, 0.0376, 0.1116, 0.6141], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,077 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,077 - train - INFO - True
2024-04-07 04:26:37,078 - train - INFO - alphas:tensor([0.5590, 0.0144, 0.0205, 0.0661, 0.3399], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,082 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,082 - train - INFO - True
2024-04-07 04:26:37,083 - train - INFO - alphas:tensor([0.4829, 0.0131, 0.0163, 0.0687, 0.4190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,090 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,090 - train - INFO - True
2024-04-07 04:26:37,091 - train - INFO - alphas:tensor([0.3631, 0.0123, 0.0227, 0.0817, 0.5202], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,095 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,095 - train - INFO - True
2024-04-07 04:26:37,096 - train - INFO - alphas:tensor([0.3748, 0.0126, 0.0165, 0.0792, 0.5169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,100 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,100 - train - INFO - True
2024-04-07 04:26:37,101 - train - INFO - alphas:tensor([0.3913, 0.0109, 0.0155, 0.0756, 0.5067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,105 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,105 - train - INFO - True
2024-04-07 04:26:37,106 - train - INFO - alphas:tensor([0.3530, 0.0124, 0.0204, 0.0822, 0.5320], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,110 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,110 - train - INFO - True
2024-04-07 04:26:37,111 - train - INFO - alphas:tensor([0.5126, 0.0107, 0.0177, 0.0575, 0.4015], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,118 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,118 - train - INFO - True
2024-04-07 04:26:37,119 - train - INFO - alphas:tensor([0.6588, 0.0096, 0.0157, 0.0466, 0.2692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,138 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,138 - train - INFO - True
2024-04-07 04:26:37,139 - train - INFO - alphas:tensor([0.3194, 0.0127, 0.0182, 0.0929, 0.5568], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,149 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,150 - train - INFO - True
2024-04-07 04:26:37,151 - train - INFO - alphas:tensor([0.3303, 0.0092, 0.0158, 0.0792, 0.5655], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,161 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,161 - train - INFO - True
2024-04-07 04:26:37,162 - train - INFO - alphas:tensor([0.3610, 0.0097, 0.0139, 0.0812, 0.5342], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,172 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,172 - train - INFO - True
2024-04-07 04:26:37,179 - train - INFO - alphas:tensor([0.3177, 0.0118, 0.0171, 0.0854, 0.5680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,189 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,189 - train - INFO - True
2024-04-07 04:26:37,196 - train - INFO - alphas:tensor([0.6573, 0.0080, 0.0107, 0.0387, 0.2854], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,217 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,217 - train - INFO - True
2024-04-07 04:26:37,218 - train - INFO - alphas:tensor([0.4888, 0.0194, 0.0255, 0.0790, 0.3872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:26:37,296 - train - INFO - tau:0.5471566423907612
2024-04-07 04:26:37,296 - train - INFO - avg block size:10.06060606060606
2024-04-07 04:26:37,297 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 04:26:37,297 - train - INFO - lasso_alpha:1.5026296018031554e-05
2024-04-07 04:26:37,522 - train - INFO - Test: [   0/78]  Time: 0.220 (0.220)  Loss:  1.0264 (1.0264)  Acc@1: 78.1250 (78.1250)  Acc@5: 94.5312 (94.5312)
2024-04-07 04:26:42,657 - train - INFO - Test: [  50/78]  Time: 0.099 (0.105)  Loss:  1.7363 (1.6301)  Acc@1: 63.2812 (63.6336)  Acc@5: 82.0312 (84.7426)
2024-04-07 04:26:45,457 - train - INFO - Test: [  78/78]  Time: 0.100 (0.103)  Loss:  1.9922 (1.6534)  Acc@1: 50.0000 (62.8500)  Acc@5: 81.2500 (84.3600)
2024-04-07 04:26:46,201 - train - INFO - Train: 63 [   0/781 (  0%)]  Loss:  3.572608 (3.5726)  Time: 0.659s,  194.10/s  (0.659s,  194.10/s)  LR: 3.159e-04  Data: 0.170 (0.170)
2024-04-07 04:27:12,648 - train - INFO - Train: 63 [  50/781 (  6%)]  Loss:  3.809501 (3.6511)  Time: 0.541s,  236.57/s  (0.531s,  240.84/s)  LR: 3.159e-04  Data: 0.005 (0.011)
2024-04-07 04:27:40,086 - train - INFO - Train: 63 [ 100/781 ( 13%)]  Loss:  3.495690 (3.6348)  Time: 0.508s,  252.17/s  (0.540s,  237.03/s)  LR: 3.159e-04  Data: 0.008 (0.010)
2024-04-07 04:28:07,125 - train - INFO - Train: 63 [ 150/781 ( 19%)]  Loss:  3.825548 (3.6640)  Time: 0.476s,  269.05/s  (0.540s,  236.93/s)  LR: 3.159e-04  Data: 0.009 (0.009)
2024-04-07 04:28:34,784 - train - INFO - Train: 63 [ 200/781 ( 26%)]  Loss:  3.707122 (3.6693)  Time: 0.508s,  252.10/s  (0.543s,  235.53/s)  LR: 3.159e-04  Data: 0.009 (0.009)
2024-04-07 04:29:02,343 - train - INFO - Train: 63 [ 250/781 ( 32%)]  Loss:  3.406089 (3.6601)  Time: 1.086s,  117.83/s  (0.545s,  234.87/s)  LR: 3.159e-04  Data: 0.005 (0.008)
2024-04-07 04:29:29,045 - train - INFO - Train: 63 [ 300/781 ( 38%)]  Loss:  3.769356 (3.6611)  Time: 0.406s,  315.50/s  (0.543s,  235.66/s)  LR: 3.159e-04  Data: 0.004 (0.008)
2024-04-07 04:29:54,973 - train - INFO - Train: 63 [ 350/781 ( 45%)]  Loss:  3.903304 (3.6600)  Time: 0.469s,  272.74/s  (0.540s,  237.19/s)  LR: 3.159e-04  Data: 0.009 (0.008)
2024-04-07 04:30:22,309 - train - INFO - Train: 63 [ 400/781 ( 51%)]  Loss:  3.704386 (3.6680)  Time: 0.663s,  193.18/s  (0.541s,  236.80/s)  LR: 3.159e-04  Data: 0.008 (0.008)
2024-04-07 04:30:48,448 - train - INFO - Train: 63 [ 450/781 ( 58%)]  Loss:  3.474031 (3.6677)  Time: 0.402s,  318.17/s  (0.539s,  237.67/s)  LR: 3.159e-04  Data: 0.005 (0.008)
2024-04-07 04:31:15,300 - train - INFO - Train: 63 [ 500/781 ( 64%)]  Loss:  3.613624 (3.6714)  Time: 0.403s,  317.27/s  (0.538s,  237.74/s)  LR: 3.159e-04  Data: 0.010 (0.008)
2024-04-07 04:31:41,563 - train - INFO - Train: 63 [ 550/781 ( 71%)]  Loss:  3.476115 (3.6700)  Time: 0.474s,  269.85/s  (0.537s,  238.27/s)  LR: 3.159e-04  Data: 0.006 (0.008)
2024-04-07 04:32:09,129 - train - INFO - Train: 63 [ 600/781 ( 77%)]  Loss:  3.897537 (3.6750)  Time: 0.544s,  235.14/s  (0.538s,  237.75/s)  LR: 3.159e-04  Data: 0.008 (0.008)
2024-04-07 04:32:36,001 - train - INFO - Train: 63 [ 650/781 ( 83%)]  Loss:  3.787085 (3.6767)  Time: 0.501s,  255.44/s  (0.538s,  237.78/s)  LR: 3.159e-04  Data: 0.007 (0.008)
2024-04-07 04:33:01,870 - train - INFO - Train: 63 [ 700/781 ( 90%)]  Loss:  3.838088 (3.6782)  Time: 0.389s,  328.99/s  (0.537s,  238.44/s)  LR: 3.159e-04  Data: 0.004 (0.008)
2024-04-07 04:33:29,305 - train - INFO - Train: 63 [ 750/781 ( 96%)]  Loss:  3.347572 (3.6773)  Time: 0.480s,  266.51/s  (0.538s,  238.09/s)  LR: 3.159e-04  Data: 0.005 (0.008)
2024-04-07 04:33:45,113 - train - INFO - Train: 63 [ 780/781 (100%)]  Loss:  3.313016 (3.6767)  Time: 0.528s,  242.50/s  (0.537s,  238.28/s)  LR: 3.159e-04  Data: 0.000 (0.008)
2024-04-07 04:33:45,114 - train - INFO - True
2024-04-07 04:33:45,123 - train - INFO - alphas:tensor([0.5619, 0.0623, 0.0793, 0.1059, 0.1906], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,124 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,124 - train - INFO - True
2024-04-07 04:33:45,131 - train - INFO - alphas:tensor([0.4060, 0.0307, 0.0487, 0.0981, 0.4166], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,131 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,131 - train - INFO - True
2024-04-07 04:33:45,132 - train - INFO - alphas:tensor([0.4369, 0.0475, 0.0954, 0.4203], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,133 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,133 - train - INFO - True
2024-04-07 04:33:45,135 - train - INFO - alphas:tensor([0.3830, 0.0437, 0.0777, 0.4956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,135 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,135 - train - INFO - True
2024-04-07 04:33:45,136 - train - INFO - alphas:tensor([0.3833, 0.0351, 0.0851, 0.4965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,137 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,137 - train - INFO - True
2024-04-07 04:33:45,138 - train - INFO - alphas:tensor([0.4662, 0.0452, 0.0766, 0.4121], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,139 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,139 - train - INFO - True
2024-04-07 04:33:45,140 - train - INFO - alphas:tensor([0.5073, 0.0310, 0.0385, 0.0788, 0.3443], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,142 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,142 - train - INFO - True
2024-04-07 04:33:45,143 - train - INFO - alphas:tensor([0.2133, 0.0176, 0.0167, 0.0706, 0.6819], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,144 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,144 - train - INFO - True
2024-04-07 04:33:45,145 - train - INFO - alphas:tensor([0.2237, 0.0143, 0.0180, 0.0584, 0.6856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,146 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,146 - train - INFO - True
2024-04-07 04:33:45,147 - train - INFO - alphas:tensor([0.2226, 0.0113, 0.0158, 0.0613, 0.6890], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,148 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,148 - train - INFO - True
2024-04-07 04:33:45,149 - train - INFO - alphas:tensor([0.2100, 0.0158, 0.0166, 0.0716, 0.6860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,149 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,150 - train - INFO - True
2024-04-07 04:33:45,151 - train - INFO - alphas:tensor([0.5182, 0.0183, 0.0282, 0.0721, 0.3632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,152 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,152 - train - INFO - True
2024-04-07 04:33:45,153 - train - INFO - alphas:tensor([0.6068, 0.0210, 0.0250, 0.0562, 0.2909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,157 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,157 - train - INFO - True
2024-04-07 04:33:45,158 - train - INFO - alphas:tensor([0.2158, 0.0269, 0.0286, 0.1093, 0.6195], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,160 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,160 - train - INFO - True
2024-04-07 04:33:45,161 - train - INFO - alphas:tensor([0.2336, 0.0193, 0.0238, 0.1062, 0.6171], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,163 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,163 - train - INFO - True
2024-04-07 04:33:45,164 - train - INFO - alphas:tensor([0.2560, 0.0165, 0.0220, 0.0952, 0.6104], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,166 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,167 - train - INFO - True
2024-04-07 04:33:45,168 - train - INFO - alphas:tensor([0.2293, 0.0217, 0.0273, 0.0942, 0.6276], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,170 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,170 - train - INFO - True
2024-04-07 04:33:45,171 - train - INFO - alphas:tensor([0.2540, 0.0163, 0.0268, 0.0922, 0.6107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,173 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,173 - train - INFO - True
2024-04-07 04:33:45,174 - train - INFO - alphas:tensor([0.2083, 0.0314, 0.0366, 0.1109, 0.6128], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,176 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,176 - train - INFO - True
2024-04-07 04:33:45,184 - train - INFO - alphas:tensor([0.5578, 0.0140, 0.0203, 0.0657, 0.3422], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,187 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,187 - train - INFO - True
2024-04-07 04:33:45,196 - train - INFO - alphas:tensor([0.4882, 0.0128, 0.0159, 0.0678, 0.4153], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,203 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,203 - train - INFO - True
2024-04-07 04:33:45,211 - train - INFO - alphas:tensor([0.3635, 0.0116, 0.0222, 0.0816, 0.5212], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,214 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,215 - train - INFO - True
2024-04-07 04:33:45,223 - train - INFO - alphas:tensor([0.3807, 0.0123, 0.0162, 0.0788, 0.5120], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,227 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,227 - train - INFO - True
2024-04-07 04:33:45,228 - train - INFO - alphas:tensor([0.3964, 0.0105, 0.0153, 0.0744, 0.5034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,231 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,232 - train - INFO - True
2024-04-07 04:33:45,232 - train - INFO - alphas:tensor([0.3589, 0.0121, 0.0199, 0.0815, 0.5277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,236 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,236 - train - INFO - True
2024-04-07 04:33:45,237 - train - INFO - alphas:tensor([0.5138, 0.0104, 0.0174, 0.0566, 0.4017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,245 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,245 - train - INFO - True
2024-04-07 04:33:45,246 - train - INFO - alphas:tensor([0.6565, 0.0093, 0.0152, 0.0460, 0.2729], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,265 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,265 - train - INFO - True
2024-04-07 04:33:45,266 - train - INFO - alphas:tensor([0.3218, 0.0125, 0.0182, 0.0932, 0.5543], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,276 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,276 - train - INFO - True
2024-04-07 04:33:45,283 - train - INFO - alphas:tensor([0.3375, 0.0090, 0.0156, 0.0791, 0.5588], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,293 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,293 - train - INFO - True
2024-04-07 04:33:45,300 - train - INFO - alphas:tensor([0.3685, 0.0094, 0.0137, 0.0809, 0.5275], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,310 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,310 - train - INFO - True
2024-04-07 04:33:45,315 - train - INFO - alphas:tensor([0.3262, 0.0115, 0.0169, 0.0855, 0.5598], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,325 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,325 - train - INFO - True
2024-04-07 04:33:45,326 - train - INFO - alphas:tensor([0.6605, 0.0077, 0.0104, 0.0383, 0.2831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,345 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,345 - train - INFO - True
2024-04-07 04:33:45,346 - train - INFO - alphas:tensor([0.4986, 0.0191, 0.0247, 0.0787, 0.3789], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:33:45,425 - train - INFO - tau:0.5416850759668536
2024-04-07 04:33:45,425 - train - INFO - avg block size:10.06060606060606
2024-04-07 04:33:45,426 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 04:33:45,651 - train - INFO - Test: [   0/78]  Time: 0.221 (0.221)  Loss:  1.0088 (1.0088)  Acc@1: 78.9062 (78.9062)  Acc@5: 92.9688 (92.9688)
2024-04-07 04:33:50,906 - train - INFO - Test: [  50/78]  Time: 0.094 (0.107)  Loss:  1.8457 (1.6431)  Acc@1: 57.0312 (63.2659)  Acc@5: 82.0312 (84.9418)
2024-04-07 04:33:53,832 - train - INFO - Test: [  78/78]  Time: 0.097 (0.106)  Loss:  1.8506 (1.6676)  Acc@1: 56.2500 (62.7500)  Acc@5: 87.5000 (84.4100)
2024-04-07 04:33:54,658 - train - INFO - Train: 64 [   0/781 (  0%)]  Loss:  3.553837 (3.5538)  Time: 0.739s,  173.28/s  (0.739s,  173.28/s)  LR: 3.109e-04  Data: 0.193 (0.193)
2024-04-07 04:34:21,369 - train - INFO - Train: 64 [  50/781 (  6%)]  Loss:  3.646958 (3.6051)  Time: 0.538s,  237.82/s  (0.538s,  237.83/s)  LR: 3.109e-04  Data: 0.006 (0.011)
2024-04-07 04:34:48,273 - train - INFO - Train: 64 [ 100/781 ( 13%)]  Loss:  3.367128 (3.6205)  Time: 0.582s,  219.80/s  (0.538s,  237.87/s)  LR: 3.109e-04  Data: 0.009 (0.010)
2024-04-07 04:35:15,387 - train - INFO - Train: 64 [ 150/781 ( 19%)]  Loss:  3.538730 (3.6299)  Time: 0.497s,  257.55/s  (0.539s,  237.26/s)  LR: 3.109e-04  Data: 0.005 (0.009)
2024-04-07 04:35:43,074 - train - INFO - Train: 64 [ 200/781 ( 26%)]  Loss:  3.715257 (3.6217)  Time: 0.541s,  236.65/s  (0.543s,  235.72/s)  LR: 3.109e-04  Data: 0.006 (0.009)
2024-04-07 04:36:10,142 - train - INFO - Train: 64 [ 250/781 ( 32%)]  Loss:  3.318503 (3.6393)  Time: 0.503s,  254.41/s  (0.543s,  235.86/s)  LR: 3.109e-04  Data: 0.009 (0.009)
2024-04-07 04:36:37,691 - train - INFO - Train: 64 [ 300/781 ( 38%)]  Loss:  3.828360 (3.6381)  Time: 0.526s,  243.19/s  (0.544s,  235.27/s)  LR: 3.109e-04  Data: 0.007 (0.009)
2024-04-07 04:37:03,563 - train - INFO - Train: 64 [ 350/781 ( 45%)]  Loss:  3.692272 (3.6459)  Time: 0.480s,  266.60/s  (0.540s,  236.92/s)  LR: 3.109e-04  Data: 0.008 (0.008)
2024-04-07 04:37:29,386 - train - INFO - Train: 64 [ 400/781 ( 51%)]  Loss:  3.661070 (3.6523)  Time: 0.500s,  256.19/s  (0.537s,  238.23/s)  LR: 3.109e-04  Data: 0.005 (0.008)
2024-04-07 04:37:55,301 - train - INFO - Train: 64 [ 450/781 ( 58%)]  Loss:  4.004594 (3.6520)  Time: 0.523s,  244.63/s  (0.535s,  239.17/s)  LR: 3.109e-04  Data: 0.008 (0.008)
2024-04-07 04:38:21,930 - train - INFO - Train: 64 [ 500/781 ( 64%)]  Loss:  3.314943 (3.6471)  Time: 0.534s,  239.78/s  (0.535s,  239.29/s)  LR: 3.109e-04  Data: 0.006 (0.008)
2024-04-07 04:38:49,180 - train - INFO - Train: 64 [ 550/781 ( 71%)]  Loss:  3.442779 (3.6495)  Time: 0.484s,  264.37/s  (0.536s,  238.88/s)  LR: 3.109e-04  Data: 0.005 (0.008)
2024-04-07 04:39:16,207 - train - INFO - Train: 64 [ 600/781 ( 77%)]  Loss:  3.830539 (3.6542)  Time: 0.520s,  246.28/s  (0.536s,  238.71/s)  LR: 3.109e-04  Data: 0.007 (0.008)
2024-04-07 04:39:43,725 - train - INFO - Train: 64 [ 650/781 ( 83%)]  Loss:  3.461056 (3.6570)  Time: 0.479s,  267.15/s  (0.537s,  238.23/s)  LR: 3.109e-04  Data: 0.006 (0.008)
2024-04-07 04:40:10,882 - train - INFO - Train: 64 [ 700/781 ( 90%)]  Loss:  3.753162 (3.6590)  Time: 0.547s,  234.05/s  (0.538s,  238.04/s)  LR: 3.109e-04  Data: 0.008 (0.008)
2024-04-07 04:40:37,487 - train - INFO - Train: 64 [ 750/781 ( 96%)]  Loss:  3.686589 (3.6572)  Time: 0.455s,  281.59/s  (0.537s,  238.21/s)  LR: 3.109e-04  Data: 0.005 (0.008)
2024-04-07 04:40:53,556 - train - INFO - Train: 64 [ 780/781 (100%)]  Loss:  3.892747 (3.6567)  Time: 0.492s,  260.39/s  (0.537s,  238.24/s)  LR: 3.109e-04  Data: 0.000 (0.008)
2024-04-07 04:40:53,558 - train - INFO - True
2024-04-07 04:40:53,560 - train - INFO - alphas:tensor([0.5657, 0.0611, 0.0780, 0.1049, 0.1904], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,561 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,561 - train - INFO - True
2024-04-07 04:40:53,563 - train - INFO - alphas:tensor([0.4106, 0.0301, 0.0476, 0.0977, 0.4140], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,563 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,563 - train - INFO - True
2024-04-07 04:40:53,565 - train - INFO - alphas:tensor([0.4347, 0.0462, 0.0942, 0.4248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,566 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,566 - train - INFO - True
2024-04-07 04:40:53,568 - train - INFO - alphas:tensor([0.3856, 0.0432, 0.0760, 0.4952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,569 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,569 - train - INFO - True
2024-04-07 04:40:53,570 - train - INFO - alphas:tensor([0.3823, 0.0341, 0.0845, 0.4990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,571 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,571 - train - INFO - True
2024-04-07 04:40:53,572 - train - INFO - alphas:tensor([0.4653, 0.0440, 0.0753, 0.4153], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,574 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,574 - train - INFO - True
2024-04-07 04:40:53,575 - train - INFO - alphas:tensor([0.5094, 0.0303, 0.0381, 0.0780, 0.3442], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,577 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,577 - train - INFO - True
2024-04-07 04:40:53,579 - train - INFO - alphas:tensor([0.2142, 0.0172, 0.0161, 0.0685, 0.6839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,580 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,580 - train - INFO - True
2024-04-07 04:40:53,581 - train - INFO - alphas:tensor([0.2246, 0.0139, 0.0177, 0.0583, 0.6855], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,582 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,582 - train - INFO - True
2024-04-07 04:40:53,584 - train - INFO - alphas:tensor([0.2262, 0.0112, 0.0155, 0.0608, 0.6863], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,585 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,585 - train - INFO - True
2024-04-07 04:40:53,586 - train - INFO - alphas:tensor([0.2111, 0.0153, 0.0161, 0.0710, 0.6865], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,587 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,587 - train - INFO - True
2024-04-07 04:40:53,588 - train - INFO - alphas:tensor([0.5168, 0.0176, 0.0279, 0.0717, 0.3661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,590 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,590 - train - INFO - True
2024-04-07 04:40:53,591 - train - INFO - alphas:tensor([0.6065, 0.0204, 0.0245, 0.0564, 0.2922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,596 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,597 - train - INFO - True
2024-04-07 04:40:53,606 - train - INFO - alphas:tensor([0.2205, 0.0268, 0.0282, 0.1086, 0.6159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,608 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,608 - train - INFO - True
2024-04-07 04:40:53,615 - train - INFO - alphas:tensor([0.2380, 0.0190, 0.0235, 0.1057, 0.6137], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,618 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,618 - train - INFO - True
2024-04-07 04:40:53,627 - train - INFO - alphas:tensor([0.2583, 0.0161, 0.0217, 0.0918, 0.6120], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,629 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,629 - train - INFO - True
2024-04-07 04:40:53,636 - train - INFO - alphas:tensor([0.2303, 0.0212, 0.0267, 0.0936, 0.6282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,639 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,639 - train - INFO - True
2024-04-07 04:40:53,644 - train - INFO - alphas:tensor([0.2577, 0.0162, 0.0264, 0.0904, 0.6092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,646 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,646 - train - INFO - True
2024-04-07 04:40:53,647 - train - INFO - alphas:tensor([0.2104, 0.0309, 0.0361, 0.1094, 0.6133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,649 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,649 - train - INFO - True
2024-04-07 04:40:53,650 - train - INFO - alphas:tensor([0.5620, 0.0136, 0.0198, 0.0644, 0.3402], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,654 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,654 - train - INFO - True
2024-04-07 04:40:53,655 - train - INFO - alphas:tensor([0.4946, 0.0124, 0.0153, 0.0663, 0.4114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,663 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,663 - train - INFO - True
2024-04-07 04:40:53,664 - train - INFO - alphas:tensor([0.3654, 0.0113, 0.0220, 0.0805, 0.5208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,668 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,668 - train - INFO - True
2024-04-07 04:40:53,669 - train - INFO - alphas:tensor([0.3804, 0.0118, 0.0156, 0.0786, 0.5136], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,672 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,673 - train - INFO - True
2024-04-07 04:40:53,673 - train - INFO - alphas:tensor([0.3941, 0.0103, 0.0149, 0.0739, 0.5070], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,677 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,677 - train - INFO - True
2024-04-07 04:40:53,678 - train - INFO - alphas:tensor([0.3637, 0.0117, 0.0192, 0.0807, 0.5247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,682 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,682 - train - INFO - True
2024-04-07 04:40:53,683 - train - INFO - alphas:tensor([0.5105, 0.0102, 0.0170, 0.0563, 0.4060], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,691 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,691 - train - INFO - True
2024-04-07 04:40:53,698 - train - INFO - alphas:tensor([0.6595, 0.0089, 0.0147, 0.0453, 0.2716], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,717 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,717 - train - INFO - True
2024-04-07 04:40:53,725 - train - INFO - alphas:tensor([0.3274, 0.0123, 0.0178, 0.0913, 0.5512], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,735 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,735 - train - INFO - True
2024-04-07 04:40:53,736 - train - INFO - alphas:tensor([0.3342, 0.0087, 0.0154, 0.0790, 0.5628], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,746 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,746 - train - INFO - True
2024-04-07 04:40:53,747 - train - INFO - alphas:tensor([0.3587, 0.0091, 0.0134, 0.0808, 0.5381], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,757 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,757 - train - INFO - True
2024-04-07 04:40:53,758 - train - INFO - alphas:tensor([0.3244, 0.0112, 0.0160, 0.0845, 0.5639], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,768 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,769 - train - INFO - True
2024-04-07 04:40:53,769 - train - INFO - alphas:tensor([0.6599, 0.0075, 0.0102, 0.0385, 0.2839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,789 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,789 - train - INFO - True
2024-04-07 04:40:53,797 - train - INFO - alphas:tensor([0.5003, 0.0184, 0.0245, 0.0783, 0.3784], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:40:53,875 - train - INFO - tau:0.536268225207185
2024-04-07 04:40:53,875 - train - INFO - avg block size:10.06060606060606
2024-04-07 04:40:53,876 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 04:40:53,876 - train - INFO - lasso_alpha:1.3660269107301411e-05
2024-04-07 04:40:54,101 - train - INFO - Test: [   0/78]  Time: 0.221 (0.221)  Loss:  1.0654 (1.0654)  Acc@1: 78.9062 (78.9062)  Acc@5: 92.9688 (92.9688)
2024-04-07 04:40:59,594 - train - INFO - Test: [  50/78]  Time: 0.130 (0.112)  Loss:  1.5811 (1.6341)  Acc@1: 60.1562 (63.7102)  Acc@5: 88.2812 (85.1103)
2024-04-07 04:41:02,445 - train - INFO - Test: [  78/78]  Time: 0.109 (0.108)  Loss:  1.9277 (1.6575)  Acc@1: 50.0000 (63.3600)  Acc@5: 93.7500 (84.4900)
2024-04-07 04:41:03,211 - train - INFO - Train: 65 [   0/781 (  0%)]  Loss:  3.504251 (3.5043)  Time: 0.647s,  197.87/s  (0.647s,  197.87/s)  LR: 3.059e-04  Data: 0.181 (0.181)
2024-04-07 04:41:29,275 - train - INFO - Train: 65 [  50/781 (  6%)]  Loss:  3.858378 (3.6895)  Time: 0.450s,  284.43/s  (0.524s,  244.41/s)  LR: 3.059e-04  Data: 0.008 (0.011)
2024-04-07 04:41:55,648 - train - INFO - Train: 65 [ 100/781 ( 13%)]  Loss:  3.981554 (3.6833)  Time: 0.525s,  243.91/s  (0.526s,  243.55/s)  LR: 3.059e-04  Data: 0.008 (0.009)
2024-04-07 04:42:21,731 - train - INFO - Train: 65 [ 150/781 ( 19%)]  Loss:  4.105510 (3.6726)  Time: 0.443s,  288.83/s  (0.524s,  244.17/s)  LR: 3.059e-04  Data: 0.006 (0.009)
2024-04-07 04:42:47,212 - train - INFO - Train: 65 [ 200/781 ( 26%)]  Loss:  3.479619 (3.6764)  Time: 0.573s,  223.27/s  (0.521s,  245.88/s)  LR: 3.059e-04  Data: 0.009 (0.008)
2024-04-07 04:43:13,694 - train - INFO - Train: 65 [ 250/781 ( 32%)]  Loss:  4.082877 (3.6810)  Time: 0.528s,  242.52/s  (0.522s,  245.03/s)  LR: 3.059e-04  Data: 0.005 (0.008)
2024-04-07 04:43:40,889 - train - INFO - Train: 65 [ 300/781 ( 38%)]  Loss:  3.730718 (3.6866)  Time: 0.563s,  227.28/s  (0.526s,  243.37/s)  LR: 3.059e-04  Data: 0.008 (0.008)
2024-04-07 04:44:07,137 - train - INFO - Train: 65 [ 350/781 ( 45%)]  Loss:  3.984851 (3.6841)  Time: 0.555s,  230.79/s  (0.526s,  243.44/s)  LR: 3.059e-04  Data: 0.005 (0.008)
2024-04-07 04:44:33,449 - train - INFO - Train: 65 [ 400/781 ( 51%)]  Loss:  3.550194 (3.6797)  Time: 0.538s,  237.85/s  (0.526s,  243.41/s)  LR: 3.059e-04  Data: 0.005 (0.008)
2024-04-07 04:44:59,609 - train - INFO - Train: 65 [ 450/781 ( 58%)]  Loss:  3.416573 (3.6744)  Time: 0.579s,  221.06/s  (0.526s,  243.55/s)  LR: 3.059e-04  Data: 0.008 (0.008)
2024-04-07 04:45:26,842 - train - INFO - Train: 65 [ 500/781 ( 64%)]  Loss:  3.892776 (3.6773)  Time: 0.536s,  239.00/s  (0.527s,  242.67/s)  LR: 3.059e-04  Data: 0.008 (0.008)
2024-04-07 04:45:53,910 - train - INFO - Train: 65 [ 550/781 ( 71%)]  Loss:  3.539988 (3.6727)  Time: 0.462s,  277.25/s  (0.529s,  242.09/s)  LR: 3.059e-04  Data: 0.006 (0.008)
2024-04-07 04:46:20,584 - train - INFO - Train: 65 [ 600/781 ( 77%)]  Loss:  3.617134 (3.6692)  Time: 0.538s,  238.01/s  (0.529s,  241.91/s)  LR: 3.059e-04  Data: 0.015 (0.008)
2024-04-07 04:46:46,694 - train - INFO - Train: 65 [ 650/781 ( 83%)]  Loss:  3.532737 (3.6681)  Time: 0.505s,  253.55/s  (0.529s,  242.16/s)  LR: 3.059e-04  Data: 0.012 (0.008)
2024-04-07 04:47:14,132 - train - INFO - Train: 65 [ 700/781 ( 90%)]  Loss:  3.983310 (3.6697)  Time: 0.418s,  306.36/s  (0.530s,  241.50/s)  LR: 3.059e-04  Data: 0.009 (0.008)
2024-04-07 04:47:41,289 - train - INFO - Train: 65 [ 750/781 ( 96%)]  Loss:  3.134580 (3.6692)  Time: 0.525s,  243.90/s  (0.531s,  241.11/s)  LR: 3.059e-04  Data: 0.007 (0.008)
2024-04-07 04:47:57,388 - train - INFO - Train: 65 [ 780/781 (100%)]  Loss:  3.396540 (3.6661)  Time: 0.596s,  214.91/s  (0.531s,  241.01/s)  LR: 3.059e-04  Data: 0.000 (0.008)
2024-04-07 04:47:57,389 - train - INFO - True
2024-04-07 04:47:57,391 - train - INFO - alphas:tensor([0.5664, 0.0599, 0.0777, 0.1046, 0.1914], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,391 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,391 - train - INFO - True
2024-04-07 04:47:57,392 - train - INFO - alphas:tensor([0.4106, 0.0293, 0.0470, 0.0972, 0.4158], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,392 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,392 - train - INFO - True
2024-04-07 04:47:57,393 - train - INFO - alphas:tensor([0.4394, 0.0452, 0.0935, 0.4220], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,394 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,394 - train - INFO - True
2024-04-07 04:47:57,394 - train - INFO - alphas:tensor([0.3870, 0.0422, 0.0744, 0.4964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,395 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,395 - train - INFO - True
2024-04-07 04:47:57,396 - train - INFO - alphas:tensor([0.3872, 0.0336, 0.0843, 0.4950], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,396 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,396 - train - INFO - True
2024-04-07 04:47:57,397 - train - INFO - alphas:tensor([0.4719, 0.0432, 0.0739, 0.4110], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,397 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,397 - train - INFO - True
2024-04-07 04:47:57,398 - train - INFO - alphas:tensor([0.5119, 0.0298, 0.0371, 0.0770, 0.3442], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,399 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,399 - train - INFO - True
2024-04-07 04:47:57,400 - train - INFO - alphas:tensor([0.2193, 0.0168, 0.0159, 0.0672, 0.6808], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,400 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,400 - train - INFO - True
2024-04-07 04:47:57,401 - train - INFO - alphas:tensor([0.2306, 0.0137, 0.0174, 0.0575, 0.6808], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,402 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,402 - train - INFO - True
2024-04-07 04:47:57,402 - train - INFO - alphas:tensor([0.2287, 0.0108, 0.0152, 0.0595, 0.6858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,403 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,403 - train - INFO - True
2024-04-07 04:47:57,404 - train - INFO - alphas:tensor([0.2138, 0.0149, 0.0155, 0.0699, 0.6858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,404 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,404 - train - INFO - True
2024-04-07 04:47:57,405 - train - INFO - alphas:tensor([0.5192, 0.0172, 0.0271, 0.0698, 0.3668], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,406 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,406 - train - INFO - True
2024-04-07 04:47:57,407 - train - INFO - alphas:tensor([0.6072, 0.0198, 0.0239, 0.0552, 0.2938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,409 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,409 - train - INFO - True
2024-04-07 04:47:57,412 - train - INFO - alphas:tensor([0.2243, 0.0265, 0.0281, 0.1092, 0.6119], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,414 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,414 - train - INFO - True
2024-04-07 04:47:57,414 - train - INFO - alphas:tensor([0.2399, 0.0187, 0.0231, 0.1038, 0.6145], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,416 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,416 - train - INFO - True
2024-04-07 04:47:57,417 - train - INFO - alphas:tensor([0.2636, 0.0157, 0.0215, 0.0925, 0.6067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,418 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,418 - train - INFO - True
2024-04-07 04:47:57,419 - train - INFO - alphas:tensor([0.2323, 0.0208, 0.0268, 0.0924, 0.6277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,420 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,420 - train - INFO - True
2024-04-07 04:47:57,421 - train - INFO - alphas:tensor([0.2648, 0.0162, 0.0265, 0.0900, 0.6026], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,422 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,422 - train - INFO - True
2024-04-07 04:47:57,423 - train - INFO - alphas:tensor([0.2150, 0.0307, 0.0357, 0.1099, 0.6088], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,424 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,424 - train - INFO - True
2024-04-07 04:47:57,425 - train - INFO - alphas:tensor([0.5613, 0.0130, 0.0192, 0.0639, 0.3426], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,428 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,428 - train - INFO - True
2024-04-07 04:47:57,428 - train - INFO - alphas:tensor([0.4964, 0.0121, 0.0147, 0.0656, 0.4113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,433 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,433 - train - INFO - True
2024-04-07 04:47:57,434 - train - INFO - alphas:tensor([0.3706, 0.0111, 0.0221, 0.0802, 0.5160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,437 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,437 - train - INFO - True
2024-04-07 04:47:57,437 - train - INFO - alphas:tensor([0.3855, 0.0115, 0.0151, 0.0772, 0.5106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,440 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,440 - train - INFO - True
2024-04-07 04:47:57,441 - train - INFO - alphas:tensor([0.4030, 0.0101, 0.0143, 0.0724, 0.5002], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,443 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,443 - train - INFO - True
2024-04-07 04:47:57,444 - train - INFO - alphas:tensor([0.3676, 0.0115, 0.0189, 0.0796, 0.5223], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,446 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,447 - train - INFO - True
2024-04-07 04:47:57,447 - train - INFO - alphas:tensor([0.5211, 0.0098, 0.0166, 0.0554, 0.3971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,452 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,452 - train - INFO - True
2024-04-07 04:47:57,453 - train - INFO - alphas:tensor([0.6637, 0.0085, 0.0143, 0.0447, 0.2688], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,465 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,465 - train - INFO - True
2024-04-07 04:47:57,471 - train - INFO - alphas:tensor([0.3328, 0.0120, 0.0174, 0.0904, 0.5474], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,477 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,477 - train - INFO - True
2024-04-07 04:47:57,482 - train - INFO - alphas:tensor([0.3419, 0.0084, 0.0150, 0.0782, 0.5564], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,488 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,488 - train - INFO - True
2024-04-07 04:47:57,494 - train - INFO - alphas:tensor([0.3756, 0.0090, 0.0134, 0.0791, 0.5230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,500 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,500 - train - INFO - True
2024-04-07 04:47:57,501 - train - INFO - alphas:tensor([0.3356, 0.0109, 0.0160, 0.0827, 0.5548], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,507 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,507 - train - INFO - True
2024-04-07 04:47:57,507 - train - INFO - alphas:tensor([0.6655, 0.0072, 0.0098, 0.0376, 0.2798], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,519 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,519 - train - INFO - True
2024-04-07 04:47:57,520 - train - INFO - alphas:tensor([0.5032, 0.0181, 0.0240, 0.0773, 0.3774], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:57,575 - train - INFO - tau:0.5309055429551132
2024-04-07 04:47:57,575 - train - INFO - avg block size:10.06060606060606
2024-04-07 04:47:57,576 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 04:47:57,878 - train - INFO - Test: [   0/78]  Time: 0.298 (0.298)  Loss:  1.1934 (1.1934)  Acc@1: 78.1250 (78.1250)  Acc@5: 92.1875 (92.1875)
2024-04-07 04:48:02,846 - train - INFO - Test: [  50/78]  Time: 0.057 (0.103)  Loss:  1.6816 (1.6275)  Acc@1: 62.5000 (63.5417)  Acc@5: 84.3750 (84.9877)
2024-04-07 04:48:06,305 - train - INFO - Test: [  78/78]  Time: 0.086 (0.110)  Loss:  2.2422 (1.6373)  Acc@1: 56.2500 (63.5000)  Acc@5: 87.5000 (84.6100)
2024-04-07 04:48:07,070 - train - INFO - Train: 66 [   0/781 (  0%)]  Loss:  3.838599 (3.8386)  Time: 0.679s,  188.38/s  (0.679s,  188.38/s)  LR: 3.009e-04  Data: 0.185 (0.185)
2024-04-07 04:48:33,199 - train - INFO - Train: 66 [  50/781 (  6%)]  Loss:  3.297518 (3.6664)  Time: 0.518s,  246.98/s  (0.526s,  243.52/s)  LR: 3.009e-04  Data: 0.009 (0.011)
2024-04-07 04:48:59,726 - train - INFO - Train: 66 [ 100/781 ( 13%)]  Loss:  3.797795 (3.6758)  Time: 0.477s,  268.46/s  (0.528s,  242.41/s)  LR: 3.009e-04  Data: 0.006 (0.009)
2024-04-07 04:49:25,761 - train - INFO - Train: 66 [ 150/781 ( 19%)]  Loss:  3.504359 (3.6659)  Time: 0.466s,  274.42/s  (0.526s,  243.53/s)  LR: 3.009e-04  Data: 0.009 (0.009)
2024-04-07 04:49:52,772 - train - INFO - Train: 66 [ 200/781 ( 26%)]  Loss:  3.827744 (3.6670)  Time: 1.103s,  116.00/s  (0.529s,  241.86/s)  LR: 3.009e-04  Data: 0.008 (0.009)
2024-04-07 04:50:19,740 - train - INFO - Train: 66 [ 250/781 ( 32%)]  Loss:  3.931810 (3.6713)  Time: 0.554s,  231.07/s  (0.531s,  240.94/s)  LR: 3.009e-04  Data: 0.009 (0.008)
2024-04-07 04:50:46,995 - train - INFO - Train: 66 [ 300/781 ( 38%)]  Loss:  3.788487 (3.6688)  Time: 0.414s,  308.85/s  (0.534s,  239.91/s)  LR: 3.009e-04  Data: 0.004 (0.008)
2024-04-07 04:51:13,233 - train - INFO - Train: 66 [ 350/781 ( 45%)]  Loss:  3.420382 (3.6664)  Time: 0.552s,  231.72/s  (0.532s,  240.47/s)  LR: 3.009e-04  Data: 0.008 (0.008)
2024-04-07 04:51:40,015 - train - INFO - Train: 66 [ 400/781 ( 51%)]  Loss:  3.265073 (3.6687)  Time: 1.106s,  115.70/s  (0.533s,  240.29/s)  LR: 3.009e-04  Data: 0.008 (0.008)
2024-04-07 04:52:06,592 - train - INFO - Train: 66 [ 450/781 ( 58%)]  Loss:  3.271298 (3.6665)  Time: 0.554s,  231.14/s  (0.533s,  240.35/s)  LR: 3.009e-04  Data: 0.010 (0.008)
2024-04-07 04:52:32,797 - train - INFO - Train: 66 [ 500/781 ( 64%)]  Loss:  3.908242 (3.6656)  Time: 1.069s,  119.73/s  (0.532s,  240.73/s)  LR: 3.009e-04  Data: 0.004 (0.008)
2024-04-07 04:52:58,357 - train - INFO - Train: 66 [ 550/781 ( 71%)]  Loss:  3.446169 (3.6632)  Time: 0.555s,  230.55/s  (0.530s,  241.58/s)  LR: 3.009e-04  Data: 0.006 (0.008)
2024-04-07 04:53:24,950 - train - INFO - Train: 66 [ 600/781 ( 77%)]  Loss:  3.391806 (3.6598)  Time: 0.441s,  289.96/s  (0.530s,  241.50/s)  LR: 3.009e-04  Data: 0.005 (0.008)
2024-04-07 04:53:52,119 - train - INFO - Train: 66 [ 650/781 ( 83%)]  Loss:  3.632659 (3.6587)  Time: 0.475s,  269.60/s  (0.531s,  241.04/s)  LR: 3.009e-04  Data: 0.008 (0.008)
2024-04-07 04:54:18,689 - train - INFO - Train: 66 [ 700/781 ( 90%)]  Loss:  3.466500 (3.6565)  Time: 0.506s,  253.17/s  (0.531s,  241.03/s)  LR: 3.009e-04  Data: 0.005 (0.008)
2024-04-07 04:54:46,432 - train - INFO - Train: 66 [ 750/781 ( 96%)]  Loss:  3.224995 (3.6598)  Time: 0.554s,  231.12/s  (0.533s,  240.31/s)  LR: 3.009e-04  Data: 0.008 (0.008)
2024-04-07 04:55:02,307 - train - INFO - Train: 66 [ 780/781 (100%)]  Loss:  3.850876 (3.6596)  Time: 0.545s,  234.79/s  (0.533s,  240.37/s)  LR: 3.009e-04  Data: 0.000 (0.008)
2024-04-07 04:55:02,308 - train - INFO - True
2024-04-07 04:55:02,316 - train - INFO - alphas:tensor([0.5714, 0.0587, 0.0765, 0.1031, 0.1902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,317 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,317 - train - INFO - True
2024-04-07 04:55:02,326 - train - INFO - alphas:tensor([0.4132, 0.0286, 0.0457, 0.0952, 0.4173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,326 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,326 - train - INFO - True
2024-04-07 04:55:02,328 - train - INFO - alphas:tensor([0.4418, 0.0443, 0.0921, 0.4217], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,329 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,329 - train - INFO - True
2024-04-07 04:55:02,330 - train - INFO - alphas:tensor([0.3898, 0.0413, 0.0738, 0.4951], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,330 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,330 - train - INFO - True
2024-04-07 04:55:02,332 - train - INFO - alphas:tensor([0.3877, 0.0325, 0.0825, 0.4973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,332 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,332 - train - INFO - True
2024-04-07 04:55:02,333 - train - INFO - alphas:tensor([0.4729, 0.0427, 0.0730, 0.4114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,334 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,334 - train - INFO - True
2024-04-07 04:55:02,335 - train - INFO - alphas:tensor([0.5117, 0.0291, 0.0367, 0.0764, 0.3461], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,337 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,337 - train - INFO - True
2024-04-07 04:55:02,338 - train - INFO - alphas:tensor([0.2194, 0.0164, 0.0154, 0.0677, 0.6811], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,339 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,339 - train - INFO - True
2024-04-07 04:55:02,340 - train - INFO - alphas:tensor([0.2274, 0.0132, 0.0169, 0.0559, 0.6866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,341 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,341 - train - INFO - True
2024-04-07 04:55:02,342 - train - INFO - alphas:tensor([0.2309, 0.0105, 0.0146, 0.0590, 0.6850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,342 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,343 - train - INFO - True
2024-04-07 04:55:02,344 - train - INFO - alphas:tensor([0.2140, 0.0144, 0.0151, 0.0689, 0.6875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,344 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,344 - train - INFO - True
2024-04-07 04:55:02,345 - train - INFO - alphas:tensor([0.5200, 0.0167, 0.0262, 0.0695, 0.3676], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,347 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,347 - train - INFO - True
2024-04-07 04:55:02,348 - train - INFO - alphas:tensor([0.6094, 0.0193, 0.0232, 0.0544, 0.2938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,352 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,352 - train - INFO - True
2024-04-07 04:55:02,353 - train - INFO - alphas:tensor([0.2245, 0.0258, 0.0276, 0.1082, 0.6138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,355 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,355 - train - INFO - True
2024-04-07 04:55:02,356 - train - INFO - alphas:tensor([0.2426, 0.0185, 0.0227, 0.1035, 0.6127], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,358 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,358 - train - INFO - True
2024-04-07 04:55:02,359 - train - INFO - alphas:tensor([0.2630, 0.0154, 0.0210, 0.0926, 0.6080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,361 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,361 - train - INFO - True
2024-04-07 04:55:02,362 - train - INFO - alphas:tensor([0.2359, 0.0207, 0.0264, 0.0909, 0.6261], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,364 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,364 - train - INFO - True
2024-04-07 04:55:02,365 - train - INFO - alphas:tensor([0.2656, 0.0159, 0.0264, 0.0903, 0.6017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,367 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,367 - train - INFO - True
2024-04-07 04:55:02,368 - train - INFO - alphas:tensor([0.2150, 0.0302, 0.0355, 0.1096, 0.6097], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,370 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,370 - train - INFO - True
2024-04-07 04:55:02,379 - train - INFO - alphas:tensor([0.5675, 0.0125, 0.0183, 0.0629, 0.3388], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,382 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,383 - train - INFO - True
2024-04-07 04:55:02,391 - train - INFO - alphas:tensor([0.4975, 0.0117, 0.0144, 0.0648, 0.4115], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,398 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,399 - train - INFO - True
2024-04-07 04:55:02,406 - train - INFO - alphas:tensor([0.3777, 0.0107, 0.0216, 0.0780, 0.5120], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,409 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,410 - train - INFO - True
2024-04-07 04:55:02,418 - train - INFO - alphas:tensor([0.3947, 0.0112, 0.0145, 0.0751, 0.5045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,421 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,421 - train - INFO - True
2024-04-07 04:55:02,422 - train - INFO - alphas:tensor([0.4018, 0.0097, 0.0142, 0.0732, 0.5010], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,426 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,426 - train - INFO - True
2024-04-07 04:55:02,427 - train - INFO - alphas:tensor([0.3656, 0.0110, 0.0181, 0.0799, 0.5252], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,431 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,431 - train - INFO - True
2024-04-07 04:55:02,432 - train - INFO - alphas:tensor([0.5195, 0.0095, 0.0160, 0.0550, 0.3999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,439 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,440 - train - INFO - True
2024-04-07 04:55:02,441 - train - INFO - alphas:tensor([0.6712, 0.0081, 0.0136, 0.0430, 0.2640], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,460 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,460 - train - INFO - True
2024-04-07 04:55:02,461 - train - INFO - alphas:tensor([0.3322, 0.0118, 0.0173, 0.0905, 0.5481], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,471 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,471 - train - INFO - True
2024-04-07 04:55:02,479 - train - INFO - alphas:tensor([0.3447, 0.0080, 0.0147, 0.0783, 0.5543], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,489 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,489 - train - INFO - True
2024-04-07 04:55:02,496 - train - INFO - alphas:tensor([0.3738, 0.0088, 0.0131, 0.0778, 0.5266], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,506 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,506 - train - INFO - True
2024-04-07 04:55:02,508 - train - INFO - alphas:tensor([0.3344, 0.0105, 0.0154, 0.0820, 0.5576], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,518 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,518 - train - INFO - True
2024-04-07 04:55:02,519 - train - INFO - alphas:tensor([0.6667, 0.0069, 0.0093, 0.0369, 0.2803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,538 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,538 - train - INFO - True
2024-04-07 04:55:02,539 - train - INFO - alphas:tensor([0.5028, 0.0179, 0.0239, 0.0772, 0.3783], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:55:02,617 - train - INFO - tau:0.525596487525562
2024-04-07 04:55:02,617 - train - INFO - avg block size:10.06060606060606
2024-04-07 04:55:02,617 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 04:55:02,618 - train - INFO - lasso_alpha:1.24184264611831e-05
2024-04-07 04:55:02,880 - train - INFO - Test: [   0/78]  Time: 0.259 (0.259)  Loss:  0.9575 (0.9575)  Acc@1: 80.4688 (80.4688)  Acc@5: 92.9688 (92.9688)
2024-04-07 04:55:08,134 - train - INFO - Test: [  50/78]  Time: 0.098 (0.108)  Loss:  1.6855 (1.6237)  Acc@1: 61.7188 (64.0319)  Acc@5: 85.9375 (85.4167)
2024-04-07 04:55:11,138 - train - INFO - Test: [  78/78]  Time: 0.096 (0.108)  Loss:  2.0176 (1.6525)  Acc@1: 62.5000 (63.7100)  Acc@5: 87.5000 (84.8700)
2024-04-07 04:55:11,962 - train - INFO - Train: 67 [   0/781 (  0%)]  Loss:  3.701812 (3.7018)  Time: 0.741s,  172.74/s  (0.741s,  172.74/s)  LR: 2.959e-04  Data: 0.180 (0.180)
2024-04-07 04:55:38,796 - train - INFO - Train: 67 [  50/781 (  6%)]  Loss:  3.233709 (3.5890)  Time: 0.548s,  233.66/s  (0.541s,  236.75/s)  LR: 2.959e-04  Data: 0.008 (0.011)
2024-04-07 04:56:06,248 - train - INFO - Train: 67 [ 100/781 ( 13%)]  Loss:  3.833772 (3.6232)  Time: 0.469s,  272.95/s  (0.545s,  234.95/s)  LR: 2.959e-04  Data: 0.008 (0.010)
2024-04-07 04:56:33,334 - train - INFO - Train: 67 [ 150/781 ( 19%)]  Loss:  3.970155 (3.6505)  Time: 0.463s,  276.28/s  (0.544s,  235.40/s)  LR: 2.959e-04  Data: 0.005 (0.009)
2024-04-07 04:56:59,756 - train - INFO - Train: 67 [ 200/781 ( 26%)]  Loss:  3.230260 (3.6326)  Time: 0.509s,  251.40/s  (0.540s,  237.06/s)  LR: 2.959e-04  Data: 0.010 (0.009)
2024-04-07 04:57:27,004 - train - INFO - Train: 67 [ 250/781 ( 32%)]  Loss:  3.405612 (3.6324)  Time: 0.500s,  256.11/s  (0.541s,  236.63/s)  LR: 2.959e-04  Data: 0.009 (0.009)
2024-04-07 04:57:53,613 - train - INFO - Train: 67 [ 300/781 ( 38%)]  Loss:  4.116018 (3.6343)  Time: 0.525s,  243.99/s  (0.539s,  237.27/s)  LR: 2.959e-04  Data: 0.009 (0.009)
2024-04-07 04:58:21,533 - train - INFO - Train: 67 [ 350/781 ( 45%)]  Loss:  4.080508 (3.6306)  Time: 0.580s,  220.58/s  (0.542s,  236.09/s)  LR: 2.959e-04  Data: 0.010 (0.008)
2024-04-07 04:58:48,880 - train - INFO - Train: 67 [ 400/781 ( 51%)]  Loss:  3.701702 (3.6337)  Time: 0.452s,  283.23/s  (0.543s,  235.83/s)  LR: 2.959e-04  Data: 0.005 (0.008)
2024-04-07 04:59:14,949 - train - INFO - Train: 67 [ 450/781 ( 58%)]  Loss:  3.960297 (3.6348)  Time: 0.597s,  214.35/s  (0.540s,  236.87/s)  LR: 2.959e-04  Data: 0.009 (0.008)
2024-04-07 04:59:40,792 - train - INFO - Train: 67 [ 500/781 ( 64%)]  Loss:  3.404987 (3.6353)  Time: 0.392s,  326.19/s  (0.538s,  237.90/s)  LR: 2.959e-04  Data: 0.005 (0.008)
2024-04-07 05:00:08,269 - train - INFO - Train: 67 [ 550/781 ( 71%)]  Loss:  3.373299 (3.6357)  Time: 0.423s,  302.69/s  (0.539s,  237.44/s)  LR: 2.959e-04  Data: 0.005 (0.008)
2024-04-07 05:00:34,150 - train - INFO - Train: 67 [ 600/781 ( 77%)]  Loss:  4.026722 (3.6368)  Time: 0.476s,  268.67/s  (0.537s,  238.23/s)  LR: 2.959e-04  Data: 0.009 (0.008)
2024-04-07 05:01:01,637 - train - INFO - Train: 67 [ 650/781 ( 83%)]  Loss:  3.532074 (3.6368)  Time: 0.545s,  234.76/s  (0.538s,  237.81/s)  LR: 2.959e-04  Data: 0.008 (0.008)
2024-04-07 05:01:28,876 - train - INFO - Train: 67 [ 700/781 ( 90%)]  Loss:  3.901739 (3.6379)  Time: 0.460s,  278.16/s  (0.539s,  237.61/s)  LR: 2.959e-04  Data: 0.008 (0.008)
2024-04-07 05:01:55,240 - train - INFO - Train: 67 [ 750/781 ( 96%)]  Loss:  3.406339 (3.6354)  Time: 0.634s,  202.01/s  (0.538s,  237.94/s)  LR: 2.959e-04  Data: 0.010 (0.008)
2024-04-07 05:02:10,347 - train - INFO - Train: 67 [ 780/781 (100%)]  Loss:  3.823211 (3.6376)  Time: 0.577s,  221.79/s  (0.537s,  238.53/s)  LR: 2.959e-04  Data: 0.000 (0.008)
2024-04-07 05:02:10,347 - train - INFO - True
2024-04-07 05:02:10,355 - train - INFO - alphas:tensor([0.5733, 0.0582, 0.0754, 0.1027, 0.1905], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,356 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,356 - train - INFO - True
2024-04-07 05:02:10,360 - train - INFO - alphas:tensor([0.4168, 0.0281, 0.0449, 0.0943, 0.4159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,360 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,361 - train - INFO - True
2024-04-07 05:02:10,361 - train - INFO - alphas:tensor([0.4434, 0.0436, 0.0898, 0.4232], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,362 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,362 - train - INFO - True
2024-04-07 05:02:10,363 - train - INFO - alphas:tensor([0.3890, 0.0402, 0.0728, 0.4980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,364 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,364 - train - INFO - True
2024-04-07 05:02:10,365 - train - INFO - alphas:tensor([0.3934, 0.0317, 0.0818, 0.4931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,365 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,365 - train - INFO - True
2024-04-07 05:02:10,366 - train - INFO - alphas:tensor([0.4744, 0.0421, 0.0715, 0.4120], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,367 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,367 - train - INFO - True
2024-04-07 05:02:10,368 - train - INFO - alphas:tensor([0.5140, 0.0283, 0.0356, 0.0747, 0.3474], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,369 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,369 - train - INFO - True
2024-04-07 05:02:10,370 - train - INFO - alphas:tensor([0.2225, 0.0158, 0.0149, 0.0667, 0.6801], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,371 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,371 - train - INFO - True
2024-04-07 05:02:10,372 - train - INFO - alphas:tensor([0.2324, 0.0129, 0.0167, 0.0556, 0.6824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,372 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,373 - train - INFO - True
2024-04-07 05:02:10,374 - train - INFO - alphas:tensor([0.2347, 0.0102, 0.0142, 0.0588, 0.6822], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,374 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,374 - train - INFO - True
2024-04-07 05:02:10,375 - train - INFO - alphas:tensor([0.2188, 0.0143, 0.0149, 0.0689, 0.6831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,376 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,376 - train - INFO - True
2024-04-07 05:02:10,377 - train - INFO - alphas:tensor([0.5234, 0.0161, 0.0255, 0.0672, 0.3678], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,378 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,378 - train - INFO - True
2024-04-07 05:02:10,379 - train - INFO - alphas:tensor([0.6155, 0.0185, 0.0225, 0.0525, 0.2910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,382 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,383 - train - INFO - True
2024-04-07 05:02:10,384 - train - INFO - alphas:tensor([0.2317, 0.0266, 0.0274, 0.1091, 0.6053], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,385 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,386 - train - INFO - True
2024-04-07 05:02:10,386 - train - INFO - alphas:tensor([0.2478, 0.0180, 0.0217, 0.1013, 0.6111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,388 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,388 - train - INFO - True
2024-04-07 05:02:10,389 - train - INFO - alphas:tensor([0.2682, 0.0148, 0.0204, 0.0915, 0.6051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,391 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,391 - train - INFO - True
2024-04-07 05:02:10,392 - train - INFO - alphas:tensor([0.2428, 0.0201, 0.0262, 0.0896, 0.6214], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,394 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,394 - train - INFO - True
2024-04-07 05:02:10,395 - train - INFO - alphas:tensor([0.2696, 0.0154, 0.0258, 0.0871, 0.6022], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,397 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,397 - train - INFO - True
2024-04-07 05:02:10,398 - train - INFO - alphas:tensor([0.2201, 0.0303, 0.0349, 0.1081, 0.6065], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,400 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,400 - train - INFO - True
2024-04-07 05:02:10,401 - train - INFO - alphas:tensor([0.5723, 0.0120, 0.0178, 0.0612, 0.3366], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,405 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,405 - train - INFO - True
2024-04-07 05:02:10,412 - train - INFO - alphas:tensor([0.5042, 0.0113, 0.0140, 0.0639, 0.4066], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,419 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,419 - train - INFO - True
2024-04-07 05:02:10,428 - train - INFO - alphas:tensor([0.3829, 0.0103, 0.0212, 0.0771, 0.5085], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,432 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,432 - train - INFO - True
2024-04-07 05:02:10,438 - train - INFO - alphas:tensor([0.3962, 0.0108, 0.0140, 0.0751, 0.5040], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,441 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,441 - train - INFO - True
2024-04-07 05:02:10,449 - train - INFO - alphas:tensor([0.4127, 0.0094, 0.0136, 0.0704, 0.4939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,453 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,453 - train - INFO - True
2024-04-07 05:02:10,454 - train - INFO - alphas:tensor([0.3747, 0.0108, 0.0180, 0.0797, 0.5168], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,458 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,458 - train - INFO - True
2024-04-07 05:02:10,459 - train - INFO - alphas:tensor([0.5240, 0.0092, 0.0155, 0.0536, 0.3977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,466 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,466 - train - INFO - True
2024-04-07 05:02:10,467 - train - INFO - alphas:tensor([0.6734, 0.0079, 0.0134, 0.0424, 0.2629], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,486 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,487 - train - INFO - True
2024-04-07 05:02:10,487 - train - INFO - alphas:tensor([0.3400, 0.0114, 0.0169, 0.0898, 0.5419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,498 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,498 - train - INFO - True
2024-04-07 05:02:10,505 - train - INFO - alphas:tensor([0.3533, 0.0077, 0.0141, 0.0772, 0.5477], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,515 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,515 - train - INFO - True
2024-04-07 05:02:10,522 - train - INFO - alphas:tensor([0.3815, 0.0085, 0.0127, 0.0774, 0.5199], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,532 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,532 - train - INFO - True
2024-04-07 05:02:10,539 - train - INFO - alphas:tensor([0.3413, 0.0102, 0.0151, 0.0806, 0.5526], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,549 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,549 - train - INFO - True
2024-04-07 05:02:10,550 - train - INFO - alphas:tensor([0.6736, 0.0067, 0.0091, 0.0357, 0.2750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,570 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,570 - train - INFO - True
2024-04-07 05:02:10,571 - train - INFO - alphas:tensor([0.5068, 0.0175, 0.0235, 0.0765, 0.3757], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:02:10,648 - train - INFO - tau:0.5203405226503064
2024-04-07 05:02:10,648 - train - INFO - avg block size:9.606060606060606
2024-04-07 05:02:10,649 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 05:02:10,958 - train - INFO - Test: [   0/78]  Time: 0.306 (0.306)  Loss:  1.0107 (1.0107)  Acc@1: 80.4688 (80.4688)  Acc@5: 91.4062 (91.4062)
2024-04-07 05:02:16,439 - train - INFO - Test: [  50/78]  Time: 0.104 (0.113)  Loss:  1.7119 (1.6171)  Acc@1: 61.7188 (63.4498)  Acc@5: 84.3750 (85.3554)
2024-04-07 05:02:19,352 - train - INFO - Test: [  78/78]  Time: 0.072 (0.110)  Loss:  2.1797 (1.6419)  Acc@1: 43.7500 (63.1300)  Acc@5: 81.2500 (84.7500)
2024-04-07 05:02:20,138 - train - INFO - Train: 68 [   0/781 (  0%)]  Loss:  3.535053 (3.5351)  Time: 0.677s,  188.98/s  (0.677s,  188.98/s)  LR: 2.908e-04  Data: 0.177 (0.177)
2024-04-07 05:02:47,539 - train - INFO - Train: 68 [  50/781 (  6%)]  Loss:  3.555613 (3.6819)  Time: 0.565s,  226.37/s  (0.551s,  232.51/s)  LR: 2.908e-04  Data: 0.005 (0.012)
2024-04-07 05:03:13,340 - train - INFO - Train: 68 [ 100/781 ( 13%)]  Loss:  3.698624 (3.6502)  Time: 0.499s,  256.57/s  (0.533s,  239.96/s)  LR: 2.908e-04  Data: 0.010 (0.010)
2024-04-07 05:03:39,784 - train - INFO - Train: 68 [ 150/781 ( 19%)]  Loss:  3.618485 (3.6496)  Time: 0.568s,  225.42/s  (0.532s,  240.64/s)  LR: 2.908e-04  Data: 0.016 (0.009)
2024-04-07 05:04:04,793 - train - INFO - Train: 68 [ 200/781 ( 26%)]  Loss:  3.667009 (3.6561)  Time: 0.422s,  303.14/s  (0.524s,  244.27/s)  LR: 2.908e-04  Data: 0.004 (0.009)
2024-04-07 05:04:31,502 - train - INFO - Train: 68 [ 250/781 ( 32%)]  Loss:  3.656443 (3.6474)  Time: 0.448s,  285.55/s  (0.526s,  243.33/s)  LR: 2.908e-04  Data: 0.006 (0.008)
2024-04-07 05:04:56,991 - train - INFO - Train: 68 [ 300/781 ( 38%)]  Loss:  3.451678 (3.6497)  Time: 0.539s,  237.43/s  (0.523s,  244.59/s)  LR: 2.908e-04  Data: 0.008 (0.008)
2024-04-07 05:05:22,943 - train - INFO - Train: 68 [ 350/781 ( 45%)]  Loss:  3.913839 (3.6517)  Time: 0.541s,  236.48/s  (0.523s,  244.88/s)  LR: 2.908e-04  Data: 0.007 (0.008)
2024-04-07 05:05:48,449 - train - INFO - Train: 68 [ 400/781 ( 51%)]  Loss:  3.434084 (3.6460)  Time: 0.574s,  222.88/s  (0.521s,  245.62/s)  LR: 2.908e-04  Data: 0.010 (0.008)
2024-04-07 05:06:15,572 - train - INFO - Train: 68 [ 450/781 ( 58%)]  Loss:  3.790179 (3.6498)  Time: 0.539s,  237.44/s  (0.523s,  244.51/s)  LR: 2.908e-04  Data: 0.007 (0.008)
2024-04-07 05:06:42,121 - train - INFO - Train: 68 [ 500/781 ( 64%)]  Loss:  3.699696 (3.6495)  Time: 0.556s,  230.20/s  (0.524s,  244.16/s)  LR: 2.908e-04  Data: 0.008 (0.008)
2024-04-07 05:07:09,488 - train - INFO - Train: 68 [ 550/781 ( 71%)]  Loss:  3.524832 (3.6420)  Time: 0.533s,  240.10/s  (0.526s,  243.19/s)  LR: 2.908e-04  Data: 0.007 (0.008)
2024-04-07 05:07:36,074 - train - INFO - Train: 68 [ 600/781 ( 77%)]  Loss:  3.500860 (3.6396)  Time: 0.534s,  239.90/s  (0.527s,  242.99/s)  LR: 2.908e-04  Data: 0.006 (0.008)
2024-04-07 05:08:03,494 - train - INFO - Train: 68 [ 650/781 ( 83%)]  Loss:  3.498528 (3.6390)  Time: 0.534s,  239.62/s  (0.528s,  242.22/s)  LR: 2.908e-04  Data: 0.012 (0.008)
2024-04-07 05:08:29,814 - train - INFO - Train: 68 [ 700/781 ( 90%)]  Loss:  3.992972 (3.6460)  Time: 0.564s,  226.81/s  (0.528s,  242.29/s)  LR: 2.908e-04  Data: 0.009 (0.008)
2024-04-07 05:08:56,962 - train - INFO - Train: 68 [ 750/781 ( 96%)]  Loss:  3.551560 (3.6477)  Time: 0.539s,  237.41/s  (0.529s,  241.85/s)  LR: 2.908e-04  Data: 0.006 (0.008)
2024-04-07 05:09:12,430 - train - INFO - Train: 68 [ 780/781 (100%)]  Loss:  3.694868 (3.6485)  Time: 0.356s,  359.18/s  (0.529s,  242.09/s)  LR: 2.908e-04  Data: 0.000 (0.008)
2024-04-07 05:09:12,430 - train - INFO - True
2024-04-07 05:09:12,432 - train - INFO - alphas:tensor([0.5770, 0.0569, 0.0746, 0.1013, 0.1901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,432 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,432 - train - INFO - True
2024-04-07 05:09:12,436 - train - INFO - alphas:tensor([0.4188, 0.0273, 0.0444, 0.0925, 0.4169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,436 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,436 - train - INFO - True
2024-04-07 05:09:12,443 - train - INFO - alphas:tensor([0.4482, 0.0430, 0.0893, 0.4194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,443 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,443 - train - INFO - True
2024-04-07 05:09:12,449 - train - INFO - alphas:tensor([0.3956, 0.0397, 0.0710, 0.4937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,449 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,450 - train - INFO - True
2024-04-07 05:09:12,455 - train - INFO - alphas:tensor([0.3951, 0.0312, 0.0809, 0.4928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,456 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,456 - train - INFO - True
2024-04-07 05:09:12,462 - train - INFO - alphas:tensor([0.4741, 0.0416, 0.0709, 0.4134], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,463 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,463 - train - INFO - True
2024-04-07 05:09:12,468 - train - INFO - alphas:tensor([0.5195, 0.0274, 0.0347, 0.0734, 0.3450], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,469 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,469 - train - INFO - True
2024-04-07 05:09:12,475 - train - INFO - alphas:tensor([0.2256, 0.0155, 0.0145, 0.0656, 0.6788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,475 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,475 - train - INFO - True
2024-04-07 05:09:12,481 - train - INFO - alphas:tensor([0.2373, 0.0126, 0.0164, 0.0549, 0.6788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,482 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,482 - train - INFO - True
2024-04-07 05:09:12,485 - train - INFO - alphas:tensor([0.2375, 0.0101, 0.0142, 0.0592, 0.6789], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,486 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,486 - train - INFO - True
2024-04-07 05:09:12,486 - train - INFO - alphas:tensor([0.2248, 0.0141, 0.0146, 0.0689, 0.6776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,487 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,487 - train - INFO - True
2024-04-07 05:09:12,488 - train - INFO - alphas:tensor([0.5296, 0.0158, 0.0247, 0.0662, 0.3636], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,489 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,489 - train - INFO - True
2024-04-07 05:09:12,490 - train - INFO - alphas:tensor([0.6177, 0.0182, 0.0217, 0.0520, 0.2905], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,492 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,492 - train - INFO - True
2024-04-07 05:09:12,493 - train - INFO - alphas:tensor([0.2315, 0.0258, 0.0271, 0.1072, 0.6084], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,495 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,495 - train - INFO - True
2024-04-07 05:09:12,496 - train - INFO - alphas:tensor([0.2516, 0.0176, 0.0214, 0.1007, 0.6086], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,497 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,497 - train - INFO - True
2024-04-07 05:09:12,498 - train - INFO - alphas:tensor([0.2718, 0.0145, 0.0201, 0.0924, 0.6012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,499 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,499 - train - INFO - True
2024-04-07 05:09:12,500 - train - INFO - alphas:tensor([0.2443, 0.0198, 0.0257, 0.0894, 0.6207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,502 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,502 - train - INFO - True
2024-04-07 05:09:12,502 - train - INFO - alphas:tensor([0.2754, 0.0150, 0.0256, 0.0876, 0.5964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,504 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,504 - train - INFO - True
2024-04-07 05:09:12,505 - train - INFO - alphas:tensor([0.2218, 0.0297, 0.0345, 0.1078, 0.6062], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,506 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,506 - train - INFO - True
2024-04-07 05:09:12,507 - train - INFO - alphas:tensor([0.5726, 0.0117, 0.0171, 0.0613, 0.3373], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,510 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,510 - train - INFO - True
2024-04-07 05:09:12,510 - train - INFO - alphas:tensor([0.5053, 0.0110, 0.0136, 0.0631, 0.4070], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,516 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,516 - train - INFO - True
2024-04-07 05:09:12,517 - train - INFO - alphas:tensor([0.3822, 0.0102, 0.0212, 0.0769, 0.5096], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,519 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,519 - train - INFO - True
2024-04-07 05:09:12,520 - train - INFO - alphas:tensor([0.3997, 0.0103, 0.0136, 0.0745, 0.5018], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,523 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,523 - train - INFO - True
2024-04-07 05:09:12,524 - train - INFO - alphas:tensor([0.4133, 0.0091, 0.0135, 0.0703, 0.4938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,527 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,527 - train - INFO - True
2024-04-07 05:09:12,527 - train - INFO - alphas:tensor([0.3740, 0.0105, 0.0175, 0.0787, 0.5193], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,530 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,530 - train - INFO - True
2024-04-07 05:09:12,535 - train - INFO - alphas:tensor([0.5282, 0.0090, 0.0150, 0.0529, 0.3949], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,540 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,540 - train - INFO - True
2024-04-07 05:09:12,546 - train - INFO - alphas:tensor([0.6751, 0.0076, 0.0130, 0.0421, 0.2621], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,559 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,559 - train - INFO - True
2024-04-07 05:09:12,565 - train - INFO - alphas:tensor([0.3375, 0.0111, 0.0162, 0.0886, 0.5466], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,571 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,572 - train - INFO - True
2024-04-07 05:09:12,574 - train - INFO - alphas:tensor([0.3539, 0.0075, 0.0139, 0.0763, 0.5485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,580 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,580 - train - INFO - True
2024-04-07 05:09:12,581 - train - INFO - alphas:tensor([0.3826, 0.0082, 0.0123, 0.0766, 0.5203], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,589 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,589 - train - INFO - True
2024-04-07 05:09:12,590 - train - INFO - alphas:tensor([0.3470, 0.0100, 0.0147, 0.0792, 0.5490], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,598 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,598 - train - INFO - True
2024-04-07 05:09:12,598 - train - INFO - alphas:tensor([0.6736, 0.0065, 0.0088, 0.0351, 0.2760], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,613 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,613 - train - INFO - True
2024-04-07 05:09:12,613 - train - INFO - alphas:tensor([0.5105, 0.0176, 0.0232, 0.0762, 0.3725], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:09:12,665 - train - INFO - tau:0.5151371174238033
2024-04-07 05:09:12,665 - train - INFO - avg block size:9.606060606060606
2024-04-07 05:09:12,665 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 05:09:12,665 - train - INFO - lasso_alpha:1.3660269107301411e-05
2024-04-07 05:09:12,933 - train - INFO - Test: [   0/78]  Time: 0.266 (0.266)  Loss:  0.9756 (0.9756)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 05:09:17,944 - train - INFO - Test: [  50/78]  Time: 0.103 (0.103)  Loss:  1.7344 (1.5783)  Acc@1: 61.7188 (64.3995)  Acc@5: 83.5938 (85.8456)
2024-04-07 05:09:20,832 - train - INFO - Test: [  78/78]  Time: 0.083 (0.103)  Loss:  2.2031 (1.6144)  Acc@1: 50.0000 (64.1500)  Acc@5: 75.0000 (85.1600)
2024-04-07 05:09:21,649 - train - INFO - Train: 69 [   0/781 (  0%)]  Loss:  3.884904 (3.8849)  Time: 0.727s,  176.05/s  (0.727s,  176.05/s)  LR: 2.857e-04  Data: 0.165 (0.165)
2024-04-07 05:09:48,034 - train - INFO - Train: 69 [  50/781 (  6%)]  Loss:  3.943175 (3.6496)  Time: 0.408s,  313.63/s  (0.532s,  240.79/s)  LR: 2.857e-04  Data: 0.004 (0.011)
2024-04-07 05:10:13,893 - train - INFO - Train: 69 [ 100/781 ( 13%)]  Loss:  3.446789 (3.6372)  Time: 0.542s,  235.98/s  (0.524s,  244.07/s)  LR: 2.857e-04  Data: 0.008 (0.009)
2024-04-07 05:10:40,170 - train - INFO - Train: 69 [ 150/781 ( 19%)]  Loss:  3.844687 (3.6362)  Time: 0.488s,  262.21/s  (0.525s,  243.91/s)  LR: 2.857e-04  Data: 0.007 (0.009)
2024-04-07 05:11:06,782 - train - INFO - Train: 69 [ 200/781 ( 26%)]  Loss:  3.526772 (3.6308)  Time: 0.435s,  294.14/s  (0.527s,  243.05/s)  LR: 2.857e-04  Data: 0.006 (0.008)
2024-04-07 05:11:33,531 - train - INFO - Train: 69 [ 250/781 ( 32%)]  Loss:  3.631608 (3.6231)  Time: 0.383s,  334.42/s  (0.528s,  242.29/s)  LR: 2.857e-04  Data: 0.004 (0.008)
2024-04-07 05:12:00,357 - train - INFO - Train: 69 [ 300/781 ( 38%)]  Loss:  3.938404 (3.6231)  Time: 0.557s,  229.79/s  (0.530s,  241.67/s)  LR: 2.857e-04  Data: 0.013 (0.008)
2024-04-07 05:12:26,605 - train - INFO - Train: 69 [ 350/781 ( 45%)]  Loss:  3.728280 (3.6293)  Time: 0.556s,  230.11/s  (0.529s,  241.97/s)  LR: 2.857e-04  Data: 0.008 (0.008)
2024-04-07 05:12:53,087 - train - INFO - Train: 69 [ 400/781 ( 51%)]  Loss:  3.888330 (3.6252)  Time: 0.400s,  319.80/s  (0.529s,  241.94/s)  LR: 2.857e-04  Data: 0.004 (0.008)
2024-04-07 05:13:19,217 - train - INFO - Train: 69 [ 450/781 ( 58%)]  Loss:  3.896002 (3.6265)  Time: 0.575s,  222.50/s  (0.528s,  242.27/s)  LR: 2.857e-04  Data: 0.008 (0.008)
2024-04-07 05:13:46,297 - train - INFO - Train: 69 [ 500/781 ( 64%)]  Loss:  3.658132 (3.6273)  Time: 0.556s,  230.15/s  (0.530s,  241.66/s)  LR: 2.857e-04  Data: 0.005 (0.008)
2024-04-07 05:14:13,043 - train - INFO - Train: 69 [ 550/781 ( 71%)]  Loss:  3.480687 (3.6280)  Time: 0.582s,  219.97/s  (0.530s,  241.45/s)  LR: 2.857e-04  Data: 0.005 (0.008)
2024-04-07 05:14:39,727 - train - INFO - Train: 69 [ 600/781 ( 77%)]  Loss:  3.498962 (3.6288)  Time: 0.466s,  274.66/s  (0.530s,  241.32/s)  LR: 2.857e-04  Data: 0.005 (0.008)
2024-04-07 05:15:05,648 - train - INFO - Train: 69 [ 650/781 ( 83%)]  Loss:  3.843724 (3.6274)  Time: 0.555s,  230.51/s  (0.530s,  241.74/s)  LR: 2.857e-04  Data: 0.009 (0.008)
2024-04-07 05:15:32,678 - train - INFO - Train: 69 [ 700/781 ( 90%)]  Loss:  3.570097 (3.6287)  Time: 0.427s,  299.60/s  (0.530s,  241.38/s)  LR: 2.857e-04  Data: 0.005 (0.008)
2024-04-07 05:15:58,451 - train - INFO - Train: 69 [ 750/781 ( 96%)]  Loss:  3.264530 (3.6300)  Time: 0.539s,  237.68/s  (0.529s,  241.83/s)  LR: 2.857e-04  Data: 0.008 (0.008)
2024-04-07 05:16:14,717 - train - INFO - Train: 69 [ 780/781 (100%)]  Loss:  3.854451 (3.6309)  Time: 0.524s,  244.38/s  (0.530s,  241.60/s)  LR: 2.857e-04  Data: 0.000 (0.008)
2024-04-07 05:16:14,718 - train - INFO - True
2024-04-07 05:16:14,719 - train - INFO - alphas:tensor([0.5802, 0.0559, 0.0734, 0.1001, 0.1904], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,720 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,720 - train - INFO - True
2024-04-07 05:16:14,721 - train - INFO - alphas:tensor([0.4191, 0.0266, 0.0434, 0.0917, 0.4193], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,722 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,722 - train - INFO - True
2024-04-07 05:16:14,723 - train - INFO - alphas:tensor([0.4486, 0.0421, 0.0885, 0.4208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,724 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,724 - train - INFO - True
2024-04-07 05:16:14,725 - train - INFO - alphas:tensor([0.3964, 0.0395, 0.0702, 0.4939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,726 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,726 - train - INFO - True
2024-04-07 05:16:14,727 - train - INFO - alphas:tensor([0.3916, 0.0304, 0.0793, 0.4987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,728 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,728 - train - INFO - True
2024-04-07 05:16:14,729 - train - INFO - alphas:tensor([0.4742, 0.0407, 0.0709, 0.4143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,730 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,730 - train - INFO - True
2024-04-07 05:16:14,731 - train - INFO - alphas:tensor([0.5182, 0.0270, 0.0341, 0.0727, 0.3480], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,733 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,733 - train - INFO - True
2024-04-07 05:16:14,734 - train - INFO - alphas:tensor([0.2228, 0.0149, 0.0139, 0.0649, 0.6835], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,735 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,735 - train - INFO - True
2024-04-07 05:16:14,736 - train - INFO - alphas:tensor([0.2336, 0.0122, 0.0158, 0.0544, 0.6840], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,737 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,737 - train - INFO - True
2024-04-07 05:16:14,738 - train - INFO - alphas:tensor([0.2350, 0.0097, 0.0138, 0.0577, 0.6837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,739 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,739 - train - INFO - True
2024-04-07 05:16:14,740 - train - INFO - alphas:tensor([0.2216, 0.0138, 0.0141, 0.0677, 0.6828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,741 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,741 - train - INFO - True
2024-04-07 05:16:14,742 - train - INFO - alphas:tensor([0.5284, 0.0152, 0.0241, 0.0653, 0.3669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,743 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,743 - train - INFO - True
2024-04-07 05:16:14,744 - train - INFO - alphas:tensor([0.6199, 0.0178, 0.0211, 0.0514, 0.2899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,748 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,749 - train - INFO - True
2024-04-07 05:16:14,750 - train - INFO - alphas:tensor([0.2308, 0.0254, 0.0267, 0.1043, 0.6128], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,752 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,752 - train - INFO - True
2024-04-07 05:16:14,753 - train - INFO - alphas:tensor([0.2490, 0.0169, 0.0209, 0.0994, 0.6138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,755 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,755 - train - INFO - True
2024-04-07 05:16:14,756 - train - INFO - alphas:tensor([0.2653, 0.0140, 0.0195, 0.0921, 0.6091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,758 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,758 - train - INFO - True
2024-04-07 05:16:14,759 - train - INFO - alphas:tensor([0.2392, 0.0194, 0.0250, 0.0896, 0.6268], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,762 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,762 - train - INFO - True
2024-04-07 05:16:14,763 - train - INFO - alphas:tensor([0.2707, 0.0147, 0.0251, 0.0877, 0.6017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,765 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,765 - train - INFO - True
2024-04-07 05:16:14,766 - train - INFO - alphas:tensor([0.2204, 0.0290, 0.0334, 0.1066, 0.6105], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,768 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,768 - train - INFO - True
2024-04-07 05:16:14,776 - train - INFO - alphas:tensor([0.5760, 0.0113, 0.0166, 0.0605, 0.3357], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,779 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,779 - train - INFO - True
2024-04-07 05:16:14,788 - train - INFO - alphas:tensor([0.5006, 0.0108, 0.0134, 0.0632, 0.4120], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,795 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,795 - train - INFO - True
2024-04-07 05:16:14,802 - train - INFO - alphas:tensor([0.3801, 0.0097, 0.0207, 0.0777, 0.5118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,806 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,806 - train - INFO - True
2024-04-07 05:16:14,814 - train - INFO - alphas:tensor([0.3944, 0.0099, 0.0133, 0.0739, 0.5085], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,818 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,818 - train - INFO - True
2024-04-07 05:16:14,819 - train - INFO - alphas:tensor([0.4151, 0.0089, 0.0134, 0.0697, 0.4930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,822 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,823 - train - INFO - True
2024-04-07 05:16:14,823 - train - INFO - alphas:tensor([0.3729, 0.0101, 0.0171, 0.0780, 0.5219], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,827 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,827 - train - INFO - True
2024-04-07 05:16:14,828 - train - INFO - alphas:tensor([0.5271, 0.0087, 0.0146, 0.0519, 0.3977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,836 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,836 - train - INFO - True
2024-04-07 05:16:14,837 - train - INFO - alphas:tensor([0.6707, 0.0074, 0.0128, 0.0420, 0.2671], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,856 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,856 - train - INFO - True
2024-04-07 05:16:14,857 - train - INFO - alphas:tensor([0.3394, 0.0109, 0.0160, 0.0877, 0.5459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,867 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,867 - train - INFO - True
2024-04-07 05:16:14,873 - train - INFO - alphas:tensor([0.3460, 0.0072, 0.0136, 0.0761, 0.5571], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,883 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,883 - train - INFO - True
2024-04-07 05:16:14,892 - train - INFO - alphas:tensor([0.3768, 0.0079, 0.0119, 0.0761, 0.5273], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,902 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,902 - train - INFO - True
2024-04-07 05:16:14,904 - train - INFO - alphas:tensor([0.3394, 0.0095, 0.0142, 0.0791, 0.5578], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,914 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,915 - train - INFO - True
2024-04-07 05:16:14,915 - train - INFO - alphas:tensor([0.6781, 0.0062, 0.0086, 0.0347, 0.2724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:14,935 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:14,935 - train - INFO - True
2024-04-07 05:16:14,936 - train - INFO - alphas:tensor([0.5091, 0.0176, 0.0229, 0.0761, 0.3744], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:16:15,013 - train - INFO - tau:0.5099857462495653
2024-04-07 05:16:15,013 - train - INFO - avg block size:10.06060606060606
2024-04-07 05:16:15,014 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 05:16:15,294 - train - INFO - Test: [   0/78]  Time: 0.276 (0.276)  Loss:  1.0557 (1.0557)  Acc@1: 78.9062 (78.9062)  Acc@5: 91.4062 (91.4062)
2024-04-07 05:16:20,824 - train - INFO - Test: [  50/78]  Time: 0.712 (0.114)  Loss:  1.6670 (1.6094)  Acc@1: 64.0625 (64.1238)  Acc@5: 84.3750 (85.5545)
2024-04-07 05:16:24,343 - train - INFO - Test: [  78/78]  Time: 0.097 (0.118)  Loss:  2.0645 (1.6322)  Acc@1: 50.0000 (63.7500)  Acc@5: 87.5000 (84.9200)
2024-04-07 05:16:25,154 - train - INFO - Train: 70 [   0/781 (  0%)]  Loss:  3.884337 (3.8843)  Time: 0.724s,  176.71/s  (0.724s,  176.71/s)  LR: 2.806e-04  Data: 0.178 (0.178)
2024-04-07 05:16:50,507 - train - INFO - Train: 70 [  50/781 (  6%)]  Loss:  3.192532 (3.5937)  Time: 0.555s,  230.75/s  (0.511s,  250.35/s)  LR: 2.806e-04  Data: 0.010 (0.011)
2024-04-07 05:17:17,950 - train - INFO - Train: 70 [ 100/781 ( 13%)]  Loss:  3.889522 (3.6209)  Time: 0.369s,  346.86/s  (0.530s,  241.57/s)  LR: 2.806e-04  Data: 0.008 (0.010)
2024-04-07 05:17:45,715 - train - INFO - Train: 70 [ 150/781 ( 19%)]  Loss:  3.966892 (3.6294)  Time: 0.528s,  242.35/s  (0.538s,  237.79/s)  LR: 2.806e-04  Data: 0.009 (0.009)
2024-04-07 05:18:12,934 - train - INFO - Train: 70 [ 200/781 ( 26%)]  Loss:  3.411915 (3.6259)  Time: 0.447s,  286.59/s  (0.540s,  237.13/s)  LR: 2.806e-04  Data: 0.006 (0.009)
2024-04-07 05:18:39,670 - train - INFO - Train: 70 [ 250/781 ( 32%)]  Loss:  3.569169 (3.6292)  Time: 0.550s,  232.78/s  (0.539s,  237.58/s)  LR: 2.806e-04  Data: 0.005 (0.009)
2024-04-07 05:19:05,466 - train - INFO - Train: 70 [ 300/781 ( 38%)]  Loss:  3.421069 (3.6178)  Time: 0.553s,  231.58/s  (0.535s,  239.27/s)  LR: 2.806e-04  Data: 0.012 (0.008)
2024-04-07 05:19:32,313 - train - INFO - Train: 70 [ 350/781 ( 45%)]  Loss:  3.820397 (3.6154)  Time: 0.606s,  211.13/s  (0.535s,  239.14/s)  LR: 2.806e-04  Data: 0.011 (0.008)
2024-04-07 05:19:58,601 - train - INFO - Train: 70 [ 400/781 ( 51%)]  Loss:  3.386044 (3.6250)  Time: 0.542s,  236.26/s  (0.534s,  239.67/s)  LR: 2.806e-04  Data: 0.006 (0.008)
2024-04-07 05:20:25,938 - train - INFO - Train: 70 [ 450/781 ( 58%)]  Loss:  3.576256 (3.6272)  Time: 0.496s,  258.11/s  (0.535s,  239.05/s)  LR: 2.806e-04  Data: 0.010 (0.008)
2024-04-07 05:20:52,337 - train - INFO - Train: 70 [ 500/781 ( 64%)]  Loss:  4.012099 (3.6255)  Time: 0.545s,  235.06/s  (0.535s,  239.38/s)  LR: 2.806e-04  Data: 0.009 (0.008)
2024-04-07 05:21:19,222 - train - INFO - Train: 70 [ 550/781 ( 71%)]  Loss:  3.466596 (3.6249)  Time: 0.552s,  232.00/s  (0.535s,  239.26/s)  LR: 2.806e-04  Data: 0.008 (0.008)
2024-04-07 05:21:45,979 - train - INFO - Train: 70 [ 600/781 ( 77%)]  Loss:  3.827672 (3.6280)  Time: 0.447s,  286.13/s  (0.535s,  239.26/s)  LR: 2.806e-04  Data: 0.008 (0.008)
2024-04-07 05:22:12,465 - train - INFO - Train: 70 [ 650/781 ( 83%)]  Loss:  3.694901 (3.6322)  Time: 0.504s,  253.88/s  (0.535s,  239.44/s)  LR: 2.806e-04  Data: 0.010 (0.008)
2024-04-07 05:22:39,255 - train - INFO - Train: 70 [ 700/781 ( 90%)]  Loss:  3.527557 (3.6351)  Time: 0.515s,  248.71/s  (0.535s,  239.40/s)  LR: 2.806e-04  Data: 0.005 (0.008)
2024-04-07 05:23:05,376 - train - INFO - Train: 70 [ 750/781 ( 96%)]  Loss:  3.892214 (3.6323)  Time: 0.453s,  282.34/s  (0.534s,  239.77/s)  LR: 2.806e-04  Data: 0.009 (0.008)
2024-04-07 05:23:20,817 - train - INFO - Train: 70 [ 780/781 (100%)]  Loss:  3.834954 (3.6315)  Time: 0.521s,  245.53/s  (0.533s,  240.10/s)  LR: 2.806e-04  Data: 0.000 (0.008)
2024-04-07 05:23:20,818 - train - INFO - True
2024-04-07 05:23:20,824 - train - INFO - alphas:tensor([0.5822, 0.0552, 0.0731, 0.0994, 0.1901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,824 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,824 - train - INFO - True
2024-04-07 05:23:20,828 - train - INFO - alphas:tensor([0.4182, 0.0258, 0.0430, 0.0908, 0.4221], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,828 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,829 - train - INFO - True
2024-04-07 05:23:20,834 - train - INFO - alphas:tensor([0.4470, 0.0416, 0.0885, 0.4229], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,835 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,835 - train - INFO - True
2024-04-07 05:23:20,841 - train - INFO - alphas:tensor([0.3916, 0.0381, 0.0692, 0.5010], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,841 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,841 - train - INFO - True
2024-04-07 05:23:20,847 - train - INFO - alphas:tensor([0.3956, 0.0297, 0.0782, 0.4964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,848 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,848 - train - INFO - True
2024-04-07 05:23:20,854 - train - INFO - alphas:tensor([0.4777, 0.0398, 0.0692, 0.4133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,855 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,855 - train - INFO - True
2024-04-07 05:23:20,856 - train - INFO - alphas:tensor([0.5175, 0.0263, 0.0334, 0.0722, 0.3505], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,857 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,857 - train - INFO - True
2024-04-07 05:23:20,858 - train - INFO - alphas:tensor([0.2215, 0.0146, 0.0137, 0.0660, 0.6842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,859 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,859 - train - INFO - True
2024-04-07 05:23:20,860 - train - INFO - alphas:tensor([0.2317, 0.0117, 0.0154, 0.0537, 0.6874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,860 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,861 - train - INFO - True
2024-04-07 05:23:20,861 - train - INFO - alphas:tensor([0.2302, 0.0095, 0.0134, 0.0573, 0.6896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,862 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,862 - train - INFO - True
2024-04-07 05:23:20,863 - train - INFO - alphas:tensor([0.2167, 0.0134, 0.0139, 0.0669, 0.6891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,864 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,864 - train - INFO - True
2024-04-07 05:23:20,865 - train - INFO - alphas:tensor([0.5272, 0.0149, 0.0238, 0.0647, 0.3693], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,866 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,866 - train - INFO - True
2024-04-07 05:23:20,867 - train - INFO - alphas:tensor([0.6175, 0.0171, 0.0206, 0.0505, 0.2943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,871 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,871 - train - INFO - True
2024-04-07 05:23:20,872 - train - INFO - alphas:tensor([0.2290, 0.0252, 0.0263, 0.1037, 0.6158], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,874 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,874 - train - INFO - True
2024-04-07 05:23:20,875 - train - INFO - alphas:tensor([0.2444, 0.0164, 0.0202, 0.0983, 0.6207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,876 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,877 - train - INFO - True
2024-04-07 05:23:20,877 - train - INFO - alphas:tensor([0.2648, 0.0133, 0.0191, 0.0900, 0.6128], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,879 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,880 - train - INFO - True
2024-04-07 05:23:20,881 - train - INFO - alphas:tensor([0.2369, 0.0187, 0.0243, 0.0877, 0.6325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,883 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,883 - train - INFO - True
2024-04-07 05:23:20,884 - train - INFO - alphas:tensor([0.2663, 0.0141, 0.0247, 0.0866, 0.6083], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,886 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,886 - train - INFO - True
2024-04-07 05:23:20,887 - train - INFO - alphas:tensor([0.2185, 0.0284, 0.0331, 0.1053, 0.6147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,889 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,889 - train - INFO - True
2024-04-07 05:23:20,890 - train - INFO - alphas:tensor([0.5728, 0.0109, 0.0162, 0.0596, 0.3405], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,893 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,893 - train - INFO - True
2024-04-07 05:23:20,894 - train - INFO - alphas:tensor([0.5019, 0.0103, 0.0130, 0.0624, 0.4123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,902 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,902 - train - INFO - True
2024-04-07 05:23:20,903 - train - INFO - alphas:tensor([0.3825, 0.0094, 0.0203, 0.0782, 0.5096], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,907 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,907 - train - INFO - True
2024-04-07 05:23:20,911 - train - INFO - alphas:tensor([0.3936, 0.0096, 0.0129, 0.0720, 0.5119], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,915 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,915 - train - INFO - True
2024-04-07 05:23:20,920 - train - INFO - alphas:tensor([0.4064, 0.0086, 0.0130, 0.0705, 0.5014], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,924 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,924 - train - INFO - True
2024-04-07 05:23:20,930 - train - INFO - alphas:tensor([0.3724, 0.0099, 0.0170, 0.0773, 0.5235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,934 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,934 - train - INFO - True
2024-04-07 05:23:20,939 - train - INFO - alphas:tensor([0.5243, 0.0083, 0.0143, 0.0518, 0.4013], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,947 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,947 - train - INFO - True
2024-04-07 05:23:20,952 - train - INFO - alphas:tensor([0.6720, 0.0072, 0.0126, 0.0421, 0.2661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,972 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,972 - train - INFO - True
2024-04-07 05:23:20,973 - train - INFO - alphas:tensor([0.3376, 0.0106, 0.0161, 0.0878, 0.5479], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,983 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,983 - train - INFO - True
2024-04-07 05:23:20,984 - train - INFO - alphas:tensor([0.3426, 0.0070, 0.0134, 0.0750, 0.5620], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:20,994 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:20,994 - train - INFO - True
2024-04-07 05:23:20,995 - train - INFO - alphas:tensor([0.3725, 0.0077, 0.0117, 0.0759, 0.5321], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:21,005 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:21,006 - train - INFO - True
2024-04-07 05:23:21,010 - train - INFO - alphas:tensor([0.3368, 0.0093, 0.0139, 0.0791, 0.5608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:21,020 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:21,020 - train - INFO - True
2024-04-07 05:23:21,025 - train - INFO - alphas:tensor([0.6733, 0.0061, 0.0085, 0.0346, 0.2774], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:21,045 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:21,045 - train - INFO - True
2024-04-07 05:23:21,050 - train - INFO - alphas:tensor([0.5075, 0.0172, 0.0227, 0.0758, 0.3768], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:21,130 - train - INFO - tau:0.5048858887870696
2024-04-07 05:23:21,130 - train - INFO - avg block size:10.06060606060606
2024-04-07 05:23:21,131 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 05:23:21,131 - train - INFO - lasso_alpha:1.24184264611831e-05
2024-04-07 05:23:21,297 - train - INFO - Test: [   0/78]  Time: 0.161 (0.161)  Loss:  0.9658 (0.9658)  Acc@1: 82.8125 (82.8125)  Acc@5: 91.4062 (91.4062)
2024-04-07 05:23:26,584 - train - INFO - Test: [  50/78]  Time: 0.058 (0.107)  Loss:  1.7744 (1.6474)  Acc@1: 59.3750 (63.7255)  Acc@5: 81.2500 (85.0797)
2024-04-07 05:23:29,397 - train - INFO - Test: [  78/78]  Time: 0.096 (0.105)  Loss:  1.8545 (1.6563)  Acc@1: 50.0000 (63.7600)  Acc@5: 93.7500 (84.7600)
2024-04-07 05:23:30,172 - train - INFO - Train: 71 [   0/781 (  0%)]  Loss:  3.572639 (3.5726)  Time: 0.687s,  186.19/s  (0.687s,  186.19/s)  LR: 2.755e-04  Data: 0.158 (0.158)
2024-04-07 05:23:56,009 - train - INFO - Train: 71 [  50/781 (  6%)]  Loss:  3.103973 (3.5653)  Time: 0.476s,  268.66/s  (0.520s,  246.13/s)  LR: 2.755e-04  Data: 0.007 (0.010)
2024-04-07 05:24:22,657 - train - INFO - Train: 71 [ 100/781 ( 13%)]  Loss:  3.963452 (3.5834)  Time: 0.521s,  245.66/s  (0.526s,  243.15/s)  LR: 2.755e-04  Data: 0.008 (0.009)
2024-04-07 05:24:49,439 - train - INFO - Train: 71 [ 150/781 ( 19%)]  Loss:  3.863359 (3.5948)  Time: 0.566s,  226.14/s  (0.529s,  241.75/s)  LR: 2.755e-04  Data: 0.008 (0.009)
2024-04-07 05:25:15,627 - train - INFO - Train: 71 [ 200/781 ( 26%)]  Loss:  3.414947 (3.5998)  Time: 0.454s,  281.95/s  (0.528s,  242.41/s)  LR: 2.755e-04  Data: 0.005 (0.008)
2024-04-07 05:25:41,306 - train - INFO - Train: 71 [ 250/781 ( 32%)]  Loss:  3.417569 (3.6028)  Time: 0.539s,  237.66/s  (0.525s,  243.74/s)  LR: 2.755e-04  Data: 0.006 (0.008)
2024-04-07 05:26:08,033 - train - INFO - Train: 71 [ 300/781 ( 38%)]  Loss:  3.229257 (3.6057)  Time: 0.517s,  247.68/s  (0.527s,  243.02/s)  LR: 2.755e-04  Data: 0.009 (0.008)
2024-04-07 05:26:35,639 - train - INFO - Train: 71 [ 350/781 ( 45%)]  Loss:  3.806690 (3.6079)  Time: 0.546s,  234.22/s  (0.530s,  241.36/s)  LR: 2.755e-04  Data: 0.010 (0.008)
2024-04-07 05:27:02,673 - train - INFO - Train: 71 [ 400/781 ( 51%)]  Loss:  3.818660 (3.6126)  Time: 1.073s,  119.32/s  (0.532s,  240.78/s)  LR: 2.755e-04  Data: 0.009 (0.008)
2024-04-07 05:27:29,317 - train - INFO - Train: 71 [ 450/781 ( 58%)]  Loss:  3.534682 (3.6166)  Time: 0.457s,  280.17/s  (0.532s,  240.72/s)  LR: 2.755e-04  Data: 0.006 (0.008)
2024-04-07 05:27:56,313 - train - INFO - Train: 71 [ 500/781 ( 64%)]  Loss:  3.894639 (3.6200)  Time: 0.549s,  233.01/s  (0.533s,  240.35/s)  LR: 2.755e-04  Data: 0.010 (0.008)
2024-04-07 05:28:21,651 - train - INFO - Train: 71 [ 550/781 ( 71%)]  Loss:  3.409096 (3.6223)  Time: 0.465s,  275.13/s  (0.530s,  241.41/s)  LR: 2.755e-04  Data: 0.005 (0.008)
2024-04-07 05:28:48,415 - train - INFO - Train: 71 [ 600/781 ( 77%)]  Loss:  3.435071 (3.6248)  Time: 0.483s,  265.20/s  (0.531s,  241.22/s)  LR: 2.755e-04  Data: 0.006 (0.008)
2024-04-07 05:29:15,840 - train - INFO - Train: 71 [ 650/781 ( 83%)]  Loss:  3.344995 (3.6251)  Time: 0.595s,  215.14/s  (0.532s,  240.60/s)  LR: 2.755e-04  Data: 0.008 (0.008)
2024-04-07 05:29:44,359 - train - INFO - Train: 71 [ 700/781 ( 90%)]  Loss:  3.537063 (3.6263)  Time: 1.020s,  125.52/s  (0.535s,  239.37/s)  LR: 2.755e-04  Data: 0.007 (0.008)
2024-04-07 05:30:10,088 - train - INFO - Train: 71 [ 750/781 ( 96%)]  Loss:  3.528760 (3.6262)  Time: 0.582s,  219.81/s  (0.533s,  239.97/s)  LR: 2.755e-04  Data: 0.009 (0.008)
2024-04-07 05:30:26,465 - train - INFO - Train: 71 [ 780/781 (100%)]  Loss:  3.868745 (3.6272)  Time: 0.542s,  236.04/s  (0.534s,  239.76/s)  LR: 2.755e-04  Data: 0.000 (0.008)
2024-04-07 05:30:26,467 - train - INFO - True
2024-04-07 05:30:26,469 - train - INFO - alphas:tensor([0.5869, 0.0541, 0.0722, 0.0977, 0.1891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,470 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,470 - train - INFO - True
2024-04-07 05:30:26,472 - train - INFO - alphas:tensor([0.4209, 0.0255, 0.0425, 0.0900, 0.4210], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,472 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,473 - train - INFO - True
2024-04-07 05:30:26,474 - train - INFO - alphas:tensor([0.4504, 0.0405, 0.0868, 0.4223], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,475 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,476 - train - INFO - True
2024-04-07 05:30:26,477 - train - INFO - alphas:tensor([0.3942, 0.0374, 0.0687, 0.4998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,478 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,478 - train - INFO - True
2024-04-07 05:30:26,480 - train - INFO - alphas:tensor([0.3986, 0.0289, 0.0774, 0.4951], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,481 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,481 - train - INFO - True
2024-04-07 05:30:26,482 - train - INFO - alphas:tensor([0.4779, 0.0392, 0.0674, 0.4156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,484 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,484 - train - INFO - True
2024-04-07 05:30:26,485 - train - INFO - alphas:tensor([0.5209, 0.0259, 0.0329, 0.0713, 0.3491], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,487 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,487 - train - INFO - True
2024-04-07 05:30:26,489 - train - INFO - alphas:tensor([0.2237, 0.0145, 0.0134, 0.0653, 0.6832], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,490 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,490 - train - INFO - True
2024-04-07 05:30:26,491 - train - INFO - alphas:tensor([0.2325, 0.0114, 0.0149, 0.0532, 0.6879], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,492 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,493 - train - INFO - True
2024-04-07 05:30:26,494 - train - INFO - alphas:tensor([0.2313, 0.0091, 0.0130, 0.0570, 0.6895], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,495 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,495 - train - INFO - True
2024-04-07 05:30:26,497 - train - INFO - alphas:tensor([0.2176, 0.0131, 0.0135, 0.0659, 0.6898], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,498 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,498 - train - INFO - True
2024-04-07 05:30:26,507 - train - INFO - alphas:tensor([0.5281, 0.0144, 0.0232, 0.0638, 0.3705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,508 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,509 - train - INFO - True
2024-04-07 05:30:26,516 - train - INFO - alphas:tensor([0.6228, 0.0165, 0.0200, 0.0491, 0.2914], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,521 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,521 - train - INFO - True
2024-04-07 05:30:26,528 - train - INFO - alphas:tensor([0.2321, 0.0245, 0.0249, 0.1019, 0.6166], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,531 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,531 - train - INFO - True
2024-04-07 05:30:26,538 - train - INFO - alphas:tensor([0.2483, 0.0162, 0.0203, 0.0976, 0.6177], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,540 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,540 - train - INFO - True
2024-04-07 05:30:26,547 - train - INFO - alphas:tensor([0.2658, 0.0130, 0.0188, 0.0899, 0.6126], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,550 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,550 - train - INFO - True
2024-04-07 05:30:26,551 - train - INFO - alphas:tensor([0.2377, 0.0184, 0.0240, 0.0874, 0.6325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,553 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,553 - train - INFO - True
2024-04-07 05:30:26,554 - train - INFO - alphas:tensor([0.2654, 0.0136, 0.0245, 0.0875, 0.6091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,556 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,556 - train - INFO - True
2024-04-07 05:30:26,557 - train - INFO - alphas:tensor([0.2205, 0.0277, 0.0327, 0.1033, 0.6158], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,559 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,560 - train - INFO - True
2024-04-07 05:30:26,561 - train - INFO - alphas:tensor([0.5786, 0.0105, 0.0158, 0.0586, 0.3364], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,564 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,564 - train - INFO - True
2024-04-07 05:30:26,565 - train - INFO - alphas:tensor([0.5015, 0.0101, 0.0125, 0.0616, 0.4143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,573 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,573 - train - INFO - True
2024-04-07 05:30:26,574 - train - INFO - alphas:tensor([0.3790, 0.0090, 0.0196, 0.0777, 0.5147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,578 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,578 - train - INFO - True
2024-04-07 05:30:26,579 - train - INFO - alphas:tensor([0.3963, 0.0093, 0.0127, 0.0722, 0.5096], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,583 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,583 - train - INFO - True
2024-04-07 05:30:26,584 - train - INFO - alphas:tensor([0.4118, 0.0083, 0.0124, 0.0705, 0.4971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,588 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,588 - train - INFO - True
2024-04-07 05:30:26,589 - train - INFO - alphas:tensor([0.3746, 0.0096, 0.0166, 0.0767, 0.5225], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,593 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,593 - train - INFO - True
2024-04-07 05:30:26,594 - train - INFO - alphas:tensor([0.5285, 0.0080, 0.0140, 0.0514, 0.3981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,601 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,601 - train - INFO - True
2024-04-07 05:30:26,602 - train - INFO - alphas:tensor([0.6745, 0.0070, 0.0123, 0.0414, 0.2649], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,622 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,622 - train - INFO - True
2024-04-07 05:30:26,626 - train - INFO - alphas:tensor([0.3429, 0.0104, 0.0155, 0.0860, 0.5453], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,636 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,637 - train - INFO - True
2024-04-07 05:30:26,646 - train - INFO - alphas:tensor([0.3491, 0.0069, 0.0129, 0.0741, 0.5571], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,656 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,656 - train - INFO - True
2024-04-07 05:30:26,664 - train - INFO - alphas:tensor([0.3820, 0.0073, 0.0114, 0.0745, 0.5248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,674 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,674 - train - INFO - True
2024-04-07 05:30:26,675 - train - INFO - alphas:tensor([0.3413, 0.0091, 0.0136, 0.0784, 0.5576], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,685 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,685 - train - INFO - True
2024-04-07 05:30:26,686 - train - INFO - alphas:tensor([0.6739, 0.0058, 0.0082, 0.0345, 0.2776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,705 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,705 - train - INFO - True
2024-04-07 05:30:26,706 - train - INFO - alphas:tensor([0.5098, 0.0169, 0.0223, 0.0755, 0.3755], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:30:26,784 - train - INFO - tau:0.4998370298991989
2024-04-07 05:30:26,784 - train - INFO - avg block size:10.06060606060606
2024-04-07 05:30:26,784 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 05:30:27,050 - train - INFO - Test: [   0/78]  Time: 0.263 (0.263)  Loss:  0.9722 (0.9722)  Acc@1: 81.2500 (81.2500)  Acc@5: 94.5312 (94.5312)
2024-04-07 05:30:31,993 - train - INFO - Test: [  50/78]  Time: 0.100 (0.102)  Loss:  1.7256 (1.5955)  Acc@1: 59.3750 (64.0472)  Acc@5: 82.0312 (85.3707)
2024-04-07 05:30:34,662 - train - INFO - Test: [  78/78]  Time: 0.094 (0.100)  Loss:  2.2324 (1.6098)  Acc@1: 43.7500 (63.9000)  Acc@5: 81.2500 (85.1100)
2024-04-07 05:30:35,437 - train - INFO - Train: 72 [   0/781 (  0%)]  Loss:  3.994338 (3.9943)  Time: 0.695s,  184.20/s  (0.695s,  184.20/s)  LR: 2.704e-04  Data: 0.190 (0.190)
2024-04-07 05:31:03,414 - train - INFO - Train: 72 [  50/781 (  6%)]  Loss:  3.336841 (3.6899)  Time: 0.521s,  245.46/s  (0.562s,  227.69/s)  LR: 2.704e-04  Data: 0.009 (0.012)
2024-04-07 05:31:29,985 - train - INFO - Train: 72 [ 100/781 ( 13%)]  Loss:  3.585068 (3.6570)  Time: 0.513s,  249.51/s  (0.547s,  234.04/s)  LR: 2.704e-04  Data: 0.008 (0.010)
2024-04-07 05:31:58,483 - train - INFO - Train: 72 [ 150/781 ( 19%)]  Loss:  3.964061 (3.6455)  Time: 0.447s,  286.19/s  (0.555s,  230.82/s)  LR: 2.704e-04  Data: 0.006 (0.009)
2024-04-07 05:32:26,366 - train - INFO - Train: 72 [ 200/781 ( 26%)]  Loss:  3.829032 (3.6490)  Time: 0.430s,  297.92/s  (0.555s,  230.50/s)  LR: 2.704e-04  Data: 0.005 (0.009)
2024-04-07 05:32:53,712 - train - INFO - Train: 72 [ 250/781 ( 32%)]  Loss:  3.522125 (3.6447)  Time: 0.556s,  230.37/s  (0.554s,  231.20/s)  LR: 2.704e-04  Data: 0.009 (0.009)
2024-04-07 05:33:20,128 - train - INFO - Train: 72 [ 300/781 ( 38%)]  Loss:  3.376172 (3.6392)  Time: 0.480s,  266.58/s  (0.549s,  232.98/s)  LR: 2.704e-04  Data: 0.008 (0.009)
2024-04-07 05:33:46,237 - train - INFO - Train: 72 [ 350/781 ( 45%)]  Loss:  3.916512 (3.6435)  Time: 0.494s,  259.18/s  (0.546s,  234.64/s)  LR: 2.704e-04  Data: 0.009 (0.009)
2024-04-07 05:34:13,416 - train - INFO - Train: 72 [ 400/781 ( 51%)]  Loss:  3.673341 (3.6398)  Time: 0.536s,  238.98/s  (0.545s,  234.74/s)  LR: 2.704e-04  Data: 0.006 (0.008)
2024-04-07 05:34:40,118 - train - INFO - Train: 72 [ 450/781 ( 58%)]  Loss:  3.231195 (3.6336)  Time: 0.453s,  282.53/s  (0.544s,  235.28/s)  LR: 2.704e-04  Data: 0.005 (0.008)
2024-04-07 05:35:07,200 - train - INFO - Train: 72 [ 500/781 ( 64%)]  Loss:  3.275639 (3.6351)  Time: 0.531s,  241.09/s  (0.544s,  235.39/s)  LR: 2.704e-04  Data: 0.006 (0.008)
2024-04-07 05:35:33,975 - train - INFO - Train: 72 [ 550/781 ( 71%)]  Loss:  3.675225 (3.6329)  Time: 0.562s,  227.88/s  (0.543s,  235.71/s)  LR: 2.704e-04  Data: 0.006 (0.008)
2024-04-07 05:36:01,076 - train - INFO - Train: 72 [ 600/781 ( 77%)]  Loss:  3.761201 (3.6303)  Time: 0.418s,  306.53/s  (0.543s,  235.75/s)  LR: 2.704e-04  Data: 0.005 (0.008)
2024-04-07 05:36:27,753 - train - INFO - Train: 72 [ 650/781 ( 83%)]  Loss:  3.501177 (3.6273)  Time: 0.480s,  266.40/s  (0.542s,  236.07/s)  LR: 2.704e-04  Data: 0.007 (0.008)
2024-04-07 05:36:54,994 - train - INFO - Train: 72 [ 700/781 ( 90%)]  Loss:  3.402931 (3.6252)  Time: 0.457s,  280.28/s  (0.542s,  235.99/s)  LR: 2.704e-04  Data: 0.008 (0.008)
2024-04-07 05:37:21,584 - train - INFO - Train: 72 [ 750/781 ( 96%)]  Loss:  3.737512 (3.6264)  Time: 0.580s,  220.79/s  (0.542s,  236.30/s)  LR: 2.704e-04  Data: 0.009 (0.008)
2024-04-07 05:37:37,834 - train - INFO - Train: 72 [ 780/781 (100%)]  Loss:  3.246727 (3.6281)  Time: 0.549s,  233.09/s  (0.542s,  236.30/s)  LR: 2.704e-04  Data: 0.000 (0.008)
2024-04-07 05:37:37,835 - train - INFO - True
2024-04-07 05:37:37,843 - train - INFO - alphas:tensor([0.5880, 0.0534, 0.0717, 0.0973, 0.1896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,844 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,845 - train - INFO - True
2024-04-07 05:37:37,846 - train - INFO - alphas:tensor([0.4203, 0.0249, 0.0418, 0.0891, 0.4239], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,847 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,847 - train - INFO - True
2024-04-07 05:37:37,848 - train - INFO - alphas:tensor([0.4534, 0.0394, 0.0852, 0.4220], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,850 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,850 - train - INFO - True
2024-04-07 05:37:37,851 - train - INFO - alphas:tensor([0.3950, 0.0371, 0.0681, 0.4998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,852 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,852 - train - INFO - True
2024-04-07 05:37:37,854 - train - INFO - alphas:tensor([0.3962, 0.0284, 0.0772, 0.4982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,854 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,855 - train - INFO - True
2024-04-07 05:37:37,856 - train - INFO - alphas:tensor([0.4820, 0.0384, 0.0669, 0.4127], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,857 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,857 - train - INFO - True
2024-04-07 05:37:37,859 - train - INFO - alphas:tensor([0.5216, 0.0252, 0.0322, 0.0699, 0.3511], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,860 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,860 - train - INFO - True
2024-04-07 05:37:37,862 - train - INFO - alphas:tensor([0.2233, 0.0140, 0.0130, 0.0638, 0.6860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,863 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,863 - train - INFO - True
2024-04-07 05:37:37,864 - train - INFO - alphas:tensor([0.2344, 0.0111, 0.0145, 0.0522, 0.6878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,865 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,865 - train - INFO - True
2024-04-07 05:37:37,867 - train - INFO - alphas:tensor([0.2353, 0.0089, 0.0127, 0.0566, 0.6864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,868 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,868 - train - INFO - True
2024-04-07 05:37:37,869 - train - INFO - alphas:tensor([0.2182, 0.0125, 0.0130, 0.0654, 0.6909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,870 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,870 - train - INFO - True
2024-04-07 05:37:37,872 - train - INFO - alphas:tensor([0.5287, 0.0139, 0.0227, 0.0628, 0.3719], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,873 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,873 - train - INFO - True
2024-04-07 05:37:37,875 - train - INFO - alphas:tensor([0.6236, 0.0160, 0.0196, 0.0484, 0.2924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,879 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,880 - train - INFO - True
2024-04-07 05:37:37,881 - train - INFO - alphas:tensor([0.2336, 0.0238, 0.0247, 0.1023, 0.6156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,883 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,884 - train - INFO - True
2024-04-07 05:37:37,885 - train - INFO - alphas:tensor([0.2469, 0.0158, 0.0197, 0.0958, 0.6219], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,887 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,887 - train - INFO - True
2024-04-07 05:37:37,894 - train - INFO - alphas:tensor([0.2719, 0.0126, 0.0183, 0.0891, 0.6081], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,896 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,896 - train - INFO - True
2024-04-07 05:37:37,903 - train - INFO - alphas:tensor([0.2411, 0.0183, 0.0234, 0.0864, 0.6307], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,906 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,906 - train - INFO - True
2024-04-07 05:37:37,915 - train - INFO - alphas:tensor([0.2714, 0.0132, 0.0236, 0.0857, 0.6060], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,917 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,917 - train - INFO - True
2024-04-07 05:37:37,924 - train - INFO - alphas:tensor([0.2229, 0.0272, 0.0321, 0.1026, 0.6152], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,926 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,926 - train - INFO - True
2024-04-07 05:37:37,934 - train - INFO - alphas:tensor([0.5717, 0.0104, 0.0155, 0.0596, 0.3428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,937 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,937 - train - INFO - True
2024-04-07 05:37:37,938 - train - INFO - alphas:tensor([0.5045, 0.0097, 0.0121, 0.0606, 0.4131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,946 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,946 - train - INFO - True
2024-04-07 05:37:37,947 - train - INFO - alphas:tensor([0.3814, 0.0086, 0.0193, 0.0755, 0.5151], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,951 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,951 - train - INFO - True
2024-04-07 05:37:37,952 - train - INFO - alphas:tensor([0.3960, 0.0090, 0.0123, 0.0712, 0.5115], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,955 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,956 - train - INFO - True
2024-04-07 05:37:37,956 - train - INFO - alphas:tensor([0.4087, 0.0080, 0.0121, 0.0704, 0.5009], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,960 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,960 - train - INFO - True
2024-04-07 05:37:37,961 - train - INFO - alphas:tensor([0.3723, 0.0092, 0.0162, 0.0759, 0.5264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,965 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,965 - train - INFO - True
2024-04-07 05:37:37,966 - train - INFO - alphas:tensor([0.5302, 0.0078, 0.0136, 0.0505, 0.3978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,974 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,974 - train - INFO - True
2024-04-07 05:37:37,975 - train - INFO - alphas:tensor([0.6784, 0.0068, 0.0120, 0.0406, 0.2622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:37,994 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:37,994 - train - INFO - True
2024-04-07 05:37:38,003 - train - INFO - alphas:tensor([0.3346, 0.0101, 0.0156, 0.0862, 0.5535], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:38,013 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:38,013 - train - INFO - True
2024-04-07 05:37:38,020 - train - INFO - alphas:tensor([0.3467, 0.0067, 0.0127, 0.0738, 0.5600], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:38,030 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:38,031 - train - INFO - True
2024-04-07 05:37:38,032 - train - INFO - alphas:tensor([0.3788, 0.0072, 0.0113, 0.0754, 0.5273], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:38,042 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:38,042 - train - INFO - True
2024-04-07 05:37:38,043 - train - INFO - alphas:tensor([0.3413, 0.0086, 0.0132, 0.0777, 0.5591], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:38,053 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:38,053 - train - INFO - True
2024-04-07 05:37:38,054 - train - INFO - alphas:tensor([0.6757, 0.0056, 0.0080, 0.0339, 0.2766], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:38,074 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:38,074 - train - INFO - True
2024-04-07 05:37:38,082 - train - INFO - alphas:tensor([0.5114, 0.0167, 0.0220, 0.0746, 0.3753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:37:38,159 - train - INFO - tau:0.49483865960020695
2024-04-07 05:37:38,159 - train - INFO - avg block size:10.06060606060606
2024-04-07 05:37:38,160 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 05:37:38,160 - train - INFO - lasso_alpha:1.1289478601075544e-05
2024-04-07 05:37:38,407 - train - INFO - Test: [   0/78]  Time: 0.243 (0.243)  Loss:  0.9946 (0.9946)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 05:37:44,062 - train - INFO - Test: [  50/78]  Time: 0.092 (0.116)  Loss:  1.7646 (1.6163)  Acc@1: 60.9375 (64.2310)  Acc@5: 84.3750 (85.4626)
2024-04-07 05:37:47,503 - train - INFO - Test: [  78/78]  Time: 0.097 (0.118)  Loss:  2.0000 (1.6311)  Acc@1: 56.2500 (64.1300)  Acc@5: 87.5000 (84.9700)
2024-04-07 05:37:48,213 - train - INFO - Train: 73 [   0/781 (  0%)]  Loss:  4.014665 (4.0147)  Time: 0.626s,  204.60/s  (0.626s,  204.60/s)  LR: 2.653e-04  Data: 0.167 (0.167)
2024-04-07 05:38:14,844 - train - INFO - Train: 73 [  50/781 (  6%)]  Loss:  3.515802 (3.6405)  Time: 0.520s,  246.13/s  (0.534s,  239.51/s)  LR: 2.653e-04  Data: 0.008 (0.010)
2024-04-07 05:38:41,717 - train - INFO - Train: 73 [ 100/781 ( 13%)]  Loss:  3.583481 (3.6214)  Time: 0.573s,  223.32/s  (0.536s,  238.85/s)  LR: 2.653e-04  Data: 0.008 (0.009)
2024-04-07 05:39:08,464 - train - INFO - Train: 73 [ 150/781 ( 19%)]  Loss:  3.274906 (3.6175)  Time: 0.600s,  213.51/s  (0.536s,  239.00/s)  LR: 2.653e-04  Data: 0.006 (0.009)
2024-04-07 05:39:36,012 - train - INFO - Train: 73 [ 200/781 ( 26%)]  Loss:  3.412942 (3.6293)  Time: 0.574s,  222.85/s  (0.539s,  237.30/s)  LR: 2.653e-04  Data: 0.008 (0.008)
2024-04-07 05:40:03,087 - train - INFO - Train: 73 [ 250/781 ( 32%)]  Loss:  3.313562 (3.6230)  Time: 0.547s,  234.12/s  (0.540s,  237.12/s)  LR: 2.653e-04  Data: 0.008 (0.008)
2024-04-07 05:40:29,767 - train - INFO - Train: 73 [ 300/781 ( 38%)]  Loss:  3.786222 (3.6227)  Time: 0.519s,  246.47/s  (0.539s,  237.58/s)  LR: 2.653e-04  Data: 0.006 (0.008)
2024-04-07 05:40:57,263 - train - INFO - Train: 73 [ 350/781 ( 45%)]  Loss:  4.002678 (3.6310)  Time: 0.542s,  236.32/s  (0.540s,  236.89/s)  LR: 2.653e-04  Data: 0.010 (0.008)
2024-04-07 05:41:23,385 - train - INFO - Train: 73 [ 400/781 ( 51%)]  Loss:  3.399032 (3.6233)  Time: 0.536s,  238.72/s  (0.538s,  237.87/s)  LR: 2.653e-04  Data: 0.019 (0.008)
2024-04-07 05:41:49,782 - train - INFO - Train: 73 [ 450/781 ( 58%)]  Loss:  3.699978 (3.6194)  Time: 0.567s,  225.68/s  (0.537s,  238.37/s)  LR: 2.653e-04  Data: 0.009 (0.008)
2024-04-07 05:42:16,622 - train - INFO - Train: 73 [ 500/781 ( 64%)]  Loss:  3.174697 (3.6205)  Time: 0.440s,  291.08/s  (0.537s,  238.38/s)  LR: 2.653e-04  Data: 0.007 (0.008)
2024-04-07 05:42:41,172 - train - INFO - Train: 73 [ 550/781 ( 71%)]  Loss:  3.627005 (3.6204)  Time: 0.361s,  354.98/s  (0.533s,  240.25/s)  LR: 2.653e-04  Data: 0.004 (0.008)
2024-04-07 05:43:08,098 - train - INFO - Train: 73 [ 600/781 ( 77%)]  Loss:  3.322121 (3.6198)  Time: 0.549s,  233.19/s  (0.533s,  240.03/s)  LR: 2.653e-04  Data: 0.012 (0.008)
2024-04-07 05:43:34,607 - train - INFO - Train: 73 [ 650/781 ( 83%)]  Loss:  3.333789 (3.6165)  Time: 0.523s,  244.52/s  (0.533s,  240.14/s)  LR: 2.653e-04  Data: 0.007 (0.008)
2024-04-07 05:44:00,990 - train - INFO - Train: 73 [ 700/781 ( 90%)]  Loss:  3.653008 (3.6165)  Time: 0.842s,  152.03/s  (0.533s,  240.32/s)  LR: 2.653e-04  Data: 0.004 (0.008)
2024-04-07 05:44:27,151 - train - INFO - Train: 73 [ 750/781 ( 96%)]  Loss:  3.909325 (3.6173)  Time: 0.441s,  290.06/s  (0.532s,  240.60/s)  LR: 2.653e-04  Data: 0.005 (0.008)
2024-04-07 05:44:43,618 - train - INFO - Train: 73 [ 780/781 (100%)]  Loss:  3.899627 (3.6193)  Time: 0.519s,  246.45/s  (0.533s,  240.31/s)  LR: 2.653e-04  Data: 0.000 (0.008)
2024-04-07 05:44:43,618 - train - INFO - True
2024-04-07 05:44:43,620 - train - INFO - alphas:tensor([0.5912, 0.0521, 0.0705, 0.0967, 0.1895], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,620 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,620 - train - INFO - True
2024-04-07 05:44:43,621 - train - INFO - alphas:tensor([0.4199, 0.0245, 0.0409, 0.0889, 0.4259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,621 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,621 - train - INFO - True
2024-04-07 05:44:43,622 - train - INFO - alphas:tensor([0.4533, 0.0387, 0.0849, 0.4231], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,623 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,623 - train - INFO - True
2024-04-07 05:44:43,624 - train - INFO - alphas:tensor([0.3962, 0.0362, 0.0668, 0.5007], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,624 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,624 - train - INFO - True
2024-04-07 05:44:43,625 - train - INFO - alphas:tensor([0.4017, 0.0279, 0.0756, 0.4948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,625 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,625 - train - INFO - True
2024-04-07 05:44:43,626 - train - INFO - alphas:tensor([0.4823, 0.0374, 0.0658, 0.4144], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,627 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,627 - train - INFO - True
2024-04-07 05:44:43,628 - train - INFO - alphas:tensor([0.5255, 0.0246, 0.0315, 0.0687, 0.3498], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,628 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,629 - train - INFO - True
2024-04-07 05:44:43,629 - train - INFO - alphas:tensor([0.2267, 0.0139, 0.0128, 0.0640, 0.6826], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,630 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,630 - train - INFO - True
2024-04-07 05:44:43,631 - train - INFO - alphas:tensor([0.2377, 0.0110, 0.0143, 0.0521, 0.6848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,631 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,631 - train - INFO - True
2024-04-07 05:44:43,632 - train - INFO - alphas:tensor([0.2388, 0.0087, 0.0124, 0.0557, 0.6844], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,633 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,633 - train - INFO - True
2024-04-07 05:44:43,634 - train - INFO - alphas:tensor([0.2226, 0.0123, 0.0126, 0.0645, 0.6880], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,634 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,634 - train - INFO - True
2024-04-07 05:44:43,635 - train - INFO - alphas:tensor([0.5333, 0.0134, 0.0221, 0.0623, 0.3689], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,636 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,636 - train - INFO - True
2024-04-07 05:44:43,637 - train - INFO - alphas:tensor([0.6253, 0.0154, 0.0190, 0.0476, 0.2927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,639 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,639 - train - INFO - True
2024-04-07 05:44:43,640 - train - INFO - alphas:tensor([0.2385, 0.0237, 0.0244, 0.1025, 0.6109], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,641 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,642 - train - INFO - True
2024-04-07 05:44:43,642 - train - INFO - alphas:tensor([0.2544, 0.0156, 0.0191, 0.0956, 0.6154], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,644 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,644 - train - INFO - True
2024-04-07 05:44:43,644 - train - INFO - alphas:tensor([0.2751, 0.0126, 0.0178, 0.0877, 0.6069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,646 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,646 - train - INFO - True
2024-04-07 05:44:43,647 - train - INFO - alphas:tensor([0.2423, 0.0183, 0.0228, 0.0857, 0.6309], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,648 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,648 - train - INFO - True
2024-04-07 05:44:43,649 - train - INFO - alphas:tensor([0.2712, 0.0128, 0.0229, 0.0854, 0.6076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,650 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,650 - train - INFO - True
2024-04-07 05:44:43,651 - train - INFO - alphas:tensor([0.2251, 0.0268, 0.0317, 0.1017, 0.6146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,653 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,653 - train - INFO - True
2024-04-07 05:44:43,653 - train - INFO - alphas:tensor([0.5828, 0.0099, 0.0151, 0.0580, 0.3341], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,656 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,656 - train - INFO - True
2024-04-07 05:44:43,657 - train - INFO - alphas:tensor([0.5075, 0.0093, 0.0117, 0.0595, 0.4120], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,662 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,662 - train - INFO - True
2024-04-07 05:44:43,663 - train - INFO - alphas:tensor([0.3861, 0.0083, 0.0184, 0.0749, 0.5123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,665 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,665 - train - INFO - True
2024-04-07 05:44:43,666 - train - INFO - alphas:tensor([0.4018, 0.0087, 0.0118, 0.0704, 0.5074], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,669 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,669 - train - INFO - True
2024-04-07 05:44:43,670 - train - INFO - alphas:tensor([0.4159, 0.0076, 0.0117, 0.0681, 0.4967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,672 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,672 - train - INFO - True
2024-04-07 05:44:43,673 - train - INFO - alphas:tensor([0.3744, 0.0090, 0.0160, 0.0753, 0.5254], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,676 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,676 - train - INFO - True
2024-04-07 05:44:43,676 - train - INFO - alphas:tensor([0.5297, 0.0075, 0.0133, 0.0501, 0.3994], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,681 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,681 - train - INFO - True
2024-04-07 05:44:43,682 - train - INFO - alphas:tensor([0.6753, 0.0066, 0.0116, 0.0405, 0.2660], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,695 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,695 - train - INFO - True
2024-04-07 05:44:43,702 - train - INFO - alphas:tensor([0.3480, 0.0097, 0.0148, 0.0857, 0.5417], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,709 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,709 - train - INFO - True
2024-04-07 05:44:43,714 - train - INFO - alphas:tensor([0.3597, 0.0065, 0.0124, 0.0733, 0.5481], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,720 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,720 - train - INFO - True
2024-04-07 05:44:43,725 - train - INFO - alphas:tensor([0.3890, 0.0071, 0.0111, 0.0758, 0.5171], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,731 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,732 - train - INFO - True
2024-04-07 05:44:43,732 - train - INFO - alphas:tensor([0.3516, 0.0085, 0.0131, 0.0764, 0.5504], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,738 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,738 - train - INFO - True
2024-04-07 05:44:43,739 - train - INFO - alphas:tensor([0.6777, 0.0055, 0.0076, 0.0334, 0.2758], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,753 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,753 - train - INFO - True
2024-04-07 05:44:43,754 - train - INFO - alphas:tensor([0.5142, 0.0163, 0.0215, 0.0738, 0.3742], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:44:43,807 - train - INFO - tau:0.4898902730042049
2024-04-07 05:44:43,808 - train - INFO - avg block size:10.06060606060606
2024-04-07 05:44:43,808 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 05:44:44,120 - train - INFO - Test: [   0/78]  Time: 0.309 (0.309)  Loss:  1.0918 (1.0918)  Acc@1: 81.2500 (81.2500)  Acc@5: 92.1875 (92.1875)
2024-04-07 05:44:50,066 - train - INFO - Test: [  50/78]  Time: 0.186 (0.123)  Loss:  1.7520 (1.6662)  Acc@1: 64.0625 (63.5723)  Acc@5: 85.1562 (84.9418)
2024-04-07 05:44:52,797 - train - INFO - Test: [  78/78]  Time: 0.047 (0.114)  Loss:  1.8994 (1.6730)  Acc@1: 62.5000 (63.4700)  Acc@5: 93.7500 (84.8800)
2024-04-07 05:44:53,569 - train - INFO - Train: 74 [   0/781 (  0%)]  Loss:  3.612157 (3.6122)  Time: 0.688s,  186.15/s  (0.688s,  186.15/s)  LR: 2.601e-04  Data: 0.182 (0.182)
2024-04-07 05:45:21,126 - train - INFO - Train: 74 [  50/781 (  6%)]  Loss:  3.708576 (3.6081)  Time: 0.490s,  261.12/s  (0.554s,  231.16/s)  LR: 2.601e-04  Data: 0.006 (0.011)
2024-04-07 05:45:48,685 - train - INFO - Train: 74 [ 100/781 ( 13%)]  Loss:  3.950926 (3.6092)  Time: 0.575s,  222.68/s  (0.552s,  231.70/s)  LR: 2.601e-04  Data: 0.010 (0.010)
2024-04-07 05:46:15,930 - train - INFO - Train: 74 [ 150/781 ( 19%)]  Loss:  3.243750 (3.6248)  Time: 0.519s,  246.51/s  (0.550s,  232.76/s)  LR: 2.601e-04  Data: 0.008 (0.009)
2024-04-07 05:46:40,762 - train - INFO - Train: 74 [ 200/781 ( 26%)]  Loss:  3.863518 (3.6241)  Time: 0.396s,  323.13/s  (0.537s,  238.51/s)  LR: 2.601e-04  Data: 0.005 (0.009)
2024-04-07 05:47:06,896 - train - INFO - Train: 74 [ 250/781 ( 32%)]  Loss:  3.611158 (3.6099)  Time: 0.435s,  294.25/s  (0.534s,  239.75/s)  LR: 2.601e-04  Data: 0.006 (0.009)
2024-04-07 05:47:34,015 - train - INFO - Train: 74 [ 300/781 ( 38%)]  Loss:  3.549817 (3.6186)  Time: 0.493s,  259.82/s  (0.535s,  239.12/s)  LR: 2.601e-04  Data: 0.006 (0.008)
2024-04-07 05:48:01,397 - train - INFO - Train: 74 [ 350/781 ( 45%)]  Loss:  3.586391 (3.6209)  Time: 0.526s,  243.33/s  (0.537s,  238.34/s)  LR: 2.601e-04  Data: 0.007 (0.008)
2024-04-07 05:48:28,035 - train - INFO - Train: 74 [ 400/781 ( 51%)]  Loss:  3.436121 (3.6105)  Time: 0.486s,  263.40/s  (0.537s,  238.58/s)  LR: 2.601e-04  Data: 0.008 (0.008)
2024-04-07 05:48:54,640 - train - INFO - Train: 74 [ 450/781 ( 58%)]  Loss:  3.774142 (3.6083)  Time: 0.502s,  255.22/s  (0.536s,  238.80/s)  LR: 2.601e-04  Data: 0.005 (0.008)
2024-04-07 05:49:21,403 - train - INFO - Train: 74 [ 500/781 ( 64%)]  Loss:  3.811878 (3.6110)  Time: 0.346s,  370.07/s  (0.536s,  238.84/s)  LR: 2.601e-04  Data: 0.004 (0.008)
2024-04-07 05:49:47,879 - train - INFO - Train: 74 [ 550/781 ( 71%)]  Loss:  3.460990 (3.6106)  Time: 0.594s,  215.52/s  (0.535s,  239.10/s)  LR: 2.601e-04  Data: 0.009 (0.008)
2024-04-07 05:50:14,827 - train - INFO - Train: 74 [ 600/781 ( 77%)]  Loss:  3.730926 (3.6102)  Time: 0.502s,  255.01/s  (0.536s,  238.96/s)  LR: 2.601e-04  Data: 0.009 (0.008)
2024-04-07 05:50:41,269 - train - INFO - Train: 74 [ 650/781 ( 83%)]  Loss:  3.786760 (3.6139)  Time: 0.491s,  260.70/s  (0.535s,  239.20/s)  LR: 2.601e-04  Data: 0.009 (0.008)
2024-04-07 05:51:07,755 - train - INFO - Train: 74 [ 700/781 ( 90%)]  Loss:  3.800475 (3.6131)  Time: 0.475s,  269.71/s  (0.535s,  239.37/s)  LR: 2.601e-04  Data: 0.010 (0.008)
2024-04-07 05:51:33,432 - train - INFO - Train: 74 [ 750/781 ( 96%)]  Loss:  3.831330 (3.6141)  Time: 0.454s,  282.17/s  (0.533s,  240.01/s)  LR: 2.601e-04  Data: 0.004 (0.008)
2024-04-07 05:51:49,812 - train - INFO - Train: 74 [ 780/781 (100%)]  Loss:  3.282372 (3.6151)  Time: 0.464s,  276.02/s  (0.534s,  239.79/s)  LR: 2.601e-04  Data: 0.000 (0.008)
2024-04-07 05:51:49,813 - train - INFO - True
2024-04-07 05:51:49,814 - train - INFO - alphas:tensor([0.5926, 0.0513, 0.0701, 0.0958, 0.1901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,815 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,815 - train - INFO - True
2024-04-07 05:51:49,816 - train - INFO - alphas:tensor([0.4218, 0.0234, 0.0399, 0.0875, 0.4274], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,816 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,816 - train - INFO - True
2024-04-07 05:51:49,817 - train - INFO - alphas:tensor([0.4557, 0.0378, 0.0834, 0.4232], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,818 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,818 - train - INFO - True
2024-04-07 05:51:49,819 - train - INFO - alphas:tensor([0.3983, 0.0355, 0.0650, 0.5012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,819 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,819 - train - INFO - True
2024-04-07 05:51:49,820 - train - INFO - alphas:tensor([0.4024, 0.0272, 0.0745, 0.4960], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,820 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,820 - train - INFO - True
2024-04-07 05:51:49,821 - train - INFO - alphas:tensor([0.4858, 0.0367, 0.0656, 0.4119], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,822 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,822 - train - INFO - True
2024-04-07 05:51:49,823 - train - INFO - alphas:tensor([0.5270, 0.0240, 0.0309, 0.0678, 0.3502], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,824 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,824 - train - INFO - True
2024-04-07 05:51:49,825 - train - INFO - alphas:tensor([0.2301, 0.0138, 0.0125, 0.0632, 0.6803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,825 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,825 - train - INFO - True
2024-04-07 05:51:49,826 - train - INFO - alphas:tensor([0.2386, 0.0106, 0.0138, 0.0512, 0.6857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,827 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,827 - train - INFO - True
2024-04-07 05:51:49,827 - train - INFO - alphas:tensor([0.2363, 0.0084, 0.0121, 0.0561, 0.6871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,828 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,828 - train - INFO - True
2024-04-07 05:51:49,829 - train - INFO - alphas:tensor([0.2232, 0.0120, 0.0123, 0.0640, 0.6884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,830 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,830 - train - INFO - True
2024-04-07 05:51:49,830 - train - INFO - alphas:tensor([0.5328, 0.0127, 0.0214, 0.0615, 0.3715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,831 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,831 - train - INFO - True
2024-04-07 05:51:49,832 - train - INFO - alphas:tensor([0.6251, 0.0151, 0.0187, 0.0470, 0.2942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,835 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,835 - train - INFO - True
2024-04-07 05:51:49,836 - train - INFO - alphas:tensor([0.2402, 0.0229, 0.0237, 0.1000, 0.6131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,837 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,838 - train - INFO - True
2024-04-07 05:51:49,838 - train - INFO - alphas:tensor([0.2521, 0.0151, 0.0184, 0.0952, 0.6191], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,840 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,840 - train - INFO - True
2024-04-07 05:51:49,841 - train - INFO - alphas:tensor([0.2781, 0.0124, 0.0176, 0.0860, 0.6060], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,842 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,842 - train - INFO - True
2024-04-07 05:51:49,843 - train - INFO - alphas:tensor([0.2432, 0.0176, 0.0223, 0.0847, 0.6322], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,845 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,845 - train - INFO - True
2024-04-07 05:51:49,846 - train - INFO - alphas:tensor([0.2763, 0.0126, 0.0226, 0.0847, 0.6038], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,847 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,847 - train - INFO - True
2024-04-07 05:51:49,848 - train - INFO - alphas:tensor([0.2279, 0.0264, 0.0311, 0.1009, 0.6138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,849 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,850 - train - INFO - True
2024-04-07 05:51:49,850 - train - INFO - alphas:tensor([0.5807, 0.0096, 0.0149, 0.0578, 0.3371], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,853 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,853 - train - INFO - True
2024-04-07 05:51:49,854 - train - INFO - alphas:tensor([0.5108, 0.0091, 0.0115, 0.0589, 0.4097], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,859 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,860 - train - INFO - True
2024-04-07 05:51:49,865 - train - INFO - alphas:tensor([0.3882, 0.0080, 0.0180, 0.0745, 0.5112], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,868 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,868 - train - INFO - True
2024-04-07 05:51:49,874 - train - INFO - alphas:tensor([0.3973, 0.0086, 0.0116, 0.0705, 0.5120], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,877 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,877 - train - INFO - True
2024-04-07 05:51:49,883 - train - INFO - alphas:tensor([0.4185, 0.0074, 0.0114, 0.0687, 0.4940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,891 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,891 - train - INFO - True
2024-04-07 05:51:49,903 - train - INFO - alphas:tensor([0.3788, 0.0087, 0.0156, 0.0744, 0.5225], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,906 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,906 - train - INFO - True
2024-04-07 05:51:49,907 - train - INFO - alphas:tensor([0.5307, 0.0072, 0.0131, 0.0499, 0.3992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,912 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,913 - train - INFO - True
2024-04-07 05:51:49,913 - train - INFO - alphas:tensor([0.6819, 0.0063, 0.0111, 0.0393, 0.2615], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,927 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,927 - train - INFO - True
2024-04-07 05:51:49,928 - train - INFO - alphas:tensor([0.3450, 0.0093, 0.0144, 0.0848, 0.5465], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,935 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,935 - train - INFO - True
2024-04-07 05:51:49,936 - train - INFO - alphas:tensor([0.3571, 0.0063, 0.0123, 0.0737, 0.5505], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,943 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,943 - train - INFO - True
2024-04-07 05:51:49,944 - train - INFO - alphas:tensor([0.3846, 0.0068, 0.0109, 0.0749, 0.5228], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,951 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,951 - train - INFO - True
2024-04-07 05:51:49,951 - train - INFO - alphas:tensor([0.3512, 0.0082, 0.0128, 0.0759, 0.5518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,958 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,958 - train - INFO - True
2024-04-07 05:51:49,963 - train - INFO - alphas:tensor([0.6823, 0.0052, 0.0073, 0.0324, 0.2728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:49,976 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:49,976 - train - INFO - True
2024-04-07 05:51:49,982 - train - INFO - alphas:tensor([0.5167, 0.0161, 0.0216, 0.0736, 0.3720], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:51:50,035 - train - INFO - tau:0.48499137027416284
2024-04-07 05:51:50,035 - train - INFO - avg block size:10.06060606060606
2024-04-07 05:51:50,035 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 05:51:50,035 - train - INFO - lasso_alpha:1.026316236461413e-05
2024-04-07 05:51:50,277 - train - INFO - Test: [   0/78]  Time: 0.238 (0.238)  Loss:  1.0762 (1.0762)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.1875 (92.1875)
2024-04-07 05:51:55,606 - train - INFO - Test: [  50/78]  Time: 0.099 (0.109)  Loss:  1.6455 (1.6008)  Acc@1: 61.7188 (64.3842)  Acc@5: 83.5938 (85.4013)
2024-04-07 05:51:58,869 - train - INFO - Test: [  78/78]  Time: 0.101 (0.112)  Loss:  1.8467 (1.6192)  Acc@1: 68.7500 (63.8300)  Acc@5: 93.7500 (84.9900)
2024-04-07 05:51:59,542 - train - INFO - Train: 75 [   0/781 (  0%)]  Loss:  3.326905 (3.3269)  Time: 0.585s,  218.91/s  (0.585s,  218.91/s)  LR: 2.550e-04  Data: 0.169 (0.169)
2024-04-07 05:52:26,765 - train - INFO - Train: 75 [  50/781 (  6%)]  Loss:  3.508570 (3.6174)  Time: 0.514s,  248.88/s  (0.545s,  234.77/s)  LR: 2.550e-04  Data: 0.008 (0.011)
2024-04-07 05:52:54,055 - train - INFO - Train: 75 [ 100/781 ( 13%)]  Loss:  3.507121 (3.6076)  Time: 0.526s,  243.27/s  (0.545s,  234.65/s)  LR: 2.550e-04  Data: 0.010 (0.010)
2024-04-07 05:53:21,335 - train - INFO - Train: 75 [ 150/781 ( 19%)]  Loss:  3.570183 (3.6099)  Time: 0.568s,  225.23/s  (0.546s,  234.64/s)  LR: 2.550e-04  Data: 0.010 (0.009)
2024-04-07 05:53:48,540 - train - INFO - Train: 75 [ 200/781 ( 26%)]  Loss:  3.916493 (3.6009)  Time: 0.568s,  225.17/s  (0.545s,  234.79/s)  LR: 2.550e-04  Data: 0.005 (0.009)
2024-04-07 05:54:15,554 - train - INFO - Train: 75 [ 250/781 ( 32%)]  Loss:  3.199398 (3.5957)  Time: 0.449s,  285.33/s  (0.544s,  235.22/s)  LR: 2.550e-04  Data: 0.009 (0.009)
2024-04-07 05:54:42,334 - train - INFO - Train: 75 [ 300/781 ( 38%)]  Loss:  3.755411 (3.6043)  Time: 0.508s,  251.93/s  (0.543s,  235.84/s)  LR: 2.550e-04  Data: 0.008 (0.008)
2024-04-07 05:55:09,406 - train - INFO - Train: 75 [ 350/781 ( 45%)]  Loss:  3.390702 (3.6095)  Time: 0.450s,  284.21/s  (0.543s,  235.92/s)  LR: 2.550e-04  Data: 0.006 (0.008)
2024-04-07 05:55:36,011 - train - INFO - Train: 75 [ 400/781 ( 51%)]  Loss:  3.341780 (3.6079)  Time: 0.511s,  250.32/s  (0.541s,  236.49/s)  LR: 2.550e-04  Data: 0.009 (0.008)
2024-04-07 05:56:02,792 - train - INFO - Train: 75 [ 450/781 ( 58%)]  Loss:  3.252628 (3.6038)  Time: 0.530s,  241.57/s  (0.541s,  236.76/s)  LR: 2.550e-04  Data: 0.010 (0.008)
2024-04-07 05:56:29,471 - train - INFO - Train: 75 [ 500/781 ( 64%)]  Loss:  3.794871 (3.6009)  Time: 0.513s,  249.38/s  (0.540s,  237.07/s)  LR: 2.550e-04  Data: 0.008 (0.008)
2024-04-07 05:56:56,746 - train - INFO - Train: 75 [ 550/781 ( 71%)]  Loss:  3.681858 (3.6035)  Time: 0.581s,  220.20/s  (0.540s,  236.85/s)  LR: 2.550e-04  Data: 0.006 (0.008)
2024-04-07 05:57:23,566 - train - INFO - Train: 75 [ 600/781 ( 77%)]  Loss:  3.406662 (3.6051)  Time: 0.491s,  260.54/s  (0.540s,  237.00/s)  LR: 2.550e-04  Data: 0.007 (0.008)
2024-04-07 05:57:50,961 - train - INFO - Train: 75 [ 650/781 ( 83%)]  Loss:  3.676087 (3.6063)  Time: 0.469s,  273.19/s  (0.541s,  236.74/s)  LR: 2.550e-04  Data: 0.007 (0.008)
2024-04-07 05:58:18,104 - train - INFO - Train: 75 [ 700/781 ( 90%)]  Loss:  3.845813 (3.6026)  Time: 0.496s,  258.14/s  (0.541s,  236.67/s)  LR: 2.550e-04  Data: 0.006 (0.008)
2024-04-07 05:58:45,194 - train - INFO - Train: 75 [ 750/781 ( 96%)]  Loss:  3.447110 (3.6083)  Time: 0.524s,  244.50/s  (0.541s,  236.64/s)  LR: 2.550e-04  Data: 0.006 (0.008)
2024-04-07 05:59:00,665 - train - INFO - Train: 75 [ 780/781 (100%)]  Loss:  3.422928 (3.6094)  Time: 0.523s,  244.84/s  (0.540s,  237.07/s)  LR: 2.550e-04  Data: 0.000 (0.008)
2024-04-07 05:59:00,666 - train - INFO - True
2024-04-07 05:59:00,674 - train - INFO - alphas:tensor([0.5960, 0.0505, 0.0689, 0.0949, 0.1896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,675 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,675 - train - INFO - True
2024-04-07 05:59:00,676 - train - INFO - alphas:tensor([0.4253, 0.0230, 0.0391, 0.0863, 0.4262], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,677 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,677 - train - INFO - True
2024-04-07 05:59:00,678 - train - INFO - alphas:tensor([0.4564, 0.0372, 0.0823, 0.4240], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,679 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,679 - train - INFO - True
2024-04-07 05:59:00,681 - train - INFO - alphas:tensor([0.4053, 0.0347, 0.0636, 0.4963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,681 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,681 - train - INFO - True
2024-04-07 05:59:00,683 - train - INFO - alphas:tensor([0.4050, 0.0266, 0.0739, 0.4945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,683 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,683 - train - INFO - True
2024-04-07 05:59:00,685 - train - INFO - alphas:tensor([0.4895, 0.0361, 0.0647, 0.4097], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,686 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,686 - train - INFO - True
2024-04-07 05:59:00,687 - train - INFO - alphas:tensor([0.5309, 0.0232, 0.0299, 0.0667, 0.3492], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,688 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,688 - train - INFO - True
2024-04-07 05:59:00,689 - train - INFO - alphas:tensor([0.2337, 0.0134, 0.0120, 0.0623, 0.6785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,690 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,690 - train - INFO - True
2024-04-07 05:59:00,692 - train - INFO - alphas:tensor([0.2399, 0.0105, 0.0133, 0.0508, 0.6855], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,692 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,693 - train - INFO - True
2024-04-07 05:59:00,694 - train - INFO - alphas:tensor([0.2405, 0.0083, 0.0116, 0.0555, 0.6841], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,695 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,695 - train - INFO - True
2024-04-07 05:59:00,696 - train - INFO - alphas:tensor([0.2244, 0.0117, 0.0121, 0.0633, 0.6884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,697 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,697 - train - INFO - True
2024-04-07 05:59:00,698 - train - INFO - alphas:tensor([0.5349, 0.0124, 0.0210, 0.0602, 0.3715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,699 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,699 - train - INFO - True
2024-04-07 05:59:00,700 - train - INFO - alphas:tensor([0.6291, 0.0147, 0.0181, 0.0457, 0.2924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,705 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,705 - train - INFO - True
2024-04-07 05:59:00,706 - train - INFO - alphas:tensor([0.2425, 0.0228, 0.0239, 0.1007, 0.6101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,708 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,708 - train - INFO - True
2024-04-07 05:59:00,709 - train - INFO - alphas:tensor([0.2601, 0.0149, 0.0181, 0.0947, 0.6123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,711 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,711 - train - INFO - True
2024-04-07 05:59:00,712 - train - INFO - alphas:tensor([0.2807, 0.0119, 0.0171, 0.0856, 0.6046], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,715 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,715 - train - INFO - True
2024-04-07 05:59:00,716 - train - INFO - alphas:tensor([0.2494, 0.0172, 0.0222, 0.0839, 0.6272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,718 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,718 - train - INFO - True
2024-04-07 05:59:00,719 - train - INFO - alphas:tensor([0.2795, 0.0123, 0.0223, 0.0846, 0.6013], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,721 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,721 - train - INFO - True
2024-04-07 05:59:00,729 - train - INFO - alphas:tensor([0.2328, 0.0262, 0.0305, 0.1002, 0.6104], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,731 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,731 - train - INFO - True
2024-04-07 05:59:00,739 - train - INFO - alphas:tensor([0.5859, 0.0091, 0.0144, 0.0565, 0.3340], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,747 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,747 - train - INFO - True
2024-04-07 05:59:00,756 - train - INFO - alphas:tensor([0.5099, 0.0087, 0.0111, 0.0581, 0.4122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,768 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,768 - train - INFO - True
2024-04-07 05:59:00,769 - train - INFO - alphas:tensor([0.3919, 0.0078, 0.0177, 0.0741, 0.5085], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,774 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,774 - train - INFO - True
2024-04-07 05:59:00,775 - train - INFO - alphas:tensor([0.4063, 0.0083, 0.0113, 0.0703, 0.5038], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,780 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,780 - train - INFO - True
2024-04-07 05:59:00,781 - train - INFO - alphas:tensor([0.4250, 0.0072, 0.0109, 0.0668, 0.4900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,786 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,786 - train - INFO - True
2024-04-07 05:59:00,787 - train - INFO - alphas:tensor([0.3845, 0.0085, 0.0154, 0.0742, 0.5175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,792 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,792 - train - INFO - True
2024-04-07 05:59:00,793 - train - INFO - alphas:tensor([0.5336, 0.0071, 0.0130, 0.0495, 0.3968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,802 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,802 - train - INFO - True
2024-04-07 05:59:00,803 - train - INFO - alphas:tensor([0.6828, 0.0062, 0.0109, 0.0387, 0.2614], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,824 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,824 - train - INFO - True
2024-04-07 05:59:00,833 - train - INFO - alphas:tensor([0.3472, 0.0090, 0.0140, 0.0839, 0.5459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,843 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,843 - train - INFO - True
2024-04-07 05:59:00,850 - train - INFO - alphas:tensor([0.3607, 0.0061, 0.0119, 0.0727, 0.5485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,860 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,860 - train - INFO - True
2024-04-07 05:59:00,861 - train - INFO - alphas:tensor([0.3924, 0.0066, 0.0104, 0.0730, 0.5176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,871 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,871 - train - INFO - True
2024-04-07 05:59:00,872 - train - INFO - alphas:tensor([0.3542, 0.0080, 0.0123, 0.0758, 0.5498], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,882 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,882 - train - INFO - True
2024-04-07 05:59:00,883 - train - INFO - alphas:tensor([0.6824, 0.0050, 0.0071, 0.0320, 0.2734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,903 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,903 - train - INFO - True
2024-04-07 05:59:00,911 - train - INFO - alphas:tensor([0.5213, 0.0157, 0.0212, 0.0728, 0.3691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:59:00,989 - train - INFO - tau:0.4801414565714212
2024-04-07 05:59:00,989 - train - INFO - avg block size:10.06060606060606
2024-04-07 05:59:00,989 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 05:59:01,244 - train - INFO - Test: [   0/78]  Time: 0.251 (0.251)  Loss:  0.9180 (0.9180)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 05:59:06,665 - train - INFO - Test: [  50/78]  Time: 0.102 (0.111)  Loss:  1.6357 (1.5961)  Acc@1: 67.9688 (64.5833)  Acc@5: 85.1562 (85.6158)
2024-04-07 05:59:08,742 - train - INFO - Test: [  78/78]  Time: 0.054 (0.098)  Loss:  1.5967 (1.6145)  Acc@1: 68.7500 (64.3700)  Acc@5: 100.0000 (85.3200)
2024-04-07 05:59:09,959 - train - INFO - Train: 76 [   0/781 (  0%)]  Loss:  3.518799 (3.5188)  Time: 1.119s,  114.43/s  (1.119s,  114.43/s)  LR: 2.499e-04  Data: 0.192 (0.192)
2024-04-07 05:59:37,379 - train - INFO - Train: 76 [  50/781 (  6%)]  Loss:  3.759151 (3.6211)  Time: 0.498s,  256.92/s  (0.560s,  228.75/s)  LR: 2.499e-04  Data: 0.014 (0.012)
2024-04-07 06:00:02,199 - train - INFO - Train: 76 [ 100/781 ( 13%)]  Loss:  3.781197 (3.5887)  Time: 0.403s,  317.25/s  (0.528s,  242.30/s)  LR: 2.499e-04  Data: 0.008 (0.009)
2024-04-07 06:00:29,093 - train - INFO - Train: 76 [ 150/781 ( 19%)]  Loss:  3.576350 (3.5986)  Time: 0.430s,  297.96/s  (0.531s,  240.85/s)  LR: 2.499e-04  Data: 0.006 (0.009)
2024-04-07 06:00:54,157 - train - INFO - Train: 76 [ 200/781 ( 26%)]  Loss:  3.618596 (3.6027)  Time: 0.466s,  274.92/s  (0.524s,  244.30/s)  LR: 2.499e-04  Data: 0.009 (0.008)
2024-04-07 06:01:20,958 - train - INFO - Train: 76 [ 250/781 ( 32%)]  Loss:  3.454218 (3.6059)  Time: 0.497s,  257.62/s  (0.526s,  243.19/s)  LR: 2.499e-04  Data: 0.009 (0.008)
2024-04-07 06:01:48,687 - train - INFO - Train: 76 [ 300/781 ( 38%)]  Loss:  3.314175 (3.6151)  Time: 0.478s,  267.54/s  (0.531s,  241.05/s)  LR: 2.499e-04  Data: 0.009 (0.008)
2024-04-07 06:02:15,386 - train - INFO - Train: 76 [ 350/781 ( 45%)]  Loss:  3.640153 (3.6147)  Time: 0.557s,  229.77/s  (0.531s,  240.86/s)  LR: 2.499e-04  Data: 0.020 (0.008)
2024-04-07 06:02:42,288 - train - INFO - Train: 76 [ 400/781 ( 51%)]  Loss:  3.411720 (3.6092)  Time: 0.558s,  229.40/s  (0.532s,  240.49/s)  LR: 2.499e-04  Data: 0.009 (0.008)
2024-04-07 06:03:09,338 - train - INFO - Train: 76 [ 450/781 ( 58%)]  Loss:  3.664009 (3.6063)  Time: 0.502s,  255.13/s  (0.533s,  240.05/s)  LR: 2.499e-04  Data: 0.005 (0.008)
2024-04-07 06:03:35,497 - train - INFO - Train: 76 [ 500/781 ( 64%)]  Loss:  3.404240 (3.6063)  Time: 0.532s,  240.57/s  (0.532s,  240.50/s)  LR: 2.499e-04  Data: 0.008 (0.008)
2024-04-07 06:04:02,837 - train - INFO - Train: 76 [ 550/781 ( 71%)]  Loss:  3.317609 (3.6071)  Time: 0.503s,  254.56/s  (0.534s,  239.91/s)  LR: 2.499e-04  Data: 0.008 (0.008)
2024-04-07 06:04:29,111 - train - INFO - Train: 76 [ 600/781 ( 77%)]  Loss:  3.845238 (3.6059)  Time: 0.479s,  267.44/s  (0.533s,  240.21/s)  LR: 2.499e-04  Data: 0.008 (0.008)
2024-04-07 06:04:56,298 - train - INFO - Train: 76 [ 650/781 ( 83%)]  Loss:  3.438288 (3.6095)  Time: 0.528s,  242.25/s  (0.534s,  239.84/s)  LR: 2.499e-04  Data: 0.008 (0.008)
2024-04-07 06:05:23,003 - train - INFO - Train: 76 [ 700/781 ( 90%)]  Loss:  3.696975 (3.6075)  Time: 0.489s,  261.75/s  (0.534s,  239.82/s)  LR: 2.499e-04  Data: 0.006 (0.008)
2024-04-07 06:05:50,762 - train - INFO - Train: 76 [ 750/781 ( 96%)]  Loss:  3.467878 (3.6069)  Time: 0.455s,  281.36/s  (0.535s,  239.19/s)  LR: 2.499e-04  Data: 0.009 (0.008)
2024-04-07 06:06:07,265 - train - INFO - Train: 76 [ 780/781 (100%)]  Loss:  3.920167 (3.6069)  Time: 0.549s,  233.03/s  (0.536s,  238.93/s)  LR: 2.499e-04  Data: 0.000 (0.008)
2024-04-07 06:06:07,266 - train - INFO - True
2024-04-07 06:06:07,268 - train - INFO - alphas:tensor([0.5982, 0.0496, 0.0685, 0.0940, 0.1896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,269 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,269 - train - INFO - True
2024-04-07 06:06:07,271 - train - INFO - alphas:tensor([0.4275, 0.0225, 0.0387, 0.0854, 0.4259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,271 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,272 - train - INFO - True
2024-04-07 06:06:07,273 - train - INFO - alphas:tensor([0.4599, 0.0365, 0.0819, 0.4218], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,274 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,274 - train - INFO - True
2024-04-07 06:06:07,275 - train - INFO - alphas:tensor([0.4063, 0.0345, 0.0627, 0.4965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,276 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,276 - train - INFO - True
2024-04-07 06:06:07,278 - train - INFO - alphas:tensor([0.4063, 0.0258, 0.0725, 0.4953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,278 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,278 - train - INFO - True
2024-04-07 06:06:07,280 - train - INFO - alphas:tensor([0.4892, 0.0353, 0.0639, 0.4116], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,281 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,281 - train - INFO - True
2024-04-07 06:06:07,282 - train - INFO - alphas:tensor([0.5326, 0.0226, 0.0291, 0.0653, 0.3504], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,284 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,284 - train - INFO - True
2024-04-07 06:06:07,285 - train - INFO - alphas:tensor([0.2328, 0.0131, 0.0118, 0.0615, 0.6808], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,286 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,286 - train - INFO - True
2024-04-07 06:06:07,287 - train - INFO - alphas:tensor([0.2434, 0.0102, 0.0130, 0.0498, 0.6835], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,288 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,288 - train - INFO - True
2024-04-07 06:06:07,290 - train - INFO - alphas:tensor([0.2437, 0.0080, 0.0113, 0.0546, 0.6823], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,290 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,291 - train - INFO - True
2024-04-07 06:06:07,292 - train - INFO - alphas:tensor([0.2265, 0.0115, 0.0116, 0.0624, 0.6880], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,293 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,293 - train - INFO - True
2024-04-07 06:06:07,294 - train - INFO - alphas:tensor([0.5362, 0.0121, 0.0206, 0.0597, 0.3714], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,295 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,296 - train - INFO - True
2024-04-07 06:06:07,297 - train - INFO - alphas:tensor([0.6305, 0.0142, 0.0176, 0.0452, 0.2925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,301 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,301 - train - INFO - True
2024-04-07 06:06:07,303 - train - INFO - alphas:tensor([0.2439, 0.0226, 0.0236, 0.0996, 0.6103], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,305 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,305 - train - INFO - True
2024-04-07 06:06:07,306 - train - INFO - alphas:tensor([0.2628, 0.0145, 0.0177, 0.0939, 0.6111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,310 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,310 - train - INFO - True
2024-04-07 06:06:07,317 - train - INFO - alphas:tensor([0.2826, 0.0116, 0.0169, 0.0838, 0.6051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,320 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,320 - train - INFO - True
2024-04-07 06:06:07,327 - train - INFO - alphas:tensor([0.2524, 0.0168, 0.0216, 0.0833, 0.6260], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,329 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,329 - train - INFO - True
2024-04-07 06:06:07,336 - train - INFO - alphas:tensor([0.2809, 0.0121, 0.0220, 0.0840, 0.6010], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,338 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,338 - train - INFO - True
2024-04-07 06:06:07,346 - train - INFO - alphas:tensor([0.2367, 0.0251, 0.0297, 0.0985, 0.6100], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,348 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,348 - train - INFO - True
2024-04-07 06:06:07,355 - train - INFO - alphas:tensor([0.5881, 0.0090, 0.0140, 0.0565, 0.3323], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,359 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,359 - train - INFO - True
2024-04-07 06:06:07,360 - train - INFO - alphas:tensor([0.5163, 0.0084, 0.0107, 0.0575, 0.4071], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,367 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,367 - train - INFO - True
2024-04-07 06:06:07,368 - train - INFO - alphas:tensor([0.3865, 0.0078, 0.0176, 0.0735, 0.5145], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,372 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,372 - train - INFO - True
2024-04-07 06:06:07,373 - train - INFO - alphas:tensor([0.4127, 0.0080, 0.0111, 0.0694, 0.4987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,377 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,377 - train - INFO - True
2024-04-07 06:06:07,378 - train - INFO - alphas:tensor([0.4268, 0.0069, 0.0106, 0.0664, 0.4892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,382 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,382 - train - INFO - True
2024-04-07 06:06:07,383 - train - INFO - alphas:tensor([0.3904, 0.0082, 0.0150, 0.0727, 0.5137], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,386 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,387 - train - INFO - True
2024-04-07 06:06:07,387 - train - INFO - alphas:tensor([0.5394, 0.0068, 0.0124, 0.0483, 0.3930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,395 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,395 - train - INFO - True
2024-04-07 06:06:07,396 - train - INFO - alphas:tensor([0.6893, 0.0059, 0.0106, 0.0379, 0.2563], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,415 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,415 - train - INFO - True
2024-04-07 06:06:07,416 - train - INFO - alphas:tensor([0.3478, 0.0088, 0.0136, 0.0834, 0.5464], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,426 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,427 - train - INFO - True
2024-04-07 06:06:07,427 - train - INFO - alphas:tensor([0.3651, 0.0059, 0.0118, 0.0713, 0.5459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,438 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,438 - train - INFO - True
2024-04-07 06:06:07,439 - train - INFO - alphas:tensor([0.3958, 0.0063, 0.0100, 0.0712, 0.5167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,449 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,449 - train - INFO - True
2024-04-07 06:06:07,457 - train - INFO - alphas:tensor([0.3555, 0.0076, 0.0119, 0.0738, 0.5512], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,467 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,467 - train - INFO - True
2024-04-07 06:06:07,474 - train - INFO - alphas:tensor([0.6866, 0.0048, 0.0068, 0.0312, 0.2707], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,493 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,494 - train - INFO - True
2024-04-07 06:06:07,495 - train - INFO - alphas:tensor([0.5238, 0.0156, 0.0208, 0.0727, 0.3671], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:06:07,572 - train - INFO - tau:0.475340042005707
2024-04-07 06:06:07,572 - train - INFO - avg block size:9.606060606060606
2024-04-07 06:06:07,573 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 06:06:07,573 - train - INFO - lasso_alpha:1.1289478601075544e-05
2024-04-07 06:06:07,813 - train - INFO - Test: [   0/78]  Time: 0.237 (0.237)  Loss:  1.0146 (1.0146)  Acc@1: 80.4688 (80.4688)  Acc@5: 93.7500 (93.7500)
2024-04-07 06:06:13,324 - train - INFO - Test: [  50/78]  Time: 0.104 (0.113)  Loss:  1.5371 (1.5954)  Acc@1: 65.6250 (64.5374)  Acc@5: 86.7188 (85.9222)
2024-04-07 06:06:15,310 - train - INFO - Test: [  78/78]  Time: 0.053 (0.098)  Loss:  1.9668 (1.6191)  Acc@1: 62.5000 (64.1100)  Acc@5: 93.7500 (85.5700)
2024-04-07 06:06:16,122 - train - INFO - Train: 77 [   0/781 (  0%)]  Loss:  3.943261 (3.9433)  Time: 0.737s,  173.71/s  (0.737s,  173.71/s)  LR: 2.447e-04  Data: 0.181 (0.181)
2024-04-07 06:06:43,140 - train - INFO - Train: 77 [  50/781 (  6%)]  Loss:  3.604023 (3.6137)  Time: 0.432s,  296.26/s  (0.544s,  235.22/s)  LR: 2.447e-04  Data: 0.004 (0.011)
2024-04-07 06:07:10,529 - train - INFO - Train: 77 [ 100/781 ( 13%)]  Loss:  3.459938 (3.6064)  Time: 0.452s,  282.97/s  (0.546s,  234.46/s)  LR: 2.447e-04  Data: 0.009 (0.010)
2024-04-07 06:07:37,555 - train - INFO - Train: 77 [ 150/781 ( 19%)]  Loss:  3.646492 (3.5939)  Time: 0.525s,  243.60/s  (0.544s,  235.24/s)  LR: 2.447e-04  Data: 0.008 (0.009)
2024-04-07 06:08:04,013 - train - INFO - Train: 77 [ 200/781 ( 26%)]  Loss:  3.834222 (3.6097)  Time: 0.540s,  237.25/s  (0.540s,  236.86/s)  LR: 2.447e-04  Data: 0.008 (0.009)
2024-04-07 06:08:30,472 - train - INFO - Train: 77 [ 250/781 ( 32%)]  Loss:  3.416730 (3.6135)  Time: 0.556s,  230.37/s  (0.538s,  237.85/s)  LR: 2.447e-04  Data: 0.009 (0.008)
2024-04-07 06:08:57,862 - train - INFO - Train: 77 [ 300/781 ( 38%)]  Loss:  3.475667 (3.6036)  Time: 0.464s,  276.15/s  (0.540s,  237.14/s)  LR: 2.447e-04  Data: 0.004 (0.008)
2024-04-07 06:09:24,775 - train - INFO - Train: 77 [ 350/781 ( 45%)]  Loss:  3.968782 (3.6098)  Time: 0.517s,  247.48/s  (0.540s,  237.24/s)  LR: 2.447e-04  Data: 0.005 (0.008)
2024-04-07 06:09:50,783 - train - INFO - Train: 77 [ 400/781 ( 51%)]  Loss:  3.337973 (3.6054)  Time: 0.575s,  222.44/s  (0.537s,  238.31/s)  LR: 2.447e-04  Data: 0.012 (0.008)
2024-04-07 06:10:17,726 - train - INFO - Train: 77 [ 450/781 ( 58%)]  Loss:  3.622665 (3.6092)  Time: 0.491s,  260.62/s  (0.537s,  238.23/s)  LR: 2.447e-04  Data: 0.008 (0.008)
2024-04-07 06:10:45,405 - train - INFO - Train: 77 [ 500/781 ( 64%)]  Loss:  3.130731 (3.6031)  Time: 0.545s,  234.72/s  (0.539s,  237.51/s)  LR: 2.447e-04  Data: 0.005 (0.008)
2024-04-07 06:11:11,383 - train - INFO - Train: 77 [ 550/781 ( 71%)]  Loss:  3.590617 (3.6041)  Time: 0.449s,  285.24/s  (0.537s,  238.29/s)  LR: 2.447e-04  Data: 0.008 (0.008)
2024-04-07 06:11:38,591 - train - INFO - Train: 77 [ 600/781 ( 77%)]  Loss:  3.485001 (3.6068)  Time: 0.537s,  238.17/s  (0.538s,  238.03/s)  LR: 2.447e-04  Data: 0.015 (0.008)
2024-04-07 06:12:04,715 - train - INFO - Train: 77 [ 650/781 ( 83%)]  Loss:  3.670646 (3.6069)  Time: 0.417s,  306.98/s  (0.537s,  238.55/s)  LR: 2.447e-04  Data: 0.004 (0.008)
2024-04-07 06:12:31,130 - train - INFO - Train: 77 [ 700/781 ( 90%)]  Loss:  3.444183 (3.6070)  Time: 0.485s,  263.89/s  (0.536s,  238.82/s)  LR: 2.447e-04  Data: 0.006 (0.008)
2024-04-07 06:12:56,673 - train - INFO - Train: 77 [ 750/781 ( 96%)]  Loss:  3.413553 (3.6047)  Time: 0.564s,  227.08/s  (0.534s,  239.56/s)  LR: 2.447e-04  Data: 0.010 (0.008)
2024-04-07 06:13:12,575 - train - INFO - Train: 77 [ 780/781 (100%)]  Loss:  3.887595 (3.6052)  Time: 0.532s,  240.40/s  (0.534s,  239.64/s)  LR: 2.447e-04  Data: 0.000 (0.008)
2024-04-07 06:13:12,576 - train - INFO - True
2024-04-07 06:13:12,585 - train - INFO - alphas:tensor([0.6015, 0.0488, 0.0677, 0.0927, 0.1892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,586 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,586 - train - INFO - True
2024-04-07 06:13:12,594 - train - INFO - alphas:tensor([0.4265, 0.0220, 0.0379, 0.0849, 0.4287], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,595 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,595 - train - INFO - True
2024-04-07 06:13:12,599 - train - INFO - alphas:tensor([0.4603, 0.0355, 0.0802, 0.4240], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,600 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,600 - train - INFO - True
2024-04-07 06:13:12,601 - train - INFO - alphas:tensor([0.4059, 0.0339, 0.0620, 0.4982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,602 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,602 - train - INFO - True
2024-04-07 06:13:12,603 - train - INFO - alphas:tensor([0.4089, 0.0253, 0.0710, 0.4949], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,603 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,603 - train - INFO - True
2024-04-07 06:13:12,604 - train - INFO - alphas:tensor([0.4881, 0.0347, 0.0626, 0.4146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,605 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,605 - train - INFO - True
2024-04-07 06:13:12,606 - train - INFO - alphas:tensor([0.5335, 0.0223, 0.0286, 0.0647, 0.3509], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,608 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,608 - train - INFO - True
2024-04-07 06:13:12,609 - train - INFO - alphas:tensor([0.2302, 0.0127, 0.0112, 0.0609, 0.6849], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,610 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,610 - train - INFO - True
2024-04-07 06:13:12,611 - train - INFO - alphas:tensor([0.2404, 0.0098, 0.0127, 0.0493, 0.6878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,612 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,612 - train - INFO - True
2024-04-07 06:13:12,613 - train - INFO - alphas:tensor([0.2388, 0.0076, 0.0108, 0.0534, 0.6893], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,614 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,614 - train - INFO - True
2024-04-07 06:13:12,615 - train - INFO - alphas:tensor([0.2264, 0.0113, 0.0112, 0.0614, 0.6896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,615 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,616 - train - INFO - True
2024-04-07 06:13:12,616 - train - INFO - alphas:tensor([0.5373, 0.0118, 0.0200, 0.0591, 0.3719], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,618 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,618 - train - INFO - True
2024-04-07 06:13:12,619 - train - INFO - alphas:tensor([0.6323, 0.0139, 0.0171, 0.0445, 0.2922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,623 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,623 - train - INFO - True
2024-04-07 06:13:12,624 - train - INFO - alphas:tensor([0.2406, 0.0220, 0.0230, 0.1007, 0.6138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,626 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,626 - train - INFO - True
2024-04-07 06:13:12,627 - train - INFO - alphas:tensor([0.2575, 0.0140, 0.0173, 0.0932, 0.6180], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,629 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,629 - train - INFO - True
2024-04-07 06:13:12,630 - train - INFO - alphas:tensor([0.2780, 0.0111, 0.0165, 0.0838, 0.6105], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,632 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,632 - train - INFO - True
2024-04-07 06:13:12,633 - train - INFO - alphas:tensor([0.2491, 0.0162, 0.0208, 0.0826, 0.6313], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,635 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,635 - train - INFO - True
2024-04-07 06:13:12,636 - train - INFO - alphas:tensor([0.2806, 0.0118, 0.0213, 0.0845, 0.6019], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,638 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,638 - train - INFO - True
2024-04-07 06:13:12,639 - train - INFO - alphas:tensor([0.2312, 0.0244, 0.0288, 0.0971, 0.6185], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,641 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,641 - train - INFO - True
2024-04-07 06:13:12,642 - train - INFO - alphas:tensor([0.5847, 0.0088, 0.0137, 0.0562, 0.3367], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,645 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,645 - train - INFO - True
2024-04-07 06:13:12,646 - train - INFO - alphas:tensor([0.5128, 0.0082, 0.0105, 0.0572, 0.4113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,654 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,654 - train - INFO - True
2024-04-07 06:13:12,659 - train - INFO - alphas:tensor([0.3849, 0.0075, 0.0170, 0.0739, 0.5166], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,663 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,663 - train - INFO - True
2024-04-07 06:13:12,669 - train - INFO - alphas:tensor([0.4039, 0.0077, 0.0106, 0.0687, 0.5090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,672 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,673 - train - INFO - True
2024-04-07 06:13:12,678 - train - INFO - alphas:tensor([0.4191, 0.0067, 0.0104, 0.0660, 0.4978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,681 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,681 - train - INFO - True
2024-04-07 06:13:12,686 - train - INFO - alphas:tensor([0.3851, 0.0079, 0.0145, 0.0729, 0.5195], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,690 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,690 - train - INFO - True
2024-04-07 06:13:12,694 - train - INFO - alphas:tensor([0.5334, 0.0065, 0.0121, 0.0475, 0.4004], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,701 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,701 - train - INFO - True
2024-04-07 06:13:12,705 - train - INFO - alphas:tensor([0.6847, 0.0057, 0.0104, 0.0384, 0.2608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,724 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,724 - train - INFO - True
2024-04-07 06:13:12,725 - train - INFO - alphas:tensor([0.3510, 0.0087, 0.0133, 0.0822, 0.5448], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,735 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,735 - train - INFO - True
2024-04-07 06:13:12,736 - train - INFO - alphas:tensor([0.3588, 0.0057, 0.0114, 0.0714, 0.5527], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,746 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,747 - train - INFO - True
2024-04-07 06:13:12,747 - train - INFO - alphas:tensor([0.3914, 0.0061, 0.0097, 0.0707, 0.5222], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,758 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,758 - train - INFO - True
2024-04-07 06:13:12,762 - train - INFO - alphas:tensor([0.3492, 0.0073, 0.0116, 0.0736, 0.5582], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,772 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,772 - train - INFO - True
2024-04-07 06:13:12,778 - train - INFO - alphas:tensor([0.6831, 0.0047, 0.0066, 0.0313, 0.2743], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,797 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,797 - train - INFO - True
2024-04-07 06:13:12,803 - train - INFO - alphas:tensor([0.5203, 0.0155, 0.0208, 0.0731, 0.3703], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:13:12,880 - train - INFO - tau:0.47058664158564995
2024-04-07 06:13:12,880 - train - INFO - avg block size:10.06060606060606
2024-04-07 06:13:12,881 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 06:13:13,121 - train - INFO - Test: [   0/78]  Time: 0.237 (0.237)  Loss:  1.0449 (1.0449)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.9688 (92.9688)
2024-04-07 06:13:18,538 - train - INFO - Test: [  50/78]  Time: 0.111 (0.111)  Loss:  1.6113 (1.5984)  Acc@1: 63.2812 (64.6599)  Acc@5: 85.9375 (85.8609)
2024-04-07 06:13:21,289 - train - INFO - Test: [  78/78]  Time: 0.051 (0.106)  Loss:  1.8496 (1.6145)  Acc@1: 62.5000 (64.5400)  Acc@5: 87.5000 (85.5300)
2024-04-07 06:13:22,565 - train - INFO - Train: 78 [   0/781 (  0%)]  Loss:  3.455885 (3.4559)  Time: 1.113s,  115.06/s  (1.113s,  115.06/s)  LR: 2.396e-04  Data: 0.185 (0.185)
2024-04-07 06:13:48,624 - train - INFO - Train: 78 [  50/781 (  6%)]  Loss:  3.319224 (3.5893)  Time: 0.587s,  218.19/s  (0.533s,  240.26/s)  LR: 2.396e-04  Data: 0.008 (0.011)
2024-04-07 06:14:14,836 - train - INFO - Train: 78 [ 100/781 ( 13%)]  Loss:  3.704482 (3.5771)  Time: 0.492s,  260.14/s  (0.529s,  242.18/s)  LR: 2.396e-04  Data: 0.010 (0.009)
2024-04-07 06:14:41,428 - train - INFO - Train: 78 [ 150/781 ( 19%)]  Loss:  3.408426 (3.5956)  Time: 0.550s,  232.74/s  (0.530s,  241.69/s)  LR: 2.396e-04  Data: 0.008 (0.009)
2024-04-07 06:15:08,047 - train - INFO - Train: 78 [ 200/781 ( 26%)]  Loss:  3.524352 (3.5902)  Time: 0.478s,  267.56/s  (0.530s,  241.38/s)  LR: 2.396e-04  Data: 0.008 (0.008)
2024-04-07 06:15:34,656 - train - INFO - Train: 78 [ 250/781 ( 32%)]  Loss:  4.034559 (3.5853)  Time: 0.552s,  231.69/s  (0.531s,  241.21/s)  LR: 2.396e-04  Data: 0.009 (0.008)
2024-04-07 06:16:01,460 - train - INFO - Train: 78 [ 300/781 ( 38%)]  Loss:  3.485147 (3.6010)  Time: 0.488s,  262.14/s  (0.532s,  240.80/s)  LR: 2.396e-04  Data: 0.007 (0.008)
2024-04-07 06:16:29,032 - train - INFO - Train: 78 [ 350/781 ( 45%)]  Loss:  3.482194 (3.5986)  Time: 0.538s,  238.14/s  (0.534s,  239.53/s)  LR: 2.396e-04  Data: 0.007 (0.008)
2024-04-07 06:16:55,123 - train - INFO - Train: 78 [ 400/781 ( 51%)]  Loss:  3.649617 (3.6010)  Time: 0.453s,  282.45/s  (0.533s,  240.23/s)  LR: 2.396e-04  Data: 0.008 (0.008)
2024-04-07 06:17:22,688 - train - INFO - Train: 78 [ 450/781 ( 58%)]  Loss:  3.443263 (3.6080)  Time: 0.532s,  240.74/s  (0.535s,  239.32/s)  LR: 2.396e-04  Data: 0.007 (0.008)
2024-04-07 06:17:48,698 - train - INFO - Train: 78 [ 500/781 ( 64%)]  Loss:  3.408217 (3.6151)  Time: 0.508s,  251.73/s  (0.533s,  239.98/s)  LR: 2.396e-04  Data: 0.007 (0.008)
2024-04-07 06:18:15,364 - train - INFO - Train: 78 [ 550/781 ( 71%)]  Loss:  3.239439 (3.6120)  Time: 0.555s,  230.48/s  (0.533s,  239.98/s)  LR: 2.396e-04  Data: 0.013 (0.008)
2024-04-07 06:18:40,708 - train - INFO - Train: 78 [ 600/781 ( 77%)]  Loss:  3.801925 (3.6142)  Time: 0.549s,  233.08/s  (0.531s,  240.98/s)  LR: 2.396e-04  Data: 0.007 (0.008)
2024-04-07 06:19:07,134 - train - INFO - Train: 78 [ 650/781 ( 83%)]  Loss:  3.639594 (3.6132)  Time: 0.542s,  236.28/s  (0.531s,  241.07/s)  LR: 2.396e-04  Data: 0.005 (0.008)
2024-04-07 06:19:33,927 - train - INFO - Train: 78 [ 700/781 ( 90%)]  Loss:  3.943265 (3.6125)  Time: 0.564s,  227.07/s  (0.531s,  240.91/s)  LR: 2.396e-04  Data: 0.010 (0.008)
2024-04-07 06:20:01,651 - train - INFO - Train: 78 [ 750/781 ( 96%)]  Loss:  3.602025 (3.6146)  Time: 0.531s,  240.86/s  (0.533s,  240.22/s)  LR: 2.396e-04  Data: 0.007 (0.008)
2024-04-07 06:20:18,329 - train - INFO - Train: 78 [ 780/781 (100%)]  Loss:  3.779947 (3.6175)  Time: 0.630s,  203.21/s  (0.534s,  239.82/s)  LR: 2.396e-04  Data: 0.000 (0.008)
2024-04-07 06:20:18,330 - train - INFO - True
2024-04-07 06:20:18,339 - train - INFO - alphas:tensor([0.6040, 0.0482, 0.0669, 0.0920, 0.1889], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,340 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,340 - train - INFO - True
2024-04-07 06:20:18,344 - train - INFO - alphas:tensor([0.4278, 0.0214, 0.0372, 0.0839, 0.4296], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,344 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,344 - train - INFO - True
2024-04-07 06:20:18,346 - train - INFO - alphas:tensor([0.4609, 0.0343, 0.0805, 0.4243], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,347 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,347 - train - INFO - True
2024-04-07 06:20:18,349 - train - INFO - alphas:tensor([0.4063, 0.0331, 0.0613, 0.4993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,349 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,350 - train - INFO - True
2024-04-07 06:20:18,351 - train - INFO - alphas:tensor([0.4065, 0.0246, 0.0698, 0.4992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,352 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,352 - train - INFO - True
2024-04-07 06:20:18,353 - train - INFO - alphas:tensor([0.4900, 0.0345, 0.0617, 0.4138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,355 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,355 - train - INFO - True
2024-04-07 06:20:18,356 - train - INFO - alphas:tensor([0.5359, 0.0216, 0.0279, 0.0639, 0.3507], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,358 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,358 - train - INFO - True
2024-04-07 06:20:18,359 - train - INFO - alphas:tensor([0.2298, 0.0123, 0.0108, 0.0595, 0.6876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,360 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,361 - train - INFO - True
2024-04-07 06:20:18,362 - train - INFO - alphas:tensor([0.2394, 0.0096, 0.0123, 0.0485, 0.6903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,363 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,363 - train - INFO - True
2024-04-07 06:20:18,365 - train - INFO - alphas:tensor([0.2377, 0.0073, 0.0106, 0.0526, 0.6918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,366 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,366 - train - INFO - True
2024-04-07 06:20:18,367 - train - INFO - alphas:tensor([0.2249, 0.0109, 0.0108, 0.0600, 0.6934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,368 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,368 - train - INFO - True
2024-04-07 06:20:18,369 - train - INFO - alphas:tensor([0.5384, 0.0114, 0.0194, 0.0583, 0.3725], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,371 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,371 - train - INFO - True
2024-04-07 06:20:18,372 - train - INFO - alphas:tensor([0.6293, 0.0134, 0.0167, 0.0438, 0.2969], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,377 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,378 - train - INFO - True
2024-04-07 06:20:18,379 - train - INFO - alphas:tensor([0.2401, 0.0217, 0.0227, 0.1008, 0.6147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,381 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,381 - train - INFO - True
2024-04-07 06:20:18,383 - train - INFO - alphas:tensor([0.2559, 0.0134, 0.0167, 0.0923, 0.6217], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,385 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,385 - train - INFO - True
2024-04-07 06:20:18,387 - train - INFO - alphas:tensor([0.2747, 0.0106, 0.0159, 0.0821, 0.6167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,389 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,389 - train - INFO - True
2024-04-07 06:20:18,390 - train - INFO - alphas:tensor([0.2471, 0.0155, 0.0202, 0.0814, 0.6358], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,393 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,393 - train - INFO - True
2024-04-07 06:20:18,394 - train - INFO - alphas:tensor([0.2744, 0.0112, 0.0208, 0.0831, 0.6106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,396 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,397 - train - INFO - True
2024-04-07 06:20:18,398 - train - INFO - alphas:tensor([0.2315, 0.0236, 0.0281, 0.0957, 0.6211], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,400 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,400 - train - INFO - True
2024-04-07 06:20:18,401 - train - INFO - alphas:tensor([0.5866, 0.0084, 0.0133, 0.0553, 0.3364], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,405 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,406 - train - INFO - True
2024-04-07 06:20:18,407 - train - INFO - alphas:tensor([0.5100, 0.0079, 0.0102, 0.0567, 0.4152], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,415 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,415 - train - INFO - True
2024-04-07 06:20:18,423 - train - INFO - alphas:tensor([0.3880, 0.0071, 0.0165, 0.0734, 0.5150], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,428 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,428 - train - INFO - True
2024-04-07 06:20:18,435 - train - INFO - alphas:tensor([0.4040, 0.0074, 0.0104, 0.0676, 0.5106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,439 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,439 - train - INFO - True
2024-04-07 06:20:18,447 - train - INFO - alphas:tensor([0.4189, 0.0065, 0.0102, 0.0658, 0.4986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,451 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,451 - train - INFO - True
2024-04-07 06:20:18,459 - train - INFO - alphas:tensor([0.3825, 0.0075, 0.0141, 0.0707, 0.5252], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,463 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,463 - train - INFO - True
2024-04-07 06:20:18,464 - train - INFO - alphas:tensor([0.5348, 0.0062, 0.0118, 0.0468, 0.4004], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,471 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,472 - train - INFO - True
2024-04-07 06:20:18,473 - train - INFO - alphas:tensor([0.6795, 0.0055, 0.0102, 0.0383, 0.2664], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,492 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,492 - train - INFO - True
2024-04-07 06:20:18,493 - train - INFO - alphas:tensor([0.3479, 0.0085, 0.0132, 0.0818, 0.5487], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,503 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,503 - train - INFO - True
2024-04-07 06:20:18,504 - train - INFO - alphas:tensor([0.3556, 0.0055, 0.0110, 0.0711, 0.5568], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,514 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,514 - train - INFO - True
2024-04-07 06:20:18,515 - train - INFO - alphas:tensor([0.3862, 0.0058, 0.0093, 0.0715, 0.5273], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,527 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,527 - train - INFO - True
2024-04-07 06:20:18,535 - train - INFO - alphas:tensor([0.3499, 0.0070, 0.0114, 0.0735, 0.5583], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,545 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,545 - train - INFO - True
2024-04-07 06:20:18,552 - train - INFO - alphas:tensor([0.6874, 0.0045, 0.0065, 0.0310, 0.2706], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,571 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,571 - train - INFO - True
2024-04-07 06:20:18,572 - train - INFO - alphas:tensor([0.5192, 0.0152, 0.0202, 0.0725, 0.3729], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:20:18,650 - train - INFO - tau:0.4658807751697934
2024-04-07 06:20:18,650 - train - INFO - avg block size:10.06060606060606
2024-04-07 06:20:18,650 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 06:20:18,650 - train - INFO - lasso_alpha:1.026316236461413e-05
2024-04-07 06:20:18,944 - train - INFO - Test: [   0/78]  Time: 0.288 (0.288)  Loss:  0.9292 (0.9292)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 06:20:24,405 - train - INFO - Test: [  50/78]  Time: 0.102 (0.113)  Loss:  1.7861 (1.6088)  Acc@1: 60.9375 (64.5374)  Acc@5: 84.3750 (85.8150)
2024-04-07 06:20:27,152 - train - INFO - Test: [  78/78]  Time: 0.095 (0.108)  Loss:  1.9043 (1.6363)  Acc@1: 56.2500 (64.1400)  Acc@5: 100.0000 (85.4700)
2024-04-07 06:20:27,988 - train - INFO - Train: 79 [   0/781 (  0%)]  Loss:  3.728659 (3.7287)  Time: 0.762s,  167.94/s  (0.762s,  167.94/s)  LR: 2.345e-04  Data: 0.188 (0.188)
2024-04-07 06:20:56,013 - train - INFO - Train: 79 [  50/781 (  6%)]  Loss:  3.532058 (3.5216)  Time: 0.558s,  229.33/s  (0.564s,  226.78/s)  LR: 2.345e-04  Data: 0.009 (0.011)
2024-04-07 06:21:22,349 - train - INFO - Train: 79 [ 100/781 ( 13%)]  Loss:  4.012177 (3.5712)  Time: 0.519s,  246.77/s  (0.546s,  234.55/s)  LR: 2.345e-04  Data: 0.007 (0.009)
2024-04-07 06:21:49,276 - train - INFO - Train: 79 [ 150/781 ( 19%)]  Loss:  3.874211 (3.5718)  Time: 0.535s,  239.20/s  (0.543s,  235.58/s)  LR: 2.345e-04  Data: 0.005 (0.009)
2024-04-07 06:22:15,342 - train - INFO - Train: 79 [ 200/781 ( 26%)]  Loss:  3.622499 (3.5781)  Time: 0.471s,  271.55/s  (0.538s,  237.99/s)  LR: 2.345e-04  Data: 0.009 (0.008)
2024-04-07 06:22:41,703 - train - INFO - Train: 79 [ 250/781 ( 32%)]  Loss:  3.772358 (3.5754)  Time: 0.571s,  224.11/s  (0.536s,  238.93/s)  LR: 2.345e-04  Data: 0.007 (0.008)
2024-04-07 06:23:09,329 - train - INFO - Train: 79 [ 300/781 ( 38%)]  Loss:  3.440633 (3.5717)  Time: 0.516s,  248.28/s  (0.539s,  237.69/s)  LR: 2.345e-04  Data: 0.010 (0.008)
2024-04-07 06:23:36,606 - train - INFO - Train: 79 [ 350/781 ( 45%)]  Loss:  3.828851 (3.5808)  Time: 0.497s,  257.33/s  (0.540s,  237.25/s)  LR: 2.345e-04  Data: 0.008 (0.008)
2024-04-07 06:24:04,265 - train - INFO - Train: 79 [ 400/781 ( 51%)]  Loss:  3.923975 (3.5901)  Time: 0.564s,  227.00/s  (0.541s,  236.51/s)  LR: 2.345e-04  Data: 0.009 (0.008)
2024-04-07 06:24:31,067 - train - INFO - Train: 79 [ 450/781 ( 58%)]  Loss:  3.900851 (3.5872)  Time: 0.652s,  196.17/s  (0.541s,  236.76/s)  LR: 2.345e-04  Data: 0.008 (0.008)
2024-04-07 06:24:59,161 - train - INFO - Train: 79 [ 500/781 ( 64%)]  Loss:  3.802968 (3.5856)  Time: 0.585s,  218.68/s  (0.543s,  235.84/s)  LR: 2.345e-04  Data: 0.009 (0.008)
2024-04-07 06:25:25,720 - train - INFO - Train: 79 [ 550/781 ( 71%)]  Loss:  3.328799 (3.5842)  Time: 0.573s,  223.38/s  (0.542s,  236.30/s)  LR: 2.345e-04  Data: 0.008 (0.008)
2024-04-07 06:25:53,012 - train - INFO - Train: 79 [ 600/781 ( 77%)]  Loss:  3.507350 (3.5855)  Time: 0.552s,  231.83/s  (0.542s,  236.15/s)  LR: 2.345e-04  Data: 0.006 (0.008)
2024-04-07 06:26:20,588 - train - INFO - Train: 79 [ 650/781 ( 83%)]  Loss:  3.713488 (3.5879)  Time: 1.072s,  119.35/s  (0.543s,  235.83/s)  LR: 2.345e-04  Data: 0.006 (0.008)
2024-04-07 06:26:46,537 - train - INFO - Train: 79 [ 700/781 ( 90%)]  Loss:  3.160293 (3.5848)  Time: 0.411s,  311.13/s  (0.541s,  236.57/s)  LR: 2.345e-04  Data: 0.006 (0.008)
2024-04-07 06:27:13,561 - train - INFO - Train: 79 [ 750/781 ( 96%)]  Loss:  3.304367 (3.5876)  Time: 0.500s,  255.88/s  (0.541s,  236.59/s)  LR: 2.345e-04  Data: 0.007 (0.008)
2024-04-07 06:27:29,473 - train - INFO - Train: 79 [ 780/781 (100%)]  Loss:  3.728557 (3.5876)  Time: 0.444s,  288.10/s  (0.541s,  236.77/s)  LR: 2.345e-04  Data: 0.000 (0.008)
2024-04-07 06:27:29,473 - train - INFO - True
2024-04-07 06:27:29,475 - train - INFO - alphas:tensor([0.6072, 0.0470, 0.0660, 0.0912, 0.1886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,475 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,475 - train - INFO - True
2024-04-07 06:27:29,476 - train - INFO - alphas:tensor([0.4279, 0.0210, 0.0368, 0.0836, 0.4307], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,476 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,476 - train - INFO - True
2024-04-07 06:27:29,477 - train - INFO - alphas:tensor([0.4630, 0.0338, 0.0792, 0.4240], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,478 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,478 - train - INFO - True
2024-04-07 06:27:29,478 - train - INFO - alphas:tensor([0.4076, 0.0325, 0.0609, 0.4991], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,479 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,479 - train - INFO - True
2024-04-07 06:27:29,480 - train - INFO - alphas:tensor([0.4080, 0.0240, 0.0692, 0.4987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,480 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,480 - train - INFO - True
2024-04-07 06:27:29,481 - train - INFO - alphas:tensor([0.4930, 0.0338, 0.0610, 0.4122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,481 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,481 - train - INFO - True
2024-04-07 06:27:29,482 - train - INFO - alphas:tensor([0.5353, 0.0213, 0.0273, 0.0630, 0.3530], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,483 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,483 - train - INFO - True
2024-04-07 06:27:29,484 - train - INFO - alphas:tensor([0.2314, 0.0119, 0.0105, 0.0590, 0.6872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,484 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,484 - train - INFO - True
2024-04-07 06:27:29,485 - train - INFO - alphas:tensor([0.2400, 0.0093, 0.0119, 0.0473, 0.6916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,486 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,486 - train - INFO - True
2024-04-07 06:27:29,487 - train - INFO - alphas:tensor([0.2394, 0.0069, 0.0101, 0.0516, 0.6920], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,487 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,487 - train - INFO - True
2024-04-07 06:27:29,488 - train - INFO - alphas:tensor([0.2275, 0.0106, 0.0106, 0.0591, 0.6922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,488 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,489 - train - INFO - True
2024-04-07 06:27:29,489 - train - INFO - alphas:tensor([0.5409, 0.0109, 0.0187, 0.0570, 0.3725], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,490 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,490 - train - INFO - True
2024-04-07 06:27:29,491 - train - INFO - alphas:tensor([0.6339, 0.0131, 0.0161, 0.0426, 0.2944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,493 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,494 - train - INFO - True
2024-04-07 06:27:29,494 - train - INFO - alphas:tensor([0.2442, 0.0213, 0.0221, 0.0986, 0.6138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,496 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,496 - train - INFO - True
2024-04-07 06:27:29,496 - train - INFO - alphas:tensor([0.2581, 0.0129, 0.0162, 0.0914, 0.6213], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,498 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,498 - train - INFO - True
2024-04-07 06:27:29,499 - train - INFO - alphas:tensor([0.2764, 0.0105, 0.0158, 0.0816, 0.6157], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,500 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,500 - train - INFO - True
2024-04-07 06:27:29,501 - train - INFO - alphas:tensor([0.2482, 0.0150, 0.0194, 0.0804, 0.6370], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,502 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,502 - train - INFO - True
2024-04-07 06:27:29,503 - train - INFO - alphas:tensor([0.2820, 0.0111, 0.0208, 0.0821, 0.6040], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,504 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,504 - train - INFO - True
2024-04-07 06:27:29,505 - train - INFO - alphas:tensor([0.2331, 0.0234, 0.0275, 0.0977, 0.6183], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,506 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,506 - train - INFO - True
2024-04-07 06:27:29,507 - train - INFO - alphas:tensor([0.5889, 0.0081, 0.0129, 0.0547, 0.3353], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,510 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,510 - train - INFO - True
2024-04-07 06:27:29,510 - train - INFO - alphas:tensor([0.5139, 0.0076, 0.0099, 0.0557, 0.4129], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,516 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,516 - train - INFO - True
2024-04-07 06:27:29,521 - train - INFO - alphas:tensor([0.3915, 0.0068, 0.0159, 0.0720, 0.5138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,524 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,524 - train - INFO - True
2024-04-07 06:27:29,530 - train - INFO - alphas:tensor([0.4081, 0.0070, 0.0100, 0.0664, 0.5084], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,533 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,533 - train - INFO - True
2024-04-07 06:27:29,539 - train - INFO - alphas:tensor([0.4212, 0.0062, 0.0100, 0.0656, 0.4970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,542 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,542 - train - INFO - True
2024-04-07 06:27:29,548 - train - INFO - alphas:tensor([0.3878, 0.0074, 0.0140, 0.0703, 0.5205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,551 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,551 - train - INFO - True
2024-04-07 06:27:29,557 - train - INFO - alphas:tensor([0.5362, 0.0061, 0.0116, 0.0464, 0.3997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,562 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,562 - train - INFO - True
2024-04-07 06:27:29,562 - train - INFO - alphas:tensor([0.6854, 0.0053, 0.0098, 0.0376, 0.2619], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,574 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,574 - train - INFO - True
2024-04-07 06:27:29,575 - train - INFO - alphas:tensor([0.3476, 0.0080, 0.0129, 0.0812, 0.5503], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,581 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,581 - train - INFO - True
2024-04-07 06:27:29,581 - train - INFO - alphas:tensor([0.3589, 0.0052, 0.0108, 0.0715, 0.5535], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,587 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,587 - train - INFO - True
2024-04-07 06:27:29,588 - train - INFO - alphas:tensor([0.3901, 0.0057, 0.0090, 0.0697, 0.5256], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,594 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,594 - train - INFO - True
2024-04-07 06:27:29,595 - train - INFO - alphas:tensor([0.3577, 0.0068, 0.0112, 0.0724, 0.5518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,601 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,601 - train - INFO - True
2024-04-07 06:27:29,602 - train - INFO - alphas:tensor([0.6866, 0.0044, 0.0063, 0.0306, 0.2722], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,614 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,614 - train - INFO - True
2024-04-07 06:27:29,619 - train - INFO - alphas:tensor([0.5198, 0.0146, 0.0200, 0.0728, 0.3728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:27:29,673 - train - INFO - tau:0.4612219674180955
2024-04-07 06:27:29,673 - train - INFO - avg block size:10.06060606060606
2024-04-07 06:27:29,673 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 06:27:29,938 - train - INFO - Test: [   0/78]  Time: 0.262 (0.262)  Loss:  0.9727 (0.9727)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.9688 (92.9688)
2024-04-07 06:27:35,304 - train - INFO - Test: [  50/78]  Time: 0.113 (0.110)  Loss:  1.5889 (1.5722)  Acc@1: 67.1875 (64.9050)  Acc@5: 85.1562 (85.9835)
2024-04-07 06:27:38,232 - train - INFO - Test: [  78/78]  Time: 0.122 (0.108)  Loss:  1.7705 (1.5986)  Acc@1: 50.0000 (64.2300)  Acc@5: 100.0000 (85.4100)
2024-04-07 06:27:39,026 - train - INFO - Train: 80 [   0/781 (  0%)]  Loss:  3.807999 (3.8080)  Time: 0.706s,  181.38/s  (0.706s,  181.38/s)  LR: 2.294e-04  Data: 0.175 (0.175)
2024-04-07 06:28:06,625 - train - INFO - Train: 80 [  50/781 (  6%)]  Loss:  3.675698 (3.6633)  Time: 0.543s,  235.66/s  (0.555s,  230.64/s)  LR: 2.294e-04  Data: 0.009 (0.011)
2024-04-07 06:28:33,352 - train - INFO - Train: 80 [ 100/781 ( 13%)]  Loss:  3.495198 (3.6327)  Time: 0.554s,  231.18/s  (0.545s,  234.93/s)  LR: 2.294e-04  Data: 0.008 (0.009)
2024-04-07 06:28:59,784 - train - INFO - Train: 80 [ 150/781 ( 19%)]  Loss:  3.252946 (3.6237)  Time: 0.570s,  224.59/s  (0.539s,  237.27/s)  LR: 2.294e-04  Data: 0.009 (0.009)
2024-04-07 06:29:27,550 - train - INFO - Train: 80 [ 200/781 ( 26%)]  Loss:  3.360419 (3.6072)  Time: 0.545s,  234.66/s  (0.543s,  235.56/s)  LR: 2.294e-04  Data: 0.010 (0.009)
2024-04-07 06:29:54,390 - train - INFO - Train: 80 [ 250/781 ( 32%)]  Loss:  3.475505 (3.6051)  Time: 0.548s,  233.53/s  (0.542s,  236.13/s)  LR: 2.294e-04  Data: 0.006 (0.008)
2024-04-07 06:30:21,773 - train - INFO - Train: 80 [ 300/781 ( 38%)]  Loss:  3.715804 (3.6083)  Time: 0.376s,  340.30/s  (0.543s,  235.73/s)  LR: 2.294e-04  Data: 0.004 (0.008)
2024-04-07 06:30:49,379 - train - INFO - Train: 80 [ 350/781 ( 45%)]  Loss:  3.627803 (3.6103)  Time: 0.444s,  288.47/s  (0.544s,  235.17/s)  LR: 2.294e-04  Data: 0.006 (0.008)
2024-04-07 06:31:16,737 - train - INFO - Train: 80 [ 400/781 ( 51%)]  Loss:  3.700873 (3.6072)  Time: 0.555s,  230.82/s  (0.545s,  235.01/s)  LR: 2.294e-04  Data: 0.009 (0.008)
2024-04-07 06:31:44,307 - train - INFO - Train: 80 [ 450/781 ( 58%)]  Loss:  4.095072 (3.5998)  Time: 0.566s,  226.35/s  (0.545s,  234.69/s)  LR: 2.294e-04  Data: 0.006 (0.008)
2024-04-07 06:32:12,170 - train - INFO - Train: 80 [ 500/781 ( 64%)]  Loss:  3.552923 (3.5990)  Time: 0.962s,  133.10/s  (0.547s,  234.19/s)  LR: 2.294e-04  Data: 0.009 (0.008)
2024-04-07 06:32:38,983 - train - INFO - Train: 80 [ 550/781 ( 71%)]  Loss:  3.641692 (3.6045)  Time: 0.539s,  237.63/s  (0.546s,  234.59/s)  LR: 2.294e-04  Data: 0.005 (0.008)
2024-04-07 06:33:05,977 - train - INFO - Train: 80 [ 600/781 ( 77%)]  Loss:  3.827971 (3.6085)  Time: 0.559s,  228.98/s  (0.545s,  234.80/s)  LR: 2.294e-04  Data: 0.008 (0.008)
2024-04-07 06:33:32,660 - train - INFO - Train: 80 [ 650/781 ( 83%)]  Loss:  3.420987 (3.6037)  Time: 0.571s,  224.18/s  (0.544s,  235.18/s)  LR: 2.294e-04  Data: 0.008 (0.008)
2024-04-07 06:33:58,655 - train - INFO - Train: 80 [ 700/781 ( 90%)]  Loss:  3.652112 (3.6047)  Time: 0.516s,  248.03/s  (0.543s,  235.93/s)  LR: 2.294e-04  Data: 0.006 (0.008)
2024-04-07 06:34:25,742 - train - INFO - Train: 80 [ 750/781 ( 96%)]  Loss:  3.624253 (3.6047)  Time: 0.498s,  256.97/s  (0.542s,  235.96/s)  LR: 2.294e-04  Data: 0.006 (0.008)
2024-04-07 06:34:42,338 - train - INFO - Train: 80 [ 780/781 (100%)]  Loss:  3.768335 (3.6036)  Time: 0.465s,  275.38/s  (0.543s,  235.78/s)  LR: 2.294e-04  Data: 0.000 (0.008)
2024-04-07 06:34:42,339 - train - INFO - True
2024-04-07 06:34:42,341 - train - INFO - alphas:tensor([0.6111, 0.0460, 0.0651, 0.0898, 0.1880], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,342 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,342 - train - INFO - True
2024-04-07 06:34:42,343 - train - INFO - alphas:tensor([0.4274, 0.0203, 0.0362, 0.0823, 0.4338], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,344 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,344 - train - INFO - True
2024-04-07 06:34:42,345 - train - INFO - alphas:tensor([0.4639, 0.0331, 0.0780, 0.4250], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,346 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,346 - train - INFO - True
2024-04-07 06:34:42,347 - train - INFO - alphas:tensor([0.4098, 0.0317, 0.0593, 0.4992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,348 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,348 - train - INFO - True
2024-04-07 06:34:42,349 - train - INFO - alphas:tensor([0.4067, 0.0232, 0.0680, 0.5021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,350 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,350 - train - INFO - True
2024-04-07 06:34:42,351 - train - INFO - alphas:tensor([0.4921, 0.0332, 0.0602, 0.4145], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,352 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,352 - train - INFO - True
2024-04-07 06:34:42,353 - train - INFO - alphas:tensor([0.5346, 0.0207, 0.0269, 0.0624, 0.3554], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,355 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,355 - train - INFO - True
2024-04-07 06:34:42,356 - train - INFO - alphas:tensor([0.2294, 0.0116, 0.0102, 0.0580, 0.6909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,357 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,357 - train - INFO - True
2024-04-07 06:34:42,358 - train - INFO - alphas:tensor([0.2407, 0.0089, 0.0114, 0.0465, 0.6925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,359 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,359 - train - INFO - True
2024-04-07 06:34:42,360 - train - INFO - alphas:tensor([0.2389, 0.0066, 0.0097, 0.0511, 0.6936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,361 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,361 - train - INFO - True
2024-04-07 06:34:42,362 - train - INFO - alphas:tensor([0.2280, 0.0103, 0.0102, 0.0589, 0.6927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,363 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,363 - train - INFO - True
2024-04-07 06:34:42,364 - train - INFO - alphas:tensor([0.5418, 0.0105, 0.0182, 0.0567, 0.3728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,366 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,366 - train - INFO - True
2024-04-07 06:34:42,367 - train - INFO - alphas:tensor([0.6353, 0.0126, 0.0157, 0.0419, 0.2945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,371 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,371 - train - INFO - True
2024-04-07 06:34:42,372 - train - INFO - alphas:tensor([0.2442, 0.0206, 0.0217, 0.0971, 0.6164], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,375 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,375 - train - INFO - True
2024-04-07 06:34:42,376 - train - INFO - alphas:tensor([0.2588, 0.0127, 0.0159, 0.0897, 0.6229], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,378 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,378 - train - INFO - True
2024-04-07 06:34:42,379 - train - INFO - alphas:tensor([0.2820, 0.0103, 0.0156, 0.0806, 0.6115], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,381 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,381 - train - INFO - True
2024-04-07 06:34:42,382 - train - INFO - alphas:tensor([0.2536, 0.0148, 0.0189, 0.0797, 0.6331], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,384 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,384 - train - INFO - True
2024-04-07 06:34:42,385 - train - INFO - alphas:tensor([0.2780, 0.0106, 0.0197, 0.0806, 0.6111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,388 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,388 - train - INFO - True
2024-04-07 06:34:42,389 - train - INFO - alphas:tensor([0.2349, 0.0230, 0.0271, 0.0948, 0.6202], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,391 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,391 - train - INFO - True
2024-04-07 06:34:42,392 - train - INFO - alphas:tensor([0.5931, 0.0079, 0.0124, 0.0540, 0.3325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,395 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,396 - train - INFO - True
2024-04-07 06:34:42,397 - train - INFO - alphas:tensor([0.5140, 0.0073, 0.0095, 0.0550, 0.4141], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,404 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,404 - train - INFO - True
2024-04-07 06:34:42,405 - train - INFO - alphas:tensor([0.3917, 0.0066, 0.0155, 0.0718, 0.5144], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,409 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,409 - train - INFO - True
2024-04-07 06:34:42,410 - train - INFO - alphas:tensor([0.4071, 0.0068, 0.0097, 0.0665, 0.5098], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,414 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,414 - train - INFO - True
2024-04-07 06:34:42,415 - train - INFO - alphas:tensor([0.4249, 0.0060, 0.0095, 0.0644, 0.4952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,419 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,419 - train - INFO - True
2024-04-07 06:34:42,420 - train - INFO - alphas:tensor([0.3846, 0.0073, 0.0135, 0.0689, 0.5256], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,423 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,423 - train - INFO - True
2024-04-07 06:34:42,424 - train - INFO - alphas:tensor([0.5377, 0.0060, 0.0112, 0.0460, 0.3991], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,431 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,431 - train - INFO - True
2024-04-07 06:34:42,432 - train - INFO - alphas:tensor([0.6861, 0.0051, 0.0095, 0.0368, 0.2625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,449 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,449 - train - INFO - True
2024-04-07 06:34:42,450 - train - INFO - alphas:tensor([0.3487, 0.0079, 0.0126, 0.0797, 0.5511], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,458 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,458 - train - INFO - True
2024-04-07 06:34:42,459 - train - INFO - alphas:tensor([0.3629, 0.0050, 0.0105, 0.0696, 0.5519], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,467 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,467 - train - INFO - True
2024-04-07 06:34:42,468 - train - INFO - alphas:tensor([0.3939, 0.0055, 0.0087, 0.0700, 0.5218], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,476 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,476 - train - INFO - True
2024-04-07 06:34:42,477 - train - INFO - alphas:tensor([0.3553, 0.0067, 0.0109, 0.0716, 0.5556], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,485 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,485 - train - INFO - True
2024-04-07 06:34:42,486 - train - INFO - alphas:tensor([0.6881, 0.0042, 0.0061, 0.0303, 0.2713], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,501 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,501 - train - INFO - True
2024-04-07 06:34:42,502 - train - INFO - alphas:tensor([0.5222, 0.0143, 0.0195, 0.0724, 0.3716], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:34:42,556 - train - INFO - tau:0.45660974774391455
2024-04-07 06:34:42,556 - train - INFO - avg block size:10.06060606060606
2024-04-07 06:34:42,557 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 06:34:42,557 - train - INFO - lasso_alpha:9.330147604194664e-06
2024-04-07 06:34:42,753 - train - INFO - Test: [   0/78]  Time: 0.192 (0.192)  Loss:  0.9707 (0.9707)  Acc@1: 81.2500 (81.2500)  Acc@5: 92.9688 (92.9688)
2024-04-07 06:34:48,721 - train - INFO - Test: [  50/78]  Time: 0.101 (0.121)  Loss:  1.6748 (1.5841)  Acc@1: 62.5000 (64.5987)  Acc@5: 84.3750 (85.8609)
2024-04-07 06:34:51,591 - train - INFO - Test: [  78/78]  Time: 0.096 (0.114)  Loss:  1.6836 (1.6062)  Acc@1: 62.5000 (64.2800)  Acc@5: 93.7500 (85.4500)
2024-04-07 06:34:52,422 - train - INFO - Train: 81 [   0/781 (  0%)]  Loss:  3.526260 (3.5263)  Time: 0.749s,  171.00/s  (0.749s,  171.00/s)  LR: 2.243e-04  Data: 0.171 (0.171)
2024-04-07 06:35:19,180 - train - INFO - Train: 81 [  50/781 (  6%)]  Loss:  3.785320 (3.6190)  Time: 0.456s,  280.46/s  (0.539s,  237.34/s)  LR: 2.243e-04  Data: 0.005 (0.011)
2024-04-07 06:35:46,280 - train - INFO - Train: 81 [ 100/781 ( 13%)]  Loss:  3.948936 (3.6139)  Time: 0.468s,  273.24/s  (0.541s,  236.76/s)  LR: 2.243e-04  Data: 0.007 (0.009)
2024-04-07 06:36:13,693 - train - INFO - Train: 81 [ 150/781 ( 19%)]  Loss:  3.687645 (3.6085)  Time: 0.553s,  231.35/s  (0.543s,  235.67/s)  LR: 2.243e-04  Data: 0.010 (0.009)
2024-04-07 06:36:41,414 - train - INFO - Train: 81 [ 200/781 ( 26%)]  Loss:  3.786374 (3.6121)  Time: 0.578s,  221.47/s  (0.546s,  234.46/s)  LR: 2.243e-04  Data: 0.008 (0.008)
2024-04-07 06:37:07,109 - train - INFO - Train: 81 [ 250/781 ( 32%)]  Loss:  3.763246 (3.6158)  Time: 0.559s,  228.79/s  (0.540s,  237.23/s)  LR: 2.243e-04  Data: 0.007 (0.008)
2024-04-07 06:37:35,089 - train - INFO - Train: 81 [ 300/781 ( 38%)]  Loss:  3.736365 (3.6087)  Time: 0.549s,  233.15/s  (0.543s,  235.78/s)  LR: 2.243e-04  Data: 0.006 (0.008)
2024-04-07 06:38:01,784 - train - INFO - Train: 81 [ 350/781 ( 45%)]  Loss:  3.612549 (3.6106)  Time: 0.467s,  274.18/s  (0.542s,  236.34/s)  LR: 2.243e-04  Data: 0.006 (0.008)
2024-04-07 06:38:29,572 - train - INFO - Train: 81 [ 400/781 ( 51%)]  Loss:  3.459148 (3.6086)  Time: 0.562s,  227.91/s  (0.543s,  235.57/s)  LR: 2.243e-04  Data: 0.007 (0.008)
2024-04-07 06:38:56,417 - train - INFO - Train: 81 [ 450/781 ( 58%)]  Loss:  3.724391 (3.6091)  Time: 0.458s,  279.53/s  (0.543s,  235.89/s)  LR: 2.243e-04  Data: 0.006 (0.008)
2024-04-07 06:39:23,100 - train - INFO - Train: 81 [ 500/781 ( 64%)]  Loss:  3.446727 (3.6051)  Time: 0.562s,  227.74/s  (0.542s,  236.28/s)  LR: 2.243e-04  Data: 0.008 (0.008)
2024-04-07 06:39:48,396 - train - INFO - Train: 81 [ 550/781 ( 71%)]  Loss:  3.625706 (3.5988)  Time: 0.471s,  271.78/s  (0.538s,  237.70/s)  LR: 2.243e-04  Data: 0.007 (0.008)
2024-04-07 06:40:14,766 - train - INFO - Train: 81 [ 600/781 ( 77%)]  Loss:  3.925477 (3.5988)  Time: 0.478s,  267.93/s  (0.538s,  238.11/s)  LR: 2.243e-04  Data: 0.008 (0.008)
2024-04-07 06:40:41,727 - train - INFO - Train: 81 [ 650/781 ( 83%)]  Loss:  3.522848 (3.5969)  Time: 0.455s,  281.39/s  (0.538s,  238.06/s)  LR: 2.243e-04  Data: 0.008 (0.008)
2024-04-07 06:41:07,539 - train - INFO - Train: 81 [ 700/781 ( 90%)]  Loss:  3.541053 (3.5973)  Time: 0.454s,  282.24/s  (0.536s,  238.74/s)  LR: 2.243e-04  Data: 0.006 (0.008)
2024-04-07 06:41:34,575 - train - INFO - Train: 81 [ 750/781 ( 96%)]  Loss:  3.417581 (3.5976)  Time: 0.563s,  227.28/s  (0.536s,  238.60/s)  LR: 2.243e-04  Data: 0.007 (0.008)
2024-04-07 06:41:51,147 - train - INFO - Train: 81 [ 780/781 (100%)]  Loss:  3.866532 (3.5976)  Time: 0.530s,  241.50/s  (0.537s,  238.33/s)  LR: 2.243e-04  Data: 0.000 (0.008)
2024-04-07 06:41:51,148 - train - INFO - True
2024-04-07 06:41:51,156 - train - INFO - alphas:tensor([0.6123, 0.0453, 0.0646, 0.0893, 0.1886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,156 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,157 - train - INFO - True
2024-04-07 06:41:51,165 - train - INFO - alphas:tensor([0.4291, 0.0197, 0.0355, 0.0812, 0.4345], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,166 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,166 - train - INFO - True
2024-04-07 06:41:51,167 - train - INFO - alphas:tensor([0.4644, 0.0323, 0.0767, 0.4267], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,168 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,168 - train - INFO - True
2024-04-07 06:41:51,169 - train - INFO - alphas:tensor([0.4091, 0.0313, 0.0592, 0.5004], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,169 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,170 - train - INFO - True
2024-04-07 06:41:51,170 - train - INFO - alphas:tensor([0.4138, 0.0227, 0.0678, 0.4957], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,171 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,171 - train - INFO - True
2024-04-07 06:41:51,172 - train - INFO - alphas:tensor([0.4937, 0.0324, 0.0590, 0.4150], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,173 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,173 - train - INFO - True
2024-04-07 06:41:51,174 - train - INFO - alphas:tensor([0.5369, 0.0203, 0.0264, 0.0618, 0.3547], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,175 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,175 - train - INFO - True
2024-04-07 06:41:51,176 - train - INFO - alphas:tensor([0.2312, 0.0113, 0.0101, 0.0580, 0.6895], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,176 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,177 - train - INFO - True
2024-04-07 06:41:51,178 - train - INFO - alphas:tensor([0.2418, 0.0087, 0.0110, 0.0457, 0.6929], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,178 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,178 - train - INFO - True
2024-04-07 06:41:51,179 - train - INFO - alphas:tensor([0.2414, 0.0065, 0.0096, 0.0509, 0.6916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,180 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,180 - train - INFO - True
2024-04-07 06:41:51,181 - train - INFO - alphas:tensor([0.2266, 0.0100, 0.0100, 0.0583, 0.6950], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,182 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,182 - train - INFO - True
2024-04-07 06:41:51,183 - train - INFO - alphas:tensor([0.5421, 0.0101, 0.0177, 0.0555, 0.3746], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,184 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,184 - train - INFO - True
2024-04-07 06:41:51,185 - train - INFO - alphas:tensor([0.6362, 0.0123, 0.0153, 0.0414, 0.2948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,188 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,188 - train - INFO - True
2024-04-07 06:41:51,189 - train - INFO - alphas:tensor([0.2466, 0.0201, 0.0215, 0.0945, 0.6173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,191 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,191 - train - INFO - True
2024-04-07 06:41:51,192 - train - INFO - alphas:tensor([0.2615, 0.0123, 0.0154, 0.0891, 0.6216], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,194 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,194 - train - INFO - True
2024-04-07 06:41:51,195 - train - INFO - alphas:tensor([0.2866, 0.0099, 0.0153, 0.0796, 0.6085], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,197 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,197 - train - INFO - True
2024-04-07 06:41:51,198 - train - INFO - alphas:tensor([0.2556, 0.0145, 0.0183, 0.0794, 0.6321], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,200 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,200 - train - INFO - True
2024-04-07 06:41:51,201 - train - INFO - alphas:tensor([0.2816, 0.0103, 0.0195, 0.0797, 0.6089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,203 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,203 - train - INFO - True
2024-04-07 06:41:51,204 - train - INFO - alphas:tensor([0.2390, 0.0226, 0.0270, 0.0950, 0.6165], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,206 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,206 - train - INFO - True
2024-04-07 06:41:51,207 - train - INFO - alphas:tensor([0.5900, 0.0076, 0.0122, 0.0545, 0.3357], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,210 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,210 - train - INFO - True
2024-04-07 06:41:51,218 - train - INFO - alphas:tensor([0.5148, 0.0071, 0.0093, 0.0547, 0.4141], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,225 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,225 - train - INFO - True
2024-04-07 06:41:51,232 - train - INFO - alphas:tensor([0.3921, 0.0063, 0.0154, 0.0722, 0.5140], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,236 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,236 - train - INFO - True
2024-04-07 06:41:51,244 - train - INFO - alphas:tensor([0.4090, 0.0067, 0.0095, 0.0655, 0.5092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,248 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,248 - train - INFO - True
2024-04-07 06:41:51,256 - train - INFO - alphas:tensor([0.4296, 0.0059, 0.0092, 0.0638, 0.4915], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,260 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,260 - train - INFO - True
2024-04-07 06:41:51,261 - train - INFO - alphas:tensor([0.3866, 0.0071, 0.0132, 0.0694, 0.5237], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,265 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,265 - train - INFO - True
2024-04-07 06:41:51,266 - train - INFO - alphas:tensor([0.5391, 0.0057, 0.0109, 0.0459, 0.3983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,273 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,274 - train - INFO - True
2024-04-07 06:41:51,275 - train - INFO - alphas:tensor([0.6890, 0.0049, 0.0092, 0.0362, 0.2607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,294 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,294 - train - INFO - True
2024-04-07 06:41:51,295 - train - INFO - alphas:tensor([0.3521, 0.0076, 0.0124, 0.0798, 0.5481], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,305 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,305 - train - INFO - True
2024-04-07 06:41:51,314 - train - INFO - alphas:tensor([0.3638, 0.0048, 0.0102, 0.0697, 0.5514], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,324 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,324 - train - INFO - True
2024-04-07 06:41:51,331 - train - INFO - alphas:tensor([0.4000, 0.0053, 0.0084, 0.0679, 0.5184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,341 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,341 - train - INFO - True
2024-04-07 06:41:51,346 - train - INFO - alphas:tensor([0.3592, 0.0064, 0.0108, 0.0712, 0.5524], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,356 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,356 - train - INFO - True
2024-04-07 06:41:51,357 - train - INFO - alphas:tensor([0.6899, 0.0040, 0.0059, 0.0297, 0.2705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,375 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,375 - train - INFO - True
2024-04-07 06:41:51,376 - train - INFO - alphas:tensor([0.5275, 0.0141, 0.0192, 0.0712, 0.3680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:41:51,438 - train - INFO - tau:0.4520436502664754
2024-04-07 06:41:51,438 - train - INFO - avg block size:10.06060606060606
2024-04-07 06:41:51,439 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 06:41:51,683 - train - INFO - Test: [   0/78]  Time: 0.240 (0.240)  Loss:  1.1436 (1.1436)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.1875 (92.1875)
2024-04-07 06:41:56,889 - train - INFO - Test: [  50/78]  Time: 0.051 (0.107)  Loss:  1.6914 (1.5802)  Acc@1: 61.7188 (64.4148)  Acc@5: 81.2500 (85.5392)
2024-04-07 06:42:00,256 - train - INFO - Test: [  78/78]  Time: 0.096 (0.112)  Loss:  1.8359 (1.5975)  Acc@1: 62.5000 (64.4000)  Acc@5: 93.7500 (85.2600)
2024-04-07 06:42:01,095 - train - INFO - Train: 82 [   0/781 (  0%)]  Loss:  3.463834 (3.4638)  Time: 0.753s,  169.89/s  (0.753s,  169.89/s)  LR: 2.192e-04  Data: 0.172 (0.172)
2024-04-07 06:42:27,532 - train - INFO - Train: 82 [  50/781 (  6%)]  Loss:  3.683708 (3.6793)  Time: 0.576s,  222.16/s  (0.533s,  240.10/s)  LR: 2.192e-04  Data: 0.005 (0.011)
2024-04-07 06:42:54,853 - train - INFO - Train: 82 [ 100/781 ( 13%)]  Loss:  3.032659 (3.5966)  Time: 0.457s,  279.99/s  (0.540s,  237.18/s)  LR: 2.192e-04  Data: 0.007 (0.009)
2024-04-07 06:43:21,634 - train - INFO - Train: 82 [ 150/781 ( 19%)]  Loss:  3.623009 (3.6067)  Time: 0.473s,  270.55/s  (0.538s,  237.77/s)  LR: 2.192e-04  Data: 0.006 (0.009)
2024-04-07 06:43:47,722 - train - INFO - Train: 82 [ 200/781 ( 26%)]  Loss:  3.367403 (3.6014)  Time: 0.575s,  222.57/s  (0.534s,  239.61/s)  LR: 2.192e-04  Data: 0.009 (0.008)
2024-04-07 06:44:15,508 - train - INFO - Train: 82 [ 250/781 ( 32%)]  Loss:  3.547538 (3.5946)  Time: 0.524s,  244.38/s  (0.538s,  237.71/s)  LR: 2.192e-04  Data: 0.007 (0.008)
2024-04-07 06:44:42,389 - train - INFO - Train: 82 [ 300/781 ( 38%)]  Loss:  4.002642 (3.5869)  Time: 0.589s,  217.18/s  (0.538s,  237.77/s)  LR: 2.192e-04  Data: 0.009 (0.008)
2024-04-07 06:45:09,349 - train - INFO - Train: 82 [ 350/781 ( 45%)]  Loss:  3.820543 (3.5867)  Time: 0.538s,  238.14/s  (0.538s,  237.72/s)  LR: 2.192e-04  Data: 0.007 (0.008)
2024-04-07 06:45:35,363 - train - INFO - Train: 82 [ 400/781 ( 51%)]  Loss:  3.894089 (3.5860)  Time: 0.482s,  265.59/s  (0.536s,  238.73/s)  LR: 2.192e-04  Data: 0.009 (0.008)
2024-04-07 06:46:02,738 - train - INFO - Train: 82 [ 450/781 ( 58%)]  Loss:  3.881513 (3.5843)  Time: 0.570s,  224.47/s  (0.537s,  238.17/s)  LR: 2.192e-04  Data: 0.008 (0.008)
2024-04-07 06:46:30,481 - train - INFO - Train: 82 [ 500/781 ( 64%)]  Loss:  3.799784 (3.5865)  Time: 0.475s,  269.30/s  (0.539s,  237.40/s)  LR: 2.192e-04  Data: 0.009 (0.008)
2024-04-07 06:46:58,074 - train - INFO - Train: 82 [ 550/781 ( 71%)]  Loss:  3.362175 (3.5803)  Time: 0.534s,  239.87/s  (0.540s,  236.90/s)  LR: 2.192e-04  Data: 0.008 (0.008)
2024-04-07 06:47:24,221 - train - INFO - Train: 82 [ 600/781 ( 77%)]  Loss:  3.586667 (3.5789)  Time: 0.567s,  225.70/s  (0.539s,  237.54/s)  LR: 2.192e-04  Data: 0.008 (0.008)
2024-04-07 06:47:51,838 - train - INFO - Train: 82 [ 650/781 ( 83%)]  Loss:  3.710428 (3.5814)  Time: 0.515s,  248.77/s  (0.540s,  237.08/s)  LR: 2.192e-04  Data: 0.007 (0.008)
2024-04-07 06:48:18,702 - train - INFO - Train: 82 [ 700/781 ( 90%)]  Loss:  3.773564 (3.5828)  Time: 0.563s,  227.34/s  (0.540s,  237.16/s)  LR: 2.192e-04  Data: 0.007 (0.008)
2024-04-07 06:48:46,232 - train - INFO - Train: 82 [ 750/781 ( 96%)]  Loss:  3.874105 (3.5847)  Time: 0.546s,  234.29/s  (0.540s,  236.85/s)  LR: 2.192e-04  Data: 0.010 (0.008)
2024-04-07 06:49:01,776 - train - INFO - Train: 82 [ 780/781 (100%)]  Loss:  3.857245 (3.5864)  Time: 0.580s,  220.53/s  (0.540s,  237.22/s)  LR: 2.192e-04  Data: 0.000 (0.008)
2024-04-07 06:49:01,778 - train - INFO - True
2024-04-07 06:49:01,780 - train - INFO - alphas:tensor([0.6155, 0.0445, 0.0636, 0.0881, 0.1883], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,781 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,781 - train - INFO - True
2024-04-07 06:49:01,783 - train - INFO - alphas:tensor([0.4316, 0.0193, 0.0348, 0.0806, 0.4336], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,784 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,784 - train - INFO - True
2024-04-07 06:49:01,785 - train - INFO - alphas:tensor([0.4659, 0.0316, 0.0766, 0.4260], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,787 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,787 - train - INFO - True
2024-04-07 06:49:01,789 - train - INFO - alphas:tensor([0.4099, 0.0307, 0.0582, 0.5013], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,789 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,790 - train - INFO - True
2024-04-07 06:49:01,791 - train - INFO - alphas:tensor([0.4130, 0.0222, 0.0671, 0.4977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,792 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,792 - train - INFO - True
2024-04-07 06:49:01,793 - train - INFO - alphas:tensor([0.4954, 0.0319, 0.0578, 0.4148], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,795 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,795 - train - INFO - True
2024-04-07 06:49:01,796 - train - INFO - alphas:tensor([0.5389, 0.0196, 0.0258, 0.0608, 0.3549], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,798 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,798 - train - INFO - True
2024-04-07 06:49:01,800 - train - INFO - alphas:tensor([0.2337, 0.0111, 0.0098, 0.0574, 0.6880], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,801 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,801 - train - INFO - True
2024-04-07 06:49:01,802 - train - INFO - alphas:tensor([0.2418, 0.0084, 0.0108, 0.0458, 0.6933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,803 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,804 - train - INFO - True
2024-04-07 06:49:01,805 - train - INFO - alphas:tensor([0.2453, 0.0063, 0.0095, 0.0513, 0.6876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,806 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,806 - train - INFO - True
2024-04-07 06:49:01,808 - train - INFO - alphas:tensor([0.2308, 0.0097, 0.0097, 0.0573, 0.6925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,809 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,809 - train - INFO - True
2024-04-07 06:49:01,810 - train - INFO - alphas:tensor([0.5467, 0.0098, 0.0173, 0.0539, 0.3723], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,812 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,812 - train - INFO - True
2024-04-07 06:49:01,813 - train - INFO - alphas:tensor([0.6400, 0.0118, 0.0148, 0.0405, 0.2930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,818 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,819 - train - INFO - True
2024-04-07 06:49:01,820 - train - INFO - alphas:tensor([0.2443, 0.0199, 0.0209, 0.0939, 0.6211], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,823 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,823 - train - INFO - True
2024-04-07 06:49:01,831 - train - INFO - alphas:tensor([0.2623, 0.0121, 0.0150, 0.0889, 0.6216], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,834 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,834 - train - INFO - True
2024-04-07 06:49:01,841 - train - INFO - alphas:tensor([0.2864, 0.0096, 0.0148, 0.0787, 0.6106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,843 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,843 - train - INFO - True
2024-04-07 06:49:01,852 - train - INFO - alphas:tensor([0.2572, 0.0143, 0.0180, 0.0785, 0.6320], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,854 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,855 - train - INFO - True
2024-04-07 06:49:01,862 - train - INFO - alphas:tensor([0.2839, 0.0100, 0.0190, 0.0793, 0.6078], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,864 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,864 - train - INFO - True
2024-04-07 06:49:01,869 - train - INFO - alphas:tensor([0.2409, 0.0217, 0.0260, 0.0928, 0.6186], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,871 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,871 - train - INFO - True
2024-04-07 06:49:01,872 - train - INFO - alphas:tensor([0.5924, 0.0073, 0.0120, 0.0534, 0.3349], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,875 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,876 - train - INFO - True
2024-04-07 06:49:01,877 - train - INFO - alphas:tensor([0.5173, 0.0069, 0.0090, 0.0539, 0.4130], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,884 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,884 - train - INFO - True
2024-04-07 06:49:01,885 - train - INFO - alphas:tensor([0.3944, 0.0061, 0.0150, 0.0714, 0.5130], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,889 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,889 - train - INFO - True
2024-04-07 06:49:01,890 - train - INFO - alphas:tensor([0.4108, 0.0064, 0.0092, 0.0654, 0.5082], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,894 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,894 - train - INFO - True
2024-04-07 06:49:01,895 - train - INFO - alphas:tensor([0.4291, 0.0056, 0.0090, 0.0632, 0.4931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,899 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,899 - train - INFO - True
2024-04-07 06:49:01,900 - train - INFO - alphas:tensor([0.3878, 0.0069, 0.0130, 0.0693, 0.5230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,904 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,904 - train - INFO - True
2024-04-07 06:49:01,905 - train - INFO - alphas:tensor([0.5387, 0.0055, 0.0106, 0.0459, 0.3992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,912 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,912 - train - INFO - True
2024-04-07 06:49:01,917 - train - INFO - alphas:tensor([0.6915, 0.0047, 0.0090, 0.0356, 0.2592], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,936 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,936 - train - INFO - True
2024-04-07 06:49:01,944 - train - INFO - alphas:tensor([0.3570, 0.0074, 0.0122, 0.0780, 0.5454], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,954 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,954 - train - INFO - True
2024-04-07 06:49:01,956 - train - INFO - alphas:tensor([0.3650, 0.0047, 0.0101, 0.0692, 0.5511], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,966 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,966 - train - INFO - True
2024-04-07 06:49:01,967 - train - INFO - alphas:tensor([0.4016, 0.0051, 0.0083, 0.0677, 0.5173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,977 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,977 - train - INFO - True
2024-04-07 06:49:01,978 - train - INFO - alphas:tensor([0.3621, 0.0061, 0.0104, 0.0702, 0.5512], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:01,988 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:01,988 - train - INFO - True
2024-04-07 06:49:01,989 - train - INFO - alphas:tensor([0.6915, 0.0039, 0.0057, 0.0292, 0.2698], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:02,009 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:02,009 - train - INFO - True
2024-04-07 06:49:02,017 - train - INFO - alphas:tensor([0.5254, 0.0139, 0.0191, 0.0711, 0.3705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:49:02,095 - train - INFO - tau:0.44752321376381066
2024-04-07 06:49:02,095 - train - INFO - avg block size:10.06060606060606
2024-04-07 06:49:02,095 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 06:49:02,095 - train - INFO - lasso_alpha:8.481952367449694e-06
2024-04-07 06:49:02,393 - train - INFO - Test: [   0/78]  Time: 0.294 (0.294)  Loss:  1.0186 (1.0186)  Acc@1: 80.4688 (80.4688)  Acc@5: 92.9688 (92.9688)
2024-04-07 06:49:07,900 - train - INFO - Test: [  50/78]  Time: 0.101 (0.114)  Loss:  1.6836 (1.5796)  Acc@1: 59.3750 (64.9203)  Acc@5: 85.1562 (86.0907)
2024-04-07 06:49:10,748 - train - INFO - Test: [  78/78]  Time: 0.101 (0.109)  Loss:  1.6699 (1.5999)  Acc@1: 62.5000 (64.7900)  Acc@5: 93.7500 (85.6400)
2024-04-07 06:49:11,481 - train - INFO - Train: 83 [   0/781 (  0%)]  Loss:  3.264842 (3.2648)  Time: 0.653s,  196.15/s  (0.653s,  196.15/s)  LR: 2.141e-04  Data: 0.199 (0.199)
2024-04-07 06:49:39,065 - train - INFO - Train: 83 [  50/781 (  6%)]  Loss:  3.910632 (3.5440)  Time: 0.566s,  226.02/s  (0.554s,  231.20/s)  LR: 2.141e-04  Data: 0.009 (0.012)
2024-04-07 06:50:05,526 - train - INFO - Train: 83 [ 100/781 ( 13%)]  Loss:  3.962507 (3.5598)  Time: 0.484s,  264.60/s  (0.542s,  236.36/s)  LR: 2.141e-04  Data: 0.005 (0.010)
2024-04-07 06:50:32,440 - train - INFO - Train: 83 [ 150/781 ( 19%)]  Loss:  3.755384 (3.5752)  Time: 0.525s,  243.80/s  (0.540s,  236.84/s)  LR: 2.141e-04  Data: 0.005 (0.009)
2024-04-07 06:50:59,447 - train - INFO - Train: 83 [ 200/781 ( 26%)]  Loss:  3.365757 (3.5560)  Time: 0.583s,  219.72/s  (0.540s,  236.88/s)  LR: 2.141e-04  Data: 0.009 (0.009)
2024-04-07 06:51:27,248 - train - INFO - Train: 83 [ 250/781 ( 32%)]  Loss:  3.763130 (3.5672)  Time: 1.070s,  119.61/s  (0.543s,  235.52/s)  LR: 2.141e-04  Data: 0.009 (0.009)
2024-04-07 06:51:54,395 - train - INFO - Train: 83 [ 300/781 ( 38%)]  Loss:  3.694724 (3.5700)  Time: 0.583s,  219.47/s  (0.543s,  235.56/s)  LR: 2.141e-04  Data: 0.009 (0.008)
2024-04-07 06:52:21,808 - train - INFO - Train: 83 [ 350/781 ( 45%)]  Loss:  3.662097 (3.5705)  Time: 0.524s,  244.19/s  (0.544s,  235.26/s)  LR: 2.141e-04  Data: 0.008 (0.008)
2024-04-07 06:52:48,864 - train - INFO - Train: 83 [ 400/781 ( 51%)]  Loss:  3.286360 (3.5696)  Time: 0.547s,  234.07/s  (0.544s,  235.43/s)  LR: 2.141e-04  Data: 0.009 (0.008)
2024-04-07 06:53:16,624 - train - INFO - Train: 83 [ 450/781 ( 58%)]  Loss:  3.511240 (3.5683)  Time: 0.543s,  235.54/s  (0.545s,  234.88/s)  LR: 2.141e-04  Data: 0.009 (0.008)
2024-04-07 06:53:42,718 - train - INFO - Train: 83 [ 500/781 ( 64%)]  Loss:  3.627629 (3.5679)  Time: 0.450s,  284.44/s  (0.543s,  235.88/s)  LR: 2.141e-04  Data: 0.008 (0.008)
2024-04-07 06:54:08,339 - train - INFO - Train: 83 [ 550/781 ( 71%)]  Loss:  3.710876 (3.5666)  Time: 0.535s,  239.04/s  (0.540s,  237.07/s)  LR: 2.141e-04  Data: 0.007 (0.008)
2024-04-07 06:54:35,213 - train - INFO - Train: 83 [ 600/781 ( 77%)]  Loss:  3.426328 (3.5696)  Time: 0.572s,  223.88/s  (0.540s,  237.17/s)  LR: 2.141e-04  Data: 0.009 (0.008)
2024-04-07 06:55:01,625 - train - INFO - Train: 83 [ 650/781 ( 83%)]  Loss:  4.008283 (3.5708)  Time: 0.455s,  281.04/s  (0.539s,  237.55/s)  LR: 2.141e-04  Data: 0.006 (0.008)
2024-04-07 06:55:28,308 - train - INFO - Train: 83 [ 700/781 ( 90%)]  Loss:  3.082114 (3.5751)  Time: 0.564s,  226.99/s  (0.538s,  237.72/s)  LR: 2.141e-04  Data: 0.007 (0.008)
2024-04-07 06:55:55,084 - train - INFO - Train: 83 [ 750/781 ( 96%)]  Loss:  3.600515 (3.5766)  Time: 0.393s,  325.57/s  (0.538s,  237.80/s)  LR: 2.141e-04  Data: 0.007 (0.008)
2024-04-07 06:56:11,417 - train - INFO - Train: 83 [ 780/781 (100%)]  Loss:  3.528266 (3.5766)  Time: 0.521s,  245.54/s  (0.538s,  237.70/s)  LR: 2.141e-04  Data: 0.000 (0.008)
2024-04-07 06:56:11,418 - train - INFO - True
2024-04-07 06:56:11,420 - train - INFO - alphas:tensor([0.6187, 0.0438, 0.0626, 0.0870, 0.1879], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,421 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,421 - train - INFO - True
2024-04-07 06:56:11,423 - train - INFO - alphas:tensor([0.4333, 0.0189, 0.0339, 0.0791, 0.4348], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,423 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,424 - train - INFO - True
2024-04-07 06:56:11,425 - train - INFO - alphas:tensor([0.4676, 0.0310, 0.0752, 0.4262], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,426 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,426 - train - INFO - True
2024-04-07 06:56:11,428 - train - INFO - alphas:tensor([0.4118, 0.0299, 0.0571, 0.5012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,428 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,428 - train - INFO - True
2024-04-07 06:56:11,430 - train - INFO - alphas:tensor([0.4156, 0.0218, 0.0663, 0.4964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,431 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,431 - train - INFO - True
2024-04-07 06:56:11,432 - train - INFO - alphas:tensor([0.4996, 0.0312, 0.0566, 0.4125], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,433 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,433 - train - INFO - True
2024-04-07 06:56:11,434 - train - INFO - alphas:tensor([0.5407, 0.0191, 0.0252, 0.0596, 0.3554], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,436 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,436 - train - INFO - True
2024-04-07 06:56:11,437 - train - INFO - alphas:tensor([0.2349, 0.0107, 0.0094, 0.0567, 0.6884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,438 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,439 - train - INFO - True
2024-04-07 06:56:11,440 - train - INFO - alphas:tensor([0.2438, 0.0082, 0.0105, 0.0450, 0.6926], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,441 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,441 - train - INFO - True
2024-04-07 06:56:11,442 - train - INFO - alphas:tensor([0.2444, 0.0061, 0.0093, 0.0508, 0.6894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,443 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,443 - train - INFO - True
2024-04-07 06:56:11,444 - train - INFO - alphas:tensor([0.2323, 0.0094, 0.0095, 0.0569, 0.6919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,445 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,445 - train - INFO - True
2024-04-07 06:56:11,447 - train - INFO - alphas:tensor([0.5467, 0.0095, 0.0167, 0.0535, 0.3736], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,448 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,448 - train - INFO - True
2024-04-07 06:56:11,450 - train - INFO - alphas:tensor([0.6437, 0.0114, 0.0143, 0.0393, 0.2913], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,454 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,454 - train - INFO - True
2024-04-07 06:56:11,455 - train - INFO - alphas:tensor([0.2494, 0.0196, 0.0202, 0.0926, 0.6183], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,458 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,458 - train - INFO - True
2024-04-07 06:56:11,459 - train - INFO - alphas:tensor([0.2682, 0.0118, 0.0148, 0.0882, 0.6170], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,461 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,462 - train - INFO - True
2024-04-07 06:56:11,463 - train - INFO - alphas:tensor([0.2875, 0.0092, 0.0143, 0.0783, 0.6106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,465 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,465 - train - INFO - True
2024-04-07 06:56:11,466 - train - INFO - alphas:tensor([0.2598, 0.0139, 0.0176, 0.0774, 0.6313], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,469 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,469 - train - INFO - True
2024-04-07 06:56:11,470 - train - INFO - alphas:tensor([0.2910, 0.0097, 0.0185, 0.0782, 0.6026], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,472 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,472 - train - INFO - True
2024-04-07 06:56:11,473 - train - INFO - alphas:tensor([0.2453, 0.0214, 0.0256, 0.0921, 0.6156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,475 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,476 - train - INFO - True
2024-04-07 06:56:11,477 - train - INFO - alphas:tensor([0.5937, 0.0070, 0.0117, 0.0526, 0.3351], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,481 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,481 - train - INFO - True
2024-04-07 06:56:11,482 - train - INFO - alphas:tensor([0.5227, 0.0067, 0.0087, 0.0530, 0.4089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,490 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,490 - train - INFO - True
2024-04-07 06:56:11,491 - train - INFO - alphas:tensor([0.4004, 0.0059, 0.0145, 0.0701, 0.5091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,495 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,495 - train - INFO - True
2024-04-07 06:56:11,496 - train - INFO - alphas:tensor([0.4167, 0.0062, 0.0091, 0.0646, 0.5035], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,500 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,500 - train - INFO - True
2024-04-07 06:56:11,501 - train - INFO - alphas:tensor([0.4255, 0.0054, 0.0086, 0.0627, 0.4978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,505 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,505 - train - INFO - True
2024-04-07 06:56:11,506 - train - INFO - alphas:tensor([0.3959, 0.0068, 0.0127, 0.0694, 0.5152], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,510 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,510 - train - INFO - True
2024-04-07 06:56:11,511 - train - INFO - alphas:tensor([0.5430, 0.0053, 0.0104, 0.0448, 0.3965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,518 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,519 - train - INFO - True
2024-04-07 06:56:11,519 - train - INFO - alphas:tensor([0.6933, 0.0045, 0.0086, 0.0350, 0.2586], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,539 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,539 - train - INFO - True
2024-04-07 06:56:11,540 - train - INFO - alphas:tensor([0.3577, 0.0071, 0.0118, 0.0785, 0.5450], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,550 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,550 - train - INFO - True
2024-04-07 06:56:11,551 - train - INFO - alphas:tensor([0.3679, 0.0045, 0.0098, 0.0688, 0.5490], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,561 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,561 - train - INFO - True
2024-04-07 06:56:11,562 - train - INFO - alphas:tensor([0.4045, 0.0049, 0.0080, 0.0664, 0.5162], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,573 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,573 - train - INFO - True
2024-04-07 06:56:11,574 - train - INFO - alphas:tensor([0.3649, 0.0059, 0.0100, 0.0698, 0.5495], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,584 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,584 - train - INFO - True
2024-04-07 06:56:11,585 - train - INFO - alphas:tensor([0.6948, 0.0037, 0.0055, 0.0287, 0.2672], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,604 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,605 - train - INFO - True
2024-04-07 06:56:11,606 - train - INFO - alphas:tensor([0.5305, 0.0136, 0.0186, 0.0700, 0.3672], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:11,684 - train - INFO - tau:0.44304798162617254
2024-04-07 06:56:11,684 - train - INFO - avg block size:10.06060606060606
2024-04-07 06:56:11,684 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 06:56:11,899 - train - INFO - Test: [   0/78]  Time: 0.211 (0.211)  Loss:  1.0225 (1.0225)  Acc@1: 79.6875 (79.6875)  Acc@5: 93.7500 (93.7500)
2024-04-07 06:56:18,232 - train - INFO - Test: [  50/78]  Time: 0.089 (0.128)  Loss:  1.5352 (1.5896)  Acc@1: 66.4062 (64.6140)  Acc@5: 89.0625 (85.8609)
2024-04-07 06:56:21,102 - train - INFO - Test: [  78/78]  Time: 0.117 (0.119)  Loss:  1.9434 (1.6067)  Acc@1: 75.0000 (64.2200)  Acc@5: 93.7500 (85.5300)
2024-04-07 06:56:21,924 - train - INFO - Train: 84 [   0/781 (  0%)]  Loss:  3.517165 (3.5172)  Time: 0.735s,  174.07/s  (0.735s,  174.07/s)  LR: 2.091e-04  Data: 0.158 (0.158)
2024-04-07 06:56:47,917 - train - INFO - Train: 84 [  50/781 (  6%)]  Loss:  3.707513 (3.6089)  Time: 0.538s,  237.70/s  (0.524s,  244.24/s)  LR: 2.091e-04  Data: 0.008 (0.010)
2024-04-07 06:57:15,485 - train - INFO - Train: 84 [ 100/781 ( 13%)]  Loss:  3.324336 (3.5874)  Time: 0.574s,  223.01/s  (0.538s,  238.11/s)  LR: 2.091e-04  Data: 0.009 (0.009)
2024-04-07 06:57:42,502 - train - INFO - Train: 84 [ 150/781 ( 19%)]  Loss:  3.642272 (3.5989)  Time: 0.524s,  244.10/s  (0.538s,  237.71/s)  LR: 2.091e-04  Data: 0.007 (0.009)
2024-04-07 06:58:08,504 - train - INFO - Train: 84 [ 200/781 ( 26%)]  Loss:  3.679918 (3.5950)  Time: 0.585s,  218.76/s  (0.534s,  239.76/s)  LR: 2.091e-04  Data: 0.008 (0.008)
2024-04-07 06:58:35,389 - train - INFO - Train: 84 [ 250/781 ( 32%)]  Loss:  3.377374 (3.5873)  Time: 0.558s,  229.44/s  (0.535s,  239.42/s)  LR: 2.091e-04  Data: 0.007 (0.008)
2024-04-07 06:59:02,906 - train - INFO - Train: 84 [ 300/781 ( 38%)]  Loss:  3.357362 (3.5834)  Time: 0.493s,  259.43/s  (0.537s,  238.26/s)  LR: 2.091e-04  Data: 0.009 (0.008)
2024-04-07 06:59:30,005 - train - INFO - Train: 84 [ 350/781 ( 45%)]  Loss:  3.584594 (3.5852)  Time: 0.550s,  232.59/s  (0.538s,  237.96/s)  LR: 2.091e-04  Data: 0.008 (0.008)
2024-04-07 06:59:55,847 - train - INFO - Train: 84 [ 400/781 ( 51%)]  Loss:  3.156156 (3.5825)  Time: 0.579s,  221.03/s  (0.535s,  239.13/s)  LR: 2.091e-04  Data: 0.009 (0.008)
2024-04-07 07:00:23,333 - train - INFO - Train: 84 [ 450/781 ( 58%)]  Loss:  3.822909 (3.5788)  Time: 0.547s,  234.19/s  (0.537s,  238.42/s)  LR: 2.091e-04  Data: 0.009 (0.008)
2024-04-07 07:00:51,143 - train - INFO - Train: 84 [ 500/781 ( 64%)]  Loss:  3.383879 (3.5743)  Time: 0.586s,  218.47/s  (0.539s,  237.56/s)  LR: 2.091e-04  Data: 0.009 (0.008)
2024-04-07 07:01:18,053 - train - INFO - Train: 84 [ 550/781 ( 71%)]  Loss:  3.546140 (3.5725)  Time: 0.562s,  227.61/s  (0.539s,  237.59/s)  LR: 2.091e-04  Data: 0.010 (0.008)
2024-04-07 07:01:44,264 - train - INFO - Train: 84 [ 600/781 ( 77%)]  Loss:  3.790053 (3.5719)  Time: 0.551s,  232.29/s  (0.538s,  238.13/s)  LR: 2.091e-04  Data: 0.009 (0.008)
2024-04-07 07:02:11,191 - train - INFO - Train: 84 [ 650/781 ( 83%)]  Loss:  3.711589 (3.5755)  Time: 0.436s,  293.55/s  (0.538s,  238.09/s)  LR: 2.091e-04  Data: 0.004 (0.008)
2024-04-07 07:02:37,326 - train - INFO - Train: 84 [ 700/781 ( 90%)]  Loss:  3.595344 (3.5756)  Time: 0.568s,  225.23/s  (0.537s,  238.56/s)  LR: 2.091e-04  Data: 0.007 (0.008)
2024-04-07 07:03:03,233 - train - INFO - Train: 84 [ 750/781 ( 96%)]  Loss:  3.947004 (3.5780)  Time: 0.496s,  258.15/s  (0.535s,  239.11/s)  LR: 2.091e-04  Data: 0.007 (0.008)
2024-04-07 07:03:18,428 - train - INFO - Train: 84 [ 780/781 (100%)]  Loss:  3.860623 (3.5790)  Time: 0.503s,  254.46/s  (0.534s,  239.61/s)  LR: 2.091e-04  Data: 0.000 (0.008)
2024-04-07 07:03:18,429 - train - INFO - True
2024-04-07 07:03:18,433 - train - INFO - alphas:tensor([0.6217, 0.0430, 0.0621, 0.0861, 0.1872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,433 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,434 - train - INFO - True
2024-04-07 07:03:18,435 - train - INFO - alphas:tensor([0.4307, 0.0185, 0.0336, 0.0784, 0.4388], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,435 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,436 - train - INFO - True
2024-04-07 07:03:18,437 - train - INFO - alphas:tensor([0.4707, 0.0303, 0.0738, 0.4252], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,438 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,438 - train - INFO - True
2024-04-07 07:03:18,439 - train - INFO - alphas:tensor([0.4132, 0.0293, 0.0561, 0.5015], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,440 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,440 - train - INFO - True
2024-04-07 07:03:18,442 - train - INFO - alphas:tensor([0.4165, 0.0212, 0.0654, 0.4969], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,442 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,442 - train - INFO - True
2024-04-07 07:03:18,444 - train - INFO - alphas:tensor([0.4988, 0.0306, 0.0561, 0.4146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,445 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,445 - train - INFO - True
2024-04-07 07:03:18,446 - train - INFO - alphas:tensor([0.5430, 0.0185, 0.0245, 0.0585, 0.3555], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,448 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,448 - train - INFO - True
2024-04-07 07:03:18,449 - train - INFO - alphas:tensor([0.2382, 0.0105, 0.0091, 0.0567, 0.6854], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,450 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,450 - train - INFO - True
2024-04-07 07:03:18,451 - train - INFO - alphas:tensor([0.2437, 0.0080, 0.0102, 0.0449, 0.6932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,452 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,452 - train - INFO - True
2024-04-07 07:03:18,454 - train - INFO - alphas:tensor([0.2493, 0.0059, 0.0091, 0.0502, 0.6855], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,454 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,455 - train - INFO - True
2024-04-07 07:03:18,456 - train - INFO - alphas:tensor([0.2341, 0.0091, 0.0093, 0.0567, 0.6908], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,457 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,457 - train - INFO - True
2024-04-07 07:03:18,458 - train - INFO - alphas:tensor([0.5459, 0.0092, 0.0162, 0.0530, 0.3757], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,459 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,460 - train - INFO - True
2024-04-07 07:03:18,461 - train - INFO - alphas:tensor([0.6441, 0.0111, 0.0139, 0.0387, 0.2921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,465 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,465 - train - INFO - True
2024-04-07 07:03:18,466 - train - INFO - alphas:tensor([0.2505, 0.0191, 0.0197, 0.0915, 0.6191], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,469 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,469 - train - INFO - True
2024-04-07 07:03:18,470 - train - INFO - alphas:tensor([0.2692, 0.0114, 0.0144, 0.0864, 0.6186], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,472 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,472 - train - INFO - True
2024-04-07 07:03:18,479 - train - INFO - alphas:tensor([0.2890, 0.0088, 0.0140, 0.0768, 0.6113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,481 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,481 - train - INFO - True
2024-04-07 07:03:18,488 - train - INFO - alphas:tensor([0.2595, 0.0133, 0.0167, 0.0760, 0.6346], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,491 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,491 - train - INFO - True
2024-04-07 07:03:18,500 - train - INFO - alphas:tensor([0.2894, 0.0094, 0.0180, 0.0776, 0.6056], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,502 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,502 - train - INFO - True
2024-04-07 07:03:18,509 - train - INFO - alphas:tensor([0.2448, 0.0204, 0.0250, 0.0897, 0.6200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,511 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,511 - train - INFO - True
2024-04-07 07:03:18,516 - train - INFO - alphas:tensor([0.5964, 0.0067, 0.0113, 0.0519, 0.3336], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,519 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,520 - train - INFO - True
2024-04-07 07:03:18,523 - train - INFO - alphas:tensor([0.5277, 0.0064, 0.0084, 0.0515, 0.4060], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,531 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,531 - train - INFO - True
2024-04-07 07:03:18,532 - train - INFO - alphas:tensor([0.4065, 0.0056, 0.0140, 0.0685, 0.5054], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,536 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,536 - train - INFO - True
2024-04-07 07:03:18,537 - train - INFO - alphas:tensor([0.4185, 0.0060, 0.0088, 0.0642, 0.5025], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,541 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,541 - train - INFO - True
2024-04-07 07:03:18,542 - train - INFO - alphas:tensor([0.4285, 0.0052, 0.0083, 0.0617, 0.4963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,546 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,546 - train - INFO - True
2024-04-07 07:03:18,547 - train - INFO - alphas:tensor([0.4019, 0.0065, 0.0123, 0.0681, 0.5113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,551 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,551 - train - INFO - True
2024-04-07 07:03:18,552 - train - INFO - alphas:tensor([0.5442, 0.0051, 0.0101, 0.0443, 0.3963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,559 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,559 - train - INFO - True
2024-04-07 07:03:18,560 - train - INFO - alphas:tensor([0.6987, 0.0043, 0.0082, 0.0338, 0.2550], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,579 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,580 - train - INFO - True
2024-04-07 07:03:18,586 - train - INFO - alphas:tensor([0.3637, 0.0069, 0.0117, 0.0785, 0.5393], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,596 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,597 - train - INFO - True
2024-04-07 07:03:18,605 - train - INFO - alphas:tensor([0.3740, 0.0043, 0.0096, 0.0685, 0.5436], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,616 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,616 - train - INFO - True
2024-04-07 07:03:18,617 - train - INFO - alphas:tensor([0.4056, 0.0047, 0.0077, 0.0653, 0.5167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,627 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,627 - train - INFO - True
2024-04-07 07:03:18,628 - train - INFO - alphas:tensor([0.3639, 0.0056, 0.0097, 0.0696, 0.5511], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,638 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,638 - train - INFO - True
2024-04-07 07:03:18,639 - train - INFO - alphas:tensor([0.6951, 0.0036, 0.0053, 0.0283, 0.2678], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,658 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,658 - train - INFO - True
2024-04-07 07:03:18,665 - train - INFO - alphas:tensor([0.5288, 0.0134, 0.0186, 0.0703, 0.3689], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:03:18,744 - train - INFO - tau:0.4386175018099108
2024-04-07 07:03:18,744 - train - INFO - avg block size:10.06060606060606
2024-04-07 07:03:18,744 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 07:03:18,744 - train - INFO - lasso_alpha:7.71086578859063e-06
2024-04-07 07:03:18,982 - train - INFO - Test: [   0/78]  Time: 0.234 (0.234)  Loss:  0.9380 (0.9380)  Acc@1: 82.0312 (82.0312)  Acc@5: 92.9688 (92.9688)
2024-04-07 07:03:24,507 - train - INFO - Test: [  50/78]  Time: 0.099 (0.113)  Loss:  1.6494 (1.5830)  Acc@1: 60.9375 (64.8438)  Acc@5: 84.3750 (85.8609)
2024-04-07 07:03:27,536 - train - INFO - Test: [  78/78]  Time: 0.089 (0.111)  Loss:  1.9326 (1.5977)  Acc@1: 56.2500 (64.7300)  Acc@5: 100.0000 (85.5700)
2024-04-07 07:03:28,337 - train - INFO - Train: 85 [   0/781 (  0%)]  Loss:  3.843721 (3.8437)  Time: 0.716s,  178.81/s  (0.716s,  178.81/s)  LR: 2.041e-04  Data: 0.158 (0.158)
2024-04-07 07:03:55,795 - train - INFO - Train: 85 [  50/781 (  6%)]  Loss:  3.596658 (3.6021)  Time: 0.537s,  238.17/s  (0.552s,  231.71/s)  LR: 2.041e-04  Data: 0.007 (0.011)
2024-04-07 07:04:22,609 - train - INFO - Train: 85 [ 100/781 ( 13%)]  Loss:  3.598858 (3.5842)  Time: 0.498s,  257.05/s  (0.544s,  235.12/s)  LR: 2.041e-04  Data: 0.005 (0.009)
2024-04-07 07:04:48,958 - train - INFO - Train: 85 [ 150/781 ( 19%)]  Loss:  3.552303 (3.5864)  Time: 0.475s,  269.56/s  (0.539s,  237.64/s)  LR: 2.041e-04  Data: 0.007 (0.008)
2024-04-07 07:05:14,477 - train - INFO - Train: 85 [ 200/781 ( 26%)]  Loss:  3.724167 (3.5758)  Time: 0.383s,  334.05/s  (0.532s,  240.79/s)  LR: 2.041e-04  Data: 0.007 (0.008)
2024-04-07 07:05:40,728 - train - INFO - Train: 85 [ 250/781 ( 32%)]  Loss:  3.823994 (3.5680)  Time: 0.607s,  210.84/s  (0.530s,  241.38/s)  LR: 2.041e-04  Data: 0.009 (0.008)
2024-04-07 07:06:08,332 - train - INFO - Train: 85 [ 300/781 ( 38%)]  Loss:  3.688735 (3.5754)  Time: 0.551s,  232.32/s  (0.534s,  239.75/s)  LR: 2.041e-04  Data: 0.007 (0.008)
2024-04-07 07:06:36,001 - train - INFO - Train: 85 [ 350/781 ( 45%)]  Loss:  3.247261 (3.5715)  Time: 0.499s,  256.61/s  (0.537s,  238.51/s)  LR: 2.041e-04  Data: 0.009 (0.008)
2024-04-07 07:07:02,865 - train - INFO - Train: 85 [ 400/781 ( 51%)]  Loss:  3.217027 (3.5680)  Time: 0.604s,  211.88/s  (0.537s,  238.48/s)  LR: 2.041e-04  Data: 0.009 (0.008)
2024-04-07 07:07:29,606 - train - INFO - Train: 85 [ 450/781 ( 58%)]  Loss:  3.488352 (3.5746)  Time: 0.449s,  285.29/s  (0.537s,  238.58/s)  LR: 2.041e-04  Data: 0.006 (0.008)
2024-04-07 07:07:55,352 - train - INFO - Train: 85 [ 500/781 ( 64%)]  Loss:  3.370929 (3.5722)  Time: 0.544s,  235.45/s  (0.534s,  239.54/s)  LR: 2.041e-04  Data: 0.009 (0.008)
2024-04-07 07:08:22,564 - train - INFO - Train: 85 [ 550/781 ( 71%)]  Loss:  3.530117 (3.5731)  Time: 0.504s,  253.81/s  (0.535s,  239.14/s)  LR: 2.041e-04  Data: 0.005 (0.008)
2024-04-07 07:08:48,707 - train - INFO - Train: 85 [ 600/781 ( 77%)]  Loss:  3.579211 (3.5718)  Time: 0.720s,  177.81/s  (0.534s,  239.60/s)  LR: 2.041e-04  Data: 0.008 (0.008)
2024-04-07 07:09:15,789 - train - INFO - Train: 85 [ 650/781 ( 83%)]  Loss:  3.166066 (3.5722)  Time: 0.565s,  226.58/s  (0.535s,  239.35/s)  LR: 2.041e-04  Data: 0.009 (0.008)
2024-04-07 07:09:41,685 - train - INFO - Train: 85 [ 700/781 ( 90%)]  Loss:  3.979192 (3.5753)  Time: 0.557s,  229.70/s  (0.534s,  239.89/s)  LR: 2.041e-04  Data: 0.009 (0.008)
2024-04-07 07:10:08,346 - train - INFO - Train: 85 [ 750/781 ( 96%)]  Loss:  3.483007 (3.5728)  Time: 0.554s,  231.13/s  (0.534s,  239.90/s)  LR: 2.041e-04  Data: 0.009 (0.008)
2024-04-07 07:10:23,374 - train - INFO - Train: 85 [ 780/781 (100%)]  Loss:  3.548781 (3.5727)  Time: 0.472s,  271.35/s  (0.532s,  240.46/s)  LR: 2.041e-04  Data: 0.000 (0.008)
2024-04-07 07:10:23,375 - train - INFO - True
2024-04-07 07:10:23,378 - train - INFO - alphas:tensor([0.6263, 0.0419, 0.0610, 0.0848, 0.1860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,379 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,379 - train - INFO - True
2024-04-07 07:10:23,381 - train - INFO - alphas:tensor([0.4350, 0.0180, 0.0327, 0.0779, 0.4365], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,381 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,382 - train - INFO - True
2024-04-07 07:10:23,383 - train - INFO - alphas:tensor([0.4698, 0.0297, 0.0732, 0.4273], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,384 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,385 - train - INFO - True
2024-04-07 07:10:23,386 - train - INFO - alphas:tensor([0.4138, 0.0287, 0.0555, 0.5021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,387 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,387 - train - INFO - True
2024-04-07 07:10:23,389 - train - INFO - alphas:tensor([0.4189, 0.0208, 0.0645, 0.4958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,390 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,390 - train - INFO - True
2024-04-07 07:10:23,391 - train - INFO - alphas:tensor([0.5024, 0.0299, 0.0557, 0.4121], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,392 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,393 - train - INFO - True
2024-04-07 07:10:23,394 - train - INFO - alphas:tensor([0.5442, 0.0180, 0.0240, 0.0576, 0.3563], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,396 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,396 - train - INFO - True
2024-04-07 07:10:23,397 - train - INFO - alphas:tensor([0.2395, 0.0102, 0.0088, 0.0558, 0.6857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,399 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,399 - train - INFO - True
2024-04-07 07:10:23,400 - train - INFO - alphas:tensor([0.2507, 0.0078, 0.0100, 0.0444, 0.6871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,401 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,401 - train - INFO - True
2024-04-07 07:10:23,403 - train - INFO - alphas:tensor([0.2500, 0.0057, 0.0089, 0.0498, 0.6856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,404 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,404 - train - INFO - True
2024-04-07 07:10:23,405 - train - INFO - alphas:tensor([0.2384, 0.0089, 0.0091, 0.0564, 0.6872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,406 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,406 - train - INFO - True
2024-04-07 07:10:23,408 - train - INFO - alphas:tensor([0.5484, 0.0089, 0.0159, 0.0521, 0.3748], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,410 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,410 - train - INFO - True
2024-04-07 07:10:23,411 - train - INFO - alphas:tensor([0.6425, 0.0108, 0.0136, 0.0383, 0.2948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,416 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,416 - train - INFO - True
2024-04-07 07:10:23,417 - train - INFO - alphas:tensor([0.2560, 0.0190, 0.0193, 0.0907, 0.6150], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,420 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,420 - train - INFO - True
2024-04-07 07:10:23,429 - train - INFO - alphas:tensor([0.2710, 0.0111, 0.0139, 0.0856, 0.6184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,432 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,432 - train - INFO - True
2024-04-07 07:10:23,439 - train - INFO - alphas:tensor([0.2969, 0.0086, 0.0136, 0.0763, 0.6046], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,441 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,441 - train - INFO - True
2024-04-07 07:10:23,450 - train - INFO - alphas:tensor([0.2662, 0.0130, 0.0164, 0.0749, 0.6294], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,452 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,453 - train - INFO - True
2024-04-07 07:10:23,460 - train - INFO - alphas:tensor([0.2922, 0.0091, 0.0178, 0.0769, 0.6040], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,462 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,462 - train - INFO - True
2024-04-07 07:10:23,467 - train - INFO - alphas:tensor([0.2483, 0.0201, 0.0245, 0.0880, 0.6190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,469 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,469 - train - INFO - True
2024-04-07 07:10:23,470 - train - INFO - alphas:tensor([0.5981, 0.0065, 0.0110, 0.0511, 0.3333], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,473 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,474 - train - INFO - True
2024-04-07 07:10:23,474 - train - INFO - alphas:tensor([0.5300, 0.0062, 0.0080, 0.0511, 0.4048], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,482 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,482 - train - INFO - True
2024-04-07 07:10:23,483 - train - INFO - alphas:tensor([0.4113, 0.0055, 0.0140, 0.0688, 0.5005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,487 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,487 - train - INFO - True
2024-04-07 07:10:23,488 - train - INFO - alphas:tensor([0.4230, 0.0058, 0.0085, 0.0629, 0.4997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,492 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,492 - train - INFO - True
2024-04-07 07:10:23,493 - train - INFO - alphas:tensor([0.4320, 0.0050, 0.0081, 0.0617, 0.4932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,497 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,497 - train - INFO - True
2024-04-07 07:10:23,498 - train - INFO - alphas:tensor([0.4007, 0.0061, 0.0120, 0.0674, 0.5138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,501 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,502 - train - INFO - True
2024-04-07 07:10:23,502 - train - INFO - alphas:tensor([0.5456, 0.0049, 0.0099, 0.0429, 0.3968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,509 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,509 - train - INFO - True
2024-04-07 07:10:23,515 - train - INFO - alphas:tensor([0.7010, 0.0041, 0.0080, 0.0331, 0.2537], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,532 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,532 - train - INFO - True
2024-04-07 07:10:23,537 - train - INFO - alphas:tensor([0.3672, 0.0066, 0.0111, 0.0777, 0.5375], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,545 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,545 - train - INFO - True
2024-04-07 07:10:23,551 - train - INFO - alphas:tensor([0.3792, 0.0042, 0.0092, 0.0675, 0.5399], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,559 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,559 - train - INFO - True
2024-04-07 07:10:23,560 - train - INFO - alphas:tensor([0.4090, 0.0046, 0.0076, 0.0657, 0.5131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,568 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,568 - train - INFO - True
2024-04-07 07:10:23,568 - train - INFO - alphas:tensor([0.3695, 0.0054, 0.0094, 0.0683, 0.5473], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,576 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,576 - train - INFO - True
2024-04-07 07:10:23,577 - train - INFO - alphas:tensor([0.6989, 0.0034, 0.0050, 0.0273, 0.2655], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,590 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,590 - train - INFO - True
2024-04-07 07:10:23,591 - train - INFO - alphas:tensor([0.5364, 0.0131, 0.0182, 0.0685, 0.3638], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:10:23,642 - train - INFO - tau:0.4342313267918117
2024-04-07 07:10:23,642 - train - INFO - avg block size:10.06060606060606
2024-04-07 07:10:23,642 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 07:10:23,927 - train - INFO - Test: [   0/78]  Time: 0.282 (0.282)  Loss:  0.9771 (0.9771)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.9688 (92.9688)
2024-04-07 07:10:29,303 - train - INFO - Test: [  50/78]  Time: 0.374 (0.111)  Loss:  1.7373 (1.6096)  Acc@1: 57.8125 (64.0319)  Acc@5: 85.1562 (85.7077)
2024-04-07 07:10:32,204 - train - INFO - Test: [  78/78]  Time: 0.099 (0.108)  Loss:  2.0859 (1.6198)  Acc@1: 56.2500 (63.9400)  Acc@5: 87.5000 (85.3500)
2024-04-07 07:10:33,004 - train - INFO - Train: 86 [   0/781 (  0%)]  Loss:  3.725018 (3.7250)  Time: 0.720s,  177.77/s  (0.720s,  177.77/s)  LR: 1.991e-04  Data: 0.190 (0.190)
2024-04-07 07:11:00,114 - train - INFO - Train: 86 [  50/781 (  6%)]  Loss:  3.625213 (3.5498)  Time: 0.578s,  221.35/s  (0.546s,  234.58/s)  LR: 1.991e-04  Data: 0.009 (0.011)
2024-04-07 07:11:28,067 - train - INFO - Train: 86 [ 100/781 ( 13%)]  Loss:  3.545465 (3.5511)  Time: 0.582s,  219.94/s  (0.552s,  231.77/s)  LR: 1.991e-04  Data: 0.009 (0.009)
2024-04-07 07:11:55,003 - train - INFO - Train: 86 [ 150/781 ( 19%)]  Loss:  3.716428 (3.5510)  Time: 0.574s,  222.93/s  (0.548s,  233.67/s)  LR: 1.991e-04  Data: 0.012 (0.009)
2024-04-07 07:12:20,139 - train - INFO - Train: 86 [ 200/781 ( 26%)]  Loss:  3.533333 (3.5670)  Time: 0.523s,  244.75/s  (0.537s,  238.56/s)  LR: 1.991e-04  Data: 0.006 (0.008)
2024-04-07 07:12:46,781 - train - INFO - Train: 86 [ 250/781 ( 32%)]  Loss:  3.567731 (3.5678)  Time: 0.540s,  236.94/s  (0.536s,  238.89/s)  LR: 1.991e-04  Data: 0.008 (0.008)
2024-04-07 07:13:12,673 - train - INFO - Train: 86 [ 300/781 ( 38%)]  Loss:  3.246959 (3.5657)  Time: 0.513s,  249.63/s  (0.533s,  240.23/s)  LR: 1.991e-04  Data: 0.006 (0.008)
2024-04-07 07:13:40,464 - train - INFO - Train: 86 [ 350/781 ( 45%)]  Loss:  3.749376 (3.5670)  Time: 0.522s,  245.37/s  (0.536s,  238.76/s)  LR: 1.991e-04  Data: 0.008 (0.008)
2024-04-07 07:14:06,041 - train - INFO - Train: 86 [ 400/781 ( 51%)]  Loss:  3.347461 (3.5625)  Time: 0.458s,  279.57/s  (0.533s,  240.14/s)  LR: 1.991e-04  Data: 0.005 (0.008)
2024-04-07 07:14:33,107 - train - INFO - Train: 86 [ 450/781 ( 58%)]  Loss:  3.361429 (3.5648)  Time: 0.531s,  240.99/s  (0.534s,  239.73/s)  LR: 1.991e-04  Data: 0.007 (0.008)
2024-04-07 07:14:58,754 - train - INFO - Train: 86 [ 500/781 ( 64%)]  Loss:  3.896947 (3.5656)  Time: 1.081s,  118.42/s  (0.532s,  240.67/s)  LR: 1.991e-04  Data: 0.006 (0.008)
2024-04-07 07:15:24,346 - train - INFO - Train: 86 [ 550/781 ( 71%)]  Loss:  3.290363 (3.5672)  Time: 0.466s,  274.53/s  (0.530s,  241.50/s)  LR: 1.991e-04  Data: 0.007 (0.008)
2024-04-07 07:15:52,134 - train - INFO - Train: 86 [ 600/781 ( 77%)]  Loss:  3.514222 (3.5655)  Time: 0.533s,  240.20/s  (0.532s,  240.53/s)  LR: 1.991e-04  Data: 0.007 (0.008)
2024-04-07 07:16:18,219 - train - INFO - Train: 86 [ 650/781 ( 83%)]  Loss:  3.443074 (3.5661)  Time: 0.502s,  254.93/s  (0.531s,  240.89/s)  LR: 1.991e-04  Data: 0.005 (0.008)
2024-04-07 07:16:44,691 - train - INFO - Train: 86 [ 700/781 ( 90%)]  Loss:  3.687003 (3.5652)  Time: 0.580s,  220.57/s  (0.531s,  240.96/s)  LR: 1.991e-04  Data: 0.009 (0.008)
2024-04-07 07:17:11,858 - train - INFO - Train: 86 [ 750/781 ( 96%)]  Loss:  3.615392 (3.5652)  Time: 0.448s,  285.89/s  (0.532s,  240.59/s)  LR: 1.991e-04  Data: 0.004 (0.008)
2024-04-07 07:17:28,380 - train - INFO - Train: 86 [ 780/781 (100%)]  Loss:  3.529140 (3.5671)  Time: 0.544s,  235.24/s  (0.533s,  240.27/s)  LR: 1.991e-04  Data: 0.000 (0.008)
2024-04-07 07:17:28,381 - train - INFO - True
2024-04-07 07:17:28,390 - train - INFO - alphas:tensor([0.6289, 0.0411, 0.0601, 0.0842, 0.1858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,391 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,391 - train - INFO - True
2024-04-07 07:17:28,399 - train - INFO - alphas:tensor([0.4347, 0.0175, 0.0323, 0.0767, 0.4389], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,400 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,400 - train - INFO - True
2024-04-07 07:17:28,409 - train - INFO - alphas:tensor([0.4719, 0.0292, 0.0723, 0.4267], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,410 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,410 - train - INFO - True
2024-04-07 07:17:28,414 - train - INFO - alphas:tensor([0.4185, 0.0284, 0.0549, 0.4982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,414 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,414 - train - INFO - True
2024-04-07 07:17:28,416 - train - INFO - alphas:tensor([0.4187, 0.0203, 0.0637, 0.4974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,416 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,416 - train - INFO - True
2024-04-07 07:17:28,417 - train - INFO - alphas:tensor([0.5029, 0.0292, 0.0549, 0.4131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,418 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,418 - train - INFO - True
2024-04-07 07:17:28,419 - train - INFO - alphas:tensor([0.5453, 0.0176, 0.0234, 0.0568, 0.3569], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,421 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,421 - train - INFO - True
2024-04-07 07:17:28,422 - train - INFO - alphas:tensor([0.2412, 0.0100, 0.0086, 0.0542, 0.6859], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,423 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,423 - train - INFO - True
2024-04-07 07:17:28,424 - train - INFO - alphas:tensor([0.2506, 0.0074, 0.0096, 0.0435, 0.6889], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,425 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,425 - train - INFO - True
2024-04-07 07:17:28,426 - train - INFO - alphas:tensor([0.2538, 0.0055, 0.0085, 0.0491, 0.6831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,427 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,427 - train - INFO - True
2024-04-07 07:17:28,428 - train - INFO - alphas:tensor([0.2382, 0.0087, 0.0088, 0.0556, 0.6887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,429 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,429 - train - INFO - True
2024-04-07 07:17:28,430 - train - INFO - alphas:tensor([0.5515, 0.0086, 0.0154, 0.0513, 0.3732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,431 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,431 - train - INFO - True
2024-04-07 07:17:28,432 - train - INFO - alphas:tensor([0.6488, 0.0104, 0.0131, 0.0372, 0.2905], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,436 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,436 - train - INFO - True
2024-04-07 07:17:28,437 - train - INFO - alphas:tensor([0.2575, 0.0181, 0.0188, 0.0898, 0.6158], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,439 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,439 - train - INFO - True
2024-04-07 07:17:28,440 - train - INFO - alphas:tensor([0.2721, 0.0108, 0.0136, 0.0845, 0.6190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,449 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,456 - train - INFO - True
2024-04-07 07:17:28,463 - train - INFO - alphas:tensor([0.2947, 0.0084, 0.0131, 0.0764, 0.6074], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,464 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,465 - train - INFO - True
2024-04-07 07:17:28,472 - train - INFO - alphas:tensor([0.2681, 0.0127, 0.0163, 0.0745, 0.6283], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,474 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,474 - train - INFO - True
2024-04-07 07:17:28,481 - train - INFO - alphas:tensor([0.2959, 0.0088, 0.0172, 0.0770, 0.6011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,483 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,483 - train - INFO - True
2024-04-07 07:17:28,490 - train - INFO - alphas:tensor([0.2489, 0.0194, 0.0240, 0.0870, 0.6206], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,492 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,492 - train - INFO - True
2024-04-07 07:17:28,499 - train - INFO - alphas:tensor([0.5997, 0.0063, 0.0107, 0.0505, 0.3328], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,503 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,503 - train - INFO - True
2024-04-07 07:17:28,506 - train - INFO - alphas:tensor([0.5308, 0.0060, 0.0078, 0.0503, 0.4052], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,514 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,514 - train - INFO - True
2024-04-07 07:17:28,515 - train - INFO - alphas:tensor([0.4094, 0.0054, 0.0137, 0.0688, 0.5028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,518 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,519 - train - INFO - True
2024-04-07 07:17:28,519 - train - INFO - alphas:tensor([0.4279, 0.0056, 0.0081, 0.0617, 0.4967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,523 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,523 - train - INFO - True
2024-04-07 07:17:28,524 - train - INFO - alphas:tensor([0.4346, 0.0048, 0.0079, 0.0608, 0.4920], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,528 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,528 - train - INFO - True
2024-04-07 07:17:28,529 - train - INFO - alphas:tensor([0.4027, 0.0059, 0.0116, 0.0666, 0.5131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,533 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,533 - train - INFO - True
2024-04-07 07:17:28,534 - train - INFO - alphas:tensor([0.5514, 0.0047, 0.0096, 0.0423, 0.3920], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,541 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,542 - train - INFO - True
2024-04-07 07:17:28,542 - train - INFO - alphas:tensor([0.6990, 0.0040, 0.0078, 0.0331, 0.2562], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,562 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,562 - train - INFO - True
2024-04-07 07:17:28,569 - train - INFO - alphas:tensor([0.3713, 0.0064, 0.0107, 0.0764, 0.5352], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,579 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,579 - train - INFO - True
2024-04-07 07:17:28,586 - train - INFO - alphas:tensor([0.3797, 0.0040, 0.0089, 0.0666, 0.5408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,596 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,596 - train - INFO - True
2024-04-07 07:17:28,597 - train - INFO - alphas:tensor([0.4162, 0.0044, 0.0073, 0.0640, 0.5082], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,607 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,607 - train - INFO - True
2024-04-07 07:17:28,608 - train - INFO - alphas:tensor([0.3692, 0.0053, 0.0092, 0.0684, 0.5479], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,618 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,618 - train - INFO - True
2024-04-07 07:17:28,619 - train - INFO - alphas:tensor([0.6980, 0.0033, 0.0049, 0.0270, 0.2668], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,640 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,640 - train - INFO - True
2024-04-07 07:17:28,649 - train - INFO - alphas:tensor([0.5322, 0.0129, 0.0178, 0.0688, 0.3683], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:17:28,727 - train - INFO - tau:0.4298890135238936
2024-04-07 07:17:28,727 - train - INFO - avg block size:10.06060606060606
2024-04-07 07:17:28,728 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 07:17:28,728 - train - INFO - lasso_alpha:7.0098779896278455e-06
2024-04-07 07:17:28,973 - train - INFO - Test: [   0/78]  Time: 0.241 (0.241)  Loss:  1.0732 (1.0732)  Acc@1: 80.4688 (80.4688)  Acc@5: 93.7500 (93.7500)
2024-04-07 07:17:34,289 - train - INFO - Test: [  50/78]  Time: 0.135 (0.109)  Loss:  1.6992 (1.5938)  Acc@1: 60.1562 (64.5680)  Acc@5: 86.7188 (85.8456)
2024-04-07 07:17:37,412 - train - INFO - Test: [  78/78]  Time: 0.096 (0.110)  Loss:  1.6680 (1.6053)  Acc@1: 56.2500 (64.3700)  Acc@5: 100.0000 (85.5400)
2024-04-07 07:17:38,238 - train - INFO - Train: 87 [   0/781 (  0%)]  Loss:  3.623985 (3.6240)  Time: 0.743s,  172.28/s  (0.743s,  172.28/s)  LR: 1.941e-04  Data: 0.171 (0.171)
2024-04-07 07:18:05,701 - train - INFO - Train: 87 [  50/781 (  6%)]  Loss:  3.554993 (3.5655)  Time: 1.166s,  109.82/s  (0.553s,  231.45/s)  LR: 1.941e-04  Data: 0.009 (0.011)
2024-04-07 07:18:32,110 - train - INFO - Train: 87 [ 100/781 ( 13%)]  Loss:  3.453111 (3.5697)  Time: 0.484s,  264.48/s  (0.541s,  236.72/s)  LR: 1.941e-04  Data: 0.008 (0.009)
2024-04-07 07:18:59,007 - train - INFO - Train: 87 [ 150/781 ( 19%)]  Loss:  3.601855 (3.5695)  Time: 0.465s,  275.38/s  (0.540s,  237.13/s)  LR: 1.941e-04  Data: 0.006 (0.009)
2024-04-07 07:19:26,271 - train - INFO - Train: 87 [ 200/781 ( 26%)]  Loss:  3.203573 (3.5658)  Time: 0.553s,  231.65/s  (0.541s,  236.54/s)  LR: 1.941e-04  Data: 0.009 (0.008)
2024-04-07 07:19:51,636 - train - INFO - Train: 87 [ 250/781 ( 32%)]  Loss:  3.793666 (3.5623)  Time: 0.553s,  231.67/s  (0.534s,  239.52/s)  LR: 1.941e-04  Data: 0.008 (0.008)
2024-04-07 07:20:18,412 - train - INFO - Train: 87 [ 300/781 ( 38%)]  Loss:  3.797287 (3.5679)  Time: 0.474s,  269.92/s  (0.535s,  239.44/s)  LR: 1.941e-04  Data: 0.010 (0.008)
2024-04-07 07:20:45,401 - train - INFO - Train: 87 [ 350/781 ( 45%)]  Loss:  3.603292 (3.5671)  Time: 0.566s,  226.05/s  (0.535s,  239.11/s)  LR: 1.941e-04  Data: 0.007 (0.008)
2024-04-07 07:21:12,033 - train - INFO - Train: 87 [ 400/781 ( 51%)]  Loss:  3.277797 (3.5600)  Time: 0.546s,  234.46/s  (0.535s,  239.26/s)  LR: 1.941e-04  Data: 0.006 (0.008)
2024-04-07 07:21:37,618 - train - INFO - Train: 87 [ 450/781 ( 58%)]  Loss:  3.621056 (3.5595)  Time: 0.587s,  218.12/s  (0.532s,  240.42/s)  LR: 1.941e-04  Data: 0.008 (0.008)
2024-04-07 07:22:04,544 - train - INFO - Train: 87 [ 500/781 ( 64%)]  Loss:  3.392346 (3.5613)  Time: 0.542s,  236.20/s  (0.533s,  240.15/s)  LR: 1.941e-04  Data: 0.008 (0.008)
2024-04-07 07:22:30,955 - train - INFO - Train: 87 [ 550/781 ( 71%)]  Loss:  3.244684 (3.5594)  Time: 0.546s,  234.58/s  (0.533s,  240.35/s)  LR: 1.941e-04  Data: 0.007 (0.008)
2024-04-07 07:22:57,437 - train - INFO - Train: 87 [ 600/781 ( 77%)]  Loss:  3.543979 (3.5607)  Time: 0.452s,  283.28/s  (0.532s,  240.46/s)  LR: 1.941e-04  Data: 0.006 (0.008)
2024-04-07 07:23:23,921 - train - INFO - Train: 87 [ 650/781 ( 83%)]  Loss:  3.578925 (3.5601)  Time: 0.597s,  214.39/s  (0.532s,  240.55/s)  LR: 1.941e-04  Data: 0.008 (0.008)
2024-04-07 07:23:50,825 - train - INFO - Train: 87 [ 700/781 ( 90%)]  Loss:  3.436486 (3.5617)  Time: 0.510s,  250.78/s  (0.533s,  240.36/s)  LR: 1.941e-04  Data: 0.007 (0.008)
2024-04-07 07:24:17,726 - train - INFO - Train: 87 [ 750/781 ( 96%)]  Loss:  3.596945 (3.5589)  Time: 0.483s,  265.21/s  (0.533s,  240.20/s)  LR: 1.941e-04  Data: 0.006 (0.008)
2024-04-07 07:24:33,273 - train - INFO - Train: 87 [ 780/781 (100%)]  Loss:  3.802840 (3.5611)  Time: 0.387s,  330.34/s  (0.532s,  240.45/s)  LR: 1.941e-04  Data: 0.000 (0.008)
2024-04-07 07:24:33,274 - train - INFO - True
2024-04-07 07:24:33,278 - train - INFO - alphas:tensor([0.6303, 0.0405, 0.0595, 0.0835, 0.1863], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,279 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,279 - train - INFO - True
2024-04-07 07:24:33,281 - train - INFO - alphas:tensor([0.4374, 0.0169, 0.0313, 0.0753, 0.4391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,281 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,281 - train - INFO - True
2024-04-07 07:24:33,283 - train - INFO - alphas:tensor([0.4710, 0.0284, 0.0710, 0.4296], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,284 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,284 - train - INFO - True
2024-04-07 07:24:33,286 - train - INFO - alphas:tensor([0.4195, 0.0276, 0.0538, 0.4991], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,287 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,287 - train - INFO - True
2024-04-07 07:24:33,288 - train - INFO - alphas:tensor([0.4210, 0.0197, 0.0628, 0.4964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,289 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,289 - train - INFO - True
2024-04-07 07:24:33,291 - train - INFO - alphas:tensor([0.5056, 0.0285, 0.0537, 0.4122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,292 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,292 - train - INFO - True
2024-04-07 07:24:33,294 - train - INFO - alphas:tensor([0.5482, 0.0170, 0.0228, 0.0559, 0.3561], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,295 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,295 - train - INFO - True
2024-04-07 07:24:33,297 - train - INFO - alphas:tensor([0.2435, 0.0099, 0.0084, 0.0539, 0.6842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,298 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,298 - train - INFO - True
2024-04-07 07:24:33,299 - train - INFO - alphas:tensor([0.2537, 0.0073, 0.0093, 0.0433, 0.6864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,300 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,301 - train - INFO - True
2024-04-07 07:24:33,302 - train - INFO - alphas:tensor([0.2534, 0.0053, 0.0083, 0.0483, 0.6846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,303 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,303 - train - INFO - True
2024-04-07 07:24:33,304 - train - INFO - alphas:tensor([0.2414, 0.0085, 0.0086, 0.0562, 0.6854], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,305 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,305 - train - INFO - True
2024-04-07 07:24:33,307 - train - INFO - alphas:tensor([0.5529, 0.0083, 0.0149, 0.0505, 0.3734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,308 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,308 - train - INFO - True
2024-04-07 07:24:33,310 - train - INFO - alphas:tensor([0.6519, 0.0101, 0.0126, 0.0367, 0.2887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,315 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,315 - train - INFO - True
2024-04-07 07:24:33,316 - train - INFO - alphas:tensor([0.2567, 0.0175, 0.0185, 0.0892, 0.6180], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,319 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,319 - train - INFO - True
2024-04-07 07:24:33,328 - train - INFO - alphas:tensor([0.2748, 0.0106, 0.0134, 0.0849, 0.6163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,330 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,330 - train - INFO - True
2024-04-07 07:24:33,337 - train - INFO - alphas:tensor([0.2969, 0.0081, 0.0127, 0.0758, 0.6064], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,339 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,340 - train - INFO - True
2024-04-07 07:24:33,348 - train - INFO - alphas:tensor([0.2725, 0.0124, 0.0160, 0.0733, 0.6259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,351 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,351 - train - INFO - True
2024-04-07 07:24:33,358 - train - INFO - alphas:tensor([0.3001, 0.0085, 0.0169, 0.0753, 0.5993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,360 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,360 - train - INFO - True
2024-04-07 07:24:33,367 - train - INFO - alphas:tensor([0.2562, 0.0192, 0.0237, 0.0863, 0.6147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,369 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,369 - train - INFO - True
2024-04-07 07:24:33,370 - train - INFO - alphas:tensor([0.5995, 0.0060, 0.0104, 0.0494, 0.3347], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,374 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,374 - train - INFO - True
2024-04-07 07:24:33,375 - train - INFO - alphas:tensor([0.5336, 0.0058, 0.0075, 0.0500, 0.4031], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,383 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,383 - train - INFO - True
2024-04-07 07:24:33,384 - train - INFO - alphas:tensor([0.4123, 0.0051, 0.0135, 0.0671, 0.5019], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,387 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,388 - train - INFO - True
2024-04-07 07:24:33,388 - train - INFO - alphas:tensor([0.4266, 0.0053, 0.0079, 0.0616, 0.4985], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,392 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,392 - train - INFO - True
2024-04-07 07:24:33,393 - train - INFO - alphas:tensor([0.4459, 0.0046, 0.0076, 0.0593, 0.4826], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,397 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,397 - train - INFO - True
2024-04-07 07:24:33,398 - train - INFO - alphas:tensor([0.4086, 0.0056, 0.0113, 0.0650, 0.5095], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,401 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,401 - train - INFO - True
2024-04-07 07:24:33,402 - train - INFO - alphas:tensor([0.5582, 0.0045, 0.0093, 0.0412, 0.3868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,409 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,409 - train - INFO - True
2024-04-07 07:24:33,415 - train - INFO - alphas:tensor([0.7061, 0.0037, 0.0074, 0.0320, 0.2507], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,431 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,431 - train - INFO - True
2024-04-07 07:24:33,436 - train - INFO - alphas:tensor([0.3726, 0.0062, 0.0106, 0.0759, 0.5348], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,444 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,444 - train - INFO - True
2024-04-07 07:24:33,450 - train - INFO - alphas:tensor([0.3875, 0.0039, 0.0087, 0.0656, 0.5344], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,458 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,458 - train - INFO - True
2024-04-07 07:24:33,459 - train - INFO - alphas:tensor([0.4200, 0.0042, 0.0070, 0.0642, 0.5045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,466 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,466 - train - INFO - True
2024-04-07 07:24:33,467 - train - INFO - alphas:tensor([0.3793, 0.0050, 0.0090, 0.0666, 0.5401], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,474 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,474 - train - INFO - True
2024-04-07 07:24:33,475 - train - INFO - alphas:tensor([0.7032, 0.0032, 0.0047, 0.0265, 0.2624], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,489 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,489 - train - INFO - True
2024-04-07 07:24:33,489 - train - INFO - alphas:tensor([0.5382, 0.0125, 0.0175, 0.0683, 0.3635], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:24:33,539 - train - INFO - tau:0.42559012338865465
2024-04-07 07:24:33,539 - train - INFO - avg block size:10.06060606060606
2024-04-07 07:24:33,539 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 07:24:33,820 - train - INFO - Test: [   0/78]  Time: 0.279 (0.279)  Loss:  1.0947 (1.0947)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.9688 (92.9688)
2024-04-07 07:24:39,443 - train - INFO - Test: [  50/78]  Time: 0.097 (0.116)  Loss:  1.5996 (1.5919)  Acc@1: 64.0625 (64.5680)  Acc@5: 85.1562 (86.1826)
2024-04-07 07:24:42,593 - train - INFO - Test: [  78/78]  Time: 0.094 (0.115)  Loss:  1.9883 (1.6149)  Acc@1: 50.0000 (64.2900)  Acc@5: 93.7500 (85.6700)
2024-04-07 07:24:43,347 - train - INFO - Train: 88 [   0/781 (  0%)]  Loss:  3.903779 (3.9038)  Time: 0.670s,  191.06/s  (0.670s,  191.06/s)  LR: 1.891e-04  Data: 0.172 (0.172)
2024-04-07 07:25:10,081 - train - INFO - Train: 88 [  50/781 (  6%)]  Loss:  3.065356 (3.5853)  Time: 0.573s,  223.29/s  (0.537s,  238.23/s)  LR: 1.891e-04  Data: 0.008 (0.010)
2024-04-07 07:25:35,907 - train - INFO - Train: 88 [ 100/781 ( 13%)]  Loss:  3.098633 (3.5641)  Time: 0.431s,  297.31/s  (0.527s,  242.89/s)  LR: 1.891e-04  Data: 0.006 (0.009)
2024-04-07 07:26:03,205 - train - INFO - Train: 88 [ 150/781 ( 19%)]  Loss:  3.851141 (3.5491)  Time: 0.571s,  224.12/s  (0.533s,  240.03/s)  LR: 1.891e-04  Data: 0.008 (0.009)
2024-04-07 07:26:29,202 - train - INFO - Train: 88 [ 200/781 ( 26%)]  Loss:  3.526590 (3.5538)  Time: 0.641s,  199.71/s  (0.530s,  241.54/s)  LR: 1.891e-04  Data: 0.007 (0.008)
2024-04-07 07:26:54,792 - train - INFO - Train: 88 [ 250/781 ( 32%)]  Loss:  3.689842 (3.5487)  Time: 0.581s,  220.23/s  (0.526s,  243.20/s)  LR: 1.891e-04  Data: 0.009 (0.008)
2024-04-07 07:27:21,463 - train - INFO - Train: 88 [ 300/781 ( 38%)]  Loss:  3.512150 (3.5517)  Time: 0.560s,  228.69/s  (0.527s,  242.66/s)  LR: 1.891e-04  Data: 0.010 (0.008)
2024-04-07 07:27:48,495 - train - INFO - Train: 88 [ 350/781 ( 45%)]  Loss:  3.933004 (3.5538)  Time: 0.397s,  322.14/s  (0.529s,  241.80/s)  LR: 1.891e-04  Data: 0.005 (0.008)
2024-04-07 07:28:15,319 - train - INFO - Train: 88 [ 400/781 ( 51%)]  Loss:  3.759539 (3.5523)  Time: 0.549s,  233.12/s  (0.530s,  241.40/s)  LR: 1.891e-04  Data: 0.005 (0.008)
2024-04-07 07:28:40,281 - train - INFO - Train: 88 [ 450/781 ( 58%)]  Loss:  3.792061 (3.5498)  Time: 0.548s,  233.50/s  (0.527s,  242.97/s)  LR: 1.891e-04  Data: 0.007 (0.008)
2024-04-07 07:29:07,670 - train - INFO - Train: 88 [ 500/781 ( 64%)]  Loss:  3.797183 (3.5539)  Time: 0.575s,  222.67/s  (0.529s,  242.01/s)  LR: 1.891e-04  Data: 0.008 (0.008)
2024-04-07 07:29:34,987 - train - INFO - Train: 88 [ 550/781 ( 71%)]  Loss:  3.775836 (3.5528)  Time: 0.521s,  245.57/s  (0.530s,  241.29/s)  LR: 1.891e-04  Data: 0.005 (0.008)
2024-04-07 07:30:00,837 - train - INFO - Train: 88 [ 600/781 ( 77%)]  Loss:  3.391424 (3.5578)  Time: 0.558s,  229.45/s  (0.529s,  241.81/s)  LR: 1.891e-04  Data: 0.008 (0.008)
2024-04-07 07:30:27,132 - train - INFO - Train: 88 [ 650/781 ( 83%)]  Loss:  3.531451 (3.5581)  Time: 0.533s,  240.03/s  (0.529s,  241.93/s)  LR: 1.891e-04  Data: 0.007 (0.008)
2024-04-07 07:30:52,718 - train - INFO - Train: 88 [ 700/781 ( 90%)]  Loss:  3.667367 (3.5625)  Time: 0.516s,  247.96/s  (0.528s,  242.50/s)  LR: 1.891e-04  Data: 0.009 (0.008)
2024-04-07 07:31:19,111 - train - INFO - Train: 88 [ 750/781 ( 96%)]  Loss:  3.585931 (3.5603)  Time: 0.583s,  219.45/s  (0.528s,  242.50/s)  LR: 1.891e-04  Data: 0.006 (0.008)
2024-04-07 07:31:35,151 - train - INFO - Train: 88 [ 780/781 (100%)]  Loss:  3.849649 (3.5612)  Time: 0.474s,  269.98/s  (0.528s,  242.38/s)  LR: 1.891e-04  Data: 0.000 (0.008)
2024-04-07 07:31:35,152 - train - INFO - True
2024-04-07 07:31:35,160 - train - INFO - alphas:tensor([0.6342, 0.0396, 0.0584, 0.0822, 0.1856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,161 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,161 - train - INFO - True
2024-04-07 07:31:35,167 - train - INFO - alphas:tensor([0.4388, 0.0166, 0.0309, 0.0745, 0.4393], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,167 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,167 - train - INFO - True
2024-04-07 07:31:35,173 - train - INFO - alphas:tensor([0.4739, 0.0279, 0.0693, 0.4290], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,174 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,174 - train - INFO - True
2024-04-07 07:31:35,180 - train - INFO - alphas:tensor([0.4234, 0.0271, 0.0528, 0.4967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,180 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,180 - train - INFO - True
2024-04-07 07:31:35,184 - train - INFO - alphas:tensor([0.4248, 0.0191, 0.0617, 0.4944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,184 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,184 - train - INFO - True
2024-04-07 07:31:35,185 - train - INFO - alphas:tensor([0.5090, 0.0278, 0.0527, 0.4106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,185 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,185 - train - INFO - True
2024-04-07 07:31:35,186 - train - INFO - alphas:tensor([0.5498, 0.0166, 0.0223, 0.0552, 0.3561], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,187 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,187 - train - INFO - True
2024-04-07 07:31:35,188 - train - INFO - alphas:tensor([0.2464, 0.0096, 0.0082, 0.0538, 0.6819], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,188 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,188 - train - INFO - True
2024-04-07 07:31:35,189 - train - INFO - alphas:tensor([0.2555, 0.0071, 0.0091, 0.0429, 0.6853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,189 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,189 - train - INFO - True
2024-04-07 07:31:35,190 - train - INFO - alphas:tensor([0.2576, 0.0051, 0.0080, 0.0471, 0.6822], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,190 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,190 - train - INFO - True
2024-04-07 07:31:35,191 - train - INFO - alphas:tensor([0.2403, 0.0082, 0.0083, 0.0542, 0.6891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,192 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,192 - train - INFO - True
2024-04-07 07:31:35,192 - train - INFO - alphas:tensor([0.5553, 0.0080, 0.0146, 0.0497, 0.3724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,193 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,193 - train - INFO - True
2024-04-07 07:31:35,194 - train - INFO - alphas:tensor([0.6537, 0.0097, 0.0123, 0.0360, 0.2883], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,196 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,196 - train - INFO - True
2024-04-07 07:31:35,197 - train - INFO - alphas:tensor([0.2635, 0.0174, 0.0180, 0.0895, 0.6116], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,198 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,198 - train - INFO - True
2024-04-07 07:31:35,199 - train - INFO - alphas:tensor([0.2778, 0.0105, 0.0132, 0.0846, 0.6139], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,200 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,200 - train - INFO - True
2024-04-07 07:31:35,201 - train - INFO - alphas:tensor([0.2981, 0.0078, 0.0126, 0.0751, 0.6064], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,202 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,202 - train - INFO - True
2024-04-07 07:31:35,203 - train - INFO - alphas:tensor([0.2703, 0.0121, 0.0153, 0.0728, 0.6294], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,204 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,204 - train - INFO - True
2024-04-07 07:31:35,205 - train - INFO - alphas:tensor([0.2982, 0.0082, 0.0166, 0.0750, 0.6020], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,206 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,206 - train - INFO - True
2024-04-07 07:31:35,207 - train - INFO - alphas:tensor([0.2549, 0.0187, 0.0230, 0.0857, 0.6177], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,208 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,208 - train - INFO - True
2024-04-07 07:31:35,209 - train - INFO - alphas:tensor([0.6044, 0.0058, 0.0101, 0.0486, 0.3311], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,211 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,211 - train - INFO - True
2024-04-07 07:31:35,212 - train - INFO - alphas:tensor([0.5380, 0.0055, 0.0072, 0.0487, 0.4006], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,216 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,216 - train - INFO - True
2024-04-07 07:31:35,217 - train - INFO - alphas:tensor([0.4122, 0.0049, 0.0132, 0.0672, 0.5025], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,220 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,220 - train - INFO - True
2024-04-07 07:31:35,220 - train - INFO - alphas:tensor([0.4312, 0.0051, 0.0075, 0.0599, 0.4963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,223 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,223 - train - INFO - True
2024-04-07 07:31:35,223 - train - INFO - alphas:tensor([0.4464, 0.0044, 0.0074, 0.0583, 0.4835], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,226 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,226 - train - INFO - True
2024-04-07 07:31:35,231 - train - INFO - alphas:tensor([0.4074, 0.0054, 0.0109, 0.0642, 0.5122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,234 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,234 - train - INFO - True
2024-04-07 07:31:35,240 - train - INFO - alphas:tensor([0.5556, 0.0044, 0.0090, 0.0408, 0.3903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,245 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,245 - train - INFO - True
2024-04-07 07:31:35,251 - train - INFO - alphas:tensor([0.7099, 0.0036, 0.0071, 0.0314, 0.2480], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,263 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,263 - train - INFO - True
2024-04-07 07:31:35,268 - train - INFO - alphas:tensor([0.3752, 0.0059, 0.0103, 0.0754, 0.5331], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,274 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,274 - train - INFO - True
2024-04-07 07:31:35,275 - train - INFO - alphas:tensor([0.3878, 0.0037, 0.0083, 0.0641, 0.5361], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,283 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,283 - train - INFO - True
2024-04-07 07:31:35,284 - train - INFO - alphas:tensor([0.4184, 0.0040, 0.0068, 0.0633, 0.5075], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,297 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,297 - train - INFO - True
2024-04-07 07:31:35,298 - train - INFO - alphas:tensor([0.3770, 0.0049, 0.0089, 0.0667, 0.5426], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,311 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,311 - train - INFO - True
2024-04-07 07:31:35,312 - train - INFO - alphas:tensor([0.7016, 0.0031, 0.0045, 0.0255, 0.2653], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,335 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,335 - train - INFO - True
2024-04-07 07:31:35,343 - train - INFO - alphas:tensor([0.5391, 0.0123, 0.0173, 0.0675, 0.3639], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:35,421 - train - INFO - tau:0.4213342221547681
2024-04-07 07:31:35,421 - train - INFO - avg block size:10.06060606060606
2024-04-07 07:31:35,422 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 07:31:35,422 - train - INFO - lasso_alpha:6.372616354207131e-06
2024-04-07 07:31:35,687 - train - INFO - Test: [   0/78]  Time: 0.262 (0.262)  Loss:  1.0537 (1.0537)  Acc@1: 80.4688 (80.4688)  Acc@5: 92.9688 (92.9688)
2024-04-07 07:31:41,336 - train - INFO - Test: [  50/78]  Time: 0.097 (0.116)  Loss:  1.6680 (1.5994)  Acc@1: 63.2812 (64.7059)  Acc@5: 85.1562 (85.9222)
2024-04-07 07:31:44,996 - train - INFO - Test: [  78/78]  Time: 0.095 (0.121)  Loss:  1.5146 (1.6145)  Acc@1: 68.7500 (64.8200)  Acc@5: 100.0000 (85.6300)
2024-04-07 07:31:45,735 - train - INFO - Train: 89 [   0/781 (  0%)]  Loss:  3.640280 (3.6403)  Time: 0.652s,  196.27/s  (0.652s,  196.27/s)  LR: 1.842e-04  Data: 0.179 (0.179)
2024-04-07 07:32:13,637 - train - INFO - Train: 89 [  50/781 (  6%)]  Loss:  3.496055 (3.6175)  Time: 0.548s,  233.72/s  (0.560s,  228.63/s)  LR: 1.842e-04  Data: 0.008 (0.011)
2024-04-07 07:32:40,382 - train - INFO - Train: 89 [ 100/781 ( 13%)]  Loss:  3.343979 (3.5828)  Time: 0.578s,  221.64/s  (0.547s,  233.82/s)  LR: 1.842e-04  Data: 0.008 (0.009)
2024-04-07 07:33:07,507 - train - INFO - Train: 89 [ 150/781 ( 19%)]  Loss:  3.697556 (3.5748)  Time: 0.550s,  232.58/s  (0.546s,  234.52/s)  LR: 1.842e-04  Data: 0.007 (0.009)
2024-04-07 07:33:33,777 - train - INFO - Train: 89 [ 200/781 ( 26%)]  Loss:  3.958406 (3.5551)  Time: 0.553s,  231.65/s  (0.541s,  236.73/s)  LR: 1.842e-04  Data: 0.008 (0.008)
2024-04-07 07:34:00,260 - train - INFO - Train: 89 [ 250/781 ( 32%)]  Loss:  3.368625 (3.5517)  Time: 0.533s,  239.94/s  (0.539s,  237.70/s)  LR: 1.842e-04  Data: 0.009 (0.008)
2024-04-07 07:34:28,226 - train - INFO - Train: 89 [ 300/781 ( 38%)]  Loss:  3.422721 (3.5507)  Time: 0.572s,  223.81/s  (0.542s,  236.18/s)  LR: 1.842e-04  Data: 0.008 (0.008)
2024-04-07 07:34:54,938 - train - INFO - Train: 89 [ 350/781 ( 45%)]  Loss:  3.209242 (3.5496)  Time: 0.517s,  247.42/s  (0.541s,  236.67/s)  LR: 1.842e-04  Data: 0.008 (0.008)
2024-04-07 07:35:21,938 - train - INFO - Train: 89 [ 400/781 ( 51%)]  Loss:  3.314493 (3.5511)  Time: 0.574s,  223.15/s  (0.541s,  236.71/s)  LR: 1.842e-04  Data: 0.007 (0.008)
2024-04-07 07:35:49,181 - train - INFO - Train: 89 [ 450/781 ( 58%)]  Loss:  3.804641 (3.5552)  Time: 0.439s,  291.71/s  (0.541s,  236.51/s)  LR: 1.842e-04  Data: 0.004 (0.008)
2024-04-07 07:36:14,543 - train - INFO - Train: 89 [ 500/781 ( 64%)]  Loss:  3.757875 (3.5592)  Time: 0.553s,  231.60/s  (0.538s,  238.01/s)  LR: 1.842e-04  Data: 0.009 (0.008)
2024-04-07 07:36:41,888 - train - INFO - Train: 89 [ 550/781 ( 71%)]  Loss:  3.746089 (3.5577)  Time: 0.548s,  233.38/s  (0.539s,  237.64/s)  LR: 1.842e-04  Data: 0.009 (0.008)
2024-04-07 07:37:08,526 - train - INFO - Train: 89 [ 600/781 ( 77%)]  Loss:  3.394986 (3.5551)  Time: 0.502s,  255.23/s  (0.538s,  237.86/s)  LR: 1.842e-04  Data: 0.007 (0.008)
2024-04-07 07:37:36,007 - train - INFO - Train: 89 [ 650/781 ( 83%)]  Loss:  3.810178 (3.5478)  Time: 0.542s,  236.20/s  (0.539s,  237.47/s)  LR: 1.842e-04  Data: 0.006 (0.008)
2024-04-07 07:38:02,155 - train - INFO - Train: 89 [ 700/781 ( 90%)]  Loss:  3.536693 (3.5492)  Time: 0.503s,  254.27/s  (0.538s,  237.98/s)  LR: 1.842e-04  Data: 0.005 (0.008)
2024-04-07 07:38:28,097 - train - INFO - Train: 89 [ 750/781 ( 96%)]  Loss:  3.869474 (3.5512)  Time: 0.544s,  235.09/s  (0.537s,  238.54/s)  LR: 1.842e-04  Data: 0.005 (0.008)
2024-04-07 07:38:44,097 - train - INFO - Train: 89 [ 780/781 (100%)]  Loss:  3.742395 (3.5541)  Time: 0.543s,  235.68/s  (0.536s,  238.60/s)  LR: 1.842e-04  Data: 0.000 (0.008)
2024-04-07 07:38:44,098 - train - INFO - True
2024-04-07 07:38:44,100 - train - INFO - alphas:tensor([0.6365, 0.0389, 0.0580, 0.0812, 0.1854], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,101 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,102 - train - INFO - True
2024-04-07 07:38:44,103 - train - INFO - alphas:tensor([0.4420, 0.0160, 0.0304, 0.0736, 0.4381], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,104 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,104 - train - INFO - True
2024-04-07 07:38:44,106 - train - INFO - alphas:tensor([0.4774, 0.0272, 0.0689, 0.4266], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,107 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,108 - train - INFO - True
2024-04-07 07:38:44,109 - train - INFO - alphas:tensor([0.4261, 0.0266, 0.0518, 0.4955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,110 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,110 - train - INFO - True
2024-04-07 07:38:44,112 - train - INFO - alphas:tensor([0.4256, 0.0187, 0.0606, 0.4950], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,112 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,113 - train - INFO - True
2024-04-07 07:38:44,114 - train - INFO - alphas:tensor([0.5154, 0.0271, 0.0513, 0.4061], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,115 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,116 - train - INFO - True
2024-04-07 07:38:44,123 - train - INFO - alphas:tensor([0.5530, 0.0162, 0.0217, 0.0540, 0.3551], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,125 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,125 - train - INFO - True
2024-04-07 07:38:44,133 - train - INFO - alphas:tensor([0.2464, 0.0094, 0.0080, 0.0534, 0.6829], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,134 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,134 - train - INFO - True
2024-04-07 07:38:44,142 - train - INFO - alphas:tensor([0.2569, 0.0070, 0.0089, 0.0422, 0.6851], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,143 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,143 - train - INFO - True
2024-04-07 07:38:44,151 - train - INFO - alphas:tensor([0.2581, 0.0049, 0.0078, 0.0463, 0.6828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,152 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,153 - train - INFO - True
2024-04-07 07:38:44,161 - train - INFO - alphas:tensor([0.2442, 0.0080, 0.0081, 0.0539, 0.6859], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,162 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,162 - train - INFO - True
2024-04-07 07:38:44,166 - train - INFO - alphas:tensor([0.5580, 0.0077, 0.0142, 0.0488, 0.3713], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,167 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,167 - train - INFO - True
2024-04-07 07:38:44,168 - train - INFO - alphas:tensor([0.6594, 0.0094, 0.0119, 0.0351, 0.2842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,172 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,173 - train - INFO - True
2024-04-07 07:38:44,174 - train - INFO - alphas:tensor([0.2634, 0.0172, 0.0178, 0.0892, 0.6124], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,176 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,176 - train - INFO - True
2024-04-07 07:38:44,177 - train - INFO - alphas:tensor([0.2815, 0.0101, 0.0129, 0.0844, 0.6111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,179 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,179 - train - INFO - True
2024-04-07 07:38:44,180 - train - INFO - alphas:tensor([0.2988, 0.0077, 0.0123, 0.0748, 0.6064], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,183 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,183 - train - INFO - True
2024-04-07 07:38:44,184 - train - INFO - alphas:tensor([0.2735, 0.0118, 0.0152, 0.0721, 0.6274], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,186 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,186 - train - INFO - True
2024-04-07 07:38:44,187 - train - INFO - alphas:tensor([0.3038, 0.0080, 0.0163, 0.0737, 0.5982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,189 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,189 - train - INFO - True
2024-04-07 07:38:44,190 - train - INFO - alphas:tensor([0.2611, 0.0182, 0.0227, 0.0849, 0.6132], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,192 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,192 - train - INFO - True
2024-04-07 07:38:44,193 - train - INFO - alphas:tensor([0.6049, 0.0056, 0.0098, 0.0481, 0.3316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,197 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,197 - train - INFO - True
2024-04-07 07:38:44,198 - train - INFO - alphas:tensor([0.5402, 0.0053, 0.0069, 0.0479, 0.3997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,206 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,206 - train - INFO - True
2024-04-07 07:38:44,207 - train - INFO - alphas:tensor([0.4183, 0.0048, 0.0128, 0.0670, 0.4971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,211 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,211 - train - INFO - True
2024-04-07 07:38:44,219 - train - INFO - alphas:tensor([0.4369, 0.0049, 0.0072, 0.0599, 0.4911], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,223 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,223 - train - INFO - True
2024-04-07 07:38:44,229 - train - INFO - alphas:tensor([0.4488, 0.0042, 0.0071, 0.0572, 0.4826], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,233 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,233 - train - INFO - True
2024-04-07 07:38:44,238 - train - INFO - alphas:tensor([0.4124, 0.0052, 0.0106, 0.0634, 0.5084], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,242 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,242 - train - INFO - True
2024-04-07 07:38:44,247 - train - INFO - alphas:tensor([0.5569, 0.0043, 0.0088, 0.0406, 0.3894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,254 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,254 - train - INFO - True
2024-04-07 07:38:44,256 - train - INFO - alphas:tensor([0.7103, 0.0035, 0.0069, 0.0313, 0.2481], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,275 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,276 - train - INFO - True
2024-04-07 07:38:44,276 - train - INFO - alphas:tensor([0.3798, 0.0057, 0.0098, 0.0745, 0.5302], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,287 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,287 - train - INFO - True
2024-04-07 07:38:44,288 - train - INFO - alphas:tensor([0.3904, 0.0036, 0.0080, 0.0636, 0.5344], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,298 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,298 - train - INFO - True
2024-04-07 07:38:44,307 - train - INFO - alphas:tensor([0.4184, 0.0039, 0.0066, 0.0635, 0.5076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,317 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,317 - train - INFO - True
2024-04-07 07:38:44,324 - train - INFO - alphas:tensor([0.3837, 0.0047, 0.0088, 0.0659, 0.5368], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,334 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,334 - train - INFO - True
2024-04-07 07:38:44,341 - train - INFO - alphas:tensor([0.7057, 0.0029, 0.0043, 0.0249, 0.2621], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,361 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,361 - train - INFO - True
2024-04-07 07:38:44,362 - train - INFO - alphas:tensor([0.5441, 0.0120, 0.0171, 0.0667, 0.3600], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:38:44,439 - train - INFO - tau:0.41712087993322045
2024-04-07 07:38:44,439 - train - INFO - avg block size:9.606060606060606
2024-04-07 07:38:44,440 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 07:38:44,729 - train - INFO - Test: [   0/78]  Time: 0.286 (0.286)  Loss:  0.9629 (0.9629)  Acc@1: 80.4688 (80.4688)  Acc@5: 92.9688 (92.9688)
2024-04-07 07:38:49,613 - train - INFO - Test: [  50/78]  Time: 0.054 (0.101)  Loss:  1.5918 (1.5839)  Acc@1: 63.2812 (64.5680)  Acc@5: 84.3750 (85.8303)
2024-04-07 07:38:52,937 - train - INFO - Test: [  78/78]  Time: 0.095 (0.108)  Loss:  1.7764 (1.5986)  Acc@1: 68.7500 (64.7100)  Acc@5: 100.0000 (85.5600)
2024-04-07 07:38:53,603 - train - INFO - Train: 90 [   0/781 (  0%)]  Loss:  3.590636 (3.5906)  Time: 0.585s,  218.88/s  (0.585s,  218.88/s)  LR: 1.793e-04  Data: 0.176 (0.176)
2024-04-07 07:39:18,475 - train - INFO - Train: 90 [  50/781 (  6%)]  Loss:  3.202209 (3.5885)  Time: 0.469s,  273.12/s  (0.499s,  256.45/s)  LR: 1.793e-04  Data: 0.005 (0.010)
2024-04-07 07:39:45,067 - train - INFO - Train: 90 [ 100/781 ( 13%)]  Loss:  3.506164 (3.5967)  Time: 0.529s,  241.92/s  (0.515s,  248.40/s)  LR: 1.793e-04  Data: 0.008 (0.009)
2024-04-07 07:40:10,186 - train - INFO - Train: 90 [ 150/781 ( 19%)]  Loss:  3.860030 (3.5803)  Time: 0.364s,  351.78/s  (0.511s,  250.48/s)  LR: 1.793e-04  Data: 0.004 (0.008)
2024-04-07 07:40:36,311 - train - INFO - Train: 90 [ 200/781 ( 26%)]  Loss:  3.157605 (3.5862)  Time: 0.493s,  259.46/s  (0.514s,  249.09/s)  LR: 1.793e-04  Data: 0.007 (0.008)
2024-04-07 07:41:03,364 - train - INFO - Train: 90 [ 250/781 ( 32%)]  Loss:  3.260725 (3.5718)  Time: 0.441s,  290.45/s  (0.519s,  246.50/s)  LR: 1.793e-04  Data: 0.004 (0.008)
2024-04-07 07:41:30,548 - train - INFO - Train: 90 [ 300/781 ( 38%)]  Loss:  3.343627 (3.5768)  Time: 0.497s,  257.34/s  (0.523s,  244.59/s)  LR: 1.793e-04  Data: 0.008 (0.008)
2024-04-07 07:41:57,370 - train - INFO - Train: 90 [ 350/781 ( 45%)]  Loss:  3.609108 (3.5759)  Time: 1.113s,  115.02/s  (0.525s,  243.72/s)  LR: 1.793e-04  Data: 0.007 (0.008)
2024-04-07 07:42:23,738 - train - INFO - Train: 90 [ 400/781 ( 51%)]  Loss:  3.100082 (3.5682)  Time: 0.539s,  237.57/s  (0.525s,  243.60/s)  LR: 1.793e-04  Data: 0.006 (0.008)
2024-04-07 07:42:50,963 - train - INFO - Train: 90 [ 450/781 ( 58%)]  Loss:  3.130900 (3.5619)  Time: 0.491s,  260.46/s  (0.528s,  242.62/s)  LR: 1.793e-04  Data: 0.008 (0.008)
2024-04-07 07:43:15,536 - train - INFO - Train: 90 [ 500/781 ( 64%)]  Loss:  3.620751 (3.5618)  Time: 0.538s,  238.12/s  (0.524s,  244.29/s)  LR: 1.793e-04  Data: 0.007 (0.008)
2024-04-07 07:43:42,585 - train - INFO - Train: 90 [ 550/781 ( 71%)]  Loss:  3.227982 (3.5609)  Time: 0.522s,  245.00/s  (0.526s,  243.58/s)  LR: 1.793e-04  Data: 0.009 (0.008)
2024-04-07 07:44:08,973 - train - INFO - Train: 90 [ 600/781 ( 77%)]  Loss:  3.268275 (3.5614)  Time: 0.560s,  228.74/s  (0.526s,  243.49/s)  LR: 1.793e-04  Data: 0.008 (0.008)
2024-04-07 07:44:36,065 - train - INFO - Train: 90 [ 650/781 ( 83%)]  Loss:  3.185310 (3.5560)  Time: 0.491s,  260.51/s  (0.527s,  242.92/s)  LR: 1.793e-04  Data: 0.009 (0.008)
2024-04-07 07:45:02,188 - train - INFO - Train: 90 [ 700/781 ( 90%)]  Loss:  3.607525 (3.5564)  Time: 1.096s,  116.77/s  (0.527s,  243.07/s)  LR: 1.793e-04  Data: 0.005 (0.008)
2024-04-07 07:45:28,688 - train - INFO - Train: 90 [ 750/781 ( 96%)]  Loss:  3.270414 (3.5546)  Time: 0.583s,  219.41/s  (0.527s,  242.96/s)  LR: 1.793e-04  Data: 0.009 (0.008)
2024-04-07 07:45:44,696 - train - INFO - Train: 90 [ 780/781 (100%)]  Loss:  3.376860 (3.5569)  Time: 0.469s,  272.86/s  (0.527s,  242.85/s)  LR: 1.793e-04  Data: 0.000 (0.008)
2024-04-07 07:45:44,696 - train - INFO - True
2024-04-07 07:45:44,705 - train - INFO - alphas:tensor([0.6405, 0.0382, 0.0571, 0.0801, 0.1841], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,705 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,706 - train - INFO - True
2024-04-07 07:45:44,712 - train - INFO - alphas:tensor([0.4417, 0.0156, 0.0298, 0.0729, 0.4400], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,712 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,713 - train - INFO - True
2024-04-07 07:45:44,719 - train - INFO - alphas:tensor([0.4773, 0.0263, 0.0679, 0.4284], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,720 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,720 - train - INFO - True
2024-04-07 07:45:44,721 - train - INFO - alphas:tensor([0.4286, 0.0260, 0.0508, 0.4946], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,721 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,721 - train - INFO - True
2024-04-07 07:45:44,722 - train - INFO - alphas:tensor([0.4301, 0.0183, 0.0596, 0.4921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,722 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,722 - train - INFO - True
2024-04-07 07:45:44,723 - train - INFO - alphas:tensor([0.5137, 0.0267, 0.0508, 0.4088], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,723 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,724 - train - INFO - True
2024-04-07 07:45:44,724 - train - INFO - alphas:tensor([0.5561, 0.0157, 0.0211, 0.0531, 0.3541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,725 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,725 - train - INFO - True
2024-04-07 07:45:44,726 - train - INFO - alphas:tensor([0.2492, 0.0090, 0.0076, 0.0525, 0.6817], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,727 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,727 - train - INFO - True
2024-04-07 07:45:44,727 - train - INFO - alphas:tensor([0.2576, 0.0067, 0.0085, 0.0409, 0.6862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,728 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,728 - train - INFO - True
2024-04-07 07:45:44,729 - train - INFO - alphas:tensor([0.2611, 0.0047, 0.0075, 0.0464, 0.6803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,729 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,729 - train - INFO - True
2024-04-07 07:45:44,730 - train - INFO - alphas:tensor([0.2456, 0.0078, 0.0078, 0.0528, 0.6860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,731 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,731 - train - INFO - True
2024-04-07 07:45:44,731 - train - INFO - alphas:tensor([0.5562, 0.0074, 0.0138, 0.0480, 0.3745], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,732 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,732 - train - INFO - True
2024-04-07 07:45:44,733 - train - INFO - alphas:tensor([0.6605, 0.0090, 0.0115, 0.0345, 0.2845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,736 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,736 - train - INFO - True
2024-04-07 07:45:44,736 - train - INFO - alphas:tensor([0.2667, 0.0170, 0.0175, 0.0877, 0.6111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,738 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,738 - train - INFO - True
2024-04-07 07:45:44,739 - train - INFO - alphas:tensor([0.2826, 0.0098, 0.0125, 0.0829, 0.6122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,740 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,740 - train - INFO - True
2024-04-07 07:45:44,741 - train - INFO - alphas:tensor([0.3040, 0.0075, 0.0120, 0.0748, 0.6018], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,742 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,742 - train - INFO - True
2024-04-07 07:45:44,743 - train - INFO - alphas:tensor([0.2794, 0.0115, 0.0147, 0.0711, 0.6232], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,744 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,744 - train - INFO - True
2024-04-07 07:45:44,745 - train - INFO - alphas:tensor([0.3089, 0.0078, 0.0158, 0.0729, 0.5945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,746 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,747 - train - INFO - True
2024-04-07 07:45:44,747 - train - INFO - alphas:tensor([0.2615, 0.0178, 0.0223, 0.0833, 0.6152], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,749 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,749 - train - INFO - True
2024-04-07 07:45:44,749 - train - INFO - alphas:tensor([0.6104, 0.0054, 0.0095, 0.0470, 0.3277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,752 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,752 - train - INFO - True
2024-04-07 07:45:44,753 - train - INFO - alphas:tensor([0.5424, 0.0052, 0.0067, 0.0475, 0.3983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,760 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,760 - train - INFO - True
2024-04-07 07:45:44,761 - train - INFO - alphas:tensor([0.4178, 0.0046, 0.0123, 0.0660, 0.4993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,764 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,764 - train - INFO - True
2024-04-07 07:45:44,769 - train - INFO - alphas:tensor([0.4333, 0.0047, 0.0071, 0.0592, 0.4957], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,772 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,772 - train - INFO - True
2024-04-07 07:45:44,778 - train - INFO - alphas:tensor([0.4493, 0.0040, 0.0069, 0.0561, 0.4837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,781 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,781 - train - INFO - True
2024-04-07 07:45:44,787 - train - INFO - alphas:tensor([0.4163, 0.0050, 0.0102, 0.0617, 0.5068], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,790 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,790 - train - INFO - True
2024-04-07 07:45:44,796 - train - INFO - alphas:tensor([0.5566, 0.0041, 0.0085, 0.0401, 0.3907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,801 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,801 - train - INFO - True
2024-04-07 07:45:44,807 - train - INFO - alphas:tensor([0.7172, 0.0033, 0.0067, 0.0301, 0.2427], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,819 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,819 - train - INFO - True
2024-04-07 07:45:44,820 - train - INFO - alphas:tensor([0.3805, 0.0055, 0.0094, 0.0730, 0.5315], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,826 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,826 - train - INFO - True
2024-04-07 07:45:44,826 - train - INFO - alphas:tensor([0.3949, 0.0035, 0.0077, 0.0624, 0.5315], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,832 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,832 - train - INFO - True
2024-04-07 07:45:44,833 - train - INFO - alphas:tensor([0.4273, 0.0037, 0.0063, 0.0627, 0.5000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,839 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,839 - train - INFO - True
2024-04-07 07:45:44,840 - train - INFO - alphas:tensor([0.3862, 0.0046, 0.0086, 0.0661, 0.5344], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,846 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,846 - train - INFO - True
2024-04-07 07:45:44,846 - train - INFO - alphas:tensor([0.7078, 0.0028, 0.0042, 0.0245, 0.2607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,859 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,859 - train - INFO - True
2024-04-07 07:45:44,865 - train - INFO - alphas:tensor([0.5501, 0.0117, 0.0167, 0.0660, 0.3556], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:45:44,918 - train - INFO - tau:0.41294967113388825
2024-04-07 07:45:44,918 - train - INFO - avg block size:9.606060606060606
2024-04-07 07:45:44,919 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 07:45:44,919 - train - INFO - lasso_alpha:7.009877989627845e-06
2024-04-07 07:45:45,190 - train - INFO - Test: [   0/78]  Time: 0.269 (0.269)  Loss:  0.9526 (0.9526)  Acc@1: 81.2500 (81.2500)  Acc@5: 92.9688 (92.9688)
2024-04-07 07:45:50,321 - train - INFO - Test: [  50/78]  Time: 0.057 (0.106)  Loss:  1.6729 (1.5822)  Acc@1: 61.7188 (65.1195)  Acc@5: 87.5000 (86.1213)
2024-04-07 07:45:53,164 - train - INFO - Test: [  78/78]  Time: 0.097 (0.104)  Loss:  1.9639 (1.6136)  Acc@1: 43.7500 (64.3400)  Acc@5: 93.7500 (85.6000)
2024-04-07 07:45:53,885 - train - INFO - Train: 91 [   0/781 (  0%)]  Loss:  3.900840 (3.9008)  Time: 0.635s,  201.55/s  (0.635s,  201.55/s)  LR: 1.744e-04  Data: 0.154 (0.154)
2024-04-07 07:46:20,972 - train - INFO - Train: 91 [  50/781 (  6%)]  Loss:  3.537239 (3.5532)  Time: 0.527s,  242.72/s  (0.544s,  235.50/s)  LR: 1.744e-04  Data: 0.009 (0.010)
2024-04-07 07:46:47,924 - train - INFO - Train: 91 [ 100/781 ( 13%)]  Loss:  3.313477 (3.5319)  Time: 0.582s,  220.03/s  (0.541s,  236.47/s)  LR: 1.744e-04  Data: 0.011 (0.009)
2024-04-07 07:47:13,859 - train - INFO - Train: 91 [ 150/781 ( 19%)]  Loss:  3.865202 (3.5310)  Time: 0.514s,  249.25/s  (0.534s,  239.79/s)  LR: 1.744e-04  Data: 0.010 (0.008)
2024-04-07 07:47:41,615 - train - INFO - Train: 91 [ 200/781 ( 26%)]  Loss:  3.951738 (3.5399)  Time: 0.542s,  236.02/s  (0.539s,  237.43/s)  LR: 1.744e-04  Data: 0.009 (0.008)
2024-04-07 07:48:08,142 - train - INFO - Train: 91 [ 250/781 ( 32%)]  Loss:  3.389584 (3.5404)  Time: 0.493s,  259.78/s  (0.537s,  238.19/s)  LR: 1.744e-04  Data: 0.009 (0.008)
2024-04-07 07:48:33,054 - train - INFO - Train: 91 [ 300/781 ( 38%)]  Loss:  3.677988 (3.5361)  Time: 0.520s,  246.26/s  (0.531s,  241.11/s)  LR: 1.744e-04  Data: 0.006 (0.008)
2024-04-07 07:49:00,382 - train - INFO - Train: 91 [ 350/781 ( 45%)]  Loss:  3.811676 (3.5451)  Time: 0.526s,  243.30/s  (0.533s,  240.10/s)  LR: 1.744e-04  Data: 0.006 (0.008)
2024-04-07 07:49:27,020 - train - INFO - Train: 91 [ 400/781 ( 51%)]  Loss:  3.477277 (3.5459)  Time: 0.486s,  263.58/s  (0.533s,  240.12/s)  LR: 1.744e-04  Data: 0.009 (0.008)
2024-04-07 07:49:54,048 - train - INFO - Train: 91 [ 450/781 ( 58%)]  Loss:  3.777291 (3.5381)  Time: 0.567s,  225.70/s  (0.534s,  239.75/s)  LR: 1.744e-04  Data: 0.008 (0.008)
2024-04-07 07:50:20,065 - train - INFO - Train: 91 [ 500/781 ( 64%)]  Loss:  3.780338 (3.5357)  Time: 0.545s,  234.86/s  (0.533s,  240.36/s)  LR: 1.744e-04  Data: 0.008 (0.008)
2024-04-07 07:50:46,542 - train - INFO - Train: 91 [ 550/781 ( 71%)]  Loss:  3.863763 (3.5372)  Time: 0.570s,  224.48/s  (0.532s,  240.48/s)  LR: 1.744e-04  Data: 0.014 (0.008)
2024-04-07 07:51:13,464 - train - INFO - Train: 91 [ 600/781 ( 77%)]  Loss:  3.688699 (3.5392)  Time: 0.508s,  251.74/s  (0.533s,  240.25/s)  LR: 1.744e-04  Data: 0.008 (0.008)
2024-04-07 07:51:39,245 - train - INFO - Train: 91 [ 650/781 ( 83%)]  Loss:  3.594529 (3.5415)  Time: 0.544s,  235.39/s  (0.531s,  240.85/s)  LR: 1.744e-04  Data: 0.008 (0.008)
2024-04-07 07:52:05,745 - train - INFO - Train: 91 [ 700/781 ( 90%)]  Loss:  3.832309 (3.5447)  Time: 0.564s,  226.84/s  (0.531s,  240.90/s)  LR: 1.744e-04  Data: 0.008 (0.008)
2024-04-07 07:52:32,390 - train - INFO - Train: 91 [ 750/781 ( 96%)]  Loss:  3.515030 (3.5444)  Time: 0.539s,  237.45/s  (0.531s,  240.85/s)  LR: 1.744e-04  Data: 0.008 (0.008)
2024-04-07 07:52:48,635 - train - INFO - Train: 91 [ 780/781 (100%)]  Loss:  3.881962 (3.5426)  Time: 0.515s,  248.60/s  (0.532s,  240.68/s)  LR: 1.744e-04  Data: 0.000 (0.008)
2024-04-07 07:52:48,637 - train - INFO - True
2024-04-07 07:52:48,642 - train - INFO - alphas:tensor([0.6443, 0.0374, 0.0560, 0.0792, 0.1831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,643 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,643 - train - INFO - True
2024-04-07 07:52:48,644 - train - INFO - alphas:tensor([0.4444, 0.0153, 0.0292, 0.0719, 0.4393], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,645 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,645 - train - INFO - True
2024-04-07 07:52:48,650 - train - INFO - alphas:tensor([0.4780, 0.0258, 0.0671, 0.4291], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,651 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,651 - train - INFO - True
2024-04-07 07:52:48,656 - train - INFO - alphas:tensor([0.4272, 0.0255, 0.0499, 0.4974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,657 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,657 - train - INFO - True
2024-04-07 07:52:48,662 - train - INFO - alphas:tensor([0.4279, 0.0178, 0.0590, 0.4953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,663 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,663 - train - INFO - True
2024-04-07 07:52:48,669 - train - INFO - alphas:tensor([0.5135, 0.0261, 0.0501, 0.4102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,670 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,670 - train - INFO - True
2024-04-07 07:52:48,675 - train - INFO - alphas:tensor([0.5598, 0.0152, 0.0204, 0.0519, 0.3526], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,676 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,676 - train - INFO - True
2024-04-07 07:52:48,679 - train - INFO - alphas:tensor([0.2485, 0.0087, 0.0073, 0.0520, 0.6834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,680 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,680 - train - INFO - True
2024-04-07 07:52:48,681 - train - INFO - alphas:tensor([0.2556, 0.0065, 0.0083, 0.0401, 0.6894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,682 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,682 - train - INFO - True
2024-04-07 07:52:48,683 - train - INFO - alphas:tensor([0.2586, 0.0046, 0.0072, 0.0453, 0.6842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,684 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,684 - train - INFO - True
2024-04-07 07:52:48,685 - train - INFO - alphas:tensor([0.2433, 0.0075, 0.0077, 0.0531, 0.6884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,686 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,686 - train - INFO - True
2024-04-07 07:52:48,687 - train - INFO - alphas:tensor([0.5591, 0.0071, 0.0133, 0.0468, 0.3736], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,688 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,689 - train - INFO - True
2024-04-07 07:52:48,690 - train - INFO - alphas:tensor([0.6574, 0.0087, 0.0113, 0.0341, 0.2885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,694 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,694 - train - INFO - True
2024-04-07 07:52:48,695 - train - INFO - alphas:tensor([0.2655, 0.0167, 0.0170, 0.0877, 0.6131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,697 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,697 - train - INFO - True
2024-04-07 07:52:48,698 - train - INFO - alphas:tensor([0.2810, 0.0094, 0.0122, 0.0822, 0.6153], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,700 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,700 - train - INFO - True
2024-04-07 07:52:48,701 - train - INFO - alphas:tensor([0.3015, 0.0072, 0.0115, 0.0732, 0.6065], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,703 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,703 - train - INFO - True
2024-04-07 07:52:48,704 - train - INFO - alphas:tensor([0.2766, 0.0112, 0.0142, 0.0703, 0.6277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,707 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,707 - train - INFO - True
2024-04-07 07:52:48,708 - train - INFO - alphas:tensor([0.3050, 0.0076, 0.0154, 0.0723, 0.5997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,710 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,710 - train - INFO - True
2024-04-07 07:52:48,711 - train - INFO - alphas:tensor([0.2622, 0.0173, 0.0218, 0.0824, 0.6163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,713 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,713 - train - INFO - True
2024-04-07 07:52:48,714 - train - INFO - alphas:tensor([0.6105, 0.0051, 0.0093, 0.0466, 0.3285], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,717 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,717 - train - INFO - True
2024-04-07 07:52:48,718 - train - INFO - alphas:tensor([0.5422, 0.0050, 0.0064, 0.0469, 0.3996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,726 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,726 - train - INFO - True
2024-04-07 07:52:48,727 - train - INFO - alphas:tensor([0.4193, 0.0044, 0.0122, 0.0651, 0.4989], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,731 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,731 - train - INFO - True
2024-04-07 07:52:48,735 - train - INFO - alphas:tensor([0.4331, 0.0045, 0.0069, 0.0590, 0.4966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,739 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,739 - train - INFO - True
2024-04-07 07:52:48,745 - train - INFO - alphas:tensor([0.4448, 0.0039, 0.0067, 0.0562, 0.4885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,749 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,749 - train - INFO - True
2024-04-07 07:52:48,754 - train - INFO - alphas:tensor([0.4158, 0.0048, 0.0099, 0.0615, 0.5081], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,758 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,758 - train - INFO - True
2024-04-07 07:52:48,764 - train - INFO - alphas:tensor([0.5594, 0.0039, 0.0083, 0.0396, 0.3889], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,771 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,771 - train - INFO - True
2024-04-07 07:52:48,776 - train - INFO - alphas:tensor([0.7128, 0.0032, 0.0066, 0.0299, 0.2475], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,796 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,796 - train - INFO - True
2024-04-07 07:52:48,797 - train - INFO - alphas:tensor([0.3812, 0.0053, 0.0091, 0.0723, 0.5321], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,807 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,807 - train - INFO - True
2024-04-07 07:52:48,808 - train - INFO - alphas:tensor([0.3882, 0.0033, 0.0073, 0.0613, 0.5398], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,819 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,819 - train - INFO - True
2024-04-07 07:52:48,820 - train - INFO - alphas:tensor([0.4186, 0.0036, 0.0062, 0.0627, 0.5089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,830 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,830 - train - INFO - True
2024-04-07 07:52:48,831 - train - INFO - alphas:tensor([0.3800, 0.0044, 0.0084, 0.0659, 0.5413], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,841 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,841 - train - INFO - True
2024-04-07 07:52:48,847 - train - INFO - alphas:tensor([0.7065, 0.0027, 0.0041, 0.0244, 0.2624], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,867 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,867 - train - INFO - True
2024-04-07 07:52:48,873 - train - INFO - alphas:tensor([0.5453, 0.0114, 0.0163, 0.0654, 0.3616], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:52:48,950 - train - INFO - tau:0.40882017442254937
2024-04-07 07:52:48,950 - train - INFO - avg block size:9.606060606060606
2024-04-07 07:52:48,951 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 07:52:49,213 - train - INFO - Test: [   0/78]  Time: 0.259 (0.259)  Loss:  0.9712 (0.9712)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.9688 (92.9688)
2024-04-07 07:52:54,535 - train - INFO - Test: [  50/78]  Time: 0.103 (0.109)  Loss:  1.7832 (1.5740)  Acc@1: 59.3750 (65.3033)  Acc@5: 82.0312 (85.6924)
2024-04-07 07:52:57,369 - train - INFO - Test: [  78/78]  Time: 0.091 (0.107)  Loss:  1.6221 (1.5878)  Acc@1: 68.7500 (65.2800)  Acc@5: 100.0000 (85.4000)
2024-04-07 07:52:58,132 - train - INFO - Train: 92 [   0/781 (  0%)]  Loss:  3.869514 (3.8695)  Time: 0.674s,  189.86/s  (0.674s,  189.86/s)  LR: 1.696e-04  Data: 0.153 (0.153)
2024-04-07 07:53:25,384 - train - INFO - Train: 92 [  50/781 (  6%)]  Loss:  3.360273 (3.5338)  Time: 0.550s,  232.64/s  (0.548s,  233.77/s)  LR: 1.696e-04  Data: 0.017 (0.011)
2024-04-07 07:53:51,851 - train - INFO - Train: 92 [ 100/781 ( 13%)]  Loss:  3.869785 (3.5445)  Time: 0.428s,  299.10/s  (0.539s,  237.69/s)  LR: 1.696e-04  Data: 0.005 (0.009)
2024-04-07 07:54:18,221 - train - INFO - Train: 92 [ 150/781 ( 19%)]  Loss:  3.697142 (3.5420)  Time: 0.455s,  281.04/s  (0.535s,  239.33/s)  LR: 1.696e-04  Data: 0.010 (0.009)
2024-04-07 07:54:44,866 - train - INFO - Train: 92 [ 200/781 ( 26%)]  Loss:  3.800902 (3.5388)  Time: 0.539s,  237.53/s  (0.534s,  239.55/s)  LR: 1.696e-04  Data: 0.007 (0.008)
2024-04-07 07:55:11,941 - train - INFO - Train: 92 [ 250/781 ( 32%)]  Loss:  3.526610 (3.5448)  Time: 0.590s,  216.84/s  (0.536s,  238.91/s)  LR: 1.696e-04  Data: 0.008 (0.008)
2024-04-07 07:55:38,203 - train - INFO - Train: 92 [ 300/781 ( 38%)]  Loss:  3.881137 (3.5494)  Time: 0.628s,  203.98/s  (0.534s,  239.70/s)  LR: 1.696e-04  Data: 0.009 (0.008)
2024-04-07 07:56:03,637 - train - INFO - Train: 92 [ 350/781 ( 45%)]  Loss:  3.385038 (3.5535)  Time: 0.619s,  206.72/s  (0.530s,  241.33/s)  LR: 1.696e-04  Data: 0.014 (0.008)
2024-04-07 07:56:30,334 - train - INFO - Train: 92 [ 400/781 ( 51%)]  Loss:  3.611403 (3.5575)  Time: 0.408s,  313.75/s  (0.531s,  241.13/s)  LR: 1.696e-04  Data: 0.008 (0.008)
2024-04-07 07:56:57,224 - train - INFO - Train: 92 [ 450/781 ( 58%)]  Loss:  3.706950 (3.5541)  Time: 0.537s,  238.57/s  (0.532s,  240.78/s)  LR: 1.696e-04  Data: 0.011 (0.008)
2024-04-07 07:57:23,702 - train - INFO - Train: 92 [ 500/781 ( 64%)]  Loss:  3.633997 (3.5542)  Time: 0.561s,  228.07/s  (0.531s,  240.88/s)  LR: 1.696e-04  Data: 0.006 (0.008)
2024-04-07 07:57:50,217 - train - INFO - Train: 92 [ 550/781 ( 71%)]  Loss:  3.697995 (3.5525)  Time: 0.522s,  245.36/s  (0.531s,  240.92/s)  LR: 1.696e-04  Data: 0.009 (0.008)
2024-04-07 07:58:16,319 - train - INFO - Train: 92 [ 600/781 ( 77%)]  Loss:  3.634544 (3.5497)  Time: 0.528s,  242.55/s  (0.531s,  241.27/s)  LR: 1.696e-04  Data: 0.009 (0.008)
2024-04-07 07:58:43,464 - train - INFO - Train: 92 [ 650/781 ( 83%)]  Loss:  3.896543 (3.5495)  Time: 0.602s,  212.45/s  (0.531s,  240.84/s)  LR: 1.696e-04  Data: 0.010 (0.008)
2024-04-07 07:59:10,149 - train - INFO - Train: 92 [ 700/781 ( 90%)]  Loss:  3.472007 (3.5500)  Time: 0.555s,  230.73/s  (0.532s,  240.77/s)  LR: 1.696e-04  Data: 0.009 (0.008)
2024-04-07 07:59:37,265 - train - INFO - Train: 92 [ 750/781 ( 96%)]  Loss:  3.271589 (3.5511)  Time: 1.139s,  112.34/s  (0.532s,  240.45/s)  LR: 1.696e-04  Data: 0.007 (0.008)
2024-04-07 07:59:53,000 - train - INFO - Train: 92 [ 780/781 (100%)]  Loss:  3.606466 (3.5493)  Time: 0.446s,  286.91/s  (0.532s,  240.59/s)  LR: 1.696e-04  Data: 0.000 (0.008)
2024-04-07 07:59:53,001 - train - INFO - True
2024-04-07 07:59:53,014 - train - INFO - alphas:tensor([0.6462, 0.0364, 0.0555, 0.0785, 0.1833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,014 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,015 - train - INFO - True
2024-04-07 07:59:53,023 - train - INFO - alphas:tensor([0.4466, 0.0147, 0.0283, 0.0709, 0.4396], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,023 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,023 - train - INFO - True
2024-04-07 07:59:53,036 - train - INFO - alphas:tensor([0.4799, 0.0253, 0.0663, 0.4285], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,036 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,037 - train - INFO - True
2024-04-07 07:59:53,050 - train - INFO - alphas:tensor([0.4287, 0.0250, 0.0491, 0.4971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,050 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,050 - train - INFO - True
2024-04-07 07:59:53,064 - train - INFO - alphas:tensor([0.4306, 0.0173, 0.0581, 0.4940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,064 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,065 - train - INFO - True
2024-04-07 07:59:53,078 - train - INFO - alphas:tensor([0.5128, 0.0256, 0.0493, 0.4124], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,079 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,079 - train - INFO - True
2024-04-07 07:59:53,087 - train - INFO - alphas:tensor([0.5594, 0.0148, 0.0200, 0.0514, 0.3544], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,088 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,088 - train - INFO - True
2024-04-07 07:59:53,102 - train - INFO - alphas:tensor([0.2471, 0.0084, 0.0071, 0.0511, 0.6864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,103 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,103 - train - INFO - True
2024-04-07 07:59:53,116 - train - INFO - alphas:tensor([0.2568, 0.0063, 0.0081, 0.0397, 0.6892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,117 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,117 - train - INFO - True
2024-04-07 07:59:53,130 - train - INFO - alphas:tensor([0.2559, 0.0044, 0.0070, 0.0447, 0.6880], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,131 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,131 - train - INFO - True
2024-04-07 07:59:53,144 - train - INFO - alphas:tensor([0.2413, 0.0072, 0.0074, 0.0526, 0.6915], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,145 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,145 - train - INFO - True
2024-04-07 07:59:53,151 - train - INFO - alphas:tensor([0.5609, 0.0069, 0.0129, 0.0461, 0.3732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,152 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,152 - train - INFO - True
2024-04-07 07:59:53,166 - train - INFO - alphas:tensor([0.6595, 0.0085, 0.0109, 0.0332, 0.2880], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,169 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,169 - train - INFO - True
2024-04-07 07:59:53,182 - train - INFO - alphas:tensor([0.2608, 0.0161, 0.0166, 0.0875, 0.6189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,184 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,184 - train - INFO - True
2024-04-07 07:59:53,198 - train - INFO - alphas:tensor([0.2792, 0.0089, 0.0118, 0.0824, 0.6176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,200 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,200 - train - INFO - True
2024-04-07 07:59:53,214 - train - INFO - alphas:tensor([0.3004, 0.0070, 0.0112, 0.0723, 0.6092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,216 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,216 - train - INFO - True
2024-04-07 07:59:53,229 - train - INFO - alphas:tensor([0.2721, 0.0107, 0.0138, 0.0694, 0.6340], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,231 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,231 - train - INFO - True
2024-04-07 07:59:53,245 - train - INFO - alphas:tensor([0.3016, 0.0073, 0.0151, 0.0711, 0.6050], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,247 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,247 - train - INFO - True
2024-04-07 07:59:53,262 - train - INFO - alphas:tensor([0.2619, 0.0168, 0.0212, 0.0811, 0.6190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,263 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,263 - train - INFO - True
2024-04-07 07:59:53,276 - train - INFO - alphas:tensor([0.6122, 0.0049, 0.0090, 0.0462, 0.3277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,279 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,279 - train - INFO - True
2024-04-07 07:59:53,293 - train - INFO - alphas:tensor([0.5416, 0.0048, 0.0062, 0.0461, 0.4013], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,299 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,299 - train - INFO - True
2024-04-07 07:59:53,311 - train - INFO - alphas:tensor([0.4189, 0.0043, 0.0118, 0.0649, 0.5001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,314 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,314 - train - INFO - True
2024-04-07 07:59:53,328 - train - INFO - alphas:tensor([0.4331, 0.0044, 0.0067, 0.0584, 0.4975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,332 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,332 - train - INFO - True
2024-04-07 07:59:53,341 - train - INFO - alphas:tensor([0.4460, 0.0037, 0.0065, 0.0557, 0.4882], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,344 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,344 - train - INFO - True
2024-04-07 07:59:53,358 - train - INFO - alphas:tensor([0.4084, 0.0046, 0.0097, 0.0613, 0.5160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,361 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,361 - train - INFO - True
2024-04-07 07:59:53,374 - train - INFO - alphas:tensor([0.5587, 0.0037, 0.0080, 0.0393, 0.3903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,379 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,379 - train - INFO - True
2024-04-07 07:59:53,392 - train - INFO - alphas:tensor([0.7149, 0.0030, 0.0063, 0.0295, 0.2463], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,405 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,405 - train - INFO - True
2024-04-07 07:59:53,419 - train - INFO - alphas:tensor([0.3799, 0.0050, 0.0089, 0.0716, 0.5347], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,425 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,426 - train - INFO - True
2024-04-07 07:59:53,440 - train - INFO - alphas:tensor([0.3867, 0.0032, 0.0072, 0.0610, 0.5419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,446 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,446 - train - INFO - True
2024-04-07 07:59:53,460 - train - INFO - alphas:tensor([0.4158, 0.0035, 0.0060, 0.0619, 0.5129], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,466 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,466 - train - INFO - True
2024-04-07 07:59:53,479 - train - INFO - alphas:tensor([0.3819, 0.0043, 0.0081, 0.0647, 0.5411], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,487 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,487 - train - INFO - True
2024-04-07 07:59:53,499 - train - INFO - alphas:tensor([0.7080, 0.0026, 0.0039, 0.0240, 0.2616], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,512 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,513 - train - INFO - True
2024-04-07 07:59:53,525 - train - INFO - alphas:tensor([0.5461, 0.0112, 0.0161, 0.0649, 0.3617], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:59:53,572 - train - INFO - tau:0.4047319726783239
2024-04-07 07:59:53,572 - train - INFO - avg block size:9.606060606060606
2024-04-07 07:59:53,573 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 07:59:53,573 - train - INFO - lasso_alpha:7.71086578859063e-06
2024-04-07 07:59:53,924 - train - INFO - Test: [   0/78]  Time: 0.349 (0.349)  Loss:  1.0137 (1.0137)  Acc@1: 81.2500 (81.2500)  Acc@5: 92.1875 (92.1875)
2024-04-07 07:59:59,295 - train - INFO - Test: [  50/78]  Time: 0.101 (0.112)  Loss:  1.6211 (1.5812)  Acc@1: 65.6250 (65.2727)  Acc@5: 83.5938 (85.9528)
2024-04-07 08:00:02,102 - train - INFO - Test: [  78/78]  Time: 0.097 (0.108)  Loss:  1.9658 (1.5931)  Acc@1: 50.0000 (65.0500)  Acc@5: 93.7500 (85.7400)
2024-04-07 08:00:02,889 - train - INFO - Train: 93 [   0/781 (  0%)]  Loss:  3.332239 (3.3322)  Time: 0.704s,  181.81/s  (0.704s,  181.81/s)  LR: 1.648e-04  Data: 0.180 (0.180)
2024-04-07 08:00:30,088 - train - INFO - Train: 93 [  50/781 (  6%)]  Loss:  3.847800 (3.5217)  Time: 0.555s,  230.67/s  (0.547s,  233.96/s)  LR: 1.648e-04  Data: 0.007 (0.011)
2024-04-07 08:00:56,521 - train - INFO - Train: 93 [ 100/781 ( 13%)]  Loss:  3.737829 (3.5299)  Time: 0.524s,  244.44/s  (0.538s,  237.94/s)  LR: 1.648e-04  Data: 0.009 (0.009)
2024-04-07 08:01:22,354 - train - INFO - Train: 93 [ 150/781 ( 19%)]  Loss:  3.684672 (3.5379)  Time: 0.531s,  240.89/s  (0.531s,  241.11/s)  LR: 1.648e-04  Data: 0.007 (0.008)
2024-04-07 08:01:48,707 - train - INFO - Train: 93 [ 200/781 ( 26%)]  Loss:  3.508746 (3.5423)  Time: 0.452s,  283.20/s  (0.530s,  241.54/s)  LR: 1.648e-04  Data: 0.006 (0.008)
2024-04-07 08:02:15,698 - train - INFO - Train: 93 [ 250/781 ( 32%)]  Loss:  3.350068 (3.5445)  Time: 0.556s,  230.40/s  (0.532s,  240.65/s)  LR: 1.648e-04  Data: 0.008 (0.008)
2024-04-07 08:02:43,108 - train - INFO - Train: 93 [ 300/781 ( 38%)]  Loss:  3.423357 (3.5481)  Time: 0.537s,  238.15/s  (0.535s,  239.43/s)  LR: 1.648e-04  Data: 0.008 (0.008)
2024-04-07 08:03:10,654 - train - INFO - Train: 93 [ 350/781 ( 45%)]  Loss:  3.747139 (3.5447)  Time: 0.540s,  236.82/s  (0.537s,  238.40/s)  LR: 1.648e-04  Data: 0.007 (0.008)
2024-04-07 08:03:37,827 - train - INFO - Train: 93 [ 400/781 ( 51%)]  Loss:  3.210580 (3.5451)  Time: 0.543s,  235.60/s  (0.538s,  238.04/s)  LR: 1.648e-04  Data: 0.007 (0.008)
2024-04-07 08:04:04,666 - train - INFO - Train: 93 [ 450/781 ( 58%)]  Loss:  3.805161 (3.5489)  Time: 0.496s,  257.84/s  (0.538s,  238.09/s)  LR: 1.648e-04  Data: 0.006 (0.008)
2024-04-07 08:04:31,309 - train - INFO - Train: 93 [ 500/781 ( 64%)]  Loss:  3.591544 (3.5465)  Time: 0.513s,  249.69/s  (0.537s,  238.30/s)  LR: 1.648e-04  Data: 0.008 (0.008)
2024-04-07 08:04:58,819 - train - INFO - Train: 93 [ 550/781 ( 71%)]  Loss:  3.317167 (3.5469)  Time: 0.550s,  232.55/s  (0.538s,  237.78/s)  LR: 1.648e-04  Data: 0.008 (0.008)
2024-04-07 08:05:25,568 - train - INFO - Train: 93 [ 600/781 ( 77%)]  Loss:  3.450623 (3.5545)  Time: 0.523s,  244.81/s  (0.538s,  237.90/s)  LR: 1.648e-04  Data: 0.008 (0.008)
2024-04-07 08:05:52,002 - train - INFO - Train: 93 [ 650/781 ( 83%)]  Loss:  3.818668 (3.5571)  Time: 0.404s,  316.70/s  (0.537s,  238.22/s)  LR: 1.648e-04  Data: 0.005 (0.008)
2024-04-07 08:06:19,757 - train - INFO - Train: 93 [ 700/781 ( 90%)]  Loss:  3.271156 (3.5553)  Time: 0.775s,  165.11/s  (0.539s,  237.66/s)  LR: 1.648e-04  Data: 0.009 (0.008)
2024-04-07 08:06:46,192 - train - INFO - Train: 93 [ 750/781 ( 96%)]  Loss:  3.629975 (3.5602)  Time: 0.538s,  237.81/s  (0.538s,  237.95/s)  LR: 1.648e-04  Data: 0.009 (0.008)
2024-04-07 08:07:02,139 - train - INFO - Train: 93 [ 780/781 (100%)]  Loss:  3.750160 (3.5608)  Time: 0.553s,  231.40/s  (0.538s,  238.06/s)  LR: 1.648e-04  Data: 0.000 (0.008)
2024-04-07 08:07:02,140 - train - INFO - True
2024-04-07 08:07:02,144 - train - INFO - alphas:tensor([0.6499, 0.0357, 0.0546, 0.0774, 0.1824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,144 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,145 - train - INFO - True
2024-04-07 08:07:02,146 - train - INFO - alphas:tensor([0.4449, 0.0143, 0.0278, 0.0701, 0.4429], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,147 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,147 - train - INFO - True
2024-04-07 08:07:02,148 - train - INFO - alphas:tensor([0.4814, 0.0247, 0.0655, 0.4284], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,149 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,149 - train - INFO - True
2024-04-07 08:07:02,150 - train - INFO - alphas:tensor([0.4278, 0.0247, 0.0487, 0.4988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,151 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,151 - train - INFO - True
2024-04-07 08:07:02,152 - train - INFO - alphas:tensor([0.4315, 0.0168, 0.0573, 0.4943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,153 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,153 - train - INFO - True
2024-04-07 08:07:02,154 - train - INFO - alphas:tensor([0.5143, 0.0251, 0.0485, 0.4120], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,155 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,155 - train - INFO - True
2024-04-07 08:07:02,157 - train - INFO - alphas:tensor([0.5595, 0.0143, 0.0194, 0.0503, 0.3565], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,158 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,158 - train - INFO - True
2024-04-07 08:07:02,159 - train - INFO - alphas:tensor([0.2416, 0.0080, 0.0068, 0.0503, 0.6933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,160 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,160 - train - INFO - True
2024-04-07 08:07:02,161 - train - INFO - alphas:tensor([0.2533, 0.0061, 0.0078, 0.0389, 0.6939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,162 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,162 - train - INFO - True
2024-04-07 08:07:02,163 - train - INFO - alphas:tensor([0.2522, 0.0042, 0.0068, 0.0437, 0.6931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,164 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,165 - train - INFO - True
2024-04-07 08:07:02,166 - train - INFO - alphas:tensor([0.2381, 0.0070, 0.0071, 0.0522, 0.6956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,166 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,167 - train - INFO - True
2024-04-07 08:07:02,168 - train - INFO - alphas:tensor([0.5607, 0.0066, 0.0126, 0.0454, 0.3748], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,169 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,169 - train - INFO - True
2024-04-07 08:07:02,170 - train - INFO - alphas:tensor([0.6623, 0.0082, 0.0105, 0.0324, 0.2866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,175 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,175 - train - INFO - True
2024-04-07 08:07:02,176 - train - INFO - alphas:tensor([0.2620, 0.0157, 0.0164, 0.0865, 0.6194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,178 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,178 - train - INFO - True
2024-04-07 08:07:02,179 - train - INFO - alphas:tensor([0.2736, 0.0086, 0.0115, 0.0817, 0.6246], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,181 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,182 - train - INFO - True
2024-04-07 08:07:02,183 - train - INFO - alphas:tensor([0.2984, 0.0067, 0.0110, 0.0717, 0.6122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,185 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,185 - train - INFO - True
2024-04-07 08:07:02,194 - train - INFO - alphas:tensor([0.2691, 0.0103, 0.0134, 0.0687, 0.6385], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,196 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,196 - train - INFO - True
2024-04-07 08:07:02,203 - train - INFO - alphas:tensor([0.2979, 0.0071, 0.0145, 0.0712, 0.6094], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,205 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,205 - train - INFO - True
2024-04-07 08:07:02,213 - train - INFO - alphas:tensor([0.2567, 0.0164, 0.0205, 0.0807, 0.6258], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,215 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,215 - train - INFO - True
2024-04-07 08:07:02,222 - train - INFO - alphas:tensor([0.6088, 0.0048, 0.0087, 0.0458, 0.3320], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,225 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,226 - train - INFO - True
2024-04-07 08:07:02,232 - train - INFO - alphas:tensor([0.5423, 0.0046, 0.0060, 0.0456, 0.4016], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,239 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,239 - train - INFO - True
2024-04-07 08:07:02,240 - train - INFO - alphas:tensor([0.4125, 0.0041, 0.0113, 0.0641, 0.5079], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,244 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,244 - train - INFO - True
2024-04-07 08:07:02,245 - train - INFO - alphas:tensor([0.4291, 0.0042, 0.0064, 0.0584, 0.5018], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,249 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,249 - train - INFO - True
2024-04-07 08:07:02,250 - train - INFO - alphas:tensor([0.4391, 0.0036, 0.0063, 0.0556, 0.4954], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,254 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,254 - train - INFO - True
2024-04-07 08:07:02,255 - train - INFO - alphas:tensor([0.4057, 0.0044, 0.0093, 0.0603, 0.5203], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,259 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,259 - train - INFO - True
2024-04-07 08:07:02,260 - train - INFO - alphas:tensor([0.5582, 0.0036, 0.0077, 0.0392, 0.3912], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,267 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,267 - train - INFO - True
2024-04-07 08:07:02,268 - train - INFO - alphas:tensor([0.7080, 0.0029, 0.0062, 0.0294, 0.2534], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,288 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,288 - train - INFO - True
2024-04-07 08:07:02,296 - train - INFO - alphas:tensor([0.3758, 0.0048, 0.0086, 0.0714, 0.5394], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,306 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,306 - train - INFO - True
2024-04-07 08:07:02,314 - train - INFO - alphas:tensor([0.3813, 0.0030, 0.0069, 0.0606, 0.5482], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,324 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,324 - train - INFO - True
2024-04-07 08:07:02,325 - train - INFO - alphas:tensor([0.4111, 0.0034, 0.0058, 0.0620, 0.5177], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,335 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,335 - train - INFO - True
2024-04-07 08:07:02,336 - train - INFO - alphas:tensor([0.3710, 0.0041, 0.0078, 0.0639, 0.5532], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,346 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,346 - train - INFO - True
2024-04-07 08:07:02,347 - train - INFO - alphas:tensor([0.7035, 0.0025, 0.0038, 0.0239, 0.2663], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,367 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,367 - train - INFO - True
2024-04-07 08:07:02,376 - train - INFO - alphas:tensor([0.5426, 0.0109, 0.0160, 0.0654, 0.3652], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:02,453 - train - INFO - tau:0.40068465295154065
2024-04-07 08:07:02,454 - train - INFO - avg block size:9.606060606060606
2024-04-07 08:07:02,454 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 08:07:02,713 - train - INFO - Test: [   0/78]  Time: 0.255 (0.255)  Loss:  1.0205 (1.0205)  Acc@1: 77.3438 (77.3438)  Acc@5: 92.1875 (92.1875)
2024-04-07 08:07:08,605 - train - INFO - Test: [  50/78]  Time: 0.056 (0.121)  Loss:  1.6084 (1.5843)  Acc@1: 63.2812 (64.7518)  Acc@5: 85.1562 (85.9222)
2024-04-07 08:07:11,989 - train - INFO - Test: [  78/78]  Time: 0.098 (0.121)  Loss:  1.8184 (1.5984)  Acc@1: 62.5000 (64.6400)  Acc@5: 87.5000 (85.5200)
2024-04-07 08:07:12,727 - train - INFO - Train: 94 [   0/781 (  0%)]  Loss:  3.789658 (3.7897)  Time: 0.660s,  193.84/s  (0.660s,  193.84/s)  LR: 1.601e-04  Data: 0.149 (0.149)
2024-04-07 08:07:40,332 - train - INFO - Train: 94 [  50/781 (  6%)]  Loss:  3.439428 (3.5362)  Time: 0.555s,  230.52/s  (0.554s,  230.96/s)  LR: 1.601e-04  Data: 0.009 (0.010)
2024-04-07 08:08:06,665 - train - INFO - Train: 94 [ 100/781 ( 13%)]  Loss:  3.634018 (3.5701)  Time: 0.511s,  250.55/s  (0.541s,  236.80/s)  LR: 1.601e-04  Data: 0.008 (0.009)
2024-04-07 08:08:33,114 - train - INFO - Train: 94 [ 150/781 ( 19%)]  Loss:  3.589827 (3.5607)  Time: 0.547s,  233.82/s  (0.537s,  238.49/s)  LR: 1.601e-04  Data: 0.008 (0.009)
2024-04-07 08:08:59,305 - train - INFO - Train: 94 [ 200/781 ( 26%)]  Loss:  3.339941 (3.5468)  Time: 0.532s,  240.55/s  (0.533s,  239.93/s)  LR: 1.601e-04  Data: 0.008 (0.008)
2024-04-07 08:09:26,737 - train - INFO - Train: 94 [ 250/781 ( 32%)]  Loss:  3.427860 (3.5404)  Time: 0.769s,  166.52/s  (0.537s,  238.58/s)  LR: 1.601e-04  Data: 0.008 (0.008)
2024-04-07 08:09:52,920 - train - INFO - Train: 94 [ 300/781 ( 38%)]  Loss:  3.561579 (3.5459)  Time: 0.433s,  295.35/s  (0.534s,  239.54/s)  LR: 1.601e-04  Data: 0.006 (0.008)
2024-04-07 08:10:19,707 - train - INFO - Train: 94 [ 350/781 ( 45%)]  Loss:  3.007857 (3.5462)  Time: 0.557s,  229.75/s  (0.535s,  239.45/s)  LR: 1.601e-04  Data: 0.009 (0.008)
2024-04-07 08:10:45,780 - train - INFO - Train: 94 [ 400/781 ( 51%)]  Loss:  3.686055 (3.5490)  Time: 0.554s,  231.15/s  (0.533s,  240.19/s)  LR: 1.601e-04  Data: 0.007 (0.008)
2024-04-07 08:11:12,429 - train - INFO - Train: 94 [ 450/781 ( 58%)]  Loss:  3.657541 (3.5500)  Time: 0.528s,  242.34/s  (0.533s,  240.18/s)  LR: 1.601e-04  Data: 0.008 (0.008)
2024-04-07 08:11:39,665 - train - INFO - Train: 94 [ 500/781 ( 64%)]  Loss:  3.659031 (3.5507)  Time: 0.458s,  279.62/s  (0.534s,  239.66/s)  LR: 1.601e-04  Data: 0.008 (0.008)
2024-04-07 08:12:05,427 - train - INFO - Train: 94 [ 550/781 ( 71%)]  Loss:  3.831547 (3.5452)  Time: 0.530s,  241.58/s  (0.532s,  240.43/s)  LR: 1.601e-04  Data: 0.007 (0.008)
2024-04-07 08:12:31,718 - train - INFO - Train: 94 [ 600/781 ( 77%)]  Loss:  3.578280 (3.5453)  Time: 0.441s,  290.10/s  (0.532s,  240.68/s)  LR: 1.601e-04  Data: 0.006 (0.008)
2024-04-07 08:12:56,504 - train - INFO - Train: 94 [ 650/781 ( 83%)]  Loss:  3.670282 (3.5448)  Time: 0.449s,  284.96/s  (0.529s,  241.94/s)  LR: 1.601e-04  Data: 0.009 (0.008)
2024-04-07 08:13:23,042 - train - INFO - Train: 94 [ 700/781 ( 90%)]  Loss:  3.220304 (3.5479)  Time: 0.494s,  259.26/s  (0.529s,  241.89/s)  LR: 1.601e-04  Data: 0.009 (0.008)
2024-04-07 08:13:50,537 - train - INFO - Train: 94 [ 750/781 ( 96%)]  Loss:  3.433602 (3.5463)  Time: 0.549s,  233.16/s  (0.531s,  241.26/s)  LR: 1.601e-04  Data: 0.006 (0.008)
2024-04-07 08:14:06,453 - train - INFO - Train: 94 [ 780/781 (100%)]  Loss:  3.944825 (3.5472)  Time: 0.475s,  269.63/s  (0.531s,  241.26/s)  LR: 1.601e-04  Data: 0.000 (0.008)
2024-04-07 08:14:06,460 - train - INFO - True
2024-04-07 08:14:06,468 - train - INFO - alphas:tensor([0.6515, 0.0351, 0.0540, 0.0768, 0.1826], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,469 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,469 - train - INFO - True
2024-04-07 08:14:06,477 - train - INFO - alphas:tensor([0.4445, 0.0139, 0.0274, 0.0690, 0.4452], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,477 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,477 - train - INFO - True
2024-04-07 08:14:06,486 - train - INFO - alphas:tensor([0.4802, 0.0242, 0.0648, 0.4309], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,487 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,487 - train - INFO - True
2024-04-07 08:14:06,491 - train - INFO - alphas:tensor([0.4296, 0.0240, 0.0473, 0.4991], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,492 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,492 - train - INFO - True
2024-04-07 08:14:06,493 - train - INFO - alphas:tensor([0.4285, 0.0164, 0.0566, 0.4985], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,493 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,493 - train - INFO - True
2024-04-07 08:14:06,494 - train - INFO - alphas:tensor([0.5151, 0.0246, 0.0479, 0.4123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,495 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,495 - train - INFO - True
2024-04-07 08:14:06,496 - train - INFO - alphas:tensor([0.5587, 0.0140, 0.0191, 0.0498, 0.3584], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,497 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,497 - train - INFO - True
2024-04-07 08:14:06,498 - train - INFO - alphas:tensor([0.2412, 0.0077, 0.0066, 0.0493, 0.6953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,499 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,499 - train - INFO - True
2024-04-07 08:14:06,500 - train - INFO - alphas:tensor([0.2486, 0.0058, 0.0075, 0.0383, 0.6998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,500 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,500 - train - INFO - True
2024-04-07 08:14:06,501 - train - INFO - alphas:tensor([0.2480, 0.0040, 0.0065, 0.0433, 0.6982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,502 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,502 - train - INFO - True
2024-04-07 08:14:06,503 - train - INFO - alphas:tensor([0.2361, 0.0068, 0.0068, 0.0512, 0.6991], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,504 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,504 - train - INFO - True
2024-04-07 08:14:06,505 - train - INFO - alphas:tensor([0.5590, 0.0063, 0.0121, 0.0449, 0.3776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,506 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,506 - train - INFO - True
2024-04-07 08:14:06,507 - train - INFO - alphas:tensor([0.6619, 0.0079, 0.0102, 0.0318, 0.2882], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,510 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,510 - train - INFO - True
2024-04-07 08:14:06,511 - train - INFO - alphas:tensor([0.2595, 0.0151, 0.0159, 0.0848, 0.6248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,513 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,513 - train - INFO - True
2024-04-07 08:14:06,514 - train - INFO - alphas:tensor([0.2716, 0.0083, 0.0111, 0.0801, 0.6290], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,516 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,516 - train - INFO - True
2024-04-07 08:14:06,517 - train - INFO - alphas:tensor([0.2952, 0.0065, 0.0108, 0.0708, 0.6167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,519 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,519 - train - INFO - True
2024-04-07 08:14:06,520 - train - INFO - alphas:tensor([0.2647, 0.0099, 0.0129, 0.0679, 0.6446], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,522 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,522 - train - INFO - True
2024-04-07 08:14:06,523 - train - INFO - alphas:tensor([0.2964, 0.0068, 0.0142, 0.0701, 0.6125], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,525 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,525 - train - INFO - True
2024-04-07 08:14:06,526 - train - INFO - alphas:tensor([0.2519, 0.0160, 0.0199, 0.0801, 0.6322], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,527 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,528 - train - INFO - True
2024-04-07 08:14:06,528 - train - INFO - alphas:tensor([0.6064, 0.0046, 0.0085, 0.0450, 0.3355], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,532 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,532 - train - INFO - True
2024-04-07 08:14:06,533 - train - INFO - alphas:tensor([0.5365, 0.0044, 0.0058, 0.0453, 0.4080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,540 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,540 - train - INFO - True
2024-04-07 08:14:06,545 - train - INFO - alphas:tensor([0.4121, 0.0039, 0.0109, 0.0638, 0.5094], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,549 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,549 - train - INFO - True
2024-04-07 08:14:06,557 - train - INFO - alphas:tensor([0.4272, 0.0040, 0.0062, 0.0576, 0.5050], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,561 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,561 - train - INFO - True
2024-04-07 08:14:06,567 - train - INFO - alphas:tensor([0.4411, 0.0035, 0.0061, 0.0547, 0.4946], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,570 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,570 - train - INFO - True
2024-04-07 08:14:06,578 - train - INFO - alphas:tensor([0.4005, 0.0042, 0.0091, 0.0607, 0.5255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,582 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,582 - train - INFO - True
2024-04-07 08:14:06,583 - train - INFO - alphas:tensor([0.5564, 0.0035, 0.0076, 0.0385, 0.3941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,590 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,590 - train - INFO - True
2024-04-07 08:14:06,591 - train - INFO - alphas:tensor([0.7108, 0.0027, 0.0060, 0.0288, 0.2517], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,611 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,611 - train - INFO - True
2024-04-07 08:14:06,612 - train - INFO - alphas:tensor([0.3711, 0.0047, 0.0085, 0.0717, 0.5441], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,622 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,622 - train - INFO - True
2024-04-07 08:14:06,623 - train - INFO - alphas:tensor([0.3758, 0.0029, 0.0067, 0.0598, 0.5547], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,633 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,633 - train - INFO - True
2024-04-07 08:14:06,639 - train - INFO - alphas:tensor([0.4106, 0.0033, 0.0057, 0.0611, 0.5193], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,649 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,649 - train - INFO - True
2024-04-07 08:14:06,656 - train - INFO - alphas:tensor([0.3667, 0.0039, 0.0075, 0.0632, 0.5587], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,666 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,666 - train - INFO - True
2024-04-07 08:14:06,671 - train - INFO - alphas:tensor([0.7059, 0.0024, 0.0037, 0.0232, 0.2648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,690 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,690 - train - INFO - True
2024-04-07 08:14:06,691 - train - INFO - alphas:tensor([0.5403, 0.0106, 0.0157, 0.0650, 0.3685], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:14:06,768 - train - INFO - tau:0.39667780642202527
2024-04-07 08:14:06,768 - train - INFO - avg block size:10.06060606060606
2024-04-07 08:14:06,769 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 08:14:06,769 - train - INFO - lasso_alpha:7.0098779896278455e-06
2024-04-07 08:14:07,047 - train - INFO - Test: [   0/78]  Time: 0.274 (0.274)  Loss:  0.9731 (0.9731)  Acc@1: 78.9062 (78.9062)  Acc@5: 92.1875 (92.1875)
2024-04-07 08:14:12,601 - train - INFO - Test: [  50/78]  Time: 0.097 (0.114)  Loss:  1.7168 (1.5727)  Acc@1: 60.1562 (64.8744)  Acc@5: 84.3750 (85.8609)
2024-04-07 08:14:15,547 - train - INFO - Test: [  78/78]  Time: 0.100 (0.111)  Loss:  1.8418 (1.5907)  Acc@1: 56.2500 (64.6100)  Acc@5: 93.7500 (85.5900)
2024-04-07 08:14:16,332 - train - INFO - Train: 95 [   0/781 (  0%)]  Loss:  3.254313 (3.2543)  Time: 0.703s,  181.98/s  (0.703s,  181.98/s)  LR: 1.553e-04  Data: 0.181 (0.181)
2024-04-07 08:14:42,345 - train - INFO - Train: 95 [  50/781 (  6%)]  Loss:  3.814091 (3.5100)  Time: 0.439s,  291.54/s  (0.524s,  244.36/s)  LR: 1.553e-04  Data: 0.007 (0.011)
2024-04-07 08:15:09,228 - train - INFO - Train: 95 [ 100/781 ( 13%)]  Loss:  3.937953 (3.5329)  Time: 0.584s,  219.16/s  (0.531s,  241.21/s)  LR: 1.553e-04  Data: 0.009 (0.009)
2024-04-07 08:15:34,899 - train - INFO - Train: 95 [ 150/781 ( 19%)]  Loss:  3.873143 (3.5440)  Time: 0.524s,  244.18/s  (0.525s,  243.84/s)  LR: 1.553e-04  Data: 0.006 (0.008)
2024-04-07 08:16:02,780 - train - INFO - Train: 95 [ 200/781 ( 26%)]  Loss:  3.403283 (3.5589)  Time: 0.479s,  267.01/s  (0.533s,  240.12/s)  LR: 1.553e-04  Data: 0.008 (0.008)
2024-04-07 08:16:30,150 - train - INFO - Train: 95 [ 250/781 ( 32%)]  Loss:  3.320262 (3.5505)  Time: 1.073s,  119.30/s  (0.536s,  238.85/s)  LR: 1.553e-04  Data: 0.005 (0.008)
2024-04-07 08:16:57,220 - train - INFO - Train: 95 [ 300/781 ( 38%)]  Loss:  3.791983 (3.5468)  Time: 0.529s,  241.74/s  (0.537s,  238.44/s)  LR: 1.553e-04  Data: 0.006 (0.008)
2024-04-07 08:17:24,135 - train - INFO - Train: 95 [ 350/781 ( 45%)]  Loss:  3.916954 (3.5517)  Time: 0.436s,  293.31/s  (0.537s,  238.35/s)  LR: 1.553e-04  Data: 0.004 (0.008)
2024-04-07 08:17:50,019 - train - INFO - Train: 95 [ 400/781 ( 51%)]  Loss:  3.409825 (3.5517)  Time: 0.553s,  231.37/s  (0.535s,  239.43/s)  LR: 1.553e-04  Data: 0.009 (0.008)
2024-04-07 08:18:17,036 - train - INFO - Train: 95 [ 450/781 ( 58%)]  Loss:  3.619966 (3.5485)  Time: 0.532s,  240.67/s  (0.535s,  239.15/s)  LR: 1.553e-04  Data: 0.008 (0.008)
2024-04-07 08:18:42,771 - train - INFO - Train: 95 [ 500/781 ( 64%)]  Loss:  3.633757 (3.5468)  Time: 0.473s,  270.72/s  (0.533s,  240.07/s)  LR: 1.553e-04  Data: 0.009 (0.008)
2024-04-07 08:19:08,532 - train - INFO - Train: 95 [ 550/781 ( 71%)]  Loss:  3.378128 (3.5476)  Time: 0.573s,  223.41/s  (0.532s,  240.80/s)  LR: 1.553e-04  Data: 0.008 (0.008)
2024-04-07 08:19:35,159 - train - INFO - Train: 95 [ 600/781 ( 77%)]  Loss:  3.350321 (3.5460)  Time: 0.416s,  307.51/s  (0.532s,  240.77/s)  LR: 1.553e-04  Data: 0.004 (0.008)
2024-04-07 08:20:00,914 - train - INFO - Train: 95 [ 650/781 ( 83%)]  Loss:  3.615868 (3.5472)  Time: 0.531s,  240.97/s  (0.530s,  241.35/s)  LR: 1.553e-04  Data: 0.007 (0.008)
2024-04-07 08:20:27,794 - train - INFO - Train: 95 [ 700/781 ( 90%)]  Loss:  3.532937 (3.5444)  Time: 0.568s,  225.44/s  (0.531s,  241.11/s)  LR: 1.553e-04  Data: 0.006 (0.008)
2024-04-07 08:20:53,646 - train - INFO - Train: 95 [ 750/781 ( 96%)]  Loss:  3.127673 (3.5434)  Time: 0.422s,  303.03/s  (0.530s,  241.53/s)  LR: 1.553e-04  Data: 0.007 (0.008)
2024-04-07 08:21:10,002 - train - INFO - Train: 95 [ 780/781 (100%)]  Loss:  3.746235 (3.5437)  Time: 0.511s,  250.64/s  (0.531s,  241.27/s)  LR: 1.553e-04  Data: 0.000 (0.008)
2024-04-07 08:21:10,003 - train - INFO - True
2024-04-07 08:21:10,005 - train - INFO - alphas:tensor([0.6555, 0.0341, 0.0531, 0.0757, 0.1817], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,005 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,006 - train - INFO - True
2024-04-07 08:21:10,007 - train - INFO - alphas:tensor([0.4463, 0.0135, 0.0267, 0.0680, 0.4454], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,007 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,007 - train - INFO - True
2024-04-07 08:21:10,008 - train - INFO - alphas:tensor([0.4806, 0.0236, 0.0635, 0.4322], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,009 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,009 - train - INFO - True
2024-04-07 08:21:10,010 - train - INFO - alphas:tensor([0.4312, 0.0234, 0.0465, 0.4989], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,011 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,011 - train - INFO - True
2024-04-07 08:21:10,012 - train - INFO - alphas:tensor([0.4314, 0.0159, 0.0559, 0.4968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,013 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,013 - train - INFO - True
2024-04-07 08:21:10,019 - train - INFO - alphas:tensor([0.5152, 0.0239, 0.0472, 0.4137], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,020 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,020 - train - INFO - True
2024-04-07 08:21:10,029 - train - INFO - alphas:tensor([0.5585, 0.0136, 0.0188, 0.0493, 0.3598], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,030 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,030 - train - INFO - True
2024-04-07 08:21:10,038 - train - INFO - alphas:tensor([0.2409, 0.0074, 0.0063, 0.0482, 0.6972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,039 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,039 - train - INFO - True
2024-04-07 08:21:10,048 - train - INFO - alphas:tensor([0.2480, 0.0056, 0.0073, 0.0373, 0.7017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,048 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,048 - train - INFO - True
2024-04-07 08:21:10,055 - train - INFO - alphas:tensor([0.2478, 0.0039, 0.0063, 0.0426, 0.6994], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,055 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,055 - train - INFO - True
2024-04-07 08:21:10,063 - train - INFO - alphas:tensor([0.2359, 0.0065, 0.0065, 0.0500, 0.7011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,064 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,064 - train - INFO - True
2024-04-07 08:21:10,066 - train - INFO - alphas:tensor([0.5602, 0.0060, 0.0119, 0.0439, 0.3781], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,067 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,067 - train - INFO - True
2024-04-07 08:21:10,068 - train - INFO - alphas:tensor([0.6618, 0.0078, 0.0099, 0.0314, 0.2891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,071 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,071 - train - INFO - True
2024-04-07 08:21:10,072 - train - INFO - alphas:tensor([0.2581, 0.0147, 0.0153, 0.0836, 0.6283], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,074 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,074 - train - INFO - True
2024-04-07 08:21:10,075 - train - INFO - alphas:tensor([0.2726, 0.0080, 0.0107, 0.0791, 0.6295], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,077 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,077 - train - INFO - True
2024-04-07 08:21:10,078 - train - INFO - alphas:tensor([0.2949, 0.0062, 0.0103, 0.0697, 0.6188], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,080 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,080 - train - INFO - True
2024-04-07 08:21:10,081 - train - INFO - alphas:tensor([0.2681, 0.0096, 0.0125, 0.0671, 0.6427], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,083 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,083 - train - INFO - True
2024-04-07 08:21:10,084 - train - INFO - alphas:tensor([0.2933, 0.0065, 0.0138, 0.0700, 0.6164], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,086 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,086 - train - INFO - True
2024-04-07 08:21:10,087 - train - INFO - alphas:tensor([0.2508, 0.0154, 0.0195, 0.0790, 0.6354], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,088 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,089 - train - INFO - True
2024-04-07 08:21:10,089 - train - INFO - alphas:tensor([0.6085, 0.0044, 0.0082, 0.0439, 0.3350], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,093 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,093 - train - INFO - True
2024-04-07 08:21:10,094 - train - INFO - alphas:tensor([0.5372, 0.0042, 0.0056, 0.0447, 0.4084], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,114 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,115 - train - INFO - True
2024-04-07 08:21:10,124 - train - INFO - alphas:tensor([0.4107, 0.0038, 0.0107, 0.0641, 0.5107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,128 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,128 - train - INFO - True
2024-04-07 08:21:10,136 - train - INFO - alphas:tensor([0.4304, 0.0038, 0.0060, 0.0561, 0.5038], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,139 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,140 - train - INFO - True
2024-04-07 08:21:10,148 - train - INFO - alphas:tensor([0.4432, 0.0034, 0.0059, 0.0534, 0.4942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,151 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,152 - train - INFO - True
2024-04-07 08:21:10,155 - train - INFO - alphas:tensor([0.4033, 0.0040, 0.0088, 0.0602, 0.5237], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,159 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,159 - train - INFO - True
2024-04-07 08:21:10,160 - train - INFO - alphas:tensor([0.5545, 0.0034, 0.0073, 0.0379, 0.3969], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,167 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,167 - train - INFO - True
2024-04-07 08:21:10,168 - train - INFO - alphas:tensor([0.7121, 0.0026, 0.0058, 0.0284, 0.2511], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,188 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,188 - train - INFO - True
2024-04-07 08:21:10,189 - train - INFO - alphas:tensor([0.3736, 0.0045, 0.0083, 0.0700, 0.5436], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,199 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,199 - train - INFO - True
2024-04-07 08:21:10,206 - train - INFO - alphas:tensor([0.3806, 0.0027, 0.0065, 0.0584, 0.5517], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,216 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,216 - train - INFO - True
2024-04-07 08:21:10,225 - train - INFO - alphas:tensor([0.4099, 0.0031, 0.0054, 0.0611, 0.5205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,235 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,235 - train - INFO - True
2024-04-07 08:21:10,243 - train - INFO - alphas:tensor([0.3719, 0.0038, 0.0073, 0.0626, 0.5544], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,253 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,253 - train - INFO - True
2024-04-07 08:21:10,254 - train - INFO - alphas:tensor([0.7064, 0.0023, 0.0035, 0.0230, 0.2648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,275 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,275 - train - INFO - True
2024-04-07 08:21:10,276 - train - INFO - alphas:tensor([0.5425, 0.0104, 0.0156, 0.0643, 0.3671], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:21:10,354 - train - INFO - tau:0.392711028357805
2024-04-07 08:21:10,354 - train - INFO - avg block size:9.606060606060606
2024-04-07 08:21:10,354 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 08:21:10,622 - train - INFO - Test: [   0/78]  Time: 0.265 (0.265)  Loss:  0.9062 (0.9062)  Acc@1: 84.3750 (84.3750)  Acc@5: 93.7500 (93.7500)
2024-04-07 08:21:16,270 - train - INFO - Test: [  50/78]  Time: 0.100 (0.116)  Loss:  1.6904 (1.5721)  Acc@1: 59.3750 (65.1348)  Acc@5: 84.3750 (85.9375)
2024-04-07 08:21:19,139 - train - INFO - Test: [  78/78]  Time: 0.107 (0.111)  Loss:  1.8555 (1.5946)  Acc@1: 62.5000 (64.9100)  Acc@5: 100.0000 (85.5300)
2024-04-07 08:21:19,900 - train - INFO - Train: 96 [   0/781 (  0%)]  Loss:  3.967242 (3.9672)  Time: 0.678s,  188.79/s  (0.678s,  188.79/s)  LR: 1.507e-04  Data: 0.150 (0.150)
2024-04-07 08:21:46,255 - train - INFO - Train: 96 [  50/781 (  6%)]  Loss:  4.002989 (3.5911)  Time: 0.621s,  206.06/s  (0.530s,  241.49/s)  LR: 1.507e-04  Data: 0.012 (0.010)
2024-04-07 08:22:12,309 - train - INFO - Train: 96 [ 100/781 ( 13%)]  Loss:  3.308190 (3.5574)  Time: 0.567s,  225.62/s  (0.526s,  243.54/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-07 08:22:39,545 - train - INFO - Train: 96 [ 150/781 ( 19%)]  Loss:  3.785343 (3.5500)  Time: 1.063s,  120.47/s  (0.532s,  240.64/s)  LR: 1.507e-04  Data: 0.010 (0.008)
2024-04-07 08:23:05,969 - train - INFO - Train: 96 [ 200/781 ( 26%)]  Loss:  3.407065 (3.5402)  Time: 0.545s,  234.76/s  (0.531s,  241.03/s)  LR: 1.507e-04  Data: 0.005 (0.008)
2024-04-07 08:23:33,272 - train - INFO - Train: 96 [ 250/781 ( 32%)]  Loss:  3.872271 (3.5511)  Time: 0.499s,  256.44/s  (0.534s,  239.69/s)  LR: 1.507e-04  Data: 0.009 (0.008)
2024-04-07 08:23:58,826 - train - INFO - Train: 96 [ 300/781 ( 38%)]  Loss:  3.516782 (3.5486)  Time: 0.560s,  228.58/s  (0.530s,  241.41/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-07 08:24:25,502 - train - INFO - Train: 96 [ 350/781 ( 45%)]  Loss:  3.403969 (3.5489)  Time: 0.410s,  312.01/s  (0.531s,  241.20/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-07 08:24:52,803 - train - INFO - Train: 96 [ 400/781 ( 51%)]  Loss:  3.195880 (3.5533)  Time: 0.516s,  248.07/s  (0.533s,  240.34/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-07 08:25:19,663 - train - INFO - Train: 96 [ 450/781 ( 58%)]  Loss:  3.244686 (3.5510)  Time: 0.564s,  226.93/s  (0.533s,  240.11/s)  LR: 1.507e-04  Data: 0.009 (0.008)
2024-04-07 08:25:45,015 - train - INFO - Train: 96 [ 500/781 ( 64%)]  Loss:  3.381013 (3.5509)  Time: 0.511s,  250.24/s  (0.530s,  241.29/s)  LR: 1.507e-04  Data: 0.007 (0.008)
2024-04-07 08:26:12,067 - train - INFO - Train: 96 [ 550/781 ( 71%)]  Loss:  3.700690 (3.5463)  Time: 0.539s,  237.31/s  (0.531s,  240.85/s)  LR: 1.507e-04  Data: 0.010 (0.008)
2024-04-07 08:26:38,629 - train - INFO - Train: 96 [ 600/781 ( 77%)]  Loss:  3.542803 (3.5467)  Time: 0.434s,  294.70/s  (0.531s,  240.86/s)  LR: 1.507e-04  Data: 0.005 (0.008)
2024-04-07 08:27:05,173 - train - INFO - Train: 96 [ 650/781 ( 83%)]  Loss:  3.753125 (3.5447)  Time: 0.602s,  212.53/s  (0.531s,  240.88/s)  LR: 1.507e-04  Data: 0.005 (0.008)
2024-04-07 08:27:32,162 - train - INFO - Train: 96 [ 700/781 ( 90%)]  Loss:  3.577335 (3.5432)  Time: 0.457s,  280.13/s  (0.532s,  240.61/s)  LR: 1.507e-04  Data: 0.005 (0.008)
2024-04-07 08:27:57,681 - train - INFO - Train: 96 [ 750/781 ( 96%)]  Loss:  3.548554 (3.5461)  Time: 0.449s,  285.15/s  (0.531s,  241.27/s)  LR: 1.507e-04  Data: 0.006 (0.008)
2024-04-07 08:28:13,561 - train - INFO - Train: 96 [ 780/781 (100%)]  Loss:  3.619212 (3.5475)  Time: 0.550s,  232.66/s  (0.530s,  241.29/s)  LR: 1.507e-04  Data: 0.000 (0.008)
2024-04-07 08:28:13,562 - train - INFO - True
2024-04-07 08:28:13,569 - train - INFO - alphas:tensor([0.6585, 0.0335, 0.0523, 0.0747, 0.1810], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,569 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,569 - train - INFO - True
2024-04-07 08:28:13,571 - train - INFO - alphas:tensor([0.4465, 0.0131, 0.0262, 0.0671, 0.4470], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,571 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,571 - train - INFO - True
2024-04-07 08:28:13,572 - train - INFO - alphas:tensor([0.4806, 0.0231, 0.0629, 0.4334], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,573 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,573 - train - INFO - True
2024-04-07 08:28:13,574 - train - INFO - alphas:tensor([0.4283, 0.0228, 0.0458, 0.5031], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,575 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,575 - train - INFO - True
2024-04-07 08:28:13,576 - train - INFO - alphas:tensor([0.4290, 0.0153, 0.0550, 0.5007], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,577 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,577 - train - INFO - True
2024-04-07 08:28:13,578 - train - INFO - alphas:tensor([0.5120, 0.0233, 0.0469, 0.4178], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,579 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,579 - train - INFO - True
2024-04-07 08:28:13,580 - train - INFO - alphas:tensor([0.5610, 0.0132, 0.0182, 0.0484, 0.3593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,581 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,581 - train - INFO - True
2024-04-07 08:28:13,582 - train - INFO - alphas:tensor([0.2370, 0.0071, 0.0061, 0.0475, 0.7023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,583 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,583 - train - INFO - True
2024-04-07 08:28:13,584 - train - INFO - alphas:tensor([0.2476, 0.0054, 0.0070, 0.0370, 0.7029], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,585 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,585 - train - INFO - True
2024-04-07 08:28:13,586 - train - INFO - alphas:tensor([0.2461, 0.0037, 0.0061, 0.0418, 0.7023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,587 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,587 - train - INFO - True
2024-04-07 08:28:13,588 - train - INFO - alphas:tensor([0.2348, 0.0062, 0.0063, 0.0493, 0.7034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,589 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,589 - train - INFO - True
2024-04-07 08:28:13,590 - train - INFO - alphas:tensor([0.5595, 0.0058, 0.0115, 0.0433, 0.3799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,591 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,591 - train - INFO - True
2024-04-07 08:28:13,592 - train - INFO - alphas:tensor([0.6639, 0.0074, 0.0095, 0.0306, 0.2886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,596 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,596 - train - INFO - True
2024-04-07 08:28:13,597 - train - INFO - alphas:tensor([0.2569, 0.0142, 0.0146, 0.0823, 0.6319], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,599 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,599 - train - INFO - True
2024-04-07 08:28:13,600 - train - INFO - alphas:tensor([0.2720, 0.0078, 0.0103, 0.0781, 0.6319], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,602 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,602 - train - INFO - True
2024-04-07 08:28:13,603 - train - INFO - alphas:tensor([0.2941, 0.0060, 0.0101, 0.0699, 0.6199], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,605 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,605 - train - INFO - True
2024-04-07 08:28:13,606 - train - INFO - alphas:tensor([0.2682, 0.0094, 0.0121, 0.0656, 0.6446], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,608 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,609 - train - INFO - True
2024-04-07 08:28:13,609 - train - INFO - alphas:tensor([0.2951, 0.0063, 0.0133, 0.0688, 0.6165], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,611 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,612 - train - INFO - True
2024-04-07 08:28:13,620 - train - INFO - alphas:tensor([0.2500, 0.0150, 0.0190, 0.0784, 0.6376], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,622 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,622 - train - INFO - True
2024-04-07 08:28:13,627 - train - INFO - alphas:tensor([0.6096, 0.0042, 0.0080, 0.0436, 0.3346], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,630 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,630 - train - INFO - True
2024-04-07 08:28:13,636 - train - INFO - alphas:tensor([0.5355, 0.0040, 0.0054, 0.0446, 0.4106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,643 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,643 - train - INFO - True
2024-04-07 08:28:13,650 - train - INFO - alphas:tensor([0.4169, 0.0036, 0.0103, 0.0623, 0.5069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,654 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,654 - train - INFO - True
2024-04-07 08:28:13,660 - train - INFO - alphas:tensor([0.4264, 0.0036, 0.0057, 0.0559, 0.5084], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,664 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,664 - train - INFO - True
2024-04-07 08:28:13,665 - train - INFO - alphas:tensor([0.4377, 0.0033, 0.0057, 0.0531, 0.5001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,669 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,669 - train - INFO - True
2024-04-07 08:28:13,670 - train - INFO - alphas:tensor([0.4019, 0.0038, 0.0084, 0.0589, 0.5270], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,674 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,674 - train - INFO - True
2024-04-07 08:28:13,675 - train - INFO - alphas:tensor([0.5558, 0.0032, 0.0070, 0.0368, 0.3972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,682 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,682 - train - INFO - True
2024-04-07 08:28:13,683 - train - INFO - alphas:tensor([0.7133, 0.0025, 0.0056, 0.0279, 0.2506], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,702 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,703 - train - INFO - True
2024-04-07 08:28:13,712 - train - INFO - alphas:tensor([0.3735, 0.0043, 0.0079, 0.0692, 0.5451], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,722 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,722 - train - INFO - True
2024-04-07 08:28:13,729 - train - INFO - alphas:tensor([0.3772, 0.0026, 0.0063, 0.0584, 0.5555], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,739 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,739 - train - INFO - True
2024-04-07 08:28:13,746 - train - INFO - alphas:tensor([0.4125, 0.0030, 0.0052, 0.0591, 0.5202], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,756 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,756 - train - INFO - True
2024-04-07 08:28:13,757 - train - INFO - alphas:tensor([0.3722, 0.0036, 0.0070, 0.0620, 0.5552], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,767 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,767 - train - INFO - True
2024-04-07 08:28:13,768 - train - INFO - alphas:tensor([0.7072, 0.0022, 0.0033, 0.0227, 0.2646], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,788 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,788 - train - INFO - True
2024-04-07 08:28:13,789 - train - INFO - alphas:tensor([0.5417, 0.0102, 0.0154, 0.0642, 0.3685], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:28:13,867 - train - INFO - tau:0.38878391807422696
2024-04-07 08:28:13,867 - train - INFO - avg block size:10.06060606060606
2024-04-07 08:28:13,867 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 08:28:13,868 - train - INFO - lasso_alpha:6.372616354207131e-06
2024-04-07 08:28:14,137 - train - INFO - Test: [   0/78]  Time: 0.266 (0.266)  Loss:  1.0059 (1.0059)  Acc@1: 81.2500 (81.2500)  Acc@5: 92.9688 (92.9688)
2024-04-07 08:28:19,294 - train - INFO - Test: [  50/78]  Time: 0.101 (0.106)  Loss:  1.5459 (1.5713)  Acc@1: 64.0625 (65.6250)  Acc@5: 89.8438 (85.9528)
2024-04-07 08:28:22,135 - train - INFO - Test: [  78/78]  Time: 0.097 (0.105)  Loss:  1.8789 (1.5866)  Acc@1: 50.0000 (65.2700)  Acc@5: 93.7500 (85.7000)
2024-04-07 08:28:22,889 - train - INFO - Train: 97 [   0/781 (  0%)]  Loss:  3.221634 (3.2216)  Time: 0.672s,  190.36/s  (0.672s,  190.36/s)  LR: 1.461e-04  Data: 0.166 (0.166)
2024-04-07 08:28:50,068 - train - INFO - Train: 97 [  50/781 (  6%)]  Loss:  3.436721 (3.5553)  Time: 0.533s,  240.32/s  (0.546s,  234.40/s)  LR: 1.461e-04  Data: 0.008 (0.011)
2024-04-07 08:29:17,195 - train - INFO - Train: 97 [ 100/781 ( 13%)]  Loss:  3.332214 (3.5372)  Time: 0.528s,  242.36/s  (0.544s,  235.16/s)  LR: 1.461e-04  Data: 0.008 (0.009)
2024-04-07 08:29:43,997 - train - INFO - Train: 97 [ 150/781 ( 19%)]  Loss:  3.533297 (3.5344)  Time: 0.570s,  224.42/s  (0.542s,  236.36/s)  LR: 1.461e-04  Data: 0.007 (0.009)
2024-04-07 08:30:10,144 - train - INFO - Train: 97 [ 200/781 ( 26%)]  Loss:  3.653569 (3.5464)  Time: 0.511s,  250.54/s  (0.537s,  238.40/s)  LR: 1.461e-04  Data: 0.008 (0.008)
2024-04-07 08:30:37,224 - train - INFO - Train: 97 [ 250/781 ( 32%)]  Loss:  3.605863 (3.5371)  Time: 0.463s,  276.43/s  (0.538s,  237.99/s)  LR: 1.461e-04  Data: 0.009 (0.008)
2024-04-07 08:31:03,665 - train - INFO - Train: 97 [ 300/781 ( 38%)]  Loss:  3.807451 (3.5450)  Time: 0.558s,  229.21/s  (0.536s,  238.66/s)  LR: 1.461e-04  Data: 0.008 (0.008)
2024-04-07 08:31:30,472 - train - INFO - Train: 97 [ 350/781 ( 45%)]  Loss:  3.469516 (3.5428)  Time: 0.425s,  300.95/s  (0.536s,  238.68/s)  LR: 1.461e-04  Data: 0.004 (0.008)
2024-04-07 08:31:56,229 - train - INFO - Train: 97 [ 400/781 ( 51%)]  Loss:  3.710412 (3.5415)  Time: 0.484s,  264.48/s  (0.534s,  239.86/s)  LR: 1.461e-04  Data: 0.008 (0.008)
2024-04-07 08:32:22,226 - train - INFO - Train: 97 [ 450/781 ( 58%)]  Loss:  3.859081 (3.5487)  Time: 0.579s,  221.17/s  (0.532s,  240.55/s)  LR: 1.461e-04  Data: 0.008 (0.008)
2024-04-07 08:32:48,804 - train - INFO - Train: 97 [ 500/781 ( 64%)]  Loss:  3.735324 (3.5518)  Time: 0.440s,  290.73/s  (0.532s,  240.57/s)  LR: 1.461e-04  Data: 0.005 (0.008)
2024-04-07 08:33:15,944 - train - INFO - Train: 97 [ 550/781 ( 71%)]  Loss:  3.368440 (3.5535)  Time: 0.438s,  291.96/s  (0.533s,  240.13/s)  LR: 1.461e-04  Data: 0.005 (0.008)
2024-04-07 08:33:42,103 - train - INFO - Train: 97 [ 600/781 ( 77%)]  Loss:  3.318477 (3.5499)  Time: 0.577s,  221.76/s  (0.532s,  240.51/s)  LR: 1.461e-04  Data: 0.009 (0.008)
2024-04-07 08:34:08,287 - train - INFO - Train: 97 [ 650/781 ( 83%)]  Loss:  3.692980 (3.5489)  Time: 0.537s,  238.16/s  (0.532s,  240.80/s)  LR: 1.461e-04  Data: 0.007 (0.008)
2024-04-07 08:34:34,912 - train - INFO - Train: 97 [ 700/781 ( 90%)]  Loss:  3.511167 (3.5491)  Time: 0.498s,  257.22/s  (0.532s,  240.77/s)  LR: 1.461e-04  Data: 0.006 (0.008)
2024-04-07 08:35:01,851 - train - INFO - Train: 97 [ 750/781 ( 96%)]  Loss:  3.183520 (3.5486)  Time: 1.178s,  108.67/s  (0.532s,  240.56/s)  LR: 1.461e-04  Data: 0.005 (0.008)
2024-04-07 08:35:16,225 - train - INFO - Train: 97 [ 780/781 (100%)]  Loss:  3.740656 (3.5489)  Time: 0.416s,  307.56/s  (0.530s,  241.48/s)  LR: 1.461e-04  Data: 0.000 (0.008)
2024-04-07 08:35:16,226 - train - INFO - True
2024-04-07 08:35:16,227 - train - INFO - alphas:tensor([0.6610, 0.0328, 0.0517, 0.0739, 0.1805], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,228 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,228 - train - INFO - True
2024-04-07 08:35:16,229 - train - INFO - alphas:tensor([0.4460, 0.0127, 0.0257, 0.0665, 0.4492], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,230 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,230 - train - INFO - True
2024-04-07 08:35:16,231 - train - INFO - alphas:tensor([0.4840, 0.0225, 0.0618, 0.4317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,231 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,232 - train - INFO - True
2024-04-07 08:35:16,233 - train - INFO - alphas:tensor([0.4281, 0.0222, 0.0457, 0.5039], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,233 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,233 - train - INFO - True
2024-04-07 08:35:16,234 - train - INFO - alphas:tensor([0.4314, 0.0150, 0.0543, 0.4992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,235 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,235 - train - INFO - True
2024-04-07 08:35:16,236 - train - INFO - alphas:tensor([0.5150, 0.0227, 0.0458, 0.4164], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,237 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,237 - train - INFO - True
2024-04-07 08:35:16,238 - train - INFO - alphas:tensor([0.5611, 0.0127, 0.0178, 0.0477, 0.3607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,239 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,239 - train - INFO - True
2024-04-07 08:35:16,240 - train - INFO - alphas:tensor([0.2384, 0.0070, 0.0059, 0.0470, 0.7018], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,241 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,241 - train - INFO - True
2024-04-07 08:35:16,242 - train - INFO - alphas:tensor([0.2466, 0.0052, 0.0068, 0.0365, 0.7049], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,242 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,242 - train - INFO - True
2024-04-07 08:35:16,243 - train - INFO - alphas:tensor([0.2443, 0.0035, 0.0059, 0.0413, 0.7051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,244 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,244 - train - INFO - True
2024-04-07 08:35:16,245 - train - INFO - alphas:tensor([0.2341, 0.0061, 0.0061, 0.0483, 0.7055], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,246 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,246 - train - INFO - True
2024-04-07 08:35:16,247 - train - INFO - alphas:tensor([0.5595, 0.0055, 0.0111, 0.0423, 0.3815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,248 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,248 - train - INFO - True
2024-04-07 08:35:16,249 - train - INFO - alphas:tensor([0.6658, 0.0072, 0.0092, 0.0300, 0.2878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,252 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,252 - train - INFO - True
2024-04-07 08:35:16,253 - train - INFO - alphas:tensor([0.2578, 0.0138, 0.0142, 0.0815, 0.6326], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,255 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,255 - train - INFO - True
2024-04-07 08:35:16,256 - train - INFO - alphas:tensor([0.2735, 0.0076, 0.0100, 0.0779, 0.6310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,258 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,258 - train - INFO - True
2024-04-07 08:35:16,259 - train - INFO - alphas:tensor([0.2939, 0.0057, 0.0097, 0.0682, 0.6223], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,261 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,261 - train - INFO - True
2024-04-07 08:35:16,262 - train - INFO - alphas:tensor([0.2683, 0.0090, 0.0117, 0.0659, 0.6451], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,264 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,264 - train - INFO - True
2024-04-07 08:35:16,265 - train - INFO - alphas:tensor([0.2916, 0.0061, 0.0131, 0.0691, 0.6200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,266 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,267 - train - INFO - True
2024-04-07 08:35:16,268 - train - INFO - alphas:tensor([0.2530, 0.0147, 0.0187, 0.0781, 0.6355], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,270 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,270 - train - INFO - True
2024-04-07 08:35:16,271 - train - INFO - alphas:tensor([0.6066, 0.0041, 0.0077, 0.0435, 0.3382], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,274 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,274 - train - INFO - True
2024-04-07 08:35:16,275 - train - INFO - alphas:tensor([0.5369, 0.0038, 0.0052, 0.0438, 0.4102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,282 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,282 - train - INFO - True
2024-04-07 08:35:16,283 - train - INFO - alphas:tensor([0.4111, 0.0034, 0.0100, 0.0628, 0.5127], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,286 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,286 - train - INFO - True
2024-04-07 08:35:16,287 - train - INFO - alphas:tensor([0.4279, 0.0035, 0.0055, 0.0551, 0.5080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,290 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,290 - train - INFO - True
2024-04-07 08:35:16,291 - train - INFO - alphas:tensor([0.4431, 0.0031, 0.0055, 0.0530, 0.4952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,294 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,295 - train - INFO - True
2024-04-07 08:35:16,295 - train - INFO - alphas:tensor([0.4051, 0.0036, 0.0082, 0.0582, 0.5249], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,299 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,299 - train - INFO - True
2024-04-07 08:35:16,300 - train - INFO - alphas:tensor([0.5563, 0.0031, 0.0068, 0.0362, 0.3977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,306 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,306 - train - INFO - True
2024-04-07 08:35:16,306 - train - INFO - alphas:tensor([0.7154, 0.0024, 0.0054, 0.0275, 0.2492], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,322 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,322 - train - INFO - True
2024-04-07 08:35:16,323 - train - INFO - alphas:tensor([0.3734, 0.0041, 0.0076, 0.0687, 0.5461], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,331 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,331 - train - INFO - True
2024-04-07 08:35:16,332 - train - INFO - alphas:tensor([0.3826, 0.0025, 0.0061, 0.0580, 0.5508], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,339 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,339 - train - INFO - True
2024-04-07 08:35:16,340 - train - INFO - alphas:tensor([0.4179, 0.0029, 0.0050, 0.0583, 0.5160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,347 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,348 - train - INFO - True
2024-04-07 08:35:16,348 - train - INFO - alphas:tensor([0.3694, 0.0034, 0.0068, 0.0614, 0.5590], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,356 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,356 - train - INFO - True
2024-04-07 08:35:16,357 - train - INFO - alphas:tensor([0.7084, 0.0020, 0.0032, 0.0223, 0.2641], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,371 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,371 - train - INFO - True
2024-04-07 08:35:16,372 - train - INFO - alphas:tensor([0.5405, 0.0099, 0.0150, 0.0636, 0.3710], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:35:16,426 - train - INFO - tau:0.3848960788934847
2024-04-07 08:35:16,426 - train - INFO - avg block size:10.06060606060606
2024-04-07 08:35:16,426 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 08:35:16,593 - train - INFO - Test: [   0/78]  Time: 0.164 (0.164)  Loss:  0.9512 (0.9512)  Acc@1: 81.2500 (81.2500)  Acc@5: 92.1875 (92.1875)
2024-04-07 08:35:21,985 - train - INFO - Test: [  50/78]  Time: 0.111 (0.109)  Loss:  1.4551 (1.5662)  Acc@1: 65.6250 (65.1501)  Acc@5: 89.0625 (85.8303)
2024-04-07 08:35:24,852 - train - INFO - Test: [  78/78]  Time: 0.098 (0.107)  Loss:  1.8555 (1.5795)  Acc@1: 50.0000 (65.1200)  Acc@5: 93.7500 (85.5800)
2024-04-07 08:35:25,615 - train - INFO - Train: 98 [   0/781 (  0%)]  Loss:  3.707868 (3.7079)  Time: 0.681s,  188.03/s  (0.681s,  188.03/s)  LR: 1.415e-04  Data: 0.190 (0.190)
2024-04-07 08:35:51,706 - train - INFO - Train: 98 [  50/781 (  6%)]  Loss:  3.493715 (3.5853)  Time: 1.148s,  111.46/s  (0.525s,  243.85/s)  LR: 1.415e-04  Data: 0.008 (0.010)
2024-04-07 08:36:17,789 - train - INFO - Train: 98 [ 100/781 ( 13%)]  Loss:  3.580374 (3.5894)  Time: 0.558s,  229.23/s  (0.523s,  244.61/s)  LR: 1.415e-04  Data: 0.008 (0.009)
2024-04-07 08:36:45,286 - train - INFO - Train: 98 [ 150/781 ( 19%)]  Loss:  3.719419 (3.5740)  Time: 0.540s,  236.83/s  (0.532s,  240.56/s)  LR: 1.415e-04  Data: 0.009 (0.008)
2024-04-07 08:37:11,671 - train - INFO - Train: 98 [ 200/781 ( 26%)]  Loss:  3.551661 (3.5544)  Time: 0.422s,  303.18/s  (0.531s,  241.06/s)  LR: 1.415e-04  Data: 0.009 (0.008)
2024-04-07 08:37:37,863 - train - INFO - Train: 98 [ 250/781 ( 32%)]  Loss:  3.718958 (3.5656)  Time: 0.528s,  242.51/s  (0.530s,  241.71/s)  LR: 1.415e-04  Data: 0.008 (0.008)
2024-04-07 08:38:04,507 - train - INFO - Train: 98 [ 300/781 ( 38%)]  Loss:  3.249301 (3.5674)  Time: 0.582s,  219.89/s  (0.530s,  241.46/s)  LR: 1.415e-04  Data: 0.007 (0.008)
2024-04-07 08:38:30,360 - train - INFO - Train: 98 [ 350/781 ( 45%)]  Loss:  3.772545 (3.5654)  Time: 0.530s,  241.74/s  (0.528s,  242.31/s)  LR: 1.415e-04  Data: 0.009 (0.008)
2024-04-07 08:38:56,486 - train - INFO - Train: 98 [ 400/781 ( 51%)]  Loss:  3.491166 (3.5602)  Time: 0.509s,  251.24/s  (0.528s,  242.64/s)  LR: 1.415e-04  Data: 0.010 (0.008)
2024-04-07 08:39:23,215 - train - INFO - Train: 98 [ 450/781 ( 58%)]  Loss:  3.417100 (3.5594)  Time: 0.478s,  267.94/s  (0.528s,  242.28/s)  LR: 1.415e-04  Data: 0.006 (0.008)
2024-04-07 08:39:50,091 - train - INFO - Train: 98 [ 500/781 ( 64%)]  Loss:  3.294438 (3.5560)  Time: 0.434s,  294.90/s  (0.529s,  241.86/s)  LR: 1.415e-04  Data: 0.004 (0.008)
2024-04-07 08:40:15,681 - train - INFO - Train: 98 [ 550/781 ( 71%)]  Loss:  3.828729 (3.5564)  Time: 0.418s,  306.18/s  (0.528s,  242.59/s)  LR: 1.415e-04  Data: 0.006 (0.008)
2024-04-07 08:40:42,758 - train - INFO - Train: 98 [ 600/781 ( 77%)]  Loss:  3.482097 (3.5568)  Time: 0.487s,  262.79/s  (0.529s,  242.06/s)  LR: 1.415e-04  Data: 0.009 (0.008)
2024-04-07 08:41:08,319 - train - INFO - Train: 98 [ 650/781 ( 83%)]  Loss:  3.741635 (3.5571)  Time: 0.505s,  253.46/s  (0.527s,  242.68/s)  LR: 1.415e-04  Data: 0.009 (0.008)
2024-04-07 08:41:35,415 - train - INFO - Train: 98 [ 700/781 ( 90%)]  Loss:  3.586852 (3.5567)  Time: 0.548s,  233.61/s  (0.528s,  242.21/s)  LR: 1.415e-04  Data: 0.015 (0.008)
2024-04-07 08:42:03,359 - train - INFO - Train: 98 [ 750/781 ( 96%)]  Loss:  3.280335 (3.5515)  Time: 0.544s,  235.20/s  (0.530s,  241.29/s)  LR: 1.415e-04  Data: 0.008 (0.008)
2024-04-07 08:42:19,843 - train - INFO - Train: 98 [ 780/781 (100%)]  Loss:  3.824700 (3.5544)  Time: 1.045s,  122.49/s  (0.531s,  240.96/s)  LR: 1.415e-04  Data: 0.000 (0.008)
2024-04-07 08:42:19,844 - train - INFO - True
2024-04-07 08:42:19,852 - train - INFO - alphas:tensor([0.6624, 0.0323, 0.0512, 0.0735, 0.1807], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,852 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,852 - train - INFO - True
2024-04-07 08:42:19,858 - train - INFO - alphas:tensor([0.4448, 0.0123, 0.0252, 0.0661, 0.4516], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,859 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,859 - train - INFO - True
2024-04-07 08:42:19,864 - train - INFO - alphas:tensor([0.4844, 0.0220, 0.0612, 0.4324], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,865 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,865 - train - INFO - True
2024-04-07 08:42:19,871 - train - INFO - alphas:tensor([0.4281, 0.0218, 0.0449, 0.5053], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,871 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,871 - train - INFO - True
2024-04-07 08:42:19,877 - train - INFO - alphas:tensor([0.4311, 0.0146, 0.0536, 0.5007], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,877 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,877 - train - INFO - True
2024-04-07 08:42:19,881 - train - INFO - alphas:tensor([0.5169, 0.0223, 0.0453, 0.4155], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,881 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,881 - train - INFO - True
2024-04-07 08:42:19,882 - train - INFO - alphas:tensor([0.5633, 0.0123, 0.0173, 0.0468, 0.3604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,883 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,883 - train - INFO - True
2024-04-07 08:42:19,884 - train - INFO - alphas:tensor([0.2401, 0.0068, 0.0058, 0.0465, 0.7008], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,885 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,885 - train - INFO - True
2024-04-07 08:42:19,885 - train - INFO - alphas:tensor([0.2462, 0.0050, 0.0065, 0.0357, 0.7066], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,886 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,886 - train - INFO - True
2024-04-07 08:42:19,887 - train - INFO - alphas:tensor([0.2459, 0.0034, 0.0057, 0.0404, 0.7046], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,887 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,887 - train - INFO - True
2024-04-07 08:42:19,888 - train - INFO - alphas:tensor([0.2332, 0.0059, 0.0059, 0.0477, 0.7073], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,889 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,889 - train - INFO - True
2024-04-07 08:42:19,890 - train - INFO - alphas:tensor([0.5619, 0.0053, 0.0108, 0.0416, 0.3804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,890 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,890 - train - INFO - True
2024-04-07 08:42:19,891 - train - INFO - alphas:tensor([0.6660, 0.0069, 0.0089, 0.0295, 0.2887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,894 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,894 - train - INFO - True
2024-04-07 08:42:19,895 - train - INFO - alphas:tensor([0.2570, 0.0135, 0.0137, 0.0811, 0.6348], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,896 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,896 - train - INFO - True
2024-04-07 08:42:19,897 - train - INFO - alphas:tensor([0.2735, 0.0072, 0.0096, 0.0772, 0.6325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,898 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,899 - train - INFO - True
2024-04-07 08:42:19,899 - train - INFO - alphas:tensor([0.2945, 0.0055, 0.0094, 0.0677, 0.6229], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,901 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,901 - train - INFO - True
2024-04-07 08:42:19,902 - train - INFO - alphas:tensor([0.2670, 0.0087, 0.0113, 0.0649, 0.6481], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,903 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,903 - train - INFO - True
2024-04-07 08:42:19,904 - train - INFO - alphas:tensor([0.2939, 0.0058, 0.0127, 0.0677, 0.6199], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,905 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,905 - train - INFO - True
2024-04-07 08:42:19,906 - train - INFO - alphas:tensor([0.2520, 0.0142, 0.0179, 0.0766, 0.6393], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,907 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,907 - train - INFO - True
2024-04-07 08:42:19,908 - train - INFO - alphas:tensor([0.6090, 0.0039, 0.0074, 0.0427, 0.3369], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,911 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,911 - train - INFO - True
2024-04-07 08:42:19,911 - train - INFO - alphas:tensor([0.5357, 0.0037, 0.0050, 0.0435, 0.4122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,917 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,917 - train - INFO - True
2024-04-07 08:42:19,918 - train - INFO - alphas:tensor([0.4097, 0.0032, 0.0098, 0.0612, 0.5162], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,921 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,921 - train - INFO - True
2024-04-07 08:42:19,921 - train - INFO - alphas:tensor([0.4302, 0.0033, 0.0053, 0.0546, 0.5065], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,924 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,924 - train - INFO - True
2024-04-07 08:42:19,930 - train - INFO - alphas:tensor([0.4406, 0.0030, 0.0053, 0.0522, 0.4989], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,933 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,933 - train - INFO - True
2024-04-07 08:42:19,939 - train - INFO - alphas:tensor([0.4031, 0.0035, 0.0079, 0.0576, 0.5279], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,942 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,942 - train - INFO - True
2024-04-07 08:42:19,948 - train - INFO - alphas:tensor([0.5581, 0.0029, 0.0065, 0.0356, 0.3968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,952 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,953 - train - INFO - True
2024-04-07 08:42:19,958 - train - INFO - alphas:tensor([0.7149, 0.0023, 0.0052, 0.0273, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,971 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,971 - train - INFO - True
2024-04-07 08:42:19,971 - train - INFO - alphas:tensor([0.3733, 0.0039, 0.0074, 0.0688, 0.5466], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,978 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,978 - train - INFO - True
2024-04-07 08:42:19,979 - train - INFO - alphas:tensor([0.3803, 0.0024, 0.0059, 0.0570, 0.5544], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,987 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,987 - train - INFO - True
2024-04-07 08:42:19,988 - train - INFO - alphas:tensor([0.4167, 0.0027, 0.0048, 0.0573, 0.5184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:19,995 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:19,995 - train - INFO - True
2024-04-07 08:42:19,996 - train - INFO - alphas:tensor([0.3724, 0.0033, 0.0066, 0.0604, 0.5573], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:20,003 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:20,003 - train - INFO - True
2024-04-07 08:42:20,003 - train - INFO - alphas:tensor([0.7104, 0.0020, 0.0031, 0.0217, 0.2628], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:20,017 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:20,017 - train - INFO - True
2024-04-07 08:42:20,023 - train - INFO - alphas:tensor([0.5439, 0.0096, 0.0147, 0.0629, 0.3689], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:20,070 - train - INFO - tau:0.38104711810454983
2024-04-07 08:42:20,070 - train - INFO - avg block size:10.06060606060606
2024-04-07 08:42:20,070 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 08:42:20,070 - train - INFO - lasso_alpha:5.793287594733756e-06
2024-04-07 08:42:20,335 - train - INFO - Test: [   0/78]  Time: 0.262 (0.262)  Loss:  0.9917 (0.9917)  Acc@1: 82.0312 (82.0312)  Acc@5: 92.1875 (92.1875)
2024-04-07 08:42:26,656 - train - INFO - Test: [  50/78]  Time: 0.099 (0.129)  Loss:  1.5742 (1.5548)  Acc@1: 63.2812 (65.6556)  Acc@5: 87.5000 (86.0141)
2024-04-07 08:42:29,784 - train - INFO - Test: [  78/78]  Time: 0.103 (0.123)  Loss:  1.6738 (1.5714)  Acc@1: 68.7500 (65.3300)  Acc@5: 93.7500 (85.7800)
2024-04-07 08:42:30,499 - train - INFO - Train: 99 [   0/781 (  0%)]  Loss:  3.721679 (3.7217)  Time: 0.622s,  205.78/s  (0.622s,  205.78/s)  LR: 1.370e-04  Data: 0.156 (0.156)
2024-04-07 08:42:56,132 - train - INFO - Train: 99 [  50/781 (  6%)]  Loss:  3.834851 (3.5383)  Time: 0.456s,  280.65/s  (0.515s,  248.65/s)  LR: 1.370e-04  Data: 0.007 (0.011)
2024-04-07 08:43:19,164 - train - INFO - Train: 99 [ 100/781 ( 13%)]  Loss:  3.618899 (3.5329)  Time: 0.505s,  253.59/s  (0.488s,  262.32/s)  LR: 1.370e-04  Data: 0.007 (0.009)
2024-04-07 08:43:43,221 - train - INFO - Train: 99 [ 150/781 ( 19%)]  Loss:  3.645782 (3.5199)  Time: 0.476s,  268.89/s  (0.486s,  263.54/s)  LR: 1.370e-04  Data: 0.007 (0.009)
2024-04-07 08:44:07,329 - train - INFO - Train: 99 [ 200/781 ( 26%)]  Loss:  3.679772 (3.5235)  Time: 0.444s,  288.27/s  (0.485s,  264.03/s)  LR: 1.370e-04  Data: 0.005 (0.008)
2024-04-07 08:44:30,588 - train - INFO - Train: 99 [ 250/781 ( 32%)]  Loss:  3.712703 (3.5257)  Time: 0.500s,  256.16/s  (0.481s,  266.18/s)  LR: 1.370e-04  Data: 0.009 (0.008)
2024-04-07 08:44:54,060 - train - INFO - Train: 99 [ 300/781 ( 38%)]  Loss:  3.833762 (3.5295)  Time: 0.469s,  272.95/s  (0.479s,  267.24/s)  LR: 1.370e-04  Data: 0.005 (0.008)
2024-04-07 08:45:17,377 - train - INFO - Train: 99 [ 350/781 ( 45%)]  Loss:  3.750879 (3.5294)  Time: 0.503s,  254.64/s  (0.477s,  268.25/s)  LR: 1.370e-04  Data: 0.006 (0.008)
2024-04-07 08:45:40,984 - train - INFO - Train: 99 [ 400/781 ( 51%)]  Loss:  3.295230 (3.5288)  Time: 0.442s,  289.34/s  (0.477s,  268.60/s)  LR: 1.370e-04  Data: 0.008 (0.008)
2024-04-07 08:46:05,264 - train - INFO - Train: 99 [ 450/781 ( 58%)]  Loss:  3.863713 (3.5317)  Time: 0.496s,  258.28/s  (0.478s,  268.04/s)  LR: 1.370e-04  Data: 0.008 (0.008)
2024-04-07 08:46:28,085 - train - INFO - Train: 99 [ 500/781 ( 64%)]  Loss:  3.540402 (3.5297)  Time: 0.479s,  267.06/s  (0.475s,  269.23/s)  LR: 1.370e-04  Data: 0.007 (0.008)
2024-04-07 08:46:51,491 - train - INFO - Train: 99 [ 550/781 ( 71%)]  Loss:  3.592149 (3.5327)  Time: 0.465s,  275.40/s  (0.475s,  269.61/s)  LR: 1.370e-04  Data: 0.008 (0.008)
2024-04-07 08:47:14,495 - train - INFO - Train: 99 [ 600/781 ( 77%)]  Loss:  3.373498 (3.5347)  Time: 0.476s,  268.71/s  (0.474s,  270.31/s)  LR: 1.370e-04  Data: 0.007 (0.008)
2024-04-07 08:47:38,955 - train - INFO - Train: 99 [ 650/781 ( 83%)]  Loss:  3.567891 (3.5367)  Time: 0.480s,  266.47/s  (0.475s,  269.62/s)  LR: 1.370e-04  Data: 0.007 (0.008)
2024-04-07 08:48:02,796 - train - INFO - Train: 99 [ 700/781 ( 90%)]  Loss:  3.272462 (3.5345)  Time: 0.349s,  366.34/s  (0.475s,  269.54/s)  LR: 1.370e-04  Data: 0.010 (0.008)
2024-04-07 08:48:26,445 - train - INFO - Train: 99 [ 750/781 ( 96%)]  Loss:  3.508046 (3.5338)  Time: 0.368s,  347.45/s  (0.475s,  269.61/s)  LR: 1.370e-04  Data: 0.005 (0.008)
2024-04-07 08:48:39,941 - train - INFO - Train: 99 [ 780/781 (100%)]  Loss:  3.460820 (3.5352)  Time: 0.441s,  290.39/s  (0.474s,  270.16/s)  LR: 1.370e-04  Data: 0.000 (0.008)
2024-04-07 08:48:39,942 - train - INFO - True
2024-04-07 08:48:39,944 - train - INFO - alphas:tensor([0.6655, 0.0315, 0.0504, 0.0726, 0.1799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,945 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,945 - train - INFO - True
2024-04-07 08:48:39,946 - train - INFO - alphas:tensor([0.4440, 0.0120, 0.0246, 0.0654, 0.4539], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,947 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,947 - train - INFO - True
2024-04-07 08:48:39,948 - train - INFO - alphas:tensor([0.4852, 0.0215, 0.0603, 0.4330], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,949 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,949 - train - INFO - True
2024-04-07 08:48:39,951 - train - INFO - alphas:tensor([0.4297, 0.0212, 0.0439, 0.5052], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,951 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,951 - train - INFO - True
2024-04-07 08:48:39,953 - train - INFO - alphas:tensor([0.4309, 0.0142, 0.0528, 0.5021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,953 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,953 - train - INFO - True
2024-04-07 08:48:39,955 - train - INFO - alphas:tensor([0.5159, 0.0217, 0.0446, 0.4178], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,956 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,956 - train - INFO - True
2024-04-07 08:48:39,957 - train - INFO - alphas:tensor([0.5638, 0.0120, 0.0168, 0.0461, 0.3613], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,958 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,959 - train - INFO - True
2024-04-07 08:48:39,960 - train - INFO - alphas:tensor([0.2398, 0.0066, 0.0056, 0.0459, 0.7022], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,961 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,961 - train - INFO - True
2024-04-07 08:48:39,962 - train - INFO - alphas:tensor([0.2452, 0.0048, 0.0063, 0.0349, 0.7087], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,963 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,963 - train - INFO - True
2024-04-07 08:48:39,964 - train - INFO - alphas:tensor([0.2467, 0.0032, 0.0054, 0.0397, 0.7049], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,965 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,965 - train - INFO - True
2024-04-07 08:48:39,966 - train - INFO - alphas:tensor([0.2337, 0.0057, 0.0057, 0.0471, 0.7077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,967 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,967 - train - INFO - True
2024-04-07 08:48:39,968 - train - INFO - alphas:tensor([0.5647, 0.0051, 0.0104, 0.0406, 0.3791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,970 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,970 - train - INFO - True
2024-04-07 08:48:39,971 - train - INFO - alphas:tensor([0.6682, 0.0066, 0.0086, 0.0287, 0.2879], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,975 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,975 - train - INFO - True
2024-04-07 08:48:39,977 - train - INFO - alphas:tensor([0.2599, 0.0130, 0.0134, 0.0811, 0.6325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,979 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,979 - train - INFO - True
2024-04-07 08:48:39,980 - train - INFO - alphas:tensor([0.2736, 0.0070, 0.0093, 0.0755, 0.6346], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,982 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,982 - train - INFO - True
2024-04-07 08:48:39,984 - train - INFO - alphas:tensor([0.2928, 0.0054, 0.0092, 0.0671, 0.6256], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,986 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,986 - train - INFO - True
2024-04-07 08:48:39,987 - train - INFO - alphas:tensor([0.2702, 0.0084, 0.0111, 0.0645, 0.6459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,989 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,989 - train - INFO - True
2024-04-07 08:48:39,990 - train - INFO - alphas:tensor([0.2970, 0.0056, 0.0125, 0.0676, 0.6172], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,992 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,993 - train - INFO - True
2024-04-07 08:48:39,994 - train - INFO - alphas:tensor([0.2559, 0.0138, 0.0175, 0.0761, 0.6367], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:39,996 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:39,996 - train - INFO - True
2024-04-07 08:48:39,997 - train - INFO - alphas:tensor([0.6134, 0.0038, 0.0072, 0.0422, 0.3335], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:40,000 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:40,001 - train - INFO - True
2024-04-07 08:48:40,002 - train - INFO - alphas:tensor([0.5397, 0.0035, 0.0048, 0.0429, 0.4091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:40,009 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:40,010 - train - INFO - True
2024-04-07 08:48:40,010 - train - INFO - alphas:tensor([0.4124, 0.0031, 0.0094, 0.0595, 0.5156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:40,015 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:40,015 - train - INFO - True
2024-04-07 08:48:40,016 - train - INFO - alphas:tensor([0.4320, 0.0032, 0.0050, 0.0540, 0.5058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:40,019 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:40,020 - train - INFO - True
2024-04-07 08:48:40,020 - train - INFO - alphas:tensor([0.4444, 0.0028, 0.0051, 0.0515, 0.4963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:40,024 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:40,024 - train - INFO - True
2024-04-07 08:48:40,025 - train - INFO - alphas:tensor([0.4067, 0.0033, 0.0077, 0.0569, 0.5254], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:40,029 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:40,029 - train - INFO - True
2024-04-07 08:48:40,030 - train - INFO - alphas:tensor([0.5577, 0.0028, 0.0064, 0.0353, 0.3978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:40,038 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:40,038 - train - INFO - True
2024-04-07 08:48:40,039 - train - INFO - alphas:tensor([0.7175, 0.0022, 0.0050, 0.0268, 0.2485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:40,058 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:40,058 - train - INFO - True
2024-04-07 08:48:40,059 - train - INFO - alphas:tensor([0.3730, 0.0037, 0.0072, 0.0676, 0.5485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:40,069 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:40,070 - train - INFO - True
2024-04-07 08:48:40,070 - train - INFO - alphas:tensor([0.3808, 0.0023, 0.0057, 0.0558, 0.5554], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:40,081 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:40,081 - train - INFO - True
2024-04-07 08:48:40,082 - train - INFO - alphas:tensor([0.4154, 0.0026, 0.0046, 0.0563, 0.5210], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:40,092 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:40,092 - train - INFO - True
2024-04-07 08:48:40,093 - train - INFO - alphas:tensor([0.3777, 0.0031, 0.0064, 0.0590, 0.5538], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:40,103 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:40,103 - train - INFO - True
2024-04-07 08:48:40,104 - train - INFO - alphas:tensor([0.7070, 0.0019, 0.0030, 0.0214, 0.2667], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:40,124 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:40,124 - train - INFO - True
2024-04-07 08:48:40,125 - train - INFO - alphas:tensor([0.5458, 0.0094, 0.0144, 0.0622, 0.3682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:48:40,203 - train - INFO - tau:0.37723664692350434
2024-04-07 08:48:40,203 - train - INFO - avg block size:10.06060606060606
2024-04-07 08:48:40,204 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 08:48:40,407 - train - INFO - Test: [   0/78]  Time: 0.200 (0.200)  Loss:  0.9580 (0.9580)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.9688 (92.9688)
2024-04-07 08:48:43,768 - train - INFO - Test: [  50/78]  Time: 0.050 (0.070)  Loss:  1.6611 (1.5723)  Acc@1: 63.2812 (65.6710)  Acc@5: 82.0312 (86.0141)
2024-04-07 08:48:45,232 - train - INFO - Test: [  78/78]  Time: 0.048 (0.064)  Loss:  1.6670 (1.5958)  Acc@1: 75.0000 (65.3300)  Acc@5: 100.0000 (85.7300)
2024-04-07 08:48:45,982 - train - INFO - Train: 100 [   0/781 (  0%)]  Loss:  3.752530 (3.7525)  Time: 0.668s,  191.59/s  (0.668s,  191.59/s)  LR: 1.325e-04  Data: 0.182 (0.182)
2024-04-07 08:49:09,339 - train - INFO - Train: 100 [  50/781 (  6%)]  Loss:  3.244576 (3.5336)  Time: 0.483s,  265.10/s  (0.471s,  271.73/s)  LR: 1.325e-04  Data: 0.007 (0.011)
2024-04-07 08:49:32,707 - train - INFO - Train: 100 [ 100/781 ( 13%)]  Loss:  3.417602 (3.5267)  Time: 0.444s,  288.35/s  (0.469s,  272.80/s)  LR: 1.325e-04  Data: 0.006 (0.009)
2024-04-07 08:49:55,293 - train - INFO - Train: 100 [ 150/781 ( 19%)]  Loss:  3.424928 (3.5206)  Time: 0.446s,  287.24/s  (0.463s,  276.21/s)  LR: 1.325e-04  Data: 0.007 (0.009)
2024-04-07 08:50:18,268 - train - INFO - Train: 100 [ 200/781 ( 26%)]  Loss:  3.563913 (3.5184)  Time: 0.375s,  341.41/s  (0.462s,  276.80/s)  LR: 1.325e-04  Data: 0.004 (0.008)
2024-04-07 08:50:41,206 - train - INFO - Train: 100 [ 250/781 ( 32%)]  Loss:  3.112105 (3.5177)  Time: 0.518s,  247.16/s  (0.462s,  277.24/s)  LR: 1.325e-04  Data: 0.009 (0.008)
2024-04-07 08:51:04,255 - train - INFO - Train: 100 [ 300/781 ( 38%)]  Loss:  3.518737 (3.5171)  Time: 0.474s,  269.82/s  (0.462s,  277.32/s)  LR: 1.325e-04  Data: 0.008 (0.008)
2024-04-07 08:51:28,779 - train - INFO - Train: 100 [ 350/781 ( 45%)]  Loss:  3.416183 (3.5136)  Time: 0.508s,  252.04/s  (0.466s,  274.87/s)  LR: 1.325e-04  Data: 0.010 (0.008)
2024-04-07 08:51:52,500 - train - INFO - Train: 100 [ 400/781 ( 51%)]  Loss:  3.489581 (3.5175)  Time: 0.477s,  268.40/s  (0.467s,  274.23/s)  LR: 1.325e-04  Data: 0.006 (0.008)
2024-04-07 08:52:15,959 - train - INFO - Train: 100 [ 450/781 ( 58%)]  Loss:  3.394034 (3.5147)  Time: 0.383s,  334.61/s  (0.467s,  274.07/s)  LR: 1.325e-04  Data: 0.009 (0.008)
2024-04-07 08:52:39,116 - train - INFO - Train: 100 [ 500/781 ( 64%)]  Loss:  3.870710 (3.5136)  Time: 0.495s,  258.67/s  (0.467s,  274.30/s)  LR: 1.325e-04  Data: 0.009 (0.008)
2024-04-07 08:53:02,709 - train - INFO - Train: 100 [ 550/781 ( 71%)]  Loss:  3.263713 (3.5189)  Time: 0.387s,  330.98/s  (0.467s,  274.03/s)  LR: 1.325e-04  Data: 0.006 (0.008)
2024-04-07 08:53:25,829 - train - INFO - Train: 100 [ 600/781 ( 77%)]  Loss:  3.737622 (3.5189)  Time: 0.486s,  263.23/s  (0.467s,  274.26/s)  LR: 1.325e-04  Data: 0.008 (0.008)
2024-04-07 08:53:48,887 - train - INFO - Train: 100 [ 650/781 ( 83%)]  Loss:  3.832400 (3.5217)  Time: 0.470s,  272.27/s  (0.466s,  274.51/s)  LR: 1.325e-04  Data: 0.008 (0.008)
2024-04-07 08:54:12,457 - train - INFO - Train: 100 [ 700/781 ( 90%)]  Loss:  3.647883 (3.5248)  Time: 0.401s,  319.02/s  (0.467s,  274.30/s)  LR: 1.325e-04  Data: 0.005 (0.008)
2024-04-07 08:54:36,606 - train - INFO - Train: 100 [ 750/781 ( 96%)]  Loss:  3.330013 (3.5264)  Time: 0.471s,  271.83/s  (0.468s,  273.66/s)  LR: 1.325e-04  Data: 0.006 (0.008)
2024-04-07 08:54:50,446 - train - INFO - Train: 100 [ 780/781 (100%)]  Loss:  3.570001 (3.5261)  Time: 0.467s,  274.04/s  (0.467s,  273.81/s)  LR: 1.325e-04  Data: 0.000 (0.008)
2024-04-07 08:54:50,447 - train - INFO - True
2024-04-07 08:54:50,449 - train - INFO - alphas:tensor([0.6673, 0.0310, 0.0500, 0.0718, 0.1799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,450 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,450 - train - INFO - True
2024-04-07 08:54:50,451 - train - INFO - alphas:tensor([0.4443, 0.0116, 0.0240, 0.0639, 0.4563], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,452 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,452 - train - INFO - True
2024-04-07 08:54:50,453 - train - INFO - alphas:tensor([0.4867, 0.0209, 0.0594, 0.4330], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,454 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,455 - train - INFO - True
2024-04-07 08:54:50,456 - train - INFO - alphas:tensor([0.4293, 0.0207, 0.0430, 0.5070], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,457 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,457 - train - INFO - True
2024-04-07 08:54:50,458 - train - INFO - alphas:tensor([0.4301, 0.0138, 0.0519, 0.5042], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,459 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,459 - train - INFO - True
2024-04-07 08:54:50,460 - train - INFO - alphas:tensor([0.5184, 0.0210, 0.0439, 0.4167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,461 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,461 - train - INFO - True
2024-04-07 08:54:50,463 - train - INFO - alphas:tensor([0.5659, 0.0116, 0.0162, 0.0452, 0.3610], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,464 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,464 - train - INFO - True
2024-04-07 08:54:50,465 - train - INFO - alphas:tensor([0.2371, 0.0064, 0.0053, 0.0454, 0.7057], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,466 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,467 - train - INFO - True
2024-04-07 08:54:50,468 - train - INFO - alphas:tensor([0.2463, 0.0047, 0.0061, 0.0344, 0.7085], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,469 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,469 - train - INFO - True
2024-04-07 08:54:50,470 - train - INFO - alphas:tensor([0.2480, 0.0031, 0.0052, 0.0391, 0.7046], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,471 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,471 - train - INFO - True
2024-04-07 08:54:50,472 - train - INFO - alphas:tensor([0.2326, 0.0055, 0.0055, 0.0462, 0.7102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,473 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,473 - train - INFO - True
2024-04-07 08:54:50,474 - train - INFO - alphas:tensor([0.5624, 0.0049, 0.0101, 0.0399, 0.3828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,476 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,476 - train - INFO - True
2024-04-07 08:54:50,477 - train - INFO - alphas:tensor([0.6706, 0.0063, 0.0082, 0.0279, 0.2869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,482 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,482 - train - INFO - True
2024-04-07 08:54:50,483 - train - INFO - alphas:tensor([0.2603, 0.0128, 0.0130, 0.0799, 0.6340], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,485 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,486 - train - INFO - True
2024-04-07 08:54:50,487 - train - INFO - alphas:tensor([0.2745, 0.0067, 0.0090, 0.0747, 0.6351], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,489 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,489 - train - INFO - True
2024-04-07 08:54:50,490 - train - INFO - alphas:tensor([0.2937, 0.0052, 0.0088, 0.0665, 0.6257], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,493 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,493 - train - INFO - True
2024-04-07 08:54:50,494 - train - INFO - alphas:tensor([0.2676, 0.0081, 0.0107, 0.0636, 0.6500], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,496 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,496 - train - INFO - True
2024-04-07 08:54:50,497 - train - INFO - alphas:tensor([0.2981, 0.0055, 0.0123, 0.0668, 0.6173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,499 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,500 - train - INFO - True
2024-04-07 08:54:50,501 - train - INFO - alphas:tensor([0.2557, 0.0132, 0.0170, 0.0744, 0.6397], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,503 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,503 - train - INFO - True
2024-04-07 08:54:50,504 - train - INFO - alphas:tensor([0.6146, 0.0036, 0.0069, 0.0413, 0.3335], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,508 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,508 - train - INFO - True
2024-04-07 08:54:50,509 - train - INFO - alphas:tensor([0.5420, 0.0034, 0.0046, 0.0418, 0.4082], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,517 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,517 - train - INFO - True
2024-04-07 08:54:50,518 - train - INFO - alphas:tensor([0.4170, 0.0029, 0.0091, 0.0583, 0.5127], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,522 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,522 - train - INFO - True
2024-04-07 08:54:50,523 - train - INFO - alphas:tensor([0.4313, 0.0031, 0.0049, 0.0539, 0.5068], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,527 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,527 - train - INFO - True
2024-04-07 08:54:50,528 - train - INFO - alphas:tensor([0.4432, 0.0027, 0.0048, 0.0504, 0.4988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,532 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,532 - train - INFO - True
2024-04-07 08:54:50,533 - train - INFO - alphas:tensor([0.4053, 0.0032, 0.0075, 0.0563, 0.5277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,537 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,537 - train - INFO - True
2024-04-07 08:54:50,538 - train - INFO - alphas:tensor([0.5540, 0.0027, 0.0062, 0.0353, 0.4018], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,545 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,545 - train - INFO - True
2024-04-07 08:54:50,546 - train - INFO - alphas:tensor([0.7194, 0.0021, 0.0049, 0.0264, 0.2473], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,566 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,566 - train - INFO - True
2024-04-07 08:54:50,567 - train - INFO - alphas:tensor([0.3704, 0.0035, 0.0070, 0.0676, 0.5515], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,577 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,577 - train - INFO - True
2024-04-07 08:54:50,578 - train - INFO - alphas:tensor([0.3791, 0.0022, 0.0056, 0.0551, 0.5581], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,588 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,588 - train - INFO - True
2024-04-07 08:54:50,589 - train - INFO - alphas:tensor([0.4159, 0.0025, 0.0045, 0.0559, 0.5213], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,599 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,599 - train - INFO - True
2024-04-07 08:54:50,600 - train - INFO - alphas:tensor([0.3784, 0.0030, 0.0062, 0.0584, 0.5540], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,610 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,610 - train - INFO - True
2024-04-07 08:54:50,611 - train - INFO - alphas:tensor([0.7082, 0.0018, 0.0028, 0.0212, 0.2660], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,630 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,631 - train - INFO - True
2024-04-07 08:54:50,631 - train - INFO - alphas:tensor([0.5500, 0.0092, 0.0141, 0.0609, 0.3659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:50,709 - train - INFO - tau:0.37346428045426927
2024-04-07 08:54:50,709 - train - INFO - avg block size:10.06060606060606
2024-04-07 08:54:50,710 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 08:54:50,710 - train - INFO - lasso_alpha:5.266625086121595e-06
2024-04-07 08:54:50,906 - train - INFO - Test: [   0/78]  Time: 0.193 (0.193)  Loss:  1.0029 (1.0029)  Acc@1: 79.6875 (79.6875)  Acc@5: 93.7500 (93.7500)
2024-04-07 08:54:54,250 - train - INFO - Test: [  50/78]  Time: 0.054 (0.069)  Loss:  1.7305 (1.5688)  Acc@1: 60.1562 (65.7322)  Acc@5: 84.3750 (86.2286)
2024-04-07 08:54:55,722 - train - INFO - Test: [  78/78]  Time: 0.045 (0.063)  Loss:  1.6963 (1.5905)  Acc@1: 62.5000 (65.3500)  Acc@5: 100.0000 (85.7800)
2024-04-07 08:54:56,320 - train - INFO - Train: 101 [   0/781 (  0%)]  Loss:  3.725856 (3.7259)  Time: 0.522s,  245.34/s  (0.522s,  245.34/s)  LR: 1.281e-04  Data: 0.165 (0.165)
2024-04-07 08:55:19,457 - train - INFO - Train: 101 [  50/781 (  6%)]  Loss:  3.349324 (3.5127)  Time: 0.513s,  249.67/s  (0.464s,  275.93/s)  LR: 1.281e-04  Data: 0.009 (0.010)
2024-04-07 08:55:43,302 - train - INFO - Train: 101 [ 100/781 ( 13%)]  Loss:  3.022290 (3.5132)  Time: 0.465s,  275.11/s  (0.470s,  272.17/s)  LR: 1.281e-04  Data: 0.009 (0.009)
2024-04-07 08:56:06,700 - train - INFO - Train: 101 [ 150/781 ( 19%)]  Loss:  3.825338 (3.5099)  Time: 0.488s,  262.08/s  (0.470s,  272.62/s)  LR: 1.281e-04  Data: 0.008 (0.009)
2024-04-07 08:56:30,757 - train - INFO - Train: 101 [ 200/781 ( 26%)]  Loss:  3.372079 (3.5120)  Time: 0.470s,  272.54/s  (0.472s,  270.96/s)  LR: 1.281e-04  Data: 0.006 (0.009)
2024-04-07 08:56:53,821 - train - INFO - Train: 101 [ 250/781 ( 32%)]  Loss:  3.170507 (3.5146)  Time: 0.503s,  254.51/s  (0.470s,  272.24/s)  LR: 1.281e-04  Data: 0.008 (0.008)
2024-04-07 08:57:17,057 - train - INFO - Train: 101 [ 300/781 ( 38%)]  Loss:  3.189811 (3.5045)  Time: 0.470s,  272.07/s  (0.469s,  272.77/s)  LR: 1.281e-04  Data: 0.006 (0.008)
2024-04-07 08:57:39,880 - train - INFO - Train: 101 [ 350/781 ( 45%)]  Loss:  3.776309 (3.5057)  Time: 0.509s,  251.40/s  (0.467s,  273.84/s)  LR: 1.281e-04  Data: 0.008 (0.008)
2024-04-07 08:58:03,073 - train - INFO - Train: 101 [ 400/781 ( 51%)]  Loss:  3.678342 (3.5081)  Time: 0.465s,  275.02/s  (0.467s,  274.10/s)  LR: 1.281e-04  Data: 0.010 (0.008)
2024-04-07 08:58:27,071 - train - INFO - Train: 101 [ 450/781 ( 58%)]  Loss:  3.315792 (3.5095)  Time: 0.495s,  258.52/s  (0.468s,  273.26/s)  LR: 1.281e-04  Data: 0.008 (0.008)
2024-04-07 08:58:51,040 - train - INFO - Train: 101 [ 500/781 ( 64%)]  Loss:  3.872782 (3.5121)  Time: 0.454s,  282.04/s  (0.470s,  272.62/s)  LR: 1.281e-04  Data: 0.008 (0.008)
2024-04-07 08:59:12,940 - train - INFO - Train: 101 [ 550/781 ( 71%)]  Loss:  3.454122 (3.5153)  Time: 0.502s,  254.77/s  (0.467s,  274.30/s)  LR: 1.281e-04  Data: 0.008 (0.008)
2024-04-07 08:59:36,240 - train - INFO - Train: 101 [ 600/781 ( 77%)]  Loss:  3.564389 (3.5177)  Time: 0.504s,  253.80/s  (0.467s,  274.33/s)  LR: 1.281e-04  Data: 0.008 (0.008)
2024-04-07 08:59:59,507 - train - INFO - Train: 101 [ 650/781 ( 83%)]  Loss:  3.389979 (3.5166)  Time: 0.438s,  292.35/s  (0.466s,  274.39/s)  LR: 1.281e-04  Data: 0.006 (0.008)
2024-04-07 09:00:22,707 - train - INFO - Train: 101 [ 700/781 ( 90%)]  Loss:  3.702393 (3.5167)  Time: 0.395s,  323.81/s  (0.466s,  274.49/s)  LR: 1.281e-04  Data: 0.008 (0.008)
2024-04-07 09:00:44,921 - train - INFO - Train: 101 [ 750/781 ( 96%)]  Loss:  3.236093 (3.5171)  Time: 0.472s,  271.04/s  (0.465s,  275.36/s)  LR: 1.281e-04  Data: 0.008 (0.008)
2024-04-07 09:00:58,898 - train - INFO - Train: 101 [ 780/781 (100%)]  Loss:  3.348318 (3.5192)  Time: 0.507s,  252.62/s  (0.465s,  275.34/s)  LR: 1.281e-04  Data: 0.000 (0.008)
2024-04-07 09:00:58,900 - train - INFO - True
2024-04-07 09:00:58,902 - train - INFO - alphas:tensor([0.6716, 0.0302, 0.0487, 0.0707, 0.1788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,903 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,903 - train - INFO - True
2024-04-07 09:00:58,905 - train - INFO - alphas:tensor([0.4456, 0.0112, 0.0233, 0.0632, 0.4566], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,905 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,905 - train - INFO - True
2024-04-07 09:00:58,907 - train - INFO - alphas:tensor([0.4869, 0.0203, 0.0585, 0.4343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,908 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,908 - train - INFO - True
2024-04-07 09:00:58,910 - train - INFO - alphas:tensor([0.4296, 0.0202, 0.0421, 0.5081], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,911 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,911 - train - INFO - True
2024-04-07 09:00:58,912 - train - INFO - alphas:tensor([0.4295, 0.0133, 0.0512, 0.5060], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,913 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,913 - train - INFO - True
2024-04-07 09:00:58,914 - train - INFO - alphas:tensor([0.5183, 0.0205, 0.0432, 0.4179], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,916 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,916 - train - INFO - True
2024-04-07 09:00:58,917 - train - INFO - alphas:tensor([0.5664, 0.0112, 0.0158, 0.0444, 0.3622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,919 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,919 - train - INFO - True
2024-04-07 09:00:58,920 - train - INFO - alphas:tensor([0.2396, 0.0062, 0.0051, 0.0449, 0.7041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,921 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,922 - train - INFO - True
2024-04-07 09:00:58,923 - train - INFO - alphas:tensor([0.2483, 0.0045, 0.0059, 0.0336, 0.7077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,924 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,924 - train - INFO - True
2024-04-07 09:00:58,926 - train - INFO - alphas:tensor([0.2496, 0.0030, 0.0051, 0.0385, 0.7038], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,927 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,927 - train - INFO - True
2024-04-07 09:00:58,928 - train - INFO - alphas:tensor([0.2343, 0.0053, 0.0053, 0.0460, 0.7091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,929 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,929 - train - INFO - True
2024-04-07 09:00:58,930 - train - INFO - alphas:tensor([0.5637, 0.0047, 0.0098, 0.0393, 0.3825], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,932 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,932 - train - INFO - True
2024-04-07 09:00:58,933 - train - INFO - alphas:tensor([0.6712, 0.0061, 0.0079, 0.0273, 0.2874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,938 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,939 - train - INFO - True
2024-04-07 09:00:58,940 - train - INFO - alphas:tensor([0.2608, 0.0125, 0.0128, 0.0789, 0.6351], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,942 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,943 - train - INFO - True
2024-04-07 09:00:58,944 - train - INFO - alphas:tensor([0.2793, 0.0065, 0.0086, 0.0735, 0.6321], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,946 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,946 - train - INFO - True
2024-04-07 09:00:58,948 - train - INFO - alphas:tensor([0.2959, 0.0050, 0.0086, 0.0653, 0.6253], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,950 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,950 - train - INFO - True
2024-04-07 09:00:58,951 - train - INFO - alphas:tensor([0.2707, 0.0078, 0.0104, 0.0624, 0.6486], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,954 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,954 - train - INFO - True
2024-04-07 09:00:58,955 - train - INFO - alphas:tensor([0.3021, 0.0053, 0.0120, 0.0661, 0.6145], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,957 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,958 - train - INFO - True
2024-04-07 09:00:58,959 - train - INFO - alphas:tensor([0.2544, 0.0128, 0.0165, 0.0732, 0.6431], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,961 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,961 - train - INFO - True
2024-04-07 09:00:58,962 - train - INFO - alphas:tensor([0.6149, 0.0034, 0.0067, 0.0408, 0.3341], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,966 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,967 - train - INFO - True
2024-04-07 09:00:58,968 - train - INFO - alphas:tensor([0.5423, 0.0032, 0.0044, 0.0411, 0.4089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,976 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,976 - train - INFO - True
2024-04-07 09:00:58,977 - train - INFO - alphas:tensor([0.4186, 0.0028, 0.0087, 0.0570, 0.5129], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,982 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,982 - train - INFO - True
2024-04-07 09:00:58,983 - train - INFO - alphas:tensor([0.4299, 0.0029, 0.0047, 0.0537, 0.5088], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,987 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,987 - train - INFO - True
2024-04-07 09:00:58,988 - train - INFO - alphas:tensor([0.4468, 0.0026, 0.0046, 0.0495, 0.4965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,992 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,992 - train - INFO - True
2024-04-07 09:00:58,993 - train - INFO - alphas:tensor([0.4089, 0.0030, 0.0073, 0.0555, 0.5254], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:58,997 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:58,997 - train - INFO - True
2024-04-07 09:00:58,998 - train - INFO - alphas:tensor([0.5602, 0.0026, 0.0059, 0.0344, 0.3970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:59,006 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:59,006 - train - INFO - True
2024-04-07 09:00:59,007 - train - INFO - alphas:tensor([0.7186, 0.0020, 0.0047, 0.0259, 0.2489], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:59,026 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:59,027 - train - INFO - True
2024-04-07 09:00:59,027 - train - INFO - alphas:tensor([0.3776, 0.0034, 0.0067, 0.0662, 0.5460], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:59,038 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:59,038 - train - INFO - True
2024-04-07 09:00:59,039 - train - INFO - alphas:tensor([0.3864, 0.0021, 0.0053, 0.0539, 0.5523], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:59,049 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:59,049 - train - INFO - True
2024-04-07 09:00:59,050 - train - INFO - alphas:tensor([0.4164, 0.0024, 0.0043, 0.0554, 0.5215], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:59,060 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:59,060 - train - INFO - True
2024-04-07 09:00:59,061 - train - INFO - alphas:tensor([0.3780, 0.0029, 0.0060, 0.0582, 0.5549], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:59,071 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:59,071 - train - INFO - True
2024-04-07 09:00:59,072 - train - INFO - alphas:tensor([0.7132, 0.0017, 0.0027, 0.0207, 0.2617], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:59,091 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:59,092 - train - INFO - True
2024-04-07 09:00:59,092 - train - INFO - alphas:tensor([0.5493, 0.0090, 0.0138, 0.0607, 0.3672], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:00:59,170 - train - INFO - tau:0.36972963764972655
2024-04-07 09:00:59,170 - train - INFO - avg block size:10.06060606060606
2024-04-07 09:00:59,170 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 09:00:59,386 - train - INFO - Test: [   0/78]  Time: 0.211 (0.211)  Loss:  0.9956 (0.9956)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 09:01:02,203 - train - INFO - Test: [  50/78]  Time: 0.050 (0.059)  Loss:  1.5420 (1.5451)  Acc@1: 63.2812 (65.8854)  Acc@5: 87.5000 (86.3205)
2024-04-07 09:01:03,643 - train - INFO - Test: [  78/78]  Time: 0.054 (0.057)  Loss:  1.9092 (1.5707)  Acc@1: 50.0000 (65.3800)  Acc@5: 93.7500 (85.8100)
2024-04-07 09:01:04,394 - train - INFO - Train: 102 [   0/781 (  0%)]  Loss:  3.649803 (3.6498)  Time: 0.673s,  190.15/s  (0.673s,  190.15/s)  LR: 1.237e-04  Data: 0.192 (0.192)
2024-04-07 09:01:28,424 - train - INFO - Train: 102 [  50/781 (  6%)]  Loss:  3.392588 (3.5395)  Time: 0.496s,  258.14/s  (0.484s,  264.28/s)  LR: 1.237e-04  Data: 0.008 (0.011)
2024-04-07 09:01:51,872 - train - INFO - Train: 102 [ 100/781 ( 13%)]  Loss:  3.758808 (3.5138)  Time: 0.501s,  255.62/s  (0.477s,  268.50/s)  LR: 1.237e-04  Data: 0.008 (0.009)
2024-04-07 09:02:15,688 - train - INFO - Train: 102 [ 150/781 ( 19%)]  Loss:  3.368174 (3.5048)  Time: 0.398s,  321.55/s  (0.477s,  268.58/s)  LR: 1.237e-04  Data: 0.006 (0.009)
2024-04-07 09:02:38,012 - train - INFO - Train: 102 [ 200/781 ( 26%)]  Loss:  3.453734 (3.5168)  Time: 0.449s,  285.16/s  (0.469s,  272.87/s)  LR: 1.237e-04  Data: 0.012 (0.008)
2024-04-07 09:03:01,244 - train - INFO - Train: 102 [ 250/781 ( 32%)]  Loss:  3.485495 (3.5088)  Time: 0.436s,  293.43/s  (0.468s,  273.39/s)  LR: 1.237e-04  Data: 0.009 (0.008)
2024-04-07 09:03:24,407 - train - INFO - Train: 102 [ 300/781 ( 38%)]  Loss:  3.599056 (3.5138)  Time: 0.456s,  280.84/s  (0.467s,  273.88/s)  LR: 1.237e-04  Data: 0.010 (0.008)
2024-04-07 09:03:47,057 - train - INFO - Train: 102 [ 350/781 ( 45%)]  Loss:  3.615977 (3.5191)  Time: 0.341s,  374.94/s  (0.465s,  275.08/s)  LR: 1.237e-04  Data: 0.004 (0.008)
2024-04-07 09:04:10,146 - train - INFO - Train: 102 [ 400/781 ( 51%)]  Loss:  3.371974 (3.5128)  Time: 0.551s,  232.30/s  (0.465s,  275.35/s)  LR: 1.237e-04  Data: 0.009 (0.008)
2024-04-07 09:04:33,492 - train - INFO - Train: 102 [ 450/781 ( 58%)]  Loss:  3.730648 (3.5227)  Time: 0.503s,  254.61/s  (0.465s,  275.21/s)  LR: 1.237e-04  Data: 0.009 (0.008)
2024-04-07 09:04:57,621 - train - INFO - Train: 102 [ 500/781 ( 64%)]  Loss:  3.886073 (3.5182)  Time: 0.469s,  273.04/s  (0.467s,  274.19/s)  LR: 1.237e-04  Data: 0.009 (0.008)
2024-04-07 09:05:20,549 - train - INFO - Train: 102 [ 550/781 ( 71%)]  Loss:  3.276653 (3.5212)  Time: 0.344s,  371.65/s  (0.466s,  274.63/s)  LR: 1.237e-04  Data: 0.006 (0.008)
2024-04-07 09:05:43,551 - train - INFO - Train: 102 [ 600/781 ( 77%)]  Loss:  3.980363 (3.5208)  Time: 0.501s,  255.24/s  (0.466s,  274.93/s)  LR: 1.237e-04  Data: 0.008 (0.008)
2024-04-07 09:06:06,129 - train - INFO - Train: 102 [ 650/781 ( 83%)]  Loss:  3.575967 (3.5247)  Time: 0.377s,  339.19/s  (0.464s,  275.57/s)  LR: 1.237e-04  Data: 0.004 (0.008)
2024-04-07 09:06:29,841 - train - INFO - Train: 102 [ 700/781 ( 90%)]  Loss:  3.762872 (3.5210)  Time: 0.509s,  251.51/s  (0.465s,  275.16/s)  LR: 1.237e-04  Data: 0.007 (0.008)
2024-04-07 09:06:53,502 - train - INFO - Train: 102 [ 750/781 ( 96%)]  Loss:  3.148298 (3.5187)  Time: 0.329s,  389.07/s  (0.466s,  274.84/s)  LR: 1.237e-04  Data: 0.006 (0.008)
2024-04-07 09:07:07,779 - train - INFO - Train: 102 [ 780/781 (100%)]  Loss:  3.752591 (3.5204)  Time: 0.463s,  276.72/s  (0.466s,  274.61/s)  LR: 1.237e-04  Data: 0.000 (0.008)
2024-04-07 09:07:07,781 - train - INFO - True
2024-04-07 09:07:07,783 - train - INFO - alphas:tensor([0.6750, 0.0295, 0.0479, 0.0697, 0.1780], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,784 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,784 - train - INFO - True
2024-04-07 09:07:07,786 - train - INFO - alphas:tensor([0.4467, 0.0108, 0.0228, 0.0622, 0.4574], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,787 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,787 - train - INFO - True
2024-04-07 09:07:07,788 - train - INFO - alphas:tensor([0.4868, 0.0198, 0.0577, 0.4357], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,790 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,790 - train - INFO - True
2024-04-07 09:07:07,791 - train - INFO - alphas:tensor([0.4304, 0.0198, 0.0414, 0.5084], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,792 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,792 - train - INFO - True
2024-04-07 09:07:07,794 - train - INFO - alphas:tensor([0.4326, 0.0129, 0.0503, 0.5042], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,795 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,795 - train - INFO - True
2024-04-07 09:07:07,797 - train - INFO - alphas:tensor([0.5198, 0.0201, 0.0423, 0.4177], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,798 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,798 - train - INFO - True
2024-04-07 09:07:07,799 - train - INFO - alphas:tensor([0.5659, 0.0108, 0.0154, 0.0437, 0.3642], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,801 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,802 - train - INFO - True
2024-04-07 09:07:07,803 - train - INFO - alphas:tensor([0.2371, 0.0059, 0.0049, 0.0437, 0.7084], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,804 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,804 - train - INFO - True
2024-04-07 09:07:07,806 - train - INFO - alphas:tensor([0.2481, 0.0043, 0.0057, 0.0330, 0.7089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,807 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,807 - train - INFO - True
2024-04-07 09:07:07,808 - train - INFO - alphas:tensor([0.2485, 0.0028, 0.0048, 0.0374, 0.7064], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,809 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,810 - train - INFO - True
2024-04-07 09:07:07,811 - train - INFO - alphas:tensor([0.2324, 0.0051, 0.0051, 0.0453, 0.7121], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,812 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,812 - train - INFO - True
2024-04-07 09:07:07,813 - train - INFO - alphas:tensor([0.5640, 0.0045, 0.0095, 0.0386, 0.3834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,815 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,815 - train - INFO - True
2024-04-07 09:07:07,817 - train - INFO - alphas:tensor([0.6747, 0.0058, 0.0076, 0.0265, 0.2853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,822 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,822 - train - INFO - True
2024-04-07 09:07:07,823 - train - INFO - alphas:tensor([0.2626, 0.0120, 0.0126, 0.0783, 0.6345], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,826 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,826 - train - INFO - True
2024-04-07 09:07:07,827 - train - INFO - alphas:tensor([0.2818, 0.0063, 0.0083, 0.0719, 0.6316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,830 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,830 - train - INFO - True
2024-04-07 09:07:07,831 - train - INFO - alphas:tensor([0.2989, 0.0049, 0.0083, 0.0641, 0.6239], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,834 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,834 - train - INFO - True
2024-04-07 09:07:07,835 - train - INFO - alphas:tensor([0.2698, 0.0075, 0.0100, 0.0614, 0.6514], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,838 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,838 - train - INFO - True
2024-04-07 09:07:07,839 - train - INFO - alphas:tensor([0.2998, 0.0051, 0.0116, 0.0652, 0.6183], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,841 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,842 - train - INFO - True
2024-04-07 09:07:07,843 - train - INFO - alphas:tensor([0.2589, 0.0125, 0.0161, 0.0727, 0.6399], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,845 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,845 - train - INFO - True
2024-04-07 09:07:07,846 - train - INFO - alphas:tensor([0.6152, 0.0033, 0.0064, 0.0399, 0.3352], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,851 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,851 - train - INFO - True
2024-04-07 09:07:07,852 - train - INFO - alphas:tensor([0.5407, 0.0031, 0.0042, 0.0404, 0.4116], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,861 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,861 - train - INFO - True
2024-04-07 09:07:07,862 - train - INFO - alphas:tensor([0.4176, 0.0027, 0.0082, 0.0558, 0.5157], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,866 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,867 - train - INFO - True
2024-04-07 09:07:07,868 - train - INFO - alphas:tensor([0.4318, 0.0028, 0.0045, 0.0529, 0.5081], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,872 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,872 - train - INFO - True
2024-04-07 09:07:07,873 - train - INFO - alphas:tensor([0.4452, 0.0024, 0.0044, 0.0485, 0.4995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,877 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,877 - train - INFO - True
2024-04-07 09:07:07,878 - train - INFO - alphas:tensor([0.4077, 0.0029, 0.0069, 0.0548, 0.5277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,883 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,883 - train - INFO - True
2024-04-07 09:07:07,884 - train - INFO - alphas:tensor([0.5623, 0.0024, 0.0058, 0.0337, 0.3958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,891 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,891 - train - INFO - True
2024-04-07 09:07:07,892 - train - INFO - alphas:tensor([0.7219, 0.0019, 0.0045, 0.0251, 0.2467], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,912 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,912 - train - INFO - True
2024-04-07 09:07:07,913 - train - INFO - alphas:tensor([0.3801, 0.0033, 0.0065, 0.0656, 0.5445], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,923 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,923 - train - INFO - True
2024-04-07 09:07:07,924 - train - INFO - alphas:tensor([0.3852, 0.0020, 0.0052, 0.0531, 0.5545], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,934 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,934 - train - INFO - True
2024-04-07 09:07:07,935 - train - INFO - alphas:tensor([0.4180, 0.0023, 0.0042, 0.0549, 0.5207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,946 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,946 - train - INFO - True
2024-04-07 09:07:07,947 - train - INFO - alphas:tensor([0.3779, 0.0028, 0.0058, 0.0578, 0.5558], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,957 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,958 - train - INFO - True
2024-04-07 09:07:07,958 - train - INFO - alphas:tensor([0.7135, 0.0016, 0.0026, 0.0202, 0.2620], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:07,978 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:07,978 - train - INFO - True
2024-04-07 09:07:07,979 - train - INFO - alphas:tensor([0.5516, 0.0088, 0.0136, 0.0600, 0.3660], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:07:08,056 - train - INFO - tau:0.36603234127322926
2024-04-07 09:07:08,056 - train - INFO - avg block size:10.06060606060606
2024-04-07 09:07:08,057 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 09:07:08,057 - train - INFO - lasso_alpha:4.787840987383268e-06
2024-04-07 09:07:08,227 - train - INFO - Test: [   0/78]  Time: 0.167 (0.167)  Loss:  0.9243 (0.9243)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 09:07:10,980 - train - INFO - Test: [  50/78]  Time: 0.049 (0.057)  Loss:  1.5371 (1.5484)  Acc@1: 67.9688 (65.4718)  Acc@5: 85.1562 (86.3971)
2024-04-07 09:07:12,432 - train - INFO - Test: [  78/78]  Time: 0.051 (0.055)  Loss:  2.0273 (1.5681)  Acc@1: 50.0000 (65.0800)  Acc@5: 87.5000 (86.0400)
2024-04-07 09:07:13,163 - train - INFO - Train: 103 [   0/781 (  0%)]  Loss:  3.649548 (3.6495)  Time: 0.658s,  194.52/s  (0.658s,  194.52/s)  LR: 1.194e-04  Data: 0.167 (0.167)
2024-04-07 09:07:36,900 - train - INFO - Train: 103 [  50/781 (  6%)]  Loss:  3.413807 (3.5559)  Time: 0.506s,  252.99/s  (0.478s,  267.61/s)  LR: 1.194e-04  Data: 0.009 (0.011)
2024-04-07 09:08:00,113 - train - INFO - Train: 103 [ 100/781 ( 13%)]  Loss:  3.759799 (3.5437)  Time: 0.491s,  260.54/s  (0.471s,  271.57/s)  LR: 1.194e-04  Data: 0.007 (0.009)
2024-04-07 09:08:23,077 - train - INFO - Train: 103 [ 150/781 ( 19%)]  Loss:  3.501609 (3.5416)  Time: 0.478s,  267.95/s  (0.467s,  273.90/s)  LR: 1.194e-04  Data: 0.008 (0.009)
2024-04-07 09:08:46,284 - train - INFO - Train: 103 [ 200/781 ( 26%)]  Loss:  3.518159 (3.5246)  Time: 0.462s,  276.92/s  (0.467s,  274.37/s)  LR: 1.194e-04  Data: 0.005 (0.008)
2024-04-07 09:09:09,175 - train - INFO - Train: 103 [ 250/781 ( 32%)]  Loss:  3.554164 (3.5307)  Time: 0.463s,  276.52/s  (0.465s,  275.40/s)  LR: 1.194e-04  Data: 0.009 (0.008)
2024-04-07 09:09:32,558 - train - INFO - Train: 103 [ 300/781 ( 38%)]  Loss:  3.486189 (3.5321)  Time: 0.481s,  266.25/s  (0.465s,  275.12/s)  LR: 1.194e-04  Data: 0.005 (0.008)
2024-04-07 09:09:55,918 - train - INFO - Train: 103 [ 350/781 ( 45%)]  Loss:  3.361497 (3.5281)  Time: 0.486s,  263.49/s  (0.466s,  274.96/s)  LR: 1.194e-04  Data: 0.007 (0.008)
2024-04-07 09:10:18,239 - train - INFO - Train: 103 [ 400/781 ( 51%)]  Loss:  3.756763 (3.5286)  Time: 0.329s,  388.65/s  (0.463s,  276.37/s)  LR: 1.194e-04  Data: 0.007 (0.008)
2024-04-07 09:10:41,298 - train - INFO - Train: 103 [ 450/781 ( 58%)]  Loss:  3.620405 (3.5276)  Time: 0.447s,  286.35/s  (0.463s,  276.50/s)  LR: 1.194e-04  Data: 0.006 (0.008)
2024-04-07 09:11:04,059 - train - INFO - Train: 103 [ 500/781 ( 64%)]  Loss:  3.762919 (3.5261)  Time: 0.497s,  257.61/s  (0.462s,  276.97/s)  LR: 1.194e-04  Data: 0.009 (0.008)
2024-04-07 09:11:27,954 - train - INFO - Train: 103 [ 550/781 ( 71%)]  Loss:  3.238202 (3.5210)  Time: 0.368s,  347.49/s  (0.464s,  276.11/s)  LR: 1.194e-04  Data: 0.004 (0.008)
2024-04-07 09:11:51,823 - train - INFO - Train: 103 [ 600/781 ( 77%)]  Loss:  3.635305 (3.5210)  Time: 0.456s,  280.54/s  (0.465s,  275.43/s)  LR: 1.194e-04  Data: 0.008 (0.008)
2024-04-07 09:12:14,415 - train - INFO - Train: 103 [ 650/781 ( 83%)]  Loss:  3.837951 (3.5201)  Time: 0.483s,  265.15/s  (0.464s,  276.02/s)  LR: 1.194e-04  Data: 0.006 (0.008)
2024-04-07 09:12:38,160 - train - INFO - Train: 103 [ 700/781 ( 90%)]  Loss:  3.608298 (3.5121)  Time: 0.354s,  361.26/s  (0.465s,  275.55/s)  LR: 1.194e-04  Data: 0.004 (0.008)
2024-04-07 09:13:01,974 - train - INFO - Train: 103 [ 750/781 ( 96%)]  Loss:  3.241183 (3.5171)  Time: 0.493s,  259.57/s  (0.465s,  275.09/s)  LR: 1.194e-04  Data: 0.008 (0.008)
2024-04-07 09:13:16,271 - train - INFO - Train: 103 [ 780/781 (100%)]  Loss:  3.228068 (3.5187)  Time: 0.372s,  344.23/s  (0.466s,  274.83/s)  LR: 1.194e-04  Data: 0.000 (0.008)
2024-04-07 09:13:16,272 - train - INFO - True
2024-04-07 09:13:16,273 - train - INFO - alphas:tensor([0.6785, 0.0288, 0.0470, 0.0684, 0.1773], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,274 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,274 - train - INFO - True
2024-04-07 09:13:16,275 - train - INFO - alphas:tensor([0.4475, 0.0105, 0.0223, 0.0614, 0.4582], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,276 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,276 - train - INFO - True
2024-04-07 09:13:16,277 - train - INFO - alphas:tensor([0.4887, 0.0194, 0.0566, 0.4354], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,277 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,278 - train - INFO - True
2024-04-07 09:13:16,279 - train - INFO - alphas:tensor([0.4314, 0.0193, 0.0408, 0.5085], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,279 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,279 - train - INFO - True
2024-04-07 09:13:16,280 - train - INFO - alphas:tensor([0.4342, 0.0125, 0.0494, 0.5039], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,281 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,281 - train - INFO - True
2024-04-07 09:13:16,282 - train - INFO - alphas:tensor([0.5209, 0.0197, 0.0416, 0.4178], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,283 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,283 - train - INFO - True
2024-04-07 09:13:16,284 - train - INFO - alphas:tensor([0.5693, 0.0105, 0.0149, 0.0428, 0.3625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,285 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,285 - train - INFO - True
2024-04-07 09:13:16,286 - train - INFO - alphas:tensor([0.2400, 0.0057, 0.0047, 0.0430, 0.7066], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,287 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,287 - train - INFO - True
2024-04-07 09:13:16,288 - train - INFO - alphas:tensor([0.2478, 0.0042, 0.0055, 0.0324, 0.7101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,288 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,289 - train - INFO - True
2024-04-07 09:13:16,289 - train - INFO - alphas:tensor([0.2481, 0.0027, 0.0047, 0.0369, 0.7076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,290 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,290 - train - INFO - True
2024-04-07 09:13:16,291 - train - INFO - alphas:tensor([0.2324, 0.0049, 0.0049, 0.0441, 0.7137], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,292 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,292 - train - INFO - True
2024-04-07 09:13:16,293 - train - INFO - alphas:tensor([0.5683, 0.0043, 0.0091, 0.0376, 0.3808], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,294 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,294 - train - INFO - True
2024-04-07 09:13:16,295 - train - INFO - alphas:tensor([0.6764, 0.0056, 0.0073, 0.0258, 0.2848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,299 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,299 - train - INFO - True
2024-04-07 09:13:16,300 - train - INFO - alphas:tensor([0.2642, 0.0117, 0.0122, 0.0782, 0.6337], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,301 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,302 - train - INFO - True
2024-04-07 09:13:16,302 - train - INFO - alphas:tensor([0.2792, 0.0060, 0.0081, 0.0713, 0.6353], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,304 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,304 - train - INFO - True
2024-04-07 09:13:16,305 - train - INFO - alphas:tensor([0.2961, 0.0047, 0.0080, 0.0630, 0.6282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,307 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,307 - train - INFO - True
2024-04-07 09:13:16,308 - train - INFO - alphas:tensor([0.2720, 0.0071, 0.0096, 0.0607, 0.6506], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,310 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,310 - train - INFO - True
2024-04-07 09:13:16,311 - train - INFO - alphas:tensor([0.3008, 0.0048, 0.0112, 0.0637, 0.6194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,313 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,313 - train - INFO - True
2024-04-07 09:13:16,314 - train - INFO - alphas:tensor([0.2597, 0.0121, 0.0157, 0.0720, 0.6405], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,316 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,316 - train - INFO - True
2024-04-07 09:13:16,316 - train - INFO - alphas:tensor([0.6161, 0.0031, 0.0062, 0.0391, 0.3355], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,320 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,320 - train - INFO - True
2024-04-07 09:13:16,321 - train - INFO - alphas:tensor([0.5417, 0.0029, 0.0041, 0.0395, 0.4117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,327 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,327 - train - INFO - True
2024-04-07 09:13:16,328 - train - INFO - alphas:tensor([0.4160, 0.0026, 0.0078, 0.0556, 0.5180], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,332 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,332 - train - INFO - True
2024-04-07 09:13:16,332 - train - INFO - alphas:tensor([0.4334, 0.0027, 0.0043, 0.0520, 0.5077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,336 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,336 - train - INFO - True
2024-04-07 09:13:16,337 - train - INFO - alphas:tensor([0.4485, 0.0023, 0.0043, 0.0477, 0.4973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,340 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,340 - train - INFO - True
2024-04-07 09:13:16,341 - train - INFO - alphas:tensor([0.4109, 0.0027, 0.0066, 0.0537, 0.5260], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,344 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,344 - train - INFO - True
2024-04-07 09:13:16,345 - train - INFO - alphas:tensor([0.5600, 0.0023, 0.0056, 0.0331, 0.3991], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,351 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,351 - train - INFO - True
2024-04-07 09:13:16,352 - train - INFO - alphas:tensor([0.7230, 0.0018, 0.0043, 0.0244, 0.2466], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,367 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,367 - train - INFO - True
2024-04-07 09:13:16,368 - train - INFO - alphas:tensor([0.3798, 0.0031, 0.0064, 0.0654, 0.5453], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,376 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,376 - train - INFO - True
2024-04-07 09:13:16,377 - train - INFO - alphas:tensor([0.3870, 0.0019, 0.0050, 0.0525, 0.5537], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,384 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,384 - train - INFO - True
2024-04-07 09:13:16,385 - train - INFO - alphas:tensor([0.4213, 0.0022, 0.0040, 0.0539, 0.5186], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,392 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,392 - train - INFO - True
2024-04-07 09:13:16,393 - train - INFO - alphas:tensor([0.3833, 0.0026, 0.0056, 0.0568, 0.5518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,401 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,401 - train - INFO - True
2024-04-07 09:13:16,401 - train - INFO - alphas:tensor([0.7141, 0.0015, 0.0025, 0.0196, 0.2622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,415 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,415 - train - INFO - True
2024-04-07 09:13:16,416 - train - INFO - alphas:tensor([0.5526, 0.0085, 0.0132, 0.0592, 0.3664], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:13:16,465 - train - INFO - tau:0.36237201786049694
2024-04-07 09:13:16,465 - train - INFO - avg block size:10.06060606060606
2024-04-07 09:13:16,466 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 09:13:16,697 - train - INFO - Test: [   0/78]  Time: 0.228 (0.228)  Loss:  1.0039 (1.0039)  Acc@1: 82.0312 (82.0312)  Acc@5: 92.9688 (92.9688)
2024-04-07 09:13:19,806 - train - INFO - Test: [  50/78]  Time: 0.075 (0.065)  Loss:  1.5947 (1.5914)  Acc@1: 68.7500 (65.5025)  Acc@5: 87.5000 (85.8303)
2024-04-07 09:13:21,833 - train - INFO - Test: [  78/78]  Time: 0.052 (0.068)  Loss:  1.8760 (1.6057)  Acc@1: 62.5000 (65.2800)  Acc@5: 93.7500 (85.5700)
2024-04-07 09:13:22,576 - train - INFO - Train: 104 [   0/781 (  0%)]  Loss:  3.389750 (3.3898)  Time: 0.660s,  193.88/s  (0.660s,  193.88/s)  LR: 1.152e-04  Data: 0.161 (0.161)
2024-04-07 09:13:46,251 - train - INFO - Train: 104 [  50/781 (  6%)]  Loss:  3.174610 (3.5278)  Time: 0.504s,  253.78/s  (0.477s,  268.27/s)  LR: 1.152e-04  Data: 0.009 (0.011)
2024-04-07 09:14:09,811 - train - INFO - Train: 104 [ 100/781 ( 13%)]  Loss:  3.882656 (3.5327)  Time: 0.503s,  254.65/s  (0.474s,  269.94/s)  LR: 1.152e-04  Data: 0.008 (0.009)
2024-04-07 09:14:33,778 - train - INFO - Train: 104 [ 150/781 ( 19%)]  Loss:  3.013023 (3.5308)  Time: 0.501s,  255.67/s  (0.476s,  268.98/s)  LR: 1.152e-04  Data: 0.010 (0.009)
2024-04-07 09:14:57,869 - train - INFO - Train: 104 [ 200/781 ( 26%)]  Loss:  3.870467 (3.5264)  Time: 0.470s,  272.17/s  (0.477s,  268.15/s)  LR: 1.152e-04  Data: 0.008 (0.009)
2024-04-07 09:15:21,314 - train - INFO - Train: 104 [ 250/781 ( 32%)]  Loss:  3.292262 (3.5213)  Time: 0.520s,  246.26/s  (0.476s,  269.10/s)  LR: 1.152e-04  Data: 0.006 (0.008)
2024-04-07 09:15:44,528 - train - INFO - Train: 104 [ 300/781 ( 38%)]  Loss:  3.293660 (3.5196)  Time: 0.473s,  270.61/s  (0.474s,  270.18/s)  LR: 1.152e-04  Data: 0.006 (0.008)
2024-04-07 09:16:08,095 - train - INFO - Train: 104 [ 350/781 ( 45%)]  Loss:  3.691489 (3.5148)  Time: 0.444s,  288.42/s  (0.473s,  270.38/s)  LR: 1.152e-04  Data: 0.005 (0.008)
2024-04-07 09:16:32,414 - train - INFO - Train: 104 [ 400/781 ( 51%)]  Loss:  3.608275 (3.5092)  Time: 0.473s,  270.52/s  (0.475s,  269.46/s)  LR: 1.152e-04  Data: 0.009 (0.008)
2024-04-07 09:16:56,465 - train - INFO - Train: 104 [ 450/781 ( 58%)]  Loss:  3.487039 (3.5128)  Time: 0.510s,  251.13/s  (0.476s,  269.09/s)  LR: 1.152e-04  Data: 0.009 (0.008)
2024-04-07 09:17:19,531 - train - INFO - Train: 104 [ 500/781 ( 64%)]  Loss:  3.330776 (3.5096)  Time: 0.400s,  320.11/s  (0.474s,  269.90/s)  LR: 1.152e-04  Data: 0.007 (0.008)
2024-04-07 09:17:41,955 - train - INFO - Train: 104 [ 550/781 ( 71%)]  Loss:  3.635176 (3.5131)  Time: 0.480s,  266.72/s  (0.472s,  271.24/s)  LR: 1.152e-04  Data: 0.005 (0.008)
2024-04-07 09:18:06,084 - train - INFO - Train: 104 [ 600/781 ( 77%)]  Loss:  3.265486 (3.5143)  Time: 0.504s,  254.21/s  (0.473s,  270.73/s)  LR: 1.152e-04  Data: 0.007 (0.008)
2024-04-07 09:18:29,521 - train - INFO - Train: 104 [ 650/781 ( 83%)]  Loss:  3.491158 (3.5155)  Time: 0.487s,  262.93/s  (0.472s,  270.91/s)  LR: 1.152e-04  Data: 0.007 (0.008)
2024-04-07 09:18:51,785 - train - INFO - Train: 104 [ 700/781 ( 90%)]  Loss:  3.471782 (3.5181)  Time: 0.505s,  253.56/s  (0.471s,  272.03/s)  LR: 1.152e-04  Data: 0.010 (0.008)
2024-04-07 09:19:15,012 - train - INFO - Train: 104 [ 750/781 ( 96%)]  Loss:  3.712033 (3.5189)  Time: 0.487s,  262.89/s  (0.470s,  272.26/s)  LR: 1.152e-04  Data: 0.008 (0.008)
2024-04-07 09:19:29,141 - train - INFO - Train: 104 [ 780/781 (100%)]  Loss:  3.778328 (3.5221)  Time: 0.415s,  308.23/s  (0.470s,  272.24/s)  LR: 1.152e-04  Data: 0.000 (0.008)
2024-04-07 09:19:29,142 - train - INFO - True
2024-04-07 09:19:29,143 - train - INFO - alphas:tensor([0.6824, 0.0280, 0.0461, 0.0675, 0.1760], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,143 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,144 - train - INFO - True
2024-04-07 09:19:29,144 - train - INFO - alphas:tensor([0.4494, 0.0102, 0.0217, 0.0605, 0.4582], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,145 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,145 - train - INFO - True
2024-04-07 09:19:29,146 - train - INFO - alphas:tensor([0.4898, 0.0188, 0.0556, 0.4358], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,146 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,146 - train - INFO - True
2024-04-07 09:19:29,147 - train - INFO - alphas:tensor([0.4337, 0.0189, 0.0401, 0.5073], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,147 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,147 - train - INFO - True
2024-04-07 09:19:29,148 - train - INFO - alphas:tensor([0.4349, 0.0121, 0.0483, 0.5047], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,149 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,149 - train - INFO - True
2024-04-07 09:19:29,149 - train - INFO - alphas:tensor([0.5206, 0.0191, 0.0408, 0.4194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,150 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,150 - train - INFO - True
2024-04-07 09:19:29,151 - train - INFO - alphas:tensor([0.5707, 0.0101, 0.0144, 0.0419, 0.3628], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,152 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,152 - train - INFO - True
2024-04-07 09:19:29,153 - train - INFO - alphas:tensor([0.2394, 0.0055, 0.0045, 0.0419, 0.7086], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,153 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,153 - train - INFO - True
2024-04-07 09:19:29,154 - train - INFO - alphas:tensor([0.2463, 0.0040, 0.0053, 0.0321, 0.7123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,154 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,155 - train - INFO - True
2024-04-07 09:19:29,155 - train - INFO - alphas:tensor([0.2482, 0.0026, 0.0045, 0.0362, 0.7085], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,156 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,156 - train - INFO - True
2024-04-07 09:19:29,157 - train - INFO - alphas:tensor([0.2350, 0.0047, 0.0047, 0.0436, 0.7120], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,157 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,157 - train - INFO - True
2024-04-07 09:19:29,158 - train - INFO - alphas:tensor([0.5694, 0.0041, 0.0088, 0.0368, 0.3810], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,159 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,159 - train - INFO - True
2024-04-07 09:19:29,160 - train - INFO - alphas:tensor([0.6748, 0.0054, 0.0071, 0.0254, 0.2873], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,162 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,162 - train - INFO - True
2024-04-07 09:19:29,163 - train - INFO - alphas:tensor([0.2643, 0.0114, 0.0118, 0.0780, 0.6346], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,165 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,165 - train - INFO - True
2024-04-07 09:19:29,165 - train - INFO - alphas:tensor([0.2785, 0.0058, 0.0078, 0.0704, 0.6375], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,167 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,167 - train - INFO - True
2024-04-07 09:19:29,168 - train - INFO - alphas:tensor([0.2984, 0.0044, 0.0077, 0.0623, 0.6272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,169 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,169 - train - INFO - True
2024-04-07 09:19:29,170 - train - INFO - alphas:tensor([0.2718, 0.0069, 0.0092, 0.0603, 0.6518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,171 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,171 - train - INFO - True
2024-04-07 09:19:29,172 - train - INFO - alphas:tensor([0.2966, 0.0047, 0.0109, 0.0633, 0.6246], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,173 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,174 - train - INFO - True
2024-04-07 09:19:29,174 - train - INFO - alphas:tensor([0.2596, 0.0117, 0.0153, 0.0707, 0.6428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,176 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,176 - train - INFO - True
2024-04-07 09:19:29,176 - train - INFO - alphas:tensor([0.6165, 0.0030, 0.0060, 0.0391, 0.3354], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,179 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,179 - train - INFO - True
2024-04-07 09:19:29,180 - train - INFO - alphas:tensor([0.5439, 0.0028, 0.0039, 0.0388, 0.4106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,185 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,185 - train - INFO - True
2024-04-07 09:19:29,186 - train - INFO - alphas:tensor([0.4176, 0.0024, 0.0076, 0.0547, 0.5176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,188 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,189 - train - INFO - True
2024-04-07 09:19:29,189 - train - INFO - alphas:tensor([0.4335, 0.0025, 0.0041, 0.0513, 0.5085], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,192 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,192 - train - INFO - True
2024-04-07 09:19:29,193 - train - INFO - alphas:tensor([0.4499, 0.0022, 0.0041, 0.0473, 0.4965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,195 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,195 - train - INFO - True
2024-04-07 09:19:29,196 - train - INFO - alphas:tensor([0.4115, 0.0026, 0.0064, 0.0531, 0.5263], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,199 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,199 - train - INFO - True
2024-04-07 09:19:29,199 - train - INFO - alphas:tensor([0.5605, 0.0022, 0.0054, 0.0325, 0.3993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,204 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,205 - train - INFO - True
2024-04-07 09:19:29,205 - train - INFO - alphas:tensor([0.7244, 0.0017, 0.0041, 0.0239, 0.2459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,220 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,220 - train - INFO - True
2024-04-07 09:19:29,221 - train - INFO - alphas:tensor([0.3809, 0.0030, 0.0061, 0.0642, 0.5458], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,228 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,229 - train - INFO - True
2024-04-07 09:19:29,229 - train - INFO - alphas:tensor([0.3904, 0.0018, 0.0048, 0.0516, 0.5514], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,236 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,236 - train - INFO - True
2024-04-07 09:19:29,237 - train - INFO - alphas:tensor([0.4217, 0.0021, 0.0038, 0.0532, 0.5192], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,244 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,244 - train - INFO - True
2024-04-07 09:19:29,245 - train - INFO - alphas:tensor([0.3813, 0.0025, 0.0054, 0.0565, 0.5543], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,252 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,252 - train - INFO - True
2024-04-07 09:19:29,253 - train - INFO - alphas:tensor([0.7137, 0.0015, 0.0024, 0.0192, 0.2632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,265 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,266 - train - INFO - True
2024-04-07 09:19:29,266 - train - INFO - alphas:tensor([0.5526, 0.0083, 0.0130, 0.0592, 0.3670], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:19:29,315 - train - INFO - tau:0.358748297681892
2024-04-07 09:19:29,315 - train - INFO - avg block size:10.06060606060606
2024-04-07 09:19:29,315 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 09:19:29,315 - train - INFO - lasso_alpha:4.35258271580297e-06
2024-04-07 09:19:29,531 - train - INFO - Test: [   0/78]  Time: 0.214 (0.214)  Loss:  1.0127 (1.0127)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 09:19:32,387 - train - INFO - Test: [  50/78]  Time: 0.056 (0.060)  Loss:  1.6426 (1.5668)  Acc@1: 65.6250 (65.6403)  Acc@5: 85.1562 (86.2439)
2024-04-07 09:19:33,868 - train - INFO - Test: [  78/78]  Time: 0.045 (0.058)  Loss:  1.8174 (1.5862)  Acc@1: 62.5000 (65.2900)  Acc@5: 93.7500 (85.9100)
2024-04-07 09:19:34,695 - train - INFO - Train: 105 [   0/781 (  0%)]  Loss:  3.792819 (3.7928)  Time: 0.674s,  189.81/s  (0.674s,  189.81/s)  LR: 1.110e-04  Data: 0.181 (0.181)
2024-04-07 09:19:57,729 - train - INFO - Train: 105 [  50/781 (  6%)]  Loss:  3.710164 (3.5278)  Time: 0.471s,  271.76/s  (0.465s,  275.36/s)  LR: 1.110e-04  Data: 0.009 (0.011)
2024-04-07 09:20:21,280 - train - INFO - Train: 105 [ 100/781 ( 13%)]  Loss:  3.860866 (3.5087)  Time: 0.469s,  273.06/s  (0.468s,  273.58/s)  LR: 1.110e-04  Data: 0.005 (0.009)
2024-04-07 09:20:45,406 - train - INFO - Train: 105 [ 150/781 ( 19%)]  Loss:  3.077669 (3.5264)  Time: 0.471s,  271.76/s  (0.473s,  270.78/s)  LR: 1.110e-04  Data: 0.006 (0.009)
2024-04-07 09:21:07,967 - train - INFO - Train: 105 [ 200/781 ( 26%)]  Loss:  3.612893 (3.5196)  Time: 0.482s,  265.57/s  (0.467s,  273.88/s)  LR: 1.110e-04  Data: 0.007 (0.008)
2024-04-07 09:21:31,404 - train - INFO - Train: 105 [ 250/781 ( 32%)]  Loss:  3.757800 (3.5280)  Time: 0.461s,  277.70/s  (0.468s,  273.72/s)  LR: 1.110e-04  Data: 0.005 (0.008)
2024-04-07 09:21:55,105 - train - INFO - Train: 105 [ 300/781 ( 38%)]  Loss:  3.571294 (3.5242)  Time: 0.476s,  268.94/s  (0.469s,  273.11/s)  LR: 1.110e-04  Data: 0.006 (0.008)
2024-04-07 09:22:19,156 - train - INFO - Train: 105 [ 350/781 ( 45%)]  Loss:  3.517424 (3.5242)  Time: 0.501s,  255.63/s  (0.470s,  272.09/s)  LR: 1.110e-04  Data: 0.009 (0.008)
2024-04-07 09:22:43,232 - train - INFO - Train: 105 [ 400/781 ( 51%)]  Loss:  3.376155 (3.5229)  Time: 0.387s,  330.91/s  (0.472s,  271.29/s)  LR: 1.110e-04  Data: 0.011 (0.008)
2024-04-07 09:23:06,644 - train - INFO - Train: 105 [ 450/781 ( 58%)]  Loss:  3.648093 (3.5221)  Time: 0.439s,  291.87/s  (0.471s,  271.52/s)  LR: 1.110e-04  Data: 0.009 (0.008)
2024-04-07 09:23:30,597 - train - INFO - Train: 105 [ 500/781 ( 64%)]  Loss:  3.340632 (3.5195)  Time: 0.450s,  284.67/s  (0.472s,  271.09/s)  LR: 1.110e-04  Data: 0.009 (0.008)
2024-04-07 09:23:54,990 - train - INFO - Train: 105 [ 550/781 ( 71%)]  Loss:  3.411579 (3.5201)  Time: 0.488s,  262.03/s  (0.474s,  270.27/s)  LR: 1.110e-04  Data: 0.008 (0.008)
2024-04-07 09:24:18,447 - train - INFO - Train: 105 [ 600/781 ( 77%)]  Loss:  3.799840 (3.5195)  Time: 0.505s,  253.51/s  (0.473s,  270.49/s)  LR: 1.110e-04  Data: 0.009 (0.008)
2024-04-07 09:24:41,870 - train - INFO - Train: 105 [ 650/781 ( 83%)]  Loss:  3.624606 (3.5204)  Time: 0.521s,  245.89/s  (0.473s,  270.70/s)  LR: 1.110e-04  Data: 0.009 (0.008)
2024-04-07 09:25:05,807 - train - INFO - Train: 105 [ 700/781 ( 90%)]  Loss:  3.689961 (3.5175)  Time: 0.391s,  327.37/s  (0.473s,  270.46/s)  LR: 1.110e-04  Data: 0.007 (0.008)
2024-04-07 09:25:29,520 - train - INFO - Train: 105 [ 750/781 ( 96%)]  Loss:  3.717368 (3.5176)  Time: 0.485s,  264.00/s  (0.473s,  270.42/s)  LR: 1.110e-04  Data: 0.009 (0.008)
2024-04-07 09:25:42,649 - train - INFO - Train: 105 [ 780/781 (100%)]  Loss:  3.330679 (3.5154)  Time: 0.367s,  349.00/s  (0.472s,  271.21/s)  LR: 1.110e-04  Data: 0.000 (0.008)
2024-04-07 09:25:42,651 - train - INFO - True
2024-04-07 09:25:42,653 - train - INFO - alphas:tensor([0.6847, 0.0274, 0.0454, 0.0666, 0.1759], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,654 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,654 - train - INFO - True
2024-04-07 09:25:42,656 - train - INFO - alphas:tensor([0.4518, 0.0099, 0.0212, 0.0592, 0.4580], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,657 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,657 - train - INFO - True
2024-04-07 09:25:42,658 - train - INFO - alphas:tensor([0.4920, 0.0183, 0.0546, 0.4351], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,660 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,660 - train - INFO - True
2024-04-07 09:25:42,661 - train - INFO - alphas:tensor([0.4327, 0.0184, 0.0393, 0.5095], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,662 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,662 - train - INFO - True
2024-04-07 09:25:42,664 - train - INFO - alphas:tensor([0.4375, 0.0117, 0.0473, 0.5035], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,665 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,665 - train - INFO - True
2024-04-07 09:25:42,667 - train - INFO - alphas:tensor([0.5223, 0.0186, 0.0401, 0.4189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,668 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,668 - train - INFO - True
2024-04-07 09:25:42,669 - train - INFO - alphas:tensor([0.5710, 0.0098, 0.0141, 0.0414, 0.3637], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,671 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,671 - train - INFO - True
2024-04-07 09:25:42,673 - train - INFO - alphas:tensor([0.2413, 0.0053, 0.0043, 0.0410, 0.7080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,674 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,674 - train - INFO - True
2024-04-07 09:25:42,676 - train - INFO - alphas:tensor([0.2483, 0.0038, 0.0051, 0.0316, 0.7111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,677 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,677 - train - INFO - True
2024-04-07 09:25:42,678 - train - INFO - alphas:tensor([0.2486, 0.0025, 0.0043, 0.0354, 0.7091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,679 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,680 - train - INFO - True
2024-04-07 09:25:42,681 - train - INFO - alphas:tensor([0.2345, 0.0045, 0.0045, 0.0428, 0.7136], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,682 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,682 - train - INFO - True
2024-04-07 09:25:42,683 - train - INFO - alphas:tensor([0.5702, 0.0039, 0.0085, 0.0360, 0.3814], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,685 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,685 - train - INFO - True
2024-04-07 09:25:42,687 - train - INFO - alphas:tensor([0.6777, 0.0052, 0.0068, 0.0248, 0.2856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,692 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,692 - train - INFO - True
2024-04-07 09:25:42,693 - train - INFO - alphas:tensor([0.2653, 0.0109, 0.0114, 0.0768, 0.6355], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,696 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,696 - train - INFO - True
2024-04-07 09:25:42,697 - train - INFO - alphas:tensor([0.2767, 0.0056, 0.0075, 0.0686, 0.6417], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,700 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,700 - train - INFO - True
2024-04-07 09:25:42,701 - train - INFO - alphas:tensor([0.3011, 0.0043, 0.0075, 0.0617, 0.6254], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,704 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,704 - train - INFO - True
2024-04-07 09:25:42,705 - train - INFO - alphas:tensor([0.2741, 0.0066, 0.0090, 0.0595, 0.6508], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,708 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,708 - train - INFO - True
2024-04-07 09:25:42,709 - train - INFO - alphas:tensor([0.2996, 0.0045, 0.0106, 0.0627, 0.6226], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,711 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,712 - train - INFO - True
2024-04-07 09:25:42,713 - train - INFO - alphas:tensor([0.2639, 0.0115, 0.0148, 0.0694, 0.6405], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,715 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,715 - train - INFO - True
2024-04-07 09:25:42,716 - train - INFO - alphas:tensor([0.6179, 0.0029, 0.0058, 0.0383, 0.3351], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,721 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,721 - train - INFO - True
2024-04-07 09:25:42,722 - train - INFO - alphas:tensor([0.5476, 0.0027, 0.0037, 0.0377, 0.4083], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,731 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,731 - train - INFO - True
2024-04-07 09:25:42,732 - train - INFO - alphas:tensor([0.4189, 0.0023, 0.0075, 0.0542, 0.5171], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,736 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,737 - train - INFO - True
2024-04-07 09:25:42,738 - train - INFO - alphas:tensor([0.4370, 0.0024, 0.0040, 0.0505, 0.5061], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,742 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,742 - train - INFO - True
2024-04-07 09:25:42,743 - train - INFO - alphas:tensor([0.4502, 0.0021, 0.0040, 0.0470, 0.4966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,747 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,747 - train - INFO - True
2024-04-07 09:25:42,748 - train - INFO - alphas:tensor([0.4150, 0.0025, 0.0061, 0.0522, 0.5241], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,752 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,753 - train - INFO - True
2024-04-07 09:25:42,753 - train - INFO - alphas:tensor([0.5602, 0.0021, 0.0052, 0.0324, 0.4001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,761 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,761 - train - INFO - True
2024-04-07 09:25:42,762 - train - INFO - alphas:tensor([0.7301, 0.0016, 0.0039, 0.0231, 0.2413], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,781 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,781 - train - INFO - True
2024-04-07 09:25:42,782 - train - INFO - alphas:tensor([0.3794, 0.0029, 0.0059, 0.0626, 0.5492], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,791 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,791 - train - INFO - True
2024-04-07 09:25:42,792 - train - INFO - alphas:tensor([0.3907, 0.0017, 0.0046, 0.0511, 0.5519], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,801 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,801 - train - INFO - True
2024-04-07 09:25:42,802 - train - INFO - alphas:tensor([0.4218, 0.0020, 0.0037, 0.0526, 0.5199], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,811 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,811 - train - INFO - True
2024-04-07 09:25:42,812 - train - INFO - alphas:tensor([0.3861, 0.0024, 0.0051, 0.0549, 0.5515], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,820 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,820 - train - INFO - True
2024-04-07 09:25:42,821 - train - INFO - alphas:tensor([0.7153, 0.0014, 0.0023, 0.0187, 0.2623], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,836 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,836 - train - INFO - True
2024-04-07 09:25:42,837 - train - INFO - alphas:tensor([0.5555, 0.0080, 0.0127, 0.0583, 0.3656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:25:42,894 - train - INFO - tau:0.35516081470507305
2024-04-07 09:25:42,894 - train - INFO - avg block size:10.06060606060606
2024-04-07 09:25:42,894 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 09:25:43,087 - train - INFO - Test: [   0/78]  Time: 0.190 (0.190)  Loss:  0.9507 (0.9507)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 09:25:46,052 - train - INFO - Test: [  50/78]  Time: 0.052 (0.062)  Loss:  1.5693 (1.5637)  Acc@1: 64.8438 (65.7016)  Acc@5: 87.5000 (86.2286)
2024-04-07 09:25:47,770 - train - INFO - Test: [  78/78]  Time: 0.046 (0.062)  Loss:  1.8867 (1.5811)  Acc@1: 62.5000 (65.4700)  Acc@5: 87.5000 (86.0000)
2024-04-07 09:25:48,506 - train - INFO - Train: 106 [   0/781 (  0%)]  Loss:  3.553644 (3.5536)  Time: 0.647s,  197.72/s  (0.647s,  197.72/s)  LR: 1.069e-04  Data: 0.185 (0.185)
2024-04-07 09:26:11,365 - train - INFO - Train: 106 [  50/781 (  6%)]  Loss:  3.193809 (3.4786)  Time: 0.499s,  256.76/s  (0.461s,  277.72/s)  LR: 1.069e-04  Data: 0.009 (0.011)
2024-04-07 09:26:33,938 - train - INFO - Train: 106 [ 100/781 ( 13%)]  Loss:  3.653181 (3.4842)  Time: 0.496s,  258.24/s  (0.456s,  280.57/s)  LR: 1.069e-04  Data: 0.008 (0.009)
2024-04-07 09:26:57,710 - train - INFO - Train: 106 [ 150/781 ( 19%)]  Loss:  3.817556 (3.4713)  Time: 0.487s,  262.77/s  (0.463s,  276.72/s)  LR: 1.069e-04  Data: 0.007 (0.009)
2024-04-07 09:27:21,734 - train - INFO - Train: 106 [ 200/781 ( 26%)]  Loss:  3.752895 (3.4833)  Time: 0.540s,  237.00/s  (0.467s,  274.08/s)  LR: 1.069e-04  Data: 0.009 (0.008)
2024-04-07 09:27:45,547 - train - INFO - Train: 106 [ 250/781 ( 32%)]  Loss:  3.829901 (3.4937)  Time: 0.482s,  265.32/s  (0.469s,  273.01/s)  LR: 1.069e-04  Data: 0.008 (0.008)
2024-04-07 09:28:08,533 - train - INFO - Train: 106 [ 300/781 ( 38%)]  Loss:  3.858394 (3.4931)  Time: 0.484s,  264.26/s  (0.467s,  273.90/s)  LR: 1.069e-04  Data: 0.007 (0.008)
2024-04-07 09:28:31,634 - train - INFO - Train: 106 [ 350/781 ( 45%)]  Loss:  3.014805 (3.4950)  Time: 0.444s,  288.20/s  (0.467s,  274.35/s)  LR: 1.069e-04  Data: 0.005 (0.008)
2024-04-07 09:28:55,443 - train - INFO - Train: 106 [ 400/781 ( 51%)]  Loss:  3.621115 (3.5003)  Time: 0.485s,  264.00/s  (0.468s,  273.65/s)  LR: 1.069e-04  Data: 0.006 (0.008)
2024-04-07 09:29:19,313 - train - INFO - Train: 106 [ 450/781 ( 58%)]  Loss:  3.522960 (3.5025)  Time: 0.483s,  264.91/s  (0.469s,  273.02/s)  LR: 1.069e-04  Data: 0.009 (0.008)
2024-04-07 09:29:42,907 - train - INFO - Train: 106 [ 500/781 ( 64%)]  Loss:  3.124380 (3.4971)  Time: 0.490s,  261.02/s  (0.469s,  272.85/s)  LR: 1.069e-04  Data: 0.009 (0.008)
2024-04-07 09:30:05,996 - train - INFO - Train: 106 [ 550/781 ( 71%)]  Loss:  3.061511 (3.4989)  Time: 0.467s,  274.34/s  (0.468s,  273.24/s)  LR: 1.069e-04  Data: 0.009 (0.008)
2024-04-07 09:30:29,048 - train - INFO - Train: 106 [ 600/781 ( 77%)]  Loss:  3.487348 (3.5013)  Time: 0.484s,  264.51/s  (0.468s,  273.60/s)  LR: 1.069e-04  Data: 0.008 (0.008)
2024-04-07 09:30:52,562 - train - INFO - Train: 106 [ 650/781 ( 83%)]  Loss:  3.733234 (3.5014)  Time: 0.389s,  329.02/s  (0.468s,  273.49/s)  LR: 1.069e-04  Data: 0.006 (0.008)
2024-04-07 09:31:15,745 - train - INFO - Train: 106 [ 700/781 ( 90%)]  Loss:  3.382926 (3.5032)  Time: 0.554s,  231.05/s  (0.468s,  273.67/s)  LR: 1.069e-04  Data: 0.009 (0.008)
2024-04-07 09:31:39,856 - train - INFO - Train: 106 [ 750/781 ( 96%)]  Loss:  3.566690 (3.4985)  Time: 0.459s,  278.82/s  (0.469s,  273.11/s)  LR: 1.069e-04  Data: 0.007 (0.008)
2024-04-07 09:31:54,219 - train - INFO - Train: 106 [ 780/781 (100%)]  Loss:  3.350335 (3.4974)  Time: 0.360s,  355.51/s  (0.469s,  272.89/s)  LR: 1.069e-04  Data: 0.000 (0.008)
2024-04-07 09:31:54,220 - train - INFO - True
2024-04-07 09:31:54,222 - train - INFO - alphas:tensor([0.6885, 0.0268, 0.0445, 0.0657, 0.1746], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,223 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,224 - train - INFO - True
2024-04-07 09:31:54,225 - train - INFO - alphas:tensor([0.4524, 0.0095, 0.0207, 0.0587, 0.4588], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,226 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,226 - train - INFO - True
2024-04-07 09:31:54,228 - train - INFO - alphas:tensor([0.4915, 0.0177, 0.0539, 0.4369], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,229 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,230 - train - INFO - True
2024-04-07 09:31:54,231 - train - INFO - alphas:tensor([0.4313, 0.0179, 0.0388, 0.5120], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,232 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,232 - train - INFO - True
2024-04-07 09:31:54,234 - train - INFO - alphas:tensor([0.4375, 0.0113, 0.0465, 0.5046], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,235 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,235 - train - INFO - True
2024-04-07 09:31:54,237 - train - INFO - alphas:tensor([0.5221, 0.0182, 0.0395, 0.4202], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,238 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,238 - train - INFO - True
2024-04-07 09:31:54,240 - train - INFO - alphas:tensor([0.5720, 0.0095, 0.0137, 0.0405, 0.3644], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,242 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,242 - train - INFO - True
2024-04-07 09:31:54,243 - train - INFO - alphas:tensor([0.2395, 0.0052, 0.0041, 0.0404, 0.7108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,245 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,245 - train - INFO - True
2024-04-07 09:31:54,246 - train - INFO - alphas:tensor([0.2488, 0.0037, 0.0050, 0.0311, 0.7114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,248 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,248 - train - INFO - True
2024-04-07 09:31:54,249 - train - INFO - alphas:tensor([0.2497, 0.0024, 0.0042, 0.0347, 0.7090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,250 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,250 - train - INFO - True
2024-04-07 09:31:54,252 - train - INFO - alphas:tensor([0.2361, 0.0044, 0.0044, 0.0420, 0.7131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,253 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,253 - train - INFO - True
2024-04-07 09:31:54,255 - train - INFO - alphas:tensor([0.5718, 0.0037, 0.0082, 0.0353, 0.3809], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,256 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,257 - train - INFO - True
2024-04-07 09:31:54,258 - train - INFO - alphas:tensor([0.6774, 0.0049, 0.0066, 0.0242, 0.2868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,263 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,264 - train - INFO - True
2024-04-07 09:31:54,265 - train - INFO - alphas:tensor([0.2663, 0.0105, 0.0110, 0.0757, 0.6365], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,268 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,268 - train - INFO - True
2024-04-07 09:31:54,269 - train - INFO - alphas:tensor([0.2803, 0.0054, 0.0072, 0.0680, 0.6391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,272 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,272 - train - INFO - True
2024-04-07 09:31:54,273 - train - INFO - alphas:tensor([0.3020, 0.0042, 0.0073, 0.0605, 0.6261], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,276 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,276 - train - INFO - True
2024-04-07 09:31:54,277 - train - INFO - alphas:tensor([0.2746, 0.0064, 0.0088, 0.0590, 0.6512], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,280 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,280 - train - INFO - True
2024-04-07 09:31:54,281 - train - INFO - alphas:tensor([0.3002, 0.0044, 0.0103, 0.0620, 0.6231], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,284 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,284 - train - INFO - True
2024-04-07 09:31:54,285 - train - INFO - alphas:tensor([0.2617, 0.0111, 0.0144, 0.0687, 0.6441], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,288 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,288 - train - INFO - True
2024-04-07 09:31:54,289 - train - INFO - alphas:tensor([0.6167, 0.0027, 0.0056, 0.0377, 0.3372], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,294 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,294 - train - INFO - True
2024-04-07 09:31:54,295 - train - INFO - alphas:tensor([0.5492, 0.0026, 0.0036, 0.0372, 0.4074], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,304 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,304 - train - INFO - True
2024-04-07 09:31:54,305 - train - INFO - alphas:tensor([0.4181, 0.0022, 0.0073, 0.0532, 0.5193], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,310 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,310 - train - INFO - True
2024-04-07 09:31:54,311 - train - INFO - alphas:tensor([0.4368, 0.0023, 0.0038, 0.0499, 0.5072], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,316 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,316 - train - INFO - True
2024-04-07 09:31:54,317 - train - INFO - alphas:tensor([0.4513, 0.0020, 0.0038, 0.0465, 0.4963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,321 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,321 - train - INFO - True
2024-04-07 09:31:54,322 - train - INFO - alphas:tensor([0.4139, 0.0024, 0.0059, 0.0514, 0.5263], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,327 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,327 - train - INFO - True
2024-04-07 09:31:54,328 - train - INFO - alphas:tensor([0.5624, 0.0020, 0.0050, 0.0318, 0.3987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,336 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,336 - train - INFO - True
2024-04-07 09:31:54,337 - train - INFO - alphas:tensor([0.7278, 0.0015, 0.0038, 0.0229, 0.2441], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,356 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,356 - train - INFO - True
2024-04-07 09:31:54,357 - train - INFO - alphas:tensor([0.3808, 0.0028, 0.0057, 0.0619, 0.5488], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,367 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,367 - train - INFO - True
2024-04-07 09:31:54,368 - train - INFO - alphas:tensor([0.3912, 0.0016, 0.0044, 0.0498, 0.5530], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,377 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,377 - train - INFO - True
2024-04-07 09:31:54,378 - train - INFO - alphas:tensor([0.4215, 0.0019, 0.0035, 0.0515, 0.5215], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,387 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,387 - train - INFO - True
2024-04-07 09:31:54,387 - train - INFO - alphas:tensor([0.3872, 0.0023, 0.0049, 0.0540, 0.5515], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,396 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,396 - train - INFO - True
2024-04-07 09:31:54,397 - train - INFO - alphas:tensor([0.7171, 0.0013, 0.0022, 0.0182, 0.2612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,412 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,413 - train - INFO - True
2024-04-07 09:31:54,413 - train - INFO - alphas:tensor([0.5559, 0.0078, 0.0124, 0.0583, 0.3656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:31:54,470 - train - INFO - tau:0.3516092065580223
2024-04-07 09:31:54,470 - train - INFO - avg block size:10.06060606060606
2024-04-07 09:31:54,470 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 09:31:54,470 - train - INFO - lasso_alpha:3.9568933780027e-06
2024-04-07 09:31:54,685 - train - INFO - Test: [   0/78]  Time: 0.212 (0.212)  Loss:  0.9570 (0.9570)  Acc@1: 83.5938 (83.5938)  Acc@5: 93.7500 (93.7500)
2024-04-07 09:31:58,128 - train - INFO - Test: [  50/78]  Time: 0.071 (0.072)  Loss:  1.5908 (1.5444)  Acc@1: 66.4062 (65.5790)  Acc@5: 87.5000 (86.3971)
2024-04-07 09:31:59,949 - train - INFO - Test: [  78/78]  Time: 0.050 (0.069)  Loss:  1.8232 (1.5647)  Acc@1: 50.0000 (65.3000)  Acc@5: 100.0000 (85.9800)
2024-04-07 09:32:00,733 - train - INFO - Train: 107 [   0/781 (  0%)]  Loss:  3.758992 (3.7590)  Time: 0.618s,  207.21/s  (0.618s,  207.21/s)  LR: 1.028e-04  Data: 0.178 (0.178)
2024-04-07 09:32:24,171 - train - INFO - Train: 107 [  50/781 (  6%)]  Loss:  3.578767 (3.4832)  Time: 0.479s,  267.40/s  (0.472s,  271.39/s)  LR: 1.028e-04  Data: 0.007 (0.011)
2024-04-07 09:32:47,828 - train - INFO - Train: 107 [ 100/781 ( 13%)]  Loss:  3.232168 (3.5100)  Time: 0.498s,  256.86/s  (0.472s,  270.97/s)  LR: 1.028e-04  Data: 0.008 (0.010)
2024-04-07 09:33:11,442 - train - INFO - Train: 107 [ 150/781 ( 19%)]  Loss:  3.386815 (3.5100)  Time: 0.485s,  263.99/s  (0.472s,  271.00/s)  LR: 1.028e-04  Data: 0.008 (0.009)
2024-04-07 09:33:34,562 - train - INFO - Train: 107 [ 200/781 ( 26%)]  Loss:  3.597178 (3.5177)  Time: 0.361s,  354.97/s  (0.470s,  272.43/s)  LR: 1.028e-04  Data: 0.006 (0.009)
2024-04-07 09:33:58,305 - train - INFO - Train: 107 [ 250/781 ( 32%)]  Loss:  3.733454 (3.5177)  Time: 0.470s,  272.56/s  (0.471s,  271.85/s)  LR: 1.028e-04  Data: 0.008 (0.008)
2024-04-07 09:34:21,955 - train - INFO - Train: 107 [ 300/781 ( 38%)]  Loss:  3.259937 (3.5182)  Time: 0.468s,  273.79/s  (0.471s,  271.65/s)  LR: 1.028e-04  Data: 0.008 (0.008)
2024-04-07 09:34:44,630 - train - INFO - Train: 107 [ 350/781 ( 45%)]  Loss:  3.522190 (3.5166)  Time: 0.336s,  381.23/s  (0.469s,  273.11/s)  LR: 1.028e-04  Data: 0.004 (0.008)
2024-04-07 09:35:07,869 - train - INFO - Train: 107 [ 400/781 ( 51%)]  Loss:  3.392914 (3.5152)  Time: 0.465s,  275.23/s  (0.468s,  273.40/s)  LR: 1.028e-04  Data: 0.008 (0.008)
2024-04-07 09:35:31,420 - train - INFO - Train: 107 [ 450/781 ( 58%)]  Loss:  3.718191 (3.5151)  Time: 0.479s,  267.09/s  (0.468s,  273.22/s)  LR: 1.028e-04  Data: 0.007 (0.008)
2024-04-07 09:35:54,363 - train - INFO - Train: 107 [ 500/781 ( 64%)]  Loss:  3.368219 (3.5149)  Time: 0.472s,  271.36/s  (0.468s,  273.78/s)  LR: 1.028e-04  Data: 0.008 (0.008)
2024-04-07 09:36:17,953 - train - INFO - Train: 107 [ 550/781 ( 71%)]  Loss:  3.218590 (3.5120)  Time: 0.490s,  261.29/s  (0.468s,  273.56/s)  LR: 1.028e-04  Data: 0.008 (0.008)
2024-04-07 09:36:41,863 - train - INFO - Train: 107 [ 600/781 ( 77%)]  Loss:  3.356891 (3.5184)  Time: 0.472s,  271.43/s  (0.469s,  273.06/s)  LR: 1.028e-04  Data: 0.008 (0.008)
2024-04-07 09:37:04,404 - train - INFO - Train: 107 [ 650/781 ( 83%)]  Loss:  3.682913 (3.5159)  Time: 0.480s,  266.65/s  (0.467s,  273.86/s)  LR: 1.028e-04  Data: 0.020 (0.008)
2024-04-07 09:37:27,373 - train - INFO - Train: 107 [ 700/781 ( 90%)]  Loss:  3.627018 (3.5139)  Time: 0.388s,  329.98/s  (0.467s,  274.20/s)  LR: 1.028e-04  Data: 0.005 (0.008)
2024-04-07 09:37:50,325 - train - INFO - Train: 107 [ 750/781 ( 96%)]  Loss:  3.632739 (3.5129)  Time: 0.497s,  257.76/s  (0.466s,  274.51/s)  LR: 1.028e-04  Data: 0.010 (0.008)
2024-04-07 09:38:04,333 - train - INFO - Train: 107 [ 780/781 (100%)]  Loss:  3.554262 (3.5135)  Time: 0.503s,  254.34/s  (0.466s,  274.49/s)  LR: 1.028e-04  Data: 0.000 (0.008)
2024-04-07 09:38:04,334 - train - INFO - True
2024-04-07 09:38:04,337 - train - INFO - alphas:tensor([0.6912, 0.0262, 0.0438, 0.0647, 0.1741], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,338 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,338 - train - INFO - True
2024-04-07 09:38:04,340 - train - INFO - alphas:tensor([0.4528, 0.0092, 0.0202, 0.0580, 0.4597], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,341 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,341 - train - INFO - True
2024-04-07 09:38:04,342 - train - INFO - alphas:tensor([0.4959, 0.0172, 0.0528, 0.4341], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,344 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,344 - train - INFO - True
2024-04-07 09:38:04,345 - train - INFO - alphas:tensor([0.4343, 0.0176, 0.0380, 0.5101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,346 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,346 - train - INFO - True
2024-04-07 09:38:04,348 - train - INFO - alphas:tensor([0.4366, 0.0109, 0.0457, 0.5067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,349 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,349 - train - INFO - True
2024-04-07 09:38:04,351 - train - INFO - alphas:tensor([0.5242, 0.0177, 0.0385, 0.4196], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,352 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,352 - train - INFO - True
2024-04-07 09:38:04,353 - train - INFO - alphas:tensor([0.5755, 0.0092, 0.0132, 0.0394, 0.3626], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,355 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,355 - train - INFO - True
2024-04-07 09:38:04,357 - train - INFO - alphas:tensor([0.2397, 0.0050, 0.0040, 0.0401, 0.7112], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,358 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,358 - train - INFO - True
2024-04-07 09:38:04,360 - train - INFO - alphas:tensor([0.2488, 0.0035, 0.0048, 0.0303, 0.7126], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,361 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,361 - train - INFO - True
2024-04-07 09:38:04,362 - train - INFO - alphas:tensor([0.2505, 0.0023, 0.0040, 0.0339, 0.7093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,363 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,363 - train - INFO - True
2024-04-07 09:38:04,365 - train - INFO - alphas:tensor([0.2356, 0.0043, 0.0042, 0.0414, 0.7146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,366 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,366 - train - INFO - True
2024-04-07 09:38:04,367 - train - INFO - alphas:tensor([0.5722, 0.0036, 0.0080, 0.0346, 0.3816], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,369 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,369 - train - INFO - True
2024-04-07 09:38:04,371 - train - INFO - alphas:tensor([0.6824, 0.0047, 0.0063, 0.0234, 0.2832], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,376 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,376 - train - INFO - True
2024-04-07 09:38:04,377 - train - INFO - alphas:tensor([0.2682, 0.0102, 0.0107, 0.0750, 0.6359], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,380 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,380 - train - INFO - True
2024-04-07 09:38:04,381 - train - INFO - alphas:tensor([0.2831, 0.0051, 0.0070, 0.0668, 0.6380], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,384 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,384 - train - INFO - True
2024-04-07 09:38:04,385 - train - INFO - alphas:tensor([0.3012, 0.0040, 0.0070, 0.0599, 0.6280], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,388 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,388 - train - INFO - True
2024-04-07 09:38:04,389 - train - INFO - alphas:tensor([0.2751, 0.0061, 0.0085, 0.0583, 0.6520], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,392 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,392 - train - INFO - True
2024-04-07 09:38:04,393 - train - INFO - alphas:tensor([0.3024, 0.0042, 0.0099, 0.0610, 0.6225], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,395 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,396 - train - INFO - True
2024-04-07 09:38:04,397 - train - INFO - alphas:tensor([0.2622, 0.0108, 0.0139, 0.0675, 0.6456], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,399 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,399 - train - INFO - True
2024-04-07 09:38:04,400 - train - INFO - alphas:tensor([0.6208, 0.0026, 0.0054, 0.0369, 0.3343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,405 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,405 - train - INFO - True
2024-04-07 09:38:04,406 - train - INFO - alphas:tensor([0.5505, 0.0025, 0.0034, 0.0366, 0.4070], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,415 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,415 - train - INFO - True
2024-04-07 09:38:04,416 - train - INFO - alphas:tensor([0.4224, 0.0021, 0.0070, 0.0522, 0.5162], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,421 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,421 - train - INFO - True
2024-04-07 09:38:04,422 - train - INFO - alphas:tensor([0.4406, 0.0022, 0.0036, 0.0493, 0.5043], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,426 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,426 - train - INFO - True
2024-04-07 09:38:04,427 - train - INFO - alphas:tensor([0.4551, 0.0019, 0.0036, 0.0455, 0.4938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,431 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,431 - train - INFO - True
2024-04-07 09:38:04,432 - train - INFO - alphas:tensor([0.4156, 0.0023, 0.0057, 0.0505, 0.5259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,438 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,438 - train - INFO - True
2024-04-07 09:38:04,439 - train - INFO - alphas:tensor([0.5625, 0.0019, 0.0048, 0.0313, 0.3994], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,447 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,447 - train - INFO - True
2024-04-07 09:38:04,448 - train - INFO - alphas:tensor([0.7295, 0.0014, 0.0036, 0.0222, 0.2432], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,467 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,468 - train - INFO - True
2024-04-07 09:38:04,468 - train - INFO - alphas:tensor([0.3886, 0.0026, 0.0054, 0.0606, 0.5428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,478 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,479 - train - INFO - True
2024-04-07 09:38:04,480 - train - INFO - alphas:tensor([0.3950, 0.0015, 0.0042, 0.0492, 0.5500], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,490 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,490 - train - INFO - True
2024-04-07 09:38:04,491 - train - INFO - alphas:tensor([0.4257, 0.0019, 0.0034, 0.0515, 0.5175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,501 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,501 - train - INFO - True
2024-04-07 09:38:04,502 - train - INFO - alphas:tensor([0.3864, 0.0022, 0.0048, 0.0532, 0.5534], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,512 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,512 - train - INFO - True
2024-04-07 09:38:04,513 - train - INFO - alphas:tensor([0.7172, 0.0012, 0.0021, 0.0180, 0.2615], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,532 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,532 - train - INFO - True
2024-04-07 09:38:04,533 - train - INFO - alphas:tensor([0.5581, 0.0076, 0.0121, 0.0574, 0.3649], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:38:04,611 - train - INFO - tau:0.34809311449244207
2024-04-07 09:38:04,611 - train - INFO - avg block size:10.06060606060606
2024-04-07 09:38:04,611 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 09:38:04,809 - train - INFO - Test: [   0/78]  Time: 0.194 (0.194)  Loss:  1.0439 (1.0439)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.1875 (92.1875)
2024-04-07 09:38:07,514 - train - INFO - Test: [  50/78]  Time: 0.050 (0.057)  Loss:  1.5986 (1.5650)  Acc@1: 67.9688 (65.8088)  Acc@5: 85.1562 (86.2898)
2024-04-07 09:38:08,957 - train - INFO - Test: [  78/78]  Time: 0.048 (0.055)  Loss:  1.8379 (1.5834)  Acc@1: 56.2500 (65.4100)  Acc@5: 87.5000 (85.9300)
2024-04-07 09:38:09,717 - train - INFO - Train: 108 [   0/781 (  0%)]  Loss:  3.511353 (3.5114)  Time: 0.673s,  190.21/s  (0.673s,  190.21/s)  LR: 9.883e-05  Data: 0.184 (0.184)
2024-04-07 09:38:32,175 - train - INFO - Train: 108 [  50/781 (  6%)]  Loss:  3.247665 (3.4996)  Time: 0.465s,  275.30/s  (0.454s,  282.24/s)  LR: 9.883e-05  Data: 0.008 (0.010)
2024-04-07 09:38:55,859 - train - INFO - Train: 108 [ 100/781 ( 13%)]  Loss:  3.534633 (3.4899)  Time: 0.463s,  276.35/s  (0.463s,  276.17/s)  LR: 9.883e-05  Data: 0.007 (0.009)
2024-04-07 09:39:19,563 - train - INFO - Train: 108 [ 150/781 ( 19%)]  Loss:  3.748824 (3.4953)  Time: 0.506s,  252.88/s  (0.467s,  274.10/s)  LR: 9.883e-05  Data: 0.008 (0.009)
2024-04-07 09:39:42,896 - train - INFO - Train: 108 [ 200/781 ( 26%)]  Loss:  3.442004 (3.5058)  Time: 0.465s,  275.48/s  (0.467s,  274.15/s)  LR: 9.883e-05  Data: 0.005 (0.008)
2024-04-07 09:40:06,165 - train - INFO - Train: 108 [ 250/781 ( 32%)]  Loss:  3.416304 (3.5013)  Time: 0.506s,  252.78/s  (0.467s,  274.33/s)  LR: 9.883e-05  Data: 0.006 (0.008)
2024-04-07 09:40:30,259 - train - INFO - Train: 108 [ 300/781 ( 38%)]  Loss:  3.827644 (3.5134)  Time: 0.377s,  339.55/s  (0.469s,  272.85/s)  LR: 9.883e-05  Data: 0.006 (0.008)
2024-04-07 09:40:53,687 - train - INFO - Train: 108 [ 350/781 ( 45%)]  Loss:  3.495695 (3.5186)  Time: 0.424s,  302.12/s  (0.469s,  272.90/s)  LR: 9.883e-05  Data: 0.010 (0.008)
2024-04-07 09:41:16,833 - train - INFO - Train: 108 [ 400/781 ( 51%)]  Loss:  3.764819 (3.5175)  Time: 0.510s,  250.87/s  (0.468s,  273.35/s)  LR: 9.883e-05  Data: 0.010 (0.008)
2024-04-07 09:41:40,411 - train - INFO - Train: 108 [ 450/781 ( 58%)]  Loss:  3.624280 (3.5173)  Time: 0.410s,  312.15/s  (0.469s,  273.14/s)  LR: 9.883e-05  Data: 0.005 (0.008)
2024-04-07 09:42:03,469 - train - INFO - Train: 108 [ 500/781 ( 64%)]  Loss:  3.481328 (3.5199)  Time: 0.498s,  256.86/s  (0.468s,  273.57/s)  LR: 9.883e-05  Data: 0.010 (0.008)
2024-04-07 09:42:26,884 - train - INFO - Train: 108 [ 550/781 ( 71%)]  Loss:  3.637007 (3.5162)  Time: 0.448s,  285.61/s  (0.468s,  273.55/s)  LR: 9.883e-05  Data: 0.006 (0.008)
2024-04-07 09:42:49,879 - train - INFO - Train: 108 [ 600/781 ( 77%)]  Loss:  3.358424 (3.5148)  Time: 0.341s,  375.24/s  (0.467s,  273.95/s)  LR: 9.883e-05  Data: 0.004 (0.008)
2024-04-07 09:43:12,957 - train - INFO - Train: 108 [ 650/781 ( 83%)]  Loss:  3.715510 (3.5133)  Time: 0.489s,  261.91/s  (0.467s,  274.20/s)  LR: 9.883e-05  Data: 0.007 (0.008)
2024-04-07 09:43:36,337 - train - INFO - Train: 108 [ 700/781 ( 90%)]  Loss:  3.715575 (3.5128)  Time: 0.513s,  249.65/s  (0.467s,  274.17/s)  LR: 9.883e-05  Data: 0.009 (0.008)
2024-04-07 09:43:59,676 - train - INFO - Train: 108 [ 750/781 ( 96%)]  Loss:  3.703944 (3.5158)  Time: 0.472s,  271.40/s  (0.467s,  274.18/s)  LR: 9.883e-05  Data: 0.006 (0.008)
2024-04-07 09:44:14,217 - train - INFO - Train: 108 [ 780/781 (100%)]  Loss:  3.790073 (3.5144)  Time: 0.428s,  299.02/s  (0.468s,  273.77/s)  LR: 9.883e-05  Data: 0.000 (0.008)
2024-04-07 09:44:14,218 - train - INFO - True
2024-04-07 09:44:14,220 - train - INFO - alphas:tensor([0.6951, 0.0255, 0.0428, 0.0636, 0.1730], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,220 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,220 - train - INFO - True
2024-04-07 09:44:14,221 - train - INFO - alphas:tensor([0.4530, 0.0089, 0.0196, 0.0570, 0.4615], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,222 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,222 - train - INFO - True
2024-04-07 09:44:14,223 - train - INFO - alphas:tensor([0.4954, 0.0167, 0.0518, 0.4360], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,223 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,224 - train - INFO - True
2024-04-07 09:44:14,224 - train - INFO - alphas:tensor([0.4354, 0.0169, 0.0372, 0.5106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,225 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,225 - train - INFO - True
2024-04-07 09:44:14,226 - train - INFO - alphas:tensor([0.4372, 0.0107, 0.0452, 0.5069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,226 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,227 - train - INFO - True
2024-04-07 09:44:14,228 - train - INFO - alphas:tensor([0.5243, 0.0172, 0.0377, 0.4208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,228 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,228 - train - INFO - True
2024-04-07 09:44:14,229 - train - INFO - alphas:tensor([0.5753, 0.0089, 0.0127, 0.0388, 0.3644], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,230 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,231 - train - INFO - True
2024-04-07 09:44:14,232 - train - INFO - alphas:tensor([0.2428, 0.0048, 0.0038, 0.0392, 0.7093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,232 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,232 - train - INFO - True
2024-04-07 09:44:14,233 - train - INFO - alphas:tensor([0.2500, 0.0033, 0.0046, 0.0297, 0.7124], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,234 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,234 - train - INFO - True
2024-04-07 09:44:14,235 - train - INFO - alphas:tensor([0.2485, 0.0022, 0.0038, 0.0337, 0.7118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,236 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,236 - train - INFO - True
2024-04-07 09:44:14,237 - train - INFO - alphas:tensor([0.2371, 0.0041, 0.0041, 0.0407, 0.7141], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,237 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,237 - train - INFO - True
2024-04-07 09:44:14,238 - train - INFO - alphas:tensor([0.5715, 0.0034, 0.0076, 0.0339, 0.3835], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,239 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,239 - train - INFO - True
2024-04-07 09:44:14,240 - train - INFO - alphas:tensor([0.6849, 0.0045, 0.0061, 0.0227, 0.2818], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,244 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,244 - train - INFO - True
2024-04-07 09:44:14,245 - train - INFO - alphas:tensor([0.2706, 0.0099, 0.0104, 0.0739, 0.6352], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,246 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,246 - train - INFO - True
2024-04-07 09:44:14,247 - train - INFO - alphas:tensor([0.2812, 0.0049, 0.0067, 0.0654, 0.6417], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,249 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,249 - train - INFO - True
2024-04-07 09:44:14,250 - train - INFO - alphas:tensor([0.3044, 0.0038, 0.0067, 0.0587, 0.6264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,252 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,252 - train - INFO - True
2024-04-07 09:44:14,253 - train - INFO - alphas:tensor([0.2749, 0.0059, 0.0082, 0.0574, 0.6536], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,255 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,255 - train - INFO - True
2024-04-07 09:44:14,256 - train - INFO - alphas:tensor([0.3027, 0.0041, 0.0096, 0.0598, 0.6237], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,257 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,257 - train - INFO - True
2024-04-07 09:44:14,258 - train - INFO - alphas:tensor([0.2641, 0.0104, 0.0135, 0.0668, 0.6452], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,260 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,260 - train - INFO - True
2024-04-07 09:44:14,261 - train - INFO - alphas:tensor([0.6227, 0.0025, 0.0052, 0.0359, 0.3337], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,264 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,264 - train - INFO - True
2024-04-07 09:44:14,265 - train - INFO - alphas:tensor([0.5504, 0.0023, 0.0033, 0.0359, 0.4080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,271 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,271 - train - INFO - True
2024-04-07 09:44:14,272 - train - INFO - alphas:tensor([0.4263, 0.0020, 0.0068, 0.0511, 0.5139], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,275 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,276 - train - INFO - True
2024-04-07 09:44:14,276 - train - INFO - alphas:tensor([0.4388, 0.0021, 0.0035, 0.0481, 0.5076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,280 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,280 - train - INFO - True
2024-04-07 09:44:14,280 - train - INFO - alphas:tensor([0.4538, 0.0018, 0.0035, 0.0447, 0.4962], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,284 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,284 - train - INFO - True
2024-04-07 09:44:14,285 - train - INFO - alphas:tensor([0.4136, 0.0021, 0.0055, 0.0495, 0.5293], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,288 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,288 - train - INFO - True
2024-04-07 09:44:14,289 - train - INFO - alphas:tensor([0.5649, 0.0018, 0.0046, 0.0306, 0.3981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,295 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,295 - train - INFO - True
2024-04-07 09:44:14,295 - train - INFO - alphas:tensor([0.7318, 0.0014, 0.0035, 0.0218, 0.2416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,310 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,310 - train - INFO - True
2024-04-07 09:44:14,311 - train - INFO - alphas:tensor([0.3880, 0.0025, 0.0053, 0.0598, 0.5444], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,319 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,319 - train - INFO - True
2024-04-07 09:44:14,319 - train - INFO - alphas:tensor([0.3959, 0.0014, 0.0040, 0.0486, 0.5500], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,327 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,327 - train - INFO - True
2024-04-07 09:44:14,328 - train - INFO - alphas:tensor([0.4221, 0.0017, 0.0032, 0.0511, 0.5218], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,335 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,335 - train - INFO - True
2024-04-07 09:44:14,335 - train - INFO - alphas:tensor([0.3852, 0.0021, 0.0046, 0.0525, 0.5557], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,342 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,342 - train - INFO - True
2024-04-07 09:44:14,343 - train - INFO - alphas:tensor([0.7165, 0.0012, 0.0020, 0.0178, 0.2625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,356 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,356 - train - INFO - True
2024-04-07 09:44:14,357 - train - INFO - alphas:tensor([0.5599, 0.0074, 0.0118, 0.0570, 0.3638], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:44:14,412 - train - INFO - tau:0.34461218334751764
2024-04-07 09:44:14,412 - train - INFO - avg block size:10.06060606060606
2024-04-07 09:44:14,412 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 09:44:14,413 - train - INFO - lasso_alpha:3.5971757981842726e-06
2024-04-07 09:44:14,595 - train - INFO - Test: [   0/78]  Time: 0.180 (0.180)  Loss:  1.0039 (1.0039)  Acc@1: 82.0312 (82.0312)  Acc@5: 92.1875 (92.1875)
2024-04-07 09:44:17,501 - train - INFO - Test: [  50/78]  Time: 0.051 (0.061)  Loss:  1.5908 (1.5678)  Acc@1: 66.4062 (65.9620)  Acc@5: 85.9375 (86.0294)
2024-04-07 09:44:18,962 - train - INFO - Test: [  78/78]  Time: 0.047 (0.058)  Loss:  1.8711 (1.5798)  Acc@1: 50.0000 (65.7200)  Acc@5: 100.0000 (85.7600)
2024-04-07 09:44:19,721 - train - INFO - Train: 109 [   0/781 (  0%)]  Loss:  3.720906 (3.7209)  Time: 0.683s,  187.30/s  (0.683s,  187.30/s)  LR: 9.491e-05  Data: 0.183 (0.183)
2024-04-07 09:44:42,698 - train - INFO - Train: 109 [  50/781 (  6%)]  Loss:  3.448414 (3.5282)  Time: 0.478s,  267.75/s  (0.464s,  275.92/s)  LR: 9.491e-05  Data: 0.006 (0.011)
2024-04-07 09:45:07,152 - train - INFO - Train: 109 [ 100/781 ( 13%)]  Loss:  3.571597 (3.5080)  Time: 0.487s,  262.73/s  (0.476s,  268.71/s)  LR: 9.491e-05  Data: 0.007 (0.009)
2024-04-07 09:45:30,036 - train - INFO - Train: 109 [ 150/781 ( 19%)]  Loss:  3.406220 (3.4965)  Time: 0.531s,  241.05/s  (0.470s,  272.25/s)  LR: 9.491e-05  Data: 0.008 (0.009)
2024-04-07 09:45:53,305 - train - INFO - Train: 109 [ 200/781 ( 26%)]  Loss:  3.411895 (3.4970)  Time: 0.422s,  303.32/s  (0.469s,  272.95/s)  LR: 9.491e-05  Data: 0.005 (0.008)
2024-04-07 09:46:15,467 - train - INFO - Train: 109 [ 250/781 ( 32%)]  Loss:  3.760717 (3.4993)  Time: 0.457s,  280.10/s  (0.464s,  275.96/s)  LR: 9.491e-05  Data: 0.006 (0.008)
2024-04-07 09:46:39,003 - train - INFO - Train: 109 [ 300/781 ( 38%)]  Loss:  2.944122 (3.4964)  Time: 0.407s,  314.11/s  (0.465s,  275.29/s)  LR: 9.491e-05  Data: 0.008 (0.008)
2024-04-07 09:47:02,115 - train - INFO - Train: 109 [ 350/781 ( 45%)]  Loss:  3.140519 (3.4921)  Time: 0.470s,  272.58/s  (0.465s,  275.52/s)  LR: 9.491e-05  Data: 0.009 (0.008)
2024-04-07 09:47:25,861 - train - INFO - Train: 109 [ 400/781 ( 51%)]  Loss:  3.685897 (3.4970)  Time: 0.467s,  273.81/s  (0.466s,  274.76/s)  LR: 9.491e-05  Data: 0.012 (0.008)
2024-04-07 09:47:49,393 - train - INFO - Train: 109 [ 450/781 ( 58%)]  Loss:  3.156116 (3.4910)  Time: 0.372s,  343.63/s  (0.466s,  274.45/s)  LR: 9.491e-05  Data: 0.004 (0.008)
2024-04-07 09:48:12,652 - train - INFO - Train: 109 [ 500/781 ( 64%)]  Loss:  3.702817 (3.4930)  Time: 0.474s,  270.07/s  (0.466s,  274.52/s)  LR: 9.491e-05  Data: 0.007 (0.008)
2024-04-07 09:48:36,261 - train - INFO - Train: 109 [ 550/781 ( 71%)]  Loss:  3.508046 (3.4920)  Time: 0.490s,  261.44/s  (0.467s,  274.21/s)  LR: 9.491e-05  Data: 0.008 (0.008)
2024-04-07 09:49:00,367 - train - INFO - Train: 109 [ 600/781 ( 77%)]  Loss:  3.683708 (3.4932)  Time: 0.487s,  262.84/s  (0.468s,  273.46/s)  LR: 9.491e-05  Data: 0.006 (0.008)
2024-04-07 09:49:23,527 - train - INFO - Train: 109 [ 650/781 ( 83%)]  Loss:  3.229284 (3.4946)  Time: 0.497s,  257.56/s  (0.468s,  273.69/s)  LR: 9.491e-05  Data: 0.007 (0.008)
2024-04-07 09:49:46,579 - train - INFO - Train: 109 [ 700/781 ( 90%)]  Loss:  3.105393 (3.4941)  Time: 0.367s,  349.06/s  (0.467s,  273.97/s)  LR: 9.491e-05  Data: 0.005 (0.008)
2024-04-07 09:50:09,872 - train - INFO - Train: 109 [ 750/781 ( 96%)]  Loss:  3.408211 (3.4909)  Time: 0.397s,  322.67/s  (0.467s,  274.02/s)  LR: 9.491e-05  Data: 0.005 (0.008)
2024-04-07 09:50:23,244 - train - INFO - Train: 109 [ 780/781 (100%)]  Loss:  3.750710 (3.4900)  Time: 0.371s,  345.14/s  (0.466s,  274.51/s)  LR: 9.491e-05  Data: 0.000 (0.008)
2024-04-07 09:50:23,244 - train - INFO - True
2024-04-07 09:50:23,246 - train - INFO - alphas:tensor([0.6983, 0.0249, 0.0419, 0.0627, 0.1722], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,247 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,247 - train - INFO - True
2024-04-07 09:50:23,248 - train - INFO - alphas:tensor([0.4528, 0.0086, 0.0192, 0.0560, 0.4634], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,248 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,248 - train - INFO - True
2024-04-07 09:50:23,250 - train - INFO - alphas:tensor([0.4944, 0.0161, 0.0510, 0.4384], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,250 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,251 - train - INFO - True
2024-04-07 09:50:23,252 - train - INFO - alphas:tensor([0.4355, 0.0164, 0.0364, 0.5117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,252 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,252 - train - INFO - True
2024-04-07 09:50:23,253 - train - INFO - alphas:tensor([0.4397, 0.0103, 0.0443, 0.5057], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,254 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,254 - train - INFO - True
2024-04-07 09:50:23,255 - train - INFO - alphas:tensor([0.5276, 0.0167, 0.0369, 0.4188], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,256 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,256 - train - INFO - True
2024-04-07 09:50:23,257 - train - INFO - alphas:tensor([0.5760, 0.0085, 0.0124, 0.0381, 0.3649], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,258 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,259 - train - INFO - True
2024-04-07 09:50:23,260 - train - INFO - alphas:tensor([0.2415, 0.0046, 0.0037, 0.0383, 0.7118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,260 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,260 - train - INFO - True
2024-04-07 09:50:23,261 - train - INFO - alphas:tensor([0.2498, 0.0032, 0.0044, 0.0292, 0.7134], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,262 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,262 - train - INFO - True
2024-04-07 09:50:23,263 - train - INFO - alphas:tensor([0.2504, 0.0021, 0.0037, 0.0331, 0.7108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,264 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,264 - train - INFO - True
2024-04-07 09:50:23,265 - train - INFO - alphas:tensor([0.2376, 0.0039, 0.0039, 0.0400, 0.7146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,266 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,266 - train - INFO - True
2024-04-07 09:50:23,267 - train - INFO - alphas:tensor([0.5742, 0.0033, 0.0074, 0.0331, 0.3820], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,268 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,268 - train - INFO - True
2024-04-07 09:50:23,269 - train - INFO - alphas:tensor([0.6857, 0.0043, 0.0058, 0.0221, 0.2821], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,273 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,273 - train - INFO - True
2024-04-07 09:50:23,274 - train - INFO - alphas:tensor([0.2698, 0.0096, 0.0100, 0.0733, 0.6372], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,276 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,276 - train - INFO - True
2024-04-07 09:50:23,277 - train - INFO - alphas:tensor([0.2840, 0.0047, 0.0065, 0.0646, 0.6402], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,279 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,279 - train - INFO - True
2024-04-07 09:50:23,280 - train - INFO - alphas:tensor([0.3047, 0.0037, 0.0065, 0.0578, 0.6273], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,282 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,283 - train - INFO - True
2024-04-07 09:50:23,283 - train - INFO - alphas:tensor([0.2772, 0.0057, 0.0080, 0.0568, 0.6522], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,285 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,286 - train - INFO - True
2024-04-07 09:50:23,286 - train - INFO - alphas:tensor([0.3034, 0.0039, 0.0093, 0.0589, 0.6245], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,288 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,288 - train - INFO - True
2024-04-07 09:50:23,289 - train - INFO - alphas:tensor([0.2642, 0.0101, 0.0130, 0.0655, 0.6471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,291 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,291 - train - INFO - True
2024-04-07 09:50:23,292 - train - INFO - alphas:tensor([0.6244, 0.0024, 0.0049, 0.0352, 0.3331], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,296 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,296 - train - INFO - True
2024-04-07 09:50:23,297 - train - INFO - alphas:tensor([0.5508, 0.0022, 0.0032, 0.0351, 0.4087], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,304 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,304 - train - INFO - True
2024-04-07 09:50:23,305 - train - INFO - alphas:tensor([0.4271, 0.0019, 0.0066, 0.0509, 0.5136], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,308 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,308 - train - INFO - True
2024-04-07 09:50:23,309 - train - INFO - alphas:tensor([0.4425, 0.0020, 0.0033, 0.0474, 0.5048], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,313 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,313 - train - INFO - True
2024-04-07 09:50:23,314 - train - INFO - alphas:tensor([0.4560, 0.0017, 0.0033, 0.0437, 0.4952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,317 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,317 - train - INFO - True
2024-04-07 09:50:23,318 - train - INFO - alphas:tensor([0.4157, 0.0020, 0.0053, 0.0488, 0.5282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,321 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,322 - train - INFO - True
2024-04-07 09:50:23,322 - train - INFO - alphas:tensor([0.5652, 0.0017, 0.0044, 0.0300, 0.3987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,329 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,329 - train - INFO - True
2024-04-07 09:50:23,330 - train - INFO - alphas:tensor([0.7334, 0.0013, 0.0033, 0.0212, 0.2408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,346 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,346 - train - INFO - True
2024-04-07 09:50:23,347 - train - INFO - alphas:tensor([0.3910, 0.0024, 0.0051, 0.0590, 0.5425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,355 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,355 - train - INFO - True
2024-04-07 09:50:23,356 - train - INFO - alphas:tensor([0.3976, 0.0014, 0.0039, 0.0477, 0.5495], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,363 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,363 - train - INFO - True
2024-04-07 09:50:23,364 - train - INFO - alphas:tensor([0.4303, 0.0017, 0.0031, 0.0501, 0.5149], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,372 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,372 - train - INFO - True
2024-04-07 09:50:23,373 - train - INFO - alphas:tensor([0.3870, 0.0020, 0.0044, 0.0516, 0.5550], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,380 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,380 - train - INFO - True
2024-04-07 09:50:23,381 - train - INFO - alphas:tensor([0.7198, 0.0011, 0.0019, 0.0172, 0.2600], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,394 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,394 - train - INFO - True
2024-04-07 09:50:23,395 - train - INFO - alphas:tensor([0.5610, 0.0071, 0.0115, 0.0562, 0.3641], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:50:23,445 - train - INFO - tau:0.34116606151404244
2024-04-07 09:50:23,445 - train - INFO - avg block size:10.06060606060606
2024-04-07 09:50:23,445 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 09:50:23,665 - train - INFO - Test: [   0/78]  Time: 0.217 (0.217)  Loss:  1.0654 (1.0654)  Acc@1: 80.4688 (80.4688)  Acc@5: 93.7500 (93.7500)
2024-04-07 09:50:26,583 - train - INFO - Test: [  50/78]  Time: 0.054 (0.061)  Loss:  1.6152 (1.5492)  Acc@1: 64.0625 (66.1765)  Acc@5: 86.7188 (86.5656)
2024-04-07 09:50:28,285 - train - INFO - Test: [  78/78]  Time: 0.047 (0.061)  Loss:  1.8301 (1.5714)  Acc@1: 50.0000 (65.5800)  Acc@5: 93.7500 (86.0600)
2024-04-07 09:50:29,011 - train - INFO - Train: 110 [   0/781 (  0%)]  Loss:  3.681579 (3.6816)  Time: 0.645s,  198.35/s  (0.645s,  198.35/s)  LR: 9.106e-05  Data: 0.167 (0.167)
2024-04-07 09:50:53,052 - train - INFO - Train: 110 [  50/781 (  6%)]  Loss:  3.276796 (3.4953)  Time: 0.476s,  268.84/s  (0.484s,  264.45/s)  LR: 9.106e-05  Data: 0.008 (0.011)
2024-04-07 09:51:17,644 - train - INFO - Train: 110 [ 100/781 ( 13%)]  Loss:  3.175090 (3.4987)  Time: 0.520s,  246.22/s  (0.488s,  262.36/s)  LR: 9.106e-05  Data: 0.009 (0.010)
2024-04-07 09:51:41,365 - train - INFO - Train: 110 [ 150/781 ( 19%)]  Loss:  3.765497 (3.4933)  Time: 0.481s,  265.94/s  (0.483s,  264.79/s)  LR: 9.106e-05  Data: 0.009 (0.009)
2024-04-07 09:52:05,199 - train - INFO - Train: 110 [ 200/781 ( 26%)]  Loss:  3.295901 (3.4928)  Time: 0.532s,  240.69/s  (0.482s,  265.71/s)  LR: 9.106e-05  Data: 0.009 (0.009)
2024-04-07 09:52:27,848 - train - INFO - Train: 110 [ 250/781 ( 32%)]  Loss:  3.314158 (3.4922)  Time: 0.499s,  256.59/s  (0.476s,  268.91/s)  LR: 9.106e-05  Data: 0.009 (0.009)
2024-04-07 09:52:52,126 - train - INFO - Train: 110 [ 300/781 ( 38%)]  Loss:  3.159078 (3.4982)  Time: 0.505s,  253.56/s  (0.478s,  268.02/s)  LR: 9.106e-05  Data: 0.009 (0.008)
2024-04-07 09:53:15,908 - train - INFO - Train: 110 [ 350/781 ( 45%)]  Loss:  3.467257 (3.5065)  Time: 0.476s,  269.12/s  (0.477s,  268.18/s)  LR: 9.106e-05  Data: 0.008 (0.008)
2024-04-07 09:53:39,450 - train - INFO - Train: 110 [ 400/781 ( 51%)]  Loss:  3.334496 (3.5056)  Time: 0.473s,  270.74/s  (0.476s,  268.63/s)  LR: 9.106e-05  Data: 0.007 (0.008)
2024-04-07 09:54:02,886 - train - INFO - Train: 110 [ 450/781 ( 58%)]  Loss:  3.265300 (3.5059)  Time: 0.483s,  265.25/s  (0.476s,  269.12/s)  LR: 9.106e-05  Data: 0.008 (0.008)
2024-04-07 09:54:26,563 - train - INFO - Train: 110 [ 500/781 ( 64%)]  Loss:  3.250536 (3.5078)  Time: 0.506s,  252.78/s  (0.475s,  269.24/s)  LR: 9.106e-05  Data: 0.011 (0.008)
2024-04-07 09:54:50,460 - train - INFO - Train: 110 [ 550/781 ( 71%)]  Loss:  3.581711 (3.5061)  Time: 0.525s,  243.94/s  (0.476s,  269.11/s)  LR: 9.106e-05  Data: 0.008 (0.008)
2024-04-07 09:55:14,190 - train - INFO - Train: 110 [ 600/781 ( 77%)]  Loss:  3.416224 (3.5040)  Time: 0.474s,  269.88/s  (0.476s,  269.16/s)  LR: 9.106e-05  Data: 0.007 (0.008)
2024-04-07 09:55:37,680 - train - INFO - Train: 110 [ 650/781 ( 83%)]  Loss:  3.138720 (3.5062)  Time: 0.463s,  276.66/s  (0.475s,  269.41/s)  LR: 9.106e-05  Data: 0.007 (0.008)
2024-04-07 09:56:00,768 - train - INFO - Train: 110 [ 700/781 ( 90%)]  Loss:  3.616347 (3.5057)  Time: 0.434s,  294.64/s  (0.474s,  269.96/s)  LR: 9.106e-05  Data: 0.011 (0.008)
2024-04-07 09:56:24,013 - train - INFO - Train: 110 [ 750/781 ( 96%)]  Loss:  3.005559 (3.5022)  Time: 0.480s,  266.91/s  (0.474s,  270.31/s)  LR: 9.106e-05  Data: 0.008 (0.008)
2024-04-07 09:56:38,379 - train - INFO - Train: 110 [ 780/781 (100%)]  Loss:  3.652692 (3.5032)  Time: 0.455s,  281.14/s  (0.474s,  270.19/s)  LR: 9.106e-05  Data: 0.000 (0.008)
2024-04-07 09:56:38,380 - train - INFO - True
2024-04-07 09:56:38,383 - train - INFO - alphas:tensor([0.7012, 0.0242, 0.0413, 0.0618, 0.1715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,383 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,384 - train - INFO - True
2024-04-07 09:56:38,385 - train - INFO - alphas:tensor([0.4552, 0.0084, 0.0188, 0.0552, 0.4625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,386 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,386 - train - INFO - True
2024-04-07 09:56:38,388 - train - INFO - alphas:tensor([0.4947, 0.0156, 0.0502, 0.4395], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,389 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,389 - train - INFO - True
2024-04-07 09:56:38,390 - train - INFO - alphas:tensor([0.4344, 0.0159, 0.0355, 0.5141], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,391 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,391 - train - INFO - True
2024-04-07 09:56:38,393 - train - INFO - alphas:tensor([0.4401, 0.0099, 0.0436, 0.5065], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,394 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,394 - train - INFO - True
2024-04-07 09:56:38,395 - train - INFO - alphas:tensor([0.5291, 0.0162, 0.0361, 0.4186], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,396 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,397 - train - INFO - True
2024-04-07 09:56:38,398 - train - INFO - alphas:tensor([0.5779, 0.0082, 0.0120, 0.0372, 0.3646], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,400 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,400 - train - INFO - True
2024-04-07 09:56:38,401 - train - INFO - alphas:tensor([0.2429, 0.0045, 0.0036, 0.0378, 0.7112], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,402 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,402 - train - INFO - True
2024-04-07 09:56:38,404 - train - INFO - alphas:tensor([0.2492, 0.0030, 0.0042, 0.0287, 0.7149], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,405 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,405 - train - INFO - True
2024-04-07 09:56:38,406 - train - INFO - alphas:tensor([0.2504, 0.0020, 0.0036, 0.0324, 0.7116], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,407 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,407 - train - INFO - True
2024-04-07 09:56:38,408 - train - INFO - alphas:tensor([0.2380, 0.0038, 0.0037, 0.0390, 0.7155], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,409 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,410 - train - INFO - True
2024-04-07 09:56:38,411 - train - INFO - alphas:tensor([0.5753, 0.0031, 0.0071, 0.0325, 0.3820], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,412 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,413 - train - INFO - True
2024-04-07 09:56:38,414 - train - INFO - alphas:tensor([0.6846, 0.0041, 0.0056, 0.0216, 0.2841], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,419 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,419 - train - INFO - True
2024-04-07 09:56:38,420 - train - INFO - alphas:tensor([0.2704, 0.0092, 0.0097, 0.0726, 0.6380], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,423 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,423 - train - INFO - True
2024-04-07 09:56:38,424 - train - INFO - alphas:tensor([0.2835, 0.0045, 0.0063, 0.0637, 0.6421], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,427 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,427 - train - INFO - True
2024-04-07 09:56:38,428 - train - INFO - alphas:tensor([0.3028, 0.0035, 0.0063, 0.0570, 0.6304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,430 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,430 - train - INFO - True
2024-04-07 09:56:38,431 - train - INFO - alphas:tensor([0.2783, 0.0055, 0.0077, 0.0558, 0.6527], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,434 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,434 - train - INFO - True
2024-04-07 09:56:38,435 - train - INFO - alphas:tensor([0.3054, 0.0038, 0.0090, 0.0580, 0.6239], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,438 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,438 - train - INFO - True
2024-04-07 09:56:38,439 - train - INFO - alphas:tensor([0.2679, 0.0097, 0.0127, 0.0642, 0.6454], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,441 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,441 - train - INFO - True
2024-04-07 09:56:38,442 - train - INFO - alphas:tensor([0.6226, 0.0023, 0.0048, 0.0348, 0.3356], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,447 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,447 - train - INFO - True
2024-04-07 09:56:38,448 - train - INFO - alphas:tensor([0.5534, 0.0021, 0.0030, 0.0345, 0.4069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,456 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,457 - train - INFO - True
2024-04-07 09:56:38,458 - train - INFO - alphas:tensor([0.4287, 0.0018, 0.0063, 0.0501, 0.5131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,462 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,462 - train - INFO - True
2024-04-07 09:56:38,463 - train - INFO - alphas:tensor([0.4435, 0.0019, 0.0032, 0.0468, 0.5046], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,467 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,467 - train - INFO - True
2024-04-07 09:56:38,468 - train - INFO - alphas:tensor([0.4559, 0.0016, 0.0032, 0.0434, 0.4958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,472 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,472 - train - INFO - True
2024-04-07 09:56:38,473 - train - INFO - alphas:tensor([0.4170, 0.0019, 0.0051, 0.0480, 0.5279], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,477 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,477 - train - INFO - True
2024-04-07 09:56:38,478 - train - INFO - alphas:tensor([0.5666, 0.0017, 0.0042, 0.0298, 0.3977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,486 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,486 - train - INFO - True
2024-04-07 09:56:38,487 - train - INFO - alphas:tensor([0.7353, 0.0012, 0.0032, 0.0206, 0.2398], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,506 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,506 - train - INFO - True
2024-04-07 09:56:38,507 - train - INFO - alphas:tensor([0.3898, 0.0023, 0.0049, 0.0590, 0.5441], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,517 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,517 - train - INFO - True
2024-04-07 09:56:38,518 - train - INFO - alphas:tensor([0.3970, 0.0013, 0.0037, 0.0466, 0.5514], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,528 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,528 - train - INFO - True
2024-04-07 09:56:38,529 - train - INFO - alphas:tensor([0.4287, 0.0016, 0.0030, 0.0495, 0.5172], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,540 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,540 - train - INFO - True
2024-04-07 09:56:38,541 - train - INFO - alphas:tensor([0.3896, 0.0019, 0.0043, 0.0510, 0.5532], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,551 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,551 - train - INFO - True
2024-04-07 09:56:38,552 - train - INFO - alphas:tensor([0.7185, 0.0011, 0.0018, 0.0169, 0.2617], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,571 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,571 - train - INFO - True
2024-04-07 09:56:38,572 - train - INFO - alphas:tensor([0.5599, 0.0069, 0.0111, 0.0560, 0.3661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:56:38,658 - train - INFO - tau:0.337754400898902
2024-04-07 09:56:38,658 - train - INFO - avg block size:10.06060606060606
2024-04-07 09:56:38,659 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 09:56:38,659 - train - INFO - lasso_alpha:3.2701598165311565e-06
2024-04-07 09:56:38,849 - train - INFO - Test: [   0/78]  Time: 0.186 (0.186)  Loss:  0.9478 (0.9478)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 09:56:41,792 - train - INFO - Test: [  50/78]  Time: 0.055 (0.061)  Loss:  1.5459 (1.5492)  Acc@1: 66.4062 (65.9314)  Acc@5: 87.5000 (86.2439)
2024-04-07 09:56:43,275 - train - INFO - Test: [  78/78]  Time: 0.055 (0.058)  Loss:  1.9346 (1.5650)  Acc@1: 50.0000 (65.5000)  Acc@5: 87.5000 (86.0400)
2024-04-07 09:56:43,973 - train - INFO - Train: 111 [   0/781 (  0%)]  Loss:  3.550268 (3.5503)  Time: 0.622s,  205.83/s  (0.622s,  205.83/s)  LR: 8.729e-05  Data: 0.178 (0.178)
2024-04-07 09:57:07,102 - train - INFO - Train: 111 [  50/781 (  6%)]  Loss:  3.277511 (3.5183)  Time: 0.395s,  323.90/s  (0.466s,  274.88/s)  LR: 8.729e-05  Data: 0.006 (0.011)
2024-04-07 09:57:30,627 - train - INFO - Train: 111 [ 100/781 ( 13%)]  Loss:  3.554940 (3.4922)  Time: 0.449s,  285.19/s  (0.468s,  273.48/s)  LR: 8.729e-05  Data: 0.006 (0.009)
2024-04-07 09:57:53,910 - train - INFO - Train: 111 [ 150/781 ( 19%)]  Loss:  3.681375 (3.4839)  Time: 0.459s,  278.69/s  (0.467s,  273.95/s)  LR: 8.729e-05  Data: 0.005 (0.008)
2024-04-07 09:58:17,325 - train - INFO - Train: 111 [ 200/781 ( 26%)]  Loss:  3.597301 (3.4796)  Time: 0.446s,  286.79/s  (0.467s,  273.80/s)  LR: 8.729e-05  Data: 0.007 (0.008)
2024-04-07 09:58:40,140 - train - INFO - Train: 111 [ 250/781 ( 32%)]  Loss:  3.261738 (3.4800)  Time: 0.492s,  260.32/s  (0.465s,  275.11/s)  LR: 8.729e-05  Data: 0.012 (0.008)
2024-04-07 09:59:03,333 - train - INFO - Train: 111 [ 300/781 ( 38%)]  Loss:  3.228781 (3.4859)  Time: 0.432s,  296.25/s  (0.465s,  275.25/s)  LR: 8.729e-05  Data: 0.009 (0.008)
2024-04-07 09:59:27,140 - train - INFO - Train: 111 [ 350/781 ( 45%)]  Loss:  3.640672 (3.4939)  Time: 0.503s,  254.33/s  (0.467s,  274.32/s)  LR: 8.729e-05  Data: 0.008 (0.008)
2024-04-07 09:59:49,926 - train - INFO - Train: 111 [ 400/781 ( 51%)]  Loss:  3.662297 (3.4937)  Time: 0.495s,  258.75/s  (0.465s,  275.13/s)  LR: 8.729e-05  Data: 0.009 (0.008)
2024-04-07 10:00:13,076 - train - INFO - Train: 111 [ 450/781 ( 58%)]  Loss:  3.069367 (3.4933)  Time: 0.510s,  250.89/s  (0.465s,  275.28/s)  LR: 8.729e-05  Data: 0.010 (0.008)
2024-04-07 10:00:36,067 - train - INFO - Train: 111 [ 500/781 ( 64%)]  Loss:  3.744030 (3.4933)  Time: 0.427s,  300.03/s  (0.464s,  275.58/s)  LR: 8.729e-05  Data: 0.006 (0.008)
2024-04-07 10:00:58,667 - train - INFO - Train: 111 [ 550/781 ( 71%)]  Loss:  3.716022 (3.4936)  Time: 0.481s,  265.88/s  (0.463s,  276.26/s)  LR: 8.729e-05  Data: 0.007 (0.008)
2024-04-07 10:01:21,977 - train - INFO - Train: 111 [ 600/781 ( 77%)]  Loss:  3.637690 (3.4955)  Time: 0.477s,  268.33/s  (0.464s,  276.12/s)  LR: 8.729e-05  Data: 0.008 (0.008)
2024-04-07 10:01:44,860 - train - INFO - Train: 111 [ 650/781 ( 83%)]  Loss:  3.237458 (3.4953)  Time: 0.346s,  370.18/s  (0.463s,  276.39/s)  LR: 8.729e-05  Data: 0.005 (0.008)
2024-04-07 10:02:08,119 - train - INFO - Train: 111 [ 700/781 ( 90%)]  Loss:  3.202369 (3.4965)  Time: 0.454s,  281.75/s  (0.463s,  276.30/s)  LR: 8.729e-05  Data: 0.006 (0.008)
2024-04-07 10:02:32,010 - train - INFO - Train: 111 [ 750/781 ( 96%)]  Loss:  3.482513 (3.4932)  Time: 0.469s,  272.65/s  (0.464s,  275.73/s)  LR: 8.729e-05  Data: 0.008 (0.008)
2024-04-07 10:02:46,199 - train - INFO - Train: 111 [ 780/781 (100%)]  Loss:  3.699974 (3.4944)  Time: 0.463s,  276.43/s  (0.465s,  275.53/s)  LR: 8.729e-05  Data: 0.000 (0.008)
2024-04-07 10:02:46,200 - train - INFO - True
2024-04-07 10:02:46,201 - train - INFO - alphas:tensor([0.7053, 0.0236, 0.0404, 0.0606, 0.1700], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,201 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,201 - train - INFO - True
2024-04-07 10:02:46,202 - train - INFO - alphas:tensor([0.4530, 0.0080, 0.0182, 0.0545, 0.4664], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,202 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,202 - train - INFO - True
2024-04-07 10:02:46,203 - train - INFO - alphas:tensor([0.4965, 0.0152, 0.0494, 0.4389], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,204 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,204 - train - INFO - True
2024-04-07 10:02:46,204 - train - INFO - alphas:tensor([0.4351, 0.0155, 0.0346, 0.5148], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,205 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,205 - train - INFO - True
2024-04-07 10:02:46,205 - train - INFO - alphas:tensor([0.4401, 0.0096, 0.0428, 0.5076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,206 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,206 - train - INFO - True
2024-04-07 10:02:46,207 - train - INFO - alphas:tensor([0.5303, 0.0158, 0.0352, 0.4187], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,207 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,207 - train - INFO - True
2024-04-07 10:02:46,208 - train - INFO - alphas:tensor([0.5796, 0.0080, 0.0117, 0.0365, 0.3643], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,209 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,209 - train - INFO - True
2024-04-07 10:02:46,209 - train - INFO - alphas:tensor([0.2436, 0.0043, 0.0034, 0.0370, 0.7116], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,210 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,210 - train - INFO - True
2024-04-07 10:02:46,211 - train - INFO - alphas:tensor([0.2494, 0.0029, 0.0040, 0.0281, 0.7157], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,211 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,211 - train - INFO - True
2024-04-07 10:02:46,212 - train - INFO - alphas:tensor([0.2491, 0.0019, 0.0034, 0.0317, 0.7138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,212 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,212 - train - INFO - True
2024-04-07 10:02:46,213 - train - INFO - alphas:tensor([0.2394, 0.0036, 0.0036, 0.0383, 0.7151], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,213 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,214 - train - INFO - True
2024-04-07 10:02:46,214 - train - INFO - alphas:tensor([0.5777, 0.0030, 0.0068, 0.0317, 0.3808], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,215 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,215 - train - INFO - True
2024-04-07 10:02:46,216 - train - INFO - alphas:tensor([0.6869, 0.0040, 0.0053, 0.0211, 0.2827], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,218 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,218 - train - INFO - True
2024-04-07 10:02:46,219 - train - INFO - alphas:tensor([0.2706, 0.0090, 0.0094, 0.0709, 0.6401], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,220 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,220 - train - INFO - True
2024-04-07 10:02:46,221 - train - INFO - alphas:tensor([0.2854, 0.0043, 0.0061, 0.0630, 0.6412], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,222 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,222 - train - INFO - True
2024-04-07 10:02:46,223 - train - INFO - alphas:tensor([0.3048, 0.0033, 0.0060, 0.0555, 0.6303], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,224 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,224 - train - INFO - True
2024-04-07 10:02:46,225 - train - INFO - alphas:tensor([0.2806, 0.0053, 0.0074, 0.0547, 0.6519], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,226 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,226 - train - INFO - True
2024-04-07 10:02:46,227 - train - INFO - alphas:tensor([0.3075, 0.0036, 0.0088, 0.0573, 0.6228], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,228 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,228 - train - INFO - True
2024-04-07 10:02:46,229 - train - INFO - alphas:tensor([0.2667, 0.0094, 0.0123, 0.0639, 0.6478], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,230 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,230 - train - INFO - True
2024-04-07 10:02:46,231 - train - INFO - alphas:tensor([0.6239, 0.0021, 0.0046, 0.0339, 0.3354], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,233 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,233 - train - INFO - True
2024-04-07 10:02:46,234 - train - INFO - alphas:tensor([0.5530, 0.0020, 0.0029, 0.0337, 0.4084], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,238 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,239 - train - INFO - True
2024-04-07 10:02:46,239 - train - INFO - alphas:tensor([0.4265, 0.0017, 0.0061, 0.0493, 0.5163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,242 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,242 - train - INFO - True
2024-04-07 10:02:46,242 - train - INFO - alphas:tensor([0.4417, 0.0018, 0.0031, 0.0456, 0.5078], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,245 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,245 - train - INFO - True
2024-04-07 10:02:46,245 - train - INFO - alphas:tensor([0.4574, 0.0016, 0.0031, 0.0430, 0.4950], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,248 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,248 - train - INFO - True
2024-04-07 10:02:46,249 - train - INFO - alphas:tensor([0.4208, 0.0018, 0.0049, 0.0471, 0.5253], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,251 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,251 - train - INFO - True
2024-04-07 10:02:46,252 - train - INFO - alphas:tensor([0.5665, 0.0016, 0.0040, 0.0289, 0.3990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,256 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,256 - train - INFO - True
2024-04-07 10:02:46,257 - train - INFO - alphas:tensor([0.7374, 0.0011, 0.0030, 0.0202, 0.2382], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,269 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,269 - train - INFO - True
2024-04-07 10:02:46,269 - train - INFO - alphas:tensor([0.3913, 0.0022, 0.0047, 0.0582, 0.5436], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,275 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,275 - train - INFO - True
2024-04-07 10:02:46,276 - train - INFO - alphas:tensor([0.3975, 0.0012, 0.0036, 0.0462, 0.5515], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,284 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,284 - train - INFO - True
2024-04-07 10:02:46,285 - train - INFO - alphas:tensor([0.4299, 0.0015, 0.0028, 0.0488, 0.5170], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,292 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,292 - train - INFO - True
2024-04-07 10:02:46,293 - train - INFO - alphas:tensor([0.3965, 0.0018, 0.0041, 0.0501, 0.5476], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,300 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,300 - train - INFO - True
2024-04-07 10:02:46,301 - train - INFO - alphas:tensor([0.7201, 0.0010, 0.0017, 0.0165, 0.2606], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,314 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,314 - train - INFO - True
2024-04-07 10:02:46,315 - train - INFO - alphas:tensor([0.5649, 0.0067, 0.0107, 0.0552, 0.3625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:02:46,364 - train - INFO - tau:0.334376856889913
2024-04-07 10:02:46,364 - train - INFO - avg block size:10.06060606060606
2024-04-07 10:02:46,364 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 10:02:46,532 - train - INFO - Test: [   0/78]  Time: 0.164 (0.164)  Loss:  1.0117 (1.0117)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.9688 (92.9688)
2024-04-07 10:02:49,564 - train - INFO - Test: [  50/78]  Time: 0.075 (0.063)  Loss:  1.6543 (1.5705)  Acc@1: 64.0625 (65.8088)  Acc@5: 85.9375 (86.1826)
2024-04-07 10:02:51,097 - train - INFO - Test: [  78/78]  Time: 0.046 (0.060)  Loss:  1.8818 (1.5857)  Acc@1: 56.2500 (65.6400)  Acc@5: 81.2500 (86.0300)
2024-04-07 10:02:51,812 - train - INFO - Train: 112 [   0/781 (  0%)]  Loss:  3.310926 (3.3109)  Time: 0.634s,  201.84/s  (0.634s,  201.84/s)  LR: 8.358e-05  Data: 0.164 (0.164)
2024-04-07 10:03:15,512 - train - INFO - Train: 112 [  50/781 (  6%)]  Loss:  3.526528 (3.4996)  Time: 0.369s,  346.73/s  (0.477s,  268.29/s)  LR: 8.358e-05  Data: 0.010 (0.011)
2024-04-07 10:03:38,752 - train - INFO - Train: 112 [ 100/781 ( 13%)]  Loss:  3.860808 (3.5072)  Time: 0.434s,  294.77/s  (0.471s,  271.77/s)  LR: 8.358e-05  Data: 0.008 (0.009)
2024-04-07 10:04:02,002 - train - INFO - Train: 112 [ 150/781 ( 19%)]  Loss:  3.797934 (3.5203)  Time: 0.449s,  285.02/s  (0.469s,  272.92/s)  LR: 8.358e-05  Data: 0.005 (0.009)
2024-04-07 10:04:24,721 - train - INFO - Train: 112 [ 200/781 ( 26%)]  Loss:  3.193406 (3.4996)  Time: 0.489s,  261.74/s  (0.465s,  275.06/s)  LR: 8.358e-05  Data: 0.005 (0.008)
2024-04-07 10:04:47,764 - train - INFO - Train: 112 [ 250/781 ( 32%)]  Loss:  3.569255 (3.5022)  Time: 0.499s,  256.30/s  (0.464s,  275.59/s)  LR: 8.358e-05  Data: 0.009 (0.008)
2024-04-07 10:05:10,998 - train - INFO - Train: 112 [ 300/781 ( 38%)]  Loss:  3.683350 (3.5012)  Time: 0.488s,  262.13/s  (0.464s,  275.57/s)  LR: 8.358e-05  Data: 0.009 (0.008)
2024-04-07 10:05:34,181 - train - INFO - Train: 112 [ 350/781 ( 45%)]  Loss:  3.469697 (3.5011)  Time: 0.482s,  265.57/s  (0.464s,  275.65/s)  LR: 8.358e-05  Data: 0.007 (0.008)
2024-04-07 10:05:57,255 - train - INFO - Train: 112 [ 400/781 ( 51%)]  Loss:  3.541625 (3.5018)  Time: 0.424s,  302.23/s  (0.464s,  275.86/s)  LR: 8.358e-05  Data: 0.008 (0.008)
2024-04-07 10:06:20,606 - train - INFO - Train: 112 [ 450/781 ( 58%)]  Loss:  3.734339 (3.5034)  Time: 0.493s,  259.72/s  (0.464s,  275.67/s)  LR: 8.358e-05  Data: 0.007 (0.008)
2024-04-07 10:06:43,088 - train - INFO - Train: 112 [ 500/781 ( 64%)]  Loss:  3.406610 (3.4989)  Time: 0.411s,  311.17/s  (0.463s,  276.54/s)  LR: 8.358e-05  Data: 0.005 (0.008)
2024-04-07 10:07:05,540 - train - INFO - Train: 112 [ 550/781 ( 71%)]  Loss:  3.830137 (3.4961)  Time: 0.333s,  384.34/s  (0.462s,  277.30/s)  LR: 8.358e-05  Data: 0.004 (0.008)
2024-04-07 10:07:28,665 - train - INFO - Train: 112 [ 600/781 ( 77%)]  Loss:  3.576417 (3.4934)  Time: 0.489s,  261.83/s  (0.462s,  277.25/s)  LR: 8.358e-05  Data: 0.007 (0.008)
2024-04-07 10:07:51,427 - train - INFO - Train: 112 [ 650/781 ( 83%)]  Loss:  3.726363 (3.4947)  Time: 0.416s,  307.92/s  (0.461s,  277.55/s)  LR: 8.358e-05  Data: 0.008 (0.008)
2024-04-07 10:08:14,590 - train - INFO - Train: 112 [ 700/781 ( 90%)]  Loss:  3.332214 (3.4985)  Time: 0.509s,  251.47/s  (0.461s,  277.46/s)  LR: 8.358e-05  Data: 0.008 (0.008)
2024-04-07 10:08:37,330 - train - INFO - Train: 112 [ 750/781 ( 96%)]  Loss:  3.196206 (3.4970)  Time: 0.472s,  271.42/s  (0.461s,  277.73/s)  LR: 8.358e-05  Data: 0.005 (0.008)
2024-04-07 10:08:50,928 - train - INFO - Train: 112 [ 780/781 (100%)]  Loss:  3.491739 (3.4982)  Time: 0.448s,  285.97/s  (0.461s,  277.90/s)  LR: 8.358e-05  Data: 0.000 (0.008)
2024-04-07 10:08:50,929 - train - INFO - True
2024-04-07 10:08:50,931 - train - INFO - alphas:tensor([0.7081, 0.0230, 0.0398, 0.0599, 0.1693], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,931 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,932 - train - INFO - True
2024-04-07 10:08:50,933 - train - INFO - alphas:tensor([0.4541, 0.0077, 0.0177, 0.0535, 0.4670], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,934 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,934 - train - INFO - True
2024-04-07 10:08:50,935 - train - INFO - alphas:tensor([0.4974, 0.0147, 0.0486, 0.4393], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,936 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,936 - train - INFO - True
2024-04-07 10:08:50,938 - train - INFO - alphas:tensor([0.4375, 0.0151, 0.0340, 0.5134], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,938 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,939 - train - INFO - True
2024-04-07 10:08:50,940 - train - INFO - alphas:tensor([0.4405, 0.0093, 0.0420, 0.5083], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,941 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,941 - train - INFO - True
2024-04-07 10:08:50,942 - train - INFO - alphas:tensor([0.5290, 0.0153, 0.0345, 0.4212], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,943 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,943 - train - INFO - True
2024-04-07 10:08:50,944 - train - INFO - alphas:tensor([0.5804, 0.0077, 0.0113, 0.0358, 0.3648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,946 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,946 - train - INFO - True
2024-04-07 10:08:50,947 - train - INFO - alphas:tensor([0.2439, 0.0042, 0.0033, 0.0365, 0.7122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,948 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,948 - train - INFO - True
2024-04-07 10:08:50,950 - train - INFO - alphas:tensor([0.2500, 0.0028, 0.0039, 0.0274, 0.7159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,951 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,951 - train - INFO - True
2024-04-07 10:08:50,952 - train - INFO - alphas:tensor([0.2494, 0.0018, 0.0033, 0.0313, 0.7142], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,953 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,953 - train - INFO - True
2024-04-07 10:08:50,954 - train - INFO - alphas:tensor([0.2382, 0.0035, 0.0034, 0.0376, 0.7173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,955 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,955 - train - INFO - True
2024-04-07 10:08:50,956 - train - INFO - alphas:tensor([0.5771, 0.0028, 0.0066, 0.0310, 0.3826], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,958 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,958 - train - INFO - True
2024-04-07 10:08:50,959 - train - INFO - alphas:tensor([0.6881, 0.0038, 0.0051, 0.0205, 0.2824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,964 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,964 - train - INFO - True
2024-04-07 10:08:50,965 - train - INFO - alphas:tensor([0.2694, 0.0087, 0.0091, 0.0702, 0.6426], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,967 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,967 - train - INFO - True
2024-04-07 10:08:50,969 - train - INFO - alphas:tensor([0.2855, 0.0042, 0.0058, 0.0620, 0.6425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,971 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,971 - train - INFO - True
2024-04-07 10:08:50,972 - train - INFO - alphas:tensor([0.3075, 0.0032, 0.0059, 0.0553, 0.6282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,974 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,974 - train - INFO - True
2024-04-07 10:08:50,975 - train - INFO - alphas:tensor([0.2801, 0.0051, 0.0071, 0.0538, 0.6538], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,978 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,978 - train - INFO - True
2024-04-07 10:08:50,979 - train - INFO - alphas:tensor([0.3069, 0.0034, 0.0084, 0.0561, 0.6251], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,981 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,981 - train - INFO - True
2024-04-07 10:08:50,982 - train - INFO - alphas:tensor([0.2683, 0.0091, 0.0119, 0.0624, 0.6483], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,984 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,985 - train - INFO - True
2024-04-07 10:08:50,986 - train - INFO - alphas:tensor([0.6278, 0.0021, 0.0044, 0.0332, 0.3326], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,990 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,990 - train - INFO - True
2024-04-07 10:08:50,991 - train - INFO - alphas:tensor([0.5558, 0.0019, 0.0028, 0.0334, 0.4061], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:50,999 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:50,999 - train - INFO - True
2024-04-07 10:08:51,000 - train - INFO - alphas:tensor([0.4320, 0.0016, 0.0059, 0.0484, 0.5122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:51,004 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:51,004 - train - INFO - True
2024-04-07 10:08:51,005 - train - INFO - alphas:tensor([0.4436, 0.0017, 0.0029, 0.0447, 0.5072], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:51,009 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:51,009 - train - INFO - True
2024-04-07 10:08:51,010 - train - INFO - alphas:tensor([0.4568, 0.0015, 0.0029, 0.0424, 0.4964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:51,014 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:51,014 - train - INFO - True
2024-04-07 10:08:51,015 - train - INFO - alphas:tensor([0.4219, 0.0017, 0.0046, 0.0459, 0.5259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:51,019 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:51,019 - train - INFO - True
2024-04-07 10:08:51,020 - train - INFO - alphas:tensor([0.5684, 0.0015, 0.0039, 0.0284, 0.3978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:51,027 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:51,027 - train - INFO - True
2024-04-07 10:08:51,028 - train - INFO - alphas:tensor([0.7389, 0.0011, 0.0029, 0.0198, 0.2373], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:51,048 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:51,048 - train - INFO - True
2024-04-07 10:08:51,049 - train - INFO - alphas:tensor([0.3937, 0.0021, 0.0045, 0.0573, 0.5424], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:51,059 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:51,059 - train - INFO - True
2024-04-07 10:08:51,060 - train - INFO - alphas:tensor([0.3976, 0.0012, 0.0035, 0.0456, 0.5522], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:51,070 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:51,070 - train - INFO - True
2024-04-07 10:08:51,071 - train - INFO - alphas:tensor([0.4305, 0.0014, 0.0027, 0.0480, 0.5175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:51,081 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:51,081 - train - INFO - True
2024-04-07 10:08:51,082 - train - INFO - alphas:tensor([0.3930, 0.0017, 0.0039, 0.0497, 0.5516], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:51,092 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:51,092 - train - INFO - True
2024-04-07 10:08:51,093 - train - INFO - alphas:tensor([0.7220, 0.0009, 0.0017, 0.0162, 0.2592], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:51,112 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:51,113 - train - INFO - True
2024-04-07 10:08:51,113 - train - INFO - alphas:tensor([0.5634, 0.0065, 0.0105, 0.0547, 0.3649], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:08:51,191 - train - INFO - tau:0.33103308832101386
2024-04-07 10:08:51,191 - train - INFO - avg block size:10.06060606060606
2024-04-07 10:08:51,192 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 10:08:51,192 - train - INFO - lasso_alpha:2.9728725604828693e-06
2024-04-07 10:08:51,397 - train - INFO - Test: [   0/78]  Time: 0.202 (0.202)  Loss:  0.9907 (0.9907)  Acc@1: 81.2500 (81.2500)  Acc@5: 92.9688 (92.9688)
2024-04-07 10:08:54,512 - train - INFO - Test: [  50/78]  Time: 0.073 (0.065)  Loss:  1.4785 (1.5588)  Acc@1: 66.4062 (65.9007)  Acc@5: 87.5000 (86.4583)
2024-04-07 10:08:56,259 - train - INFO - Test: [  78/78]  Time: 0.046 (0.064)  Loss:  1.8760 (1.5756)  Acc@1: 56.2500 (65.5000)  Acc@5: 87.5000 (85.9600)
2024-04-07 10:08:57,012 - train - INFO - Train: 113 [   0/781 (  0%)]  Loss:  3.883668 (3.8837)  Time: 0.674s,  190.00/s  (0.674s,  190.00/s)  LR: 7.995e-05  Data: 0.177 (0.177)
2024-04-07 10:09:21,254 - train - INFO - Train: 113 [  50/781 (  6%)]  Loss:  3.574438 (3.5118)  Time: 0.436s,  293.77/s  (0.489s,  262.02/s)  LR: 7.995e-05  Data: 0.007 (0.011)
2024-04-07 10:09:45,143 - train - INFO - Train: 113 [ 100/781 ( 13%)]  Loss:  3.553563 (3.4931)  Time: 0.480s,  266.44/s  (0.483s,  264.91/s)  LR: 7.995e-05  Data: 0.009 (0.010)
2024-04-07 10:10:08,193 - train - INFO - Train: 113 [ 150/781 ( 19%)]  Loss:  3.060725 (3.4830)  Time: 0.473s,  270.53/s  (0.476s,  269.01/s)  LR: 7.995e-05  Data: 0.006 (0.009)
2024-04-07 10:10:32,279 - train - INFO - Train: 113 [ 200/781 ( 26%)]  Loss:  3.515940 (3.4888)  Time: 0.486s,  263.53/s  (0.477s,  268.18/s)  LR: 7.995e-05  Data: 0.009 (0.008)
2024-04-07 10:10:56,153 - train - INFO - Train: 113 [ 250/781 ( 32%)]  Loss:  3.595362 (3.4891)  Time: 0.520s,  246.36/s  (0.477s,  268.17/s)  LR: 7.995e-05  Data: 0.012 (0.008)
2024-04-07 10:11:20,101 - train - INFO - Train: 113 [ 300/781 ( 38%)]  Loss:  3.385900 (3.4902)  Time: 0.457s,  280.12/s  (0.478s,  268.01/s)  LR: 7.995e-05  Data: 0.007 (0.008)
2024-04-07 10:11:43,652 - train - INFO - Train: 113 [ 350/781 ( 45%)]  Loss:  3.547112 (3.4860)  Time: 0.482s,  265.62/s  (0.477s,  268.54/s)  LR: 7.995e-05  Data: 0.008 (0.008)
2024-04-07 10:12:07,654 - train - INFO - Train: 113 [ 400/781 ( 51%)]  Loss:  3.820803 (3.4874)  Time: 0.474s,  269.88/s  (0.477s,  268.31/s)  LR: 7.995e-05  Data: 0.007 (0.008)
2024-04-07 10:12:31,016 - train - INFO - Train: 113 [ 450/781 ( 58%)]  Loss:  3.400671 (3.4851)  Time: 0.489s,  261.85/s  (0.476s,  268.92/s)  LR: 7.995e-05  Data: 0.007 (0.008)
2024-04-07 10:12:53,818 - train - INFO - Train: 113 [ 500/781 ( 64%)]  Loss:  3.914611 (3.4878)  Time: 0.360s,  355.62/s  (0.474s,  270.05/s)  LR: 7.995e-05  Data: 0.005 (0.008)
2024-04-07 10:13:17,363 - train - INFO - Train: 113 [ 550/781 ( 71%)]  Loss:  3.648535 (3.4840)  Time: 0.457s,  279.94/s  (0.474s,  270.22/s)  LR: 7.995e-05  Data: 0.008 (0.008)
2024-04-07 10:13:40,236 - train - INFO - Train: 113 [ 600/781 ( 77%)]  Loss:  3.851128 (3.4823)  Time: 0.408s,  313.42/s  (0.472s,  270.99/s)  LR: 7.995e-05  Data: 0.008 (0.008)
2024-04-07 10:14:04,233 - train - INFO - Train: 113 [ 650/781 ( 83%)]  Loss:  3.721877 (3.4839)  Time: 0.495s,  258.46/s  (0.473s,  270.66/s)  LR: 7.995e-05  Data: 0.007 (0.008)
2024-04-07 10:14:26,898 - train - INFO - Train: 113 [ 700/781 ( 90%)]  Loss:  3.765319 (3.4833)  Time: 0.493s,  259.53/s  (0.472s,  271.46/s)  LR: 7.995e-05  Data: 0.009 (0.008)
2024-04-07 10:14:50,532 - train - INFO - Train: 113 [ 750/781 ( 96%)]  Loss:  3.524866 (3.4829)  Time: 0.510s,  250.92/s  (0.472s,  271.42/s)  LR: 7.995e-05  Data: 0.009 (0.008)
2024-04-07 10:15:04,023 - train - INFO - Train: 113 [ 780/781 (100%)]  Loss:  3.114573 (3.4843)  Time: 0.478s,  267.73/s  (0.471s,  271.91/s)  LR: 7.995e-05  Data: 0.000 (0.008)
2024-04-07 10:15:04,023 - train - INFO - True
2024-04-07 10:15:04,025 - train - INFO - alphas:tensor([0.7122, 0.0223, 0.0389, 0.0586, 0.1680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,025 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,025 - train - INFO - True
2024-04-07 10:15:04,026 - train - INFO - alphas:tensor([0.4548, 0.0075, 0.0173, 0.0528, 0.4677], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,027 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,027 - train - INFO - True
2024-04-07 10:15:04,028 - train - INFO - alphas:tensor([0.4972, 0.0143, 0.0479, 0.4406], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,028 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,028 - train - INFO - True
2024-04-07 10:15:04,029 - train - INFO - alphas:tensor([0.4370, 0.0147, 0.0334, 0.5149], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,030 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,030 - train - INFO - True
2024-04-07 10:15:04,031 - train - INFO - alphas:tensor([0.4414, 0.0090, 0.0411, 0.5085], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,031 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,031 - train - INFO - True
2024-04-07 10:15:04,032 - train - INFO - alphas:tensor([0.5321, 0.0148, 0.0336, 0.4194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,033 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,033 - train - INFO - True
2024-04-07 10:15:04,034 - train - INFO - alphas:tensor([0.5815, 0.0074, 0.0109, 0.0351, 0.3651], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,035 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,035 - train - INFO - True
2024-04-07 10:15:04,036 - train - INFO - alphas:tensor([0.2426, 0.0040, 0.0031, 0.0358, 0.7146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,037 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,037 - train - INFO - True
2024-04-07 10:15:04,038 - train - INFO - alphas:tensor([0.2505, 0.0027, 0.0037, 0.0268, 0.7163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,038 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,039 - train - INFO - True
2024-04-07 10:15:04,039 - train - INFO - alphas:tensor([0.2495, 0.0017, 0.0031, 0.0309, 0.7147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,040 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,040 - train - INFO - True
2024-04-07 10:15:04,041 - train - INFO - alphas:tensor([0.2385, 0.0033, 0.0033, 0.0371, 0.7178], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,042 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,042 - train - INFO - True
2024-04-07 10:15:04,043 - train - INFO - alphas:tensor([0.5791, 0.0027, 0.0063, 0.0303, 0.3817], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,044 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,044 - train - INFO - True
2024-04-07 10:15:04,045 - train - INFO - alphas:tensor([0.6898, 0.0036, 0.0049, 0.0199, 0.2819], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,048 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,048 - train - INFO - True
2024-04-07 10:15:04,049 - train - INFO - alphas:tensor([0.2727, 0.0085, 0.0088, 0.0693, 0.6407], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,051 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,051 - train - INFO - True
2024-04-07 10:15:04,052 - train - INFO - alphas:tensor([0.2857, 0.0040, 0.0056, 0.0614, 0.6433], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,054 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,054 - train - INFO - True
2024-04-07 10:15:04,055 - train - INFO - alphas:tensor([0.3057, 0.0030, 0.0056, 0.0545, 0.6311], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,057 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,057 - train - INFO - True
2024-04-07 10:15:04,058 - train - INFO - alphas:tensor([0.2825, 0.0049, 0.0069, 0.0534, 0.6523], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,060 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,060 - train - INFO - True
2024-04-07 10:15:04,061 - train - INFO - alphas:tensor([0.3069, 0.0033, 0.0082, 0.0551, 0.6265], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,063 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,063 - train - INFO - True
2024-04-07 10:15:04,064 - train - INFO - alphas:tensor([0.2697, 0.0088, 0.0116, 0.0616, 0.6482], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,066 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,066 - train - INFO - True
2024-04-07 10:15:04,067 - train - INFO - alphas:tensor([0.6272, 0.0020, 0.0042, 0.0325, 0.3341], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,070 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,070 - train - INFO - True
2024-04-07 10:15:04,071 - train - INFO - alphas:tensor([0.5565, 0.0018, 0.0026, 0.0326, 0.4064], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,079 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,079 - train - INFO - True
2024-04-07 10:15:04,080 - train - INFO - alphas:tensor([0.4344, 0.0015, 0.0057, 0.0478, 0.5106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,083 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,084 - train - INFO - True
2024-04-07 10:15:04,085 - train - INFO - alphas:tensor([0.4466, 0.0016, 0.0028, 0.0438, 0.5053], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,088 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,088 - train - INFO - True
2024-04-07 10:15:04,089 - train - INFO - alphas:tensor([0.4581, 0.0014, 0.0028, 0.0414, 0.4963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,093 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,093 - train - INFO - True
2024-04-07 10:15:04,094 - train - INFO - alphas:tensor([0.4243, 0.0016, 0.0044, 0.0453, 0.5244], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,098 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,098 - train - INFO - True
2024-04-07 10:15:04,099 - train - INFO - alphas:tensor([0.5682, 0.0014, 0.0037, 0.0277, 0.3990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,106 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,106 - train - INFO - True
2024-04-07 10:15:04,107 - train - INFO - alphas:tensor([0.7408, 0.0010, 0.0028, 0.0192, 0.2361], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,133 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,133 - train - INFO - True
2024-04-07 10:15:04,134 - train - INFO - alphas:tensor([0.3917, 0.0020, 0.0044, 0.0572, 0.5446], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,144 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,145 - train - INFO - True
2024-04-07 10:15:04,145 - train - INFO - alphas:tensor([0.4017, 0.0011, 0.0033, 0.0453, 0.5486], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,155 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,156 - train - INFO - True
2024-04-07 10:15:04,156 - train - INFO - alphas:tensor([0.4320, 0.0013, 0.0026, 0.0474, 0.5168], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,167 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,167 - train - INFO - True
2024-04-07 10:15:04,168 - train - INFO - alphas:tensor([0.3924, 0.0016, 0.0038, 0.0490, 0.5532], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,178 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,178 - train - INFO - True
2024-04-07 10:15:04,179 - train - INFO - alphas:tensor([0.7249, 0.0009, 0.0016, 0.0156, 0.2570], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,198 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,198 - train - INFO - True
2024-04-07 10:15:04,199 - train - INFO - alphas:tensor([0.5660, 0.0063, 0.0102, 0.0538, 0.3637], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:15:04,276 - train - INFO - tau:0.3277227574378037
2024-04-07 10:15:04,277 - train - INFO - avg block size:10.06060606060606
2024-04-07 10:15:04,277 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 10:15:04,478 - train - INFO - Test: [   0/78]  Time: 0.197 (0.197)  Loss:  0.9502 (0.9502)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.9688 (92.9688)
2024-04-07 10:15:07,638 - train - INFO - Test: [  50/78]  Time: 0.053 (0.066)  Loss:  1.6367 (1.5545)  Acc@1: 64.0625 (66.0386)  Acc@5: 85.9375 (86.4277)
2024-04-07 10:15:09,121 - train - INFO - Test: [  78/78]  Time: 0.050 (0.061)  Loss:  1.9658 (1.5715)  Acc@1: 56.2500 (65.7600)  Acc@5: 87.5000 (86.0500)
2024-04-07 10:15:09,885 - train - INFO - Train: 114 [   0/781 (  0%)]  Loss:  3.891854 (3.8919)  Time: 0.676s,  189.37/s  (0.676s,  189.37/s)  LR: 7.640e-05  Data: 0.192 (0.192)
2024-04-07 10:15:32,858 - train - INFO - Train: 114 [  50/781 (  6%)]  Loss:  3.482708 (3.5052)  Time: 0.436s,  293.88/s  (0.464s,  276.06/s)  LR: 7.640e-05  Data: 0.005 (0.011)
2024-04-07 10:15:56,600 - train - INFO - Train: 114 [ 100/781 ( 13%)]  Loss:  3.779752 (3.5056)  Time: 0.457s,  280.34/s  (0.469s,  272.82/s)  LR: 7.640e-05  Data: 0.007 (0.009)
2024-04-07 10:16:20,518 - train - INFO - Train: 114 [ 150/781 ( 19%)]  Loss:  3.327145 (3.4993)  Time: 0.444s,  288.43/s  (0.472s,  271.06/s)  LR: 7.640e-05  Data: 0.010 (0.009)
2024-04-07 10:16:44,175 - train - INFO - Train: 114 [ 200/781 ( 26%)]  Loss:  3.457074 (3.4901)  Time: 0.458s,  279.23/s  (0.472s,  270.94/s)  LR: 7.640e-05  Data: 0.008 (0.008)
2024-04-07 10:17:07,431 - train - INFO - Train: 114 [ 250/781 ( 32%)]  Loss:  3.633312 (3.4815)  Time: 0.386s,  331.68/s  (0.471s,  271.78/s)  LR: 7.640e-05  Data: 0.005 (0.008)
2024-04-07 10:17:29,944 - train - INFO - Train: 114 [ 300/781 ( 38%)]  Loss:  3.224626 (3.4749)  Time: 0.501s,  255.66/s  (0.468s,  273.78/s)  LR: 7.640e-05  Data: 0.009 (0.008)
2024-04-07 10:17:52,865 - train - INFO - Train: 114 [ 350/781 ( 45%)]  Loss:  3.682350 (3.4780)  Time: 0.503s,  254.26/s  (0.466s,  274.55/s)  LR: 7.640e-05  Data: 0.009 (0.008)
2024-04-07 10:18:16,706 - train - INFO - Train: 114 [ 400/781 ( 51%)]  Loss:  3.173394 (3.4785)  Time: 0.478s,  267.97/s  (0.468s,  273.77/s)  LR: 7.640e-05  Data: 0.010 (0.008)
2024-04-07 10:18:39,838 - train - INFO - Train: 114 [ 450/781 ( 58%)]  Loss:  3.437104 (3.4746)  Time: 0.472s,  271.18/s  (0.467s,  274.09/s)  LR: 7.640e-05  Data: 0.010 (0.008)
2024-04-07 10:19:03,250 - train - INFO - Train: 114 [ 500/781 ( 64%)]  Loss:  3.416872 (3.4729)  Time: 0.495s,  258.58/s  (0.467s,  274.02/s)  LR: 7.640e-05  Data: 0.010 (0.008)
2024-04-07 10:19:26,668 - train - INFO - Train: 114 [ 550/781 ( 71%)]  Loss:  3.385430 (3.4733)  Time: 0.447s,  286.27/s  (0.467s,  273.96/s)  LR: 7.640e-05  Data: 0.006 (0.008)
2024-04-07 10:19:48,876 - train - INFO - Train: 114 [ 600/781 ( 77%)]  Loss:  3.132034 (3.4730)  Time: 0.441s,  290.35/s  (0.465s,  275.09/s)  LR: 7.640e-05  Data: 0.005 (0.008)
2024-04-07 10:20:12,019 - train - INFO - Train: 114 [ 650/781 ( 83%)]  Loss:  3.410146 (3.4772)  Time: 0.446s,  287.19/s  (0.465s,  275.20/s)  LR: 7.640e-05  Data: 0.009 (0.008)
2024-04-07 10:20:35,586 - train - INFO - Train: 114 [ 700/781 ( 90%)]  Loss:  3.372222 (3.4775)  Time: 0.521s,  245.91/s  (0.466s,  274.94/s)  LR: 7.640e-05  Data: 0.007 (0.008)
2024-04-07 10:20:59,826 - train - INFO - Train: 114 [ 750/781 ( 96%)]  Loss:  3.706661 (3.4805)  Time: 0.445s,  287.65/s  (0.467s,  274.19/s)  LR: 7.640e-05  Data: 0.006 (0.008)
2024-04-07 10:21:13,255 - train - INFO - Train: 114 [ 780/781 (100%)]  Loss:  3.637866 (3.4834)  Time: 0.464s,  276.07/s  (0.466s,  274.62/s)  LR: 7.640e-05  Data: 0.000 (0.008)
2024-04-07 10:21:13,256 - train - INFO - True
2024-04-07 10:21:13,258 - train - INFO - alphas:tensor([0.7155, 0.0218, 0.0381, 0.0577, 0.1669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,259 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,259 - train - INFO - True
2024-04-07 10:21:13,260 - train - INFO - alphas:tensor([0.4536, 0.0072, 0.0168, 0.0520, 0.4705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,261 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,261 - train - INFO - True
2024-04-07 10:21:13,263 - train - INFO - alphas:tensor([0.4995, 0.0139, 0.0471, 0.4395], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,264 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,264 - train - INFO - True
2024-04-07 10:21:13,265 - train - INFO - alphas:tensor([0.4373, 0.0142, 0.0327, 0.5157], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,266 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,266 - train - INFO - True
2024-04-07 10:21:13,268 - train - INFO - alphas:tensor([0.4412, 0.0087, 0.0404, 0.5097], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,268 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,268 - train - INFO - True
2024-04-07 10:21:13,270 - train - INFO - alphas:tensor([0.5331, 0.0144, 0.0330, 0.4195], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,271 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,271 - train - INFO - True
2024-04-07 10:21:13,272 - train - INFO - alphas:tensor([0.5818, 0.0071, 0.0106, 0.0344, 0.3661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,274 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,274 - train - INFO - True
2024-04-07 10:21:13,276 - train - INFO - alphas:tensor([0.2413, 0.0039, 0.0030, 0.0350, 0.7168], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,276 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,277 - train - INFO - True
2024-04-07 10:21:13,278 - train - INFO - alphas:tensor([0.2501, 0.0025, 0.0036, 0.0262, 0.7176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,279 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,279 - train - INFO - True
2024-04-07 10:21:13,280 - train - INFO - alphas:tensor([0.2501, 0.0016, 0.0030, 0.0304, 0.7148], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,281 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,281 - train - INFO - True
2024-04-07 10:21:13,283 - train - INFO - alphas:tensor([0.2384, 0.0032, 0.0032, 0.0364, 0.7188], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,284 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,284 - train - INFO - True
2024-04-07 10:21:13,285 - train - INFO - alphas:tensor([0.5814, 0.0026, 0.0061, 0.0296, 0.3803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,286 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,287 - train - INFO - True
2024-04-07 10:21:13,288 - train - INFO - alphas:tensor([0.6911, 0.0035, 0.0047, 0.0193, 0.2815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,293 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,293 - train - INFO - True
2024-04-07 10:21:13,294 - train - INFO - alphas:tensor([0.2719, 0.0082, 0.0085, 0.0679, 0.6434], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,296 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,297 - train - INFO - True
2024-04-07 10:21:13,298 - train - INFO - alphas:tensor([0.2863, 0.0039, 0.0054, 0.0608, 0.6436], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,300 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,300 - train - INFO - True
2024-04-07 10:21:13,301 - train - INFO - alphas:tensor([0.3069, 0.0029, 0.0054, 0.0537, 0.6311], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,304 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,304 - train - INFO - True
2024-04-07 10:21:13,305 - train - INFO - alphas:tensor([0.2804, 0.0047, 0.0066, 0.0524, 0.6558], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,307 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,308 - train - INFO - True
2024-04-07 10:21:13,309 - train - INFO - alphas:tensor([0.3057, 0.0032, 0.0079, 0.0543, 0.6289], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,311 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,311 - train - INFO - True
2024-04-07 10:21:13,312 - train - INFO - alphas:tensor([0.2692, 0.0085, 0.0113, 0.0608, 0.6501], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,315 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,315 - train - INFO - True
2024-04-07 10:21:13,316 - train - INFO - alphas:tensor([0.6273, 0.0019, 0.0040, 0.0320, 0.3348], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,320 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,320 - train - INFO - True
2024-04-07 10:21:13,321 - train - INFO - alphas:tensor([0.5587, 0.0017, 0.0025, 0.0319, 0.4052], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,329 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,329 - train - INFO - True
2024-04-07 10:21:13,330 - train - INFO - alphas:tensor([0.4325, 0.0014, 0.0054, 0.0467, 0.5140], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,335 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,335 - train - INFO - True
2024-04-07 10:21:13,336 - train - INFO - alphas:tensor([0.4466, 0.0015, 0.0026, 0.0429, 0.5063], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,340 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,340 - train - INFO - True
2024-04-07 10:21:13,341 - train - INFO - alphas:tensor([0.4582, 0.0013, 0.0027, 0.0407, 0.4972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,345 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,345 - train - INFO - True
2024-04-07 10:21:13,346 - train - INFO - alphas:tensor([0.4247, 0.0016, 0.0043, 0.0446, 0.5249], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,350 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,350 - train - INFO - True
2024-04-07 10:21:13,351 - train - INFO - alphas:tensor([0.5677, 0.0013, 0.0035, 0.0270, 0.4004], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,358 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,358 - train - INFO - True
2024-04-07 10:21:13,359 - train - INFO - alphas:tensor([0.7410, 0.0010, 0.0026, 0.0188, 0.2367], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,379 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,379 - train - INFO - True
2024-04-07 10:21:13,380 - train - INFO - alphas:tensor([0.3915, 0.0019, 0.0041, 0.0562, 0.5463], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,390 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,390 - train - INFO - True
2024-04-07 10:21:13,391 - train - INFO - alphas:tensor([0.4035, 0.0011, 0.0032, 0.0447, 0.5476], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,401 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,401 - train - INFO - True
2024-04-07 10:21:13,402 - train - INFO - alphas:tensor([0.4323, 0.0013, 0.0024, 0.0471, 0.5170], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,412 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,412 - train - INFO - True
2024-04-07 10:21:13,413 - train - INFO - alphas:tensor([0.3950, 0.0015, 0.0037, 0.0482, 0.5516], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,423 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,423 - train - INFO - True
2024-04-07 10:21:13,424 - train - INFO - alphas:tensor([0.7231, 0.0008, 0.0015, 0.0153, 0.2592], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,443 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,443 - train - INFO - True
2024-04-07 10:21:13,444 - train - INFO - alphas:tensor([0.5643, 0.0061, 0.0100, 0.0537, 0.3660], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:21:13,522 - train - INFO - tau:0.3244455298634257
2024-04-07 10:21:13,522 - train - INFO - avg block size:10.06060606060606
2024-04-07 10:21:13,522 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 10:21:13,522 - train - INFO - lasso_alpha:2.70261141862079e-06
2024-04-07 10:21:13,732 - train - INFO - Test: [   0/78]  Time: 0.206 (0.206)  Loss:  0.9497 (0.9497)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 10:21:16,773 - train - INFO - Test: [  50/78]  Time: 0.074 (0.064)  Loss:  1.5869 (1.5504)  Acc@1: 64.8438 (65.9467)  Acc@5: 86.7188 (86.6881)
2024-04-07 10:21:18,724 - train - INFO - Test: [  78/78]  Time: 0.071 (0.066)  Loss:  1.8760 (1.5738)  Acc@1: 62.5000 (65.5300)  Acc@5: 87.5000 (86.1700)
2024-04-07 10:21:19,513 - train - INFO - Train: 115 [   0/781 (  0%)]  Loss:  3.714279 (3.7143)  Time: 0.684s,  187.07/s  (0.684s,  187.07/s)  LR: 7.293e-05  Data: 0.184 (0.184)
2024-04-07 10:21:43,255 - train - INFO - Train: 115 [  50/781 (  6%)]  Loss:  3.722570 (3.5318)  Time: 0.476s,  269.14/s  (0.479s,  267.26/s)  LR: 7.293e-05  Data: 0.008 (0.011)
2024-04-07 10:22:07,036 - train - INFO - Train: 115 [ 100/781 ( 13%)]  Loss:  3.703361 (3.5185)  Time: 0.485s,  263.68/s  (0.477s,  268.19/s)  LR: 7.293e-05  Data: 0.007 (0.009)
2024-04-07 10:22:29,603 - train - INFO - Train: 115 [ 150/781 ( 19%)]  Loss:  3.782431 (3.5254)  Time: 0.391s,  327.49/s  (0.469s,  273.11/s)  LR: 7.293e-05  Data: 0.005 (0.008)
2024-04-07 10:22:52,340 - train - INFO - Train: 115 [ 200/781 ( 26%)]  Loss:  3.721427 (3.5211)  Time: 0.461s,  277.53/s  (0.465s,  275.15/s)  LR: 7.293e-05  Data: 0.006 (0.008)
2024-04-07 10:23:14,934 - train - INFO - Train: 115 [ 250/781 ( 32%)]  Loss:  3.544054 (3.5144)  Time: 0.364s,  351.51/s  (0.463s,  276.73/s)  LR: 7.293e-05  Data: 0.004 (0.008)
2024-04-07 10:23:37,899 - train - INFO - Train: 115 [ 300/781 ( 38%)]  Loss:  3.724514 (3.5073)  Time: 0.443s,  289.13/s  (0.462s,  277.06/s)  LR: 7.293e-05  Data: 0.008 (0.008)
2024-04-07 10:24:01,438 - train - INFO - Train: 115 [ 350/781 ( 45%)]  Loss:  3.748014 (3.5100)  Time: 0.490s,  261.44/s  (0.463s,  276.31/s)  LR: 7.293e-05  Data: 0.006 (0.008)
2024-04-07 10:24:24,797 - train - INFO - Train: 115 [ 400/781 ( 51%)]  Loss:  3.742111 (3.5106)  Time: 0.450s,  284.64/s  (0.464s,  276.02/s)  LR: 7.293e-05  Data: 0.006 (0.008)
2024-04-07 10:24:48,802 - train - INFO - Train: 115 [ 450/781 ( 58%)]  Loss:  3.195436 (3.5158)  Time: 0.464s,  276.03/s  (0.466s,  274.95/s)  LR: 7.293e-05  Data: 0.009 (0.008)
2024-04-07 10:25:12,916 - train - INFO - Train: 115 [ 500/781 ( 64%)]  Loss:  4.026898 (3.5132)  Time: 0.454s,  281.84/s  (0.467s,  273.97/s)  LR: 7.293e-05  Data: 0.007 (0.008)
2024-04-07 10:25:36,766 - train - INFO - Train: 115 [ 550/781 ( 71%)]  Loss:  3.155101 (3.5104)  Time: 0.502s,  254.89/s  (0.468s,  273.45/s)  LR: 7.293e-05  Data: 0.008 (0.008)
2024-04-07 10:25:59,077 - train - INFO - Train: 115 [ 600/781 ( 77%)]  Loss:  3.770303 (3.5099)  Time: 0.380s,  336.65/s  (0.466s,  274.52/s)  LR: 7.293e-05  Data: 0.005 (0.008)
2024-04-07 10:26:22,133 - train - INFO - Train: 115 [ 650/781 ( 83%)]  Loss:  3.098968 (3.5064)  Time: 0.508s,  252.20/s  (0.466s,  274.75/s)  LR: 7.293e-05  Data: 0.009 (0.008)
2024-04-07 10:26:45,402 - train - INFO - Train: 115 [ 700/781 ( 90%)]  Loss:  3.166642 (3.5056)  Time: 0.508s,  252.02/s  (0.466s,  274.77/s)  LR: 7.293e-05  Data: 0.008 (0.008)
2024-04-07 10:27:09,143 - train - INFO - Train: 115 [ 750/781 ( 96%)]  Loss:  3.285875 (3.5069)  Time: 0.459s,  278.75/s  (0.466s,  274.42/s)  LR: 7.293e-05  Data: 0.005 (0.008)
2024-04-07 10:27:22,117 - train - INFO - Train: 115 [ 780/781 (100%)]  Loss:  3.838074 (3.5041)  Time: 0.460s,  278.45/s  (0.465s,  275.19/s)  LR: 7.293e-05  Data: 0.000 (0.008)
2024-04-07 10:27:22,118 - train - INFO - True
2024-04-07 10:27:22,119 - train - INFO - alphas:tensor([0.7189, 0.0213, 0.0374, 0.0568, 0.1658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,120 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,120 - train - INFO - True
2024-04-07 10:27:22,121 - train - INFO - alphas:tensor([0.4562, 0.0069, 0.0163, 0.0509, 0.4697], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,121 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,122 - train - INFO - True
2024-04-07 10:27:22,123 - train - INFO - alphas:tensor([0.5003, 0.0135, 0.0461, 0.4402], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,123 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,124 - train - INFO - True
2024-04-07 10:27:22,125 - train - INFO - alphas:tensor([0.4376, 0.0138, 0.0321, 0.5164], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,125 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,125 - train - INFO - True
2024-04-07 10:27:22,126 - train - INFO - alphas:tensor([0.4418, 0.0084, 0.0396, 0.5102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,127 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,127 - train - INFO - True
2024-04-07 10:27:22,128 - train - INFO - alphas:tensor([0.5354, 0.0139, 0.0324, 0.4183], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,129 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,129 - train - INFO - True
2024-04-07 10:27:22,130 - train - INFO - alphas:tensor([0.5850, 0.0069, 0.0103, 0.0335, 0.3644], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,131 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,131 - train - INFO - True
2024-04-07 10:27:22,132 - train - INFO - alphas:tensor([0.2414, 0.0037, 0.0029, 0.0343, 0.7178], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,133 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,133 - train - INFO - True
2024-04-07 10:27:22,134 - train - INFO - alphas:tensor([0.2492, 0.0024, 0.0034, 0.0256, 0.7194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,135 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,135 - train - INFO - True
2024-04-07 10:27:22,136 - train - INFO - alphas:tensor([0.2489, 0.0015, 0.0029, 0.0296, 0.7172], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,137 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,137 - train - INFO - True
2024-04-07 10:27:22,138 - train - INFO - alphas:tensor([0.2391, 0.0031, 0.0030, 0.0358, 0.7190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,138 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,139 - train - INFO - True
2024-04-07 10:27:22,140 - train - INFO - alphas:tensor([0.5815, 0.0025, 0.0058, 0.0290, 0.3812], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,141 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,141 - train - INFO - True
2024-04-07 10:27:22,142 - train - INFO - alphas:tensor([0.6928, 0.0033, 0.0045, 0.0187, 0.2807], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,145 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,145 - train - INFO - True
2024-04-07 10:27:22,146 - train - INFO - alphas:tensor([0.2711, 0.0079, 0.0082, 0.0670, 0.6458], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,148 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,148 - train - INFO - True
2024-04-07 10:27:22,149 - train - INFO - alphas:tensor([0.2898, 0.0037, 0.0052, 0.0600, 0.6412], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,151 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,151 - train - INFO - True
2024-04-07 10:27:22,152 - train - INFO - alphas:tensor([0.3085, 0.0028, 0.0052, 0.0527, 0.6309], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,154 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,154 - train - INFO - True
2024-04-07 10:27:22,155 - train - INFO - alphas:tensor([0.2810, 0.0045, 0.0064, 0.0516, 0.6565], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,157 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,157 - train - INFO - True
2024-04-07 10:27:22,158 - train - INFO - alphas:tensor([0.3092, 0.0030, 0.0077, 0.0535, 0.6266], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,160 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,160 - train - INFO - True
2024-04-07 10:27:22,161 - train - INFO - alphas:tensor([0.2682, 0.0082, 0.0110, 0.0597, 0.6530], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,163 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,163 - train - INFO - True
2024-04-07 10:27:22,164 - train - INFO - alphas:tensor([0.6287, 0.0018, 0.0039, 0.0314, 0.3342], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,167 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,167 - train - INFO - True
2024-04-07 10:27:22,168 - train - INFO - alphas:tensor([0.5610, 0.0016, 0.0024, 0.0312, 0.4038], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,175 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,175 - train - INFO - True
2024-04-07 10:27:22,176 - train - INFO - alphas:tensor([0.4315, 0.0014, 0.0052, 0.0461, 0.5158], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,179 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,179 - train - INFO - True
2024-04-07 10:27:22,180 - train - INFO - alphas:tensor([0.4480, 0.0014, 0.0025, 0.0423, 0.5058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,184 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,184 - train - INFO - True
2024-04-07 10:27:22,184 - train - INFO - alphas:tensor([0.4582, 0.0012, 0.0025, 0.0399, 0.4982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,188 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,188 - train - INFO - True
2024-04-07 10:27:22,189 - train - INFO - alphas:tensor([0.4269, 0.0015, 0.0041, 0.0440, 0.5236], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,192 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,192 - train - INFO - True
2024-04-07 10:27:22,193 - train - INFO - alphas:tensor([0.5691, 0.0013, 0.0034, 0.0265, 0.3996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,199 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,199 - train - INFO - True
2024-04-07 10:27:22,200 - train - INFO - alphas:tensor([0.7428, 0.0009, 0.0025, 0.0182, 0.2355], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,216 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,216 - train - INFO - True
2024-04-07 10:27:22,217 - train - INFO - alphas:tensor([0.3933, 0.0018, 0.0040, 0.0554, 0.5456], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,224 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,224 - train - INFO - True
2024-04-07 10:27:22,225 - train - INFO - alphas:tensor([0.4057, 0.0010, 0.0031, 0.0440, 0.5462], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,233 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,233 - train - INFO - True
2024-04-07 10:27:22,234 - train - INFO - alphas:tensor([0.4332, 0.0012, 0.0023, 0.0466, 0.5166], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,241 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,241 - train - INFO - True
2024-04-07 10:27:22,242 - train - INFO - alphas:tensor([0.3977, 0.0015, 0.0035, 0.0475, 0.5498], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,249 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,249 - train - INFO - True
2024-04-07 10:27:22,250 - train - INFO - alphas:tensor([0.7241, 0.0008, 0.0014, 0.0149, 0.2588], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,263 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,263 - train - INFO - True
2024-04-07 10:27:22,264 - train - INFO - alphas:tensor([0.5686, 0.0059, 0.0097, 0.0528, 0.3630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:27:22,313 - train - INFO - tau:0.3212010745647914
2024-04-07 10:27:22,313 - train - INFO - avg block size:10.06060606060606
2024-04-07 10:27:22,313 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 10:27:22,526 - train - INFO - Test: [   0/78]  Time: 0.210 (0.210)  Loss:  1.0059 (1.0059)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 10:27:25,383 - train - INFO - Test: [  50/78]  Time: 0.050 (0.060)  Loss:  1.5059 (1.5516)  Acc@1: 65.6250 (66.0999)  Acc@5: 88.2812 (86.5962)
2024-04-07 10:27:27,110 - train - INFO - Test: [  78/78]  Time: 0.054 (0.061)  Loss:  1.9385 (1.5743)  Acc@1: 50.0000 (65.6300)  Acc@5: 87.5000 (85.9600)
2024-04-07 10:27:27,807 - train - INFO - Train: 116 [   0/781 (  0%)]  Loss:  3.248465 (3.2485)  Time: 0.621s,  206.26/s  (0.621s,  206.26/s)  LR: 6.954e-05  Data: 0.170 (0.170)
2024-04-07 10:27:51,995 - train - INFO - Train: 116 [  50/781 (  6%)]  Loss:  3.680452 (3.4900)  Time: 0.479s,  267.13/s  (0.486s,  263.16/s)  LR: 6.954e-05  Data: 0.009 (0.011)
2024-04-07 10:28:14,998 - train - INFO - Train: 116 [ 100/781 ( 13%)]  Loss:  3.462825 (3.4897)  Time: 0.464s,  275.72/s  (0.473s,  270.42/s)  LR: 6.954e-05  Data: 0.005 (0.009)
2024-04-07 10:28:38,128 - train - INFO - Train: 116 [ 150/781 ( 19%)]  Loss:  3.316620 (3.4781)  Time: 0.491s,  260.62/s  (0.470s,  272.47/s)  LR: 6.954e-05  Data: 0.007 (0.009)
2024-04-07 10:29:01,158 - train - INFO - Train: 116 [ 200/781 ( 26%)]  Loss:  3.554248 (3.4795)  Time: 0.470s,  272.13/s  (0.467s,  273.80/s)  LR: 6.954e-05  Data: 0.014 (0.008)
2024-04-07 10:29:24,675 - train - INFO - Train: 116 [ 250/781 ( 32%)]  Loss:  3.708516 (3.4892)  Time: 0.452s,  283.45/s  (0.468s,  273.48/s)  LR: 6.954e-05  Data: 0.006 (0.008)
2024-04-07 10:29:47,927 - train - INFO - Train: 116 [ 300/781 ( 38%)]  Loss:  3.412280 (3.4839)  Time: 0.505s,  253.40/s  (0.468s,  273.77/s)  LR: 6.954e-05  Data: 0.009 (0.008)
2024-04-07 10:30:11,205 - train - INFO - Train: 116 [ 350/781 ( 45%)]  Loss:  3.589407 (3.4848)  Time: 0.486s,  263.48/s  (0.467s,  273.94/s)  LR: 6.954e-05  Data: 0.010 (0.008)
2024-04-07 10:30:35,208 - train - INFO - Train: 116 [ 400/781 ( 51%)]  Loss:  3.196096 (3.4853)  Time: 0.477s,  268.32/s  (0.469s,  273.01/s)  LR: 6.954e-05  Data: 0.007 (0.008)
2024-04-07 10:30:58,489 - train - INFO - Train: 116 [ 450/781 ( 58%)]  Loss:  3.673996 (3.4900)  Time: 0.499s,  256.40/s  (0.468s,  273.22/s)  LR: 6.954e-05  Data: 0.008 (0.008)
2024-04-07 10:31:21,828 - train - INFO - Train: 116 [ 500/781 ( 64%)]  Loss:  3.175523 (3.4877)  Time: 0.467s,  274.31/s  (0.468s,  273.32/s)  LR: 6.954e-05  Data: 0.006 (0.008)
2024-04-07 10:31:45,089 - train - INFO - Train: 116 [ 550/781 ( 71%)]  Loss:  3.366744 (3.4870)  Time: 0.491s,  260.71/s  (0.468s,  273.49/s)  LR: 6.954e-05  Data: 0.008 (0.008)
2024-04-07 10:32:08,023 - train - INFO - Train: 116 [ 600/781 ( 77%)]  Loss:  3.844931 (3.4895)  Time: 0.471s,  271.55/s  (0.467s,  273.94/s)  LR: 6.954e-05  Data: 0.009 (0.008)
2024-04-07 10:32:31,747 - train - INFO - Train: 116 [ 650/781 ( 83%)]  Loss:  3.333982 (3.4900)  Time: 0.484s,  264.41/s  (0.468s,  273.62/s)  LR: 6.954e-05  Data: 0.007 (0.008)
2024-04-07 10:32:55,051 - train - INFO - Train: 116 [ 700/781 ( 90%)]  Loss:  3.642925 (3.4882)  Time: 0.468s,  273.33/s  (0.468s,  273.69/s)  LR: 6.954e-05  Data: 0.007 (0.008)
2024-04-07 10:33:18,780 - train - INFO - Train: 116 [ 750/781 ( 96%)]  Loss:  3.679727 (3.4877)  Time: 0.473s,  270.48/s  (0.468s,  273.43/s)  LR: 6.954e-05  Data: 0.009 (0.008)
2024-04-07 10:33:33,125 - train - INFO - Train: 116 [ 780/781 (100%)]  Loss:  3.569237 (3.4881)  Time: 0.511s,  250.61/s  (0.469s,  273.20/s)  LR: 6.954e-05  Data: 0.000 (0.008)
2024-04-07 10:33:33,126 - train - INFO - True
2024-04-07 10:33:33,128 - train - INFO - alphas:tensor([0.7220, 0.0207, 0.0367, 0.0559, 0.1647], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,129 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,129 - train - INFO - True
2024-04-07 10:33:33,130 - train - INFO - alphas:tensor([0.4577, 0.0067, 0.0158, 0.0501, 0.4697], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,131 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,131 - train - INFO - True
2024-04-07 10:33:33,132 - train - INFO - alphas:tensor([0.5016, 0.0130, 0.0454, 0.4400], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,133 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,133 - train - INFO - True
2024-04-07 10:33:33,134 - train - INFO - alphas:tensor([0.4389, 0.0134, 0.0315, 0.5163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,135 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,135 - train - INFO - True
2024-04-07 10:33:33,136 - train - INFO - alphas:tensor([0.4433, 0.0081, 0.0388, 0.5098], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,137 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,137 - train - INFO - True
2024-04-07 10:33:33,138 - train - INFO - alphas:tensor([0.5344, 0.0136, 0.0317, 0.4203], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,139 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,139 - train - INFO - True
2024-04-07 10:33:33,140 - train - INFO - alphas:tensor([0.5862, 0.0066, 0.0099, 0.0327, 0.3646], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,142 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,142 - train - INFO - True
2024-04-07 10:33:33,143 - train - INFO - alphas:tensor([0.2415, 0.0035, 0.0027, 0.0336, 0.7187], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,144 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,144 - train - INFO - True
2024-04-07 10:33:33,145 - train - INFO - alphas:tensor([0.2494, 0.0023, 0.0032, 0.0249, 0.7202], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,146 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,146 - train - INFO - True
2024-04-07 10:33:33,147 - train - INFO - alphas:tensor([0.2498, 0.0015, 0.0028, 0.0290, 0.7169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,148 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,148 - train - INFO - True
2024-04-07 10:33:33,149 - train - INFO - alphas:tensor([0.2382, 0.0029, 0.0029, 0.0351, 0.7208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,150 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,150 - train - INFO - True
2024-04-07 10:33:33,151 - train - INFO - alphas:tensor([0.5815, 0.0023, 0.0056, 0.0284, 0.3822], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,152 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,153 - train - INFO - True
2024-04-07 10:33:33,154 - train - INFO - alphas:tensor([0.6945, 0.0031, 0.0043, 0.0182, 0.2798], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,158 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,158 - train - INFO - True
2024-04-07 10:33:33,159 - train - INFO - alphas:tensor([0.2743, 0.0077, 0.0080, 0.0666, 0.6434], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,161 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,161 - train - INFO - True
2024-04-07 10:33:33,162 - train - INFO - alphas:tensor([0.2896, 0.0036, 0.0050, 0.0589, 0.6430], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,165 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,165 - train - INFO - True
2024-04-07 10:33:33,166 - train - INFO - alphas:tensor([0.3061, 0.0026, 0.0050, 0.0517, 0.6345], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,175 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,181 - train - INFO - True
2024-04-07 10:33:33,182 - train - INFO - alphas:tensor([0.2809, 0.0043, 0.0062, 0.0506, 0.6580], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,184 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,185 - train - INFO - True
2024-04-07 10:33:33,185 - train - INFO - alphas:tensor([0.3074, 0.0029, 0.0073, 0.0525, 0.6299], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,187 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,187 - train - INFO - True
2024-04-07 10:33:33,188 - train - INFO - alphas:tensor([0.2696, 0.0079, 0.0106, 0.0588, 0.6531], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,190 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,190 - train - INFO - True
2024-04-07 10:33:33,191 - train - INFO - alphas:tensor([0.6299, 0.0017, 0.0037, 0.0308, 0.3339], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,195 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,195 - train - INFO - True
2024-04-07 10:33:33,196 - train - INFO - alphas:tensor([0.5616, 0.0016, 0.0023, 0.0305, 0.4041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,203 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,203 - train - INFO - True
2024-04-07 10:33:33,204 - train - INFO - alphas:tensor([0.4344, 0.0013, 0.0050, 0.0453, 0.5141], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,208 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,208 - train - INFO - True
2024-04-07 10:33:33,209 - train - INFO - alphas:tensor([0.4484, 0.0014, 0.0024, 0.0415, 0.5064], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,213 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,213 - train - INFO - True
2024-04-07 10:33:33,214 - train - INFO - alphas:tensor([0.4595, 0.0012, 0.0024, 0.0391, 0.4977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,218 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,218 - train - INFO - True
2024-04-07 10:33:33,219 - train - INFO - alphas:tensor([0.4279, 0.0014, 0.0039, 0.0431, 0.5238], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,222 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,223 - train - INFO - True
2024-04-07 10:33:33,224 - train - INFO - alphas:tensor([0.5718, 0.0012, 0.0033, 0.0259, 0.3979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,231 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,231 - train - INFO - True
2024-04-07 10:33:33,232 - train - INFO - alphas:tensor([0.7442, 0.0009, 0.0024, 0.0177, 0.2348], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,251 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,251 - train - INFO - True
2024-04-07 10:33:33,252 - train - INFO - alphas:tensor([0.3960, 0.0017, 0.0038, 0.0546, 0.5439], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,262 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,263 - train - INFO - True
2024-04-07 10:33:33,263 - train - INFO - alphas:tensor([0.4010, 0.0009, 0.0029, 0.0428, 0.5523], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,273 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,274 - train - INFO - True
2024-04-07 10:33:33,274 - train - INFO - alphas:tensor([0.4344, 0.0011, 0.0022, 0.0461, 0.5162], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,285 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,285 - train - INFO - True
2024-04-07 10:33:33,286 - train - INFO - alphas:tensor([0.3957, 0.0014, 0.0034, 0.0467, 0.5529], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,296 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,296 - train - INFO - True
2024-04-07 10:33:33,297 - train - INFO - alphas:tensor([0.7242, 0.0007, 0.0013, 0.0146, 0.2591], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,316 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,316 - train - INFO - True
2024-04-07 10:33:33,317 - train - INFO - alphas:tensor([0.5702, 0.0057, 0.0094, 0.0519, 0.3629], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:33:33,395 - train - INFO - tau:0.3179890638191435
2024-04-07 10:33:33,395 - train - INFO - avg block size:10.06060606060606
2024-04-07 10:33:33,395 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 10:33:33,396 - train - INFO - lasso_alpha:2.456919471473445e-06
2024-04-07 10:33:33,610 - train - INFO - Test: [   0/78]  Time: 0.211 (0.211)  Loss:  0.9800 (0.9800)  Acc@1: 82.0312 (82.0312)  Acc@5: 92.1875 (92.1875)
2024-04-07 10:33:36,583 - train - INFO - Test: [  50/78]  Time: 0.054 (0.062)  Loss:  1.6162 (1.5519)  Acc@1: 63.2812 (65.9161)  Acc@5: 85.1562 (86.2898)
2024-04-07 10:33:38,529 - train - INFO - Test: [  78/78]  Time: 0.071 (0.065)  Loss:  1.8193 (1.5671)  Acc@1: 62.5000 (65.6700)  Acc@5: 87.5000 (85.9100)
2024-04-07 10:33:39,280 - train - INFO - Train: 117 [   0/781 (  0%)]  Loss:  3.348029 (3.3480)  Time: 0.635s,  201.58/s  (0.635s,  201.58/s)  LR: 6.622e-05  Data: 0.180 (0.180)
2024-04-07 10:34:02,113 - train - INFO - Train: 117 [  50/781 (  6%)]  Loss:  3.144973 (3.4707)  Time: 0.457s,  279.80/s  (0.460s,  278.18/s)  LR: 6.622e-05  Data: 0.008 (0.011)
2024-04-07 10:34:25,118 - train - INFO - Train: 117 [ 100/781 ( 13%)]  Loss:  3.201131 (3.5029)  Time: 0.493s,  259.55/s  (0.460s,  278.20/s)  LR: 6.622e-05  Data: 0.013 (0.009)
2024-04-07 10:34:48,319 - train - INFO - Train: 117 [ 150/781 ( 19%)]  Loss:  3.245108 (3.5032)  Time: 0.500s,  255.83/s  (0.461s,  277.42/s)  LR: 6.622e-05  Data: 0.009 (0.009)
2024-04-07 10:35:11,672 - train - INFO - Train: 117 [ 200/781 ( 26%)]  Loss:  3.728973 (3.5041)  Time: 0.440s,  290.87/s  (0.463s,  276.58/s)  LR: 6.622e-05  Data: 0.005 (0.008)
2024-04-07 10:35:34,120 - train - INFO - Train: 117 [ 250/781 ( 32%)]  Loss:  3.589082 (3.4976)  Time: 0.444s,  288.06/s  (0.460s,  278.24/s)  LR: 6.622e-05  Data: 0.007 (0.008)
2024-04-07 10:35:57,856 - train - INFO - Train: 117 [ 300/781 ( 38%)]  Loss:  3.577354 (3.4961)  Time: 0.509s,  251.36/s  (0.462s,  276.78/s)  LR: 6.622e-05  Data: 0.011 (0.008)
2024-04-07 10:36:21,010 - train - INFO - Train: 117 [ 350/781 ( 45%)]  Loss:  3.333324 (3.4945)  Time: 0.478s,  267.86/s  (0.463s,  276.73/s)  LR: 6.622e-05  Data: 0.007 (0.008)
2024-04-07 10:36:45,109 - train - INFO - Train: 117 [ 400/781 ( 51%)]  Loss:  3.626866 (3.4977)  Time: 0.507s,  252.48/s  (0.465s,  275.29/s)  LR: 6.622e-05  Data: 0.007 (0.008)
2024-04-07 10:37:07,240 - train - INFO - Train: 117 [ 450/781 ( 58%)]  Loss:  3.188890 (3.5033)  Time: 0.486s,  263.57/s  (0.462s,  276.76/s)  LR: 6.622e-05  Data: 0.009 (0.008)
2024-04-07 10:37:29,705 - train - INFO - Train: 117 [ 500/781 ( 64%)]  Loss:  3.635756 (3.5041)  Time: 0.483s,  264.77/s  (0.461s,  277.56/s)  LR: 6.622e-05  Data: 0.006 (0.008)
2024-04-07 10:37:52,686 - train - INFO - Train: 117 [ 550/781 ( 71%)]  Loss:  3.016521 (3.5011)  Time: 0.370s,  345.57/s  (0.461s,  277.64/s)  LR: 6.622e-05  Data: 0.004 (0.008)
2024-04-07 10:38:16,806 - train - INFO - Train: 117 [ 600/781 ( 77%)]  Loss:  3.314089 (3.4988)  Time: 0.474s,  269.89/s  (0.463s,  276.58/s)  LR: 6.622e-05  Data: 0.015 (0.008)
2024-04-07 10:38:40,381 - train - INFO - Train: 117 [ 650/781 ( 83%)]  Loss:  3.441061 (3.4990)  Time: 0.445s,  287.59/s  (0.463s,  276.18/s)  LR: 6.622e-05  Data: 0.007 (0.008)
2024-04-07 10:39:04,165 - train - INFO - Train: 117 [ 700/781 ( 90%)]  Loss:  3.621606 (3.4961)  Time: 0.544s,  235.22/s  (0.464s,  275.66/s)  LR: 6.622e-05  Data: 0.012 (0.008)
2024-04-07 10:39:28,097 - train - INFO - Train: 117 [ 750/781 ( 96%)]  Loss:  3.245712 (3.4939)  Time: 0.484s,  264.65/s  (0.465s,  275.10/s)  LR: 6.622e-05  Data: 0.007 (0.008)
2024-04-07 10:39:42,355 - train - INFO - Train: 117 [ 780/781 (100%)]  Loss:  3.396715 (3.4913)  Time: 0.473s,  270.64/s  (0.466s,  274.87/s)  LR: 6.622e-05  Data: 0.000 (0.008)
2024-04-07 10:39:42,357 - train - INFO - True
2024-04-07 10:39:42,359 - train - INFO - alphas:tensor([0.7250, 0.0201, 0.0359, 0.0550, 0.1639], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,360 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,360 - train - INFO - True
2024-04-07 10:39:42,362 - train - INFO - alphas:tensor([0.4573, 0.0064, 0.0155, 0.0494, 0.4715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,362 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,363 - train - INFO - True
2024-04-07 10:39:42,364 - train - INFO - alphas:tensor([0.5024, 0.0126, 0.0444, 0.4407], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,365 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,366 - train - INFO - True
2024-04-07 10:39:42,367 - train - INFO - alphas:tensor([0.4384, 0.0130, 0.0309, 0.5176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,368 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,368 - train - INFO - True
2024-04-07 10:39:42,370 - train - INFO - alphas:tensor([0.4434, 0.0078, 0.0380, 0.5108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,371 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,371 - train - INFO - True
2024-04-07 10:39:42,372 - train - INFO - alphas:tensor([0.5365, 0.0131, 0.0310, 0.4193], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,373 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,373 - train - INFO - True
2024-04-07 10:39:42,375 - train - INFO - alphas:tensor([0.5870, 0.0064, 0.0096, 0.0320, 0.3651], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,377 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,377 - train - INFO - True
2024-04-07 10:39:42,378 - train - INFO - alphas:tensor([0.2406, 0.0034, 0.0026, 0.0330, 0.7204], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,379 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,380 - train - INFO - True
2024-04-07 10:39:42,381 - train - INFO - alphas:tensor([0.2488, 0.0022, 0.0031, 0.0242, 0.7218], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,382 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,382 - train - INFO - True
2024-04-07 10:39:42,384 - train - INFO - alphas:tensor([0.2502, 0.0014, 0.0026, 0.0285, 0.7172], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,385 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,385 - train - INFO - True
2024-04-07 10:39:42,386 - train - INFO - alphas:tensor([0.2368, 0.0028, 0.0028, 0.0344, 0.7232], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,387 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,387 - train - INFO - True
2024-04-07 10:39:42,389 - train - INFO - alphas:tensor([0.5826, 0.0022, 0.0054, 0.0277, 0.3822], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,390 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,391 - train - INFO - True
2024-04-07 10:39:42,392 - train - INFO - alphas:tensor([0.6977, 0.0030, 0.0041, 0.0177, 0.2775], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,397 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,397 - train - INFO - True
2024-04-07 10:39:42,398 - train - INFO - alphas:tensor([0.2768, 0.0075, 0.0077, 0.0655, 0.6424], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,401 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,401 - train - INFO - True
2024-04-07 10:39:42,402 - train - INFO - alphas:tensor([0.2887, 0.0034, 0.0048, 0.0581, 0.6450], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,405 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,405 - train - INFO - True
2024-04-07 10:39:42,406 - train - INFO - alphas:tensor([0.3054, 0.0025, 0.0048, 0.0508, 0.6364], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,409 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,409 - train - INFO - True
2024-04-07 10:39:42,410 - train - INFO - alphas:tensor([0.2827, 0.0042, 0.0059, 0.0498, 0.6574], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,413 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,413 - train - INFO - True
2024-04-07 10:39:42,414 - train - INFO - alphas:tensor([0.3087, 0.0028, 0.0071, 0.0519, 0.6295], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,416 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,417 - train - INFO - True
2024-04-07 10:39:42,418 - train - INFO - alphas:tensor([0.2702, 0.0076, 0.0102, 0.0578, 0.6541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,420 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,420 - train - INFO - True
2024-04-07 10:39:42,421 - train - INFO - alphas:tensor([0.6304, 0.0016, 0.0036, 0.0302, 0.3342], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,426 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,426 - train - INFO - True
2024-04-07 10:39:42,427 - train - INFO - alphas:tensor([0.5638, 0.0015, 0.0022, 0.0297, 0.4029], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,436 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,436 - train - INFO - True
2024-04-07 10:39:42,437 - train - INFO - alphas:tensor([0.4359, 0.0012, 0.0048, 0.0446, 0.5135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,441 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,441 - train - INFO - True
2024-04-07 10:39:42,442 - train - INFO - alphas:tensor([0.4481, 0.0013, 0.0023, 0.0407, 0.5076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,447 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,447 - train - INFO - True
2024-04-07 10:39:42,448 - train - INFO - alphas:tensor([0.4635, 0.0011, 0.0023, 0.0383, 0.4947], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,452 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,452 - train - INFO - True
2024-04-07 10:39:42,453 - train - INFO - alphas:tensor([0.4291, 0.0013, 0.0037, 0.0422, 0.5236], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,457 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,457 - train - INFO - True
2024-04-07 10:39:42,458 - train - INFO - alphas:tensor([0.5742, 0.0011, 0.0031, 0.0253, 0.3963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,466 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,466 - train - INFO - True
2024-04-07 10:39:42,467 - train - INFO - alphas:tensor([0.7467, 0.0008, 0.0023, 0.0173, 0.2329], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,486 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,487 - train - INFO - True
2024-04-07 10:39:42,487 - train - INFO - alphas:tensor([0.3951, 0.0017, 0.0036, 0.0543, 0.5453], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,498 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,498 - train - INFO - True
2024-04-07 10:39:42,499 - train - INFO - alphas:tensor([0.4034, 0.0009, 0.0028, 0.0422, 0.5508], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,509 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,509 - train - INFO - True
2024-04-07 10:39:42,510 - train - INFO - alphas:tensor([0.4364, 0.0011, 0.0021, 0.0451, 0.5154], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,520 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,520 - train - INFO - True
2024-04-07 10:39:42,521 - train - INFO - alphas:tensor([0.3969, 0.0013, 0.0032, 0.0458, 0.5527], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,531 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,531 - train - INFO - True
2024-04-07 10:39:42,532 - train - INFO - alphas:tensor([7.2644e-01, 6.9756e-04, 1.2755e-03, 1.4195e-02, 2.5739e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,551 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,551 - train - INFO - True
2024-04-07 10:39:42,552 - train - INFO - alphas:tensor([0.5717, 0.0055, 0.0091, 0.0512, 0.3625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:39:42,629 - train - INFO - tau:0.31480917318095203
2024-04-07 10:39:42,629 - train - INFO - avg block size:10.06060606060606
2024-04-07 10:39:42,630 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 10:39:42,845 - train - INFO - Test: [   0/78]  Time: 0.211 (0.211)  Loss:  0.9604 (0.9604)  Acc@1: 83.5938 (83.5938)  Acc@5: 92.9688 (92.9688)
2024-04-07 10:39:45,900 - train - INFO - Test: [  50/78]  Time: 0.054 (0.064)  Loss:  1.5410 (1.5421)  Acc@1: 64.0625 (66.3450)  Acc@5: 88.2812 (86.4583)
2024-04-07 10:39:47,600 - train - INFO - Test: [  78/78]  Time: 0.071 (0.063)  Loss:  1.8105 (1.5647)  Acc@1: 50.0000 (65.7700)  Acc@5: 87.5000 (86.0000)
2024-04-07 10:39:48,380 - train - INFO - Train: 118 [   0/781 (  0%)]  Loss:  3.881994 (3.8820)  Time: 0.669s,  191.24/s  (0.669s,  191.24/s)  LR: 6.300e-05  Data: 0.196 (0.196)
2024-04-07 10:40:11,580 - train - INFO - Train: 118 [  50/781 (  6%)]  Loss:  3.667662 (3.5202)  Time: 0.462s,  277.28/s  (0.468s,  273.51/s)  LR: 6.300e-05  Data: 0.005 (0.012)
2024-04-07 10:40:34,925 - train - INFO - Train: 118 [ 100/781 ( 13%)]  Loss:  3.149757 (3.5070)  Time: 0.485s,  263.72/s  (0.467s,  273.83/s)  LR: 6.300e-05  Data: 0.008 (0.010)
2024-04-07 10:40:57,069 - train - INFO - Train: 118 [ 150/781 ( 19%)]  Loss:  3.636762 (3.5058)  Time: 0.510s,  251.16/s  (0.459s,  278.69/s)  LR: 6.300e-05  Data: 0.006 (0.009)
2024-04-07 10:41:19,797 - train - INFO - Train: 118 [ 200/781 ( 26%)]  Loss:  3.214059 (3.5075)  Time: 0.491s,  260.67/s  (0.458s,  279.41/s)  LR: 6.300e-05  Data: 0.008 (0.008)
2024-04-07 10:41:43,098 - train - INFO - Train: 118 [ 250/781 ( 32%)]  Loss:  3.574114 (3.5010)  Time: 0.469s,  273.19/s  (0.460s,  278.45/s)  LR: 6.300e-05  Data: 0.007 (0.008)
2024-04-07 10:42:06,136 - train - INFO - Train: 118 [ 300/781 ( 38%)]  Loss:  3.751375 (3.4997)  Time: 0.474s,  269.83/s  (0.460s,  278.35/s)  LR: 6.300e-05  Data: 0.007 (0.008)
2024-04-07 10:42:29,566 - train - INFO - Train: 118 [ 350/781 ( 45%)]  Loss:  3.281139 (3.4971)  Time: 0.446s,  287.20/s  (0.461s,  277.60/s)  LR: 6.300e-05  Data: 0.005 (0.008)
2024-04-07 10:42:53,463 - train - INFO - Train: 118 [ 400/781 ( 51%)]  Loss:  3.355735 (3.4979)  Time: 0.452s,  283.48/s  (0.463s,  276.34/s)  LR: 6.300e-05  Data: 0.006 (0.008)
2024-04-07 10:43:17,068 - train - INFO - Train: 118 [ 450/781 ( 58%)]  Loss:  3.384435 (3.4984)  Time: 0.484s,  264.33/s  (0.464s,  275.76/s)  LR: 6.300e-05  Data: 0.005 (0.008)
2024-04-07 10:43:40,204 - train - INFO - Train: 118 [ 500/781 ( 64%)]  Loss:  3.436295 (3.4968)  Time: 0.528s,  242.58/s  (0.464s,  275.85/s)  LR: 6.300e-05  Data: 0.012 (0.008)
2024-04-07 10:44:04,207 - train - INFO - Train: 118 [ 550/781 ( 71%)]  Loss:  3.743132 (3.4914)  Time: 0.502s,  255.23/s  (0.465s,  274.99/s)  LR: 6.300e-05  Data: 0.007 (0.008)
2024-04-07 10:44:27,600 - train - INFO - Train: 118 [ 600/781 ( 77%)]  Loss:  3.421985 (3.4930)  Time: 0.484s,  264.59/s  (0.466s,  274.87/s)  LR: 6.300e-05  Data: 0.006 (0.008)
2024-04-07 10:44:50,496 - train - INFO - Train: 118 [ 650/781 ( 83%)]  Loss:  3.591034 (3.4919)  Time: 0.495s,  258.50/s  (0.465s,  275.23/s)  LR: 6.300e-05  Data: 0.010 (0.008)
2024-04-07 10:45:13,403 - train - INFO - Train: 118 [ 700/781 ( 90%)]  Loss:  3.740467 (3.4946)  Time: 0.402s,  318.59/s  (0.465s,  275.52/s)  LR: 6.300e-05  Data: 0.005 (0.008)
2024-04-07 10:45:37,125 - train - INFO - Train: 118 [ 750/781 ( 96%)]  Loss:  3.556378 (3.4931)  Time: 0.502s,  255.15/s  (0.465s,  275.13/s)  LR: 6.300e-05  Data: 0.009 (0.008)
2024-04-07 10:45:51,414 - train - INFO - Train: 118 [ 780/781 (100%)]  Loss:  3.240923 (3.4968)  Time: 0.495s,  258.53/s  (0.466s,  274.88/s)  LR: 6.300e-05  Data: 0.000 (0.008)
2024-04-07 10:45:51,415 - train - INFO - True
2024-04-07 10:45:51,417 - train - INFO - alphas:tensor([0.7278, 0.0195, 0.0353, 0.0541, 0.1632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,417 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,417 - train - INFO - True
2024-04-07 10:45:51,418 - train - INFO - alphas:tensor([0.4578, 0.0062, 0.0149, 0.0483, 0.4727], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,419 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,419 - train - INFO - True
2024-04-07 10:45:51,420 - train - INFO - alphas:tensor([0.5025, 0.0122, 0.0435, 0.4418], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,420 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,421 - train - INFO - True
2024-04-07 10:45:51,421 - train - INFO - alphas:tensor([0.4391, 0.0126, 0.0302, 0.5181], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,422 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,422 - train - INFO - True
2024-04-07 10:45:51,423 - train - INFO - alphas:tensor([0.4457, 0.0075, 0.0371, 0.5097], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,424 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,424 - train - INFO - True
2024-04-07 10:45:51,425 - train - INFO - alphas:tensor([0.5367, 0.0128, 0.0305, 0.4200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,425 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,425 - train - INFO - True
2024-04-07 10:45:51,426 - train - INFO - alphas:tensor([0.5892, 0.0061, 0.0092, 0.0312, 0.3642], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,427 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,428 - train - INFO - True
2024-04-07 10:45:51,428 - train - INFO - alphas:tensor([0.2421, 0.0033, 0.0025, 0.0323, 0.7199], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,429 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,429 - train - INFO - True
2024-04-07 10:45:51,430 - train - INFO - alphas:tensor([0.2479, 0.0021, 0.0030, 0.0235, 0.7235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,431 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,431 - train - INFO - True
2024-04-07 10:45:51,432 - train - INFO - alphas:tensor([0.2486, 0.0013, 0.0025, 0.0279, 0.7196], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,432 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,433 - train - INFO - True
2024-04-07 10:45:51,434 - train - INFO - alphas:tensor([0.2366, 0.0027, 0.0026, 0.0336, 0.7245], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,434 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,434 - train - INFO - True
2024-04-07 10:45:51,435 - train - INFO - alphas:tensor([0.5838, 0.0021, 0.0052, 0.0270, 0.3820], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,436 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,436 - train - INFO - True
2024-04-07 10:45:51,437 - train - INFO - alphas:tensor([0.6995, 0.0029, 0.0039, 0.0171, 0.2766], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,441 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,441 - train - INFO - True
2024-04-07 10:45:51,442 - train - INFO - alphas:tensor([0.2764, 0.0073, 0.0074, 0.0646, 0.6443], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,444 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,444 - train - INFO - True
2024-04-07 10:45:51,445 - train - INFO - alphas:tensor([0.2880, 0.0032, 0.0046, 0.0571, 0.6470], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,447 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,447 - train - INFO - True
2024-04-07 10:45:51,448 - train - INFO - alphas:tensor([0.3054, 0.0024, 0.0047, 0.0500, 0.6376], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,450 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,450 - train - INFO - True
2024-04-07 10:45:51,451 - train - INFO - alphas:tensor([0.2831, 0.0040, 0.0057, 0.0491, 0.6582], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,453 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,453 - train - INFO - True
2024-04-07 10:45:51,454 - train - INFO - alphas:tensor([0.3106, 0.0026, 0.0068, 0.0510, 0.6289], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,456 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,456 - train - INFO - True
2024-04-07 10:45:51,457 - train - INFO - alphas:tensor([0.2714, 0.0073, 0.0099, 0.0569, 0.6545], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,459 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,459 - train - INFO - True
2024-04-07 10:45:51,460 - train - INFO - alphas:tensor([0.6305, 0.0015, 0.0034, 0.0295, 0.3351], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,463 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,463 - train - INFO - True
2024-04-07 10:45:51,464 - train - INFO - alphas:tensor([0.5655, 0.0014, 0.0021, 0.0291, 0.4019], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,472 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,472 - train - INFO - True
2024-04-07 10:45:51,473 - train - INFO - alphas:tensor([0.4362, 0.0011, 0.0047, 0.0439, 0.5142], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,476 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,477 - train - INFO - True
2024-04-07 10:45:51,477 - train - INFO - alphas:tensor([0.4484, 0.0012, 0.0021, 0.0403, 0.5079], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,481 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,481 - train - INFO - True
2024-04-07 10:45:51,482 - train - INFO - alphas:tensor([0.4635, 0.0011, 0.0022, 0.0375, 0.4958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,486 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,486 - train - INFO - True
2024-04-07 10:45:51,487 - train - INFO - alphas:tensor([0.4294, 0.0012, 0.0036, 0.0414, 0.5244], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,491 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,491 - train - INFO - True
2024-04-07 10:45:51,492 - train - INFO - alphas:tensor([0.5715, 0.0011, 0.0030, 0.0250, 0.3995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,500 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,500 - train - INFO - True
2024-04-07 10:45:51,501 - train - INFO - alphas:tensor([0.7473, 0.0008, 0.0022, 0.0169, 0.2328], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,520 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,520 - train - INFO - True
2024-04-07 10:45:51,521 - train - INFO - alphas:tensor([0.3960, 0.0016, 0.0035, 0.0537, 0.5452], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,536 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,536 - train - INFO - True
2024-04-07 10:45:51,537 - train - INFO - alphas:tensor([0.4071, 0.0008, 0.0027, 0.0414, 0.5480], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,545 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,545 - train - INFO - True
2024-04-07 10:45:51,546 - train - INFO - alphas:tensor([0.4351, 0.0010, 0.0020, 0.0446, 0.5173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,553 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,553 - train - INFO - True
2024-04-07 10:45:51,554 - train - INFO - alphas:tensor([0.3979, 0.0013, 0.0031, 0.0452, 0.5526], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,562 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,562 - train - INFO - True
2024-04-07 10:45:51,563 - train - INFO - alphas:tensor([7.2635e-01, 6.5443e-04, 1.2070e-03, 1.3793e-02, 2.5800e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,577 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,577 - train - INFO - True
2024-04-07 10:45:51,578 - train - INFO - alphas:tensor([0.5733, 0.0053, 0.0089, 0.0504, 0.3622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:45:51,638 - train - INFO - tau:0.3116610814491425
2024-04-07 10:45:51,638 - train - INFO - avg block size:10.06060606060606
2024-04-07 10:45:51,639 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 10:45:51,639 - train - INFO - lasso_alpha:2.23356315588495e-06
2024-04-07 10:45:51,812 - train - INFO - Test: [   0/78]  Time: 0.170 (0.170)  Loss:  0.9883 (0.9883)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 10:45:55,018 - train - INFO - Test: [  50/78]  Time: 0.073 (0.066)  Loss:  1.6084 (1.5611)  Acc@1: 64.0625 (65.8241)  Acc@5: 84.3750 (86.0294)
2024-04-07 10:45:56,536 - train - INFO - Test: [  78/78]  Time: 0.053 (0.062)  Loss:  1.8926 (1.5801)  Acc@1: 50.0000 (65.6000)  Acc@5: 93.7500 (85.8100)
2024-04-07 10:45:57,278 - train - INFO - Train: 119 [   0/781 (  0%)]  Loss:  3.430130 (3.4301)  Time: 0.667s,  191.79/s  (0.667s,  191.79/s)  LR: 5.985e-05  Data: 0.187 (0.187)
2024-04-07 10:46:20,548 - train - INFO - Train: 119 [  50/781 (  6%)]  Loss:  3.268783 (3.5273)  Time: 0.445s,  287.65/s  (0.469s,  272.73/s)  LR: 5.985e-05  Data: 0.007 (0.011)
2024-04-07 10:46:42,323 - train - INFO - Train: 119 [ 100/781 ( 13%)]  Loss:  3.862696 (3.5118)  Time: 0.461s,  277.93/s  (0.453s,  282.83/s)  LR: 5.985e-05  Data: 0.006 (0.009)
2024-04-07 10:47:04,944 - train - INFO - Train: 119 [ 150/781 ( 19%)]  Loss:  3.539026 (3.4846)  Time: 0.473s,  270.48/s  (0.453s,  282.86/s)  LR: 5.985e-05  Data: 0.007 (0.009)
2024-04-07 10:47:28,433 - train - INFO - Train: 119 [ 200/781 ( 26%)]  Loss:  3.094309 (3.4907)  Time: 0.467s,  273.92/s  (0.457s,  280.21/s)  LR: 5.985e-05  Data: 0.005 (0.008)
2024-04-07 10:47:51,816 - train - INFO - Train: 119 [ 250/781 ( 32%)]  Loss:  3.169445 (3.4920)  Time: 0.368s,  348.17/s  (0.459s,  278.89/s)  LR: 5.985e-05  Data: 0.008 (0.008)
2024-04-07 10:48:15,214 - train - INFO - Train: 119 [ 300/781 ( 38%)]  Loss:  2.942059 (3.4880)  Time: 0.495s,  258.66/s  (0.460s,  277.99/s)  LR: 5.985e-05  Data: 0.008 (0.008)
2024-04-07 10:48:37,952 - train - INFO - Train: 119 [ 350/781 ( 45%)]  Loss:  3.748797 (3.4928)  Time: 0.364s,  351.28/s  (0.460s,  278.48/s)  LR: 5.985e-05  Data: 0.005 (0.008)
2024-04-07 10:49:01,134 - train - INFO - Train: 119 [ 400/781 ( 51%)]  Loss:  3.678665 (3.4904)  Time: 0.499s,  256.54/s  (0.460s,  278.18/s)  LR: 5.985e-05  Data: 0.010 (0.008)
2024-04-07 10:49:25,512 - train - INFO - Train: 119 [ 450/781 ( 58%)]  Loss:  3.307937 (3.4944)  Time: 0.497s,  257.58/s  (0.463s,  276.36/s)  LR: 5.985e-05  Data: 0.008 (0.008)
2024-04-07 10:49:48,763 - train - INFO - Train: 119 [ 500/781 ( 64%)]  Loss:  3.127020 (3.4909)  Time: 0.357s,  358.73/s  (0.463s,  276.25/s)  LR: 5.985e-05  Data: 0.004 (0.008)
2024-04-07 10:50:11,422 - train - INFO - Train: 119 [ 550/781 ( 71%)]  Loss:  2.900842 (3.4915)  Time: 0.480s,  266.74/s  (0.462s,  276.80/s)  LR: 5.985e-05  Data: 0.007 (0.008)
2024-04-07 10:50:34,929 - train - INFO - Train: 119 [ 600/781 ( 77%)]  Loss:  3.511676 (3.4860)  Time: 0.478s,  267.99/s  (0.463s,  276.42/s)  LR: 5.985e-05  Data: 0.009 (0.008)
2024-04-07 10:50:58,081 - train - INFO - Train: 119 [ 650/781 ( 83%)]  Loss:  3.344759 (3.4849)  Time: 0.442s,  289.31/s  (0.463s,  276.42/s)  LR: 5.985e-05  Data: 0.005 (0.008)
2024-04-07 10:51:21,894 - train - INFO - Train: 119 [ 700/781 ( 90%)]  Loss:  3.239802 (3.4819)  Time: 0.547s,  234.13/s  (0.464s,  275.86/s)  LR: 5.985e-05  Data: 0.008 (0.008)
2024-04-07 10:51:45,283 - train - INFO - Train: 119 [ 750/781 ( 96%)]  Loss:  3.497148 (3.4834)  Time: 0.423s,  302.96/s  (0.464s,  275.72/s)  LR: 5.985e-05  Data: 0.007 (0.008)
2024-04-07 10:51:58,925 - train - INFO - Train: 119 [ 780/781 (100%)]  Loss:  3.146290 (3.4807)  Time: 0.506s,  253.03/s  (0.464s,  275.93/s)  LR: 5.985e-05  Data: 0.000 (0.008)
2024-04-07 10:51:58,926 - train - INFO - True
2024-04-07 10:51:58,927 - train - INFO - alphas:tensor([0.7318, 0.0190, 0.0344, 0.0530, 0.1619], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,928 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,928 - train - INFO - True
2024-04-07 10:51:58,929 - train - INFO - alphas:tensor([0.4592, 0.0060, 0.0144, 0.0474, 0.4730], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,929 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,929 - train - INFO - True
2024-04-07 10:51:58,930 - train - INFO - alphas:tensor([0.5035, 0.0118, 0.0426, 0.4420], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,931 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,931 - train - INFO - True
2024-04-07 10:51:58,932 - train - INFO - alphas:tensor([0.4390, 0.0122, 0.0295, 0.5193], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,933 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,933 - train - INFO - True
2024-04-07 10:51:58,934 - train - INFO - alphas:tensor([0.4456, 0.0072, 0.0363, 0.5109], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,934 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,934 - train - INFO - True
2024-04-07 10:51:58,935 - train - INFO - alphas:tensor([0.5380, 0.0123, 0.0297, 0.4200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,936 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,936 - train - INFO - True
2024-04-07 10:51:58,937 - train - INFO - alphas:tensor([0.5920, 0.0059, 0.0089, 0.0306, 0.3627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,938 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,938 - train - INFO - True
2024-04-07 10:51:58,939 - train - INFO - alphas:tensor([0.2416, 0.0031, 0.0024, 0.0317, 0.7212], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,940 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,940 - train - INFO - True
2024-04-07 10:51:58,941 - train - INFO - alphas:tensor([0.2489, 0.0020, 0.0029, 0.0231, 0.7232], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,942 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,942 - train - INFO - True
2024-04-07 10:51:58,943 - train - INFO - alphas:tensor([0.2493, 0.0012, 0.0024, 0.0274, 0.7197], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,943 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,944 - train - INFO - True
2024-04-07 10:51:58,944 - train - INFO - alphas:tensor([0.2369, 0.0026, 0.0025, 0.0330, 0.7249], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,945 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,945 - train - INFO - True
2024-04-07 10:51:58,946 - train - INFO - alphas:tensor([0.5846, 0.0020, 0.0050, 0.0264, 0.3821], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,947 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,947 - train - INFO - True
2024-04-07 10:51:58,948 - train - INFO - alphas:tensor([0.7016, 0.0027, 0.0037, 0.0166, 0.2753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,952 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,952 - train - INFO - True
2024-04-07 10:51:58,953 - train - INFO - alphas:tensor([0.2757, 0.0070, 0.0071, 0.0637, 0.6464], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,955 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,955 - train - INFO - True
2024-04-07 10:51:58,956 - train - INFO - alphas:tensor([0.2900, 0.0031, 0.0044, 0.0561, 0.6464], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,957 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,958 - train - INFO - True
2024-04-07 10:51:58,958 - train - INFO - alphas:tensor([0.3077, 0.0023, 0.0045, 0.0492, 0.6362], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,960 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,960 - train - INFO - True
2024-04-07 10:51:58,961 - train - INFO - alphas:tensor([0.2824, 0.0038, 0.0055, 0.0478, 0.6605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,963 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,963 - train - INFO - True
2024-04-07 10:51:58,964 - train - INFO - alphas:tensor([0.3113, 0.0025, 0.0066, 0.0502, 0.6294], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,966 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,966 - train - INFO - True
2024-04-07 10:51:58,967 - train - INFO - alphas:tensor([0.2701, 0.0070, 0.0095, 0.0560, 0.6574], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,969 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,969 - train - INFO - True
2024-04-07 10:51:58,970 - train - INFO - alphas:tensor([0.6321, 0.0014, 0.0032, 0.0289, 0.3343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,973 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,974 - train - INFO - True
2024-04-07 10:51:58,974 - train - INFO - alphas:tensor([0.5663, 0.0013, 0.0020, 0.0284, 0.4020], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,982 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,982 - train - INFO - True
2024-04-07 10:51:58,983 - train - INFO - alphas:tensor([0.4390, 0.0011, 0.0044, 0.0426, 0.5128], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,987 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,987 - train - INFO - True
2024-04-07 10:51:58,988 - train - INFO - alphas:tensor([0.4517, 0.0012, 0.0020, 0.0393, 0.5058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,991 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,992 - train - INFO - True
2024-04-07 10:51:58,992 - train - INFO - alphas:tensor([0.4647, 0.0010, 0.0021, 0.0364, 0.4958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:58,996 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:58,996 - train - INFO - True
2024-04-07 10:51:58,997 - train - INFO - alphas:tensor([0.4289, 0.0012, 0.0034, 0.0410, 0.5255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:59,001 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:59,001 - train - INFO - True
2024-04-07 10:51:59,002 - train - INFO - alphas:tensor([0.5731, 0.0010, 0.0028, 0.0242, 0.3988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:59,010 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:59,010 - train - INFO - True
2024-04-07 10:51:59,010 - train - INFO - alphas:tensor([7.4982e-01, 7.1852e-04, 2.0654e-03, 1.6416e-02, 2.3098e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:59,030 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:59,030 - train - INFO - True
2024-04-07 10:51:59,031 - train - INFO - alphas:tensor([0.3976, 0.0015, 0.0033, 0.0530, 0.5445], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:59,041 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:59,041 - train - INFO - True
2024-04-07 10:51:59,042 - train - INFO - alphas:tensor([0.4068, 0.0008, 0.0025, 0.0407, 0.5492], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:59,052 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:59,052 - train - INFO - True
2024-04-07 10:51:59,053 - train - INFO - alphas:tensor([0.4359, 0.0010, 0.0019, 0.0437, 0.5175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:59,063 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:59,063 - train - INFO - True
2024-04-07 10:51:59,064 - train - INFO - alphas:tensor([0.4007, 0.0012, 0.0029, 0.0442, 0.5510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:59,074 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:59,075 - train - INFO - True
2024-04-07 10:51:59,075 - train - INFO - alphas:tensor([7.2775e-01, 6.1729e-04, 1.1405e-03, 1.3398e-02, 2.5709e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:59,095 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:59,095 - train - INFO - True
2024-04-07 10:51:59,096 - train - INFO - alphas:tensor([0.5748, 0.0051, 0.0086, 0.0497, 0.3619], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:51:59,173 - train - INFO - tau:0.30854447063465107
2024-04-07 10:51:59,174 - train - INFO - avg block size:10.06060606060606
2024-04-07 10:51:59,174 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 10:51:59,380 - train - INFO - Test: [   0/78]  Time: 0.203 (0.203)  Loss:  1.0020 (1.0020)  Acc@1: 81.2500 (81.2500)  Acc@5: 92.9688 (92.9688)
2024-04-07 10:52:02,503 - train - INFO - Test: [  50/78]  Time: 0.057 (0.065)  Loss:  1.5068 (1.5332)  Acc@1: 66.4062 (66.4369)  Acc@5: 89.0625 (86.6115)
2024-04-07 10:52:04,009 - train - INFO - Test: [  78/78]  Time: 0.050 (0.061)  Loss:  1.8555 (1.5565)  Acc@1: 50.0000 (65.8600)  Acc@5: 87.5000 (86.2100)
2024-04-07 10:52:04,723 - train - INFO - Train: 120 [   0/781 (  0%)]  Loss:  3.497608 (3.4976)  Time: 0.629s,  203.36/s  (0.629s,  203.36/s)  LR: 5.679e-05  Data: 0.188 (0.188)
2024-04-07 10:52:28,055 - train - INFO - Train: 120 [  50/781 (  6%)]  Loss:  3.563245 (3.4496)  Time: 0.388s,  329.97/s  (0.470s,  272.46/s)  LR: 5.679e-05  Data: 0.004 (0.011)
2024-04-07 10:52:51,616 - train - INFO - Train: 120 [ 100/781 ( 13%)]  Loss:  3.857166 (3.4511)  Time: 0.399s,  320.56/s  (0.470s,  272.06/s)  LR: 5.679e-05  Data: 0.006 (0.010)
2024-04-07 10:53:15,015 - train - INFO - Train: 120 [ 150/781 ( 19%)]  Loss:  3.605003 (3.4550)  Time: 0.525s,  243.62/s  (0.470s,  272.55/s)  LR: 5.679e-05  Data: 0.008 (0.009)
2024-04-07 10:53:38,781 - train - INFO - Train: 120 [ 200/781 ( 26%)]  Loss:  3.811417 (3.4626)  Time: 0.434s,  294.96/s  (0.471s,  271.73/s)  LR: 5.679e-05  Data: 0.012 (0.009)
2024-04-07 10:54:02,128 - train - INFO - Train: 120 [ 250/781 ( 32%)]  Loss:  3.454654 (3.4753)  Time: 0.499s,  256.59/s  (0.470s,  272.21/s)  LR: 5.679e-05  Data: 0.008 (0.009)
2024-04-07 10:54:25,511 - train - INFO - Train: 120 [ 300/781 ( 38%)]  Loss:  3.146844 (3.4774)  Time: 0.491s,  260.74/s  (0.470s,  272.46/s)  LR: 5.679e-05  Data: 0.007 (0.008)
2024-04-07 10:54:48,681 - train - INFO - Train: 120 [ 350/781 ( 45%)]  Loss:  3.493947 (3.4721)  Time: 0.514s,  248.84/s  (0.469s,  272.99/s)  LR: 5.679e-05  Data: 0.008 (0.008)
2024-04-07 10:55:12,102 - train - INFO - Train: 120 [ 400/781 ( 51%)]  Loss:  3.671979 (3.4767)  Time: 0.460s,  278.49/s  (0.469s,  273.03/s)  LR: 5.679e-05  Data: 0.008 (0.008)
2024-04-07 10:55:35,244 - train - INFO - Train: 120 [ 450/781 ( 58%)]  Loss:  3.587633 (3.4783)  Time: 0.471s,  271.51/s  (0.468s,  273.42/s)  LR: 5.679e-05  Data: 0.009 (0.008)
2024-04-07 10:55:58,891 - train - INFO - Train: 120 [ 500/781 ( 64%)]  Loss:  3.495441 (3.4849)  Time: 0.500s,  256.21/s  (0.469s,  273.14/s)  LR: 5.679e-05  Data: 0.010 (0.008)
2024-04-07 10:56:22,113 - train - INFO - Train: 120 [ 550/781 ( 71%)]  Loss:  3.341847 (3.4842)  Time: 0.501s,  255.28/s  (0.468s,  273.36/s)  LR: 5.679e-05  Data: 0.010 (0.008)
2024-04-07 10:56:45,224 - train - INFO - Train: 120 [ 600/781 ( 77%)]  Loss:  3.368689 (3.4816)  Time: 0.477s,  268.62/s  (0.468s,  273.66/s)  LR: 5.679e-05  Data: 0.005 (0.008)
2024-04-07 10:57:07,687 - train - INFO - Train: 120 [ 650/781 ( 83%)]  Loss:  3.121150 (3.4787)  Time: 0.484s,  264.23/s  (0.466s,  274.49/s)  LR: 5.679e-05  Data: 0.007 (0.008)
2024-04-07 10:57:31,831 - train - INFO - Train: 120 [ 700/781 ( 90%)]  Loss:  3.749364 (3.4768)  Time: 0.481s,  265.91/s  (0.467s,  273.80/s)  LR: 5.679e-05  Data: 0.009 (0.008)
2024-04-07 10:57:54,745 - train - INFO - Train: 120 [ 750/781 ( 96%)]  Loss:  3.646356 (3.4752)  Time: 0.372s,  343.73/s  (0.467s,  274.16/s)  LR: 5.679e-05  Data: 0.006 (0.008)
2024-04-07 10:58:09,016 - train - INFO - Train: 120 [ 780/781 (100%)]  Loss:  3.712193 (3.4748)  Time: 0.458s,  279.64/s  (0.467s,  273.96/s)  LR: 5.679e-05  Data: 0.000 (0.008)
2024-04-07 10:58:09,017 - train - INFO - True
2024-04-07 10:58:09,020 - train - INFO - alphas:tensor([0.7350, 0.0185, 0.0338, 0.0520, 0.1607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,021 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,021 - train - INFO - True
2024-04-07 10:58:09,022 - train - INFO - alphas:tensor([0.4594, 0.0057, 0.0141, 0.0464, 0.4744], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,023 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,023 - train - INFO - True
2024-04-07 10:58:09,025 - train - INFO - alphas:tensor([0.5037, 0.0115, 0.0418, 0.4431], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,026 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,026 - train - INFO - True
2024-04-07 10:58:09,028 - train - INFO - alphas:tensor([0.4405, 0.0118, 0.0287, 0.5190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,029 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,029 - train - INFO - True
2024-04-07 10:58:09,030 - train - INFO - alphas:tensor([0.4464, 0.0069, 0.0356, 0.5111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,031 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,032 - train - INFO - True
2024-04-07 10:58:09,033 - train - INFO - alphas:tensor([0.5390, 0.0119, 0.0290, 0.4201], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,034 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,034 - train - INFO - True
2024-04-07 10:58:09,036 - train - INFO - alphas:tensor([0.5933, 0.0056, 0.0086, 0.0299, 0.3627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,038 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,038 - train - INFO - True
2024-04-07 10:58:09,039 - train - INFO - alphas:tensor([0.2402, 0.0030, 0.0022, 0.0310, 0.7235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,040 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,041 - train - INFO - True
2024-04-07 10:58:09,042 - train - INFO - alphas:tensor([0.2483, 0.0019, 0.0027, 0.0224, 0.7247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,043 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,043 - train - INFO - True
2024-04-07 10:58:09,045 - train - INFO - alphas:tensor([0.2476, 0.0012, 0.0023, 0.0267, 0.7222], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,046 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,046 - train - INFO - True
2024-04-07 10:58:09,047 - train - INFO - alphas:tensor([0.2370, 0.0024, 0.0024, 0.0324, 0.7258], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,048 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,048 - train - INFO - True
2024-04-07 10:58:09,050 - train - INFO - alphas:tensor([0.5861, 0.0019, 0.0047, 0.0257, 0.3815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,052 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,052 - train - INFO - True
2024-04-07 10:58:09,053 - train - INFO - alphas:tensor([0.7025, 0.0026, 0.0036, 0.0161, 0.2752], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,058 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,058 - train - INFO - True
2024-04-07 10:58:09,059 - train - INFO - alphas:tensor([0.2760, 0.0067, 0.0069, 0.0628, 0.6476], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,062 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,062 - train - INFO - True
2024-04-07 10:58:09,064 - train - INFO - alphas:tensor([0.2902, 0.0030, 0.0042, 0.0554, 0.6472], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,066 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,066 - train - INFO - True
2024-04-07 10:58:09,068 - train - INFO - alphas:tensor([0.3074, 0.0022, 0.0044, 0.0485, 0.6375], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,070 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,070 - train - INFO - True
2024-04-07 10:58:09,072 - train - INFO - alphas:tensor([0.2845, 0.0037, 0.0053, 0.0471, 0.6594], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,074 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,074 - train - INFO - True
2024-04-07 10:58:09,075 - train - INFO - alphas:tensor([0.3100, 0.0024, 0.0063, 0.0493, 0.6320], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,078 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,078 - train - INFO - True
2024-04-07 10:58:09,079 - train - INFO - alphas:tensor([0.2713, 0.0068, 0.0092, 0.0552, 0.6575], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,081 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,082 - train - INFO - True
2024-04-07 10:58:09,083 - train - INFO - alphas:tensor([0.6355, 0.0013, 0.0031, 0.0283, 0.3317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,089 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,089 - train - INFO - True
2024-04-07 10:58:09,090 - train - INFO - alphas:tensor([0.5660, 0.0012, 0.0019, 0.0279, 0.4031], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,099 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,099 - train - INFO - True
2024-04-07 10:58:09,100 - train - INFO - alphas:tensor([0.4422, 0.0010, 0.0043, 0.0419, 0.5107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,104 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,104 - train - INFO - True
2024-04-07 10:58:09,105 - train - INFO - alphas:tensor([0.4490, 0.0011, 0.0019, 0.0388, 0.5092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,110 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,110 - train - INFO - True
2024-04-07 10:58:09,111 - train - INFO - alphas:tensor([0.4658, 0.0009, 0.0020, 0.0355, 0.4957], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,115 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,115 - train - INFO - True
2024-04-07 10:58:09,116 - train - INFO - alphas:tensor([0.4295, 0.0011, 0.0033, 0.0403, 0.5259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,120 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,120 - train - INFO - True
2024-04-07 10:58:09,121 - train - INFO - alphas:tensor([0.5757, 0.0010, 0.0027, 0.0237, 0.3970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,129 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,129 - train - INFO - True
2024-04-07 10:58:09,130 - train - INFO - alphas:tensor([7.5155e-01, 6.7232e-04, 1.9575e-03, 1.5884e-02, 2.2993e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,149 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,149 - train - INFO - True
2024-04-07 10:58:09,150 - train - INFO - alphas:tensor([0.3991, 0.0014, 0.0032, 0.0523, 0.5439], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,160 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,160 - train - INFO - True
2024-04-07 10:58:09,161 - train - INFO - alphas:tensor([0.4060, 0.0007, 0.0024, 0.0398, 0.5510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,171 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,171 - train - INFO - True
2024-04-07 10:58:09,172 - train - INFO - alphas:tensor([0.4360, 0.0009, 0.0018, 0.0432, 0.5180], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,182 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,182 - train - INFO - True
2024-04-07 10:58:09,183 - train - INFO - alphas:tensor([0.3994, 0.0011, 0.0028, 0.0437, 0.5530], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,193 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,193 - train - INFO - True
2024-04-07 10:58:09,194 - train - INFO - alphas:tensor([7.3196e-01, 5.7416e-04, 1.0706e-03, 1.2934e-02, 2.5346e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,214 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,214 - train - INFO - True
2024-04-07 10:58:09,215 - train - INFO - alphas:tensor([0.5749, 0.0049, 0.0083, 0.0491, 0.3628], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:58:09,292 - train - INFO - tau:0.30545902592830454
2024-04-07 10:58:09,293 - train - INFO - avg block size:10.06060606060606
2024-04-07 10:58:09,293 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 10:58:09,293 - train - INFO - lasso_alpha:2.030511959895409e-06
2024-04-07 10:58:09,447 - train - INFO - Test: [   0/78]  Time: 0.151 (0.151)  Loss:  0.9692 (0.9692)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 10:58:12,480 - train - INFO - Test: [  50/78]  Time: 0.050 (0.062)  Loss:  1.6104 (1.5558)  Acc@1: 65.6250 (66.0080)  Acc@5: 85.9375 (86.4277)
2024-04-07 10:58:14,223 - train - INFO - Test: [  78/78]  Time: 0.071 (0.062)  Loss:  1.8867 (1.5682)  Acc@1: 56.2500 (65.7600)  Acc@5: 87.5000 (86.1400)
2024-04-07 10:58:14,988 - train - INFO - Train: 121 [   0/781 (  0%)]  Loss:  3.405117 (3.4051)  Time: 0.659s,  194.28/s  (0.659s,  194.28/s)  LR: 5.382e-05  Data: 0.184 (0.184)
2024-04-07 10:58:37,737 - train - INFO - Train: 121 [  50/781 (  6%)]  Loss:  3.694509 (3.4740)  Time: 0.442s,  289.63/s  (0.459s,  278.90/s)  LR: 5.382e-05  Data: 0.005 (0.011)
2024-04-07 10:59:00,714 - train - INFO - Train: 121 [ 100/781 ( 13%)]  Loss:  3.612634 (3.4689)  Time: 0.472s,  270.93/s  (0.459s,  278.73/s)  LR: 5.382e-05  Data: 0.005 (0.009)
2024-04-07 10:59:24,310 - train - INFO - Train: 121 [ 150/781 ( 19%)]  Loss:  3.502713 (3.4805)  Time: 0.495s,  258.63/s  (0.463s,  276.21/s)  LR: 5.382e-05  Data: 0.009 (0.009)
2024-04-07 10:59:48,108 - train - INFO - Train: 121 [ 200/781 ( 26%)]  Loss:  3.198805 (3.4710)  Time: 0.505s,  253.26/s  (0.467s,  274.37/s)  LR: 5.382e-05  Data: 0.009 (0.008)
2024-04-07 11:00:11,880 - train - INFO - Train: 121 [ 250/781 ( 32%)]  Loss:  3.795614 (3.4818)  Time: 0.461s,  277.77/s  (0.468s,  273.33/s)  LR: 5.382e-05  Data: 0.006 (0.008)
2024-04-07 11:00:35,951 - train - INFO - Train: 121 [ 300/781 ( 38%)]  Loss:  3.182221 (3.4824)  Time: 0.494s,  258.92/s  (0.470s,  272.07/s)  LR: 5.382e-05  Data: 0.010 (0.008)
2024-04-07 11:00:59,995 - train - INFO - Train: 121 [ 350/781 ( 45%)]  Loss:  3.643691 (3.4783)  Time: 0.483s,  264.74/s  (0.472s,  271.21/s)  LR: 5.382e-05  Data: 0.007 (0.008)
2024-04-07 11:01:23,234 - train - INFO - Train: 121 [ 400/781 ( 51%)]  Loss:  3.665244 (3.4766)  Time: 0.365s,  350.57/s  (0.471s,  271.73/s)  LR: 5.382e-05  Data: 0.005 (0.008)
2024-04-07 11:01:46,043 - train - INFO - Train: 121 [ 450/781 ( 58%)]  Loss:  3.299384 (3.4658)  Time: 0.441s,  290.12/s  (0.469s,  272.69/s)  LR: 5.382e-05  Data: 0.009 (0.008)
2024-04-07 11:02:09,306 - train - INFO - Train: 121 [ 500/781 ( 64%)]  Loss:  3.464768 (3.4709)  Time: 0.461s,  277.46/s  (0.469s,  272.93/s)  LR: 5.382e-05  Data: 0.006 (0.008)
2024-04-07 11:02:32,222 - train - INFO - Train: 121 [ 550/781 ( 71%)]  Loss:  3.791997 (3.4715)  Time: 0.466s,  274.50/s  (0.468s,  273.50/s)  LR: 5.382e-05  Data: 0.007 (0.008)
2024-04-07 11:02:55,666 - train - INFO - Train: 121 [ 600/781 ( 77%)]  Loss:  3.376673 (3.4726)  Time: 0.512s,  250.18/s  (0.468s,  273.46/s)  LR: 5.382e-05  Data: 0.009 (0.008)
2024-04-07 11:03:19,130 - train - INFO - Train: 121 [ 650/781 ( 83%)]  Loss:  3.643961 (3.4748)  Time: 0.478s,  267.99/s  (0.468s,  273.40/s)  LR: 5.382e-05  Data: 0.008 (0.008)
2024-04-07 11:03:42,886 - train - INFO - Train: 121 [ 700/781 ( 90%)]  Loss:  3.693954 (3.4760)  Time: 0.505s,  253.30/s  (0.469s,  273.12/s)  LR: 5.382e-05  Data: 0.010 (0.008)
2024-04-07 11:04:05,263 - train - INFO - Train: 121 [ 750/781 ( 96%)]  Loss:  3.765612 (3.4728)  Time: 0.367s,  348.53/s  (0.467s,  273.94/s)  LR: 5.382e-05  Data: 0.005 (0.008)
2024-04-07 11:04:18,941 - train - INFO - Train: 121 [ 780/781 (100%)]  Loss:  3.330311 (3.4726)  Time: 0.405s,  315.98/s  (0.467s,  274.20/s)  LR: 5.382e-05  Data: 0.000 (0.008)
2024-04-07 11:04:18,942 - train - INFO - True
2024-04-07 11:04:18,944 - train - INFO - alphas:tensor([0.7389, 0.0179, 0.0330, 0.0510, 0.1592], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,945 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,945 - train - INFO - True
2024-04-07 11:04:18,946 - train - INFO - alphas:tensor([0.4591, 0.0055, 0.0136, 0.0454, 0.4764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,947 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,947 - train - INFO - True
2024-04-07 11:04:18,948 - train - INFO - alphas:tensor([0.5056, 0.0111, 0.0409, 0.4424], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,949 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,949 - train - INFO - True
2024-04-07 11:04:18,950 - train - INFO - alphas:tensor([0.4398, 0.0114, 0.0280, 0.5207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,951 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,951 - train - INFO - True
2024-04-07 11:04:18,952 - train - INFO - alphas:tensor([0.4466, 0.0067, 0.0350, 0.5117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,953 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,953 - train - INFO - True
2024-04-07 11:04:18,954 - train - INFO - alphas:tensor([0.5403, 0.0115, 0.0283, 0.4199], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,955 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,955 - train - INFO - True
2024-04-07 11:04:18,956 - train - INFO - alphas:tensor([0.5950, 0.0054, 0.0083, 0.0291, 0.3622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,958 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,958 - train - INFO - True
2024-04-07 11:04:18,959 - train - INFO - alphas:tensor([0.2385, 0.0028, 0.0021, 0.0304, 0.7261], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,960 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,960 - train - INFO - True
2024-04-07 11:04:18,961 - train - INFO - alphas:tensor([0.2477, 0.0018, 0.0026, 0.0218, 0.7261], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,962 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,962 - train - INFO - True
2024-04-07 11:04:18,963 - train - INFO - alphas:tensor([0.2484, 0.0011, 0.0022, 0.0260, 0.7224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,964 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,964 - train - INFO - True
2024-04-07 11:04:18,965 - train - INFO - alphas:tensor([0.2353, 0.0023, 0.0023, 0.0317, 0.7284], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,966 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,966 - train - INFO - True
2024-04-07 11:04:18,967 - train - INFO - alphas:tensor([0.5870, 0.0018, 0.0045, 0.0250, 0.3817], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,969 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,969 - train - INFO - True
2024-04-07 11:04:18,970 - train - INFO - alphas:tensor([0.7053, 0.0025, 0.0034, 0.0155, 0.2733], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,974 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,974 - train - INFO - True
2024-04-07 11:04:18,975 - train - INFO - alphas:tensor([0.2737, 0.0065, 0.0067, 0.0623, 0.6509], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,977 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,978 - train - INFO - True
2024-04-07 11:04:18,979 - train - INFO - alphas:tensor([0.2890, 0.0028, 0.0040, 0.0545, 0.6497], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,981 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,982 - train - INFO - True
2024-04-07 11:04:18,983 - train - INFO - alphas:tensor([0.3077, 0.0021, 0.0042, 0.0478, 0.6383], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,985 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,985 - train - INFO - True
2024-04-07 11:04:18,986 - train - INFO - alphas:tensor([0.2831, 0.0035, 0.0050, 0.0458, 0.6626], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,988 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,988 - train - INFO - True
2024-04-07 11:04:18,989 - train - INFO - alphas:tensor([0.3091, 0.0023, 0.0061, 0.0489, 0.6335], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,991 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,991 - train - INFO - True
2024-04-07 11:04:18,992 - train - INFO - alphas:tensor([0.2718, 0.0065, 0.0089, 0.0543, 0.6585], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,994 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,994 - train - INFO - True
2024-04-07 11:04:18,995 - train - INFO - alphas:tensor([0.6377, 0.0013, 0.0030, 0.0276, 0.3304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:18,999 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:18,999 - train - INFO - True
2024-04-07 11:04:19,001 - train - INFO - alphas:tensor([0.5680, 0.0012, 0.0018, 0.0270, 0.4021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:19,011 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:19,011 - train - INFO - True
2024-04-07 11:04:19,013 - train - INFO - alphas:tensor([0.4395, 0.0010, 0.0041, 0.0412, 0.5142], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:19,018 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:19,018 - train - INFO - True
2024-04-07 11:04:19,019 - train - INFO - alphas:tensor([0.4532, 0.0010, 0.0018, 0.0380, 0.5059], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:19,024 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:19,024 - train - INFO - True
2024-04-07 11:04:19,025 - train - INFO - alphas:tensor([0.4668, 0.0009, 0.0019, 0.0348, 0.4956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:19,030 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:19,030 - train - INFO - True
2024-04-07 11:04:19,031 - train - INFO - alphas:tensor([0.4316, 0.0010, 0.0031, 0.0395, 0.5247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:19,035 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:19,035 - train - INFO - True
2024-04-07 11:04:19,036 - train - INFO - alphas:tensor([0.5772, 0.0009, 0.0026, 0.0232, 0.3961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:19,045 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:19,045 - train - INFO - True
2024-04-07 11:04:19,046 - train - INFO - alphas:tensor([7.5359e-01, 6.2981e-04, 1.8532e-03, 1.5451e-02, 2.2848e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:19,066 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:19,067 - train - INFO - True
2024-04-07 11:04:19,068 - train - INFO - alphas:tensor([0.4012, 0.0013, 0.0031, 0.0511, 0.5433], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:19,078 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:19,078 - train - INFO - True
2024-04-07 11:04:19,079 - train - INFO - alphas:tensor([0.4086, 0.0007, 0.0023, 0.0391, 0.5493], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:19,089 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:19,089 - train - INFO - True
2024-04-07 11:04:19,090 - train - INFO - alphas:tensor([0.4381, 0.0009, 0.0017, 0.0424, 0.5168], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:19,100 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:19,100 - train - INFO - True
2024-04-07 11:04:19,101 - train - INFO - alphas:tensor([0.4015, 0.0011, 0.0027, 0.0430, 0.5518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:19,111 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:19,111 - train - INFO - True
2024-04-07 11:04:19,112 - train - INFO - alphas:tensor([7.2889e-01, 5.4261e-04, 1.0236e-03, 1.2659e-02, 2.5689e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:19,132 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:19,132 - train - INFO - True
2024-04-07 11:04:19,133 - train - INFO - alphas:tensor([0.5760, 0.0047, 0.0081, 0.0484, 0.3628], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:04:19,212 - train - INFO - tau:0.3024044356690215
2024-04-07 11:04:19,212 - train - INFO - avg block size:10.06060606060606
2024-04-07 11:04:19,213 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 11:04:19,444 - train - INFO - Test: [   0/78]  Time: 0.228 (0.228)  Loss:  0.9863 (0.9863)  Acc@1: 82.0312 (82.0312)  Acc@5: 92.9688 (92.9688)
2024-04-07 11:04:22,558 - train - INFO - Test: [  50/78]  Time: 0.053 (0.066)  Loss:  1.5889 (1.5504)  Acc@1: 67.1875 (66.2377)  Acc@5: 87.5000 (86.5502)
2024-04-07 11:04:24,144 - train - INFO - Test: [  78/78]  Time: 0.071 (0.062)  Loss:  1.7695 (1.5691)  Acc@1: 56.2500 (65.7700)  Acc@5: 100.0000 (86.1500)
2024-04-07 11:04:24,876 - train - INFO - Train: 122 [   0/781 (  0%)]  Loss:  3.787816 (3.7878)  Time: 0.615s,  208.06/s  (0.615s,  208.06/s)  LR: 5.093e-05  Data: 0.167 (0.167)
2024-04-07 11:04:47,518 - train - INFO - Train: 122 [  50/781 (  6%)]  Loss:  3.332958 (3.4480)  Time: 0.462s,  276.91/s  (0.456s,  280.70/s)  LR: 5.093e-05  Data: 0.005 (0.011)
2024-04-07 11:05:10,387 - train - INFO - Train: 122 [ 100/781 ( 13%)]  Loss:  3.620869 (3.4675)  Time: 0.462s,  276.89/s  (0.457s,  280.29/s)  LR: 5.093e-05  Data: 0.008 (0.009)
2024-04-07 11:05:33,746 - train - INFO - Train: 122 [ 150/781 ( 19%)]  Loss:  3.390004 (3.4763)  Time: 0.453s,  282.57/s  (0.460s,  278.18/s)  LR: 5.093e-05  Data: 0.006 (0.009)
2024-04-07 11:05:57,120 - train - INFO - Train: 122 [ 200/781 ( 26%)]  Loss:  3.592514 (3.4740)  Time: 0.486s,  263.57/s  (0.462s,  277.08/s)  LR: 5.093e-05  Data: 0.016 (0.008)
2024-04-07 11:06:20,939 - train - INFO - Train: 122 [ 250/781 ( 32%)]  Loss:  3.752346 (3.4800)  Time: 0.439s,  291.29/s  (0.465s,  275.37/s)  LR: 5.093e-05  Data: 0.007 (0.008)
2024-04-07 11:06:42,971 - train - INFO - Train: 122 [ 300/781 ( 38%)]  Loss:  3.307577 (3.4748)  Time: 0.498s,  256.84/s  (0.461s,  277.78/s)  LR: 5.093e-05  Data: 0.009 (0.008)
2024-04-07 11:07:05,940 - train - INFO - Train: 122 [ 350/781 ( 45%)]  Loss:  3.364438 (3.4788)  Time: 0.411s,  311.75/s  (0.461s,  277.90/s)  LR: 5.093e-05  Data: 0.007 (0.008)
2024-04-07 11:07:28,744 - train - INFO - Train: 122 [ 400/781 ( 51%)]  Loss:  3.074669 (3.4810)  Time: 0.366s,  349.61/s  (0.460s,  278.24/s)  LR: 5.093e-05  Data: 0.005 (0.008)
2024-04-07 11:07:52,419 - train - INFO - Train: 122 [ 450/781 ( 58%)]  Loss:  3.643145 (3.4801)  Time: 0.409s,  313.33/s  (0.462s,  277.35/s)  LR: 5.093e-05  Data: 0.008 (0.008)
2024-04-07 11:08:16,127 - train - INFO - Train: 122 [ 500/781 ( 64%)]  Loss:  3.376550 (3.4774)  Time: 0.552s,  231.80/s  (0.463s,  276.59/s)  LR: 5.093e-05  Data: 0.008 (0.008)
2024-04-07 11:08:38,153 - train - INFO - Train: 122 [ 550/781 ( 71%)]  Loss:  3.613941 (3.4737)  Time: 0.425s,  301.40/s  (0.461s,  277.81/s)  LR: 5.093e-05  Data: 0.007 (0.008)
2024-04-07 11:09:01,621 - train - INFO - Train: 122 [ 600/781 ( 77%)]  Loss:  3.244225 (3.4734)  Time: 0.472s,  271.21/s  (0.461s,  277.38/s)  LR: 5.093e-05  Data: 0.009 (0.008)
2024-04-07 11:09:25,091 - train - INFO - Train: 122 [ 650/781 ( 83%)]  Loss:  3.160736 (3.4720)  Time: 0.489s,  261.51/s  (0.462s,  277.01/s)  LR: 5.093e-05  Data: 0.009 (0.008)
2024-04-07 11:09:47,819 - train - INFO - Train: 122 [ 700/781 ( 90%)]  Loss:  3.350741 (3.4736)  Time: 0.360s,  355.21/s  (0.462s,  277.33/s)  LR: 5.093e-05  Data: 0.004 (0.008)
2024-04-07 11:10:11,877 - train - INFO - Train: 122 [ 750/781 ( 96%)]  Loss:  3.470526 (3.4725)  Time: 0.488s,  262.15/s  (0.463s,  276.55/s)  LR: 5.093e-05  Data: 0.005 (0.008)
2024-04-07 11:10:26,094 - train - INFO - Train: 122 [ 780/781 (100%)]  Loss:  3.591312 (3.4752)  Time: 0.468s,  273.52/s  (0.463s,  276.30/s)  LR: 5.093e-05  Data: 0.000 (0.008)
2024-04-07 11:10:26,095 - train - INFO - True
2024-04-07 11:10:26,098 - train - INFO - alphas:tensor([0.7429, 0.0174, 0.0321, 0.0499, 0.1577], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,099 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,099 - train - INFO - True
2024-04-07 11:10:26,101 - train - INFO - alphas:tensor([0.4599, 0.0053, 0.0132, 0.0447, 0.4768], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,101 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,101 - train - INFO - True
2024-04-07 11:10:26,103 - train - INFO - alphas:tensor([0.5052, 0.0107, 0.0402, 0.4438], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,105 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,105 - train - INFO - True
2024-04-07 11:10:26,106 - train - INFO - alphas:tensor([0.4402, 0.0111, 0.0274, 0.5213], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,107 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,108 - train - INFO - True
2024-04-07 11:10:26,109 - train - INFO - alphas:tensor([0.4468, 0.0064, 0.0342, 0.5126], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,110 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,110 - train - INFO - True
2024-04-07 11:10:26,112 - train - INFO - alphas:tensor([0.5405, 0.0111, 0.0277, 0.4206], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,113 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,113 - train - INFO - True
2024-04-07 11:10:26,115 - train - INFO - alphas:tensor([0.5969, 0.0052, 0.0080, 0.0284, 0.3616], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,117 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,117 - train - INFO - True
2024-04-07 11:10:26,126 - train - INFO - alphas:tensor([0.2391, 0.0027, 0.0020, 0.0297, 0.7265], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,126 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,126 - train - INFO - True
2024-04-07 11:10:26,127 - train - INFO - alphas:tensor([0.2476, 0.0017, 0.0025, 0.0212, 0.7270], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,128 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,128 - train - INFO - True
2024-04-07 11:10:26,129 - train - INFO - alphas:tensor([0.2453, 0.0010, 0.0020, 0.0252, 0.7265], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,136 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,136 - train - INFO - True
2024-04-07 11:10:26,137 - train - INFO - alphas:tensor([0.2348, 0.0022, 0.0022, 0.0310, 0.7298], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,138 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,138 - train - INFO - True
2024-04-07 11:10:26,139 - train - INFO - alphas:tensor([0.5883, 0.0017, 0.0044, 0.0244, 0.3813], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,140 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,140 - train - INFO - True
2024-04-07 11:10:26,141 - train - INFO - alphas:tensor([0.7073, 0.0023, 0.0032, 0.0151, 0.2721], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,144 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,145 - train - INFO - True
2024-04-07 11:10:26,145 - train - INFO - alphas:tensor([0.2740, 0.0063, 0.0064, 0.0613, 0.6519], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,147 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,147 - train - INFO - True
2024-04-07 11:10:26,148 - train - INFO - alphas:tensor([0.2879, 0.0027, 0.0039, 0.0537, 0.6519], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,150 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,150 - train - INFO - True
2024-04-07 11:10:26,151 - train - INFO - alphas:tensor([0.3071, 0.0020, 0.0040, 0.0470, 0.6399], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,153 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,153 - train - INFO - True
2024-04-07 11:10:26,154 - train - INFO - alphas:tensor([0.2826, 0.0033, 0.0049, 0.0451, 0.6641], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,156 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,156 - train - INFO - True
2024-04-07 11:10:26,157 - train - INFO - alphas:tensor([0.3093, 0.0022, 0.0059, 0.0480, 0.6347], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,159 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,159 - train - INFO - True
2024-04-07 11:10:26,160 - train - INFO - alphas:tensor([0.2725, 0.0062, 0.0086, 0.0534, 0.6593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,162 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,162 - train - INFO - True
2024-04-07 11:10:26,163 - train - INFO - alphas:tensor([0.6368, 0.0012, 0.0028, 0.0272, 0.3320], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,166 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,166 - train - INFO - True
2024-04-07 11:10:26,167 - train - INFO - alphas:tensor([0.5667, 0.0011, 0.0017, 0.0264, 0.4042], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,175 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,175 - train - INFO - True
2024-04-07 11:10:26,176 - train - INFO - alphas:tensor([0.4422, 0.0009, 0.0039, 0.0402, 0.5127], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,180 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,180 - train - INFO - True
2024-04-07 11:10:26,181 - train - INFO - alphas:tensor([0.4531, 0.0010, 0.0018, 0.0373, 0.5069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,184 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,185 - train - INFO - True
2024-04-07 11:10:26,185 - train - INFO - alphas:tensor([0.4658, 0.0008, 0.0018, 0.0341, 0.4976], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,189 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,189 - train - INFO - True
2024-04-07 11:10:26,190 - train - INFO - alphas:tensor([0.4299, 0.0010, 0.0030, 0.0388, 0.5273], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,194 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,194 - train - INFO - True
2024-04-07 11:10:26,195 - train - INFO - alphas:tensor([0.5783, 0.0009, 0.0025, 0.0226, 0.3958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,203 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,203 - train - INFO - True
2024-04-07 11:10:26,204 - train - INFO - alphas:tensor([7.5496e-01, 5.9148e-04, 1.7638e-03, 1.4976e-02, 2.2771e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,223 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,223 - train - INFO - True
2024-04-07 11:10:26,224 - train - INFO - alphas:tensor([0.4021, 0.0013, 0.0029, 0.0503, 0.5434], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,234 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,234 - train - INFO - True
2024-04-07 11:10:26,235 - train - INFO - alphas:tensor([0.4091, 0.0007, 0.0022, 0.0384, 0.5497], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,245 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,245 - train - INFO - True
2024-04-07 11:10:26,246 - train - INFO - alphas:tensor([0.4352, 0.0008, 0.0017, 0.0417, 0.5205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,256 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,256 - train - INFO - True
2024-04-07 11:10:26,257 - train - INFO - alphas:tensor([0.4014, 0.0010, 0.0025, 0.0421, 0.5529], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,267 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,267 - train - INFO - True
2024-04-07 11:10:26,268 - train - INFO - alphas:tensor([7.3243e-01, 5.0843e-04, 9.6203e-04, 1.2276e-02, 2.5382e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,287 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,288 - train - INFO - True
2024-04-07 11:10:26,288 - train - INFO - alphas:tensor([0.5772, 0.0045, 0.0078, 0.0478, 0.3626], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:10:26,366 - train - INFO - tau:0.29938039131233124
2024-04-07 11:10:26,366 - train - INFO - avg block size:10.06060606060606
2024-04-07 11:10:26,366 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 11:10:26,367 - train - INFO - lasso_alpha:1.8459199635412806e-06
2024-04-07 11:10:26,570 - train - INFO - Test: [   0/78]  Time: 0.200 (0.200)  Loss:  0.9292 (0.9292)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.9688 (92.9688)
2024-04-07 11:10:29,907 - train - INFO - Test: [  50/78]  Time: 0.074 (0.069)  Loss:  1.5527 (1.5439)  Acc@1: 63.2812 (66.0846)  Acc@5: 88.2812 (86.2898)
2024-04-07 11:10:31,931 - train - INFO - Test: [  78/78]  Time: 0.071 (0.070)  Loss:  1.7383 (1.5617)  Acc@1: 56.2500 (65.7600)  Acc@5: 100.0000 (86.0500)
2024-04-07 11:10:32,761 - train - INFO - Train: 123 [   0/781 (  0%)]  Loss:  3.263738 (3.2637)  Time: 0.677s,  189.13/s  (0.677s,  189.13/s)  LR: 4.814e-05  Data: 0.200 (0.200)
2024-04-07 11:10:56,729 - train - INFO - Train: 123 [  50/781 (  6%)]  Loss:  3.655336 (3.4797)  Time: 0.488s,  262.56/s  (0.483s,  264.90/s)  LR: 4.814e-05  Data: 0.010 (0.011)
2024-04-07 11:11:20,326 - train - INFO - Train: 123 [ 100/781 ( 13%)]  Loss:  3.777369 (3.4654)  Time: 0.503s,  254.31/s  (0.478s,  268.00/s)  LR: 4.814e-05  Data: 0.011 (0.009)
2024-04-07 11:11:43,615 - train - INFO - Train: 123 [ 150/781 ( 19%)]  Loss:  3.458348 (3.4810)  Time: 0.384s,  333.08/s  (0.474s,  270.22/s)  LR: 4.814e-05  Data: 0.005 (0.009)
2024-04-07 11:12:06,232 - train - INFO - Train: 123 [ 200/781 ( 26%)]  Loss:  3.084120 (3.4691)  Time: 0.462s,  276.87/s  (0.468s,  273.29/s)  LR: 4.814e-05  Data: 0.014 (0.009)
2024-04-07 11:12:29,577 - train - INFO - Train: 123 [ 250/781 ( 32%)]  Loss:  3.317111 (3.4727)  Time: 0.491s,  260.93/s  (0.468s,  273.46/s)  LR: 4.814e-05  Data: 0.009 (0.008)
2024-04-07 11:12:52,347 - train - INFO - Train: 123 [ 300/781 ( 38%)]  Loss:  3.774509 (3.4859)  Time: 0.489s,  261.80/s  (0.466s,  274.70/s)  LR: 4.814e-05  Data: 0.005 (0.008)
2024-04-07 11:13:15,305 - train - INFO - Train: 123 [ 350/781 ( 45%)]  Loss:  3.378440 (3.4829)  Time: 0.472s,  271.02/s  (0.465s,  275.28/s)  LR: 4.814e-05  Data: 0.009 (0.008)
2024-04-07 11:13:37,452 - train - INFO - Train: 123 [ 400/781 ( 51%)]  Loss:  3.531280 (3.4842)  Time: 0.471s,  271.51/s  (0.462s,  276.92/s)  LR: 4.814e-05  Data: 0.009 (0.008)
2024-04-07 11:14:00,879 - train - INFO - Train: 123 [ 450/781 ( 58%)]  Loss:  3.234516 (3.4802)  Time: 0.496s,  258.15/s  (0.463s,  276.50/s)  LR: 4.814e-05  Data: 0.006 (0.008)
2024-04-07 11:14:24,258 - train - INFO - Train: 123 [ 500/781 ( 64%)]  Loss:  3.254121 (3.4834)  Time: 0.512s,  250.24/s  (0.463s,  276.23/s)  LR: 4.814e-05  Data: 0.008 (0.008)
2024-04-07 11:14:47,185 - train - INFO - Train: 123 [ 550/781 ( 71%)]  Loss:  3.806704 (3.4875)  Time: 0.444s,  288.56/s  (0.463s,  276.50/s)  LR: 4.814e-05  Data: 0.009 (0.008)
2024-04-07 11:15:09,855 - train - INFO - Train: 123 [ 600/781 ( 77%)]  Loss:  3.784405 (3.4889)  Time: 0.453s,  282.31/s  (0.462s,  276.97/s)  LR: 4.814e-05  Data: 0.007 (0.008)
2024-04-07 11:15:32,644 - train - INFO - Train: 123 [ 650/781 ( 83%)]  Loss:  3.555682 (3.4928)  Time: 0.390s,  328.53/s  (0.462s,  277.27/s)  LR: 4.814e-05  Data: 0.006 (0.008)
2024-04-07 11:15:54,880 - train - INFO - Train: 123 [ 700/781 ( 90%)]  Loss:  3.221087 (3.4935)  Time: 0.463s,  276.65/s  (0.460s,  278.00/s)  LR: 4.814e-05  Data: 0.009 (0.008)
2024-04-07 11:16:18,041 - train - INFO - Train: 123 [ 750/781 ( 96%)]  Loss:  3.478773 (3.4950)  Time: 0.479s,  267.43/s  (0.461s,  277.89/s)  LR: 4.814e-05  Data: 0.008 (0.008)
2024-04-07 11:16:32,283 - train - INFO - Train: 123 [ 780/781 (100%)]  Loss:  3.758429 (3.4943)  Time: 0.428s,  299.00/s  (0.461s,  277.56/s)  LR: 4.814e-05  Data: 0.000 (0.008)
2024-04-07 11:16:32,284 - train - INFO - True
2024-04-07 11:16:32,285 - train - INFO - alphas:tensor([0.7466, 0.0169, 0.0314, 0.0490, 0.1562], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,286 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,286 - train - INFO - True
2024-04-07 11:16:32,286 - train - INFO - alphas:tensor([0.4608, 0.0051, 0.0128, 0.0437, 0.4777], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,287 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,287 - train - INFO - True
2024-04-07 11:16:32,287 - train - INFO - alphas:tensor([0.5075, 0.0103, 0.0393, 0.4429], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,288 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,288 - train - INFO - True
2024-04-07 11:16:32,289 - train - INFO - alphas:tensor([0.4405, 0.0108, 0.0268, 0.5219], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,289 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,289 - train - INFO - True
2024-04-07 11:16:32,290 - train - INFO - alphas:tensor([0.4492, 0.0062, 0.0335, 0.5111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,290 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,290 - train - INFO - True
2024-04-07 11:16:32,291 - train - INFO - alphas:tensor([0.5414, 0.0108, 0.0271, 0.4207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,292 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,292 - train - INFO - True
2024-04-07 11:16:32,292 - train - INFO - alphas:tensor([0.5985, 0.0050, 0.0077, 0.0277, 0.3612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,293 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,293 - train - INFO - True
2024-04-07 11:16:32,294 - train - INFO - alphas:tensor([0.2381, 0.0026, 0.0019, 0.0290, 0.7284], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,294 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,294 - train - INFO - True
2024-04-07 11:16:32,295 - train - INFO - alphas:tensor([0.2464, 0.0016, 0.0024, 0.0207, 0.7289], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,296 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,296 - train - INFO - True
2024-04-07 11:16:32,296 - train - INFO - alphas:tensor([0.2464, 0.0010, 0.0019, 0.0247, 0.7259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,297 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,297 - train - INFO - True
2024-04-07 11:16:32,298 - train - INFO - alphas:tensor([0.2342, 0.0021, 0.0021, 0.0302, 0.7313], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,298 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,298 - train - INFO - True
2024-04-07 11:16:32,299 - train - INFO - alphas:tensor([0.5899, 0.0016, 0.0042, 0.0237, 0.3807], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,300 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,300 - train - INFO - True
2024-04-07 11:16:32,300 - train - INFO - alphas:tensor([0.7075, 0.0022, 0.0031, 0.0146, 0.2725], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,303 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,303 - train - INFO - True
2024-04-07 11:16:32,304 - train - INFO - alphas:tensor([0.2749, 0.0061, 0.0062, 0.0605, 0.6524], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,305 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,305 - train - INFO - True
2024-04-07 11:16:32,306 - train - INFO - alphas:tensor([0.2892, 0.0026, 0.0037, 0.0528, 0.6518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,307 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,307 - train - INFO - True
2024-04-07 11:16:32,308 - train - INFO - alphas:tensor([0.3078, 0.0019, 0.0038, 0.0462, 0.6402], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,309 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,309 - train - INFO - True
2024-04-07 11:16:32,310 - train - INFO - alphas:tensor([0.2822, 0.0032, 0.0046, 0.0445, 0.6655], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,311 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,311 - train - INFO - True
2024-04-07 11:16:32,312 - train - INFO - alphas:tensor([0.3099, 0.0021, 0.0056, 0.0472, 0.6352], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,313 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,313 - train - INFO - True
2024-04-07 11:16:32,314 - train - INFO - alphas:tensor([0.2722, 0.0060, 0.0082, 0.0524, 0.6612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,315 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,315 - train - INFO - True
2024-04-07 11:16:32,316 - train - INFO - alphas:tensor([0.6394, 0.0011, 0.0027, 0.0265, 0.3304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,318 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,318 - train - INFO - True
2024-04-07 11:16:32,319 - train - INFO - alphas:tensor([0.5681, 0.0010, 0.0016, 0.0257, 0.4036], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,324 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,324 - train - INFO - True
2024-04-07 11:16:32,324 - train - INFO - alphas:tensor([0.4418, 0.0008, 0.0037, 0.0395, 0.5142], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,327 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,327 - train - INFO - True
2024-04-07 11:16:32,328 - train - INFO - alphas:tensor([0.4533, 0.0009, 0.0017, 0.0365, 0.5076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,330 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,330 - train - INFO - True
2024-04-07 11:16:32,331 - train - INFO - alphas:tensor([0.4691, 0.0008, 0.0017, 0.0333, 0.4952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,333 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,333 - train - INFO - True
2024-04-07 11:16:32,334 - train - INFO - alphas:tensor([0.4323, 0.0009, 0.0028, 0.0379, 0.5260], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,336 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,336 - train - INFO - True
2024-04-07 11:16:32,337 - train - INFO - alphas:tensor([0.5786, 0.0008, 0.0024, 0.0220, 0.3962], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,342 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,342 - train - INFO - True
2024-04-07 11:16:32,342 - train - INFO - alphas:tensor([7.5445e-01, 5.5308e-04, 1.6744e-03, 1.4626e-02, 2.2870e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,354 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,354 - train - INFO - True
2024-04-07 11:16:32,355 - train - INFO - alphas:tensor([0.4031, 0.0012, 0.0028, 0.0496, 0.5433], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,361 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,361 - train - INFO - True
2024-04-07 11:16:32,362 - train - INFO - alphas:tensor([0.4096, 0.0006, 0.0021, 0.0376, 0.5501], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,368 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,368 - train - INFO - True
2024-04-07 11:16:32,369 - train - INFO - alphas:tensor([0.4381, 0.0008, 0.0016, 0.0411, 0.5184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,375 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,375 - train - INFO - True
2024-04-07 11:16:32,376 - train - INFO - alphas:tensor([0.4016, 0.0010, 0.0024, 0.0412, 0.5539], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,382 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,382 - train - INFO - True
2024-04-07 11:16:32,382 - train - INFO - alphas:tensor([7.3038e-01, 4.7939e-04, 9.1472e-04, 1.1988e-02, 2.5623e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,394 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,394 - train - INFO - True
2024-04-07 11:16:32,394 - train - INFO - alphas:tensor([0.5778, 0.0043, 0.0076, 0.0471, 0.3632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:16:32,445 - train - INFO - tau:0.2963865873992079
2024-04-07 11:16:32,445 - train - INFO - avg block size:10.06060606060606
2024-04-07 11:16:32,445 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 11:16:32,649 - train - INFO - Test: [   0/78]  Time: 0.199 (0.199)  Loss:  0.9238 (0.9238)  Acc@1: 83.5938 (83.5938)  Acc@5: 92.9688 (92.9688)
2024-04-07 11:16:35,567 - train - INFO - Test: [  50/78]  Time: 0.054 (0.061)  Loss:  1.6172 (1.5475)  Acc@1: 61.7188 (65.9314)  Acc@5: 89.0625 (86.4737)
2024-04-07 11:16:37,081 - train - INFO - Test: [  78/78]  Time: 0.051 (0.059)  Loss:  1.8096 (1.5655)  Acc@1: 56.2500 (65.7000)  Acc@5: 93.7500 (86.1300)
2024-04-07 11:16:37,814 - train - INFO - Train: 124 [   0/781 (  0%)]  Loss:  3.693291 (3.6933)  Time: 0.651s,  196.55/s  (0.651s,  196.55/s)  LR: 4.544e-05  Data: 0.183 (0.183)
2024-04-07 11:17:01,377 - train - INFO - Train: 124 [  50/781 (  6%)]  Loss:  3.261932 (3.4626)  Time: 0.473s,  270.89/s  (0.475s,  269.62/s)  LR: 4.544e-05  Data: 0.006 (0.011)
2024-04-07 11:17:24,138 - train - INFO - Train: 124 [ 100/781 ( 13%)]  Loss:  4.035152 (3.4941)  Time: 0.465s,  275.48/s  (0.465s,  275.23/s)  LR: 4.544e-05  Data: 0.009 (0.009)
2024-04-07 11:17:47,438 - train - INFO - Train: 124 [ 150/781 ( 19%)]  Loss:  3.837387 (3.4776)  Time: 0.463s,  276.17/s  (0.465s,  275.05/s)  LR: 4.544e-05  Data: 0.005 (0.009)
2024-04-07 11:18:10,628 - train - INFO - Train: 124 [ 200/781 ( 26%)]  Loss:  3.587990 (3.4829)  Time: 0.477s,  268.26/s  (0.465s,  275.29/s)  LR: 4.544e-05  Data: 0.007 (0.008)
2024-04-07 11:18:33,933 - train - INFO - Train: 124 [ 250/781 ( 32%)]  Loss:  3.772400 (3.4743)  Time: 0.481s,  265.90/s  (0.465s,  275.16/s)  LR: 4.544e-05  Data: 0.007 (0.008)
2024-04-07 11:18:57,887 - train - INFO - Train: 124 [ 300/781 ( 38%)]  Loss:  3.152920 (3.4718)  Time: 0.348s,  367.34/s  (0.467s,  273.80/s)  LR: 4.544e-05  Data: 0.006 (0.008)
2024-04-07 11:19:21,410 - train - INFO - Train: 124 [ 350/781 ( 45%)]  Loss:  3.626675 (3.4765)  Time: 0.480s,  266.85/s  (0.468s,  273.56/s)  LR: 4.544e-05  Data: 0.006 (0.008)
2024-04-07 11:19:44,651 - train - INFO - Train: 124 [ 400/781 ( 51%)]  Loss:  3.419377 (3.4755)  Time: 0.483s,  264.78/s  (0.468s,  273.79/s)  LR: 4.544e-05  Data: 0.008 (0.008)
2024-04-07 11:20:08,222 - train - INFO - Train: 124 [ 450/781 ( 58%)]  Loss:  3.417414 (3.4747)  Time: 0.474s,  269.89/s  (0.468s,  273.54/s)  LR: 4.544e-05  Data: 0.008 (0.008)
2024-04-07 11:20:32,067 - train - INFO - Train: 124 [ 500/781 ( 64%)]  Loss:  3.093747 (3.4736)  Time: 0.375s,  341.57/s  (0.469s,  273.02/s)  LR: 4.544e-05  Data: 0.004 (0.008)
2024-04-07 11:20:55,201 - train - INFO - Train: 124 [ 550/781 ( 71%)]  Loss:  3.607595 (3.4727)  Time: 0.482s,  265.60/s  (0.468s,  273.34/s)  LR: 4.544e-05  Data: 0.009 (0.008)
2024-04-07 11:21:19,327 - train - INFO - Train: 124 [ 600/781 ( 77%)]  Loss:  3.238344 (3.4732)  Time: 0.522s,  245.22/s  (0.469s,  272.66/s)  LR: 4.544e-05  Data: 0.008 (0.008)
2024-04-07 11:21:41,734 - train - INFO - Train: 124 [ 650/781 ( 83%)]  Loss:  3.455199 (3.4741)  Time: 0.474s,  269.81/s  (0.468s,  273.61/s)  LR: 4.544e-05  Data: 0.008 (0.008)
2024-04-07 11:22:04,582 - train - INFO - Train: 124 [ 700/781 ( 90%)]  Loss:  3.102048 (3.4719)  Time: 0.524s,  244.18/s  (0.467s,  274.07/s)  LR: 4.544e-05  Data: 0.004 (0.008)
2024-04-07 11:22:28,324 - train - INFO - Train: 124 [ 750/781 ( 96%)]  Loss:  3.407137 (3.4711)  Time: 0.502s,  255.03/s  (0.468s,  273.77/s)  LR: 4.544e-05  Data: 0.009 (0.008)
2024-04-07 11:22:42,253 - train - INFO - Train: 124 [ 780/781 (100%)]  Loss:  3.620100 (3.4700)  Time: 0.442s,  289.38/s  (0.467s,  273.84/s)  LR: 4.544e-05  Data: 0.000 (0.008)
2024-04-07 11:22:42,255 - train - INFO - True
2024-04-07 11:22:42,257 - train - INFO - alphas:tensor([0.7498, 0.0164, 0.0307, 0.0481, 0.1551], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,258 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,258 - train - INFO - True
2024-04-07 11:22:42,259 - train - INFO - alphas:tensor([0.4627, 0.0049, 0.0123, 0.0428, 0.4773], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,260 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,260 - train - INFO - True
2024-04-07 11:22:42,261 - train - INFO - alphas:tensor([0.5088, 0.0100, 0.0386, 0.4426], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,262 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,263 - train - INFO - True
2024-04-07 11:22:42,264 - train - INFO - alphas:tensor([0.4412, 0.0104, 0.0261, 0.5223], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,265 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,265 - train - INFO - True
2024-04-07 11:22:42,266 - train - INFO - alphas:tensor([0.4480, 0.0060, 0.0328, 0.5133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,267 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,267 - train - INFO - True
2024-04-07 11:22:42,268 - train - INFO - alphas:tensor([0.5425, 0.0104, 0.0264, 0.4207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,269 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,270 - train - INFO - True
2024-04-07 11:22:42,271 - train - INFO - alphas:tensor([0.5994, 0.0048, 0.0074, 0.0270, 0.3615], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,272 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,273 - train - INFO - True
2024-04-07 11:22:42,274 - train - INFO - alphas:tensor([0.2376, 0.0025, 0.0018, 0.0284, 0.7297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,275 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,275 - train - INFO - True
2024-04-07 11:22:42,276 - train - INFO - alphas:tensor([0.2459, 0.0015, 0.0022, 0.0203, 0.7300], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,277 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,277 - train - INFO - True
2024-04-07 11:22:42,279 - train - INFO - alphas:tensor([0.2456, 0.0009, 0.0018, 0.0241, 0.7276], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,280 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,280 - train - INFO - True
2024-04-07 11:22:42,281 - train - INFO - alphas:tensor([0.2349, 0.0020, 0.0020, 0.0297, 0.7314], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,282 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,282 - train - INFO - True
2024-04-07 11:22:42,283 - train - INFO - alphas:tensor([0.5911, 0.0015, 0.0040, 0.0230, 0.3804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,285 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,285 - train - INFO - True
2024-04-07 11:22:42,286 - train - INFO - alphas:tensor([0.7100, 0.0021, 0.0029, 0.0142, 0.2708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,291 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,291 - train - INFO - True
2024-04-07 11:22:42,292 - train - INFO - alphas:tensor([0.2745, 0.0059, 0.0060, 0.0596, 0.6540], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,294 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,294 - train - INFO - True
2024-04-07 11:22:42,295 - train - INFO - alphas:tensor([0.2892, 0.0024, 0.0035, 0.0518, 0.6531], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,298 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,298 - train - INFO - True
2024-04-07 11:22:42,299 - train - INFO - alphas:tensor([0.3083, 0.0018, 0.0037, 0.0457, 0.6405], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,302 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,302 - train - INFO - True
2024-04-07 11:22:42,303 - train - INFO - alphas:tensor([0.2822, 0.0030, 0.0044, 0.0435, 0.6669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,305 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,305 - train - INFO - True
2024-04-07 11:22:42,306 - train - INFO - alphas:tensor([0.3097, 0.0020, 0.0054, 0.0464, 0.6365], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,309 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,309 - train - INFO - True
2024-04-07 11:22:42,310 - train - INFO - alphas:tensor([0.2725, 0.0057, 0.0080, 0.0516, 0.6622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,312 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,312 - train - INFO - True
2024-04-07 11:22:42,313 - train - INFO - alphas:tensor([0.6398, 0.0011, 0.0026, 0.0259, 0.3306], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,317 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,317 - train - INFO - True
2024-04-07 11:22:42,318 - train - INFO - alphas:tensor([0.5700, 0.0010, 0.0015, 0.0250, 0.4025], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,326 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,327 - train - INFO - True
2024-04-07 11:22:42,328 - train - INFO - alphas:tensor([0.4426, 0.0008, 0.0036, 0.0388, 0.5143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,332 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,332 - train - INFO - True
2024-04-07 11:22:42,333 - train - INFO - alphas:tensor([0.4531, 0.0009, 0.0016, 0.0358, 0.5086], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,337 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,337 - train - INFO - True
2024-04-07 11:22:42,338 - train - INFO - alphas:tensor([0.4698, 0.0007, 0.0016, 0.0325, 0.4953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,342 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,342 - train - INFO - True
2024-04-07 11:22:42,343 - train - INFO - alphas:tensor([0.4322, 0.0009, 0.0027, 0.0373, 0.5269], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,347 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,347 - train - INFO - True
2024-04-07 11:22:42,348 - train - INFO - alphas:tensor([0.5790, 0.0008, 0.0023, 0.0215, 0.3965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,355 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,355 - train - INFO - True
2024-04-07 11:22:42,356 - train - INFO - alphas:tensor([7.5666e-01, 5.1915e-04, 1.5860e-03, 1.4137e-02, 2.2710e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,376 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,376 - train - INFO - True
2024-04-07 11:22:42,377 - train - INFO - alphas:tensor([0.4025, 0.0011, 0.0026, 0.0486, 0.5451], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,387 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,387 - train - INFO - True
2024-04-07 11:22:42,388 - train - INFO - alphas:tensor([0.4078, 0.0006, 0.0020, 0.0371, 0.5526], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,398 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,398 - train - INFO - True
2024-04-07 11:22:42,399 - train - INFO - alphas:tensor([0.4387, 0.0007, 0.0015, 0.0405, 0.5186], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,409 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,409 - train - INFO - True
2024-04-07 11:22:42,410 - train - INFO - alphas:tensor([0.4022, 0.0009, 0.0023, 0.0404, 0.5542], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,420 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,420 - train - INFO - True
2024-04-07 11:22:42,421 - train - INFO - alphas:tensor([7.3098e-01, 4.4700e-04, 8.5922e-04, 1.1610e-02, 2.5610e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,440 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,440 - train - INFO - True
2024-04-07 11:22:42,441 - train - INFO - alphas:tensor([0.5808, 0.0042, 0.0073, 0.0464, 0.3613], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:22:42,519 - train - INFO - tau:0.29342272152521587
2024-04-07 11:22:42,519 - train - INFO - avg block size:10.06060606060606
2024-04-07 11:22:42,519 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 11:22:42,519 - train - INFO - lasso_alpha:1.6781090577648005e-06
2024-04-07 11:22:42,690 - train - INFO - Test: [   0/78]  Time: 0.167 (0.167)  Loss:  0.9492 (0.9492)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 11:22:45,758 - train - INFO - Test: [  50/78]  Time: 0.051 (0.063)  Loss:  1.5537 (1.5460)  Acc@1: 65.6250 (66.2377)  Acc@5: 90.6250 (86.4737)
2024-04-07 11:22:47,254 - train - INFO - Test: [  78/78]  Time: 0.049 (0.060)  Loss:  1.8584 (1.5672)  Acc@1: 50.0000 (65.7300)  Acc@5: 87.5000 (86.0700)
2024-04-07 11:22:47,997 - train - INFO - Train: 125 [   0/781 (  0%)]  Loss:  3.244977 (3.2450)  Time: 0.663s,  193.02/s  (0.663s,  193.02/s)  LR: 4.282e-05  Data: 0.183 (0.183)
2024-04-07 11:23:11,459 - train - INFO - Train: 125 [  50/781 (  6%)]  Loss:  3.353739 (3.4945)  Time: 0.512s,  249.97/s  (0.473s,  270.61/s)  LR: 4.282e-05  Data: 0.009 (0.011)
2024-04-07 11:23:35,289 - train - INFO - Train: 125 [ 100/781 ( 13%)]  Loss:  3.721838 (3.5063)  Time: 0.415s,  308.38/s  (0.475s,  269.60/s)  LR: 4.282e-05  Data: 0.007 (0.009)
2024-04-07 11:23:59,140 - train - INFO - Train: 125 [ 150/781 ( 19%)]  Loss:  3.690645 (3.5157)  Time: 0.409s,  312.59/s  (0.476s,  269.19/s)  LR: 4.282e-05  Data: 0.008 (0.009)
2024-04-07 11:24:22,675 - train - INFO - Train: 125 [ 200/781 ( 26%)]  Loss:  2.940659 (3.5115)  Time: 0.479s,  267.15/s  (0.474s,  269.87/s)  LR: 4.282e-05  Data: 0.010 (0.009)
2024-04-07 11:24:46,188 - train - INFO - Train: 125 [ 250/781 ( 32%)]  Loss:  3.433769 (3.4973)  Time: 0.463s,  276.67/s  (0.473s,  270.33/s)  LR: 4.282e-05  Data: 0.005 (0.008)
2024-04-07 11:25:10,252 - train - INFO - Train: 125 [ 300/781 ( 38%)]  Loss:  3.291572 (3.5003)  Time: 0.499s,  256.39/s  (0.475s,  269.60/s)  LR: 4.282e-05  Data: 0.009 (0.008)
2024-04-07 11:25:33,806 - train - INFO - Train: 125 [ 350/781 ( 45%)]  Loss:  3.361957 (3.4937)  Time: 0.485s,  263.79/s  (0.474s,  269.90/s)  LR: 4.282e-05  Data: 0.008 (0.008)
2024-04-07 11:25:57,346 - train - INFO - Train: 125 [ 400/781 ( 51%)]  Loss:  3.323786 (3.4902)  Time: 0.444s,  288.61/s  (0.474s,  270.15/s)  LR: 4.282e-05  Data: 0.009 (0.008)
2024-04-07 11:26:20,565 - train - INFO - Train: 125 [ 450/781 ( 58%)]  Loss:  3.660883 (3.4864)  Time: 0.464s,  275.64/s  (0.473s,  270.75/s)  LR: 4.282e-05  Data: 0.006 (0.008)
2024-04-07 11:26:43,938 - train - INFO - Train: 125 [ 500/781 ( 64%)]  Loss:  3.667081 (3.4835)  Time: 0.480s,  266.49/s  (0.472s,  271.06/s)  LR: 4.282e-05  Data: 0.009 (0.008)
2024-04-07 11:27:06,390 - train - INFO - Train: 125 [ 550/781 ( 71%)]  Loss:  3.494571 (3.4802)  Time: 0.402s,  318.71/s  (0.470s,  272.27/s)  LR: 4.282e-05  Data: 0.005 (0.008)
2024-04-07 11:27:29,318 - train - INFO - Train: 125 [ 600/781 ( 77%)]  Loss:  3.264890 (3.4780)  Time: 0.477s,  268.10/s  (0.469s,  272.83/s)  LR: 4.282e-05  Data: 0.004 (0.008)
2024-04-07 11:27:51,959 - train - INFO - Train: 125 [ 650/781 ( 83%)]  Loss:  3.210796 (3.4817)  Time: 0.499s,  256.61/s  (0.468s,  273.56/s)  LR: 4.282e-05  Data: 0.007 (0.008)
2024-04-07 11:28:15,354 - train - INFO - Train: 125 [ 700/781 ( 90%)]  Loss:  3.517161 (3.4798)  Time: 0.498s,  257.23/s  (0.468s,  273.56/s)  LR: 4.282e-05  Data: 0.008 (0.008)
2024-04-07 11:28:38,285 - train - INFO - Train: 125 [ 750/781 ( 96%)]  Loss:  3.243107 (3.4793)  Time: 0.452s,  283.44/s  (0.467s,  273.93/s)  LR: 4.282e-05  Data: 0.009 (0.008)
2024-04-07 11:28:51,415 - train - INFO - Train: 125 [ 780/781 (100%)]  Loss:  3.296893 (3.4779)  Time: 0.439s,  291.60/s  (0.466s,  274.60/s)  LR: 4.282e-05  Data: 0.000 (0.008)
2024-04-07 11:28:51,416 - train - INFO - True
2024-04-07 11:28:51,417 - train - INFO - alphas:tensor([0.7529, 0.0159, 0.0300, 0.0472, 0.1542], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,418 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,418 - train - INFO - True
2024-04-07 11:28:51,420 - train - INFO - alphas:tensor([0.4635, 0.0046, 0.0120, 0.0420, 0.4779], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,420 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,420 - train - INFO - True
2024-04-07 11:28:51,421 - train - INFO - alphas:tensor([0.5094, 0.0096, 0.0379, 0.4430], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,422 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,423 - train - INFO - True
2024-04-07 11:28:51,424 - train - INFO - alphas:tensor([0.4417, 0.0100, 0.0254, 0.5228], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,424 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,425 - train - INFO - True
2024-04-07 11:28:51,426 - train - INFO - alphas:tensor([0.4483, 0.0057, 0.0320, 0.5140], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,426 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,426 - train - INFO - True
2024-04-07 11:28:51,428 - train - INFO - alphas:tensor([0.5420, 0.0101, 0.0258, 0.4221], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,429 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,429 - train - INFO - True
2024-04-07 11:28:51,430 - train - INFO - alphas:tensor([0.6014, 0.0046, 0.0071, 0.0264, 0.3605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,431 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,432 - train - INFO - True
2024-04-07 11:28:51,433 - train - INFO - alphas:tensor([0.2366, 0.0024, 0.0017, 0.0277, 0.7316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,433 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,434 - train - INFO - True
2024-04-07 11:28:51,435 - train - INFO - alphas:tensor([0.2451, 0.0015, 0.0021, 0.0198, 0.7315], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,436 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,436 - train - INFO - True
2024-04-07 11:28:51,437 - train - INFO - alphas:tensor([0.2456, 0.0009, 0.0018, 0.0235, 0.7283], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,438 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,438 - train - INFO - True
2024-04-07 11:28:51,439 - train - INFO - alphas:tensor([0.2336, 0.0019, 0.0019, 0.0291, 0.7335], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,440 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,440 - train - INFO - True
2024-04-07 11:28:51,441 - train - INFO - alphas:tensor([0.5914, 0.0014, 0.0038, 0.0224, 0.3810], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,442 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,442 - train - INFO - True
2024-04-07 11:28:51,444 - train - INFO - alphas:tensor([0.7099, 0.0020, 0.0028, 0.0137, 0.2717], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,448 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,448 - train - INFO - True
2024-04-07 11:28:51,449 - train - INFO - alphas:tensor([0.2748, 0.0056, 0.0058, 0.0586, 0.6552], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,451 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,451 - train - INFO - True
2024-04-07 11:28:51,452 - train - INFO - alphas:tensor([0.2871, 0.0023, 0.0034, 0.0509, 0.6563], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,455 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,455 - train - INFO - True
2024-04-07 11:28:51,456 - train - INFO - alphas:tensor([0.3092, 0.0017, 0.0035, 0.0448, 0.6408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,458 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,458 - train - INFO - True
2024-04-07 11:28:51,459 - train - INFO - alphas:tensor([0.2821, 0.0029, 0.0043, 0.0428, 0.6679], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,461 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,461 - train - INFO - True
2024-04-07 11:28:51,462 - train - INFO - alphas:tensor([0.3084, 0.0019, 0.0052, 0.0457, 0.6389], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,464 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,464 - train - INFO - True
2024-04-07 11:28:51,465 - train - INFO - alphas:tensor([0.2700, 0.0055, 0.0076, 0.0507, 0.6662], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,468 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,468 - train - INFO - True
2024-04-07 11:28:51,469 - train - INFO - alphas:tensor([0.6401, 0.0010, 0.0024, 0.0253, 0.3312], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,472 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,472 - train - INFO - True
2024-04-07 11:28:51,473 - train - INFO - alphas:tensor([0.5712, 0.0009, 0.0014, 0.0244, 0.4020], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,481 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,481 - train - INFO - True
2024-04-07 11:28:51,482 - train - INFO - alphas:tensor([0.4431, 0.0008, 0.0034, 0.0381, 0.5147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,486 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,486 - train - INFO - True
2024-04-07 11:28:51,487 - train - INFO - alphas:tensor([0.4535, 0.0008, 0.0015, 0.0351, 0.5091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,491 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,491 - train - INFO - True
2024-04-07 11:28:51,492 - train - INFO - alphas:tensor([0.4687, 0.0007, 0.0015, 0.0318, 0.4973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,496 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,496 - train - INFO - True
2024-04-07 11:28:51,497 - train - INFO - alphas:tensor([0.4314, 0.0008, 0.0026, 0.0366, 0.5286], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,500 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,501 - train - INFO - True
2024-04-07 11:28:51,501 - train - INFO - alphas:tensor([0.5796, 0.0007, 0.0021, 0.0208, 0.3967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,509 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,509 - train - INFO - True
2024-04-07 11:28:51,510 - train - INFO - alphas:tensor([7.5842e-01, 4.8725e-04, 1.5055e-03, 1.3758e-02, 2.2583e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,529 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,529 - train - INFO - True
2024-04-07 11:28:51,530 - train - INFO - alphas:tensor([0.4030, 0.0011, 0.0025, 0.0479, 0.5455], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,540 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,540 - train - INFO - True
2024-04-07 11:28:51,541 - train - INFO - alphas:tensor([4.1132e-01, 5.3860e-04, 1.8760e-03, 3.6312e-02, 5.4995e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,551 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,551 - train - INFO - True
2024-04-07 11:28:51,552 - train - INFO - alphas:tensor([0.4389, 0.0007, 0.0014, 0.0395, 0.5194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,562 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,562 - train - INFO - True
2024-04-07 11:28:51,563 - train - INFO - alphas:tensor([0.4028, 0.0008, 0.0022, 0.0396, 0.5546], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,573 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,574 - train - INFO - True
2024-04-07 11:28:51,574 - train - INFO - alphas:tensor([7.3414e-01, 4.1846e-04, 8.0776e-04, 1.1231e-02, 2.5341e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,595 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,595 - train - INFO - True
2024-04-07 11:28:51,596 - train - INFO - alphas:tensor([0.5821, 0.0040, 0.0071, 0.0456, 0.3612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:28:51,674 - train - INFO - tau:0.2904884943099637
2024-04-07 11:28:51,674 - train - INFO - avg block size:10.06060606060606
2024-04-07 11:28:51,674 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 11:28:51,895 - train - INFO - Test: [   0/78]  Time: 0.217 (0.217)  Loss:  0.9380 (0.9380)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.1875 (92.1875)
2024-04-07 11:28:54,975 - train - INFO - Test: [  50/78]  Time: 0.074 (0.065)  Loss:  1.5801 (1.5470)  Acc@1: 64.8438 (65.7782)  Acc@5: 89.0625 (86.5043)
2024-04-07 11:28:56,532 - train - INFO - Test: [  78/78]  Time: 0.053 (0.061)  Loss:  1.7910 (1.5599)  Acc@1: 56.2500 (65.5700)  Acc@5: 87.5000 (86.2200)
2024-04-07 11:28:57,280 - train - INFO - Train: 126 [   0/781 (  0%)]  Loss:  3.290523 (3.2905)  Time: 0.670s,  191.09/s  (0.670s,  191.09/s)  LR: 4.030e-05  Data: 0.185 (0.185)
2024-04-07 11:29:20,010 - train - INFO - Train: 126 [  50/781 (  6%)]  Loss:  3.417940 (3.4966)  Time: 0.371s,  345.18/s  (0.459s,  278.99/s)  LR: 4.030e-05  Data: 0.006 (0.010)
2024-04-07 11:29:43,662 - train - INFO - Train: 126 [ 100/781 ( 13%)]  Loss:  3.357336 (3.4891)  Time: 0.475s,  269.58/s  (0.466s,  274.78/s)  LR: 4.030e-05  Data: 0.007 (0.009)
2024-04-07 11:30:07,006 - train - INFO - Train: 126 [ 150/781 ( 19%)]  Loss:  3.323214 (3.4687)  Time: 0.539s,  237.40/s  (0.466s,  274.58/s)  LR: 4.030e-05  Data: 0.010 (0.009)
2024-04-07 11:30:31,462 - train - INFO - Train: 126 [ 200/781 ( 26%)]  Loss:  3.803290 (3.4819)  Time: 0.461s,  277.48/s  (0.472s,  271.26/s)  LR: 4.030e-05  Data: 0.007 (0.009)
2024-04-07 11:30:54,770 - train - INFO - Train: 126 [ 250/781 ( 32%)]  Loss:  3.491521 (3.4781)  Time: 0.383s,  334.19/s  (0.471s,  271.92/s)  LR: 4.030e-05  Data: 0.009 (0.009)
2024-04-07 11:31:18,075 - train - INFO - Train: 126 [ 300/781 ( 38%)]  Loss:  3.613043 (3.4772)  Time: 0.475s,  269.25/s  (0.470s,  272.37/s)  LR: 4.030e-05  Data: 0.008 (0.008)
2024-04-07 11:31:41,909 - train - INFO - Train: 126 [ 350/781 ( 45%)]  Loss:  3.716372 (3.4794)  Time: 0.475s,  269.62/s  (0.471s,  271.82/s)  LR: 4.030e-05  Data: 0.007 (0.008)
2024-04-07 11:32:03,562 - train - INFO - Train: 126 [ 400/781 ( 51%)]  Loss:  3.648344 (3.4855)  Time: 0.417s,  306.99/s  (0.466s,  274.57/s)  LR: 4.030e-05  Data: 0.006 (0.008)
2024-04-07 11:32:27,262 - train - INFO - Train: 126 [ 450/781 ( 58%)]  Loss:  3.449206 (3.4851)  Time: 0.491s,  260.62/s  (0.467s,  274.06/s)  LR: 4.030e-05  Data: 0.008 (0.008)
2024-04-07 11:32:50,767 - train - INFO - Train: 126 [ 500/781 ( 64%)]  Loss:  3.401287 (3.4802)  Time: 0.440s,  291.19/s  (0.467s,  273.89/s)  LR: 4.030e-05  Data: 0.005 (0.008)
2024-04-07 11:33:13,363 - train - INFO - Train: 126 [ 550/781 ( 71%)]  Loss:  3.527849 (3.4834)  Time: 0.494s,  259.32/s  (0.466s,  274.71/s)  LR: 4.030e-05  Data: 0.008 (0.008)
2024-04-07 11:33:35,739 - train - INFO - Train: 126 [ 600/781 ( 77%)]  Loss:  3.062031 (3.4830)  Time: 0.504s,  253.83/s  (0.464s,  275.62/s)  LR: 4.030e-05  Data: 0.009 (0.008)
2024-04-07 11:33:59,515 - train - INFO - Train: 126 [ 650/781 ( 83%)]  Loss:  3.739815 (3.4842)  Time: 0.392s,  326.44/s  (0.465s,  275.11/s)  LR: 4.030e-05  Data: 0.005 (0.008)
2024-04-07 11:34:22,579 - train - INFO - Train: 126 [ 700/781 ( 90%)]  Loss:  3.151527 (3.4789)  Time: 0.490s,  261.21/s  (0.465s,  275.28/s)  LR: 4.030e-05  Data: 0.008 (0.008)
2024-04-07 11:34:46,324 - train - INFO - Train: 126 [ 750/781 ( 96%)]  Loss:  3.480950 (3.4772)  Time: 0.462s,  276.95/s  (0.466s,  274.89/s)  LR: 4.030e-05  Data: 0.007 (0.008)
2024-04-07 11:35:00,221 - train - INFO - Train: 126 [ 780/781 (100%)]  Loss:  3.448570 (3.4780)  Time: 0.352s,  363.22/s  (0.466s,  274.95/s)  LR: 4.030e-05  Data: 0.000 (0.008)
2024-04-07 11:35:00,222 - train - INFO - True
2024-04-07 11:35:00,225 - train - INFO - alphas:tensor([0.7563, 0.0154, 0.0292, 0.0463, 0.1529], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,226 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,226 - train - INFO - True
2024-04-07 11:35:00,228 - train - INFO - alphas:tensor([0.4638, 0.0044, 0.0116, 0.0412, 0.4790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,229 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,229 - train - INFO - True
2024-04-07 11:35:00,230 - train - INFO - alphas:tensor([0.5101, 0.0093, 0.0371, 0.4435], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,232 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,232 - train - INFO - True
2024-04-07 11:35:00,233 - train - INFO - alphas:tensor([0.4428, 0.0097, 0.0247, 0.5229], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,234 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,234 - train - INFO - True
2024-04-07 11:35:00,236 - train - INFO - alphas:tensor([0.4484, 0.0055, 0.0314, 0.5148], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,237 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,237 - train - INFO - True
2024-04-07 11:35:00,238 - train - INFO - alphas:tensor([0.5432, 0.0097, 0.0252, 0.4219], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,240 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,240 - train - INFO - True
2024-04-07 11:35:00,241 - train - INFO - alphas:tensor([0.6028, 0.0044, 0.0068, 0.0257, 0.3602], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,243 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,243 - train - INFO - True
2024-04-07 11:35:00,245 - train - INFO - alphas:tensor([0.2354, 0.0023, 0.0016, 0.0270, 0.7337], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,246 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,246 - train - INFO - True
2024-04-07 11:35:00,247 - train - INFO - alphas:tensor([0.2444, 0.0014, 0.0020, 0.0193, 0.7329], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,249 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,249 - train - INFO - True
2024-04-07 11:35:00,250 - train - INFO - alphas:tensor([0.2454, 0.0008, 0.0017, 0.0228, 0.7293], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,251 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,251 - train - INFO - True
2024-04-07 11:35:00,253 - train - INFO - alphas:tensor([0.2331, 0.0018, 0.0018, 0.0285, 0.7348], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,254 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,254 - train - INFO - True
2024-04-07 11:35:00,255 - train - INFO - alphas:tensor([0.5921, 0.0014, 0.0036, 0.0218, 0.3811], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,257 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,257 - train - INFO - True
2024-04-07 11:35:00,258 - train - INFO - alphas:tensor([0.7123, 0.0019, 0.0027, 0.0132, 0.2699], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,264 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,264 - train - INFO - True
2024-04-07 11:35:00,265 - train - INFO - alphas:tensor([0.2746, 0.0054, 0.0056, 0.0577, 0.6567], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,268 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,268 - train - INFO - True
2024-04-07 11:35:00,269 - train - INFO - alphas:tensor([0.2867, 0.0022, 0.0032, 0.0498, 0.6581], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,272 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,272 - train - INFO - True
2024-04-07 11:35:00,273 - train - INFO - alphas:tensor([0.3090, 0.0016, 0.0034, 0.0440, 0.6420], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,276 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,276 - train - INFO - True
2024-04-07 11:35:00,277 - train - INFO - alphas:tensor([0.2808, 0.0027, 0.0041, 0.0420, 0.6704], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,280 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,280 - train - INFO - True
2024-04-07 11:35:00,281 - train - INFO - alphas:tensor([0.3088, 0.0018, 0.0050, 0.0449, 0.6395], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,283 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,284 - train - INFO - True
2024-04-07 11:35:00,285 - train - INFO - alphas:tensor([0.2705, 0.0052, 0.0074, 0.0497, 0.6672], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,287 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,287 - train - INFO - True
2024-04-07 11:35:00,288 - train - INFO - alphas:tensor([0.6394, 0.0009, 0.0023, 0.0248, 0.3325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,293 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,293 - train - INFO - True
2024-04-07 11:35:00,294 - train - INFO - alphas:tensor([0.5705, 0.0009, 0.0013, 0.0240, 0.4033], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,309 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,309 - train - INFO - True
2024-04-07 11:35:00,310 - train - INFO - alphas:tensor([0.4460, 0.0007, 0.0033, 0.0374, 0.5126], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,314 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,314 - train - INFO - True
2024-04-07 11:35:00,315 - train - INFO - alphas:tensor([0.4540, 0.0008, 0.0014, 0.0344, 0.5094], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,319 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,319 - train - INFO - True
2024-04-07 11:35:00,320 - train - INFO - alphas:tensor([0.4696, 0.0006, 0.0014, 0.0310, 0.4973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,324 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,324 - train - INFO - True
2024-04-07 11:35:00,325 - train - INFO - alphas:tensor([0.4333, 0.0008, 0.0025, 0.0357, 0.5277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,329 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,329 - train - INFO - True
2024-04-07 11:35:00,330 - train - INFO - alphas:tensor([0.5809, 0.0007, 0.0020, 0.0204, 0.3960], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,337 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,338 - train - INFO - True
2024-04-07 11:35:00,338 - train - INFO - alphas:tensor([7.6008e-01, 4.5484e-04, 1.4262e-03, 1.3340e-02, 2.2470e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,358 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,358 - train - INFO - True
2024-04-07 11:35:00,359 - train - INFO - alphas:tensor([0.4048, 0.0010, 0.0024, 0.0471, 0.5448], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,369 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,369 - train - INFO - True
2024-04-07 11:35:00,370 - train - INFO - alphas:tensor([4.1149e-01, 5.0640e-04, 1.7826e-03, 3.5712e-02, 5.5051e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,380 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,381 - train - INFO - True
2024-04-07 11:35:00,381 - train - INFO - alphas:tensor([0.4418, 0.0006, 0.0014, 0.0388, 0.5175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,392 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,392 - train - INFO - True
2024-04-07 11:35:00,393 - train - INFO - alphas:tensor([0.4039, 0.0008, 0.0021, 0.0390, 0.5542], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,403 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,403 - train - INFO - True
2024-04-07 11:35:00,404 - train - INFO - alphas:tensor([7.3622e-01, 3.9063e-04, 7.5927e-04, 1.0872e-02, 2.5175e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,424 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,424 - train - INFO - True
2024-04-07 11:35:00,425 - train - INFO - alphas:tensor([0.5818, 0.0038, 0.0068, 0.0451, 0.3624], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:35:00,510 - train - INFO - tau:0.28758360936686406
2024-04-07 11:35:00,510 - train - INFO - avg block size:10.06060606060606
2024-04-07 11:35:00,511 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 11:35:00,511 - train - INFO - lasso_alpha:1.5255536888770912e-06
2024-04-07 11:35:00,735 - train - INFO - Test: [   0/78]  Time: 0.220 (0.220)  Loss:  0.9922 (0.9922)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 11:35:03,788 - train - INFO - Test: [  50/78]  Time: 0.049 (0.064)  Loss:  1.5547 (1.5716)  Acc@1: 64.8438 (65.8395)  Acc@5: 89.0625 (86.4430)
2024-04-07 11:35:05,434 - train - INFO - Test: [  78/78]  Time: 0.048 (0.062)  Loss:  1.8809 (1.5893)  Acc@1: 56.2500 (65.5400)  Acc@5: 87.5000 (86.0700)
2024-04-07 11:35:06,157 - train - INFO - Train: 127 [   0/781 (  0%)]  Loss:  3.860121 (3.8601)  Time: 0.561s,  228.20/s  (0.561s,  228.20/s)  LR: 3.788e-05  Data: 0.171 (0.171)
2024-04-07 11:35:28,663 - train - INFO - Train: 127 [  50/781 (  6%)]  Loss:  3.472441 (3.4746)  Time: 0.478s,  267.86/s  (0.452s,  283.02/s)  LR: 3.788e-05  Data: 0.008 (0.010)
2024-04-07 11:35:51,909 - train - INFO - Train: 127 [ 100/781 ( 13%)]  Loss:  3.277503 (3.4828)  Time: 0.502s,  254.98/s  (0.459s,  279.16/s)  LR: 3.788e-05  Data: 0.010 (0.009)
2024-04-07 11:36:15,423 - train - INFO - Train: 127 [ 150/781 ( 19%)]  Loss:  3.094439 (3.4819)  Time: 0.413s,  310.25/s  (0.462s,  276.82/s)  LR: 3.788e-05  Data: 0.006 (0.009)
2024-04-07 11:36:38,669 - train - INFO - Train: 127 [ 200/781 ( 26%)]  Loss:  3.189642 (3.4919)  Time: 0.479s,  267.20/s  (0.463s,  276.45/s)  LR: 3.788e-05  Data: 0.019 (0.008)
2024-04-07 11:37:02,797 - train - INFO - Train: 127 [ 250/781 ( 32%)]  Loss:  3.443288 (3.4874)  Time: 0.469s,  273.18/s  (0.467s,  274.15/s)  LR: 3.788e-05  Data: 0.009 (0.008)
2024-04-07 11:37:26,750 - train - INFO - Train: 127 [ 300/781 ( 38%)]  Loss:  3.601070 (3.4904)  Time: 0.477s,  268.57/s  (0.469s,  272.97/s)  LR: 3.788e-05  Data: 0.007 (0.008)
2024-04-07 11:37:49,230 - train - INFO - Train: 127 [ 350/781 ( 45%)]  Loss:  3.323923 (3.4881)  Time: 0.500s,  256.25/s  (0.466s,  274.58/s)  LR: 3.788e-05  Data: 0.009 (0.008)
2024-04-07 11:38:11,962 - train - INFO - Train: 127 [ 400/781 ( 51%)]  Loss:  3.432164 (3.4895)  Time: 0.507s,  252.35/s  (0.465s,  275.43/s)  LR: 3.788e-05  Data: 0.009 (0.008)
2024-04-07 11:38:35,541 - train - INFO - Train: 127 [ 450/781 ( 58%)]  Loss:  3.642504 (3.4877)  Time: 0.504s,  253.79/s  (0.465s,  274.99/s)  LR: 3.788e-05  Data: 0.009 (0.008)
2024-04-07 11:38:58,083 - train - INFO - Train: 127 [ 500/781 ( 64%)]  Loss:  3.250035 (3.4856)  Time: 0.493s,  259.41/s  (0.464s,  275.85/s)  LR: 3.788e-05  Data: 0.008 (0.008)
2024-04-07 11:39:20,772 - train - INFO - Train: 127 [ 550/781 ( 71%)]  Loss:  3.189620 (3.4879)  Time: 0.428s,  299.40/s  (0.463s,  276.41/s)  LR: 3.788e-05  Data: 0.006 (0.008)
2024-04-07 11:39:43,054 - train - INFO - Train: 127 [ 600/781 ( 77%)]  Loss:  3.858964 (3.4888)  Time: 0.497s,  257.29/s  (0.462s,  277.28/s)  LR: 3.788e-05  Data: 0.008 (0.008)
2024-04-07 11:40:06,749 - train - INFO - Train: 127 [ 650/781 ( 83%)]  Loss:  3.398598 (3.4880)  Time: 0.462s,  277.34/s  (0.463s,  276.72/s)  LR: 3.788e-05  Data: 0.008 (0.008)
2024-04-07 11:40:31,156 - train - INFO - Train: 127 [ 700/781 ( 90%)]  Loss:  3.499468 (3.4896)  Time: 0.467s,  274.29/s  (0.464s,  275.63/s)  LR: 3.788e-05  Data: 0.008 (0.008)
2024-04-07 11:40:54,402 - train - INFO - Train: 127 [ 750/781 ( 96%)]  Loss:  3.513216 (3.4865)  Time: 0.427s,  299.43/s  (0.464s,  275.61/s)  LR: 3.788e-05  Data: 0.005 (0.008)
2024-04-07 11:41:08,056 - train - INFO - Train: 127 [ 780/781 (100%)]  Loss:  3.433160 (3.4839)  Time: 0.463s,  276.61/s  (0.464s,  275.82/s)  LR: 3.788e-05  Data: 0.000 (0.008)
2024-04-07 11:41:08,057 - train - INFO - True
2024-04-07 11:41:08,059 - train - INFO - alphas:tensor([0.7604, 0.0149, 0.0285, 0.0452, 0.1510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,060 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,060 - train - INFO - True
2024-04-07 11:41:08,062 - train - INFO - alphas:tensor([0.4644, 0.0043, 0.0112, 0.0403, 0.4798], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,062 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,062 - train - INFO - True
2024-04-07 11:41:08,064 - train - INFO - alphas:tensor([0.5096, 0.0090, 0.0364, 0.4451], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,065 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,065 - train - INFO - True
2024-04-07 11:41:08,066 - train - INFO - alphas:tensor([0.4425, 0.0093, 0.0241, 0.5241], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,067 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,067 - train - INFO - True
2024-04-07 11:41:08,068 - train - INFO - alphas:tensor([0.4482, 0.0053, 0.0306, 0.5159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,069 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,069 - train - INFO - True
2024-04-07 11:41:08,071 - train - INFO - alphas:tensor([0.5444, 0.0094, 0.0245, 0.4217], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,072 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,072 - train - INFO - True
2024-04-07 11:41:08,073 - train - INFO - alphas:tensor([0.6037, 0.0042, 0.0066, 0.0250, 0.3605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,075 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,075 - train - INFO - True
2024-04-07 11:41:08,076 - train - INFO - alphas:tensor([0.2355, 0.0021, 0.0016, 0.0265, 0.7343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,077 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,077 - train - INFO - True
2024-04-07 11:41:08,078 - train - INFO - alphas:tensor([0.2426, 0.0013, 0.0019, 0.0186, 0.7356], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,079 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,079 - train - INFO - True
2024-04-07 11:41:08,081 - train - INFO - alphas:tensor([0.2438, 0.0008, 0.0016, 0.0222, 0.7317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,082 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,082 - train - INFO - True
2024-04-07 11:41:08,083 - train - INFO - alphas:tensor([0.2322, 0.0017, 0.0017, 0.0278, 0.7366], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,084 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,084 - train - INFO - True
2024-04-07 11:41:08,085 - train - INFO - alphas:tensor([0.5919, 0.0013, 0.0035, 0.0212, 0.3821], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,087 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,087 - train - INFO - True
2024-04-07 11:41:08,088 - train - INFO - alphas:tensor([0.7136, 0.0018, 0.0025, 0.0128, 0.2692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,093 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,093 - train - INFO - True
2024-04-07 11:41:08,094 - train - INFO - alphas:tensor([0.2752, 0.0052, 0.0053, 0.0567, 0.6577], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,096 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,096 - train - INFO - True
2024-04-07 11:41:08,098 - train - INFO - alphas:tensor([0.2864, 0.0021, 0.0031, 0.0489, 0.6595], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,100 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,100 - train - INFO - True
2024-04-07 11:41:08,101 - train - INFO - alphas:tensor([0.3095, 0.0015, 0.0032, 0.0434, 0.6424], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,104 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,104 - train - INFO - True
2024-04-07 11:41:08,105 - train - INFO - alphas:tensor([0.2809, 0.0026, 0.0039, 0.0413, 0.6713], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,107 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,107 - train - INFO - True
2024-04-07 11:41:08,108 - train - INFO - alphas:tensor([0.3118, 0.0017, 0.0048, 0.0440, 0.6378], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,111 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,111 - train - INFO - True
2024-04-07 11:41:08,112 - train - INFO - alphas:tensor([0.2714, 0.0050, 0.0071, 0.0488, 0.6677], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,114 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,114 - train - INFO - True
2024-04-07 11:41:08,115 - train - INFO - alphas:tensor([0.6412, 0.0009, 0.0022, 0.0242, 0.3314], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,119 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,119 - train - INFO - True
2024-04-07 11:41:08,120 - train - INFO - alphas:tensor([0.5723, 0.0008, 0.0013, 0.0233, 0.4023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,128 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,128 - train - INFO - True
2024-04-07 11:41:08,129 - train - INFO - alphas:tensor([0.4452, 0.0007, 0.0031, 0.0367, 0.5143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,134 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,134 - train - INFO - True
2024-04-07 11:41:08,135 - train - INFO - alphas:tensor([0.4555, 0.0007, 0.0013, 0.0334, 0.5090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,139 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,139 - train - INFO - True
2024-04-07 11:41:08,140 - train - INFO - alphas:tensor([0.4695, 0.0006, 0.0014, 0.0305, 0.4981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,144 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,144 - train - INFO - True
2024-04-07 11:41:08,145 - train - INFO - alphas:tensor([0.4345, 0.0007, 0.0023, 0.0350, 0.5274], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,148 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,149 - train - INFO - True
2024-04-07 11:41:08,149 - train - INFO - alphas:tensor([0.5816, 0.0006, 0.0019, 0.0197, 0.3961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,157 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,157 - train - INFO - True
2024-04-07 11:41:08,158 - train - INFO - alphas:tensor([7.6105e-01, 4.2532e-04, 1.3512e-03, 1.3004e-02, 2.2417e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,177 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,177 - train - INFO - True
2024-04-07 11:41:08,178 - train - INFO - alphas:tensor([0.4043, 0.0010, 0.0023, 0.0466, 0.5459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,188 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,188 - train - INFO - True
2024-04-07 11:41:08,189 - train - INFO - alphas:tensor([4.1154e-01, 4.7363e-04, 1.6828e-03, 3.4938e-02, 5.5136e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,199 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,199 - train - INFO - True
2024-04-07 11:41:08,200 - train - INFO - alphas:tensor([0.4406, 0.0006, 0.0013, 0.0380, 0.5196], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,210 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,211 - train - INFO - True
2024-04-07 11:41:08,211 - train - INFO - alphas:tensor([0.4045, 0.0007, 0.0020, 0.0382, 0.5545], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,221 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,222 - train - INFO - True
2024-04-07 11:41:08,222 - train - INFO - alphas:tensor([7.3583e-01, 3.6429e-04, 7.1655e-04, 1.0549e-02, 2.5254e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,242 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,242 - train - INFO - True
2024-04-07 11:41:08,243 - train - INFO - alphas:tensor([0.5837, 0.0037, 0.0066, 0.0445, 0.3615], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:08,320 - train - INFO - tau:0.2847077732731954
2024-04-07 11:41:08,320 - train - INFO - avg block size:10.06060606060606
2024-04-07 11:41:08,321 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 11:41:08,531 - train - INFO - Test: [   0/78]  Time: 0.206 (0.206)  Loss:  0.9761 (0.9761)  Acc@1: 82.0312 (82.0312)  Acc@5: 92.9688 (92.9688)
2024-04-07 11:41:11,908 - train - INFO - Test: [  50/78]  Time: 0.053 (0.070)  Loss:  1.5352 (1.5609)  Acc@1: 66.4062 (66.1765)  Acc@5: 90.6250 (86.6575)
2024-04-07 11:41:13,393 - train - INFO - Test: [  78/78]  Time: 0.053 (0.064)  Loss:  1.8398 (1.5820)  Acc@1: 62.5000 (65.7400)  Acc@5: 93.7500 (86.2300)
2024-04-07 11:41:14,055 - train - INFO - Train: 128 [   0/781 (  0%)]  Loss:  3.547143 (3.5471)  Time: 0.585s,  218.98/s  (0.585s,  218.98/s)  LR: 3.555e-05  Data: 0.193 (0.193)
2024-04-07 11:41:36,252 - train - INFO - Train: 128 [  50/781 (  6%)]  Loss:  3.198709 (3.4678)  Time: 0.368s,  347.45/s  (0.447s,  286.56/s)  LR: 3.555e-05  Data: 0.004 (0.010)
2024-04-07 11:41:59,457 - train - INFO - Train: 128 [ 100/781 ( 13%)]  Loss:  3.011119 (3.4939)  Time: 0.467s,  274.25/s  (0.455s,  281.15/s)  LR: 3.555e-05  Data: 0.008 (0.009)
2024-04-07 11:42:22,543 - train - INFO - Train: 128 [ 150/781 ( 19%)]  Loss:  3.382104 (3.4907)  Time: 0.458s,  279.42/s  (0.457s,  279.84/s)  LR: 3.555e-05  Data: 0.006 (0.008)
2024-04-07 11:42:45,488 - train - INFO - Train: 128 [ 200/781 ( 26%)]  Loss:  3.640719 (3.5029)  Time: 0.483s,  264.86/s  (0.458s,  279.62/s)  LR: 3.555e-05  Data: 0.010 (0.008)
2024-04-07 11:43:08,507 - train - INFO - Train: 128 [ 250/781 ( 32%)]  Loss:  3.693225 (3.4965)  Time: 0.492s,  260.25/s  (0.458s,  279.30/s)  LR: 3.555e-05  Data: 0.008 (0.008)
2024-04-07 11:43:32,710 - train - INFO - Train: 128 [ 300/781 ( 38%)]  Loss:  3.623253 (3.4929)  Time: 0.450s,  284.23/s  (0.463s,  276.72/s)  LR: 3.555e-05  Data: 0.007 (0.008)
2024-04-07 11:43:56,052 - train - INFO - Train: 128 [ 350/781 ( 45%)]  Loss:  3.567185 (3.4902)  Time: 0.460s,  278.52/s  (0.463s,  276.36/s)  LR: 3.555e-05  Data: 0.005 (0.008)
2024-04-07 11:44:19,709 - train - INFO - Train: 128 [ 400/781 ( 51%)]  Loss:  3.752832 (3.4872)  Time: 0.478s,  267.63/s  (0.464s,  275.62/s)  LR: 3.555e-05  Data: 0.008 (0.008)
2024-04-07 11:44:42,263 - train - INFO - Train: 128 [ 450/781 ( 58%)]  Loss:  3.752768 (3.4857)  Time: 0.543s,  235.64/s  (0.463s,  276.50/s)  LR: 3.555e-05  Data: 0.010 (0.008)
2024-04-07 11:45:05,268 - train - INFO - Train: 128 [ 500/781 ( 64%)]  Loss:  3.170471 (3.4798)  Time: 0.512s,  250.09/s  (0.463s,  276.68/s)  LR: 3.555e-05  Data: 0.008 (0.008)
2024-04-07 11:45:28,429 - train - INFO - Train: 128 [ 550/781 ( 71%)]  Loss:  3.768175 (3.4782)  Time: 0.492s,  260.30/s  (0.463s,  276.64/s)  LR: 3.555e-05  Data: 0.008 (0.008)
2024-04-07 11:45:51,651 - train - INFO - Train: 128 [ 600/781 ( 77%)]  Loss:  3.091598 (3.4799)  Time: 0.489s,  261.74/s  (0.463s,  276.56/s)  LR: 3.555e-05  Data: 0.008 (0.008)
2024-04-07 11:46:14,180 - train - INFO - Train: 128 [ 650/781 ( 83%)]  Loss:  3.255899 (3.4787)  Time: 0.451s,  283.55/s  (0.462s,  277.12/s)  LR: 3.555e-05  Data: 0.005 (0.008)
2024-04-07 11:46:37,075 - train - INFO - Train: 128 [ 700/781 ( 90%)]  Loss:  3.610964 (3.4795)  Time: 0.351s,  364.60/s  (0.462s,  277.30/s)  LR: 3.555e-05  Data: 0.005 (0.008)
2024-04-07 11:46:59,833 - train - INFO - Train: 128 [ 750/781 ( 96%)]  Loss:  3.166889 (3.4778)  Time: 0.519s,  246.70/s  (0.461s,  277.56/s)  LR: 3.555e-05  Data: 0.009 (0.008)
2024-04-07 11:47:14,011 - train - INFO - Train: 128 [ 780/781 (100%)]  Loss:  3.683271 (3.4776)  Time: 0.355s,  360.18/s  (0.462s,  277.30/s)  LR: 3.555e-05  Data: 0.000 (0.008)
2024-04-07 11:47:14,012 - train - INFO - True
2024-04-07 11:47:14,014 - train - INFO - alphas:tensor([0.7632, 0.0144, 0.0278, 0.0444, 0.1502], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,014 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,015 - train - INFO - True
2024-04-07 11:47:14,016 - train - INFO - alphas:tensor([0.4656, 0.0041, 0.0108, 0.0395, 0.4800], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,016 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,016 - train - INFO - True
2024-04-07 11:47:14,018 - train - INFO - alphas:tensor([0.5116, 0.0086, 0.0356, 0.4442], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,019 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,019 - train - INFO - True
2024-04-07 11:47:14,020 - train - INFO - alphas:tensor([0.4420, 0.0090, 0.0235, 0.5256], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,021 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,021 - train - INFO - True
2024-04-07 11:47:14,022 - train - INFO - alphas:tensor([0.4490, 0.0050, 0.0299, 0.5160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,023 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,023 - train - INFO - True
2024-04-07 11:47:14,024 - train - INFO - alphas:tensor([0.5441, 0.0091, 0.0239, 0.4229], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,025 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,025 - train - INFO - True
2024-04-07 11:47:14,026 - train - INFO - alphas:tensor([0.6058, 0.0040, 0.0063, 0.0243, 0.3596], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,027 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,028 - train - INFO - True
2024-04-07 11:47:14,029 - train - INFO - alphas:tensor([0.2340, 0.0020, 0.0015, 0.0258, 0.7367], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,030 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,030 - train - INFO - True
2024-04-07 11:47:14,031 - train - INFO - alphas:tensor([0.2417, 0.0012, 0.0018, 0.0182, 0.7370], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,032 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,032 - train - INFO - True
2024-04-07 11:47:14,033 - train - INFO - alphas:tensor([2.4202e-01, 7.2474e-04, 1.4900e-03, 2.1647e-02, 7.3412e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,034 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,034 - train - INFO - True
2024-04-07 11:47:14,035 - train - INFO - alphas:tensor([0.2309, 0.0016, 0.0016, 0.0271, 0.7388], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,036 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,036 - train - INFO - True
2024-04-07 11:47:14,037 - train - INFO - alphas:tensor([0.5939, 0.0012, 0.0033, 0.0206, 0.3809], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,038 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,038 - train - INFO - True
2024-04-07 11:47:14,039 - train - INFO - alphas:tensor([0.7156, 0.0017, 0.0024, 0.0124, 0.2679], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,045 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,045 - train - INFO - True
2024-04-07 11:47:14,046 - train - INFO - alphas:tensor([0.2737, 0.0050, 0.0051, 0.0558, 0.6604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,048 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,048 - train - INFO - True
2024-04-07 11:47:14,049 - train - INFO - alphas:tensor([0.2857, 0.0020, 0.0029, 0.0480, 0.6614], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,051 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,051 - train - INFO - True
2024-04-07 11:47:14,052 - train - INFO - alphas:tensor([0.3086, 0.0014, 0.0031, 0.0425, 0.6443], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,055 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,055 - train - INFO - True
2024-04-07 11:47:14,056 - train - INFO - alphas:tensor([0.2812, 0.0025, 0.0037, 0.0405, 0.6721], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,058 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,058 - train - INFO - True
2024-04-07 11:47:14,059 - train - INFO - alphas:tensor([0.3097, 0.0016, 0.0046, 0.0434, 0.6407], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,061 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,061 - train - INFO - True
2024-04-07 11:47:14,062 - train - INFO - alphas:tensor([0.2718, 0.0048, 0.0068, 0.0479, 0.6687], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,064 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,064 - train - INFO - True
2024-04-07 11:47:14,065 - train - INFO - alphas:tensor([0.6419, 0.0008, 0.0021, 0.0235, 0.3316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,069 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,069 - train - INFO - True
2024-04-07 11:47:14,070 - train - INFO - alphas:tensor([0.5721, 0.0008, 0.0012, 0.0227, 0.4032], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,077 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,077 - train - INFO - True
2024-04-07 11:47:14,078 - train - INFO - alphas:tensor([0.4443, 0.0006, 0.0030, 0.0360, 0.5160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,082 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,082 - train - INFO - True
2024-04-07 11:47:14,083 - train - INFO - alphas:tensor([0.4550, 0.0007, 0.0013, 0.0327, 0.5104], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,087 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,087 - train - INFO - True
2024-04-07 11:47:14,088 - train - INFO - alphas:tensor([0.4705, 0.0006, 0.0013, 0.0297, 0.4980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,091 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,092 - train - INFO - True
2024-04-07 11:47:14,092 - train - INFO - alphas:tensor([0.4335, 0.0007, 0.0022, 0.0343, 0.5293], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,096 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,096 - train - INFO - True
2024-04-07 11:47:14,097 - train - INFO - alphas:tensor([0.5816, 0.0006, 0.0018, 0.0192, 0.3968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,104 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,104 - train - INFO - True
2024-04-07 11:47:14,105 - train - INFO - alphas:tensor([7.6263e-01, 3.9563e-04, 1.2780e-03, 1.2612e-02, 2.2308e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,121 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,122 - train - INFO - True
2024-04-07 11:47:14,122 - train - INFO - alphas:tensor([0.4050, 0.0009, 0.0022, 0.0458, 0.5461], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,131 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,131 - train - INFO - True
2024-04-07 11:47:14,132 - train - INFO - alphas:tensor([4.1240e-01, 4.4496e-04, 1.6017e-03, 3.4413e-02, 5.5114e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,140 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,140 - train - INFO - True
2024-04-07 11:47:14,141 - train - INFO - alphas:tensor([0.4409, 0.0005, 0.0012, 0.0374, 0.5200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,148 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,149 - train - INFO - True
2024-04-07 11:47:14,149 - train - INFO - alphas:tensor([0.4041, 0.0007, 0.0019, 0.0377, 0.5556], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,157 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,157 - train - INFO - True
2024-04-07 11:47:14,158 - train - INFO - alphas:tensor([7.3644e-01, 3.3865e-04, 6.7477e-04, 1.0237e-02, 2.5231e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,172 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,173 - train - INFO - True
2024-04-07 11:47:14,173 - train - INFO - alphas:tensor([0.5832, 0.0035, 0.0064, 0.0439, 0.3629], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:47:14,229 - train - INFO - tau:0.28186069554046345
2024-04-07 11:47:14,229 - train - INFO - avg block size:10.06060606060606
2024-04-07 11:47:14,229 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 11:47:14,229 - train - INFO - lasso_alpha:1.3868669898882646e-06
2024-04-07 11:47:14,416 - train - INFO - Test: [   0/78]  Time: 0.183 (0.183)  Loss:  0.9785 (0.9785)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.9688 (92.9688)
2024-04-07 11:47:17,221 - train - INFO - Test: [  50/78]  Time: 0.052 (0.059)  Loss:  1.5791 (1.5534)  Acc@1: 65.6250 (66.2071)  Acc@5: 87.5000 (86.5196)
2024-04-07 11:47:18,754 - train - INFO - Test: [  78/78]  Time: 0.051 (0.057)  Loss:  1.8857 (1.5741)  Acc@1: 56.2500 (65.6800)  Acc@5: 87.5000 (86.1500)
2024-04-07 11:47:19,548 - train - INFO - Train: 129 [   0/781 (  0%)]  Loss:  3.452407 (3.4524)  Time: 0.630s,  203.11/s  (0.630s,  203.11/s)  LR: 3.332e-05  Data: 0.183 (0.183)
2024-04-07 11:47:43,239 - train - INFO - Train: 129 [  50/781 (  6%)]  Loss:  3.740948 (3.4499)  Time: 0.520s,  246.08/s  (0.477s,  268.42/s)  LR: 3.332e-05  Data: 0.009 (0.011)
2024-04-07 11:48:07,002 - train - INFO - Train: 129 [ 100/781 ( 13%)]  Loss:  3.196446 (3.4406)  Time: 0.506s,  253.13/s  (0.476s,  268.88/s)  LR: 3.332e-05  Data: 0.010 (0.010)
2024-04-07 11:48:30,089 - train - INFO - Train: 129 [ 150/781 ( 19%)]  Loss:  3.561173 (3.4314)  Time: 0.479s,  267.12/s  (0.471s,  271.59/s)  LR: 3.332e-05  Data: 0.009 (0.009)
2024-04-07 11:48:53,446 - train - INFO - Train: 129 [ 200/781 ( 26%)]  Loss:  3.236661 (3.4296)  Time: 0.466s,  274.76/s  (0.470s,  272.19/s)  LR: 3.332e-05  Data: 0.005 (0.009)
2024-04-07 11:49:16,269 - train - INFO - Train: 129 [ 250/781 ( 32%)]  Loss:  3.171590 (3.4295)  Time: 0.455s,  281.44/s  (0.468s,  273.80/s)  LR: 3.332e-05  Data: 0.013 (0.008)
2024-04-07 11:49:38,748 - train - INFO - Train: 129 [ 300/781 ( 38%)]  Loss:  3.170893 (3.4389)  Time: 0.443s,  288.64/s  (0.465s,  275.55/s)  LR: 3.332e-05  Data: 0.006 (0.008)
2024-04-07 11:50:02,255 - train - INFO - Train: 129 [ 350/781 ( 45%)]  Loss:  3.219165 (3.4394)  Time: 0.483s,  265.13/s  (0.465s,  275.08/s)  LR: 3.332e-05  Data: 0.006 (0.008)
2024-04-07 11:50:25,138 - train - INFO - Train: 129 [ 400/781 ( 51%)]  Loss:  3.501813 (3.4414)  Time: 0.460s,  278.46/s  (0.464s,  275.65/s)  LR: 3.332e-05  Data: 0.008 (0.008)
2024-04-07 11:50:48,357 - train - INFO - Train: 129 [ 450/781 ( 58%)]  Loss:  3.210835 (3.4364)  Time: 0.451s,  283.72/s  (0.464s,  275.65/s)  LR: 3.332e-05  Data: 0.006 (0.008)
2024-04-07 11:51:11,628 - train - INFO - Train: 129 [ 500/781 ( 64%)]  Loss:  3.665540 (3.4401)  Time: 0.526s,  243.27/s  (0.464s,  275.59/s)  LR: 3.332e-05  Data: 0.010 (0.008)
2024-04-07 11:51:34,958 - train - INFO - Train: 129 [ 550/781 ( 71%)]  Loss:  3.443079 (3.4422)  Time: 0.468s,  273.72/s  (0.465s,  275.48/s)  LR: 3.332e-05  Data: 0.021 (0.008)
2024-04-07 11:51:58,359 - train - INFO - Train: 129 [ 600/781 ( 77%)]  Loss:  3.256794 (3.4448)  Time: 0.495s,  258.74/s  (0.465s,  275.31/s)  LR: 3.332e-05  Data: 0.009 (0.008)
2024-04-07 11:52:20,543 - train - INFO - Train: 129 [ 650/781 ( 83%)]  Loss:  3.804975 (3.4464)  Time: 0.491s,  260.73/s  (0.463s,  276.28/s)  LR: 3.332e-05  Data: 0.005 (0.008)
2024-04-07 11:52:43,775 - train - INFO - Train: 129 [ 700/781 ( 90%)]  Loss:  3.302446 (3.4484)  Time: 0.473s,  270.59/s  (0.463s,  276.23/s)  LR: 3.332e-05  Data: 0.012 (0.008)
2024-04-07 11:53:07,185 - train - INFO - Train: 129 [ 750/781 ( 96%)]  Loss:  3.320427 (3.4500)  Time: 0.383s,  334.43/s  (0.464s,  276.04/s)  LR: 3.332e-05  Data: 0.004 (0.008)
2024-04-07 11:53:20,595 - train - INFO - Train: 129 [ 780/781 (100%)]  Loss:  3.621083 (3.4489)  Time: 0.468s,  273.25/s  (0.463s,  276.42/s)  LR: 3.332e-05  Data: 0.000 (0.008)
2024-04-07 11:53:20,596 - train - INFO - True
2024-04-07 11:53:20,597 - train - INFO - alphas:tensor([0.7667, 0.0140, 0.0271, 0.0434, 0.1488], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,598 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,598 - train - INFO - True
2024-04-07 11:53:20,599 - train - INFO - alphas:tensor([0.4640, 0.0039, 0.0105, 0.0389, 0.4828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,599 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,599 - train - INFO - True
2024-04-07 11:53:20,600 - train - INFO - alphas:tensor([0.5124, 0.0083, 0.0348, 0.4445], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,601 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,601 - train - INFO - True
2024-04-07 11:53:20,602 - train - INFO - alphas:tensor([0.4427, 0.0087, 0.0229, 0.5257], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,603 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,603 - train - INFO - True
2024-04-07 11:53:20,603 - train - INFO - alphas:tensor([0.4490, 0.0048, 0.0292, 0.5169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,604 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,604 - train - INFO - True
2024-04-07 11:53:20,605 - train - INFO - alphas:tensor([0.5454, 0.0087, 0.0233, 0.4226], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,606 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,606 - train - INFO - True
2024-04-07 11:53:20,607 - train - INFO - alphas:tensor([0.6069, 0.0038, 0.0061, 0.0237, 0.3595], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,608 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,608 - train - INFO - True
2024-04-07 11:53:20,609 - train - INFO - alphas:tensor([0.2337, 0.0019, 0.0014, 0.0251, 0.7379], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,609 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,610 - train - INFO - True
2024-04-07 11:53:20,610 - train - INFO - alphas:tensor([0.2406, 0.0012, 0.0017, 0.0176, 0.7389], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,611 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,611 - train - INFO - True
2024-04-07 11:53:20,612 - train - INFO - alphas:tensor([2.4119e-01, 6.7878e-04, 1.4100e-03, 2.1051e-02, 7.3567e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,613 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,613 - train - INFO - True
2024-04-07 11:53:20,614 - train - INFO - alphas:tensor([0.2304, 0.0015, 0.0015, 0.0264, 0.7401], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,614 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,615 - train - INFO - True
2024-04-07 11:53:20,615 - train - INFO - alphas:tensor([0.5944, 0.0012, 0.0031, 0.0200, 0.3813], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,617 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,617 - train - INFO - True
2024-04-07 11:53:20,618 - train - INFO - alphas:tensor([0.7166, 0.0016, 0.0023, 0.0120, 0.2675], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,621 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,621 - train - INFO - True
2024-04-07 11:53:20,622 - train - INFO - alphas:tensor([0.2739, 0.0048, 0.0049, 0.0550, 0.6615], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,624 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,624 - train - INFO - True
2024-04-07 11:53:20,625 - train - INFO - alphas:tensor([0.2860, 0.0019, 0.0028, 0.0470, 0.6624], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,627 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,627 - train - INFO - True
2024-04-07 11:53:20,628 - train - INFO - alphas:tensor([0.3081, 0.0014, 0.0029, 0.0417, 0.6459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,630 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,630 - train - INFO - True
2024-04-07 11:53:20,631 - train - INFO - alphas:tensor([0.2794, 0.0024, 0.0036, 0.0397, 0.6750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,632 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,633 - train - INFO - True
2024-04-07 11:53:20,634 - train - INFO - alphas:tensor([0.3090, 0.0015, 0.0044, 0.0428, 0.6422], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,635 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,635 - train - INFO - True
2024-04-07 11:53:20,636 - train - INFO - alphas:tensor([0.2700, 0.0046, 0.0065, 0.0471, 0.6718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,638 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,638 - train - INFO - True
2024-04-07 11:53:20,639 - train - INFO - alphas:tensor([0.6429, 0.0008, 0.0020, 0.0229, 0.3313], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,643 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,643 - train - INFO - True
2024-04-07 11:53:20,644 - train - INFO - alphas:tensor([0.5733, 0.0007, 0.0011, 0.0221, 0.4028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,651 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,651 - train - INFO - True
2024-04-07 11:53:20,652 - train - INFO - alphas:tensor([0.4450, 0.0006, 0.0029, 0.0352, 0.5164], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,656 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,656 - train - INFO - True
2024-04-07 11:53:20,657 - train - INFO - alphas:tensor([0.4545, 0.0006, 0.0012, 0.0321, 0.5116], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,661 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,661 - train - INFO - True
2024-04-07 11:53:20,662 - train - INFO - alphas:tensor([0.4715, 0.0005, 0.0012, 0.0290, 0.4978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,666 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,666 - train - INFO - True
2024-04-07 11:53:20,667 - train - INFO - alphas:tensor([0.4336, 0.0006, 0.0021, 0.0336, 0.5300], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,670 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,670 - train - INFO - True
2024-04-07 11:53:20,671 - train - INFO - alphas:tensor([5.8109e-01, 5.4794e-04, 1.7351e-03, 1.8765e-02, 3.9786e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,679 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,679 - train - INFO - True
2024-04-07 11:53:20,680 - train - INFO - alphas:tensor([7.6518e-01, 3.6915e-04, 1.2034e-03, 1.2186e-02, 2.2106e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,699 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,699 - train - INFO - True
2024-04-07 11:53:20,700 - train - INFO - alphas:tensor([0.4053, 0.0009, 0.0021, 0.0450, 0.5468], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,710 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,710 - train - INFO - True
2024-04-07 11:53:20,711 - train - INFO - alphas:tensor([4.1260e-01, 4.1581e-04, 1.5187e-03, 3.3683e-02, 5.5178e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,721 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,721 - train - INFO - True
2024-04-07 11:53:20,722 - train - INFO - alphas:tensor([4.4268e-01, 5.1396e-04, 1.1488e-03, 3.6537e-02, 5.1912e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,732 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,732 - train - INFO - True
2024-04-07 11:53:20,733 - train - INFO - alphas:tensor([0.4041, 0.0007, 0.0018, 0.0369, 0.5565], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,743 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,743 - train - INFO - True
2024-04-07 11:53:20,744 - train - INFO - alphas:tensor([7.3782e-01, 3.1548e-04, 6.3378e-04, 9.8807e-03, 2.5135e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,764 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,764 - train - INFO - True
2024-04-07 11:53:20,765 - train - INFO - alphas:tensor([0.5848, 0.0034, 0.0061, 0.0431, 0.3625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:20,844 - train - INFO - tau:0.2790420885850588
2024-04-07 11:53:20,844 - train - INFO - avg block size:10.06060606060606
2024-04-07 11:53:20,845 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 11:53:21,085 - train - INFO - Test: [   0/78]  Time: 0.237 (0.237)  Loss:  0.9302 (0.9302)  Acc@1: 84.3750 (84.3750)  Acc@5: 93.7500 (93.7500)
2024-04-07 11:53:24,509 - train - INFO - Test: [  50/78]  Time: 0.076 (0.072)  Loss:  1.5586 (1.5448)  Acc@1: 64.8438 (66.4062)  Acc@5: 86.7188 (86.5809)
2024-04-07 11:53:26,434 - train - INFO - Test: [  78/78]  Time: 0.050 (0.071)  Loss:  1.8281 (1.5636)  Acc@1: 50.0000 (65.7500)  Acc@5: 87.5000 (86.1800)
2024-04-07 11:53:27,121 - train - INFO - Train: 130 [   0/781 (  0%)]  Loss:  3.210011 (3.2100)  Time: 0.603s,  212.38/s  (0.603s,  212.38/s)  LR: 3.118e-05  Data: 0.166 (0.166)
2024-04-07 11:53:50,699 - train - INFO - Train: 130 [  50/781 (  6%)]  Loss:  3.151890 (3.4903)  Time: 0.392s,  326.91/s  (0.474s,  269.98/s)  LR: 3.118e-05  Data: 0.004 (0.010)
2024-04-07 11:54:14,627 - train - INFO - Train: 130 [ 100/781 ( 13%)]  Loss:  3.590595 (3.4964)  Time: 0.471s,  271.89/s  (0.476s,  268.74/s)  LR: 3.118e-05  Data: 0.007 (0.009)
2024-04-07 11:54:38,224 - train - INFO - Train: 130 [ 150/781 ( 19%)]  Loss:  3.365121 (3.4901)  Time: 0.493s,  259.80/s  (0.475s,  269.56/s)  LR: 3.118e-05  Data: 0.008 (0.009)
2024-04-07 11:55:01,576 - train - INFO - Train: 130 [ 200/781 ( 26%)]  Loss:  3.501566 (3.4806)  Time: 0.482s,  265.59/s  (0.473s,  270.67/s)  LR: 3.118e-05  Data: 0.008 (0.009)
2024-04-07 11:55:25,528 - train - INFO - Train: 130 [ 250/781 ( 32%)]  Loss:  3.850036 (3.4877)  Time: 0.486s,  263.51/s  (0.474s,  269.98/s)  LR: 3.118e-05  Data: 0.009 (0.009)
2024-04-07 11:55:49,478 - train - INFO - Train: 130 [ 300/781 ( 38%)]  Loss:  3.076505 (3.4864)  Time: 0.448s,  286.02/s  (0.475s,  269.52/s)  LR: 3.118e-05  Data: 0.009 (0.008)
2024-04-07 11:56:12,940 - train - INFO - Train: 130 [ 350/781 ( 45%)]  Loss:  3.124104 (3.4846)  Time: 0.489s,  261.61/s  (0.474s,  269.98/s)  LR: 3.118e-05  Data: 0.008 (0.008)
2024-04-07 11:56:35,497 - train - INFO - Train: 130 [ 400/781 ( 51%)]  Loss:  3.358625 (3.4814)  Time: 0.458s,  279.39/s  (0.471s,  271.63/s)  LR: 3.118e-05  Data: 0.005 (0.008)
2024-04-07 11:56:58,299 - train - INFO - Train: 130 [ 450/781 ( 58%)]  Loss:  3.427057 (3.4752)  Time: 0.480s,  266.66/s  (0.470s,  272.60/s)  LR: 3.118e-05  Data: 0.009 (0.008)
2024-04-07 11:57:21,473 - train - INFO - Train: 130 [ 500/781 ( 64%)]  Loss:  3.672973 (3.4698)  Time: 0.467s,  273.92/s  (0.469s,  272.96/s)  LR: 3.118e-05  Data: 0.006 (0.008)
2024-04-07 11:57:44,850 - train - INFO - Train: 130 [ 550/781 ( 71%)]  Loss:  3.509984 (3.4662)  Time: 0.419s,  305.63/s  (0.469s,  273.03/s)  LR: 3.118e-05  Data: 0.010 (0.008)
2024-04-07 11:58:06,457 - train - INFO - Train: 130 [ 600/781 ( 77%)]  Loss:  3.754206 (3.4687)  Time: 0.505s,  253.67/s  (0.466s,  274.82/s)  LR: 3.118e-05  Data: 0.009 (0.008)
2024-04-07 11:58:30,010 - train - INFO - Train: 130 [ 650/781 ( 83%)]  Loss:  3.236388 (3.4665)  Time: 0.471s,  271.62/s  (0.466s,  274.58/s)  LR: 3.118e-05  Data: 0.005 (0.008)
2024-04-07 11:58:52,735 - train - INFO - Train: 130 [ 700/781 ( 90%)]  Loss:  3.709273 (3.4653)  Time: 0.409s,  312.59/s  (0.465s,  275.08/s)  LR: 3.118e-05  Data: 0.006 (0.008)
2024-04-07 11:59:13,325 - train - INFO - Train: 130 [ 750/781 ( 96%)]  Loss:  3.328592 (3.4656)  Time: 0.445s,  287.45/s  (0.462s,  277.20/s)  LR: 3.118e-05  Data: 0.005 (0.008)
2024-04-07 11:59:27,802 - train - INFO - Train: 130 [ 780/781 (100%)]  Loss:  3.475928 (3.4657)  Time: 0.428s,  298.89/s  (0.463s,  276.72/s)  LR: 3.118e-05  Data: 0.000 (0.008)
2024-04-07 11:59:27,803 - train - INFO - True
2024-04-07 11:59:27,806 - train - INFO - alphas:tensor([0.7701, 0.0135, 0.0265, 0.0425, 0.1474], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,807 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,807 - train - INFO - True
2024-04-07 11:59:27,809 - train - INFO - alphas:tensor([0.4649, 0.0037, 0.0101, 0.0381, 0.4832], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,809 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,810 - train - INFO - True
2024-04-07 11:59:27,811 - train - INFO - alphas:tensor([0.5127, 0.0080, 0.0339, 0.4454], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,812 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,813 - train - INFO - True
2024-04-07 11:59:27,814 - train - INFO - alphas:tensor([0.4436, 0.0084, 0.0223, 0.5257], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,815 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,815 - train - INFO - True
2024-04-07 11:59:27,817 - train - INFO - alphas:tensor([0.4495, 0.0046, 0.0286, 0.5173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,818 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,818 - train - INFO - True
2024-04-07 11:59:27,819 - train - INFO - alphas:tensor([0.5462, 0.0084, 0.0227, 0.4227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,821 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,821 - train - INFO - True
2024-04-07 11:59:27,823 - train - INFO - alphas:tensor([0.6085, 0.0036, 0.0058, 0.0230, 0.3590], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,825 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,825 - train - INFO - True
2024-04-07 11:59:27,826 - train - INFO - alphas:tensor([0.2322, 0.0018, 0.0013, 0.0245, 0.7401], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,828 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,828 - train - INFO - True
2024-04-07 11:59:27,829 - train - INFO - alphas:tensor([0.2394, 0.0011, 0.0016, 0.0170, 0.7408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,830 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,831 - train - INFO - True
2024-04-07 11:59:27,832 - train - INFO - alphas:tensor([2.4037e-01, 6.3716e-04, 1.3363e-03, 2.0470e-02, 7.3718e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,833 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,833 - train - INFO - True
2024-04-07 11:59:27,834 - train - INFO - alphas:tensor([0.2278, 0.0014, 0.0014, 0.0258, 0.7435], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,835 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,836 - train - INFO - True
2024-04-07 11:59:27,837 - train - INFO - alphas:tensor([0.5968, 0.0011, 0.0030, 0.0194, 0.3797], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,839 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,839 - train - INFO - True
2024-04-07 11:59:27,840 - train - INFO - alphas:tensor([0.7192, 0.0015, 0.0022, 0.0115, 0.2656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,845 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,845 - train - INFO - True
2024-04-07 11:59:27,847 - train - INFO - alphas:tensor([0.2737, 0.0046, 0.0048, 0.0542, 0.6628], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,849 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,849 - train - INFO - True
2024-04-07 11:59:27,851 - train - INFO - alphas:tensor([0.2856, 0.0018, 0.0026, 0.0460, 0.6640], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,853 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,853 - train - INFO - True
2024-04-07 11:59:27,855 - train - INFO - alphas:tensor([0.3077, 0.0013, 0.0028, 0.0407, 0.6475], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,857 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,857 - train - INFO - True
2024-04-07 11:59:27,859 - train - INFO - alphas:tensor([0.2794, 0.0023, 0.0034, 0.0388, 0.6761], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,861 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,861 - train - INFO - True
2024-04-07 11:59:27,862 - train - INFO - alphas:tensor([0.3087, 0.0014, 0.0042, 0.0421, 0.6436], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,865 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,865 - train - INFO - True
2024-04-07 11:59:27,866 - train - INFO - alphas:tensor([0.2694, 0.0044, 0.0063, 0.0463, 0.6736], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,869 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,869 - train - INFO - True
2024-04-07 11:59:27,870 - train - INFO - alphas:tensor([0.6446, 0.0007, 0.0019, 0.0224, 0.3304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,874 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,874 - train - INFO - True
2024-04-07 11:59:27,875 - train - INFO - alphas:tensor([0.5746, 0.0007, 0.0011, 0.0215, 0.4022], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,884 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,884 - train - INFO - True
2024-04-07 11:59:27,886 - train - INFO - alphas:tensor([0.4448, 0.0005, 0.0027, 0.0346, 0.5174], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,890 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,890 - train - INFO - True
2024-04-07 11:59:27,891 - train - INFO - alphas:tensor([0.4548, 0.0006, 0.0011, 0.0313, 0.5121], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,895 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,896 - train - INFO - True
2024-04-07 11:59:27,896 - train - INFO - alphas:tensor([4.7258e-01, 4.9265e-04, 1.1511e-03, 2.8484e-02, 4.9729e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,901 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,901 - train - INFO - True
2024-04-07 11:59:27,902 - train - INFO - alphas:tensor([0.4348, 0.0006, 0.0020, 0.0329, 0.5297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,906 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,906 - train - INFO - True
2024-04-07 11:59:27,907 - train - INFO - alphas:tensor([5.8286e-01, 5.1176e-04, 1.6385e-03, 1.8200e-02, 3.9679e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,915 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,915 - train - INFO - True
2024-04-07 11:59:27,916 - train - INFO - alphas:tensor([7.6547e-01, 3.4470e-04, 1.1365e-03, 1.1818e-02, 2.2123e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,935 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,935 - train - INFO - True
2024-04-07 11:59:27,936 - train - INFO - alphas:tensor([0.4066, 0.0008, 0.0020, 0.0441, 0.5465], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,946 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,946 - train - INFO - True
2024-04-07 11:59:27,947 - train - INFO - alphas:tensor([4.1214e-01, 3.8737e-04, 1.4389e-03, 3.2940e-02, 5.5309e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,957 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,957 - train - INFO - True
2024-04-07 11:59:27,958 - train - INFO - alphas:tensor([4.4260e-01, 4.8163e-04, 1.0847e-03, 3.5942e-02, 5.1989e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,968 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,968 - train - INFO - True
2024-04-07 11:59:27,969 - train - INFO - alphas:tensor([0.4036, 0.0006, 0.0017, 0.0362, 0.5579], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:27,980 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:27,980 - train - INFO - True
2024-04-07 11:59:27,980 - train - INFO - alphas:tensor([7.3839e-01, 2.9355e-04, 5.9507e-04, 9.5715e-03, 2.5115e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:28,000 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:28,000 - train - INFO - True
2024-04-07 11:59:28,001 - train - INFO - alphas:tensor([0.5864, 0.0032, 0.0059, 0.0423, 0.3621], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:59:28,079 - train - INFO - tau:0.2762516676992082
2024-04-07 11:59:28,079 - train - INFO - avg block size:10.06060606060606
2024-04-07 11:59:28,080 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 11:59:28,080 - train - INFO - lasso_alpha:1.260788172625695e-06
2024-04-07 11:59:28,293 - train - INFO - Test: [   0/78]  Time: 0.210 (0.210)  Loss:  0.9336 (0.9336)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 11:59:31,772 - train - INFO - Test: [  50/78]  Time: 0.052 (0.072)  Loss:  1.5059 (1.5601)  Acc@1: 67.1875 (66.0846)  Acc@5: 91.4062 (86.4583)
2024-04-07 11:59:33,272 - train - INFO - Test: [  78/78]  Time: 0.051 (0.066)  Loss:  1.8818 (1.5753)  Acc@1: 43.7500 (65.8600)  Acc@5: 87.5000 (86.2000)
2024-04-07 11:59:33,999 - train - INFO - Train: 131 [   0/781 (  0%)]  Loss:  3.458266 (3.4583)  Time: 0.645s,  198.60/s  (0.645s,  198.60/s)  LR: 2.914e-05  Data: 0.184 (0.184)
2024-04-07 11:59:57,439 - train - INFO - Train: 131 [  50/781 (  6%)]  Loss:  3.506703 (3.4958)  Time: 0.512s,  249.90/s  (0.472s,  271.06/s)  LR: 2.914e-05  Data: 0.008 (0.011)
2024-04-07 12:00:20,295 - train - INFO - Train: 131 [ 100/781 ( 13%)]  Loss:  3.400077 (3.4712)  Time: 0.416s,  307.53/s  (0.465s,  275.43/s)  LR: 2.914e-05  Data: 0.007 (0.009)
2024-04-07 12:00:43,182 - train - INFO - Train: 131 [ 150/781 ( 19%)]  Loss:  3.236453 (3.4685)  Time: 0.470s,  272.31/s  (0.462s,  276.81/s)  LR: 2.914e-05  Data: 0.006 (0.009)
2024-04-07 12:01:06,870 - train - INFO - Train: 131 [ 200/781 ( 26%)]  Loss:  3.426682 (3.4603)  Time: 0.515s,  248.39/s  (0.465s,  275.14/s)  LR: 2.914e-05  Data: 0.008 (0.009)
2024-04-07 12:01:30,077 - train - INFO - Train: 131 [ 250/781 ( 32%)]  Loss:  3.098820 (3.4514)  Time: 0.511s,  250.65/s  (0.465s,  275.27/s)  LR: 2.914e-05  Data: 0.009 (0.008)
2024-04-07 12:01:53,547 - train - INFO - Train: 131 [ 300/781 ( 38%)]  Loss:  3.575959 (3.4530)  Time: 0.487s,  262.73/s  (0.466s,  274.84/s)  LR: 2.914e-05  Data: 0.014 (0.008)
2024-04-07 12:02:16,261 - train - INFO - Train: 131 [ 350/781 ( 45%)]  Loss:  3.561299 (3.4558)  Time: 0.459s,  278.89/s  (0.464s,  275.81/s)  LR: 2.914e-05  Data: 0.005 (0.008)
2024-04-07 12:02:39,953 - train - INFO - Train: 131 [ 400/781 ( 51%)]  Loss:  3.642144 (3.4616)  Time: 0.480s,  266.66/s  (0.465s,  275.09/s)  LR: 2.914e-05  Data: 0.010 (0.008)
2024-04-07 12:03:03,280 - train - INFO - Train: 131 [ 450/781 ( 58%)]  Loss:  3.534362 (3.4688)  Time: 0.449s,  285.38/s  (0.465s,  275.01/s)  LR: 2.914e-05  Data: 0.005 (0.008)
2024-04-07 12:03:26,543 - train - INFO - Train: 131 [ 500/781 ( 64%)]  Loss:  3.302252 (3.4661)  Time: 0.503s,  254.46/s  (0.465s,  275.02/s)  LR: 2.914e-05  Data: 0.008 (0.008)
2024-04-07 12:03:50,750 - train - INFO - Train: 131 [ 550/781 ( 71%)]  Loss:  3.363846 (3.4625)  Time: 0.516s,  248.08/s  (0.467s,  274.03/s)  LR: 2.914e-05  Data: 0.008 (0.008)
2024-04-07 12:04:13,903 - train - INFO - Train: 131 [ 600/781 ( 77%)]  Loss:  3.152820 (3.4594)  Time: 0.442s,  289.42/s  (0.467s,  274.23/s)  LR: 2.914e-05  Data: 0.009 (0.008)
2024-04-07 12:04:37,592 - train - INFO - Train: 131 [ 650/781 ( 83%)]  Loss:  3.877160 (3.4627)  Time: 0.346s,  370.13/s  (0.467s,  273.91/s)  LR: 2.914e-05  Data: 0.004 (0.008)
2024-04-07 12:05:00,963 - train - INFO - Train: 131 [ 700/781 ( 90%)]  Loss:  3.754979 (3.4612)  Time: 0.454s,  282.03/s  (0.467s,  273.91/s)  LR: 2.914e-05  Data: 0.006 (0.008)
2024-04-07 12:05:24,275 - train - INFO - Train: 131 [ 750/781 ( 96%)]  Loss:  3.801147 (3.4609)  Time: 0.465s,  275.02/s  (0.467s,  273.95/s)  LR: 2.914e-05  Data: 0.006 (0.008)
2024-04-07 12:05:38,615 - train - INFO - Train: 131 [ 780/781 (100%)]  Loss:  3.310608 (3.4578)  Time: 0.487s,  262.72/s  (0.468s,  273.71/s)  LR: 2.914e-05  Data: 0.000 (0.008)
2024-04-07 12:05:38,616 - train - INFO - True
2024-04-07 12:05:38,618 - train - INFO - alphas:tensor([0.7733, 0.0130, 0.0258, 0.0416, 0.1463], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,619 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,619 - train - INFO - True
2024-04-07 12:05:38,620 - train - INFO - alphas:tensor([0.4651, 0.0036, 0.0098, 0.0374, 0.4843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,621 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,621 - train - INFO - True
2024-04-07 12:05:38,622 - train - INFO - alphas:tensor([0.5127, 0.0077, 0.0332, 0.4463], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,623 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,623 - train - INFO - True
2024-04-07 12:05:38,624 - train - INFO - alphas:tensor([0.4428, 0.0080, 0.0217, 0.5275], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,625 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,625 - train - INFO - True
2024-04-07 12:05:38,626 - train - INFO - alphas:tensor([0.4504, 0.0044, 0.0279, 0.5173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,627 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,627 - train - INFO - True
2024-04-07 12:05:38,628 - train - INFO - alphas:tensor([0.5466, 0.0081, 0.0221, 0.4231], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,629 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,629 - train - INFO - True
2024-04-07 12:05:38,630 - train - INFO - alphas:tensor([0.6099, 0.0034, 0.0056, 0.0224, 0.3587], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,632 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,632 - train - INFO - True
2024-04-07 12:05:38,633 - train - INFO - alphas:tensor([0.2317, 0.0017, 0.0013, 0.0239, 0.7413], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,634 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,634 - train - INFO - True
2024-04-07 12:05:38,635 - train - INFO - alphas:tensor([0.2384, 0.0010, 0.0016, 0.0165, 0.7425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,636 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,636 - train - INFO - True
2024-04-07 12:05:38,637 - train - INFO - alphas:tensor([2.3991e-01, 5.9780e-04, 1.2671e-03, 1.9898e-02, 7.3832e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,638 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,638 - train - INFO - True
2024-04-07 12:05:38,639 - train - INFO - alphas:tensor([0.2271, 0.0014, 0.0014, 0.0251, 0.7450], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,640 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,640 - train - INFO - True
2024-04-07 12:05:38,641 - train - INFO - alphas:tensor([0.5969, 0.0010, 0.0028, 0.0189, 0.3803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,643 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,643 - train - INFO - True
2024-04-07 12:05:38,644 - train - INFO - alphas:tensor([0.7204, 0.0014, 0.0020, 0.0111, 0.2650], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,648 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,648 - train - INFO - True
2024-04-07 12:05:38,649 - train - INFO - alphas:tensor([0.2733, 0.0044, 0.0046, 0.0534, 0.6644], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,651 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,651 - train - INFO - True
2024-04-07 12:05:38,652 - train - INFO - alphas:tensor([0.2861, 0.0017, 0.0025, 0.0452, 0.6646], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,655 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,655 - train - INFO - True
2024-04-07 12:05:38,656 - train - INFO - alphas:tensor([0.3072, 0.0012, 0.0027, 0.0398, 0.6491], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,658 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,658 - train - INFO - True
2024-04-07 12:05:38,659 - train - INFO - alphas:tensor([0.2793, 0.0021, 0.0033, 0.0381, 0.6773], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,661 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,661 - train - INFO - True
2024-04-07 12:05:38,662 - train - INFO - alphas:tensor([0.3087, 0.0014, 0.0041, 0.0412, 0.6447], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,664 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,664 - train - INFO - True
2024-04-07 12:05:38,665 - train - INFO - alphas:tensor([0.2694, 0.0042, 0.0060, 0.0454, 0.6750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,667 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,668 - train - INFO - True
2024-04-07 12:05:38,669 - train - INFO - alphas:tensor([0.6461, 0.0007, 0.0018, 0.0217, 0.3297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,672 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,672 - train - INFO - True
2024-04-07 12:05:38,673 - train - INFO - alphas:tensor([0.5754, 0.0006, 0.0010, 0.0209, 0.4020], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,681 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,681 - train - INFO - True
2024-04-07 12:05:38,682 - train - INFO - alphas:tensor([4.4596e-01, 5.1025e-04, 2.6022e-03, 3.3746e-02, 5.1718e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,685 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,686 - train - INFO - True
2024-04-07 12:05:38,687 - train - INFO - alphas:tensor([0.4552, 0.0006, 0.0011, 0.0307, 0.5125], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,690 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,690 - train - INFO - True
2024-04-07 12:05:38,691 - train - INFO - alphas:tensor([4.7346e-01, 4.6145e-04, 1.0863e-03, 2.7837e-02, 4.9716e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,695 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,695 - train - INFO - True
2024-04-07 12:05:38,696 - train - INFO - alphas:tensor([0.4350, 0.0006, 0.0019, 0.0322, 0.5304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,700 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,700 - train - INFO - True
2024-04-07 12:05:38,701 - train - INFO - alphas:tensor([5.8341e-01, 4.7855e-04, 1.5539e-03, 1.7761e-02, 3.9680e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,708 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,708 - train - INFO - True
2024-04-07 12:05:38,709 - train - INFO - alphas:tensor([7.6645e-01, 3.2128e-04, 1.0731e-03, 1.1439e-02, 2.2072e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,729 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,729 - train - INFO - True
2024-04-07 12:05:38,730 - train - INFO - alphas:tensor([0.4057, 0.0008, 0.0019, 0.0435, 0.5482], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,740 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,740 - train - INFO - True
2024-04-07 12:05:38,741 - train - INFO - alphas:tensor([4.1066e-01, 3.6215e-04, 1.3643e-03, 3.2331e-02, 5.5529e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,751 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,751 - train - INFO - True
2024-04-07 12:05:38,752 - train - INFO - alphas:tensor([4.4221e-01, 4.5007e-04, 1.0203e-03, 3.5368e-02, 5.2095e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,762 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,762 - train - INFO - True
2024-04-07 12:05:38,763 - train - INFO - alphas:tensor([0.4034, 0.0006, 0.0016, 0.0354, 0.5590], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,773 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,773 - train - INFO - True
2024-04-07 12:05:38,774 - train - INFO - alphas:tensor([7.4007e-01, 2.7265e-04, 5.5777e-04, 9.2536e-03, 2.4985e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,793 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,793 - train - INFO - True
2024-04-07 12:05:38,794 - train - INFO - alphas:tensor([0.5869, 0.0031, 0.0057, 0.0416, 0.3627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:38,872 - train - INFO - tau:0.27348915102221616
2024-04-07 12:05:38,872 - train - INFO - avg block size:10.06060606060606
2024-04-07 12:05:38,873 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 12:05:39,033 - train - INFO - Test: [   0/78]  Time: 0.156 (0.156)  Loss:  0.9487 (0.9487)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 12:05:41,973 - train - INFO - Test: [  50/78]  Time: 0.053 (0.061)  Loss:  1.5674 (1.5429)  Acc@1: 64.8438 (66.1765)  Acc@5: 90.6250 (86.5656)
2024-04-07 12:05:43,459 - train - INFO - Test: [  78/78]  Time: 0.051 (0.058)  Loss:  1.8271 (1.5666)  Acc@1: 56.2500 (65.7000)  Acc@5: 87.5000 (86.1800)
2024-04-07 12:05:44,184 - train - INFO - Train: 132 [   0/781 (  0%)]  Loss:  3.407608 (3.4076)  Time: 0.651s,  196.67/s  (0.651s,  196.67/s)  LR: 2.720e-05  Data: 0.173 (0.173)
2024-04-07 12:06:07,600 - train - INFO - Train: 132 [  50/781 (  6%)]  Loss:  3.633603 (3.5155)  Time: 0.464s,  275.63/s  (0.472s,  271.26/s)  LR: 2.720e-05  Data: 0.016 (0.011)
2024-04-07 12:06:31,296 - train - INFO - Train: 132 [ 100/781 ( 13%)]  Loss:  3.245790 (3.4967)  Time: 0.485s,  263.71/s  (0.473s,  270.69/s)  LR: 2.720e-05  Data: 0.009 (0.009)
2024-04-07 12:06:55,712 - train - INFO - Train: 132 [ 150/781 ( 19%)]  Loss:  3.355287 (3.4848)  Time: 0.501s,  255.30/s  (0.478s,  267.80/s)  LR: 2.720e-05  Data: 0.008 (0.009)
2024-04-07 12:07:19,527 - train - INFO - Train: 132 [ 200/781 ( 26%)]  Loss:  3.670303 (3.4900)  Time: 0.505s,  253.24/s  (0.478s,  268.04/s)  LR: 2.720e-05  Data: 0.009 (0.009)
2024-04-07 12:07:42,079 - train - INFO - Train: 132 [ 250/781 ( 32%)]  Loss:  3.392426 (3.4891)  Time: 0.394s,  325.10/s  (0.472s,  271.04/s)  LR: 2.720e-05  Data: 0.006 (0.008)
2024-04-07 12:08:04,113 - train - INFO - Train: 132 [ 300/781 ( 38%)]  Loss:  3.276774 (3.4887)  Time: 0.363s,  352.46/s  (0.467s,  274.08/s)  LR: 2.720e-05  Data: 0.010 (0.008)
2024-04-07 12:08:27,850 - train - INFO - Train: 132 [ 350/781 ( 45%)]  Loss:  3.312045 (3.4956)  Time: 0.504s,  254.02/s  (0.468s,  273.44/s)  LR: 2.720e-05  Data: 0.007 (0.008)
2024-04-07 12:08:50,894 - train - INFO - Train: 132 [ 400/781 ( 51%)]  Loss:  3.452021 (3.4929)  Time: 0.490s,  261.45/s  (0.467s,  273.97/s)  LR: 2.720e-05  Data: 0.009 (0.008)
2024-04-07 12:09:14,473 - train - INFO - Train: 132 [ 450/781 ( 58%)]  Loss:  3.633439 (3.4867)  Time: 0.495s,  258.34/s  (0.468s,  273.69/s)  LR: 2.720e-05  Data: 0.010 (0.008)
2024-04-07 12:09:37,481 - train - INFO - Train: 132 [ 500/781 ( 64%)]  Loss:  3.186374 (3.4823)  Time: 0.447s,  286.62/s  (0.467s,  274.13/s)  LR: 2.720e-05  Data: 0.005 (0.008)
2024-04-07 12:10:01,652 - train - INFO - Train: 132 [ 550/781 ( 71%)]  Loss:  3.549400 (3.4789)  Time: 0.505s,  253.65/s  (0.468s,  273.26/s)  LR: 2.720e-05  Data: 0.007 (0.008)
2024-04-07 12:10:24,713 - train - INFO - Train: 132 [ 600/781 ( 77%)]  Loss:  3.657135 (3.4798)  Time: 0.488s,  262.19/s  (0.468s,  273.61/s)  LR: 2.720e-05  Data: 0.008 (0.008)
2024-04-07 12:10:46,955 - train - INFO - Train: 132 [ 650/781 ( 83%)]  Loss:  3.576164 (3.4790)  Time: 0.365s,  350.39/s  (0.466s,  274.65/s)  LR: 2.720e-05  Data: 0.004 (0.008)
2024-04-07 12:11:10,535 - train - INFO - Train: 132 [ 700/781 ( 90%)]  Loss:  3.451223 (3.4766)  Time: 0.486s,  263.62/s  (0.466s,  274.42/s)  LR: 2.720e-05  Data: 0.006 (0.008)
2024-04-07 12:11:33,501 - train - INFO - Train: 132 [ 750/781 ( 96%)]  Loss:  3.713875 (3.4755)  Time: 0.401s,  319.24/s  (0.466s,  274.70/s)  LR: 2.720e-05  Data: 0.006 (0.008)
2024-04-07 12:11:46,877 - train - INFO - Train: 132 [ 780/781 (100%)]  Loss:  3.435807 (3.4751)  Time: 0.447s,  286.11/s  (0.465s,  275.15/s)  LR: 2.720e-05  Data: 0.000 (0.008)
2024-04-07 12:11:46,878 - train - INFO - True
2024-04-07 12:11:46,880 - train - INFO - alphas:tensor([0.7765, 0.0126, 0.0252, 0.0408, 0.1450], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,881 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,881 - train - INFO - True
2024-04-07 12:11:46,883 - train - INFO - alphas:tensor([0.4650, 0.0034, 0.0095, 0.0365, 0.4856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,884 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,884 - train - INFO - True
2024-04-07 12:11:46,885 - train - INFO - alphas:tensor([0.5132, 0.0074, 0.0324, 0.4470], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,887 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,887 - train - INFO - True
2024-04-07 12:11:46,888 - train - INFO - alphas:tensor([0.4437, 0.0077, 0.0211, 0.5275], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,889 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,889 - train - INFO - True
2024-04-07 12:11:46,891 - train - INFO - alphas:tensor([0.4510, 0.0042, 0.0272, 0.5176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,891 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,891 - train - INFO - True
2024-04-07 12:11:46,893 - train - INFO - alphas:tensor([0.5478, 0.0078, 0.0215, 0.4229], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,894 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,894 - train - INFO - True
2024-04-07 12:11:46,896 - train - INFO - alphas:tensor([0.6102, 0.0033, 0.0054, 0.0218, 0.3594], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,897 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,898 - train - INFO - True
2024-04-07 12:11:46,899 - train - INFO - alphas:tensor([0.2308, 0.0016, 0.0012, 0.0232, 0.7431], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,900 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,900 - train - INFO - True
2024-04-07 12:11:46,901 - train - INFO - alphas:tensor([0.2377, 0.0010, 0.0015, 0.0160, 0.7438], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,902 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,903 - train - INFO - True
2024-04-07 12:11:46,904 - train - INFO - alphas:tensor([2.3856e-01, 5.5821e-04, 1.1931e-03, 1.9352e-02, 7.4033e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,905 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,905 - train - INFO - True
2024-04-07 12:11:46,906 - train - INFO - alphas:tensor([0.2261, 0.0013, 0.0013, 0.0245, 0.7468], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,907 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,908 - train - INFO - True
2024-04-07 12:11:46,909 - train - INFO - alphas:tensor([0.5982, 0.0010, 0.0027, 0.0183, 0.3798], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,910 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,911 - train - INFO - True
2024-04-07 12:11:46,912 - train - INFO - alphas:tensor([0.7228, 0.0013, 0.0019, 0.0107, 0.2632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,917 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,917 - train - INFO - True
2024-04-07 12:11:46,918 - train - INFO - alphas:tensor([0.2725, 0.0042, 0.0044, 0.0527, 0.6662], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,921 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,921 - train - INFO - True
2024-04-07 12:11:46,922 - train - INFO - alphas:tensor([0.2858, 0.0016, 0.0024, 0.0444, 0.6659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,925 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,925 - train - INFO - True
2024-04-07 12:11:46,926 - train - INFO - alphas:tensor([0.3064, 0.0011, 0.0025, 0.0389, 0.6510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,929 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,929 - train - INFO - True
2024-04-07 12:11:46,930 - train - INFO - alphas:tensor([0.2787, 0.0020, 0.0031, 0.0372, 0.6789], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,936 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,936 - train - INFO - True
2024-04-07 12:11:46,937 - train - INFO - alphas:tensor([0.3094, 0.0013, 0.0039, 0.0404, 0.6450], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,939 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,939 - train - INFO - True
2024-04-07 12:11:46,941 - train - INFO - alphas:tensor([0.2694, 0.0040, 0.0058, 0.0446, 0.6762], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,943 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,943 - train - INFO - True
2024-04-07 12:11:46,944 - train - INFO - alphas:tensor([0.6467, 0.0007, 0.0017, 0.0211, 0.3297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,948 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,948 - train - INFO - True
2024-04-07 12:11:46,949 - train - INFO - alphas:tensor([0.5753, 0.0006, 0.0009, 0.0204, 0.4028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,958 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,958 - train - INFO - True
2024-04-07 12:11:46,959 - train - INFO - alphas:tensor([4.4559e-01, 4.7777e-04, 2.4842e-03, 3.2983e-02, 5.1846e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,963 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,963 - train - INFO - True
2024-04-07 12:11:46,964 - train - INFO - alphas:tensor([0.4566, 0.0005, 0.0010, 0.0300, 0.5119], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,969 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,969 - train - INFO - True
2024-04-07 12:11:46,970 - train - INFO - alphas:tensor([4.7311e-01, 4.3323e-04, 1.0247e-03, 2.7257e-02, 4.9817e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,974 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,974 - train - INFO - True
2024-04-07 12:11:46,975 - train - INFO - alphas:tensor([4.3398e-01, 5.2980e-04, 1.7925e-03, 3.1472e-02, 5.3222e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,979 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,979 - train - INFO - True
2024-04-07 12:11:46,980 - train - INFO - alphas:tensor([5.8361e-01, 4.4611e-04, 1.4742e-03, 1.7230e-02, 3.9724e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:46,987 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:46,987 - train - INFO - True
2024-04-07 12:11:46,988 - train - INFO - alphas:tensor([7.6878e-01, 2.9876e-04, 1.0083e-03, 1.1011e-02, 2.1890e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:47,007 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:47,007 - train - INFO - True
2024-04-07 12:11:47,008 - train - INFO - alphas:tensor([0.4042, 0.0007, 0.0018, 0.0428, 0.5505], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:47,019 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:47,019 - train - INFO - True
2024-04-07 12:11:47,020 - train - INFO - alphas:tensor([4.1165e-01, 3.3770e-04, 1.2897e-03, 3.1650e-02, 5.5508e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:47,030 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:47,030 - train - INFO - True
2024-04-07 12:11:47,031 - train - INFO - alphas:tensor([4.4056e-01, 4.2092e-04, 9.6175e-04, 3.4749e-02, 5.2330e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:47,041 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:47,041 - train - INFO - True
2024-04-07 12:11:47,042 - train - INFO - alphas:tensor([4.0327e-01, 5.3736e-04, 1.5210e-03, 3.4740e-02, 5.5994e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:47,052 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:47,052 - train - INFO - True
2024-04-07 12:11:47,053 - train - INFO - alphas:tensor([7.4037e-01, 2.5277e-04, 5.2318e-04, 8.9528e-03, 2.4991e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:47,072 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:47,072 - train - INFO - True
2024-04-07 12:11:47,073 - train - INFO - alphas:tensor([0.5888, 0.0029, 0.0055, 0.0409, 0.3618], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:11:47,151 - train - INFO - tau:0.270754259511994
2024-04-07 12:11:47,151 - train - INFO - avg block size:10.06060606060606
2024-04-07 12:11:47,151 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 12:11:47,152 - train - INFO - lasso_alpha:1.1461710660233588e-06
2024-04-07 12:11:47,343 - train - INFO - Test: [   0/78]  Time: 0.187 (0.187)  Loss:  0.9722 (0.9722)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 12:11:50,254 - train - INFO - Test: [  50/78]  Time: 0.078 (0.061)  Loss:  1.5645 (1.5437)  Acc@1: 65.6250 (66.4828)  Acc@5: 89.8438 (86.6422)
2024-04-07 12:11:52,072 - train - INFO - Test: [  78/78]  Time: 0.048 (0.062)  Loss:  1.8193 (1.5609)  Acc@1: 62.5000 (66.0200)  Acc@5: 93.7500 (86.2900)
2024-04-07 12:11:52,830 - train - INFO - Train: 133 [   0/781 (  0%)]  Loss:  3.339250 (3.3393)  Time: 0.649s,  197.20/s  (0.649s,  197.20/s)  LR: 2.537e-05  Data: 0.183 (0.183)
2024-04-07 12:12:14,603 - train - INFO - Train: 133 [  50/781 (  6%)]  Loss:  3.209557 (3.4136)  Time: 0.477s,  268.20/s  (0.440s,  291.17/s)  LR: 2.537e-05  Data: 0.007 (0.010)
2024-04-07 12:12:38,180 - train - INFO - Train: 133 [ 100/781 ( 13%)]  Loss:  2.953365 (3.4441)  Time: 0.448s,  285.47/s  (0.455s,  281.07/s)  LR: 2.537e-05  Data: 0.008 (0.009)
2024-04-07 12:13:00,917 - train - INFO - Train: 133 [ 150/781 ( 19%)]  Loss:  3.521406 (3.4525)  Time: 0.416s,  308.06/s  (0.455s,  281.21/s)  LR: 2.537e-05  Data: 0.005 (0.009)
2024-04-07 12:13:23,287 - train - INFO - Train: 133 [ 200/781 ( 26%)]  Loss:  3.104590 (3.4516)  Time: 0.484s,  264.25/s  (0.453s,  282.42/s)  LR: 2.537e-05  Data: 0.008 (0.008)
2024-04-07 12:13:47,095 - train - INFO - Train: 133 [ 250/781 ( 32%)]  Loss:  3.624384 (3.4535)  Time: 0.435s,  294.10/s  (0.458s,  279.60/s)  LR: 2.537e-05  Data: 0.005 (0.008)
2024-04-07 12:14:10,422 - train - INFO - Train: 133 [ 300/781 ( 38%)]  Loss:  3.607479 (3.4534)  Time: 0.452s,  283.14/s  (0.459s,  278.72/s)  LR: 2.537e-05  Data: 0.011 (0.008)
2024-04-07 12:14:34,077 - train - INFO - Train: 133 [ 350/781 ( 45%)]  Loss:  3.269164 (3.4527)  Time: 0.489s,  261.60/s  (0.461s,  277.53/s)  LR: 2.537e-05  Data: 0.026 (0.008)
2024-04-07 12:14:56,398 - train - INFO - Train: 133 [ 400/781 ( 51%)]  Loss:  3.661727 (3.4532)  Time: 0.445s,  287.63/s  (0.459s,  278.65/s)  LR: 2.537e-05  Data: 0.005 (0.008)
2024-04-07 12:15:19,441 - train - INFO - Train: 133 [ 450/781 ( 58%)]  Loss:  3.578635 (3.4487)  Time: 0.488s,  262.05/s  (0.460s,  278.55/s)  LR: 2.537e-05  Data: 0.009 (0.008)
2024-04-07 12:15:42,863 - train - INFO - Train: 133 [ 500/781 ( 64%)]  Loss:  3.535524 (3.4524)  Time: 0.439s,  291.38/s  (0.460s,  278.01/s)  LR: 2.537e-05  Data: 0.005 (0.008)
2024-04-07 12:16:05,797 - train - INFO - Train: 133 [ 550/781 ( 71%)]  Loss:  2.976171 (3.4563)  Time: 0.486s,  263.37/s  (0.460s,  278.11/s)  LR: 2.537e-05  Data: 0.008 (0.008)
2024-04-07 12:16:28,618 - train - INFO - Train: 133 [ 600/781 ( 77%)]  Loss:  3.372302 (3.4563)  Time: 0.503s,  254.28/s  (0.460s,  278.30/s)  LR: 2.537e-05  Data: 0.009 (0.008)
2024-04-07 12:16:51,678 - train - INFO - Train: 133 [ 650/781 ( 83%)]  Loss:  3.098647 (3.4555)  Time: 0.514s,  248.86/s  (0.460s,  278.25/s)  LR: 2.537e-05  Data: 0.010 (0.008)
2024-04-07 12:17:15,531 - train - INFO - Train: 133 [ 700/781 ( 90%)]  Loss:  3.412862 (3.4532)  Time: 0.475s,  269.52/s  (0.461s,  277.52/s)  LR: 2.537e-05  Data: 0.018 (0.008)
2024-04-07 12:17:38,302 - train - INFO - Train: 133 [ 750/781 ( 96%)]  Loss:  3.607590 (3.4513)  Time: 0.459s,  278.87/s  (0.461s,  277.75/s)  LR: 2.537e-05  Data: 0.008 (0.008)
2024-04-07 12:17:52,398 - train - INFO - Train: 133 [ 780/781 (100%)]  Loss:  3.079850 (3.4524)  Time: 0.460s,  278.34/s  (0.461s,  277.54/s)  LR: 2.537e-05  Data: 0.000 (0.008)
2024-04-07 12:17:52,399 - train - INFO - True
2024-04-07 12:17:52,402 - train - INFO - alphas:tensor([0.7796, 0.0122, 0.0245, 0.0399, 0.1438], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,402 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,403 - train - INFO - True
2024-04-07 12:17:52,404 - train - INFO - alphas:tensor([0.4660, 0.0032, 0.0091, 0.0357, 0.4860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,405 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,405 - train - INFO - True
2024-04-07 12:17:52,406 - train - INFO - alphas:tensor([0.5144, 0.0071, 0.0317, 0.4467], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,407 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,407 - train - INFO - True
2024-04-07 12:17:52,409 - train - INFO - alphas:tensor([0.4439, 0.0074, 0.0205, 0.5282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,410 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,410 - train - INFO - True
2024-04-07 12:17:52,411 - train - INFO - alphas:tensor([0.4507, 0.0040, 0.0265, 0.5187], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,412 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,412 - train - INFO - True
2024-04-07 12:17:52,413 - train - INFO - alphas:tensor([0.5489, 0.0075, 0.0209, 0.4227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,414 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,415 - train - INFO - True
2024-04-07 12:17:52,416 - train - INFO - alphas:tensor([0.6119, 0.0031, 0.0051, 0.0212, 0.3586], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,417 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,418 - train - INFO - True
2024-04-07 12:17:52,419 - train - INFO - alphas:tensor([0.2300, 0.0016, 0.0011, 0.0227, 0.7446], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,420 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,420 - train - INFO - True
2024-04-07 12:17:52,421 - train - INFO - alphas:tensor([0.2361, 0.0009, 0.0014, 0.0155, 0.7461], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,422 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,422 - train - INFO - True
2024-04-07 12:17:52,423 - train - INFO - alphas:tensor([2.3796e-01, 5.2314e-04, 1.1306e-03, 1.8871e-02, 7.4152e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,424 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,425 - train - INFO - True
2024-04-07 12:17:52,426 - train - INFO - alphas:tensor([0.2252, 0.0012, 0.0012, 0.0238, 0.7485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,427 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,427 - train - INFO - True
2024-04-07 12:17:52,428 - train - INFO - alphas:tensor([0.5990, 0.0009, 0.0026, 0.0178, 0.3798], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,429 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,430 - train - INFO - True
2024-04-07 12:17:52,431 - train - INFO - alphas:tensor([0.7248, 0.0013, 0.0018, 0.0103, 0.2617], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,436 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,436 - train - INFO - True
2024-04-07 12:17:52,437 - train - INFO - alphas:tensor([0.2732, 0.0040, 0.0042, 0.0520, 0.6666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,439 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,439 - train - INFO - True
2024-04-07 12:17:52,441 - train - INFO - alphas:tensor([0.2848, 0.0015, 0.0023, 0.0436, 0.6678], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,443 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,443 - train - INFO - True
2024-04-07 12:17:52,444 - train - INFO - alphas:tensor([0.3070, 0.0011, 0.0024, 0.0382, 0.6513], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,447 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,447 - train - INFO - True
2024-04-07 12:17:52,448 - train - INFO - alphas:tensor([0.2784, 0.0019, 0.0030, 0.0365, 0.6803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,450 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,450 - train - INFO - True
2024-04-07 12:17:52,451 - train - INFO - alphas:tensor([0.3082, 0.0012, 0.0037, 0.0396, 0.6473], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,454 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,454 - train - INFO - True
2024-04-07 12:17:52,455 - train - INFO - alphas:tensor([0.2696, 0.0039, 0.0056, 0.0439, 0.6771], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,457 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,457 - train - INFO - True
2024-04-07 12:17:52,458 - train - INFO - alphas:tensor([6.4838e-01, 6.1237e-04, 1.6168e-03, 2.0546e-02, 3.2884e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,462 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,462 - train - INFO - True
2024-04-07 12:17:52,463 - train - INFO - alphas:tensor([5.7723e-01, 5.5169e-04, 8.8942e-04, 1.9757e-02, 4.0157e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,472 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,472 - train - INFO - True
2024-04-07 12:17:52,473 - train - INFO - alphas:tensor([4.4563e-01, 4.4791e-04, 2.3668e-03, 3.2265e-02, 5.1929e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,477 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,477 - train - INFO - True
2024-04-07 12:17:52,478 - train - INFO - alphas:tensor([4.5740e-01, 4.8284e-04, 9.4012e-04, 2.9243e-02, 5.1193e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,482 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,482 - train - INFO - True
2024-04-07 12:17:52,483 - train - INFO - alphas:tensor([4.7326e-01, 4.0512e-04, 9.6573e-04, 2.6591e-02, 4.9878e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,487 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,487 - train - INFO - True
2024-04-07 12:17:52,488 - train - INFO - alphas:tensor([4.3467e-01, 4.9609e-04, 1.7030e-03, 3.0666e-02, 5.3247e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,492 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,492 - train - INFO - True
2024-04-07 12:17:52,493 - train - INFO - alphas:tensor([5.8515e-01, 4.1628e-04, 1.3924e-03, 1.6775e-02, 3.9627e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,500 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,500 - train - INFO - True
2024-04-07 12:17:52,501 - train - INFO - alphas:tensor([7.7010e-01, 2.7727e-04, 9.5006e-04, 1.0630e-02, 2.1804e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,521 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,521 - train - INFO - True
2024-04-07 12:17:52,522 - train - INFO - alphas:tensor([0.4055, 0.0007, 0.0017, 0.0419, 0.5502], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,532 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,532 - train - INFO - True
2024-04-07 12:17:52,533 - train - INFO - alphas:tensor([4.1091e-01, 3.1352e-04, 1.2155e-03, 3.0931e-02, 5.5663e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,543 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,543 - train - INFO - True
2024-04-07 12:17:52,544 - train - INFO - alphas:tensor([4.4189e-01, 3.9291e-04, 9.0887e-04, 3.4096e-02, 5.2271e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,554 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,554 - train - INFO - True
2024-04-07 12:17:52,555 - train - INFO - alphas:tensor([4.0351e-01, 5.0296e-04, 1.4443e-03, 3.4069e-02, 5.6047e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,565 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,565 - train - INFO - True
2024-04-07 12:17:52,566 - train - INFO - alphas:tensor([7.4100e-01, 2.3521e-04, 4.9072e-04, 8.6546e-03, 2.4962e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,585 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,586 - train - INFO - True
2024-04-07 12:17:52,586 - train - INFO - alphas:tensor([0.5903, 0.0028, 0.0053, 0.0402, 0.3614], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:52,664 - train - INFO - tau:0.26804671691687404
2024-04-07 12:17:52,664 - train - INFO - avg block size:10.06060606060606
2024-04-07 12:17:52,665 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 12:17:52,872 - train - INFO - Test: [   0/78]  Time: 0.204 (0.204)  Loss:  0.9453 (0.9453)  Acc@1: 84.3750 (84.3750)  Acc@5: 93.7500 (93.7500)
2024-04-07 12:17:55,770 - train - INFO - Test: [  50/78]  Time: 0.056 (0.061)  Loss:  1.5205 (1.5511)  Acc@1: 69.5312 (66.3297)  Acc@5: 88.2812 (86.5196)
2024-04-07 12:17:57,272 - train - INFO - Test: [  78/78]  Time: 0.052 (0.058)  Loss:  1.9434 (1.5690)  Acc@1: 50.0000 (65.9800)  Acc@5: 87.5000 (86.0900)
2024-04-07 12:17:57,983 - train - INFO - Train: 134 [   0/781 (  0%)]  Loss:  3.713084 (3.7131)  Time: 0.629s,  203.49/s  (0.629s,  203.49/s)  LR: 2.363e-05  Data: 0.185 (0.185)
2024-04-07 12:18:21,978 - train - INFO - Train: 134 [  50/781 (  6%)]  Loss:  3.431398 (3.4503)  Time: 0.450s,  284.48/s  (0.483s,  265.12/s)  LR: 2.363e-05  Data: 0.005 (0.011)
2024-04-07 12:18:45,380 - train - INFO - Train: 134 [ 100/781 ( 13%)]  Loss:  3.521080 (3.4612)  Time: 0.479s,  267.38/s  (0.475s,  269.20/s)  LR: 2.363e-05  Data: 0.009 (0.009)
2024-04-07 12:19:08,505 - train - INFO - Train: 134 [ 150/781 ( 19%)]  Loss:  3.521403 (3.4722)  Time: 0.393s,  325.62/s  (0.471s,  271.66/s)  LR: 2.363e-05  Data: 0.004 (0.009)
2024-04-07 12:19:32,786 - train - INFO - Train: 134 [ 200/781 ( 26%)]  Loss:  3.111588 (3.4836)  Time: 0.482s,  265.53/s  (0.475s,  269.61/s)  LR: 2.363e-05  Data: 0.008 (0.008)
2024-04-07 12:19:56,103 - train - INFO - Train: 134 [ 250/781 ( 32%)]  Loss:  3.729025 (3.4785)  Time: 0.462s,  277.34/s  (0.473s,  270.57/s)  LR: 2.363e-05  Data: 0.006 (0.008)
2024-04-07 12:20:18,645 - train - INFO - Train: 134 [ 300/781 ( 38%)]  Loss:  3.350807 (3.4816)  Time: 0.504s,  253.94/s  (0.469s,  272.70/s)  LR: 2.363e-05  Data: 0.009 (0.008)
2024-04-07 12:20:41,787 - train - INFO - Train: 134 [ 350/781 ( 45%)]  Loss:  3.748068 (3.4786)  Time: 0.357s,  358.80/s  (0.468s,  273.25/s)  LR: 2.363e-05  Data: 0.004 (0.008)
2024-04-07 12:21:04,408 - train - INFO - Train: 134 [ 400/781 ( 51%)]  Loss:  3.519253 (3.4762)  Time: 0.429s,  298.55/s  (0.466s,  274.42/s)  LR: 2.363e-05  Data: 0.007 (0.008)
2024-04-07 12:21:27,508 - train - INFO - Train: 134 [ 450/781 ( 58%)]  Loss:  3.050678 (3.4783)  Time: 0.481s,  266.33/s  (0.466s,  274.71/s)  LR: 2.363e-05  Data: 0.007 (0.008)
2024-04-07 12:21:50,570 - train - INFO - Train: 134 [ 500/781 ( 64%)]  Loss:  3.183037 (3.4814)  Time: 0.495s,  258.56/s  (0.465s,  274.99/s)  LR: 2.363e-05  Data: 0.012 (0.008)
2024-04-07 12:22:13,669 - train - INFO - Train: 134 [ 550/781 ( 71%)]  Loss:  3.694103 (3.4822)  Time: 0.494s,  258.93/s  (0.465s,  275.18/s)  LR: 2.363e-05  Data: 0.006 (0.008)
2024-04-07 12:22:36,528 - train - INFO - Train: 134 [ 600/781 ( 77%)]  Loss:  3.597530 (3.4771)  Time: 0.386s,  331.77/s  (0.464s,  275.57/s)  LR: 2.363e-05  Data: 0.004 (0.008)
2024-04-07 12:22:59,706 - train - INFO - Train: 134 [ 650/781 ( 83%)]  Loss:  3.338861 (3.4749)  Time: 0.487s,  263.09/s  (0.464s,  275.62/s)  LR: 2.363e-05  Data: 0.008 (0.008)
2024-04-07 12:23:22,245 - train - INFO - Train: 134 [ 700/781 ( 90%)]  Loss:  3.687027 (3.4755)  Time: 0.492s,  260.39/s  (0.463s,  276.20/s)  LR: 2.363e-05  Data: 0.006 (0.008)
2024-04-07 12:23:46,507 - train - INFO - Train: 134 [ 750/781 ( 96%)]  Loss:  3.537224 (3.4750)  Time: 0.365s,  350.40/s  (0.465s,  275.34/s)  LR: 2.363e-05  Data: 0.006 (0.008)
2024-04-07 12:24:00,618 - train - INFO - Train: 134 [ 780/781 (100%)]  Loss:  3.770129 (3.4766)  Time: 0.456s,  280.86/s  (0.465s,  275.21/s)  LR: 2.363e-05  Data: 0.000 (0.008)
2024-04-07 12:24:00,619 - train - INFO - True
2024-04-07 12:24:00,621 - train - INFO - alphas:tensor([0.7834, 0.0118, 0.0238, 0.0389, 0.1421], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,621 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,621 - train - INFO - True
2024-04-07 12:24:00,623 - train - INFO - alphas:tensor([0.4660, 0.0031, 0.0088, 0.0350, 0.4872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,623 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,623 - train - INFO - True
2024-04-07 12:24:00,624 - train - INFO - alphas:tensor([0.5146, 0.0069, 0.0310, 0.4476], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,625 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,625 - train - INFO - True
2024-04-07 12:24:00,626 - train - INFO - alphas:tensor([0.4445, 0.0072, 0.0200, 0.5283], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,627 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,627 - train - INFO - True
2024-04-07 12:24:00,628 - train - INFO - alphas:tensor([0.4507, 0.0039, 0.0258, 0.5196], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,629 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,629 - train - INFO - True
2024-04-07 12:24:00,630 - train - INFO - alphas:tensor([0.5498, 0.0072, 0.0203, 0.4226], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,631 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,631 - train - INFO - True
2024-04-07 12:24:00,632 - train - INFO - alphas:tensor([0.6128, 0.0030, 0.0049, 0.0206, 0.3587], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,634 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,634 - train - INFO - True
2024-04-07 12:24:00,635 - train - INFO - alphas:tensor([0.2276, 0.0015, 0.0011, 0.0221, 0.7478], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,636 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,636 - train - INFO - True
2024-04-07 12:24:00,637 - train - INFO - alphas:tensor([0.2346, 0.0009, 0.0013, 0.0151, 0.7481], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,638 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,638 - train - INFO - True
2024-04-07 12:24:00,639 - train - INFO - alphas:tensor([2.3663e-01, 4.8975e-04, 1.0681e-03, 1.8364e-02, 7.4344e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,640 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,640 - train - INFO - True
2024-04-07 12:24:00,641 - train - INFO - alphas:tensor([0.2237, 0.0012, 0.0011, 0.0233, 0.7508], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,642 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,642 - train - INFO - True
2024-04-07 12:24:00,643 - train - INFO - alphas:tensor([0.6001, 0.0008, 0.0025, 0.0173, 0.3794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,644 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,644 - train - INFO - True
2024-04-07 12:24:00,645 - train - INFO - alphas:tensor([0.7272, 0.0012, 0.0017, 0.0099, 0.2600], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,649 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,649 - train - INFO - True
2024-04-07 12:24:00,650 - train - INFO - alphas:tensor([0.2726, 0.0039, 0.0040, 0.0511, 0.6684], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,653 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,653 - train - INFO - True
2024-04-07 12:24:00,654 - train - INFO - alphas:tensor([0.2837, 0.0014, 0.0022, 0.0427, 0.6701], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,656 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,656 - train - INFO - True
2024-04-07 12:24:00,657 - train - INFO - alphas:tensor([0.3065, 0.0010, 0.0023, 0.0374, 0.6528], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,659 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,659 - train - INFO - True
2024-04-07 12:24:00,660 - train - INFO - alphas:tensor([0.2784, 0.0018, 0.0028, 0.0356, 0.6813], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,662 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,662 - train - INFO - True
2024-04-07 12:24:00,663 - train - INFO - alphas:tensor([0.3067, 0.0012, 0.0036, 0.0388, 0.6499], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,665 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,665 - train - INFO - True
2024-04-07 12:24:00,666 - train - INFO - alphas:tensor([0.2691, 0.0037, 0.0054, 0.0429, 0.6790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,668 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,668 - train - INFO - True
2024-04-07 12:24:00,669 - train - INFO - alphas:tensor([6.4878e-01, 5.7464e-04, 1.5378e-03, 1.9996e-02, 3.2911e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,673 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,673 - train - INFO - True
2024-04-07 12:24:00,674 - train - INFO - alphas:tensor([5.7796e-01, 5.1635e-04, 8.3593e-04, 1.9194e-02, 4.0150e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,681 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,681 - train - INFO - True
2024-04-07 12:24:00,682 - train - INFO - alphas:tensor([4.4730e-01, 4.1822e-04, 2.2462e-03, 3.1486e-02, 5.1855e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,686 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,686 - train - INFO - True
2024-04-07 12:24:00,687 - train - INFO - alphas:tensor([4.5760e-01, 4.5156e-04, 8.8374e-04, 2.8535e-02, 5.1253e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,691 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,691 - train - INFO - True
2024-04-07 12:24:00,692 - train - INFO - alphas:tensor([4.7332e-01, 3.7801e-04, 9.1262e-04, 2.5956e-02, 4.9943e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,696 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,696 - train - INFO - True
2024-04-07 12:24:00,697 - train - INFO - alphas:tensor([4.3545e-01, 4.6548e-04, 1.6141e-03, 2.9874e-02, 5.3259e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,701 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,701 - train - INFO - True
2024-04-07 12:24:00,702 - train - INFO - alphas:tensor([5.8558e-01, 3.8759e-04, 1.3159e-03, 1.6282e-02, 3.9643e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,709 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,709 - train - INFO - True
2024-04-07 12:24:00,710 - train - INFO - alphas:tensor([7.7171e-01, 2.5732e-04, 8.9476e-04, 1.0267e-02, 2.1687e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,730 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,730 - train - INFO - True
2024-04-07 12:24:00,731 - train - INFO - alphas:tensor([0.4048, 0.0006, 0.0016, 0.0412, 0.5517], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,741 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,741 - train - INFO - True
2024-04-07 12:24:00,742 - train - INFO - alphas:tensor([4.1125e-01, 2.9198e-04, 1.1473e-03, 3.0200e-02, 5.5711e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,752 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,752 - train - INFO - True
2024-04-07 12:24:00,753 - train - INFO - alphas:tensor([4.4153e-01, 3.6643e-04, 8.5437e-04, 3.3323e-02, 5.2392e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,763 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,763 - train - INFO - True
2024-04-07 12:24:00,764 - train - INFO - alphas:tensor([4.0293e-01, 4.7012e-04, 1.3640e-03, 3.3384e-02, 5.6186e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,774 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,774 - train - INFO - True
2024-04-07 12:24:00,775 - train - INFO - alphas:tensor([7.4209e-01, 2.1936e-04, 4.6058e-04, 8.4035e-03, 2.4883e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,795 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,795 - train - INFO - True
2024-04-07 12:24:00,796 - train - INFO - alphas:tensor([0.5904, 0.0027, 0.0051, 0.0396, 0.3622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:24:00,873 - train - INFO - tau:0.2653662497477053
2024-04-07 12:24:00,874 - train - INFO - avg block size:10.06060606060606
2024-04-07 12:24:00,874 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 12:24:00,874 - train - INFO - lasso_alpha:1.0419736963848717e-06
2024-04-07 12:24:01,090 - train - INFO - Test: [   0/78]  Time: 0.212 (0.212)  Loss:  1.0000 (1.0000)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.1875 (92.1875)
2024-04-07 12:24:04,002 - train - INFO - Test: [  50/78]  Time: 0.113 (0.061)  Loss:  1.5439 (1.5482)  Acc@1: 65.6250 (66.4522)  Acc@5: 88.2812 (86.4583)
2024-04-07 12:24:05,986 - train - INFO - Test: [  78/78]  Time: 0.049 (0.065)  Loss:  1.8418 (1.5651)  Acc@1: 50.0000 (66.0800)  Acc@5: 87.5000 (86.2000)
2024-04-07 12:24:06,688 - train - INFO - Train: 135 [   0/781 (  0%)]  Loss:  3.355336 (3.3553)  Time: 0.621s,  206.17/s  (0.621s,  206.17/s)  LR: 2.199e-05  Data: 0.163 (0.163)
2024-04-07 12:24:30,196 - train - INFO - Train: 135 [  50/781 (  6%)]  Loss:  3.461092 (3.4663)  Time: 0.481s,  266.09/s  (0.473s,  270.56/s)  LR: 2.199e-05  Data: 0.006 (0.011)
2024-04-07 12:24:54,271 - train - INFO - Train: 135 [ 100/781 ( 13%)]  Loss:  2.986678 (3.4594)  Time: 0.451s,  283.88/s  (0.477s,  268.21/s)  LR: 2.199e-05  Data: 0.007 (0.009)
2024-04-07 12:25:17,807 - train - INFO - Train: 135 [ 150/781 ( 19%)]  Loss:  3.407386 (3.4455)  Time: 0.495s,  258.79/s  (0.475s,  269.44/s)  LR: 2.199e-05  Data: 0.008 (0.009)
2024-04-07 12:25:41,560 - train - INFO - Train: 135 [ 200/781 ( 26%)]  Loss:  3.328140 (3.4381)  Time: 0.477s,  268.35/s  (0.475s,  269.44/s)  LR: 2.199e-05  Data: 0.014 (0.008)
2024-04-07 12:26:05,694 - train - INFO - Train: 135 [ 250/781 ( 32%)]  Loss:  3.097883 (3.4360)  Time: 0.516s,  248.13/s  (0.477s,  268.59/s)  LR: 2.199e-05  Data: 0.009 (0.008)
2024-04-07 12:26:29,560 - train - INFO - Train: 135 [ 300/781 ( 38%)]  Loss:  3.528311 (3.4324)  Time: 0.472s,  271.16/s  (0.477s,  268.52/s)  LR: 2.199e-05  Data: 0.006 (0.008)
2024-04-07 12:26:53,174 - train - INFO - Train: 135 [ 350/781 ( 45%)]  Loss:  3.439310 (3.4341)  Time: 0.501s,  255.61/s  (0.476s,  268.88/s)  LR: 2.199e-05  Data: 0.008 (0.008)
2024-04-07 12:27:16,818 - train - INFO - Train: 135 [ 400/781 ( 51%)]  Loss:  3.673935 (3.4372)  Time: 0.511s,  250.30/s  (0.476s,  269.10/s)  LR: 2.199e-05  Data: 0.009 (0.008)
2024-04-07 12:27:40,779 - train - INFO - Train: 135 [ 450/781 ( 58%)]  Loss:  3.542771 (3.4345)  Time: 0.468s,  273.46/s  (0.476s,  268.88/s)  LR: 2.199e-05  Data: 0.007 (0.008)
2024-04-07 12:28:05,166 - train - INFO - Train: 135 [ 500/781 ( 64%)]  Loss:  3.353224 (3.4375)  Time: 0.505s,  253.71/s  (0.477s,  268.23/s)  LR: 2.199e-05  Data: 0.010 (0.008)
2024-04-07 12:28:28,513 - train - INFO - Train: 135 [ 550/781 ( 71%)]  Loss:  3.584871 (3.4441)  Time: 0.483s,  265.10/s  (0.476s,  268.75/s)  LR: 2.199e-05  Data: 0.005 (0.008)
2024-04-07 12:28:52,539 - train - INFO - Train: 135 [ 600/781 ( 77%)]  Loss:  3.589747 (3.4455)  Time: 0.499s,  256.27/s  (0.477s,  268.55/s)  LR: 2.199e-05  Data: 0.008 (0.008)
2024-04-07 12:29:16,261 - train - INFO - Train: 135 [ 650/781 ( 83%)]  Loss:  3.733357 (3.4441)  Time: 0.475s,  269.51/s  (0.476s,  268.65/s)  LR: 2.199e-05  Data: 0.005 (0.008)
2024-04-07 12:29:40,241 - train - INFO - Train: 135 [ 700/781 ( 90%)]  Loss:  3.409199 (3.4432)  Time: 0.443s,  288.86/s  (0.477s,  268.53/s)  LR: 2.199e-05  Data: 0.005 (0.008)
2024-04-07 12:30:04,042 - train - INFO - Train: 135 [ 750/781 ( 96%)]  Loss:  3.268012 (3.4464)  Time: 0.406s,  315.65/s  (0.477s,  268.55/s)  LR: 2.199e-05  Data: 0.007 (0.008)
2024-04-07 12:30:16,911 - train - INFO - Train: 135 [ 780/781 (100%)]  Loss:  3.265147 (3.4462)  Time: 0.485s,  264.09/s  (0.475s,  269.59/s)  LR: 2.199e-05  Data: 0.000 (0.008)
2024-04-07 12:30:16,911 - train - INFO - True
2024-04-07 12:30:16,913 - train - INFO - alphas:tensor([0.7866, 0.0113, 0.0231, 0.0381, 0.1408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,914 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,914 - train - INFO - True
2024-04-07 12:30:16,915 - train - INFO - alphas:tensor([0.4659, 0.0030, 0.0085, 0.0341, 0.4885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,916 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,916 - train - INFO - True
2024-04-07 12:30:16,917 - train - INFO - alphas:tensor([0.5161, 0.0066, 0.0302, 0.4471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,918 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,918 - train - INFO - True
2024-04-07 12:30:16,920 - train - INFO - alphas:tensor([0.4432, 0.0069, 0.0194, 0.5305], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,920 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,920 - train - INFO - True
2024-04-07 12:30:16,922 - train - INFO - alphas:tensor([0.4508, 0.0037, 0.0251, 0.5204], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,922 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,922 - train - INFO - True
2024-04-07 12:30:16,923 - train - INFO - alphas:tensor([0.5510, 0.0069, 0.0198, 0.4223], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,924 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,925 - train - INFO - True
2024-04-07 12:30:16,926 - train - INFO - alphas:tensor([0.6148, 0.0028, 0.0047, 0.0200, 0.3577], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,927 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,927 - train - INFO - True
2024-04-07 12:30:16,929 - train - INFO - alphas:tensor([0.2257, 0.0014, 0.0010, 0.0214, 0.7505], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,929 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,930 - train - INFO - True
2024-04-07 12:30:16,931 - train - INFO - alphas:tensor([0.2337, 0.0008, 0.0012, 0.0146, 0.7497], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,932 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,932 - train - INFO - True
2024-04-07 12:30:16,933 - train - INFO - alphas:tensor([2.3554e-01, 4.5655e-04, 1.0059e-03, 1.7843e-02, 7.4516e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,934 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,934 - train - INFO - True
2024-04-07 12:30:16,935 - train - INFO - alphas:tensor([0.2233, 0.0011, 0.0011, 0.0227, 0.7518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,936 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,936 - train - INFO - True
2024-04-07 12:30:16,937 - train - INFO - alphas:tensor([0.6011, 0.0008, 0.0023, 0.0167, 0.3790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,938 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,938 - train - INFO - True
2024-04-07 12:30:16,940 - train - INFO - alphas:tensor([0.7289, 0.0011, 0.0016, 0.0096, 0.2587], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,944 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,944 - train - INFO - True
2024-04-07 12:30:16,945 - train - INFO - alphas:tensor([0.2723, 0.0037, 0.0039, 0.0502, 0.6700], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,947 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,947 - train - INFO - True
2024-04-07 12:30:16,948 - train - INFO - alphas:tensor([0.2836, 0.0014, 0.0021, 0.0419, 0.6711], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,951 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,951 - train - INFO - True
2024-04-07 12:30:16,952 - train - INFO - alphas:tensor([0.3058, 0.0010, 0.0022, 0.0367, 0.6544], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,954 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,954 - train - INFO - True
2024-04-07 12:30:16,955 - train - INFO - alphas:tensor([0.2772, 0.0017, 0.0027, 0.0348, 0.6836], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,957 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,957 - train - INFO - True
2024-04-07 12:30:16,958 - train - INFO - alphas:tensor([0.3048, 0.0011, 0.0034, 0.0381, 0.6526], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,961 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,961 - train - INFO - True
2024-04-07 12:30:16,962 - train - INFO - alphas:tensor([0.2689, 0.0035, 0.0051, 0.0421, 0.6804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,964 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,964 - train - INFO - True
2024-04-07 12:30:16,965 - train - INFO - alphas:tensor([6.5040e-01, 5.3644e-04, 1.4494e-03, 1.9440e-02, 3.2818e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,969 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,969 - train - INFO - True
2024-04-07 12:30:16,970 - train - INFO - alphas:tensor([5.7863e-01, 4.8234e-04, 7.8661e-04, 1.8683e-02, 4.0142e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,977 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,977 - train - INFO - True
2024-04-07 12:30:16,978 - train - INFO - alphas:tensor([4.4790e-01, 3.8968e-04, 2.1291e-03, 3.0752e-02, 5.1883e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,982 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,982 - train - INFO - True
2024-04-07 12:30:16,983 - train - INFO - alphas:tensor([4.5694e-01, 4.1910e-04, 8.2892e-04, 2.7796e-02, 5.1402e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,987 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,987 - train - INFO - True
2024-04-07 12:30:16,988 - train - INFO - alphas:tensor([4.7228e-01, 3.5219e-04, 8.5747e-04, 2.5298e-02, 5.0121e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,992 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,992 - train - INFO - True
2024-04-07 12:30:16,993 - train - INFO - alphas:tensor([4.3554e-01, 4.3412e-04, 1.5231e-03, 2.9134e-02, 5.3337e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:16,997 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:16,997 - train - INFO - True
2024-04-07 12:30:16,998 - train - INFO - alphas:tensor([5.8570e-01, 3.6086e-04, 1.2460e-03, 1.5812e-02, 3.9688e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:17,005 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:17,005 - train - INFO - True
2024-04-07 12:30:17,006 - train - INFO - alphas:tensor([7.7322e-01, 2.3860e-04, 8.4240e-04, 9.9382e-03, 2.1576e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:17,025 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:17,025 - train - INFO - True
2024-04-07 12:30:17,026 - train - INFO - alphas:tensor([0.4053, 0.0006, 0.0015, 0.0404, 0.5522], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:17,036 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:17,037 - train - INFO - True
2024-04-07 12:30:17,037 - train - INFO - alphas:tensor([4.1117e-01, 2.7216e-04, 1.0819e-03, 2.9468e-02, 5.5801e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:17,047 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:17,048 - train - INFO - True
2024-04-07 12:30:17,048 - train - INFO - alphas:tensor([4.4344e-01, 3.4158e-04, 8.0760e-04, 3.2625e-02, 5.2279e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:17,058 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:17,059 - train - INFO - True
2024-04-07 12:30:17,059 - train - INFO - alphas:tensor([4.0389e-01, 4.3954e-04, 1.2907e-03, 3.2624e-02, 5.6176e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:17,069 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:17,070 - train - INFO - True
2024-04-07 12:30:17,070 - train - INFO - alphas:tensor([7.4211e-01, 2.0410e-04, 4.3081e-04, 8.1278e-03, 2.4912e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:17,090 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:17,090 - train - INFO - True
2024-04-07 12:30:17,091 - train - INFO - alphas:tensor([0.5906, 0.0026, 0.0049, 0.0389, 0.3630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:17,168 - train - INFO - tau:0.2627125872502282
2024-04-07 12:30:17,168 - train - INFO - avg block size:10.06060606060606
2024-04-07 12:30:17,169 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 12:30:17,388 - train - INFO - Test: [   0/78]  Time: 0.215 (0.215)  Loss:  0.9756 (0.9756)  Acc@1: 82.0312 (82.0312)  Acc@5: 92.1875 (92.1875)
2024-04-07 12:30:20,732 - train - INFO - Test: [  50/78]  Time: 0.055 (0.070)  Loss:  1.5469 (1.5393)  Acc@1: 66.4062 (66.0846)  Acc@5: 89.0625 (86.2592)
2024-04-07 12:30:22,444 - train - INFO - Test: [  78/78]  Time: 0.051 (0.067)  Loss:  1.8477 (1.5595)  Acc@1: 62.5000 (65.7500)  Acc@5: 87.5000 (86.0000)
2024-04-07 12:30:23,058 - train - INFO - Train: 136 [   0/781 (  0%)]  Loss:  3.100106 (3.1001)  Time: 0.539s,  237.39/s  (0.539s,  237.39/s)  LR: 2.046e-05  Data: 0.190 (0.190)
2024-04-07 12:30:46,634 - train - INFO - Train: 136 [  50/781 (  6%)]  Loss:  3.447040 (3.4837)  Time: 0.396s,  322.93/s  (0.473s,  270.71/s)  LR: 2.046e-05  Data: 0.008 (0.011)
2024-04-07 12:31:10,773 - train - INFO - Train: 136 [ 100/781 ( 13%)]  Loss:  3.861842 (3.4756)  Time: 0.494s,  259.16/s  (0.478s,  267.93/s)  LR: 2.046e-05  Data: 0.009 (0.010)
2024-04-07 12:31:34,049 - train - INFO - Train: 136 [ 150/781 ( 19%)]  Loss:  3.149733 (3.4578)  Time: 0.514s,  248.85/s  (0.474s,  270.23/s)  LR: 2.046e-05  Data: 0.006 (0.009)
2024-04-07 12:31:56,827 - train - INFO - Train: 136 [ 200/781 ( 26%)]  Loss:  3.070241 (3.4640)  Time: 0.491s,  260.51/s  (0.469s,  272.83/s)  LR: 2.046e-05  Data: 0.007 (0.009)
2024-04-07 12:32:20,419 - train - INFO - Train: 136 [ 250/781 ( 32%)]  Loss:  3.781093 (3.4539)  Time: 0.507s,  252.24/s  (0.470s,  272.53/s)  LR: 2.046e-05  Data: 0.007 (0.008)
2024-04-07 12:32:44,329 - train - INFO - Train: 136 [ 300/781 ( 38%)]  Loss:  3.455728 (3.4613)  Time: 0.480s,  266.74/s  (0.471s,  271.71/s)  LR: 2.046e-05  Data: 0.009 (0.008)
2024-04-07 12:33:07,050 - train - INFO - Train: 136 [ 350/781 ( 45%)]  Loss:  3.507073 (3.4588)  Time: 0.465s,  275.10/s  (0.469s,  273.09/s)  LR: 2.046e-05  Data: 0.010 (0.008)
2024-04-07 12:33:29,473 - train - INFO - Train: 136 [ 400/781 ( 51%)]  Loss:  3.458231 (3.4577)  Time: 0.467s,  273.80/s  (0.466s,  274.57/s)  LR: 2.046e-05  Data: 0.007 (0.008)
2024-04-07 12:33:52,805 - train - INFO - Train: 136 [ 450/781 ( 58%)]  Loss:  3.642395 (3.4635)  Time: 0.509s,  251.61/s  (0.466s,  274.54/s)  LR: 2.046e-05  Data: 0.009 (0.008)
2024-04-07 12:34:16,465 - train - INFO - Train: 136 [ 500/781 ( 64%)]  Loss:  3.361125 (3.4652)  Time: 0.502s,  255.11/s  (0.467s,  274.14/s)  LR: 2.046e-05  Data: 0.009 (0.008)
2024-04-07 12:34:40,233 - train - INFO - Train: 136 [ 550/781 ( 71%)]  Loss:  3.173874 (3.4591)  Time: 0.481s,  266.20/s  (0.468s,  273.69/s)  LR: 2.046e-05  Data: 0.009 (0.008)
2024-04-07 12:35:04,009 - train - INFO - Train: 136 [ 600/781 ( 77%)]  Loss:  3.693770 (3.4608)  Time: 0.430s,  297.56/s  (0.468s,  273.31/s)  LR: 2.046e-05  Data: 0.005 (0.008)
2024-04-07 12:35:26,986 - train - INFO - Train: 136 [ 650/781 ( 83%)]  Loss:  3.295781 (3.4630)  Time: 0.503s,  254.31/s  (0.468s,  273.71/s)  LR: 2.046e-05  Data: 0.008 (0.008)
2024-04-07 12:35:50,895 - train - INFO - Train: 136 [ 700/781 ( 90%)]  Loss:  3.769097 (3.4597)  Time: 0.517s,  247.40/s  (0.468s,  273.27/s)  LR: 2.046e-05  Data: 0.007 (0.008)
2024-04-07 12:36:14,675 - train - INFO - Train: 136 [ 750/781 ( 96%)]  Loss:  3.500317 (3.4583)  Time: 0.436s,  293.87/s  (0.469s,  272.99/s)  LR: 2.046e-05  Data: 0.006 (0.008)
2024-04-07 12:36:28,885 - train - INFO - Train: 136 [ 780/781 (100%)]  Loss:  3.476942 (3.4596)  Time: 0.475s,  269.71/s  (0.469s,  272.89/s)  LR: 2.046e-05  Data: 0.000 (0.008)
2024-04-07 12:36:28,886 - train - INFO - True
2024-04-07 12:36:28,888 - train - INFO - alphas:tensor([0.7900, 0.0110, 0.0225, 0.0372, 0.1393], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,889 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,889 - train - INFO - True
2024-04-07 12:36:28,891 - train - INFO - alphas:tensor([0.4664, 0.0028, 0.0082, 0.0334, 0.4892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,891 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,891 - train - INFO - True
2024-04-07 12:36:28,893 - train - INFO - alphas:tensor([0.5151, 0.0063, 0.0294, 0.4492], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,894 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,894 - train - INFO - True
2024-04-07 12:36:28,895 - train - INFO - alphas:tensor([0.4442, 0.0066, 0.0189, 0.5304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,896 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,896 - train - INFO - True
2024-04-07 12:36:28,897 - train - INFO - alphas:tensor([0.4517, 0.0035, 0.0244, 0.5204], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,898 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,898 - train - INFO - True
2024-04-07 12:36:28,899 - train - INFO - alphas:tensor([0.5520, 0.0066, 0.0192, 0.4221], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,900 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,900 - train - INFO - True
2024-04-07 12:36:28,902 - train - INFO - alphas:tensor([0.6161, 0.0027, 0.0045, 0.0194, 0.3573], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,903 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,903 - train - INFO - True
2024-04-07 12:36:28,905 - train - INFO - alphas:tensor([0.2257, 0.0013, 0.0009, 0.0208, 0.7512], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,905 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,906 - train - INFO - True
2024-04-07 12:36:28,907 - train - INFO - alphas:tensor([0.2321, 0.0008, 0.0012, 0.0141, 0.7519], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,908 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,908 - train - INFO - True
2024-04-07 12:36:28,909 - train - INFO - alphas:tensor([2.3398e-01, 4.2629e-04, 9.4626e-04, 1.7250e-02, 7.4740e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,910 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,910 - train - INFO - True
2024-04-07 12:36:28,911 - train - INFO - alphas:tensor([0.2208, 0.0010, 0.0010, 0.0221, 0.7551], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,912 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,912 - train - INFO - True
2024-04-07 12:36:28,913 - train - INFO - alphas:tensor([0.6015, 0.0008, 0.0022, 0.0162, 0.3793], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,915 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,915 - train - INFO - True
2024-04-07 12:36:28,916 - train - INFO - alphas:tensor([0.7297, 0.0011, 0.0016, 0.0092, 0.2585], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,921 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,921 - train - INFO - True
2024-04-07 12:36:28,922 - train - INFO - alphas:tensor([0.2720, 0.0035, 0.0037, 0.0493, 0.6716], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,924 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,924 - train - INFO - True
2024-04-07 12:36:28,925 - train - INFO - alphas:tensor([0.2824, 0.0013, 0.0019, 0.0410, 0.6734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,928 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,928 - train - INFO - True
2024-04-07 12:36:28,929 - train - INFO - alphas:tensor([0.3048, 0.0009, 0.0021, 0.0358, 0.6564], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,931 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,931 - train - INFO - True
2024-04-07 12:36:28,932 - train - INFO - alphas:tensor([0.2760, 0.0016, 0.0025, 0.0342, 0.6856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,935 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,935 - train - INFO - True
2024-04-07 12:36:28,936 - train - INFO - alphas:tensor([0.3057, 0.0010, 0.0032, 0.0373, 0.6527], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,938 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,938 - train - INFO - True
2024-04-07 12:36:28,939 - train - INFO - alphas:tensor([0.2682, 0.0034, 0.0049, 0.0411, 0.6824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,941 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,942 - train - INFO - True
2024-04-07 12:36:28,942 - train - INFO - alphas:tensor([6.5162e-01, 5.0023e-04, 1.3678e-03, 1.8893e-02, 3.2762e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,946 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,946 - train - INFO - True
2024-04-07 12:36:28,947 - train - INFO - alphas:tensor([5.7955e-01, 4.4993e-04, 7.3843e-04, 1.8098e-02, 4.0116e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,956 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,956 - train - INFO - True
2024-04-07 12:36:28,957 - train - INFO - alphas:tensor([4.4869e-01, 3.6354e-04, 2.0248e-03, 3.0083e-02, 5.1884e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,961 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,961 - train - INFO - True
2024-04-07 12:36:28,962 - train - INFO - alphas:tensor([4.5650e-01, 3.9132e-04, 7.8133e-04, 2.7114e-02, 5.1521e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,966 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,966 - train - INFO - True
2024-04-07 12:36:28,967 - train - INFO - alphas:tensor([4.7274e-01, 3.2748e-04, 8.0558e-04, 2.4704e-02, 5.0142e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,970 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,971 - train - INFO - True
2024-04-07 12:36:28,971 - train - INFO - alphas:tensor([4.3543e-01, 4.0474e-04, 1.4412e-03, 2.8435e-02, 5.3429e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,975 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,975 - train - INFO - True
2024-04-07 12:36:28,976 - train - INFO - alphas:tensor([5.8600e-01, 3.3675e-04, 1.1771e-03, 1.5339e-02, 3.9714e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:28,984 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:28,984 - train - INFO - True
2024-04-07 12:36:28,985 - train - INFO - alphas:tensor([7.7431e-01, 2.2123e-04, 7.9166e-04, 9.5835e-03, 2.1509e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:29,004 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:29,004 - train - INFO - True
2024-04-07 12:36:29,005 - train - INFO - alphas:tensor([4.0635e-01, 5.4940e-04, 1.4498e-03, 3.9663e-02, 5.5199e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:29,015 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:29,015 - train - INFO - True
2024-04-07 12:36:29,016 - train - INFO - alphas:tensor([4.1194e-01, 2.5274e-04, 1.0203e-03, 2.8877e-02, 5.5791e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:29,026 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:29,026 - train - INFO - True
2024-04-07 12:36:29,027 - train - INFO - alphas:tensor([4.4474e-01, 3.1887e-04, 7.6114e-04, 3.2113e-02, 5.2207e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:29,037 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:29,037 - train - INFO - True
2024-04-07 12:36:29,038 - train - INFO - alphas:tensor([4.0568e-01, 4.0970e-04, 1.2172e-03, 3.1841e-02, 5.6086e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:29,048 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:29,048 - train - INFO - True
2024-04-07 12:36:29,049 - train - INFO - alphas:tensor([7.4339e-01, 1.8872e-04, 4.0113e-04, 7.8150e-03, 2.4820e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:29,069 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:29,069 - train - INFO - True
2024-04-07 12:36:29,070 - train - INFO - alphas:tensor([0.5925, 0.0024, 0.0047, 0.0382, 0.3622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:36:29,147 - train - INFO - tau:0.2600854613777259
2024-04-07 12:36:29,147 - train - INFO - avg block size:10.06060606060606
2024-04-07 12:36:29,148 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 12:36:29,148 - train - INFO - lasso_alpha:9.472488148953378e-07
2024-04-07 12:36:29,348 - train - INFO - Test: [   0/78]  Time: 0.196 (0.196)  Loss:  0.9624 (0.9624)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 12:36:32,296 - train - INFO - Test: [  50/78]  Time: 0.075 (0.062)  Loss:  1.5674 (1.5510)  Acc@1: 67.9688 (66.2990)  Acc@5: 88.2812 (86.7341)
2024-04-07 12:36:34,206 - train - INFO - Test: [  78/78]  Time: 0.094 (0.064)  Loss:  1.8994 (1.5692)  Acc@1: 50.0000 (65.8200)  Acc@5: 87.5000 (86.2700)
2024-04-07 12:36:35,001 - train - INFO - Train: 137 [   0/781 (  0%)]  Loss:  3.153320 (3.1533)  Time: 0.683s,  187.36/s  (0.683s,  187.36/s)  LR: 1.903e-05  Data: 0.200 (0.200)
2024-04-07 12:36:59,225 - train - INFO - Train: 137 [  50/781 (  6%)]  Loss:  3.510780 (3.4611)  Time: 0.490s,  261.11/s  (0.488s,  262.11/s)  LR: 1.903e-05  Data: 0.017 (0.012)
2024-04-07 12:37:22,875 - train - INFO - Train: 137 [ 100/781 ( 13%)]  Loss:  3.130303 (3.4665)  Time: 0.477s,  268.27/s  (0.481s,  266.26/s)  LR: 1.903e-05  Data: 0.005 (0.010)
2024-04-07 12:37:46,383 - train - INFO - Train: 137 [ 150/781 ( 19%)]  Loss:  3.724863 (3.4799)  Time: 0.501s,  255.70/s  (0.477s,  268.22/s)  LR: 1.903e-05  Data: 0.009 (0.009)
2024-04-07 12:38:09,008 - train - INFO - Train: 137 [ 200/781 ( 26%)]  Loss:  3.545969 (3.4814)  Time: 0.432s,  296.62/s  (0.471s,  271.72/s)  LR: 1.903e-05  Data: 0.007 (0.009)
2024-04-07 12:38:32,614 - train - INFO - Train: 137 [ 250/781 ( 32%)]  Loss:  3.628786 (3.4939)  Time: 0.463s,  276.23/s  (0.471s,  271.61/s)  LR: 1.903e-05  Data: 0.008 (0.008)
2024-04-07 12:38:56,264 - train - INFO - Train: 137 [ 300/781 ( 38%)]  Loss:  3.345877 (3.4950)  Time: 0.477s,  268.55/s  (0.472s,  271.45/s)  LR: 1.903e-05  Data: 0.005 (0.008)
2024-04-07 12:39:20,558 - train - INFO - Train: 137 [ 350/781 ( 45%)]  Loss:  3.503648 (3.4921)  Time: 0.502s,  254.88/s  (0.474s,  270.28/s)  LR: 1.903e-05  Data: 0.008 (0.008)
2024-04-07 12:39:44,204 - train - INFO - Train: 137 [ 400/781 ( 51%)]  Loss:  3.284722 (3.4915)  Time: 0.478s,  267.86/s  (0.473s,  270.33/s)  LR: 1.903e-05  Data: 0.006 (0.008)
2024-04-07 12:40:07,857 - train - INFO - Train: 137 [ 450/781 ( 58%)]  Loss:  3.518684 (3.4906)  Time: 0.467s,  274.38/s  (0.473s,  270.36/s)  LR: 1.903e-05  Data: 0.008 (0.008)
2024-04-07 12:40:31,374 - train - INFO - Train: 137 [ 500/781 ( 64%)]  Loss:  3.664624 (3.4828)  Time: 0.430s,  297.96/s  (0.473s,  270.54/s)  LR: 1.903e-05  Data: 0.007 (0.008)
2024-04-07 12:40:54,015 - train - INFO - Train: 137 [ 550/781 ( 71%)]  Loss:  3.439673 (3.4800)  Time: 0.478s,  267.55/s  (0.471s,  271.60/s)  LR: 1.903e-05  Data: 0.018 (0.008)
2024-04-07 12:41:16,384 - train - INFO - Train: 137 [ 600/781 ( 77%)]  Loss:  3.669316 (3.4813)  Time: 0.430s,  297.71/s  (0.469s,  272.75/s)  LR: 1.903e-05  Data: 0.009 (0.008)
2024-04-07 12:41:40,015 - train - INFO - Train: 137 [ 650/781 ( 83%)]  Loss:  3.617237 (3.4806)  Time: 0.468s,  273.71/s  (0.470s,  272.60/s)  LR: 1.903e-05  Data: 0.006 (0.008)
2024-04-07 12:42:03,439 - train - INFO - Train: 137 [ 700/781 ( 90%)]  Loss:  3.515893 (3.4804)  Time: 0.459s,  278.97/s  (0.469s,  272.65/s)  LR: 1.903e-05  Data: 0.007 (0.008)
2024-04-07 12:42:27,547 - train - INFO - Train: 137 [ 750/781 ( 96%)]  Loss:  3.610190 (3.4801)  Time: 0.494s,  259.16/s  (0.470s,  272.16/s)  LR: 1.903e-05  Data: 0.009 (0.008)
2024-04-07 12:42:41,861 - train - INFO - Train: 137 [ 780/781 (100%)]  Loss:  3.612693 (3.4800)  Time: 0.457s,  280.34/s  (0.471s,  272.01/s)  LR: 1.903e-05  Data: 0.000 (0.008)
2024-04-07 12:42:41,862 - train - INFO - True
2024-04-07 12:42:41,864 - train - INFO - alphas:tensor([0.7933, 0.0106, 0.0219, 0.0364, 0.1378], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,865 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,865 - train - INFO - True
2024-04-07 12:42:41,867 - train - INFO - alphas:tensor([0.4673, 0.0027, 0.0079, 0.0326, 0.4896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,867 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,868 - train - INFO - True
2024-04-07 12:42:41,869 - train - INFO - alphas:tensor([0.5174, 0.0061, 0.0287, 0.4478], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,870 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,871 - train - INFO - True
2024-04-07 12:42:41,872 - train - INFO - alphas:tensor([0.4441, 0.0063, 0.0183, 0.5312], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,873 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,873 - train - INFO - True
2024-04-07 12:42:41,874 - train - INFO - alphas:tensor([0.4519, 0.0033, 0.0238, 0.5210], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,875 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,875 - train - INFO - True
2024-04-07 12:42:41,877 - train - INFO - alphas:tensor([0.5526, 0.0064, 0.0187, 0.4224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,878 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,878 - train - INFO - True
2024-04-07 12:42:41,879 - train - INFO - alphas:tensor([0.6180, 0.0026, 0.0043, 0.0188, 0.3563], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,881 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,881 - train - INFO - True
2024-04-07 12:42:41,883 - train - INFO - alphas:tensor([0.2246, 0.0012, 0.0009, 0.0203, 0.7530], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,884 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,884 - train - INFO - True
2024-04-07 12:42:41,885 - train - INFO - alphas:tensor([2.3028e-01, 7.1447e-04, 1.1044e-03, 1.3645e-02, 7.5426e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,886 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,886 - train - INFO - True
2024-04-07 12:42:41,888 - train - INFO - alphas:tensor([2.3178e-01, 3.9710e-04, 8.8837e-04, 1.6722e-02, 7.5021e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,889 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,889 - train - INFO - True
2024-04-07 12:42:41,890 - train - INFO - alphas:tensor([0.2200, 0.0010, 0.0010, 0.0214, 0.7567], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,891 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,891 - train - INFO - True
2024-04-07 12:42:41,892 - train - INFO - alphas:tensor([0.6028, 0.0007, 0.0021, 0.0157, 0.3786], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,894 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,894 - train - INFO - True
2024-04-07 12:42:41,895 - train - INFO - alphas:tensor([0.7310, 0.0010, 0.0015, 0.0089, 0.2577], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,900 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,901 - train - INFO - True
2024-04-07 12:42:41,902 - train - INFO - alphas:tensor([0.2721, 0.0034, 0.0035, 0.0483, 0.6727], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,904 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,905 - train - INFO - True
2024-04-07 12:42:41,906 - train - INFO - alphas:tensor([0.2818, 0.0012, 0.0019, 0.0402, 0.6750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,908 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,908 - train - INFO - True
2024-04-07 12:42:41,910 - train - INFO - alphas:tensor([0.3045, 0.0009, 0.0020, 0.0351, 0.6576], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,912 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,912 - train - INFO - True
2024-04-07 12:42:41,913 - train - INFO - alphas:tensor([0.2760, 0.0016, 0.0024, 0.0333, 0.6866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,916 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,916 - train - INFO - True
2024-04-07 12:42:41,917 - train - INFO - alphas:tensor([0.3055, 0.0010, 0.0031, 0.0365, 0.6539], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,919 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,920 - train - INFO - True
2024-04-07 12:42:41,921 - train - INFO - alphas:tensor([0.2677, 0.0032, 0.0047, 0.0402, 0.6842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,923 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,923 - train - INFO - True
2024-04-07 12:42:41,924 - train - INFO - alphas:tensor([6.5224e-01, 4.6833e-04, 1.2961e-03, 1.8390e-02, 3.2761e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,928 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,928 - train - INFO - True
2024-04-07 12:42:41,929 - train - INFO - alphas:tensor([5.8004e-01, 4.1964e-04, 6.9348e-04, 1.7574e-02, 4.0127e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,938 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,938 - train - INFO - True
2024-04-07 12:42:41,939 - train - INFO - alphas:tensor([4.4993e-01, 3.3793e-04, 1.9193e-03, 2.9367e-02, 5.1845e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,944 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,944 - train - INFO - True
2024-04-07 12:42:41,945 - train - INFO - alphas:tensor([4.5739e-01, 3.6522e-04, 7.3504e-04, 2.6459e-02, 5.1505e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,949 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,949 - train - INFO - True
2024-04-07 12:42:41,950 - train - INFO - alphas:tensor([4.7316e-01, 3.0427e-04, 7.5668e-04, 2.4101e-02, 5.0168e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,954 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,954 - train - INFO - True
2024-04-07 12:42:41,955 - train - INFO - alphas:tensor([4.3723e-01, 3.7761e-04, 1.3602e-03, 2.7698e-02, 5.3333e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,959 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,959 - train - INFO - True
2024-04-07 12:42:41,960 - train - INFO - alphas:tensor([5.8738e-01, 3.1392e-04, 1.1104e-03, 1.4880e-02, 3.9631e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,968 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,968 - train - INFO - True
2024-04-07 12:42:41,969 - train - INFO - alphas:tensor([7.7579e-01, 2.0536e-04, 7.4529e-04, 9.2541e-03, 2.1400e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,988 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,988 - train - INFO - True
2024-04-07 12:42:41,989 - train - INFO - alphas:tensor([4.0500e-01, 5.1365e-04, 1.3711e-03, 3.8922e-02, 5.5419e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:41,999 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:41,999 - train - INFO - True
2024-04-07 12:42:42,000 - train - INFO - alphas:tensor([4.1200e-01, 2.3501e-04, 9.6153e-04, 2.8195e-02, 5.5861e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:42,010 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:42,010 - train - INFO - True
2024-04-07 12:42:42,011 - train - INFO - alphas:tensor([4.4553e-01, 2.9661e-04, 7.1556e-04, 3.1420e-02, 5.2204e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:42,021 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:42,021 - train - INFO - True
2024-04-07 12:42:42,022 - train - INFO - alphas:tensor([4.0620e-01, 3.8171e-04, 1.1464e-03, 3.1035e-02, 5.6124e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:42,032 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:42,032 - train - INFO - True
2024-04-07 12:42:42,033 - train - INFO - alphas:tensor([7.4423e-01, 1.7468e-04, 3.7523e-04, 7.5383e-03, 2.4768e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:42,052 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:42,053 - train - INFO - True
2024-04-07 12:42:42,053 - train - INFO - alphas:tensor([0.5940, 0.0023, 0.0045, 0.0374, 0.3617], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:42:42,131 - train - INFO - tau:0.2574846067639487
2024-04-07 12:42:42,131 - train - INFO - avg block size:10.06060606060606
2024-04-07 12:42:42,131 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 12:42:42,328 - train - INFO - Test: [   0/78]  Time: 0.193 (0.193)  Loss:  0.9648 (0.9648)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 12:42:45,385 - train - INFO - Test: [  50/78]  Time: 0.054 (0.064)  Loss:  1.5469 (1.5434)  Acc@1: 66.4062 (66.0233)  Acc@5: 85.1562 (86.3051)
2024-04-07 12:42:46,877 - train - INFO - Test: [  78/78]  Time: 0.054 (0.060)  Loss:  1.8350 (1.5619)  Acc@1: 56.2500 (65.8500)  Acc@5: 87.5000 (86.0200)
2024-04-07 12:42:47,743 - train - INFO - Train: 138 [   0/781 (  0%)]  Loss:  3.338899 (3.3389)  Time: 0.704s,  181.71/s  (0.704s,  181.71/s)  LR: 1.770e-05  Data: 0.199 (0.199)
2024-04-07 12:43:11,941 - train - INFO - Train: 138 [  50/781 (  6%)]  Loss:  3.779489 (3.4682)  Time: 0.506s,  252.87/s  (0.488s,  262.15/s)  LR: 1.770e-05  Data: 0.008 (0.011)
2024-04-07 12:43:34,922 - train - INFO - Train: 138 [ 100/781 ( 13%)]  Loss:  2.992820 (3.4352)  Time: 0.416s,  307.81/s  (0.474s,  270.01/s)  LR: 1.770e-05  Data: 0.007 (0.010)
2024-04-07 12:43:58,338 - train - INFO - Train: 138 [ 150/781 ( 19%)]  Loss:  3.781186 (3.4563)  Time: 0.497s,  257.46/s  (0.472s,  271.10/s)  LR: 1.770e-05  Data: 0.006 (0.009)
2024-04-07 12:44:20,553 - train - INFO - Train: 138 [ 200/781 ( 26%)]  Loss:  3.692202 (3.4531)  Time: 0.510s,  251.16/s  (0.465s,  275.14/s)  LR: 1.770e-05  Data: 0.009 (0.009)
2024-04-07 12:44:43,949 - train - INFO - Train: 138 [ 250/781 ( 32%)]  Loss:  3.338969 (3.4512)  Time: 0.481s,  266.05/s  (0.466s,  274.83/s)  LR: 1.770e-05  Data: 0.007 (0.009)
2024-04-07 12:45:07,279 - train - INFO - Train: 138 [ 300/781 ( 38%)]  Loss:  3.564187 (3.4529)  Time: 0.447s,  286.07/s  (0.466s,  274.75/s)  LR: 1.770e-05  Data: 0.006 (0.008)
2024-04-07 12:45:31,694 - train - INFO - Train: 138 [ 350/781 ( 45%)]  Loss:  3.050094 (3.4504)  Time: 0.502s,  255.13/s  (0.469s,  272.88/s)  LR: 1.770e-05  Data: 0.009 (0.008)
2024-04-07 12:45:55,587 - train - INFO - Train: 138 [ 400/781 ( 51%)]  Loss:  3.165666 (3.4464)  Time: 0.479s,  267.27/s  (0.470s,  272.25/s)  LR: 1.770e-05  Data: 0.007 (0.008)
2024-04-07 12:46:18,493 - train - INFO - Train: 138 [ 450/781 ( 58%)]  Loss:  3.786287 (3.4468)  Time: 0.369s,  347.04/s  (0.469s,  273.02/s)  LR: 1.770e-05  Data: 0.005 (0.008)
2024-04-07 12:46:41,503 - train - INFO - Train: 138 [ 500/781 ( 64%)]  Loss:  3.462980 (3.4426)  Time: 0.385s,  332.08/s  (0.468s,  273.53/s)  LR: 1.770e-05  Data: 0.004 (0.008)
2024-04-07 12:47:04,994 - train - INFO - Train: 138 [ 550/781 ( 71%)]  Loss:  3.300058 (3.4432)  Time: 0.445s,  287.79/s  (0.468s,  273.43/s)  LR: 1.770e-05  Data: 0.005 (0.008)
2024-04-07 12:47:28,211 - train - INFO - Train: 138 [ 600/781 ( 77%)]  Loss:  3.215699 (3.4454)  Time: 0.459s,  278.89/s  (0.468s,  273.62/s)  LR: 1.770e-05  Data: 0.007 (0.008)
2024-04-07 12:47:51,754 - train - INFO - Train: 138 [ 650/781 ( 83%)]  Loss:  3.752836 (3.4522)  Time: 0.448s,  285.44/s  (0.468s,  273.48/s)  LR: 1.770e-05  Data: 0.006 (0.008)
2024-04-07 12:48:14,912 - train - INFO - Train: 138 [ 700/781 ( 90%)]  Loss:  3.512174 (3.4562)  Time: 0.433s,  295.53/s  (0.468s,  273.69/s)  LR: 1.770e-05  Data: 0.005 (0.008)
2024-04-07 12:48:38,488 - train - INFO - Train: 138 [ 750/781 ( 96%)]  Loss:  3.494661 (3.4566)  Time: 0.485s,  263.65/s  (0.468s,  273.54/s)  LR: 1.770e-05  Data: 0.009 (0.008)
2024-04-07 12:48:52,606 - train - INFO - Train: 138 [ 780/781 (100%)]  Loss:  3.822080 (3.4542)  Time: 0.483s,  264.90/s  (0.468s,  273.48/s)  LR: 1.770e-05  Data: 0.000 (0.008)
2024-04-07 12:48:52,607 - train - INFO - True
2024-04-07 12:48:52,609 - train - INFO - alphas:tensor([0.7971, 0.0102, 0.0212, 0.0354, 0.1360], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,610 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,610 - train - INFO - True
2024-04-07 12:48:52,612 - train - INFO - alphas:tensor([0.4679, 0.0025, 0.0076, 0.0318, 0.4901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,612 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,613 - train - INFO - True
2024-04-07 12:48:52,614 - train - INFO - alphas:tensor([0.5181, 0.0058, 0.0281, 0.4480], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,615 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,615 - train - INFO - True
2024-04-07 12:48:52,617 - train - INFO - alphas:tensor([0.4435, 0.0061, 0.0178, 0.5326], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,617 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,618 - train - INFO - True
2024-04-07 12:48:52,619 - train - INFO - alphas:tensor([0.4518, 0.0032, 0.0231, 0.5218], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,620 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,620 - train - INFO - True
2024-04-07 12:48:52,621 - train - INFO - alphas:tensor([0.5533, 0.0061, 0.0182, 0.4224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,622 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,622 - train - INFO - True
2024-04-07 12:48:52,624 - train - INFO - alphas:tensor([0.6198, 0.0024, 0.0041, 0.0182, 0.3555], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,625 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,626 - train - INFO - True
2024-04-07 12:48:52,627 - train - INFO - alphas:tensor([0.2228, 0.0012, 0.0008, 0.0197, 0.7555], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,628 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,628 - train - INFO - True
2024-04-07 12:48:52,629 - train - INFO - alphas:tensor([2.2915e-01, 6.6998e-04, 1.0404e-03, 1.3186e-02, 7.5595e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,630 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,630 - train - INFO - True
2024-04-07 12:48:52,632 - train - INFO - alphas:tensor([2.3061e-01, 3.7081e-04, 8.3785e-04, 1.6238e-02, 7.5195e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,632 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,633 - train - INFO - True
2024-04-07 12:48:52,634 - train - INFO - alphas:tensor([0.2186, 0.0009, 0.0009, 0.0208, 0.7588], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,635 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,635 - train - INFO - True
2024-04-07 12:48:52,636 - train - INFO - alphas:tensor([0.6034, 0.0007, 0.0020, 0.0152, 0.3787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,638 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,638 - train - INFO - True
2024-04-07 12:48:52,639 - train - INFO - alphas:tensor([0.7328, 0.0009, 0.0014, 0.0086, 0.2563], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,644 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,644 - train - INFO - True
2024-04-07 12:48:52,645 - train - INFO - alphas:tensor([0.2718, 0.0032, 0.0034, 0.0474, 0.6742], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,648 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,648 - train - INFO - True
2024-04-07 12:48:52,649 - train - INFO - alphas:tensor([0.2812, 0.0011, 0.0018, 0.0392, 0.6767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,651 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,652 - train - INFO - True
2024-04-07 12:48:52,653 - train - INFO - alphas:tensor([0.3038, 0.0008, 0.0019, 0.0343, 0.6592], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,655 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,655 - train - INFO - True
2024-04-07 12:48:52,656 - train - INFO - alphas:tensor([0.2756, 0.0015, 0.0023, 0.0326, 0.6881], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,659 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,659 - train - INFO - True
2024-04-07 12:48:52,660 - train - INFO - alphas:tensor([0.3049, 0.0009, 0.0030, 0.0358, 0.6555], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,662 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,662 - train - INFO - True
2024-04-07 12:48:52,663 - train - INFO - alphas:tensor([0.2672, 0.0031, 0.0045, 0.0393, 0.6860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,666 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,666 - train - INFO - True
2024-04-07 12:48:52,667 - train - INFO - alphas:tensor([6.5244e-01, 4.3772e-04, 1.2233e-03, 1.7865e-02, 3.2804e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,671 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,671 - train - INFO - True
2024-04-07 12:48:52,672 - train - INFO - alphas:tensor([5.8023e-01, 3.9152e-04, 6.5074e-04, 1.7047e-02, 4.0168e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,680 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,681 - train - INFO - True
2024-04-07 12:48:52,681 - train - INFO - alphas:tensor([4.4920e-01, 3.1392e-04, 1.8231e-03, 2.8691e-02, 5.1997e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,686 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,686 - train - INFO - True
2024-04-07 12:48:52,687 - train - INFO - alphas:tensor([4.5826e-01, 3.4031e-04, 6.9010e-04, 2.5777e-02, 5.1494e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,691 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,691 - train - INFO - True
2024-04-07 12:48:52,692 - train - INFO - alphas:tensor([4.7406e-01, 2.8281e-04, 7.1076e-04, 2.3497e-02, 5.0144e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,696 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,696 - train - INFO - True
2024-04-07 12:48:52,697 - train - INFO - alphas:tensor([4.3698e-01, 3.5120e-04, 1.2817e-03, 2.7015e-02, 5.3438e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,701 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,701 - train - INFO - True
2024-04-07 12:48:52,702 - train - INFO - alphas:tensor([5.8725e-01, 2.9241e-04, 1.0503e-03, 1.4474e-02, 3.9693e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,709 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,709 - train - INFO - True
2024-04-07 12:48:52,710 - train - INFO - alphas:tensor([7.7721e-01, 1.9030e-04, 6.9989e-04, 8.9392e-03, 2.1296e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,729 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,730 - train - INFO - True
2024-04-07 12:48:52,730 - train - INFO - alphas:tensor([4.0524e-01, 4.8056e-04, 1.2984e-03, 3.8215e-02, 5.5477e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,740 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,741 - train - INFO - True
2024-04-07 12:48:52,741 - train - INFO - alphas:tensor([4.1277e-01, 2.1809e-04, 9.0501e-04, 2.7487e-02, 5.5861e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,752 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,752 - train - INFO - True
2024-04-07 12:48:52,753 - train - INFO - alphas:tensor([4.4543e-01, 2.7620e-04, 6.7208e-04, 3.0835e-02, 5.2279e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,763 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,763 - train - INFO - True
2024-04-07 12:48:52,764 - train - INFO - alphas:tensor([4.0530e-01, 3.5501e-04, 1.0837e-03, 3.0421e-02, 5.6284e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,774 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,774 - train - INFO - True
2024-04-07 12:48:52,775 - train - INFO - alphas:tensor([7.4497e-01, 1.6188e-04, 3.4978e-04, 7.2632e-03, 2.4725e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,794 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,794 - train - INFO - True
2024-04-07 12:48:52,795 - train - INFO - alphas:tensor([0.5940, 0.0022, 0.0043, 0.0369, 0.3626], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:48:52,873 - train - INFO - tau:0.2549097606963092
2024-04-07 12:48:52,873 - train - INFO - avg block size:10.06060606060606
2024-04-07 12:48:52,873 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 12:48:52,873 - train - INFO - lasso_alpha:8.611352862684889e-07
2024-04-07 12:48:53,081 - train - INFO - Test: [   0/78]  Time: 0.204 (0.204)  Loss:  0.9697 (0.9697)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 12:48:55,748 - train - INFO - Test: [  50/78]  Time: 0.092 (0.056)  Loss:  1.5137 (1.5334)  Acc@1: 67.9688 (66.2531)  Acc@5: 88.2812 (86.4583)
2024-04-07 12:48:57,428 - train - INFO - Test: [  78/78]  Time: 0.053 (0.058)  Loss:  1.8486 (1.5536)  Acc@1: 56.2500 (65.9000)  Acc@5: 87.5000 (86.0900)
2024-04-07 12:48:58,163 - train - INFO - Train: 139 [   0/781 (  0%)]  Loss:  3.093523 (3.0935)  Time: 0.658s,  194.50/s  (0.658s,  194.50/s)  LR: 1.647e-05  Data: 0.191 (0.191)
2024-04-07 12:49:21,731 - train - INFO - Train: 139 [  50/781 (  6%)]  Loss:  3.714647 (3.4199)  Time: 0.519s,  246.75/s  (0.475s,  269.48/s)  LR: 1.647e-05  Data: 0.010 (0.011)
2024-04-07 12:49:45,942 - train - INFO - Train: 139 [ 100/781 ( 13%)]  Loss:  3.232470 (3.4608)  Time: 0.509s,  251.33/s  (0.480s,  266.92/s)  LR: 1.647e-05  Data: 0.008 (0.010)
2024-04-07 12:50:09,326 - train - INFO - Train: 139 [ 150/781 ( 19%)]  Loss:  3.371301 (3.4543)  Time: 0.510s,  251.00/s  (0.476s,  269.13/s)  LR: 1.647e-05  Data: 0.006 (0.009)
2024-04-07 12:50:33,242 - train - INFO - Train: 139 [ 200/781 ( 26%)]  Loss:  3.646866 (3.4451)  Time: 0.522s,  245.21/s  (0.476s,  268.75/s)  LR: 1.647e-05  Data: 0.008 (0.009)
2024-04-07 12:50:56,236 - train - INFO - Train: 139 [ 250/781 ( 32%)]  Loss:  3.423324 (3.4535)  Time: 0.450s,  284.45/s  (0.473s,  270.61/s)  LR: 1.647e-05  Data: 0.006 (0.009)
2024-04-07 12:51:18,047 - train - INFO - Train: 139 [ 300/781 ( 38%)]  Loss:  3.637892 (3.4572)  Time: 0.468s,  273.54/s  (0.467s,  274.16/s)  LR: 1.647e-05  Data: 0.008 (0.008)
2024-04-07 12:51:41,028 - train - INFO - Train: 139 [ 350/781 ( 45%)]  Loss:  3.761360 (3.4587)  Time: 0.510s,  250.86/s  (0.466s,  274.77/s)  LR: 1.647e-05  Data: 0.008 (0.008)
2024-04-07 12:52:05,107 - train - INFO - Train: 139 [ 400/781 ( 51%)]  Loss:  3.521678 (3.4588)  Time: 0.486s,  263.22/s  (0.468s,  273.62/s)  LR: 1.647e-05  Data: 0.007 (0.008)
2024-04-07 12:52:28,980 - train - INFO - Train: 139 [ 450/781 ( 58%)]  Loss:  3.693520 (3.4647)  Time: 0.467s,  274.16/s  (0.469s,  273.00/s)  LR: 1.647e-05  Data: 0.009 (0.008)
2024-04-07 12:52:52,574 - train - INFO - Train: 139 [ 500/781 ( 64%)]  Loss:  3.323001 (3.4624)  Time: 0.474s,  270.32/s  (0.469s,  272.83/s)  LR: 1.647e-05  Data: 0.007 (0.008)
2024-04-07 12:53:16,120 - train - INFO - Train: 139 [ 550/781 ( 71%)]  Loss:  3.695143 (3.4612)  Time: 0.456s,  280.52/s  (0.469s,  272.74/s)  LR: 1.647e-05  Data: 0.005 (0.008)
2024-04-07 12:53:39,697 - train - INFO - Train: 139 [ 600/781 ( 77%)]  Loss:  3.591250 (3.4646)  Time: 0.514s,  249.14/s  (0.469s,  272.63/s)  LR: 1.647e-05  Data: 0.009 (0.008)
2024-04-07 12:54:03,437 - train - INFO - Train: 139 [ 650/781 ( 83%)]  Loss:  3.472054 (3.4681)  Time: 0.465s,  275.52/s  (0.470s,  272.40/s)  LR: 1.647e-05  Data: 0.005 (0.008)
2024-04-07 12:54:27,170 - train - INFO - Train: 139 [ 700/781 ( 90%)]  Loss:  3.189771 (3.4713)  Time: 0.439s,  291.50/s  (0.470s,  272.20/s)  LR: 1.647e-05  Data: 0.008 (0.008)
2024-04-07 12:54:50,476 - train - INFO - Train: 139 [ 750/781 ( 96%)]  Loss:  3.103034 (3.4688)  Time: 0.493s,  259.80/s  (0.470s,  272.36/s)  LR: 1.647e-05  Data: 0.008 (0.008)
2024-04-07 12:55:04,624 - train - INFO - Train: 139 [ 780/781 (100%)]  Loss:  2.991206 (3.4679)  Time: 0.488s,  262.15/s  (0.470s,  272.33/s)  LR: 1.647e-05  Data: 0.000 (0.008)
2024-04-07 12:55:04,626 - train - INFO - True
2024-04-07 12:55:04,628 - train - INFO - alphas:tensor([0.8005, 0.0098, 0.0206, 0.0346, 0.1345], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,629 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,629 - train - INFO - True
2024-04-07 12:55:04,631 - train - INFO - alphas:tensor([0.4680, 0.0024, 0.0073, 0.0311, 0.4912], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,631 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,632 - train - INFO - True
2024-04-07 12:55:04,633 - train - INFO - alphas:tensor([0.5187, 0.0056, 0.0274, 0.4484], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,634 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,634 - train - INFO - True
2024-04-07 12:55:04,636 - train - INFO - alphas:tensor([0.4435, 0.0058, 0.0172, 0.5334], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,637 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,637 - train - INFO - True
2024-04-07 12:55:04,638 - train - INFO - alphas:tensor([0.4517, 0.0030, 0.0225, 0.5228], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,639 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,639 - train - INFO - True
2024-04-07 12:55:04,641 - train - INFO - alphas:tensor([0.5527, 0.0059, 0.0176, 0.4238], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,642 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,642 - train - INFO - True
2024-04-07 12:55:04,643 - train - INFO - alphas:tensor([0.6204, 0.0023, 0.0039, 0.0177, 0.3557], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,645 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,645 - train - INFO - True
2024-04-07 12:55:04,646 - train - INFO - alphas:tensor([0.2220, 0.0011, 0.0008, 0.0191, 0.7570], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,647 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,648 - train - INFO - True
2024-04-07 12:55:04,649 - train - INFO - alphas:tensor([2.2773e-01, 6.2822e-04, 9.7900e-04, 1.2743e-02, 7.5792e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,650 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,650 - train - INFO - True
2024-04-07 12:55:04,651 - train - INFO - alphas:tensor([2.2968e-01, 3.4537e-04, 7.8566e-04, 1.5754e-02, 7.5344e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,652 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,652 - train - INFO - True
2024-04-07 12:55:04,654 - train - INFO - alphas:tensor([0.2172, 0.0009, 0.0008, 0.0202, 0.7609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,655 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,655 - train - INFO - True
2024-04-07 12:55:04,656 - train - INFO - alphas:tensor([0.6034, 0.0006, 0.0019, 0.0148, 0.3793], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,658 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,658 - train - INFO - True
2024-04-07 12:55:04,659 - train - INFO - alphas:tensor([0.7344, 0.0009, 0.0013, 0.0082, 0.2552], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,664 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,664 - train - INFO - True
2024-04-07 12:55:04,665 - train - INFO - alphas:tensor([0.2719, 0.0031, 0.0032, 0.0466, 0.6752], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,668 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,668 - train - INFO - True
2024-04-07 12:55:04,669 - train - INFO - alphas:tensor([0.2807, 0.0011, 0.0017, 0.0384, 0.6782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,672 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,672 - train - INFO - True
2024-04-07 12:55:04,673 - train - INFO - alphas:tensor([0.3031, 0.0008, 0.0018, 0.0336, 0.6608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,675 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,676 - train - INFO - True
2024-04-07 12:55:04,677 - train - INFO - alphas:tensor([0.2745, 0.0014, 0.0022, 0.0319, 0.6900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,679 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,679 - train - INFO - True
2024-04-07 12:55:04,680 - train - INFO - alphas:tensor([0.3035, 0.0009, 0.0028, 0.0350, 0.6578], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,683 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,683 - train - INFO - True
2024-04-07 12:55:04,684 - train - INFO - alphas:tensor([0.2669, 0.0029, 0.0043, 0.0385, 0.6874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,686 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,686 - train - INFO - True
2024-04-07 12:55:04,687 - train - INFO - alphas:tensor([6.5403e-01, 4.0843e-04, 1.1568e-03, 1.7357e-02, 3.2705e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,692 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,692 - train - INFO - True
2024-04-07 12:55:04,693 - train - INFO - alphas:tensor([5.8157e-01, 3.6445e-04, 6.0971e-04, 1.6526e-02, 4.0093e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,701 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,701 - train - INFO - True
2024-04-07 12:55:04,702 - train - INFO - alphas:tensor([4.4936e-01, 2.9151e-04, 1.7256e-03, 2.8002e-02, 5.2062e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,707 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,707 - train - INFO - True
2024-04-07 12:55:04,708 - train - INFO - alphas:tensor([4.5782e-01, 3.1656e-04, 6.4628e-04, 2.5053e-02, 5.1616e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,712 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,712 - train - INFO - True
2024-04-07 12:55:04,713 - train - INFO - alphas:tensor([4.7491e-01, 2.6281e-04, 6.6828e-04, 2.2882e-02, 5.0128e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,717 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,717 - train - INFO - True
2024-04-07 12:55:04,718 - train - INFO - alphas:tensor([4.3660e-01, 3.2717e-04, 1.2085e-03, 2.6359e-02, 5.3550e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,722 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,722 - train - INFO - True
2024-04-07 12:55:04,723 - train - INFO - alphas:tensor([5.8871e-01, 2.7179e-04, 9.8848e-04, 1.4001e-02, 3.9603e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,730 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,731 - train - INFO - True
2024-04-07 12:55:04,731 - train - INFO - alphas:tensor([7.7869e-01, 1.7608e-04, 6.5693e-04, 8.6157e-03, 2.1186e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,751 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,751 - train - INFO - True
2024-04-07 12:55:04,752 - train - INFO - alphas:tensor([4.0550e-01, 4.4888e-04, 1.2305e-03, 3.7581e-02, 5.5524e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,762 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,762 - train - INFO - True
2024-04-07 12:55:04,763 - train - INFO - alphas:tensor([4.1390e-01, 2.0180e-04, 8.5248e-04, 2.6778e-02, 5.5827e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,773 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,773 - train - INFO - True
2024-04-07 12:55:04,774 - train - INFO - alphas:tensor([4.4640e-01, 2.5660e-04, 6.2934e-04, 3.0102e-02, 5.2261e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,784 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,785 - train - INFO - True
2024-04-07 12:55:04,785 - train - INFO - alphas:tensor([4.0538e-01, 3.3086e-04, 1.0230e-03, 2.9736e-02, 5.6353e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,796 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,796 - train - INFO - True
2024-04-07 12:55:04,797 - train - INFO - alphas:tensor([7.4577e-01, 1.4975e-04, 3.2692e-04, 7.0120e-03, 2.4674e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,816 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,816 - train - INFO - True
2024-04-07 12:55:04,817 - train - INFO - alphas:tensor([0.5951, 0.0021, 0.0042, 0.0361, 0.3625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:55:04,895 - train - INFO - tau:0.2523606630893461
2024-04-07 12:55:04,895 - train - INFO - avg block size:10.06060606060606
2024-04-07 12:55:04,895 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 12:55:05,099 - train - INFO - Test: [   0/78]  Time: 0.201 (0.201)  Loss:  0.9541 (0.9541)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 12:55:08,185 - train - INFO - Test: [  50/78]  Time: 0.074 (0.064)  Loss:  1.5312 (1.5430)  Acc@1: 67.9688 (66.2224)  Acc@5: 89.8438 (86.5809)
2024-04-07 12:55:09,712 - train - INFO - Test: [  78/78]  Time: 0.048 (0.061)  Loss:  1.8984 (1.5622)  Acc@1: 50.0000 (65.8900)  Acc@5: 87.5000 (86.3400)
2024-04-07 12:55:10,458 - train - INFO - Train: 140 [   0/781 (  0%)]  Loss:  3.401710 (3.4017)  Time: 0.666s,  192.18/s  (0.666s,  192.18/s)  LR: 1.535e-05  Data: 0.179 (0.179)
2024-04-07 12:55:34,287 - train - INFO - Train: 140 [  50/781 (  6%)]  Loss:  3.574655 (3.4135)  Time: 0.462s,  276.84/s  (0.480s,  266.52/s)  LR: 1.535e-05  Data: 0.009 (0.011)
2024-04-07 12:55:57,362 - train - INFO - Train: 140 [ 100/781 ( 13%)]  Loss:  3.071621 (3.4154)  Time: 0.449s,  284.97/s  (0.471s,  271.79/s)  LR: 1.535e-05  Data: 0.005 (0.010)
2024-04-07 12:56:20,805 - train - INFO - Train: 140 [ 150/781 ( 19%)]  Loss:  3.648050 (3.4349)  Time: 0.499s,  256.74/s  (0.470s,  272.19/s)  LR: 1.535e-05  Data: 0.005 (0.009)
2024-04-07 12:56:42,791 - train - INFO - Train: 140 [ 200/781 ( 26%)]  Loss:  3.174125 (3.4450)  Time: 0.493s,  259.46/s  (0.463s,  276.67/s)  LR: 1.535e-05  Data: 0.007 (0.008)
2024-04-07 12:57:05,911 - train - INFO - Train: 140 [ 250/781 ( 32%)]  Loss:  3.716113 (3.4490)  Time: 0.468s,  273.42/s  (0.463s,  276.70/s)  LR: 1.535e-05  Data: 0.008 (0.008)
2024-04-07 12:57:29,236 - train - INFO - Train: 140 [ 300/781 ( 38%)]  Loss:  3.545527 (3.4471)  Time: 0.404s,  316.55/s  (0.463s,  276.32/s)  LR: 1.535e-05  Data: 0.006 (0.008)
2024-04-07 12:57:53,008 - train - INFO - Train: 140 [ 350/781 ( 45%)]  Loss:  3.586951 (3.4490)  Time: 0.472s,  271.42/s  (0.465s,  275.29/s)  LR: 1.535e-05  Data: 0.008 (0.008)
2024-04-07 12:58:16,050 - train - INFO - Train: 140 [ 400/781 ( 51%)]  Loss:  3.178533 (3.4476)  Time: 0.493s,  259.69/s  (0.464s,  275.59/s)  LR: 1.535e-05  Data: 0.008 (0.008)
2024-04-07 12:58:39,412 - train - INFO - Train: 140 [ 450/781 ( 58%)]  Loss:  3.546933 (3.4480)  Time: 0.440s,  291.10/s  (0.465s,  275.41/s)  LR: 1.535e-05  Data: 0.007 (0.008)
2024-04-07 12:59:02,160 - train - INFO - Train: 140 [ 500/781 ( 64%)]  Loss:  3.825522 (3.4493)  Time: 0.454s,  281.90/s  (0.464s,  275.99/s)  LR: 1.535e-05  Data: 0.006 (0.008)
2024-04-07 12:59:26,024 - train - INFO - Train: 140 [ 550/781 ( 71%)]  Loss:  3.477916 (3.4523)  Time: 0.466s,  274.51/s  (0.465s,  275.27/s)  LR: 1.535e-05  Data: 0.007 (0.008)
2024-04-07 12:59:50,337 - train - INFO - Train: 140 [ 600/781 ( 77%)]  Loss:  3.573944 (3.4562)  Time: 0.480s,  266.52/s  (0.467s,  274.23/s)  LR: 1.535e-05  Data: 0.008 (0.008)
2024-04-07 13:00:13,097 - train - INFO - Train: 140 [ 650/781 ( 83%)]  Loss:  3.166238 (3.4582)  Time: 0.483s,  264.77/s  (0.466s,  274.75/s)  LR: 1.535e-05  Data: 0.009 (0.008)
2024-04-07 13:00:36,228 - train - INFO - Train: 140 [ 700/781 ( 90%)]  Loss:  3.322185 (3.4579)  Time: 0.398s,  321.98/s  (0.466s,  274.89/s)  LR: 1.535e-05  Data: 0.007 (0.008)
2024-04-07 13:00:59,915 - train - INFO - Train: 140 [ 750/781 ( 96%)]  Loss:  3.309450 (3.4588)  Time: 0.468s,  273.34/s  (0.466s,  274.57/s)  LR: 1.535e-05  Data: 0.005 (0.008)
2024-04-07 13:01:13,903 - train - INFO - Train: 140 [ 780/781 (100%)]  Loss:  3.781489 (3.4611)  Time: 0.439s,  291.87/s  (0.466s,  274.57/s)  LR: 1.535e-05  Data: 0.000 (0.008)
2024-04-07 13:01:13,904 - train - INFO - True
2024-04-07 13:01:13,906 - train - INFO - alphas:tensor([0.8035, 0.0094, 0.0200, 0.0338, 0.1332], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,907 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,907 - train - INFO - True
2024-04-07 13:01:13,908 - train - INFO - alphas:tensor([0.4680, 0.0023, 0.0070, 0.0303, 0.4924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,909 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,909 - train - INFO - True
2024-04-07 13:01:13,910 - train - INFO - alphas:tensor([0.5191, 0.0054, 0.0267, 0.4489], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,911 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,911 - train - INFO - True
2024-04-07 13:01:13,912 - train - INFO - alphas:tensor([0.4443, 0.0056, 0.0167, 0.5334], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,913 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,913 - train - INFO - True
2024-04-07 13:01:13,914 - train - INFO - alphas:tensor([0.4519, 0.0029, 0.0218, 0.5234], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,915 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,915 - train - INFO - True
2024-04-07 13:01:13,916 - train - INFO - alphas:tensor([0.5539, 0.0056, 0.0171, 0.4233], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,917 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,917 - train - INFO - True
2024-04-07 13:01:13,919 - train - INFO - alphas:tensor([0.6216, 0.0022, 0.0037, 0.0172, 0.3553], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,920 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,920 - train - INFO - True
2024-04-07 13:01:13,921 - train - INFO - alphas:tensor([2.2023e-01, 1.0435e-03, 7.3298e-04, 1.8499e-02, 7.5950e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,922 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,922 - train - INFO - True
2024-04-07 13:01:13,923 - train - INFO - alphas:tensor([2.2644e-01, 5.8782e-04, 9.1909e-04, 1.2315e-02, 7.5973e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,924 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,924 - train - INFO - True
2024-04-07 13:01:13,925 - train - INFO - alphas:tensor([2.2786e-01, 3.2127e-04, 7.3939e-04, 1.5249e-02, 7.5583e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,926 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,926 - train - INFO - True
2024-04-07 13:01:13,927 - train - INFO - alphas:tensor([0.2163, 0.0008, 0.0008, 0.0197, 0.7624], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,928 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,928 - train - INFO - True
2024-04-07 13:01:13,929 - train - INFO - alphas:tensor([6.0485e-01, 5.7884e-04, 1.7860e-03, 1.4294e-02, 3.7849e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,931 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,931 - train - INFO - True
2024-04-07 13:01:13,932 - train - INFO - alphas:tensor([0.7358, 0.0008, 0.0012, 0.0079, 0.2542], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,936 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,936 - train - INFO - True
2024-04-07 13:01:13,937 - train - INFO - alphas:tensor([0.2702, 0.0029, 0.0031, 0.0457, 0.6781], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,939 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,940 - train - INFO - True
2024-04-07 13:01:13,941 - train - INFO - alphas:tensor([0.2803, 0.0010, 0.0016, 0.0376, 0.6795], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,943 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,943 - train - INFO - True
2024-04-07 13:01:13,944 - train - INFO - alphas:tensor([0.3024, 0.0007, 0.0017, 0.0328, 0.6625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,946 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,946 - train - INFO - True
2024-04-07 13:01:13,947 - train - INFO - alphas:tensor([0.2736, 0.0013, 0.0021, 0.0312, 0.6919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,949 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,949 - train - INFO - True
2024-04-07 13:01:13,950 - train - INFO - alphas:tensor([0.3034, 0.0008, 0.0027, 0.0342, 0.6589], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,952 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,953 - train - INFO - True
2024-04-07 13:01:13,954 - train - INFO - alphas:tensor([0.2655, 0.0028, 0.0041, 0.0376, 0.6900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,956 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,956 - train - INFO - True
2024-04-07 13:01:13,957 - train - INFO - alphas:tensor([6.5563e-01, 3.8133e-04, 1.0906e-03, 1.6855e-02, 3.2604e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,960 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,960 - train - INFO - True
2024-04-07 13:01:13,961 - train - INFO - alphas:tensor([5.8227e-01, 3.3940e-04, 5.7054e-04, 1.6036e-02, 4.0078e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,969 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,969 - train - INFO - True
2024-04-07 13:01:13,970 - train - INFO - alphas:tensor([4.4943e-01, 2.7083e-04, 1.6361e-03, 2.7305e-02, 5.2136e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,974 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,974 - train - INFO - True
2024-04-07 13:01:13,975 - train - INFO - alphas:tensor([4.5771e-01, 2.9440e-04, 6.0533e-04, 2.4438e-02, 5.1696e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,979 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,979 - train - INFO - True
2024-04-07 13:01:13,980 - train - INFO - alphas:tensor([4.7614e-01, 2.4364e-04, 6.2591e-04, 2.2275e-02, 5.0072e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,984 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,984 - train - INFO - True
2024-04-07 13:01:13,984 - train - INFO - alphas:tensor([4.3775e-01, 3.0434e-04, 1.1428e-03, 2.5743e-02, 5.3506e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,988 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,988 - train - INFO - True
2024-04-07 13:01:13,989 - train - INFO - alphas:tensor([5.8903e-01, 2.5222e-04, 9.2899e-04, 1.3559e-02, 3.9623e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:13,997 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:13,997 - train - INFO - True
2024-04-07 13:01:13,999 - train - INFO - alphas:tensor([7.7981e-01, 1.6299e-04, 6.1724e-04, 8.3102e-03, 2.1110e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:14,024 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:14,024 - train - INFO - True
2024-04-07 13:01:14,025 - train - INFO - alphas:tensor([4.0589e-01, 4.2065e-04, 1.1653e-03, 3.6958e-02, 5.5557e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:14,037 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:14,037 - train - INFO - True
2024-04-07 13:01:14,038 - train - INFO - alphas:tensor([4.1418e-01, 1.8638e-04, 8.0252e-04, 2.6122e-02, 5.5871e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:14,048 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:14,049 - train - INFO - True
2024-04-07 13:01:14,050 - train - INFO - alphas:tensor([4.4613e-01, 2.3789e-04, 5.9084e-04, 2.9454e-02, 5.2359e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:14,060 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:14,060 - train - INFO - True
2024-04-07 13:01:14,061 - train - INFO - alphas:tensor([4.0500e-01, 3.0764e-04, 9.6430e-04, 2.9105e-02, 5.6462e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:14,070 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:14,071 - train - INFO - True
2024-04-07 13:01:14,071 - train - INFO - alphas:tensor([7.4744e-01, 1.3805e-04, 3.0408e-04, 6.7502e-03, 2.4537e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:14,089 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:14,089 - train - INFO - True
2024-04-07 13:01:14,090 - train - INFO - alphas:tensor([0.5960, 0.0020, 0.0040, 0.0355, 0.3625], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:01:14,152 - train - INFO - tau:0.24983705645845267
2024-04-07 13:01:14,152 - train - INFO - avg block size:10.06060606060606
2024-04-07 13:01:14,152 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 13:01:14,152 - train - INFO - lasso_alpha:7.828502602440807e-07
2024-04-07 13:01:14,363 - train - INFO - Test: [   0/78]  Time: 0.207 (0.207)  Loss:  0.9839 (0.9839)  Acc@1: 82.0312 (82.0312)  Acc@5: 92.9688 (92.9688)
2024-04-07 13:01:17,235 - train - INFO - Test: [  50/78]  Time: 0.054 (0.060)  Loss:  1.5303 (1.5459)  Acc@1: 67.1875 (66.1612)  Acc@5: 89.0625 (86.3511)
2024-04-07 13:01:18,717 - train - INFO - Test: [  78/78]  Time: 0.047 (0.058)  Loss:  1.8057 (1.5677)  Acc@1: 56.2500 (65.8600)  Acc@5: 93.7500 (86.0500)
2024-04-07 13:01:19,488 - train - INFO - Train: 141 [   0/781 (  0%)]  Loss:  3.522963 (3.5230)  Time: 0.691s,  185.21/s  (0.691s,  185.21/s)  LR: 1.434e-05  Data: 0.197 (0.197)
2024-04-07 13:01:42,614 - train - INFO - Train: 141 [  50/781 (  6%)]  Loss:  3.760749 (3.4965)  Time: 0.493s,  259.70/s  (0.467s,  274.11/s)  LR: 1.434e-05  Data: 0.009 (0.011)
2024-04-07 13:02:06,758 - train - INFO - Train: 141 [ 100/781 ( 13%)]  Loss:  3.459776 (3.4727)  Time: 0.480s,  266.76/s  (0.475s,  269.57/s)  LR: 1.434e-05  Data: 0.008 (0.010)
2024-04-07 13:02:30,170 - train - INFO - Train: 141 [ 150/781 ( 19%)]  Loss:  3.506474 (3.4775)  Time: 0.420s,  304.71/s  (0.473s,  270.82/s)  LR: 1.434e-05  Data: 0.008 (0.009)
2024-04-07 13:02:53,369 - train - INFO - Train: 141 [ 200/781 ( 26%)]  Loss:  3.615696 (3.4734)  Time: 0.474s,  269.79/s  (0.470s,  272.07/s)  LR: 1.434e-05  Data: 0.009 (0.009)
2024-04-07 13:03:16,858 - train - INFO - Train: 141 [ 250/781 ( 32%)]  Loss:  3.650674 (3.4667)  Time: 0.483s,  264.88/s  (0.470s,  272.15/s)  LR: 1.434e-05  Data: 0.009 (0.009)
2024-04-07 13:03:40,698 - train - INFO - Train: 141 [ 300/781 ( 38%)]  Loss:  3.499055 (3.4672)  Time: 0.485s,  263.93/s  (0.471s,  271.53/s)  LR: 1.434e-05  Data: 0.009 (0.009)
2024-04-07 13:04:04,900 - train - INFO - Train: 141 [ 350/781 ( 45%)]  Loss:  3.263107 (3.4694)  Time: 0.392s,  326.55/s  (0.473s,  270.50/s)  LR: 1.434e-05  Data: 0.006 (0.009)
2024-04-07 13:04:28,171 - train - INFO - Train: 141 [ 400/781 ( 51%)]  Loss:  3.495399 (3.4711)  Time: 0.485s,  263.81/s  (0.472s,  271.06/s)  LR: 1.434e-05  Data: 0.008 (0.008)
2024-04-07 13:04:51,824 - train - INFO - Train: 141 [ 450/781 ( 58%)]  Loss:  3.122371 (3.4738)  Time: 0.507s,  252.33/s  (0.472s,  271.01/s)  LR: 1.434e-05  Data: 0.009 (0.008)
2024-04-07 13:05:15,654 - train - INFO - Train: 141 [ 500/781 ( 64%)]  Loss:  3.666420 (3.4719)  Time: 0.485s,  264.04/s  (0.473s,  270.76/s)  LR: 1.434e-05  Data: 0.008 (0.008)
2024-04-07 13:05:39,143 - train - INFO - Train: 141 [ 550/781 ( 71%)]  Loss:  3.458110 (3.4726)  Time: 0.473s,  270.75/s  (0.472s,  270.92/s)  LR: 1.434e-05  Data: 0.008 (0.008)
2024-04-07 13:06:02,323 - train - INFO - Train: 141 [ 600/781 ( 77%)]  Loss:  3.720612 (3.4707)  Time: 0.496s,  257.95/s  (0.472s,  271.35/s)  LR: 1.434e-05  Data: 0.009 (0.008)
2024-04-07 13:06:25,399 - train - INFO - Train: 141 [ 650/781 ( 83%)]  Loss:  3.630642 (3.4710)  Time: 0.373s,  342.93/s  (0.471s,  271.80/s)  LR: 1.434e-05  Data: 0.004 (0.008)
2024-04-07 13:06:48,445 - train - INFO - Train: 141 [ 700/781 ( 90%)]  Loss:  3.286977 (3.4683)  Time: 0.488s,  262.31/s  (0.470s,  272.21/s)  LR: 1.434e-05  Data: 0.007 (0.008)
2024-04-07 13:07:11,887 - train - INFO - Train: 141 [ 750/781 ( 96%)]  Loss:  3.849093 (3.4693)  Time: 0.473s,  270.88/s  (0.470s,  272.27/s)  LR: 1.434e-05  Data: 0.008 (0.008)
2024-04-07 13:07:25,778 - train - INFO - Train: 141 [ 780/781 (100%)]  Loss:  3.229185 (3.4688)  Time: 0.542s,  236.11/s  (0.470s,  272.43/s)  LR: 1.434e-05  Data: 0.000 (0.008)
2024-04-07 13:07:25,779 - train - INFO - True
2024-04-07 13:07:25,780 - train - INFO - alphas:tensor([0.8070, 0.0091, 0.0194, 0.0329, 0.1316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,781 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,781 - train - INFO - True
2024-04-07 13:07:25,781 - train - INFO - alphas:tensor([0.4684, 0.0022, 0.0067, 0.0296, 0.4931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,782 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,782 - train - INFO - True
2024-04-07 13:07:25,783 - train - INFO - alphas:tensor([0.5199, 0.0051, 0.0260, 0.4489], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,783 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,783 - train - INFO - True
2024-04-07 13:07:25,784 - train - INFO - alphas:tensor([0.4445, 0.0054, 0.0162, 0.5339], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,784 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,784 - train - INFO - True
2024-04-07 13:07:25,785 - train - INFO - alphas:tensor([0.4519, 0.0027, 0.0212, 0.5241], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,785 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,785 - train - INFO - True
2024-04-07 13:07:25,786 - train - INFO - alphas:tensor([0.5545, 0.0054, 0.0166, 0.4235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,786 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,787 - train - INFO - True
2024-04-07 13:07:25,787 - train - INFO - alphas:tensor([0.6229, 0.0021, 0.0036, 0.0167, 0.3548], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,788 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,788 - train - INFO - True
2024-04-07 13:07:25,789 - train - INFO - alphas:tensor([2.1898e-01, 9.8410e-04, 6.8671e-04, 1.7954e-02, 7.6140e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,789 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,789 - train - INFO - True
2024-04-07 13:07:25,790 - train - INFO - alphas:tensor([2.2516e-01, 5.4960e-04, 8.6434e-04, 1.1885e-02, 7.6154e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,790 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,790 - train - INFO - True
2024-04-07 13:07:25,791 - train - INFO - alphas:tensor([2.2666e-01, 2.9843e-04, 6.9356e-04, 1.4771e-02, 7.5758e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,792 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,792 - train - INFO - True
2024-04-07 13:07:25,792 - train - INFO - alphas:tensor([2.1484e-01, 7.5506e-04, 7.5004e-04, 1.9044e-02, 7.6461e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,793 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,793 - train - INFO - True
2024-04-07 13:07:25,793 - train - INFO - alphas:tensor([6.0624e-01, 5.4046e-04, 1.6897e-03, 1.3811e-02, 3.7772e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,794 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,794 - train - INFO - True
2024-04-07 13:07:25,795 - train - INFO - alphas:tensor([0.7377, 0.0008, 0.0012, 0.0076, 0.2527], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,797 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,797 - train - INFO - True
2024-04-07 13:07:25,798 - train - INFO - alphas:tensor([0.2704, 0.0028, 0.0029, 0.0448, 0.6791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,799 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,799 - train - INFO - True
2024-04-07 13:07:25,800 - train - INFO - alphas:tensor([0.2794, 0.0010, 0.0015, 0.0367, 0.6815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,801 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,801 - train - INFO - True
2024-04-07 13:07:25,802 - train - INFO - alphas:tensor([0.3016, 0.0007, 0.0016, 0.0320, 0.6641], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,803 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,803 - train - INFO - True
2024-04-07 13:07:25,804 - train - INFO - alphas:tensor([0.2730, 0.0012, 0.0020, 0.0304, 0.6934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,805 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,805 - train - INFO - True
2024-04-07 13:07:25,806 - train - INFO - alphas:tensor([0.3037, 0.0008, 0.0026, 0.0335, 0.6595], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,807 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,807 - train - INFO - True
2024-04-07 13:07:25,808 - train - INFO - alphas:tensor([0.2649, 0.0026, 0.0040, 0.0368, 0.6917], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,809 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,809 - train - INFO - True
2024-04-07 13:07:25,810 - train - INFO - alphas:tensor([6.5593e-01, 3.5523e-04, 1.0273e-03, 1.6372e-02, 3.2631e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,812 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,812 - train - INFO - True
2024-04-07 13:07:25,813 - train - INFO - alphas:tensor([5.8269e-01, 3.1589e-04, 5.3427e-04, 1.5521e-02, 4.0094e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,817 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,818 - train - INFO - True
2024-04-07 13:07:25,818 - train - INFO - alphas:tensor([4.4901e-01, 2.5145e-04, 1.5467e-03, 2.6695e-02, 5.2250e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,821 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,821 - train - INFO - True
2024-04-07 13:07:25,821 - train - INFO - alphas:tensor([4.5858e-01, 2.7365e-04, 5.6715e-04, 2.3770e-02, 5.1681e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,824 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,824 - train - INFO - True
2024-04-07 13:07:25,824 - train - INFO - alphas:tensor([4.7675e-01, 2.2660e-04, 5.8729e-04, 2.1712e-02, 5.0072e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,827 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,827 - train - INFO - True
2024-04-07 13:07:25,827 - train - INFO - alphas:tensor([4.3791e-01, 2.8336e-04, 1.0788e-03, 2.5039e-02, 5.3569e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,830 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,830 - train - INFO - True
2024-04-07 13:07:25,830 - train - INFO - alphas:tensor([5.8870e-01, 2.3394e-04, 8.7372e-04, 1.3138e-02, 3.9705e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,835 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,835 - train - INFO - True
2024-04-07 13:07:25,836 - train - INFO - alphas:tensor([7.8156e-01, 1.5044e-04, 5.7714e-04, 7.9957e-03, 2.0972e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,847 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,847 - train - INFO - True
2024-04-07 13:07:25,848 - train - INFO - alphas:tensor([4.0662e-01, 3.9218e-04, 1.1005e-03, 3.6201e-02, 5.5569e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,855 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,855 - train - INFO - True
2024-04-07 13:07:25,855 - train - INFO - alphas:tensor([4.1496e-01, 1.7219e-04, 7.5477e-04, 2.5437e-02, 5.5868e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,863 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,863 - train - INFO - True
2024-04-07 13:07:25,864 - train - INFO - alphas:tensor([4.4665e-01, 2.2090e-04, 5.5443e-04, 2.8840e-02, 5.2374e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,872 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,872 - train - INFO - True
2024-04-07 13:07:25,872 - train - INFO - alphas:tensor([4.0537e-01, 2.8657e-04, 9.0954e-04, 2.8449e-02, 5.6498e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,879 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,879 - train - INFO - True
2024-04-07 13:07:25,880 - train - INFO - alphas:tensor([7.4964e-01, 1.2698e-04, 2.8309e-04, 6.4659e-03, 2.4348e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,893 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,893 - train - INFO - True
2024-04-07 13:07:25,894 - train - INFO - alphas:tensor([0.5976, 0.0019, 0.0038, 0.0348, 0.3619], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:07:25,943 - train - INFO - tau:0.24733868589386815
2024-04-07 13:07:25,943 - train - INFO - avg block size:10.06060606060606
2024-04-07 13:07:25,943 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 13:07:26,170 - train - INFO - Test: [   0/78]  Time: 0.223 (0.223)  Loss:  0.9473 (0.9473)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 13:07:29,184 - train - INFO - Test: [  50/78]  Time: 0.057 (0.063)  Loss:  1.5488 (1.5494)  Acc@1: 65.6250 (66.1612)  Acc@5: 89.0625 (86.4737)
2024-04-07 13:07:30,705 - train - INFO - Test: [  78/78]  Time: 0.050 (0.060)  Loss:  1.8330 (1.5679)  Acc@1: 56.2500 (65.8200)  Acc@5: 93.7500 (86.1300)
2024-04-07 13:07:31,353 - train - INFO - Train: 142 [   0/781 (  0%)]  Loss:  3.712030 (3.7120)  Time: 0.570s,  224.42/s  (0.570s,  224.42/s)  LR: 1.343e-05  Data: 0.174 (0.174)
2024-04-07 13:07:55,070 - train - INFO - Train: 142 [  50/781 (  6%)]  Loss:  3.671597 (3.4274)  Time: 0.475s,  269.37/s  (0.476s,  268.81/s)  LR: 1.343e-05  Data: 0.008 (0.011)
2024-04-07 13:08:18,994 - train - INFO - Train: 142 [ 100/781 ( 13%)]  Loss:  3.116746 (3.4294)  Time: 0.494s,  259.15/s  (0.477s,  268.17/s)  LR: 1.343e-05  Data: 0.008 (0.009)
2024-04-07 13:08:41,735 - train - INFO - Train: 142 [ 150/781 ( 19%)]  Loss:  3.606790 (3.4231)  Time: 0.478s,  267.53/s  (0.470s,  272.43/s)  LR: 1.343e-05  Data: 0.006 (0.009)
2024-04-07 13:09:05,554 - train - INFO - Train: 142 [ 200/781 ( 26%)]  Loss:  3.857767 (3.4429)  Time: 0.491s,  260.56/s  (0.471s,  271.50/s)  LR: 1.343e-05  Data: 0.009 (0.009)
2024-04-07 13:09:28,935 - train - INFO - Train: 142 [ 250/781 ( 32%)]  Loss:  3.483206 (3.4472)  Time: 0.508s,  252.13/s  (0.471s,  271.94/s)  LR: 1.343e-05  Data: 0.008 (0.008)
2024-04-07 13:09:53,037 - train - INFO - Train: 142 [ 300/781 ( 38%)]  Loss:  3.275031 (3.4509)  Time: 0.490s,  261.22/s  (0.473s,  270.86/s)  LR: 1.343e-05  Data: 0.009 (0.008)
2024-04-07 13:10:17,036 - train - INFO - Train: 142 [ 350/781 ( 45%)]  Loss:  3.772882 (3.4583)  Time: 0.463s,  276.58/s  (0.474s,  270.26/s)  LR: 1.343e-05  Data: 0.010 (0.008)
2024-04-07 13:10:40,292 - train - INFO - Train: 142 [ 400/781 ( 51%)]  Loss:  3.777386 (3.4564)  Time: 0.405s,  316.09/s  (0.473s,  270.87/s)  LR: 1.343e-05  Data: 0.006 (0.008)
2024-04-07 13:11:03,170 - train - INFO - Train: 142 [ 450/781 ( 58%)]  Loss:  3.696642 (3.4549)  Time: 0.438s,  292.41/s  (0.471s,  271.83/s)  LR: 1.343e-05  Data: 0.009 (0.008)
2024-04-07 13:11:26,779 - train - INFO - Train: 142 [ 500/781 ( 64%)]  Loss:  3.105026 (3.4498)  Time: 0.471s,  271.53/s  (0.471s,  271.75/s)  LR: 1.343e-05  Data: 0.005 (0.008)
2024-04-07 13:11:50,119 - train - INFO - Train: 142 [ 550/781 ( 71%)]  Loss:  3.255361 (3.4527)  Time: 0.468s,  273.73/s  (0.471s,  271.98/s)  LR: 1.343e-05  Data: 0.010 (0.008)
2024-04-07 13:12:14,196 - train - INFO - Train: 142 [ 600/781 ( 77%)]  Loss:  3.775555 (3.4549)  Time: 0.454s,  281.82/s  (0.472s,  271.45/s)  LR: 1.343e-05  Data: 0.006 (0.008)
2024-04-07 13:12:37,563 - train - INFO - Train: 142 [ 650/781 ( 83%)]  Loss:  3.360326 (3.4547)  Time: 0.465s,  275.15/s  (0.471s,  271.64/s)  LR: 1.343e-05  Data: 0.009 (0.008)
2024-04-07 13:13:01,572 - train - INFO - Train: 142 [ 700/781 ( 90%)]  Loss:  3.181056 (3.4562)  Time: 0.477s,  268.30/s  (0.472s,  271.27/s)  LR: 1.343e-05  Data: 0.009 (0.008)
2024-04-07 13:13:25,442 - train - INFO - Train: 142 [ 750/781 ( 96%)]  Loss:  3.561990 (3.4540)  Time: 0.463s,  276.26/s  (0.472s,  271.06/s)  LR: 1.343e-05  Data: 0.007 (0.008)
2024-04-07 13:13:39,910 - train - INFO - Train: 142 [ 780/781 (100%)]  Loss:  3.668401 (3.4564)  Time: 0.472s,  271.08/s  (0.473s,  270.84/s)  LR: 1.343e-05  Data: 0.000 (0.008)
2024-04-07 13:13:39,910 - train - INFO - True
2024-04-07 13:13:39,912 - train - INFO - alphas:tensor([0.8104, 0.0087, 0.0188, 0.0321, 0.1301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,912 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,912 - train - INFO - True
2024-04-07 13:13:39,913 - train - INFO - alphas:tensor([0.4692, 0.0021, 0.0065, 0.0288, 0.4935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,914 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,914 - train - INFO - True
2024-04-07 13:13:39,915 - train - INFO - alphas:tensor([0.5209, 0.0049, 0.0253, 0.4489], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,916 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,916 - train - INFO - True
2024-04-07 13:13:39,917 - train - INFO - alphas:tensor([0.4445, 0.0051, 0.0157, 0.5347], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,917 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,917 - train - INFO - True
2024-04-07 13:13:39,918 - train - INFO - alphas:tensor([0.4525, 0.0026, 0.0206, 0.5243], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,919 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,919 - train - INFO - True
2024-04-07 13:13:39,920 - train - INFO - alphas:tensor([0.5554, 0.0052, 0.0160, 0.4234], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,920 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,920 - train - INFO - True
2024-04-07 13:13:39,921 - train - INFO - alphas:tensor([0.6245, 0.0020, 0.0034, 0.0161, 0.3540], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,922 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,923 - train - INFO - True
2024-04-07 13:13:39,923 - train - INFO - alphas:tensor([2.1777e-01, 9.2569e-04, 6.4265e-04, 1.7422e-02, 7.6323e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,924 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,924 - train - INFO - True
2024-04-07 13:13:39,925 - train - INFO - alphas:tensor([2.2403e-01, 5.1447e-04, 8.1337e-04, 1.1490e-02, 7.6315e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,926 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,926 - train - INFO - True
2024-04-07 13:13:39,927 - train - INFO - alphas:tensor([2.2578e-01, 2.7743e-04, 6.4974e-04, 1.4289e-02, 7.5900e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,927 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,927 - train - INFO - True
2024-04-07 13:13:39,928 - train - INFO - alphas:tensor([2.1311e-01, 7.0887e-04, 7.0349e-04, 1.8476e-02, 7.6700e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,929 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,929 - train - INFO - True
2024-04-07 13:13:39,930 - train - INFO - alphas:tensor([6.0730e-01, 5.0585e-04, 1.5993e-03, 1.3350e-02, 3.7724e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,931 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,931 - train - INFO - True
2024-04-07 13:13:39,932 - train - INFO - alphas:tensor([7.3944e-01, 7.2226e-04, 1.0944e-03, 7.3034e-03, 2.5144e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,935 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,936 - train - INFO - True
2024-04-07 13:13:39,936 - train - INFO - alphas:tensor([0.2700, 0.0027, 0.0028, 0.0439, 0.6806], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,938 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,938 - train - INFO - True
2024-04-07 13:13:39,939 - train - INFO - alphas:tensor([0.2787, 0.0009, 0.0014, 0.0359, 0.6831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,941 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,941 - train - INFO - True
2024-04-07 13:13:39,942 - train - INFO - alphas:tensor([3.0167e-01, 6.2663e-04, 1.5061e-03, 3.1310e-02, 6.6488e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,944 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,944 - train - INFO - True
2024-04-07 13:13:39,945 - train - INFO - alphas:tensor([0.2728, 0.0012, 0.0019, 0.0297, 0.6945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,947 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,947 - train - INFO - True
2024-04-07 13:13:39,948 - train - INFO - alphas:tensor([0.3033, 0.0007, 0.0024, 0.0328, 0.6608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,950 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,950 - train - INFO - True
2024-04-07 13:13:39,951 - train - INFO - alphas:tensor([0.2641, 0.0025, 0.0038, 0.0360, 0.6936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,953 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,953 - train - INFO - True
2024-04-07 13:13:39,954 - train - INFO - alphas:tensor([6.5717e-01, 3.3047e-04, 9.6645e-04, 1.5897e-02, 3.2563e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,957 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,957 - train - INFO - True
2024-04-07 13:13:39,958 - train - INFO - alphas:tensor([5.8374e-01, 2.9340e-04, 4.9939e-04, 1.5010e-02, 4.0046e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,966 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,966 - train - INFO - True
2024-04-07 13:13:39,966 - train - INFO - alphas:tensor([4.4957e-01, 2.3338e-04, 1.4639e-03, 2.6068e-02, 5.2266e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,970 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,970 - train - INFO - True
2024-04-07 13:13:39,971 - train - INFO - alphas:tensor([4.5912e-01, 2.5410e-04, 5.2987e-04, 2.3149e-02, 5.1695e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,975 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,975 - train - INFO - True
2024-04-07 13:13:39,976 - train - INFO - alphas:tensor([4.7697e-01, 2.0974e-04, 5.4866e-04, 2.1094e-02, 5.0118e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,980 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,980 - train - INFO - True
2024-04-07 13:13:39,981 - train - INFO - alphas:tensor([4.3783e-01, 2.6286e-04, 1.0157e-03, 2.4373e-02, 5.3652e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,985 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,985 - train - INFO - True
2024-04-07 13:13:39,986 - train - INFO - alphas:tensor([5.8968e-01, 2.1640e-04, 8.2291e-04, 1.2702e-02, 3.9658e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:39,993 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:39,993 - train - INFO - True
2024-04-07 13:13:39,994 - train - INFO - alphas:tensor([7.8317e-01, 1.3885e-04, 5.4055e-04, 7.6951e-03, 2.0846e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:40,013 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:40,014 - train - INFO - True
2024-04-07 13:13:40,014 - train - INFO - alphas:tensor([4.0601e-01, 3.6575e-04, 1.0366e-03, 3.5466e-02, 5.5713e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:40,024 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:40,025 - train - INFO - True
2024-04-07 13:13:40,025 - train - INFO - alphas:tensor([4.1481e-01, 1.5904e-04, 7.0786e-04, 2.4748e-02, 5.5957e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:40,036 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:40,036 - train - INFO - True
2024-04-07 13:13:40,036 - train - INFO - alphas:tensor([4.4610e-01, 2.0525e-04, 5.1934e-04, 2.8243e-02, 5.2493e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:40,047 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:40,047 - train - INFO - True
2024-04-07 13:13:40,048 - train - INFO - alphas:tensor([4.0544e-01, 2.6606e-04, 8.5713e-04, 2.7734e-02, 5.6570e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:40,058 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:40,058 - train - INFO - True
2024-04-07 13:13:40,059 - train - INFO - alphas:tensor([7.5009e-01, 1.1708e-04, 2.6293e-04, 6.2240e-03, 2.4331e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:40,078 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:40,078 - train - INFO - True
2024-04-07 13:13:40,079 - train - INFO - alphas:tensor([0.5976, 0.0018, 0.0037, 0.0341, 0.3628], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:13:40,156 - train - INFO - tau:0.24486529903492946
2024-04-07 13:13:40,157 - train - INFO - avg block size:10.06060606060606
2024-04-07 13:13:40,157 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 13:13:40,157 - train - INFO - lasso_alpha:7.116820547673461e-07
2024-04-07 13:13:40,337 - train - INFO - Test: [   0/78]  Time: 0.177 (0.177)  Loss:  0.9731 (0.9731)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 13:13:43,557 - train - INFO - Test: [  50/78]  Time: 0.053 (0.067)  Loss:  1.5537 (1.5452)  Acc@1: 67.1875 (65.9314)  Acc@5: 87.5000 (86.5196)
2024-04-07 13:13:45,294 - train - INFO - Test: [  78/78]  Time: 0.071 (0.065)  Loss:  1.8164 (1.5645)  Acc@1: 56.2500 (65.6900)  Acc@5: 87.5000 (86.2500)
2024-04-07 13:13:46,082 - train - INFO - Train: 143 [   0/781 (  0%)]  Loss:  3.487149 (3.4871)  Time: 0.677s,  188.97/s  (0.677s,  188.97/s)  LR: 1.263e-05  Data: 0.194 (0.194)
2024-04-07 13:14:09,990 - train - INFO - Train: 143 [  50/781 (  6%)]  Loss:  3.100389 (3.4569)  Time: 0.465s,  275.21/s  (0.482s,  265.54/s)  LR: 1.263e-05  Data: 0.007 (0.011)
2024-04-07 13:14:32,754 - train - INFO - Train: 143 [ 100/781 ( 13%)]  Loss:  3.439146 (3.4706)  Time: 0.443s,  288.86/s  (0.469s,  273.05/s)  LR: 1.263e-05  Data: 0.008 (0.009)
2024-04-07 13:14:55,838 - train - INFO - Train: 143 [ 150/781 ( 19%)]  Loss:  3.343116 (3.4746)  Time: 0.499s,  256.66/s  (0.466s,  274.43/s)  LR: 1.263e-05  Data: 0.009 (0.009)
2024-04-07 13:15:19,650 - train - INFO - Train: 143 [ 200/781 ( 26%)]  Loss:  3.067848 (3.4697)  Time: 0.517s,  247.45/s  (0.469s,  273.01/s)  LR: 1.263e-05  Data: 0.009 (0.008)
2024-04-07 13:15:42,497 - train - INFO - Train: 143 [ 250/781 ( 32%)]  Loss:  3.366518 (3.4663)  Time: 0.479s,  266.96/s  (0.466s,  274.40/s)  LR: 1.263e-05  Data: 0.006 (0.008)
2024-04-07 13:16:06,291 - train - INFO - Train: 143 [ 300/781 ( 38%)]  Loss:  3.570070 (3.4710)  Time: 0.454s,  281.76/s  (0.468s,  273.49/s)  LR: 1.263e-05  Data: 0.007 (0.008)
2024-04-07 13:16:28,814 - train - INFO - Train: 143 [ 350/781 ( 45%)]  Loss:  3.178900 (3.4687)  Time: 0.376s,  340.00/s  (0.466s,  274.96/s)  LR: 1.263e-05  Data: 0.004 (0.008)
2024-04-07 13:16:53,031 - train - INFO - Train: 143 [ 400/781 ( 51%)]  Loss:  3.614627 (3.4655)  Time: 0.417s,  306.78/s  (0.468s,  273.58/s)  LR: 1.263e-05  Data: 0.005 (0.008)
2024-04-07 13:17:15,225 - train - INFO - Train: 143 [ 450/781 ( 58%)]  Loss:  3.131137 (3.4591)  Time: 0.407s,  314.34/s  (0.465s,  275.15/s)  LR: 1.263e-05  Data: 0.009 (0.008)
2024-04-07 13:17:39,101 - train - INFO - Train: 143 [ 500/781 ( 64%)]  Loss:  3.546606 (3.4563)  Time: 0.463s,  276.64/s  (0.466s,  274.43/s)  LR: 1.263e-05  Data: 0.009 (0.008)
2024-04-07 13:18:02,359 - train - INFO - Train: 143 [ 550/781 ( 71%)]  Loss:  3.556195 (3.4540)  Time: 0.458s,  279.19/s  (0.466s,  274.50/s)  LR: 1.263e-05  Data: 0.007 (0.008)
2024-04-07 13:18:25,735 - train - INFO - Train: 143 [ 600/781 ( 77%)]  Loss:  3.682284 (3.4540)  Time: 0.420s,  304.82/s  (0.466s,  274.44/s)  LR: 1.263e-05  Data: 0.008 (0.008)
2024-04-07 13:18:48,615 - train - INFO - Train: 143 [ 650/781 ( 83%)]  Loss:  3.302948 (3.4582)  Time: 0.451s,  283.76/s  (0.466s,  274.84/s)  LR: 1.263e-05  Data: 0.008 (0.008)
2024-04-07 13:19:12,884 - train - INFO - Train: 143 [ 700/781 ( 90%)]  Loss:  3.181860 (3.4562)  Time: 0.499s,  256.70/s  (0.467s,  274.01/s)  LR: 1.263e-05  Data: 0.009 (0.008)
2024-04-07 13:19:36,223 - train - INFO - Train: 143 [ 750/781 ( 96%)]  Loss:  3.606980 (3.4592)  Time: 0.461s,  277.38/s  (0.467s,  274.03/s)  LR: 1.263e-05  Data: 0.005 (0.008)
2024-04-07 13:19:49,161 - train - INFO - Train: 143 [ 780/781 (100%)]  Loss:  3.523431 (3.4602)  Time: 0.388s,  329.99/s  (0.466s,  274.84/s)  LR: 1.263e-05  Data: 0.000 (0.008)
2024-04-07 13:19:49,161 - train - INFO - True
2024-04-07 13:19:49,162 - train - INFO - alphas:tensor([0.8139, 0.0084, 0.0182, 0.0312, 0.1283], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,163 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,163 - train - INFO - True
2024-04-07 13:19:49,164 - train - INFO - alphas:tensor([0.4693, 0.0020, 0.0062, 0.0281, 0.4944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,164 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,164 - train - INFO - True
2024-04-07 13:19:49,165 - train - INFO - alphas:tensor([0.5218, 0.0047, 0.0247, 0.4488], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,166 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,166 - train - INFO - True
2024-04-07 13:19:49,167 - train - INFO - alphas:tensor([0.4445, 0.0049, 0.0151, 0.5354], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,167 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,167 - train - INFO - True
2024-04-07 13:19:49,168 - train - INFO - alphas:tensor([0.4531, 0.0025, 0.0200, 0.5244], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,168 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,168 - train - INFO - True
2024-04-07 13:19:49,169 - train - INFO - alphas:tensor([0.5562, 0.0049, 0.0155, 0.4233], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,170 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,170 - train - INFO - True
2024-04-07 13:19:49,171 - train - INFO - alphas:tensor([0.6258, 0.0019, 0.0032, 0.0156, 0.3535], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,171 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,172 - train - INFO - True
2024-04-07 13:19:49,172 - train - INFO - alphas:tensor([2.1685e-01, 8.7154e-04, 6.0269e-04, 1.6933e-02, 7.6474e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,173 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,173 - train - INFO - True
2024-04-07 13:19:49,174 - train - INFO - alphas:tensor([2.2227e-01, 4.7951e-04, 7.6302e-04, 1.1085e-02, 7.6540e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,174 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,174 - train - INFO - True
2024-04-07 13:19:49,175 - train - INFO - alphas:tensor([2.2433e-01, 2.5768e-04, 6.0923e-04, 1.3859e-02, 7.6094e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,176 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,176 - train - INFO - True
2024-04-07 13:19:49,176 - train - INFO - alphas:tensor([2.1122e-01, 6.6286e-04, 6.5911e-04, 1.7859e-02, 7.6960e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,177 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,177 - train - INFO - True
2024-04-07 13:19:49,178 - train - INFO - alphas:tensor([6.0881e-01, 4.7226e-04, 1.5086e-03, 1.2904e-02, 3.7631e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,179 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,179 - train - INFO - True
2024-04-07 13:19:49,179 - train - INFO - alphas:tensor([7.4096e-01, 6.7722e-04, 1.0301e-03, 6.9972e-03, 2.5033e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,182 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,182 - train - INFO - True
2024-04-07 13:19:49,183 - train - INFO - alphas:tensor([0.2691, 0.0025, 0.0027, 0.0431, 0.6826], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,185 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,185 - train - INFO - True
2024-04-07 13:19:49,185 - train - INFO - alphas:tensor([0.2775, 0.0008, 0.0013, 0.0351, 0.6852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,187 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,187 - train - INFO - True
2024-04-07 13:19:49,188 - train - INFO - alphas:tensor([3.0088e-01, 5.8645e-04, 1.4258e-03, 3.0562e-02, 6.6655e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,189 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,189 - train - INFO - True
2024-04-07 13:19:49,190 - train - INFO - alphas:tensor([0.2716, 0.0011, 0.0018, 0.0289, 0.6966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,191 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,191 - train - INFO - True
2024-04-07 13:19:49,192 - train - INFO - alphas:tensor([0.3030, 0.0007, 0.0023, 0.0320, 0.6620], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,194 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,194 - train - INFO - True
2024-04-07 13:19:49,195 - train - INFO - alphas:tensor([0.2635, 0.0024, 0.0036, 0.0352, 0.6953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,196 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,196 - train - INFO - True
2024-04-07 13:19:49,197 - train - INFO - alphas:tensor([6.5823e-01, 3.0789e-04, 9.1157e-04, 1.5419e-02, 3.2513e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,199 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,199 - train - INFO - True
2024-04-07 13:19:49,200 - train - INFO - alphas:tensor([5.8404e-01, 2.7221e-04, 4.6632e-04, 1.4513e-02, 4.0071e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,207 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,207 - train - INFO - True
2024-04-07 13:19:49,208 - train - INFO - alphas:tensor([4.5014e-01, 2.1631e-04, 1.3818e-03, 2.5339e-02, 5.2292e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,210 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,211 - train - INFO - True
2024-04-07 13:19:49,211 - train - INFO - alphas:tensor([4.5971e-01, 2.3609e-04, 4.9552e-04, 2.2519e-02, 5.1704e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,219 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,219 - train - INFO - True
2024-04-07 13:19:49,220 - train - INFO - alphas:tensor([4.7645e-01, 1.9439e-04, 5.1386e-04, 2.0551e-02, 5.0230e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,223 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,223 - train - INFO - True
2024-04-07 13:19:49,223 - train - INFO - alphas:tensor([4.3777e-01, 2.4362e-04, 9.5567e-04, 2.3736e-02, 5.3729e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,226 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,226 - train - INFO - True
2024-04-07 13:19:49,227 - train - INFO - alphas:tensor([5.9081e-01, 2.0083e-04, 7.7492e-04, 1.2289e-02, 3.9593e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,233 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,233 - train - INFO - True
2024-04-07 13:19:49,234 - train - INFO - alphas:tensor([7.8441e-01, 1.2795e-04, 5.0545e-04, 7.4000e-03, 2.0756e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,248 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,248 - train - INFO - True
2024-04-07 13:19:49,249 - train - INFO - alphas:tensor([4.0680e-01, 3.4137e-04, 9.7721e-04, 3.4669e-02, 5.5721e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,256 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,256 - train - INFO - True
2024-04-07 13:19:49,257 - train - INFO - alphas:tensor([4.1522e-01, 1.4703e-04, 6.6562e-04, 2.4126e-02, 5.5984e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,264 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,264 - train - INFO - True
2024-04-07 13:19:49,264 - train - INFO - alphas:tensor([4.4527e-01, 1.9002e-04, 4.8663e-04, 2.7630e-02, 5.2642e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,271 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,271 - train - INFO - True
2024-04-07 13:19:49,272 - train - INFO - alphas:tensor([4.0627e-01, 2.4715e-04, 8.0619e-04, 2.7084e-02, 5.6559e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,279 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,279 - train - INFO - True
2024-04-07 13:19:49,280 - train - INFO - alphas:tensor([7.5063e-01, 1.0782e-04, 2.4441e-04, 5.9862e-03, 2.4303e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,292 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,292 - train - INFO - True
2024-04-07 13:19:49,293 - train - INFO - alphas:tensor([0.5984, 0.0017, 0.0035, 0.0334, 0.3630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:19:49,342 - train - INFO - tau:0.24241664604458016
2024-04-07 13:19:49,342 - train - INFO - avg block size:10.06060606060606
2024-04-07 13:19:49,343 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 13:19:49,552 - train - INFO - Test: [   0/78]  Time: 0.207 (0.207)  Loss:  0.9575 (0.9575)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.9688 (92.9688)
2024-04-07 13:19:52,497 - train - INFO - Test: [  50/78]  Time: 0.055 (0.062)  Loss:  1.5508 (1.5478)  Acc@1: 68.7500 (66.1458)  Acc@5: 85.9375 (86.4277)
2024-04-07 13:19:54,024 - train - INFO - Test: [  78/78]  Time: 0.046 (0.059)  Loss:  1.9189 (1.5670)  Acc@1: 56.2500 (65.8500)  Acc@5: 87.5000 (86.1100)
2024-04-07 13:19:54,743 - train - INFO - Train: 144 [   0/781 (  0%)]  Loss:  3.725276 (3.7253)  Time: 0.639s,  200.39/s  (0.639s,  200.39/s)  LR: 1.193e-05  Data: 0.177 (0.177)
2024-04-07 13:20:17,672 - train - INFO - Train: 144 [  50/781 (  6%)]  Loss:  3.448157 (3.4574)  Time: 0.518s,  247.34/s  (0.462s,  277.01/s)  LR: 1.193e-05  Data: 0.009 (0.011)
2024-04-07 13:20:41,621 - train - INFO - Train: 144 [ 100/781 ( 13%)]  Loss:  3.577999 (3.4535)  Time: 0.404s,  316.54/s  (0.470s,  272.09/s)  LR: 1.193e-05  Data: 0.004 (0.009)
2024-04-07 13:21:05,485 - train - INFO - Train: 144 [ 150/781 ( 19%)]  Loss:  3.696171 (3.4521)  Time: 0.481s,  265.99/s  (0.473s,  270.80/s)  LR: 1.193e-05  Data: 0.007 (0.009)
2024-04-07 13:21:27,871 - train - INFO - Train: 144 [ 200/781 ( 26%)]  Loss:  3.534035 (3.4558)  Time: 0.468s,  273.45/s  (0.466s,  274.40/s)  LR: 1.193e-05  Data: 0.006 (0.008)
2024-04-07 13:21:50,312 - train - INFO - Train: 144 [ 250/781 ( 32%)]  Loss:  3.289674 (3.4519)  Time: 0.453s,  282.51/s  (0.463s,  276.49/s)  LR: 1.193e-05  Data: 0.006 (0.008)
2024-04-07 13:22:12,800 - train - INFO - Train: 144 [ 300/781 ( 38%)]  Loss:  3.563853 (3.4479)  Time: 0.501s,  255.71/s  (0.461s,  277.81/s)  LR: 1.193e-05  Data: 0.009 (0.008)
2024-04-07 13:22:34,909 - train - INFO - Train: 144 [ 350/781 ( 45%)]  Loss:  3.461494 (3.4473)  Time: 0.411s,  311.58/s  (0.458s,  279.42/s)  LR: 1.193e-05  Data: 0.005 (0.008)
2024-04-07 13:22:57,773 - train - INFO - Train: 144 [ 400/781 ( 51%)]  Loss:  3.536879 (3.4546)  Time: 0.355s,  360.21/s  (0.458s,  279.48/s)  LR: 1.193e-05  Data: 0.005 (0.008)
2024-04-07 13:23:21,396 - train - INFO - Train: 144 [ 450/781 ( 58%)]  Loss:  3.544751 (3.4567)  Time: 0.488s,  262.38/s  (0.460s,  278.51/s)  LR: 1.193e-05  Data: 0.008 (0.008)
2024-04-07 13:23:44,616 - train - INFO - Train: 144 [ 500/781 ( 64%)]  Loss:  3.358567 (3.4634)  Time: 0.553s,  231.48/s  (0.460s,  278.22/s)  LR: 1.193e-05  Data: 0.009 (0.008)
2024-04-07 13:24:08,226 - train - INFO - Train: 144 [ 550/781 ( 71%)]  Loss:  3.655103 (3.4618)  Time: 0.457s,  279.90/s  (0.461s,  277.56/s)  LR: 1.193e-05  Data: 0.005 (0.008)
2024-04-07 13:24:31,874 - train - INFO - Train: 144 [ 600/781 ( 77%)]  Loss:  3.516599 (3.4578)  Time: 0.489s,  261.83/s  (0.462s,  276.97/s)  LR: 1.193e-05  Data: 0.007 (0.008)
2024-04-07 13:24:55,955 - train - INFO - Train: 144 [ 650/781 ( 83%)]  Loss:  3.224823 (3.4618)  Time: 0.481s,  265.94/s  (0.464s,  276.08/s)  LR: 1.193e-05  Data: 0.007 (0.008)
2024-04-07 13:25:19,086 - train - INFO - Train: 144 [ 700/781 ( 90%)]  Loss:  2.921307 (3.4589)  Time: 0.425s,  301.34/s  (0.464s,  276.12/s)  LR: 1.193e-05  Data: 0.008 (0.008)
2024-04-07 13:25:42,944 - train - INFO - Train: 144 [ 750/781 ( 96%)]  Loss:  3.387046 (3.4593)  Time: 0.457s,  280.36/s  (0.464s,  275.59/s)  LR: 1.193e-05  Data: 0.005 (0.008)
2024-04-07 13:25:56,819 - train - INFO - Train: 144 [ 780/781 (100%)]  Loss:  3.649773 (3.4617)  Time: 0.484s,  264.42/s  (0.464s,  275.63/s)  LR: 1.193e-05  Data: 0.000 (0.008)
2024-04-07 13:25:56,820 - train - INFO - True
2024-04-07 13:25:56,822 - train - INFO - alphas:tensor([0.8173, 0.0081, 0.0176, 0.0304, 0.1266], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,822 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,823 - train - INFO - True
2024-04-07 13:25:56,824 - train - INFO - alphas:tensor([0.4692, 0.0019, 0.0059, 0.0274, 0.4956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,824 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,825 - train - INFO - True
2024-04-07 13:25:56,826 - train - INFO - alphas:tensor([0.5221, 0.0045, 0.0240, 0.4494], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,827 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,827 - train - INFO - True
2024-04-07 13:25:56,829 - train - INFO - alphas:tensor([0.4442, 0.0047, 0.0147, 0.5364], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,829 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,829 - train - INFO - True
2024-04-07 13:25:56,831 - train - INFO - alphas:tensor([0.4527, 0.0024, 0.0194, 0.5255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,831 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,832 - train - INFO - True
2024-04-07 13:25:56,833 - train - INFO - alphas:tensor([0.5567, 0.0047, 0.0151, 0.4235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,834 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,834 - train - INFO - True
2024-04-07 13:25:56,835 - train - INFO - alphas:tensor([0.6268, 0.0018, 0.0031, 0.0151, 0.3533], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,837 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,837 - train - INFO - True
2024-04-07 13:25:56,838 - train - INFO - alphas:tensor([2.1570e-01, 8.1894e-04, 5.6339e-04, 1.6374e-02, 7.6654e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,839 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,839 - train - INFO - True
2024-04-07 13:25:56,840 - train - INFO - alphas:tensor([2.2103e-01, 4.4849e-04, 7.1675e-04, 1.0686e-02, 7.6712e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,841 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,841 - train - INFO - True
2024-04-07 13:25:56,843 - train - INFO - alphas:tensor([2.2262e-01, 2.3935e-04, 5.6942e-04, 1.3397e-02, 7.6317e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,843 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,844 - train - INFO - True
2024-04-07 13:25:56,845 - train - INFO - alphas:tensor([2.1051e-01, 6.2178e-04, 6.1795e-04, 1.7346e-02, 7.7090e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,846 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,846 - train - INFO - True
2024-04-07 13:25:56,847 - train - INFO - alphas:tensor([6.0905e-01, 4.4029e-04, 1.4251e-03, 1.2476e-02, 3.7661e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,848 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,848 - train - INFO - True
2024-04-07 13:25:56,850 - train - INFO - alphas:tensor([7.4277e-01, 6.3413e-04, 9.6795e-04, 6.7104e-03, 2.4891e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,854 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,854 - train - INFO - True
2024-04-07 13:25:56,855 - train - INFO - alphas:tensor([0.2685, 0.0024, 0.0025, 0.0423, 0.6843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,858 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,858 - train - INFO - True
2024-04-07 13:25:56,859 - train - INFO - alphas:tensor([0.2773, 0.0008, 0.0012, 0.0343, 0.6864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,861 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,861 - train - INFO - True
2024-04-07 13:25:56,862 - train - INFO - alphas:tensor([2.9968e-01, 5.4935e-04, 1.3470e-03, 2.9884e-02, 6.6854e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,865 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,865 - train - INFO - True
2024-04-07 13:25:56,866 - train - INFO - alphas:tensor([0.2712, 0.0010, 0.0017, 0.0282, 0.6980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,868 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,868 - train - INFO - True
2024-04-07 13:25:56,869 - train - INFO - alphas:tensor([3.0247e-01, 6.2927e-04, 2.2073e-03, 3.1259e-02, 6.6344e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,871 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,872 - train - INFO - True
2024-04-07 13:25:56,873 - train - INFO - alphas:tensor([0.2627, 0.0023, 0.0034, 0.0344, 0.6972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,875 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,875 - train - INFO - True
2024-04-07 13:25:56,876 - train - INFO - alphas:tensor([6.5952e-01, 2.8618e-04, 8.5630e-04, 1.4937e-02, 3.2440e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,880 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,880 - train - INFO - True
2024-04-07 13:25:56,881 - train - INFO - alphas:tensor([5.8556e-01, 2.5268e-04, 4.3517e-04, 1.4038e-02, 3.9971e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,889 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,889 - train - INFO - True
2024-04-07 13:25:56,890 - train - INFO - alphas:tensor([4.4981e-01, 2.0020e-04, 1.3064e-03, 2.4704e-02, 5.2398e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,894 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,894 - train - INFO - True
2024-04-07 13:25:56,895 - train - INFO - alphas:tensor([4.5892e-01, 2.1859e-04, 4.6299e-04, 2.1904e-02, 5.1850e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,899 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,899 - train - INFO - True
2024-04-07 13:25:56,900 - train - INFO - alphas:tensor([4.7588e-01, 1.8000e-04, 4.8107e-04, 1.9970e-02, 5.0349e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,904 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,904 - train - INFO - True
2024-04-07 13:25:56,905 - train - INFO - alphas:tensor([4.3794e-01, 2.2587e-04, 8.9935e-04, 2.3094e-02, 5.3785e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,909 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,909 - train - INFO - True
2024-04-07 13:25:56,910 - train - INFO - alphas:tensor([5.9125e-01, 1.8593e-04, 7.2763e-04, 1.1859e-02, 3.9598e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,917 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,917 - train - INFO - True
2024-04-07 13:25:56,918 - train - INFO - alphas:tensor([7.8562e-01, 1.1807e-04, 4.7269e-04, 7.1207e-03, 2.0666e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,937 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,937 - train - INFO - True
2024-04-07 13:25:56,938 - train - INFO - alphas:tensor([4.0776e-01, 3.1740e-04, 9.1916e-04, 3.3874e-02, 5.5713e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,948 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,948 - train - INFO - True
2024-04-07 13:25:56,949 - train - INFO - alphas:tensor([4.1508e-01, 1.3574e-04, 6.2373e-04, 2.3530e-02, 5.6063e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,959 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,959 - train - INFO - True
2024-04-07 13:25:56,960 - train - INFO - alphas:tensor([4.4522e-01, 1.7592e-04, 4.5458e-04, 2.6979e-02, 5.2717e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,970 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,971 - train - INFO - True
2024-04-07 13:25:56,971 - train - INFO - alphas:tensor([4.0629e-01, 2.2941e-04, 7.5870e-04, 2.6480e-02, 5.6624e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:56,981 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:56,982 - train - INFO - True
2024-04-07 13:25:56,982 - train - INFO - alphas:tensor([7.5165e-01, 9.9403e-05, 2.2695e-04, 5.7403e-03, 2.4229e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:57,002 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:57,002 - train - INFO - True
2024-04-07 13:25:57,003 - train - INFO - alphas:tensor([0.5996, 0.0016, 0.0033, 0.0327, 0.3628], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:25:57,080 - train - INFO - tau:0.23999247958413436
2024-04-07 13:25:57,080 - train - INFO - avg block size:10.06060606060606
2024-04-07 13:25:57,081 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 13:25:57,081 - train - INFO - lasso_alpha:6.469836861521327e-07
2024-04-07 13:25:57,294 - train - INFO - Test: [   0/78]  Time: 0.210 (0.210)  Loss:  0.9434 (0.9434)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 13:26:00,145 - train - INFO - Test: [  50/78]  Time: 0.050 (0.060)  Loss:  1.5254 (1.5464)  Acc@1: 66.4062 (65.9773)  Acc@5: 87.5000 (86.2439)
2024-04-07 13:26:01,837 - train - INFO - Test: [  78/78]  Time: 0.049 (0.060)  Loss:  1.7910 (1.5620)  Acc@1: 56.2500 (65.8300)  Acc@5: 93.7500 (86.0600)
2024-04-07 13:26:02,551 - train - INFO - Train: 145 [   0/781 (  0%)]  Loss:  3.296215 (3.2962)  Time: 0.635s,  201.59/s  (0.635s,  201.59/s)  LR: 1.134e-05  Data: 0.180 (0.180)
2024-04-07 13:26:25,412 - train - INFO - Train: 145 [  50/781 (  6%)]  Loss:  3.110526 (3.4802)  Time: 0.460s,  278.48/s  (0.461s,  277.85/s)  LR: 1.134e-05  Data: 0.008 (0.011)
2024-04-07 13:26:48,707 - train - INFO - Train: 145 [ 100/781 ( 13%)]  Loss:  3.538326 (3.4635)  Time: 0.346s,  369.73/s  (0.463s,  276.31/s)  LR: 1.134e-05  Data: 0.004 (0.009)
2024-04-07 13:27:11,358 - train - INFO - Train: 145 [ 150/781 ( 19%)]  Loss:  3.526767 (3.4668)  Time: 0.497s,  257.56/s  (0.460s,  278.35/s)  LR: 1.134e-05  Data: 0.009 (0.008)
2024-04-07 13:27:34,598 - train - INFO - Train: 145 [ 200/781 ( 26%)]  Loss:  3.310931 (3.4580)  Time: 0.478s,  267.76/s  (0.461s,  277.61/s)  LR: 1.134e-05  Data: 0.007 (0.008)
2024-04-07 13:27:57,544 - train - INFO - Train: 145 [ 250/781 ( 32%)]  Loss:  3.837559 (3.4599)  Time: 0.502s,  255.13/s  (0.461s,  277.88/s)  LR: 1.134e-05  Data: 0.008 (0.008)
2024-04-07 13:28:21,697 - train - INFO - Train: 145 [ 300/781 ( 38%)]  Loss:  3.689485 (3.4571)  Time: 0.500s,  255.97/s  (0.464s,  275.65/s)  LR: 1.134e-05  Data: 0.009 (0.008)
2024-04-07 13:28:45,230 - train - INFO - Train: 145 [ 350/781 ( 45%)]  Loss:  3.721854 (3.4621)  Time: 0.507s,  252.24/s  (0.465s,  275.12/s)  LR: 1.134e-05  Data: 0.009 (0.008)
2024-04-07 13:29:08,759 - train - INFO - Train: 145 [ 400/781 ( 51%)]  Loss:  3.502425 (3.4586)  Time: 0.466s,  274.41/s  (0.466s,  274.73/s)  LR: 1.134e-05  Data: 0.009 (0.008)
2024-04-07 13:29:31,948 - train - INFO - Train: 145 [ 450/781 ( 58%)]  Loss:  3.256216 (3.4607)  Time: 0.490s,  261.02/s  (0.466s,  274.87/s)  LR: 1.134e-05  Data: 0.010 (0.008)
2024-04-07 13:29:55,529 - train - INFO - Train: 145 [ 500/781 ( 64%)]  Loss:  3.397231 (3.4639)  Time: 0.494s,  259.28/s  (0.466s,  274.52/s)  LR: 1.134e-05  Data: 0.008 (0.008)
2024-04-07 13:30:19,104 - train - INFO - Train: 145 [ 550/781 ( 71%)]  Loss:  3.674487 (3.4646)  Time: 0.458s,  279.59/s  (0.467s,  274.25/s)  LR: 1.134e-05  Data: 0.007 (0.008)
2024-04-07 13:30:42,795 - train - INFO - Train: 145 [ 600/781 ( 77%)]  Loss:  3.825307 (3.4608)  Time: 0.453s,  282.40/s  (0.467s,  273.90/s)  LR: 1.134e-05  Data: 0.009 (0.008)
2024-04-07 13:31:06,486 - train - INFO - Train: 145 [ 650/781 ( 83%)]  Loss:  3.754400 (3.4582)  Time: 0.472s,  271.06/s  (0.468s,  273.61/s)  LR: 1.134e-05  Data: 0.008 (0.008)
2024-04-07 13:31:28,851 - train - INFO - Train: 145 [ 700/781 ( 90%)]  Loss:  3.380712 (3.4547)  Time: 0.457s,  279.95/s  (0.466s,  274.47/s)  LR: 1.134e-05  Data: 0.008 (0.008)
2024-04-07 13:31:52,525 - train - INFO - Train: 145 [ 750/781 ( 96%)]  Loss:  3.349679 (3.4503)  Time: 0.505s,  253.47/s  (0.467s,  274.19/s)  LR: 1.134e-05  Data: 0.009 (0.008)
2024-04-07 13:32:06,634 - train - INFO - Train: 145 [ 780/781 (100%)]  Loss:  3.540021 (3.4521)  Time: 0.483s,  265.25/s  (0.467s,  274.12/s)  LR: 1.134e-05  Data: 0.000 (0.008)
2024-04-07 13:32:06,635 - train - INFO - True
2024-04-07 13:32:06,636 - train - INFO - alphas:tensor([0.8205, 0.0077, 0.0170, 0.0296, 0.1251], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,636 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,637 - train - INFO - True
2024-04-07 13:32:06,638 - train - INFO - alphas:tensor([0.4693, 0.0018, 0.0057, 0.0267, 0.4965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,638 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,638 - train - INFO - True
2024-04-07 13:32:06,639 - train - INFO - alphas:tensor([0.5230, 0.0043, 0.0233, 0.4494], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,640 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,640 - train - INFO - True
2024-04-07 13:32:06,641 - train - INFO - alphas:tensor([0.4445, 0.0045, 0.0142, 0.5368], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,641 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,641 - train - INFO - True
2024-04-07 13:32:06,642 - train - INFO - alphas:tensor([0.4529, 0.0022, 0.0189, 0.5260], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,643 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,643 - train - INFO - True
2024-04-07 13:32:06,644 - train - INFO - alphas:tensor([0.5580, 0.0045, 0.0146, 0.4229], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,645 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,645 - train - INFO - True
2024-04-07 13:32:06,646 - train - INFO - alphas:tensor([0.6282, 0.0017, 0.0029, 0.0146, 0.3526], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,647 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,647 - train - INFO - True
2024-04-07 13:32:06,648 - train - INFO - alphas:tensor([2.1373e-01, 7.6849e-04, 5.2724e-04, 1.5852e-02, 7.6912e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,648 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,649 - train - INFO - True
2024-04-07 13:32:06,649 - train - INFO - alphas:tensor([2.1939e-01, 4.1834e-04, 6.7014e-04, 1.0299e-02, 7.6922e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,650 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,650 - train - INFO - True
2024-04-07 13:32:06,651 - train - INFO - alphas:tensor([2.2150e-01, 2.2198e-04, 5.3400e-04, 1.2974e-02, 7.6477e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,652 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,652 - train - INFO - True
2024-04-07 13:32:06,653 - train - INFO - alphas:tensor([2.0936e-01, 5.8253e-04, 5.7853e-04, 1.6809e-02, 7.7267e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,653 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,653 - train - INFO - True
2024-04-07 13:32:06,654 - train - INFO - alphas:tensor([6.1041e-01, 4.1080e-04, 1.3475e-03, 1.2048e-02, 3.7578e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,655 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,655 - train - INFO - True
2024-04-07 13:32:06,656 - train - INFO - alphas:tensor([7.4449e-01, 5.9350e-04, 9.1074e-04, 6.4376e-03, 2.4757e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,660 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,660 - train - INFO - True
2024-04-07 13:32:06,661 - train - INFO - alphas:tensor([0.2678, 0.0023, 0.0024, 0.0415, 0.6860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,663 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,663 - train - INFO - True
2024-04-07 13:32:06,664 - train - INFO - alphas:tensor([0.2762, 0.0007, 0.0012, 0.0335, 0.6884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,665 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,666 - train - INFO - True
2024-04-07 13:32:06,666 - train - INFO - alphas:tensor([2.9964e-01, 5.1431e-04, 1.2748e-03, 2.9203e-02, 6.6937e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,668 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,668 - train - INFO - True
2024-04-07 13:32:06,669 - train - INFO - alphas:tensor([0.2706, 0.0010, 0.0016, 0.0275, 0.6993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,671 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,671 - train - INFO - True
2024-04-07 13:32:06,672 - train - INFO - alphas:tensor([3.0136e-01, 5.8844e-04, 2.0952e-03, 3.0489e-02, 6.6546e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,674 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,674 - train - INFO - True
2024-04-07 13:32:06,675 - train - INFO - alphas:tensor([0.2620, 0.0022, 0.0033, 0.0336, 0.6990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,677 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,677 - train - INFO - True
2024-04-07 13:32:06,678 - train - INFO - alphas:tensor([6.6103e-01, 2.6554e-04, 8.0406e-04, 1.4469e-02, 3.2343e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,681 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,681 - train - INFO - True
2024-04-07 13:32:06,682 - train - INFO - alphas:tensor([5.8615e-01, 2.3420e-04, 4.0604e-04, 1.3591e-02, 3.9961e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,690 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,690 - train - INFO - True
2024-04-07 13:32:06,691 - train - INFO - alphas:tensor([4.5008e-01, 1.8499e-04, 1.2325e-03, 2.4043e-02, 5.2446e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,694 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,695 - train - INFO - True
2024-04-07 13:32:06,695 - train - INFO - alphas:tensor([4.5957e-01, 2.0231e-04, 4.3246e-04, 2.1267e-02, 5.1852e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,699 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,699 - train - INFO - True
2024-04-07 13:32:06,700 - train - INFO - alphas:tensor([4.7606e-01, 1.6610e-04, 4.4950e-04, 1.9375e-02, 5.0395e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,704 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,704 - train - INFO - True
2024-04-07 13:32:06,705 - train - INFO - alphas:tensor([4.3821e-01, 2.0956e-04, 8.4572e-04, 2.2489e-02, 5.3825e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,709 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,709 - train - INFO - True
2024-04-07 13:32:06,710 - train - INFO - alphas:tensor([5.9060e-01, 1.7200e-04, 6.8359e-04, 1.1491e-02, 3.9706e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,717 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,717 - train - INFO - True
2024-04-07 13:32:06,718 - train - INFO - alphas:tensor([7.8721e-01, 1.0865e-04, 4.4155e-04, 6.8484e-03, 2.0539e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,751 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,751 - train - INFO - True
2024-04-07 13:32:06,752 - train - INFO - alphas:tensor([4.0742e-01, 2.9503e-04, 8.6421e-04, 3.3089e-02, 5.5833e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,762 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,762 - train - INFO - True
2024-04-07 13:32:06,763 - train - INFO - alphas:tensor([4.1451e-01, 1.2477e-04, 5.8463e-04, 2.2891e-02, 5.6189e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,773 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,773 - train - INFO - True
2024-04-07 13:32:06,774 - train - INFO - alphas:tensor([4.4492e-01, 1.6231e-04, 4.2439e-04, 2.6318e-02, 5.2817e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,784 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,784 - train - INFO - True
2024-04-07 13:32:06,785 - train - INFO - alphas:tensor([4.0626e-01, 2.1278e-04, 7.1256e-04, 2.5814e-02, 5.6700e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,795 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,795 - train - INFO - True
2024-04-07 13:32:06,796 - train - INFO - alphas:tensor([7.5222e-01, 9.1455e-05, 2.1068e-04, 5.5152e-03, 2.4196e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,815 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,815 - train - INFO - True
2024-04-07 13:32:06,816 - train - INFO - alphas:tensor([0.5997, 0.0015, 0.0032, 0.0321, 0.3636], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:32:06,894 - train - INFO - tau:0.23759255478829303
2024-04-07 13:32:06,894 - train - INFO - avg block size:10.06060606060606
2024-04-07 13:32:06,894 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 13:32:07,089 - train - INFO - Test: [   0/78]  Time: 0.191 (0.191)  Loss:  0.9375 (0.9375)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 13:32:10,562 - train - INFO - Test: [  50/78]  Time: 0.055 (0.072)  Loss:  1.5547 (1.5439)  Acc@1: 65.6250 (66.2837)  Acc@5: 88.2812 (86.4277)
2024-04-07 13:32:12,032 - train - INFO - Test: [  78/78]  Time: 0.053 (0.065)  Loss:  1.8594 (1.5625)  Acc@1: 50.0000 (66.0000)  Acc@5: 87.5000 (86.1500)
2024-04-07 13:32:12,751 - train - INFO - Train: 146 [   0/781 (  0%)]  Loss:  3.528713 (3.5287)  Time: 0.637s,  200.81/s  (0.637s,  200.81/s)  LR: 1.086e-05  Data: 0.179 (0.179)
2024-04-07 13:32:36,450 - train - INFO - Train: 146 [  50/781 (  6%)]  Loss:  3.642974 (3.4740)  Time: 0.473s,  270.39/s  (0.477s,  268.26/s)  LR: 1.086e-05  Data: 0.008 (0.011)
2024-04-07 13:32:59,315 - train - INFO - Train: 146 [ 100/781 ( 13%)]  Loss:  3.227774 (3.4559)  Time: 0.455s,  281.02/s  (0.467s,  273.91/s)  LR: 1.086e-05  Data: 0.007 (0.009)
2024-04-07 13:33:21,904 - train - INFO - Train: 146 [ 150/781 ( 19%)]  Loss:  3.482277 (3.4526)  Time: 0.434s,  295.03/s  (0.462s,  276.96/s)  LR: 1.086e-05  Data: 0.007 (0.009)
2024-04-07 13:33:44,879 - train - INFO - Train: 146 [ 200/781 ( 26%)]  Loss:  3.248049 (3.4583)  Time: 0.467s,  274.10/s  (0.461s,  277.36/s)  LR: 1.086e-05  Data: 0.008 (0.008)
2024-04-07 13:34:07,930 - train - INFO - Train: 146 [ 250/781 ( 32%)]  Loss:  3.490769 (3.4456)  Time: 0.435s,  294.32/s  (0.461s,  277.42/s)  LR: 1.086e-05  Data: 0.006 (0.008)
2024-04-07 13:34:30,347 - train - INFO - Train: 146 [ 300/781 ( 38%)]  Loss:  3.413679 (3.4513)  Time: 0.420s,  304.96/s  (0.459s,  278.74/s)  LR: 1.086e-05  Data: 0.006 (0.008)
2024-04-07 13:34:53,892 - train - INFO - Train: 146 [ 350/781 ( 45%)]  Loss:  3.367845 (3.4481)  Time: 0.491s,  260.84/s  (0.461s,  277.73/s)  LR: 1.086e-05  Data: 0.008 (0.008)
2024-04-07 13:35:17,573 - train - INFO - Train: 146 [ 400/781 ( 51%)]  Loss:  3.340091 (3.4507)  Time: 0.497s,  257.50/s  (0.462s,  276.78/s)  LR: 1.086e-05  Data: 0.008 (0.008)
2024-04-07 13:35:40,610 - train - INFO - Train: 146 [ 450/781 ( 58%)]  Loss:  3.245263 (3.4467)  Time: 0.474s,  270.11/s  (0.462s,  276.90/s)  LR: 1.086e-05  Data: 0.008 (0.008)
2024-04-07 13:36:04,243 - train - INFO - Train: 146 [ 500/781 ( 64%)]  Loss:  3.063316 (3.4482)  Time: 0.491s,  260.45/s  (0.463s,  276.28/s)  LR: 1.086e-05  Data: 0.006 (0.008)
2024-04-07 13:36:27,873 - train - INFO - Train: 146 [ 550/781 ( 71%)]  Loss:  3.165419 (3.4487)  Time: 0.465s,  275.40/s  (0.464s,  275.78/s)  LR: 1.086e-05  Data: 0.007 (0.008)
2024-04-07 13:36:51,279 - train - INFO - Train: 146 [ 600/781 ( 77%)]  Loss:  3.291151 (3.4500)  Time: 0.494s,  259.01/s  (0.464s,  275.58/s)  LR: 1.086e-05  Data: 0.008 (0.008)
2024-04-07 13:37:15,146 - train - INFO - Train: 146 [ 650/781 ( 83%)]  Loss:  3.454856 (3.4523)  Time: 0.492s,  260.31/s  (0.465s,  275.00/s)  LR: 1.086e-05  Data: 0.007 (0.008)
2024-04-07 13:37:37,954 - train - INFO - Train: 146 [ 700/781 ( 90%)]  Loss:  3.079634 (3.4530)  Time: 0.418s,  306.07/s  (0.465s,  275.39/s)  LR: 1.086e-05  Data: 0.009 (0.008)
2024-04-07 13:38:01,125 - train - INFO - Train: 146 [ 750/781 ( 96%)]  Loss:  3.394308 (3.4538)  Time: 0.505s,  253.38/s  (0.465s,  275.45/s)  LR: 1.086e-05  Data: 0.009 (0.008)
2024-04-07 13:38:16,067 - train - INFO - Train: 146 [ 780/781 (100%)]  Loss:  3.167300 (3.4534)  Time: 0.490s,  261.06/s  (0.466s,  274.69/s)  LR: 1.086e-05  Data: 0.000 (0.008)
2024-04-07 13:38:16,068 - train - INFO - True
2024-04-07 13:38:16,071 - train - INFO - alphas:tensor([0.8240, 0.0074, 0.0165, 0.0288, 0.1234], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,072 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,072 - train - INFO - True
2024-04-07 13:38:16,073 - train - INFO - alphas:tensor([0.4696, 0.0017, 0.0055, 0.0260, 0.4972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,074 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,074 - train - INFO - True
2024-04-07 13:38:16,075 - train - INFO - alphas:tensor([0.5237, 0.0041, 0.0227, 0.4495], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,077 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,077 - train - INFO - True
2024-04-07 13:38:16,078 - train - INFO - alphas:tensor([0.4445, 0.0043, 0.0137, 0.5375], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,079 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,079 - train - INFO - True
2024-04-07 13:38:16,080 - train - INFO - alphas:tensor([0.4526, 0.0021, 0.0183, 0.5270], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,081 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,081 - train - INFO - True
2024-04-07 13:38:16,082 - train - INFO - alphas:tensor([0.5585, 0.0043, 0.0141, 0.4230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,084 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,084 - train - INFO - True
2024-04-07 13:38:16,085 - train - INFO - alphas:tensor([0.6298, 0.0016, 0.0028, 0.0141, 0.3517], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,087 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,087 - train - INFO - True
2024-04-07 13:38:16,088 - train - INFO - alphas:tensor([2.1240e-01, 7.2039e-04, 4.9354e-04, 1.5359e-02, 7.7103e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,089 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,089 - train - INFO - True
2024-04-07 13:38:16,091 - train - INFO - alphas:tensor([2.1831e-01, 3.8997e-04, 6.2736e-04, 9.9219e-03, 7.7075e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,092 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,092 - train - INFO - True
2024-04-07 13:38:16,093 - train - INFO - alphas:tensor([2.1965e-01, 2.0539e-04, 4.9883e-04, 1.2541e-02, 7.6710e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,094 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,094 - train - INFO - True
2024-04-07 13:38:16,095 - train - INFO - alphas:tensor([2.0743e-01, 5.4456e-04, 5.4136e-04, 1.6267e-02, 7.7522e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,096 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,096 - train - INFO - True
2024-04-07 13:38:16,098 - train - INFO - alphas:tensor([6.1088e-01, 3.8245e-04, 1.2700e-03, 1.1640e-02, 3.7583e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,099 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,099 - train - INFO - True
2024-04-07 13:38:16,100 - train - INFO - alphas:tensor([7.4591e-01, 5.5503e-04, 8.5381e-04, 6.1694e-03, 2.4651e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,105 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,105 - train - INFO - True
2024-04-07 13:38:16,106 - train - INFO - alphas:tensor([0.2674, 0.0022, 0.0023, 0.0407, 0.6874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,109 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,109 - train - INFO - True
2024-04-07 13:38:16,110 - train - INFO - alphas:tensor([0.2753, 0.0007, 0.0011, 0.0327, 0.6903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,113 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,113 - train - INFO - True
2024-04-07 13:38:16,114 - train - INFO - alphas:tensor([2.9952e-01, 4.8066e-04, 1.2040e-03, 2.8478e-02, 6.7032e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,116 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,116 - train - INFO - True
2024-04-07 13:38:16,118 - train - INFO - alphas:tensor([0.2698, 0.0009, 0.0015, 0.0268, 0.7010], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,120 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,120 - train - INFO - True
2024-04-07 13:38:16,121 - train - INFO - alphas:tensor([3.0065e-01, 5.5116e-04, 1.9867e-03, 2.9782e-02, 6.6703e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,123 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,123 - train - INFO - True
2024-04-07 13:38:16,124 - train - INFO - alphas:tensor([0.2615, 0.0020, 0.0031, 0.0328, 0.7005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,127 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,127 - train - INFO - True
2024-04-07 13:38:16,128 - train - INFO - alphas:tensor([6.6260e-01, 2.4620e-04, 7.5395e-04, 1.3994e-02, 3.2241e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,132 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,132 - train - INFO - True
2024-04-07 13:38:16,133 - train - INFO - alphas:tensor([5.8650e-01, 2.1720e-04, 3.7878e-04, 1.3132e-02, 3.9977e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,142 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,142 - train - INFO - True
2024-04-07 13:38:16,143 - train - INFO - alphas:tensor([4.4959e-01, 1.7127e-04, 1.1628e-03, 2.3421e-02, 5.2565e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,147 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,147 - train - INFO - True
2024-04-07 13:38:16,148 - train - INFO - alphas:tensor([4.5844e-01, 1.8733e-04, 4.0313e-04, 2.0659e-02, 5.2031e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,152 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,152 - train - INFO - True
2024-04-07 13:38:16,153 - train - INFO - alphas:tensor([4.7594e-01, 1.5360e-04, 4.1955e-04, 1.8823e-02, 5.0467e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,157 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,157 - train - INFO - True
2024-04-07 13:38:16,158 - train - INFO - alphas:tensor([4.3900e-01, 1.9421e-04, 7.9498e-04, 2.1855e-02, 5.3816e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,162 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,162 - train - INFO - True
2024-04-07 13:38:16,163 - train - INFO - alphas:tensor([5.9169e-01, 1.5881e-04, 6.3967e-04, 1.1085e-02, 3.9642e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,170 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,170 - train - INFO - True
2024-04-07 13:38:16,171 - train - INFO - alphas:tensor([7.8840e-01, 9.9912e-05, 4.1169e-04, 6.5811e-03, 2.0451e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,191 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,191 - train - INFO - True
2024-04-07 13:38:16,192 - train - INFO - alphas:tensor([4.0795e-01, 2.7436e-04, 8.1264e-04, 3.2347e-02, 5.5862e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,202 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,202 - train - INFO - True
2024-04-07 13:38:16,203 - train - INFO - alphas:tensor([4.1468e-01, 1.1494e-04, 5.4692e-04, 2.2259e-02, 5.6240e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,213 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,213 - train - INFO - True
2024-04-07 13:38:16,214 - train - INFO - alphas:tensor([4.4468e-01, 1.5004e-04, 3.9663e-04, 2.5677e-02, 5.2910e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,224 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,224 - train - INFO - True
2024-04-07 13:38:16,225 - train - INFO - alphas:tensor([4.0676e-01, 1.9761e-04, 6.6967e-04, 2.5169e-02, 5.6721e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,235 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,235 - train - INFO - True
2024-04-07 13:38:16,236 - train - INFO - alphas:tensor([7.5262e-01, 8.3973e-05, 1.9591e-04, 5.3019e-03, 2.4180e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,255 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,256 - train - INFO - True
2024-04-07 13:38:16,257 - train - INFO - alphas:tensor([0.6009, 0.0015, 0.0031, 0.0314, 0.3632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:38:16,334 - train - INFO - tau:0.2352166292404101
2024-04-07 13:38:16,334 - train - INFO - avg block size:10.06060606060606
2024-04-07 13:38:16,335 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 13:38:16,335 - train - INFO - lasso_alpha:5.881669874110298e-07
2024-04-07 13:38:16,558 - train - INFO - Test: [   0/78]  Time: 0.220 (0.220)  Loss:  0.9443 (0.9443)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 13:38:19,278 - train - INFO - Test: [  50/78]  Time: 0.049 (0.058)  Loss:  1.5479 (1.5375)  Acc@1: 66.4062 (66.2837)  Acc@5: 86.7188 (86.5656)
2024-04-07 13:38:20,668 - train - INFO - Test: [  78/78]  Time: 0.047 (0.055)  Loss:  1.8564 (1.5591)  Acc@1: 50.0000 (65.9600)  Acc@5: 87.5000 (86.2100)
2024-04-07 13:38:21,357 - train - INFO - Train: 147 [   0/781 (  0%)]  Loss:  3.363814 (3.3638)  Time: 0.618s,  207.09/s  (0.618s,  207.09/s)  LR: 1.048e-05  Data: 0.183 (0.183)
2024-04-07 13:38:46,262 - train - INFO - Train: 147 [  50/781 (  6%)]  Loss:  3.378381 (3.3920)  Time: 0.491s,  260.55/s  (0.500s,  255.78/s)  LR: 1.048e-05  Data: 0.009 (0.012)
2024-04-07 13:39:11,023 - train - INFO - Train: 147 [ 100/781 ( 13%)]  Loss:  3.557897 (3.4298)  Time: 0.504s,  254.05/s  (0.498s,  257.11/s)  LR: 1.048e-05  Data: 0.010 (0.010)
2024-04-07 13:39:35,674 - train - INFO - Train: 147 [ 150/781 ( 19%)]  Loss:  3.730631 (3.4199)  Time: 0.503s,  254.29/s  (0.496s,  257.94/s)  LR: 1.048e-05  Data: 0.009 (0.010)
2024-04-07 13:40:00,525 - train - INFO - Train: 147 [ 200/781 ( 26%)]  Loss:  3.187315 (3.4334)  Time: 0.495s,  258.40/s  (0.496s,  257.85/s)  LR: 1.048e-05  Data: 0.008 (0.009)
2024-04-07 13:40:24,907 - train - INFO - Train: 147 [ 250/781 ( 32%)]  Loss:  3.605714 (3.4313)  Time: 0.511s,  250.71/s  (0.495s,  258.76/s)  LR: 1.048e-05  Data: 0.009 (0.009)
2024-04-07 13:40:50,077 - train - INFO - Train: 147 [ 300/781 ( 38%)]  Loss:  3.444150 (3.4316)  Time: 0.503s,  254.61/s  (0.496s,  258.01/s)  LR: 1.048e-05  Data: 0.010 (0.009)
2024-04-07 13:41:15,250 - train - INFO - Train: 147 [ 350/781 ( 45%)]  Loss:  3.410827 (3.4371)  Time: 0.503s,  254.67/s  (0.497s,  257.47/s)  LR: 1.048e-05  Data: 0.009 (0.009)
2024-04-07 13:41:40,356 - train - INFO - Train: 147 [ 400/781 ( 51%)]  Loss:  3.674203 (3.4414)  Time: 0.502s,  254.84/s  (0.498s,  257.15/s)  LR: 1.048e-05  Data: 0.008 (0.009)
2024-04-07 13:42:05,145 - train - INFO - Train: 147 [ 450/781 ( 58%)]  Loss:  3.961254 (3.4410)  Time: 0.501s,  255.72/s  (0.498s,  257.27/s)  LR: 1.048e-05  Data: 0.009 (0.009)
2024-04-07 13:42:28,291 - train - INFO - Train: 147 [ 500/781 ( 64%)]  Loss:  3.662333 (3.4438)  Time: 0.405s,  315.97/s  (0.494s,  259.07/s)  LR: 1.048e-05  Data: 0.005 (0.009)
2024-04-07 13:42:50,847 - train - INFO - Train: 147 [ 550/781 ( 71%)]  Loss:  3.555544 (3.4457)  Time: 0.507s,  252.30/s  (0.490s,  261.13/s)  LR: 1.048e-05  Data: 0.008 (0.009)
2024-04-07 13:43:14,196 - train - INFO - Train: 147 [ 600/781 ( 77%)]  Loss:  2.942305 (3.4508)  Time: 0.490s,  261.19/s  (0.488s,  262.16/s)  LR: 1.048e-05  Data: 0.009 (0.009)
2024-04-07 13:43:38,008 - train - INFO - Train: 147 [ 650/781 ( 83%)]  Loss:  3.570682 (3.4497)  Time: 0.494s,  258.87/s  (0.487s,  262.66/s)  LR: 1.048e-05  Data: 0.009 (0.009)
2024-04-07 13:44:01,086 - train - INFO - Train: 147 [ 700/781 ( 90%)]  Loss:  3.626687 (3.4488)  Time: 0.404s,  317.22/s  (0.485s,  263.65/s)  LR: 1.048e-05  Data: 0.006 (0.009)
2024-04-07 13:44:24,383 - train - INFO - Train: 147 [ 750/781 ( 96%)]  Loss:  3.612294 (3.4472)  Time: 0.475s,  269.57/s  (0.484s,  264.36/s)  LR: 1.048e-05  Data: 0.006 (0.008)
2024-04-07 13:44:39,172 - train - INFO - Train: 147 [ 780/781 (100%)]  Loss:  3.551625 (3.4487)  Time: 0.451s,  283.59/s  (0.485s,  264.18/s)  LR: 1.048e-05  Data: 0.000 (0.008)
2024-04-07 13:44:39,173 - train - INFO - True
2024-04-07 13:44:39,174 - train - INFO - alphas:tensor([0.8271, 0.0071, 0.0159, 0.0280, 0.1219], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,175 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,175 - train - INFO - True
2024-04-07 13:44:39,176 - train - INFO - alphas:tensor([0.4698, 0.0016, 0.0053, 0.0253, 0.4980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,176 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,176 - train - INFO - True
2024-04-07 13:44:39,177 - train - INFO - alphas:tensor([0.5239, 0.0039, 0.0221, 0.4501], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,178 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,178 - train - INFO - True
2024-04-07 13:44:39,179 - train - INFO - alphas:tensor([0.4449, 0.0041, 0.0133, 0.5377], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,179 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,180 - train - INFO - True
2024-04-07 13:44:39,180 - train - INFO - alphas:tensor([0.4531, 0.0020, 0.0177, 0.5272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,181 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,181 - train - INFO - True
2024-04-07 13:44:39,182 - train - INFO - alphas:tensor([0.5594, 0.0041, 0.0137, 0.4228], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,183 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,183 - train - INFO - True
2024-04-07 13:44:39,184 - train - INFO - alphas:tensor([0.6313, 0.0015, 0.0026, 0.0136, 0.3510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,185 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,185 - train - INFO - True
2024-04-07 13:44:39,186 - train - INFO - alphas:tensor([2.1133e-01, 6.7497e-04, 4.6116e-04, 1.4861e-02, 7.7268e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,186 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,187 - train - INFO - True
2024-04-07 13:44:39,187 - train - INFO - alphas:tensor([2.1661e-01, 3.6321e-04, 5.8807e-04, 9.5515e-03, 7.7289e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,188 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,188 - train - INFO - True
2024-04-07 13:44:39,189 - train - INFO - alphas:tensor([2.1827e-01, 1.9017e-04, 4.6563e-04, 1.2109e-02, 7.6896e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,190 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,190 - train - INFO - True
2024-04-07 13:44:39,191 - train - INFO - alphas:tensor([2.0604e-01, 5.0889e-04, 5.0617e-04, 1.5749e-02, 7.7719e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,191 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,191 - train - INFO - True
2024-04-07 13:44:39,192 - train - INFO - alphas:tensor([6.1207e-01, 3.5584e-04, 1.1979e-03, 1.1225e-02, 3.7515e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,193 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,194 - train - INFO - True
2024-04-07 13:44:39,194 - train - INFO - alphas:tensor([7.4777e-01, 5.1817e-04, 8.0124e-04, 5.9041e-03, 2.4500e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,198 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,198 - train - INFO - True
2024-04-07 13:44:39,199 - train - INFO - alphas:tensor([0.2659, 0.0021, 0.0022, 0.0399, 0.6899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,201 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,201 - train - INFO - True
2024-04-07 13:44:39,202 - train - INFO - alphas:tensor([2.7448e-01, 6.5832e-04, 1.0475e-03, 3.1904e-02, 6.9191e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,204 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,204 - train - INFO - True
2024-04-07 13:44:39,205 - train - INFO - alphas:tensor([2.9796e-01, 4.4836e-04, 1.1360e-03, 2.7763e-02, 6.7270e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,206 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,207 - train - INFO - True
2024-04-07 13:44:39,207 - train - INFO - alphas:tensor([0.2689, 0.0009, 0.0014, 0.0261, 0.7026], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,209 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,209 - train - INFO - True
2024-04-07 13:44:39,210 - train - INFO - alphas:tensor([3.0013e-01, 5.1609e-04, 1.8872e-03, 2.9093e-02, 6.6838e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,212 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,212 - train - INFO - True
2024-04-07 13:44:39,213 - train - INFO - alphas:tensor([0.2607, 0.0019, 0.0030, 0.0321, 0.7023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,215 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,215 - train - INFO - True
2024-04-07 13:44:39,216 - train - INFO - alphas:tensor([6.6380e-01, 2.2820e-04, 7.0795e-04, 1.3531e-02, 3.2173e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,220 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,220 - train - INFO - True
2024-04-07 13:44:39,220 - train - INFO - alphas:tensor([5.8764e-01, 2.0101e-04, 3.5214e-04, 1.2687e-02, 3.9912e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,228 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,228 - train - INFO - True
2024-04-07 13:44:39,229 - train - INFO - alphas:tensor([4.4993e-01, 1.5815e-04, 1.0959e-03, 2.2789e-02, 5.2603e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,233 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,233 - train - INFO - True
2024-04-07 13:44:39,234 - train - INFO - alphas:tensor([4.5883e-01, 1.7327e-04, 3.7643e-04, 2.0104e-02, 5.2051e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,237 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,238 - train - INFO - True
2024-04-07 13:44:39,238 - train - INFO - alphas:tensor([4.7720e-01, 1.4168e-04, 3.9159e-04, 1.8278e-02, 5.0399e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,242 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,242 - train - INFO - True
2024-04-07 13:44:39,243 - train - INFO - alphas:tensor([4.3828e-01, 1.7972e-04, 7.4670e-04, 2.1258e-02, 5.3953e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,247 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,247 - train - INFO - True
2024-04-07 13:44:39,248 - train - INFO - alphas:tensor([5.9289e-01, 1.4664e-04, 6.0003e-04, 1.0710e-02, 3.9565e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,255 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,256 - train - INFO - True
2024-04-07 13:44:39,256 - train - INFO - alphas:tensor([7.9003e-01, 9.1670e-05, 3.8348e-04, 6.3093e-03, 2.0318e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,276 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,276 - train - INFO - True
2024-04-07 13:44:39,277 - train - INFO - alphas:tensor([4.0873e-01, 2.5498e-04, 7.6266e-04, 3.1623e-02, 5.5863e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,287 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,287 - train - INFO - True
2024-04-07 13:44:39,288 - train - INFO - alphas:tensor([4.1500e-01, 1.0581e-04, 5.1228e-04, 2.1681e-02, 5.6270e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,298 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,298 - train - INFO - True
2024-04-07 13:44:39,299 - train - INFO - alphas:tensor([4.4526e-01, 1.3858e-04, 3.7052e-04, 2.5072e-02, 5.2916e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,309 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,309 - train - INFO - True
2024-04-07 13:44:39,310 - train - INFO - alphas:tensor([4.0678e-01, 1.8299e-04, 6.2924e-04, 2.4587e-02, 5.6782e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,320 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,320 - train - INFO - True
2024-04-07 13:44:39,321 - train - INFO - alphas:tensor([7.5370e-01, 7.7012e-05, 1.8155e-04, 5.0879e-03, 2.4095e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,340 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,340 - train - INFO - True
2024-04-07 13:44:39,341 - train - INFO - alphas:tensor([0.6017, 0.0014, 0.0029, 0.0307, 0.3633], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:44:39,419 - train - INFO - tau:0.232864462948006
2024-04-07 13:44:39,419 - train - INFO - avg block size:10.06060606060606
2024-04-07 13:44:39,419 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 13:44:39,613 - train - INFO - Test: [   0/78]  Time: 0.191 (0.191)  Loss:  0.9556 (0.9556)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 13:44:42,268 - train - INFO - Test: [  50/78]  Time: 0.053 (0.056)  Loss:  1.5625 (1.5451)  Acc@1: 65.6250 (66.0846)  Acc@5: 86.7188 (86.2898)
2024-04-07 13:44:43,964 - train - INFO - Test: [  78/78]  Time: 0.046 (0.057)  Loss:  1.8408 (1.5617)  Acc@1: 50.0000 (65.7800)  Acc@5: 87.5000 (86.0400)
2024-04-07 13:44:44,694 - train - INFO - Train: 148 [   0/781 (  0%)]  Loss:  3.580050 (3.5800)  Time: 0.655s,  195.44/s  (0.655s,  195.44/s)  LR: 1.021e-05  Data: 0.162 (0.162)
2024-04-07 13:45:08,156 - train - INFO - Train: 148 [  50/781 (  6%)]  Loss:  3.157331 (3.4610)  Time: 0.485s,  263.87/s  (0.473s,  270.70/s)  LR: 1.021e-05  Data: 0.006 (0.011)
2024-04-07 13:45:31,777 - train - INFO - Train: 148 [ 100/781 ( 13%)]  Loss:  3.406865 (3.4543)  Time: 0.385s,  332.24/s  (0.473s,  270.83/s)  LR: 1.021e-05  Data: 0.005 (0.009)
2024-04-07 13:45:54,769 - train - INFO - Train: 148 [ 150/781 ( 19%)]  Loss:  3.370684 (3.4704)  Time: 0.473s,  270.43/s  (0.468s,  273.28/s)  LR: 1.021e-05  Data: 0.008 (0.009)
2024-04-07 13:46:18,023 - train - INFO - Train: 148 [ 200/781 ( 26%)]  Loss:  3.247914 (3.4738)  Time: 0.378s,  338.71/s  (0.468s,  273.77/s)  LR: 1.021e-05  Data: 0.005 (0.008)
2024-04-07 13:46:41,267 - train - INFO - Train: 148 [ 250/781 ( 32%)]  Loss:  3.615878 (3.4808)  Time: 0.514s,  249.24/s  (0.467s,  274.08/s)  LR: 1.021e-05  Data: 0.008 (0.008)
2024-04-07 13:47:05,284 - train - INFO - Train: 148 [ 300/781 ( 38%)]  Loss:  3.507183 (3.4758)  Time: 0.484s,  264.25/s  (0.469s,  272.79/s)  LR: 1.021e-05  Data: 0.007 (0.008)
2024-04-07 13:47:28,809 - train - INFO - Train: 148 [ 350/781 ( 45%)]  Loss:  3.283533 (3.4692)  Time: 0.489s,  261.80/s  (0.469s,  272.69/s)  LR: 1.021e-05  Data: 0.006 (0.008)
2024-04-07 13:47:52,637 - train - INFO - Train: 148 [ 400/781 ( 51%)]  Loss:  3.416293 (3.4686)  Time: 0.495s,  258.57/s  (0.470s,  272.17/s)  LR: 1.021e-05  Data: 0.007 (0.008)
2024-04-07 13:48:16,003 - train - INFO - Train: 148 [ 450/781 ( 58%)]  Loss:  3.824471 (3.4662)  Time: 0.464s,  275.73/s  (0.470s,  272.37/s)  LR: 1.021e-05  Data: 0.010 (0.008)
2024-04-07 13:48:39,803 - train - INFO - Train: 148 [ 500/781 ( 64%)]  Loss:  3.685243 (3.4663)  Time: 0.496s,  257.87/s  (0.471s,  272.02/s)  LR: 1.021e-05  Data: 0.008 (0.008)
2024-04-07 13:49:03,699 - train - INFO - Train: 148 [ 550/781 ( 71%)]  Loss:  3.768520 (3.4641)  Time: 0.486s,  263.53/s  (0.471s,  271.63/s)  LR: 1.021e-05  Data: 0.016 (0.008)
2024-04-07 13:49:28,085 - train - INFO - Train: 148 [ 600/781 ( 77%)]  Loss:  3.204143 (3.4628)  Time: 0.494s,  258.88/s  (0.473s,  270.85/s)  LR: 1.021e-05  Data: 0.008 (0.008)
2024-04-07 13:49:50,952 - train - INFO - Train: 148 [ 650/781 ( 83%)]  Loss:  3.588708 (3.4630)  Time: 0.404s,  316.81/s  (0.471s,  271.52/s)  LR: 1.021e-05  Data: 0.006 (0.008)
2024-04-07 13:50:14,291 - train - INFO - Train: 148 [ 700/781 ( 90%)]  Loss:  3.498772 (3.4595)  Time: 0.490s,  261.00/s  (0.471s,  271.71/s)  LR: 1.021e-05  Data: 0.007 (0.008)
2024-04-07 13:50:37,952 - train - INFO - Train: 148 [ 750/781 ( 96%)]  Loss:  3.696600 (3.4596)  Time: 0.493s,  259.46/s  (0.471s,  271.63/s)  LR: 1.021e-05  Data: 0.007 (0.008)
2024-04-07 13:50:51,860 - train - INFO - Train: 148 [ 780/781 (100%)]  Loss:  3.781573 (3.4603)  Time: 0.494s,  258.88/s  (0.471s,  271.80/s)  LR: 1.021e-05  Data: 0.000 (0.008)
2024-04-07 13:50:51,861 - train - INFO - True
2024-04-07 13:50:51,863 - train - INFO - alphas:tensor([0.8302, 0.0068, 0.0154, 0.0272, 0.1203], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,864 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,864 - train - INFO - True
2024-04-07 13:50:51,865 - train - INFO - alphas:tensor([0.4703, 0.0015, 0.0050, 0.0247, 0.4985], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,866 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,866 - train - INFO - True
2024-04-07 13:50:51,867 - train - INFO - alphas:tensor([0.5245, 0.0037, 0.0214, 0.4504], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,868 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,869 - train - INFO - True
2024-04-07 13:50:51,870 - train - INFO - alphas:tensor([0.4440, 0.0039, 0.0128, 0.5392], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,871 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,871 - train - INFO - True
2024-04-07 13:50:51,872 - train - INFO - alphas:tensor([0.4533, 0.0019, 0.0172, 0.5276], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,873 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,873 - train - INFO - True
2024-04-07 13:50:51,874 - train - INFO - alphas:tensor([0.5602, 0.0040, 0.0132, 0.4226], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,875 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,875 - train - INFO - True
2024-04-07 13:50:51,877 - train - INFO - alphas:tensor([0.6322, 0.0014, 0.0025, 0.0132, 0.3506], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,878 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,878 - train - INFO - True
2024-04-07 13:50:51,879 - train - INFO - alphas:tensor([2.1004e-01, 6.3213e-04, 4.2957e-04, 1.4333e-02, 7.7456e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,880 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,881 - train - INFO - True
2024-04-07 13:50:51,882 - train - INFO - alphas:tensor([2.1532e-01, 3.3817e-04, 5.5117e-04, 9.2056e-03, 7.7458e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,883 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,883 - train - INFO - True
2024-04-07 13:50:51,884 - train - INFO - alphas:tensor([2.1665e-01, 1.7551e-04, 4.3434e-04, 1.1686e-02, 7.7106e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,885 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,885 - train - INFO - True
2024-04-07 13:50:51,886 - train - INFO - alphas:tensor([2.0443e-01, 4.7521e-04, 4.7229e-04, 1.5239e-02, 7.7939e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,887 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,887 - train - INFO - True
2024-04-07 13:50:51,888 - train - INFO - alphas:tensor([6.1275e-01, 3.3097e-04, 1.1302e-03, 1.0824e-02, 3.7496e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,890 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,890 - train - INFO - True
2024-04-07 13:50:51,891 - train - INFO - alphas:tensor([7.4923e-01, 4.8351e-04, 7.5120e-04, 5.6509e-03, 2.4388e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,895 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,896 - train - INFO - True
2024-04-07 13:50:51,897 - train - INFO - alphas:tensor([0.2648, 0.0020, 0.0021, 0.0391, 0.6920], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,899 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,899 - train - INFO - True
2024-04-07 13:50:51,900 - train - INFO - alphas:tensor([2.7386e-01, 6.1645e-04, 9.8729e-04, 3.1143e-02, 6.9340e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,903 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,903 - train - INFO - True
2024-04-07 13:50:51,904 - train - INFO - alphas:tensor([2.9698e-01, 4.1787e-04, 1.0710e-03, 2.7067e-02, 6.7446e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,906 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,906 - train - INFO - True
2024-04-07 13:50:51,907 - train - INFO - alphas:tensor([0.2684, 0.0008, 0.0013, 0.0255, 0.7040], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,910 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,910 - train - INFO - True
2024-04-07 13:50:51,911 - train - INFO - alphas:tensor([2.9922e-01, 4.8352e-04, 1.7916e-03, 2.8386e-02, 6.7011e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,913 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,913 - train - INFO - True
2024-04-07 13:50:51,914 - train - INFO - alphas:tensor([0.2602, 0.0018, 0.0028, 0.0312, 0.7039], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,916 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,917 - train - INFO - True
2024-04-07 13:50:51,918 - train - INFO - alphas:tensor([6.6492e-01, 2.1121e-04, 6.6437e-04, 1.3073e-02, 3.2113e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,922 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,922 - train - INFO - True
2024-04-07 13:50:51,923 - train - INFO - alphas:tensor([5.8851e-01, 1.8600e-04, 3.2786e-04, 1.2250e-02, 3.9873e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,931 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,931 - train - INFO - True
2024-04-07 13:50:51,932 - train - INFO - alphas:tensor([4.4999e-01, 1.4599e-04, 1.0333e-03, 2.2166e-02, 5.2667e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,936 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,936 - train - INFO - True
2024-04-07 13:50:51,937 - train - INFO - alphas:tensor([4.5935e-01, 1.6003e-04, 3.5046e-04, 1.9478e-02, 5.2066e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,941 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,941 - train - INFO - True
2024-04-07 13:50:51,942 - train - INFO - alphas:tensor([4.7731e-01, 1.3068e-04, 3.6512e-04, 1.7745e-02, 5.0444e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,946 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,946 - train - INFO - True
2024-04-07 13:50:51,947 - train - INFO - alphas:tensor([4.3903e-01, 1.6619e-04, 7.0087e-04, 2.0664e-02, 5.3944e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,950 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,951 - train - INFO - True
2024-04-07 13:50:51,951 - train - INFO - alphas:tensor([5.9340e-01, 1.3518e-04, 5.6175e-04, 1.0354e-02, 3.9555e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,959 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,959 - train - INFO - True
2024-04-07 13:50:51,960 - train - INFO - alphas:tensor([7.9163e-01, 8.4115e-05, 3.5761e-04, 6.0604e-03, 2.0186e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,979 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,979 - train - INFO - True
2024-04-07 13:50:51,980 - train - INFO - alphas:tensor([4.0881e-01, 2.3693e-04, 7.1695e-04, 3.0952e-02, 5.5928e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:51,990 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:51,990 - train - INFO - True
2024-04-07 13:50:51,991 - train - INFO - alphas:tensor([4.1519e-01, 9.7149e-05, 4.7968e-04, 2.1084e-02, 5.6315e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:52,001 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:52,001 - train - INFO - True
2024-04-07 13:50:52,002 - train - INFO - alphas:tensor([4.4542e-01, 1.2772e-04, 3.4530e-04, 2.4450e-02, 5.2965e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:52,012 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:52,012 - train - INFO - True
2024-04-07 13:50:52,013 - train - INFO - alphas:tensor([4.0640e-01, 1.6939e-04, 5.8924e-04, 2.3962e-02, 5.6888e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:52,023 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:52,023 - train - INFO - True
2024-04-07 13:50:52,024 - train - INFO - alphas:tensor([7.5421e-01, 7.0603e-05, 1.6846e-04, 4.8861e-03, 2.4066e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:52,043 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:52,043 - train - INFO - True
2024-04-07 13:50:52,044 - train - INFO - alphas:tensor([0.6029, 0.0013, 0.0028, 0.0301, 0.3630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:50:52,122 - train - INFO - tau:0.23053581831852593
2024-04-07 13:50:52,122 - train - INFO - avg block size:10.06060606060606
2024-04-07 13:50:52,122 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 13:50:52,122 - train - INFO - lasso_alpha:5.346972612827543e-07
2024-04-07 13:50:52,320 - train - INFO - Test: [   0/78]  Time: 0.194 (0.194)  Loss:  0.9419 (0.9419)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 13:50:55,488 - train - INFO - Test: [  50/78]  Time: 0.052 (0.066)  Loss:  1.5547 (1.5486)  Acc@1: 63.2812 (66.0999)  Acc@5: 86.7188 (86.3205)
2024-04-07 13:50:56,952 - train - INFO - Test: [  78/78]  Time: 0.047 (0.061)  Loss:  1.9092 (1.5650)  Acc@1: 50.0000 (65.8000)  Acc@5: 87.5000 (85.9300)
2024-04-07 13:50:57,751 - train - INFO - Train: 149 [   0/781 (  0%)]  Loss:  3.071097 (3.0711)  Time: 0.639s,  200.39/s  (0.639s,  200.39/s)  LR: 1.005e-05  Data: 0.175 (0.175)
2024-04-07 13:51:21,062 - train - INFO - Train: 149 [  50/781 (  6%)]  Loss:  3.450513 (3.4471)  Time: 0.393s,  325.89/s  (0.470s,  272.59/s)  LR: 1.005e-05  Data: 0.007 (0.011)
2024-04-07 13:51:44,426 - train - INFO - Train: 149 [ 100/781 ( 13%)]  Loss:  3.495154 (3.4693)  Time: 0.478s,  268.01/s  (0.468s,  273.26/s)  LR: 1.005e-05  Data: 0.007 (0.009)
2024-04-07 13:52:08,240 - train - INFO - Train: 149 [ 150/781 ( 19%)]  Loss:  3.781612 (3.4677)  Time: 0.457s,  279.92/s  (0.471s,  271.76/s)  LR: 1.005e-05  Data: 0.007 (0.009)
2024-04-07 13:52:31,940 - train - INFO - Train: 149 [ 200/781 ( 26%)]  Loss:  3.752124 (3.4828)  Time: 0.500s,  255.90/s  (0.472s,  271.33/s)  LR: 1.005e-05  Data: 0.007 (0.008)
2024-04-07 13:52:55,697 - train - INFO - Train: 149 [ 250/781 ( 32%)]  Loss:  3.582840 (3.4841)  Time: 0.489s,  261.89/s  (0.472s,  270.95/s)  LR: 1.005e-05  Data: 0.008 (0.008)
2024-04-07 13:53:19,637 - train - INFO - Train: 149 [ 300/781 ( 38%)]  Loss:  3.268125 (3.4742)  Time: 0.496s,  258.29/s  (0.473s,  270.34/s)  LR: 1.005e-05  Data: 0.010 (0.008)
2024-04-07 13:53:42,949 - train - INFO - Train: 149 [ 350/781 ( 45%)]  Loss:  3.744221 (3.4693)  Time: 0.426s,  300.72/s  (0.472s,  270.94/s)  LR: 1.005e-05  Data: 0.007 (0.008)
2024-04-07 13:54:06,372 - train - INFO - Train: 149 [ 400/781 ( 51%)]  Loss:  3.619184 (3.4632)  Time: 0.484s,  264.59/s  (0.472s,  271.22/s)  LR: 1.005e-05  Data: 0.011 (0.008)
2024-04-07 13:54:30,311 - train - INFO - Train: 149 [ 450/781 ( 58%)]  Loss:  3.391522 (3.4621)  Time: 0.504s,  254.20/s  (0.473s,  270.79/s)  LR: 1.005e-05  Data: 0.009 (0.008)
2024-04-07 13:54:53,158 - train - INFO - Train: 149 [ 500/781 ( 64%)]  Loss:  3.721434 (3.4609)  Time: 0.469s,  272.90/s  (0.471s,  271.69/s)  LR: 1.005e-05  Data: 0.008 (0.008)
2024-04-07 13:55:16,290 - train - INFO - Train: 149 [ 550/781 ( 71%)]  Loss:  3.274561 (3.4583)  Time: 0.435s,  294.06/s  (0.470s,  272.14/s)  LR: 1.005e-05  Data: 0.008 (0.008)
2024-04-07 13:55:39,852 - train - INFO - Train: 149 [ 600/781 ( 77%)]  Loss:  3.426486 (3.4573)  Time: 0.497s,  257.78/s  (0.470s,  272.10/s)  LR: 1.005e-05  Data: 0.009 (0.008)
2024-04-07 13:56:03,197 - train - INFO - Train: 149 [ 650/781 ( 83%)]  Loss:  3.491022 (3.4566)  Time: 0.436s,  293.79/s  (0.470s,  272.26/s)  LR: 1.005e-05  Data: 0.005 (0.008)
2024-04-07 13:56:25,934 - train - INFO - Train: 149 [ 700/781 ( 90%)]  Loss:  3.044869 (3.4568)  Time: 0.490s,  261.39/s  (0.469s,  272.90/s)  LR: 1.005e-05  Data: 0.007 (0.008)
2024-04-07 13:56:48,566 - train - INFO - Train: 149 [ 750/781 ( 96%)]  Loss:  3.494184 (3.4518)  Time: 0.482s,  265.33/s  (0.468s,  273.53/s)  LR: 1.005e-05  Data: 0.010 (0.008)
2024-04-07 13:57:02,475 - train - INFO - Train: 149 [ 780/781 (100%)]  Loss:  3.068090 (3.4504)  Time: 0.486s,  263.42/s  (0.468s,  273.63/s)  LR: 1.005e-05  Data: 0.000 (0.008)
2024-04-07 13:57:02,476 - train - INFO - True
2024-04-07 13:57:02,479 - train - INFO - alphas:tensor([0.8334, 0.0065, 0.0149, 0.0265, 0.1187], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,480 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,480 - train - INFO - True
2024-04-07 13:57:02,482 - train - INFO - alphas:tensor([0.4706, 0.0014, 0.0048, 0.0240, 0.4992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,482 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,482 - train - INFO - True
2024-04-07 13:57:02,484 - train - INFO - alphas:tensor([0.5250, 0.0036, 0.0208, 0.4506], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,485 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,485 - train - INFO - True
2024-04-07 13:57:02,487 - train - INFO - alphas:tensor([0.4445, 0.0038, 0.0124, 0.5394], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,488 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,488 - train - INFO - True
2024-04-07 13:57:02,489 - train - INFO - alphas:tensor([0.4534, 0.0018, 0.0166, 0.5281], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,490 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,491 - train - INFO - True
2024-04-07 13:57:02,492 - train - INFO - alphas:tensor([0.5609, 0.0038, 0.0128, 0.4225], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,493 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,493 - train - INFO - True
2024-04-07 13:57:02,495 - train - INFO - alphas:tensor([0.6336, 0.0013, 0.0024, 0.0127, 0.3500], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,497 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,497 - train - INFO - True
2024-04-07 13:57:02,498 - train - INFO - alphas:tensor([2.0897e-01, 5.9320e-04, 4.0077e-04, 1.3859e-02, 7.7618e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,499 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,500 - train - INFO - True
2024-04-07 13:57:02,501 - train - INFO - alphas:tensor([2.1395e-01, 3.1443e-04, 5.1510e-04, 8.8619e-03, 7.7636e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,502 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,502 - train - INFO - True
2024-04-07 13:57:02,503 - train - INFO - alphas:tensor([2.1560e-01, 1.6232e-04, 4.0480e-04, 1.1295e-02, 7.7254e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,504 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,505 - train - INFO - True
2024-04-07 13:57:02,506 - train - INFO - alphas:tensor([2.0332e-01, 4.4350e-04, 4.4080e-04, 1.4743e-02, 7.8106e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,507 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,507 - train - INFO - True
2024-04-07 13:57:02,508 - train - INFO - alphas:tensor([6.1419e-01, 3.0773e-04, 1.0642e-03, 1.0427e-02, 3.7401e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,510 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,510 - train - INFO - True
2024-04-07 13:57:02,512 - train - INFO - alphas:tensor([7.5105e-01, 4.5095e-04, 7.0334e-04, 5.4029e-03, 2.4239e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,517 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,517 - train - INFO - True
2024-04-07 13:57:02,518 - train - INFO - alphas:tensor([0.2635, 0.0019, 0.0020, 0.0383, 0.6944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,521 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,521 - train - INFO - True
2024-04-07 13:57:02,522 - train - INFO - alphas:tensor([2.7322e-01, 5.7748e-04, 9.3009e-04, 3.0375e-02, 6.9490e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,525 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,525 - train - INFO - True
2024-04-07 13:57:02,526 - train - INFO - alphas:tensor([2.9638e-01, 3.9067e-04, 1.0089e-03, 2.6390e-02, 6.7583e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,529 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,529 - train - INFO - True
2024-04-07 13:57:02,530 - train - INFO - alphas:tensor([0.2681, 0.0008, 0.0013, 0.0248, 0.7051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,533 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,533 - train - INFO - True
2024-04-07 13:57:02,534 - train - INFO - alphas:tensor([2.9828e-01, 4.5170e-04, 1.6945e-03, 2.7651e-02, 6.7193e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,536 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,536 - train - INFO - True
2024-04-07 13:57:02,538 - train - INFO - alphas:tensor([0.2597, 0.0017, 0.0027, 0.0305, 0.7053], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,540 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,540 - train - INFO - True
2024-04-07 13:57:02,541 - train - INFO - alphas:tensor([6.6569e-01, 1.9556e-04, 6.2274e-04, 1.2637e-02, 3.2085e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,546 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,546 - train - INFO - True
2024-04-07 13:57:02,547 - train - INFO - alphas:tensor([5.9026e-01, 1.7181e-04, 3.0469e-04, 1.1817e-02, 3.9745e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,557 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,557 - train - INFO - True
2024-04-07 13:57:02,558 - train - INFO - alphas:tensor([4.5039e-01, 1.3448e-04, 9.7292e-04, 2.1515e-02, 5.2699e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,563 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,563 - train - INFO - True
2024-04-07 13:57:02,564 - train - INFO - alphas:tensor([4.6014e-01, 1.4756e-04, 3.2619e-04, 1.8864e-02, 5.2052e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,568 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,568 - train - INFO - True
2024-04-07 13:57:02,569 - train - INFO - alphas:tensor([4.7738e-01, 1.2058e-04, 3.3997e-04, 1.7230e-02, 5.0493e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,573 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,574 - train - INFO - True
2024-04-07 13:57:02,574 - train - INFO - alphas:tensor([4.3931e-01, 1.5339e-04, 6.5678e-04, 2.0061e-02, 5.3982e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,578 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,579 - train - INFO - True
2024-04-07 13:57:02,579 - train - INFO - alphas:tensor([5.9441e-01, 1.2453e-04, 5.2574e-04, 1.0001e-02, 3.9493e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,587 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,587 - train - INFO - True
2024-04-07 13:57:02,588 - train - INFO - alphas:tensor([7.9337e-01, 7.7094e-05, 3.3274e-04, 5.8020e-03, 2.0042e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,607 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,608 - train - INFO - True
2024-04-07 13:57:02,608 - train - INFO - alphas:tensor([4.0932e-01, 2.1976e-04, 6.7360e-04, 3.0290e-02, 5.5950e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,619 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,619 - train - INFO - True
2024-04-07 13:57:02,619 - train - INFO - alphas:tensor([4.1547e-01, 8.9149e-05, 4.4766e-04, 2.0512e-02, 5.6348e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,630 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,630 - train - INFO - True
2024-04-07 13:57:02,631 - train - INFO - alphas:tensor([4.4593e-01, 1.1798e-04, 3.2225e-04, 2.3852e-02, 5.2978e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,641 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,641 - train - INFO - True
2024-04-07 13:57:02,642 - train - INFO - alphas:tensor([4.0690e-01, 1.5646e-04, 5.5206e-04, 2.3343e-02, 5.6905e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,652 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,652 - train - INFO - True
2024-04-07 13:57:02,653 - train - INFO - alphas:tensor([7.5554e-01, 6.4619e-05, 1.5545e-04, 4.6808e-03, 2.3955e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,672 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,672 - train - INFO - True
2024-04-07 13:57:02,673 - train - INFO - alphas:tensor([0.6033, 0.0012, 0.0027, 0.0294, 0.3634], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:57:02,750 - train - INFO - tau:0.22823046013534068
2024-04-07 13:57:02,750 - train - INFO - avg block size:10.06060606060606
2024-04-07 13:57:02,751 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 13:57:02,986 - train - INFO - Test: [   0/78]  Time: 0.232 (0.232)  Loss:  0.9478 (0.9478)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 13:57:06,323 - train - INFO - Test: [  50/78]  Time: 0.049 (0.070)  Loss:  1.5615 (1.5318)  Acc@1: 66.4062 (66.5135)  Acc@5: 85.9375 (86.4890)
2024-04-07 13:57:07,739 - train - INFO - Test: [  78/78]  Time: 0.049 (0.063)  Loss:  1.8623 (1.5516)  Acc@1: 50.0000 (66.0200)  Acc@5: 87.5000 (86.1500)
2024-04-07 13:57:08,500 - train - INFO - Train: 150 [   0/781 (  0%)]  Loss:  3.345903 (3.3459)  Time: 0.671s,  190.65/s  (0.671s,  190.65/s)  LR: 1.000e-05  Data: 0.181 (0.181)
2024-04-07 13:57:32,365 - train - INFO - Train: 150 [  50/781 (  6%)]  Loss:  3.900546 (3.4944)  Time: 0.497s,  257.68/s  (0.481s,  266.08/s)  LR: 1.000e-05  Data: 0.007 (0.011)
2024-04-07 13:57:55,447 - train - INFO - Train: 150 [ 100/781 ( 13%)]  Loss:  3.614875 (3.5090)  Time: 0.472s,  271.20/s  (0.471s,  271.51/s)  LR: 1.000e-05  Data: 0.008 (0.009)
2024-04-07 13:58:18,889 - train - INFO - Train: 150 [ 150/781 ( 19%)]  Loss:  3.630934 (3.4979)  Time: 0.384s,  332.93/s  (0.471s,  272.01/s)  LR: 1.000e-05  Data: 0.004 (0.009)
2024-04-07 13:58:42,347 - train - INFO - Train: 150 [ 200/781 ( 26%)]  Loss:  3.285981 (3.4932)  Time: 0.500s,  255.98/s  (0.470s,  272.22/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 13:59:05,870 - train - INFO - Train: 150 [ 250/781 ( 32%)]  Loss:  3.771667 (3.4851)  Time: 0.504s,  253.94/s  (0.470s,  272.19/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 13:59:28,995 - train - INFO - Train: 150 [ 300/781 ( 38%)]  Loss:  3.691880 (3.4821)  Time: 0.475s,  269.26/s  (0.469s,  272.95/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 13:59:52,204 - train - INFO - Train: 150 [ 350/781 ( 45%)]  Loss:  3.511715 (3.4815)  Time: 0.489s,  261.59/s  (0.468s,  273.35/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:00:15,843 - train - INFO - Train: 150 [ 400/781 ( 51%)]  Loss:  3.600562 (3.4834)  Time: 0.467s,  274.35/s  (0.469s,  273.02/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:00:39,853 - train - INFO - Train: 150 [ 450/781 ( 58%)]  Loss:  3.159650 (3.4847)  Time: 0.506s,  253.12/s  (0.470s,  272.29/s)  LR: 1.000e-05  Data: 0.010 (0.008)
2024-04-07 14:01:03,815 - train - INFO - Train: 150 [ 500/781 ( 64%)]  Loss:  3.537441 (3.4787)  Time: 0.493s,  259.85/s  (0.471s,  271.76/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:01:26,673 - train - INFO - Train: 150 [ 550/781 ( 71%)]  Loss:  3.376529 (3.4718)  Time: 0.494s,  259.19/s  (0.470s,  272.49/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:01:50,344 - train - INFO - Train: 150 [ 600/781 ( 77%)]  Loss:  3.430555 (3.4686)  Time: 0.503s,  254.41/s  (0.470s,  272.32/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:02:14,420 - train - INFO - Train: 150 [ 650/781 ( 83%)]  Loss:  3.512019 (3.4697)  Time: 0.520s,  246.29/s  (0.471s,  271.81/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:02:38,161 - train - INFO - Train: 150 [ 700/781 ( 90%)]  Loss:  3.155508 (3.4703)  Time: 0.497s,  257.43/s  (0.471s,  271.65/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:03:02,360 - train - INFO - Train: 150 [ 750/781 ( 96%)]  Loss:  3.753789 (3.4710)  Time: 0.504s,  254.18/s  (0.472s,  271.16/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:03:16,808 - train - INFO - Train: 150 [ 780/781 (100%)]  Loss:  3.460931 (3.4713)  Time: 0.506s,  252.77/s  (0.472s,  270.95/s)  LR: 1.000e-05  Data: 0.000 (0.008)
2024-04-07 14:03:16,809 - train - INFO - True
2024-04-07 14:03:16,810 - train - INFO - alphas:tensor([0.8365, 0.0063, 0.0144, 0.0257, 0.1171], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,811 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,811 - train - INFO - True
2024-04-07 14:03:16,812 - train - INFO - alphas:tensor([0.4709, 0.0013, 0.0046, 0.0233, 0.4998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,812 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,812 - train - INFO - True
2024-04-07 14:03:16,813 - train - INFO - alphas:tensor([0.5256, 0.0034, 0.0202, 0.4508], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,814 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,814 - train - INFO - True
2024-04-07 14:03:16,815 - train - INFO - alphas:tensor([0.4443, 0.0036, 0.0120, 0.5401], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,816 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,816 - train - INFO - True
2024-04-07 14:03:16,817 - train - INFO - alphas:tensor([0.4532, 0.0017, 0.0162, 0.5289], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,817 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,817 - train - INFO - True
2024-04-07 14:03:16,818 - train - INFO - alphas:tensor([0.5621, 0.0036, 0.0123, 0.4220], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,819 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,819 - train - INFO - True
2024-04-07 14:03:16,820 - train - INFO - alphas:tensor([0.6345, 0.0013, 0.0023, 0.0123, 0.3497], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,821 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,821 - train - INFO - True
2024-04-07 14:03:16,822 - train - INFO - alphas:tensor([2.0751e-01, 5.5411e-04, 3.7365e-04, 1.3401e-02, 7.7817e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,822 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,823 - train - INFO - True
2024-04-07 14:03:16,823 - train - INFO - alphas:tensor([2.1240e-01, 2.9180e-04, 4.8089e-04, 8.5164e-03, 7.7831e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,824 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,824 - train - INFO - True
2024-04-07 14:03:16,825 - train - INFO - alphas:tensor([2.1485e-01, 1.4992e-04, 3.7757e-04, 1.0898e-02, 7.7372e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,826 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,826 - train - INFO - True
2024-04-07 14:03:16,827 - train - INFO - alphas:tensor([2.0209e-01, 4.1428e-04, 4.1202e-04, 1.4293e-02, 7.8279e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,827 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,827 - train - INFO - True
2024-04-07 14:03:16,828 - train - INFO - alphas:tensor([6.1497e-01, 2.8573e-04, 1.0004e-03, 1.0055e-02, 3.7369e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,829 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,830 - train - INFO - True
2024-04-07 14:03:16,830 - train - INFO - alphas:tensor([7.5249e-01, 4.2070e-04, 6.5932e-04, 5.1721e-03, 2.4126e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,834 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,834 - train - INFO - True
2024-04-07 14:03:16,835 - train - INFO - alphas:tensor([0.2633, 0.0018, 0.0019, 0.0375, 0.6956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,837 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,837 - train - INFO - True
2024-04-07 14:03:16,838 - train - INFO - alphas:tensor([2.7304e-01, 5.4074e-04, 8.7475e-04, 2.9662e-02, 6.9588e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,840 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,840 - train - INFO - True
2024-04-07 14:03:16,841 - train - INFO - alphas:tensor([2.9513e-01, 3.6403e-04, 9.4787e-04, 2.5697e-02, 6.7786e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,842 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,843 - train - INFO - True
2024-04-07 14:03:16,843 - train - INFO - alphas:tensor([0.2674, 0.0007, 0.0012, 0.0241, 0.7066], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,845 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,845 - train - INFO - True
2024-04-07 14:03:16,846 - train - INFO - alphas:tensor([2.9762e-01, 4.2220e-04, 1.6063e-03, 2.7003e-02, 6.7335e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,848 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,848 - train - INFO - True
2024-04-07 14:03:16,849 - train - INFO - alphas:tensor([0.2591, 0.0016, 0.0026, 0.0298, 0.7069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,851 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,851 - train - INFO - True
2024-04-07 14:03:16,852 - train - INFO - alphas:tensor([6.6678e-01, 1.8091e-04, 5.8342e-04, 1.2220e-02, 3.2023e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,856 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,856 - train - INFO - True
2024-04-07 14:03:16,857 - train - INFO - alphas:tensor([5.9008e-01, 1.5880e-04, 2.8344e-04, 1.1439e-02, 3.9804e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,864 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,864 - train - INFO - True
2024-04-07 14:03:16,865 - train - INFO - alphas:tensor([4.5072e-01, 1.2413e-04, 9.1453e-04, 2.0916e-02, 5.2732e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,869 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,869 - train - INFO - True
2024-04-07 14:03:16,870 - train - INFO - alphas:tensor([4.6018e-01, 1.3638e-04, 3.0371e-04, 1.8319e-02, 5.2106e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,874 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,874 - train - INFO - True
2024-04-07 14:03:16,875 - train - INFO - alphas:tensor([4.7782e-01, 1.1100e-04, 3.1609e-04, 1.6719e-02, 5.0504e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,878 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,878 - train - INFO - True
2024-04-07 14:03:16,879 - train - INFO - alphas:tensor([4.3890e-01, 1.4148e-04, 6.1575e-04, 1.9477e-02, 5.4087e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,883 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,883 - train - INFO - True
2024-04-07 14:03:16,884 - train - INFO - alphas:tensor([5.9421e-01, 1.1470e-04, 4.9220e-04, 9.6602e-03, 3.9552e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,891 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,892 - train - INFO - True
2024-04-07 14:03:16,892 - train - INFO - alphas:tensor([7.9440e-01, 7.0736e-05, 3.1014e-04, 5.5767e-03, 1.9964e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,912 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,912 - train - INFO - True
2024-04-07 14:03:16,913 - train - INFO - alphas:tensor([4.0912e-01, 2.0358e-04, 6.3227e-04, 2.9669e-02, 5.6037e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,923 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,923 - train - INFO - True
2024-04-07 14:03:16,924 - train - INFO - alphas:tensor([4.1511e-01, 8.1935e-05, 4.1840e-04, 1.9978e-02, 5.6441e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,934 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,934 - train - INFO - True
2024-04-07 14:03:16,935 - train - INFO - alphas:tensor([4.4630e-01, 1.0891e-04, 3.0068e-04, 2.3333e-02, 5.2996e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,945 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,945 - train - INFO - True
2024-04-07 14:03:16,946 - train - INFO - alphas:tensor([4.0686e-01, 1.4439e-04, 5.1621e-04, 2.2707e-02, 5.6977e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,956 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,956 - train - INFO - True
2024-04-07 14:03:16,957 - train - INFO - alphas:tensor([7.5610e-01, 5.9111e-05, 1.4373e-04, 4.4833e-03, 2.3921e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,976 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:16,976 - train - INFO - True
2024-04-07 14:03:16,977 - train - INFO - alphas:tensor([0.6045, 0.0012, 0.0025, 0.0288, 0.3631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:17,064 - train - INFO - tau:0.22594815553398728
2024-04-07 14:03:17,064 - train - INFO - avg block size:10.06060606060606
2024-04-07 14:03:17,064 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 14:03:17,064 - train - INFO - lasso_alpha:4.860884193479584e-07
2024-04-07 14:03:17,260 - train - INFO - Test: [   0/78]  Time: 0.191 (0.191)  Loss:  0.9707 (0.9707)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.9688 (92.9688)
2024-04-07 14:03:20,177 - train - INFO - Test: [  50/78]  Time: 0.054 (0.061)  Loss:  1.5811 (1.5455)  Acc@1: 66.4062 (66.2684)  Acc@5: 85.9375 (86.4124)
2024-04-07 14:03:21,672 - train - INFO - Test: [  78/78]  Time: 0.048 (0.058)  Loss:  1.8770 (1.5647)  Acc@1: 56.2500 (65.9100)  Acc@5: 87.5000 (86.0600)
2024-04-07 14:03:22,469 - train - INFO - Train: 151 [   0/781 (  0%)]  Loss:  3.658399 (3.6584)  Time: 0.640s,  199.94/s  (0.640s,  199.94/s)  LR: 1.000e-05  Data: 0.183 (0.183)
2024-04-07 14:03:46,391 - train - INFO - Train: 151 [  50/781 (  6%)]  Loss:  3.068965 (3.4481)  Time: 0.463s,  276.63/s  (0.482s,  265.79/s)  LR: 1.000e-05  Data: 0.007 (0.011)
2024-04-07 14:04:10,071 - train - INFO - Train: 151 [ 100/781 ( 13%)]  Loss:  3.150638 (3.4344)  Time: 0.569s,  225.07/s  (0.478s,  268.00/s)  LR: 1.000e-05  Data: 0.009 (0.009)
2024-04-07 14:04:33,833 - train - INFO - Train: 151 [ 150/781 ( 19%)]  Loss:  3.448115 (3.4444)  Time: 0.457s,  279.80/s  (0.477s,  268.45/s)  LR: 1.000e-05  Data: 0.008 (0.009)
2024-04-07 14:04:57,180 - train - INFO - Train: 151 [ 200/781 ( 26%)]  Loss:  3.850250 (3.4538)  Time: 0.458s,  279.41/s  (0.474s,  269.84/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:05:20,641 - train - INFO - Train: 151 [ 250/781 ( 32%)]  Loss:  3.590864 (3.4501)  Time: 0.490s,  261.08/s  (0.473s,  270.43/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:05:44,365 - train - INFO - Train: 151 [ 300/781 ( 38%)]  Loss:  3.702533 (3.4524)  Time: 0.474s,  269.84/s  (0.474s,  270.32/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:06:08,098 - train - INFO - Train: 151 [ 350/781 ( 45%)]  Loss:  3.692619 (3.4520)  Time: 0.520s,  246.02/s  (0.474s,  270.23/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:06:31,172 - train - INFO - Train: 151 [ 400/781 ( 51%)]  Loss:  3.365071 (3.4507)  Time: 0.470s,  272.31/s  (0.472s,  271.10/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:06:54,081 - train - INFO - Train: 151 [ 450/781 ( 58%)]  Loss:  3.605292 (3.4531)  Time: 0.373s,  343.25/s  (0.471s,  272.00/s)  LR: 1.000e-05  Data: 0.004 (0.008)
2024-04-07 14:07:18,248 - train - INFO - Train: 151 [ 500/781 ( 64%)]  Loss:  3.257074 (3.4512)  Time: 0.491s,  260.51/s  (0.472s,  271.27/s)  LR: 1.000e-05  Data: 0.011 (0.008)
2024-04-07 14:07:41,016 - train - INFO - Train: 151 [ 550/781 ( 71%)]  Loss:  3.646932 (3.4527)  Time: 0.505s,  253.66/s  (0.470s,  272.13/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:08:03,809 - train - INFO - Train: 151 [ 600/781 ( 77%)]  Loss:  3.608414 (3.4524)  Time: 0.326s,  392.73/s  (0.469s,  272.83/s)  LR: 1.000e-05  Data: 0.004 (0.008)
2024-04-07 14:08:27,522 - train - INFO - Train: 151 [ 650/781 ( 83%)]  Loss:  3.178001 (3.4506)  Time: 0.467s,  273.93/s  (0.470s,  272.61/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:08:51,344 - train - INFO - Train: 151 [ 700/781 ( 90%)]  Loss:  3.400717 (3.4541)  Time: 0.448s,  285.79/s  (0.470s,  272.32/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:09:14,872 - train - INFO - Train: 151 [ 750/781 ( 96%)]  Loss:  3.029334 (3.4531)  Time: 0.503s,  254.62/s  (0.470s,  272.30/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:09:29,141 - train - INFO - Train: 151 [ 780/781 (100%)]  Loss:  3.352710 (3.4523)  Time: 0.487s,  262.75/s  (0.470s,  272.18/s)  LR: 1.000e-05  Data: 0.000 (0.008)
2024-04-07 14:09:29,142 - train - INFO - True
2024-04-07 14:09:29,144 - train - INFO - alphas:tensor([0.8397, 0.0060, 0.0139, 0.0250, 0.1154], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,145 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,145 - train - INFO - True
2024-04-07 14:09:29,147 - train - INFO - alphas:tensor([0.4712, 0.0013, 0.0044, 0.0227, 0.5005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,148 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,148 - train - INFO - True
2024-04-07 14:09:29,149 - train - INFO - alphas:tensor([0.5262, 0.0032, 0.0196, 0.4510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,150 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,151 - train - INFO - True
2024-04-07 14:09:29,152 - train - INFO - alphas:tensor([0.4444, 0.0034, 0.0116, 0.5406], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,153 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,153 - train - INFO - True
2024-04-07 14:09:29,154 - train - INFO - alphas:tensor([0.4528, 0.0016, 0.0156, 0.5299], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,155 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,155 - train - INFO - True
2024-04-07 14:09:29,157 - train - INFO - alphas:tensor([0.5622, 0.0034, 0.0119, 0.4225], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,158 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,158 - train - INFO - True
2024-04-07 14:09:29,160 - train - INFO - alphas:tensor([0.6359, 0.0012, 0.0022, 0.0119, 0.3489], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,161 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,161 - train - INFO - True
2024-04-07 14:09:29,163 - train - INFO - alphas:tensor([2.0636e-01, 5.1828e-04, 3.4808e-04, 1.2947e-02, 7.7983e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,164 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,164 - train - INFO - True
2024-04-07 14:09:29,165 - train - INFO - alphas:tensor([2.1132e-01, 2.7148e-04, 4.4916e-04, 8.1926e-03, 7.7977e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,166 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,166 - train - INFO - True
2024-04-07 14:09:29,168 - train - INFO - alphas:tensor([2.1310e-01, 1.3823e-04, 3.5120e-04, 1.0509e-02, 7.7591e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,169 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,169 - train - INFO - True
2024-04-07 14:09:29,170 - train - INFO - alphas:tensor([2.0068e-01, 3.8666e-04, 3.8419e-04, 1.3824e-02, 7.8472e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,171 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,171 - train - INFO - True
2024-04-07 14:09:29,172 - train - INFO - alphas:tensor([6.1556e-01, 2.6556e-04, 9.4127e-04, 9.6994e-03, 3.7353e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,174 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,174 - train - INFO - True
2024-04-07 14:09:29,175 - train - INFO - alphas:tensor([7.5448e-01, 3.9164e-04, 6.1720e-04, 4.9466e-03, 2.3956e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,180 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,180 - train - INFO - True
2024-04-07 14:09:29,182 - train - INFO - alphas:tensor([0.2625, 0.0017, 0.0018, 0.0367, 0.6974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,184 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,184 - train - INFO - True
2024-04-07 14:09:29,186 - train - INFO - alphas:tensor([2.7284e-01, 5.0568e-04, 8.2240e-04, 2.8904e-02, 6.9693e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,188 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,188 - train - INFO - True
2024-04-07 14:09:29,189 - train - INFO - alphas:tensor([2.9469e-01, 3.3937e-04, 8.9099e-04, 2.5074e-02, 6.7901e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,192 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,192 - train - INFO - True
2024-04-07 14:09:29,201 - train - INFO - alphas:tensor([2.6694e-01, 6.8337e-04, 1.1304e-03, 2.3519e-02, 7.0773e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,205 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,210 - train - INFO - True
2024-04-07 14:09:29,211 - train - INFO - alphas:tensor([2.9660e-01, 3.9423e-04, 1.5240e-03, 2.6316e-02, 6.7517e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,213 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,213 - train - INFO - True
2024-04-07 14:09:29,214 - train - INFO - alphas:tensor([0.2579, 0.0016, 0.0024, 0.0291, 0.7090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,216 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,216 - train - INFO - True
2024-04-07 14:09:29,217 - train - INFO - alphas:tensor([6.6728e-01, 1.6732e-04, 5.4683e-04, 1.1813e-02, 3.2019e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,220 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,221 - train - INFO - True
2024-04-07 14:09:29,221 - train - INFO - alphas:tensor([5.9093e-01, 1.4666e-04, 2.6325e-04, 1.1033e-02, 3.9763e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,229 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,229 - train - INFO - True
2024-04-07 14:09:29,230 - train - INFO - alphas:tensor([4.5106e-01, 1.1438e-04, 8.6034e-04, 2.0339e-02, 5.2763e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,234 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,234 - train - INFO - True
2024-04-07 14:09:29,235 - train - INFO - alphas:tensor([4.6094e-01, 1.2561e-04, 2.8210e-04, 1.7749e-02, 5.2091e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,238 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,239 - train - INFO - True
2024-04-07 14:09:29,239 - train - INFO - alphas:tensor([4.7849e-01, 1.0215e-04, 2.9393e-04, 1.6189e-02, 5.0493e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,243 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,243 - train - INFO - True
2024-04-07 14:09:29,244 - train - INFO - alphas:tensor([4.3908e-01, 1.3031e-04, 5.7664e-04, 1.8909e-02, 5.4130e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,248 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,248 - train - INFO - True
2024-04-07 14:09:29,249 - train - INFO - alphas:tensor([5.9487e-01, 1.0556e-04, 4.5948e-04, 9.3094e-03, 3.9526e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,256 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,257 - train - INFO - True
2024-04-07 14:09:29,257 - train - INFO - alphas:tensor([7.9551e-01, 6.4739e-05, 2.8871e-04, 5.3493e-03, 1.9879e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,277 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,277 - train - INFO - True
2024-04-07 14:09:29,278 - train - INFO - alphas:tensor([4.0826e-01, 1.8837e-04, 5.9294e-04, 2.8987e-02, 5.6197e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,288 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,288 - train - INFO - True
2024-04-07 14:09:29,289 - train - INFO - alphas:tensor([4.1488e-01, 7.5047e-05, 3.9039e-04, 1.9418e-02, 5.6524e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,299 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,299 - train - INFO - True
2024-04-07 14:09:29,300 - train - INFO - alphas:tensor([4.4672e-01, 1.0035e-04, 2.7991e-04, 2.2765e-02, 5.3014e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,310 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,310 - train - INFO - True
2024-04-07 14:09:29,311 - train - INFO - alphas:tensor([4.0738e-01, 1.3343e-04, 4.8370e-04, 2.2144e-02, 5.6986e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,321 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,321 - train - INFO - True
2024-04-07 14:09:29,322 - train - INFO - alphas:tensor([7.5641e-01, 5.4161e-05, 1.3297e-04, 4.3000e-03, 2.3910e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,342 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,342 - train - INFO - True
2024-04-07 14:09:29,343 - train - INFO - alphas:tensor([0.6051, 0.0011, 0.0024, 0.0281, 0.3632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:09:29,420 - train - INFO - tau:0.22368867397864742
2024-04-07 14:09:29,420 - train - INFO - avg block size:10.06060606060606
2024-04-07 14:09:29,421 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 14:09:29,639 - train - INFO - Test: [   0/78]  Time: 0.215 (0.215)  Loss:  0.9263 (0.9263)  Acc@1: 83.5938 (83.5938)  Acc@5: 93.7500 (93.7500)
2024-04-07 14:09:32,744 - train - INFO - Test: [  50/78]  Time: 0.054 (0.065)  Loss:  1.5674 (1.5419)  Acc@1: 65.6250 (66.2224)  Acc@5: 86.7188 (86.4277)
2024-04-07 14:09:34,207 - train - INFO - Test: [  78/78]  Time: 0.046 (0.061)  Loss:  1.8320 (1.5575)  Acc@1: 50.0000 (65.9600)  Acc@5: 87.5000 (86.1000)
2024-04-07 14:09:34,977 - train - INFO - Train: 152 [   0/781 (  0%)]  Loss:  3.427550 (3.4275)  Time: 0.691s,  185.20/s  (0.691s,  185.20/s)  LR: 1.000e-05  Data: 0.198 (0.198)
2024-04-07 14:09:59,417 - train - INFO - Train: 152 [  50/781 (  6%)]  Loss:  3.644635 (3.4365)  Time: 0.473s,  270.60/s  (0.493s,  259.78/s)  LR: 1.000e-05  Data: 0.006 (0.012)
2024-04-07 14:10:22,504 - train - INFO - Train: 152 [ 100/781 ( 13%)]  Loss:  3.299145 (3.4497)  Time: 0.483s,  264.91/s  (0.477s,  268.13/s)  LR: 1.000e-05  Data: 0.007 (0.009)
2024-04-07 14:10:45,432 - train - INFO - Train: 152 [ 150/781 ( 19%)]  Loss:  3.608878 (3.4420)  Time: 0.449s,  285.08/s  (0.471s,  271.68/s)  LR: 1.000e-05  Data: 0.008 (0.009)
2024-04-07 14:11:09,038 - train - INFO - Train: 152 [ 200/781 ( 26%)]  Loss:  3.257025 (3.4459)  Time: 0.487s,  262.72/s  (0.471s,  271.55/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:11:32,798 - train - INFO - Train: 152 [ 250/781 ( 32%)]  Loss:  3.765764 (3.4411)  Time: 0.446s,  286.92/s  (0.472s,  271.11/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:11:56,321 - train - INFO - Train: 152 [ 300/781 ( 38%)]  Loss:  3.670151 (3.4397)  Time: 0.500s,  255.94/s  (0.472s,  271.28/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:12:19,653 - train - INFO - Train: 152 [ 350/781 ( 45%)]  Loss:  3.321065 (3.4430)  Time: 0.486s,  263.23/s  (0.471s,  271.70/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:12:42,553 - train - INFO - Train: 152 [ 400/781 ( 51%)]  Loss:  3.660289 (3.4476)  Time: 0.490s,  261.21/s  (0.469s,  272.65/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:13:06,401 - train - INFO - Train: 152 [ 450/781 ( 58%)]  Loss:  3.544375 (3.4480)  Time: 0.448s,  285.51/s  (0.470s,  272.17/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:13:29,437 - train - INFO - Train: 152 [ 500/781 ( 64%)]  Loss:  3.590092 (3.4487)  Time: 0.487s,  262.71/s  (0.469s,  272.73/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:13:52,174 - train - INFO - Train: 152 [ 550/781 ( 71%)]  Loss:  3.567491 (3.4552)  Time: 0.479s,  267.28/s  (0.468s,  273.50/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:14:14,874 - train - INFO - Train: 152 [ 600/781 ( 77%)]  Loss:  3.695844 (3.4578)  Time: 0.440s,  290.64/s  (0.467s,  274.19/s)  LR: 1.000e-05  Data: 0.005 (0.008)
2024-04-07 14:14:38,555 - train - INFO - Train: 152 [ 650/781 ( 83%)]  Loss:  3.710738 (3.4552)  Time: 0.383s,  334.21/s  (0.467s,  273.88/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:15:02,589 - train - INFO - Train: 152 [ 700/781 ( 90%)]  Loss:  3.227365 (3.4561)  Time: 0.489s,  261.71/s  (0.468s,  273.33/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:15:26,166 - train - INFO - Train: 152 [ 750/781 ( 96%)]  Loss:  3.556472 (3.4526)  Time: 0.474s,  269.80/s  (0.469s,  273.20/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:15:40,053 - train - INFO - Train: 152 [ 780/781 (100%)]  Loss:  3.192642 (3.4516)  Time: 0.498s,  256.96/s  (0.468s,  273.33/s)  LR: 1.000e-05  Data: 0.000 (0.008)
2024-04-07 14:15:40,054 - train - INFO - True
2024-04-07 14:15:40,056 - train - INFO - alphas:tensor([0.8428, 0.0057, 0.0134, 0.0243, 0.1138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,057 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,058 - train - INFO - True
2024-04-07 14:15:40,059 - train - INFO - alphas:tensor([0.4712, 0.0012, 0.0042, 0.0220, 0.5014], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,059 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,060 - train - INFO - True
2024-04-07 14:15:40,061 - train - INFO - alphas:tensor([0.5272, 0.0031, 0.0191, 0.4507], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,062 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,062 - train - INFO - True
2024-04-07 14:15:40,064 - train - INFO - alphas:tensor([0.4443, 0.0033, 0.0112, 0.5412], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,064 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,064 - train - INFO - True
2024-04-07 14:15:40,066 - train - INFO - alphas:tensor([0.4529, 0.0015, 0.0151, 0.5304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,066 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,067 - train - INFO - True
2024-04-07 14:15:40,068 - train - INFO - alphas:tensor([0.5627, 0.0033, 0.0115, 0.4226], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,069 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,069 - train - INFO - True
2024-04-07 14:15:40,070 - train - INFO - alphas:tensor([0.6378, 0.0011, 0.0020, 0.0114, 0.3476], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,072 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,072 - train - INFO - True
2024-04-07 14:15:40,073 - train - INFO - alphas:tensor([2.0539e-01, 4.8463e-04, 3.2393e-04, 1.2523e-02, 7.8128e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,074 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,074 - train - INFO - True
2024-04-07 14:15:40,076 - train - INFO - alphas:tensor([2.0962e-01, 2.5138e-04, 4.1830e-04, 7.8691e-03, 7.8184e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,077 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,077 - train - INFO - True
2024-04-07 14:15:40,078 - train - INFO - alphas:tensor([2.1164e-01, 1.2746e-04, 3.2692e-04, 1.0127e-02, 7.7778e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,079 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,079 - train - INFO - True
2024-04-07 14:15:40,080 - train - INFO - alphas:tensor([1.9924e-01, 3.6007e-04, 3.5794e-04, 1.3369e-02, 7.8667e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,081 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,081 - train - INFO - True
2024-04-07 14:15:40,082 - train - INFO - alphas:tensor([6.1663e-01, 2.4610e-04, 8.8446e-04, 9.3436e-03, 3.7290e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,084 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,084 - train - INFO - True
2024-04-07 14:15:40,085 - train - INFO - alphas:tensor([7.5586e-01, 3.6455e-04, 5.7657e-04, 4.7255e-03, 2.3847e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,090 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,090 - train - INFO - True
2024-04-07 14:15:40,091 - train - INFO - alphas:tensor([0.2619, 0.0016, 0.0017, 0.0360, 0.6988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,093 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,093 - train - INFO - True
2024-04-07 14:15:40,094 - train - INFO - alphas:tensor([2.7188e-01, 4.7244e-04, 7.7128e-04, 2.8178e-02, 6.9870e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,097 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,097 - train - INFO - True
2024-04-07 14:15:40,098 - train - INFO - alphas:tensor([2.9378e-01, 3.1564e-04, 8.3750e-04, 2.4426e-02, 6.8064e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,100 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,100 - train - INFO - True
2024-04-07 14:15:40,101 - train - INFO - alphas:tensor([2.6601e-01, 6.3986e-04, 1.0643e-03, 2.2867e-02, 7.0941e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,104 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,104 - train - INFO - True
2024-04-07 14:15:40,105 - train - INFO - alphas:tensor([2.9544e-01, 3.6814e-04, 1.4416e-03, 2.5698e-02, 6.7705e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,107 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,107 - train - INFO - True
2024-04-07 14:15:40,108 - train - INFO - alphas:tensor([0.2574, 0.0015, 0.0023, 0.0284, 0.7104], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,111 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,111 - train - INFO - True
2024-04-07 14:15:40,112 - train - INFO - alphas:tensor([6.6788e-01, 1.5451e-04, 5.1133e-04, 1.1411e-02, 3.2004e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,116 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,116 - train - INFO - True
2024-04-07 14:15:40,117 - train - INFO - alphas:tensor([5.9187e-01, 1.3508e-04, 2.4421e-04, 1.0651e-02, 3.9710e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,125 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,125 - train - INFO - True
2024-04-07 14:15:40,126 - train - INFO - alphas:tensor([4.5115e-01, 1.0533e-04, 8.0800e-04, 1.9766e-02, 5.2817e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,130 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,130 - train - INFO - True
2024-04-07 14:15:40,131 - train - INFO - alphas:tensor([4.6147e-01, 1.1570e-04, 2.6196e-04, 1.7214e-02, 5.2094e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,135 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,135 - train - INFO - True
2024-04-07 14:15:40,136 - train - INFO - alphas:tensor([4.7873e-01, 9.3684e-05, 2.7318e-04, 1.5670e-02, 5.0524e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,140 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,140 - train - INFO - True
2024-04-07 14:15:40,141 - train - INFO - alphas:tensor([4.3896e-01, 1.2025e-04, 5.3910e-04, 1.8332e-02, 5.4205e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,145 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,145 - train - INFO - True
2024-04-07 14:15:40,146 - train - INFO - alphas:tensor([5.9593e-01, 9.7129e-05, 4.2931e-04, 8.9922e-03, 3.9455e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,153 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,153 - train - INFO - True
2024-04-07 14:15:40,154 - train - INFO - alphas:tensor([7.9670e-01, 5.9306e-05, 2.6819e-04, 5.1226e-03, 1.9785e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,174 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,174 - train - INFO - True
2024-04-07 14:15:40,175 - train - INFO - alphas:tensor([4.0842e-01, 1.7454e-04, 5.5588e-04, 2.8298e-02, 5.6255e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,185 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,185 - train - INFO - True
2024-04-07 14:15:40,186 - train - INFO - alphas:tensor([4.1518e-01, 6.8735e-05, 3.6396e-04, 1.8846e-02, 5.6555e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,196 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,196 - train - INFO - True
2024-04-07 14:15:40,197 - train - INFO - alphas:tensor([4.4676e-01, 9.2164e-05, 2.6072e-04, 2.2186e-02, 5.3070e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,207 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,207 - train - INFO - True
2024-04-07 14:15:40,208 - train - INFO - alphas:tensor([4.0804e-01, 1.2311e-04, 4.5210e-04, 2.1572e-02, 5.6981e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,218 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,218 - train - INFO - True
2024-04-07 14:15:40,219 - train - INFO - alphas:tensor([7.5696e-01, 4.9488e-05, 1.2283e-04, 4.1193e-03, 2.3874e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,238 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,238 - train - INFO - True
2024-04-07 14:15:40,239 - train - INFO - alphas:tensor([0.6061, 0.0010, 0.0023, 0.0276, 0.3630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:40,316 - train - INFO - tau:0.22145178723886094
2024-04-07 14:15:40,317 - train - INFO - avg block size:10.06060606060606
2024-04-07 14:15:40,317 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 14:15:40,317 - train - INFO - lasso_alpha:4.418985630435985e-07
2024-04-07 14:15:40,498 - train - INFO - Test: [   0/78]  Time: 0.178 (0.178)  Loss:  0.9351 (0.9351)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 14:15:43,681 - train - INFO - Test: [  50/78]  Time: 0.051 (0.066)  Loss:  1.5156 (1.5379)  Acc@1: 67.9688 (66.3909)  Acc@5: 89.0625 (86.6881)
2024-04-07 14:15:45,078 - train - INFO - Test: [  78/78]  Time: 0.047 (0.060)  Loss:  1.8682 (1.5598)  Acc@1: 50.0000 (65.9400)  Acc@5: 87.5000 (86.2400)
2024-04-07 14:15:45,829 - train - INFO - Train: 153 [   0/781 (  0%)]  Loss:  3.637847 (3.6378)  Time: 0.674s,  189.96/s  (0.674s,  189.96/s)  LR: 1.000e-05  Data: 0.181 (0.181)
2024-04-07 14:16:09,071 - train - INFO - Train: 153 [  50/781 (  6%)]  Loss:  3.714700 (3.4903)  Time: 0.453s,  282.70/s  (0.469s,  272.97/s)  LR: 1.000e-05  Data: 0.009 (0.010)
2024-04-07 14:16:32,150 - train - INFO - Train: 153 [ 100/781 ( 13%)]  Loss:  3.611597 (3.4759)  Time: 0.442s,  289.58/s  (0.465s,  275.11/s)  LR: 1.000e-05  Data: 0.009 (0.009)
2024-04-07 14:16:55,787 - train - INFO - Train: 153 [ 150/781 ( 19%)]  Loss:  3.430516 (3.4694)  Time: 0.470s,  272.33/s  (0.468s,  273.66/s)  LR: 1.000e-05  Data: 0.007 (0.009)
2024-04-07 14:17:18,706 - train - INFO - Train: 153 [ 200/781 ( 26%)]  Loss:  3.331954 (3.4723)  Time: 0.366s,  349.78/s  (0.465s,  275.04/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:17:41,343 - train - INFO - Train: 153 [ 250/781 ( 32%)]  Loss:  3.151362 (3.4511)  Time: 0.446s,  287.00/s  (0.463s,  276.54/s)  LR: 1.000e-05  Data: 0.005 (0.008)
2024-04-07 14:18:05,162 - train - INFO - Train: 153 [ 300/781 ( 38%)]  Loss:  3.594050 (3.4498)  Time: 0.493s,  259.48/s  (0.465s,  275.20/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:18:28,551 - train - INFO - Train: 153 [ 350/781 ( 45%)]  Loss:  3.497242 (3.4548)  Time: 0.497s,  257.44/s  (0.465s,  274.98/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:18:52,741 - train - INFO - Train: 153 [ 400/781 ( 51%)]  Loss:  3.715180 (3.4559)  Time: 0.472s,  271.20/s  (0.468s,  273.64/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:19:15,802 - train - INFO - Train: 153 [ 450/781 ( 58%)]  Loss:  3.081510 (3.4522)  Time: 0.453s,  282.68/s  (0.467s,  274.07/s)  LR: 1.000e-05  Data: 0.014 (0.008)
2024-04-07 14:19:38,783 - train - INFO - Train: 153 [ 500/781 ( 64%)]  Loss:  3.784421 (3.4493)  Time: 0.475s,  269.49/s  (0.466s,  274.51/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:20:03,083 - train - INFO - Train: 153 [ 550/781 ( 71%)]  Loss:  3.777682 (3.4434)  Time: 0.489s,  261.81/s  (0.468s,  273.46/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:20:27,367 - train - INFO - Train: 153 [ 600/781 ( 77%)]  Loss:  3.806612 (3.4443)  Time: 0.487s,  262.86/s  (0.470s,  272.61/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:20:51,117 - train - INFO - Train: 153 [ 650/781 ( 83%)]  Loss:  3.348811 (3.4413)  Time: 0.487s,  262.72/s  (0.470s,  272.37/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:21:14,436 - train - INFO - Train: 153 [ 700/781 ( 90%)]  Loss:  3.739842 (3.4448)  Time: 0.470s,  272.25/s  (0.470s,  272.52/s)  LR: 1.000e-05  Data: 0.005 (0.008)
2024-04-07 14:21:38,025 - train - INFO - Train: 153 [ 750/781 ( 96%)]  Loss:  3.661408 (3.4463)  Time: 0.397s,  322.43/s  (0.470s,  272.44/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:21:51,725 - train - INFO - Train: 153 [ 780/781 (100%)]  Loss:  3.240324 (3.4461)  Time: 0.489s,  262.02/s  (0.469s,  272.73/s)  LR: 1.000e-05  Data: 0.000 (0.008)
2024-04-07 14:21:51,726 - train - INFO - True
2024-04-07 14:21:51,728 - train - INFO - alphas:tensor([0.8459, 0.0055, 0.0129, 0.0236, 0.1121], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,729 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,729 - train - INFO - True
2024-04-07 14:21:51,731 - train - INFO - alphas:tensor([0.4711, 0.0011, 0.0040, 0.0214, 0.5024], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,732 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,732 - train - INFO - True
2024-04-07 14:21:51,733 - train - INFO - alphas:tensor([0.5276, 0.0029, 0.0185, 0.4509], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,735 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,735 - train - INFO - True
2024-04-07 14:21:51,736 - train - INFO - alphas:tensor([0.4438, 0.0031, 0.0108, 0.5422], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,737 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,737 - train - INFO - True
2024-04-07 14:21:51,739 - train - INFO - alphas:tensor([0.4528, 0.0014, 0.0147, 0.5311], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,739 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,740 - train - INFO - True
2024-04-07 14:21:51,741 - train - INFO - alphas:tensor([0.5635, 0.0031, 0.0111, 0.4223], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,742 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,742 - train - INFO - True
2024-04-07 14:21:51,744 - train - INFO - alphas:tensor([0.6389, 0.0010, 0.0019, 0.0111, 0.3471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,746 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,746 - train - INFO - True
2024-04-07 14:21:51,747 - train - INFO - alphas:tensor([2.0407e-01, 4.5179e-04, 3.0107e-04, 1.2082e-02, 7.8310e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,748 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,748 - train - INFO - True
2024-04-07 14:21:51,750 - train - INFO - alphas:tensor([2.0798e-01, 2.3283e-04, 3.8998e-04, 7.5465e-03, 7.8385e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,751 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,751 - train - INFO - True
2024-04-07 14:21:51,752 - train - INFO - alphas:tensor([2.1024e-01, 1.1727e-04, 3.0434e-04, 9.7663e-03, 7.7957e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,753 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,753 - train - INFO - True
2024-04-07 14:21:51,755 - train - INFO - alphas:tensor([1.9839e-01, 3.3513e-04, 3.3359e-04, 1.2930e-02, 7.8802e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,756 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,756 - train - INFO - True
2024-04-07 14:21:51,757 - train - INFO - alphas:tensor([6.1678e-01, 2.2831e-04, 8.3171e-04, 9.0031e-03, 3.7315e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,759 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,759 - train - INFO - True
2024-04-07 14:21:51,760 - train - INFO - alphas:tensor([7.5783e-01, 3.3895e-04, 5.3909e-04, 4.5114e-03, 2.3678e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,765 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,765 - train - INFO - True
2024-04-07 14:21:51,766 - train - INFO - alphas:tensor([0.2617, 0.0015, 0.0016, 0.0352, 0.7000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,769 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,769 - train - INFO - True
2024-04-07 14:21:51,770 - train - INFO - alphas:tensor([2.7144e-01, 4.4145e-04, 7.2540e-04, 2.7487e-02, 6.9991e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,773 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,773 - train - INFO - True
2024-04-07 14:21:51,774 - train - INFO - alphas:tensor([2.9377e-01, 2.9386e-04, 7.8886e-04, 2.3819e-02, 6.8133e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,777 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,777 - train - INFO - True
2024-04-07 14:21:51,778 - train - INFO - alphas:tensor([2.6538e-01, 6.0062e-04, 1.0031e-03, 2.2289e-02, 7.1073e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,780 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,780 - train - INFO - True
2024-04-07 14:21:51,782 - train - INFO - alphas:tensor([2.9554e-01, 3.4394e-04, 1.3658e-03, 2.5136e-02, 6.7761e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,784 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,784 - train - INFO - True
2024-04-07 14:21:51,785 - train - INFO - alphas:tensor([0.2569, 0.0014, 0.0022, 0.0277, 0.7118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,788 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,788 - train - INFO - True
2024-04-07 14:21:51,789 - train - INFO - alphas:tensor([6.6861e-01, 1.4230e-04, 4.7844e-04, 1.1030e-02, 3.1974e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,793 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,793 - train - INFO - True
2024-04-07 14:21:51,794 - train - INFO - alphas:tensor([5.9324e-01, 1.2435e-04, 2.2618e-04, 1.0266e-02, 3.9615e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,803 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,803 - train - INFO - True
2024-04-07 14:21:51,804 - train - INFO - alphas:tensor([4.5036e-01, 9.6765e-05, 7.5848e-04, 1.9245e-02, 5.2954e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,808 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,809 - train - INFO - True
2024-04-07 14:21:51,809 - train - INFO - alphas:tensor([4.6195e-01, 1.0647e-04, 2.4323e-04, 1.6700e-02, 5.2100e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,814 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,814 - train - INFO - True
2024-04-07 14:21:51,815 - train - INFO - alphas:tensor([4.7808e-01, 8.6079e-05, 2.5359e-04, 1.5196e-02, 5.0639e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,819 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,819 - train - INFO - True
2024-04-07 14:21:51,820 - train - INFO - alphas:tensor([4.3879e-01, 1.1061e-04, 5.0418e-04, 1.7784e-02, 5.4281e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,824 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,824 - train - INFO - True
2024-04-07 14:21:51,825 - train - INFO - alphas:tensor([5.9675e-01, 8.9107e-05, 4.0074e-04, 8.6560e-03, 3.9411e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,833 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,833 - train - INFO - True
2024-04-07 14:21:51,833 - train - INFO - alphas:tensor([7.9809e-01, 5.4134e-05, 2.4896e-04, 4.9071e-03, 1.9670e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,853 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,853 - train - INFO - True
2024-04-07 14:21:51,854 - train - INFO - alphas:tensor([4.0930e-01, 1.6139e-04, 5.2015e-04, 2.7626e-02, 5.6239e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,864 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,864 - train - INFO - True
2024-04-07 14:21:51,865 - train - INFO - alphas:tensor([4.1537e-01, 6.2845e-05, 3.3890e-04, 1.8315e-02, 5.6591e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,875 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,875 - train - INFO - True
2024-04-07 14:21:51,876 - train - INFO - alphas:tensor([4.4674e-01, 8.4607e-05, 2.4244e-04, 2.1650e-02, 5.3128e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,886 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,886 - train - INFO - True
2024-04-07 14:21:51,887 - train - INFO - alphas:tensor([4.0783e-01, 1.1350e-04, 4.2218e-04, 2.1038e-02, 5.7060e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,897 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,897 - train - INFO - True
2024-04-07 14:21:51,898 - train - INFO - alphas:tensor([7.5816e-01, 4.5064e-05, 1.1312e-04, 3.9328e-03, 2.3775e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,917 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,917 - train - INFO - True
2024-04-07 14:21:51,918 - train - INFO - alphas:tensor([0.6065, 0.0010, 0.0022, 0.0270, 0.3633], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:21:51,996 - train - INFO - tau:0.21923726936647234
2024-04-07 14:21:51,996 - train - INFO - avg block size:10.06060606060606
2024-04-07 14:21:51,996 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 14:21:52,203 - train - INFO - Test: [   0/78]  Time: 0.203 (0.203)  Loss:  0.9785 (0.9785)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 14:21:55,402 - train - INFO - Test: [  50/78]  Time: 0.075 (0.067)  Loss:  1.5430 (1.5376)  Acc@1: 65.6250 (66.2531)  Acc@5: 88.2812 (86.3358)
2024-04-07 14:21:57,072 - train - INFO - Test: [  78/78]  Time: 0.072 (0.064)  Loss:  1.8760 (1.5572)  Acc@1: 50.0000 (65.8600)  Acc@5: 87.5000 (86.0700)
2024-04-07 14:21:57,842 - train - INFO - Train: 154 [   0/781 (  0%)]  Loss:  3.611308 (3.6113)  Time: 0.656s,  195.25/s  (0.656s,  195.25/s)  LR: 1.000e-05  Data: 0.190 (0.190)
2024-04-07 14:22:21,082 - train - INFO - Train: 154 [  50/781 (  6%)]  Loss:  3.435917 (3.5211)  Time: 0.416s,  307.33/s  (0.469s,  273.21/s)  LR: 1.000e-05  Data: 0.005 (0.011)
2024-04-07 14:22:44,299 - train - INFO - Train: 154 [ 100/781 ( 13%)]  Loss:  3.641826 (3.5175)  Time: 0.478s,  267.99/s  (0.466s,  274.43/s)  LR: 1.000e-05  Data: 0.008 (0.010)
2024-04-07 14:23:07,547 - train - INFO - Train: 154 [ 150/781 ( 19%)]  Loss:  3.337819 (3.4798)  Time: 0.403s,  317.50/s  (0.466s,  274.72/s)  LR: 1.000e-05  Data: 0.009 (0.009)
2024-04-07 14:23:31,456 - train - INFO - Train: 154 [ 200/781 ( 26%)]  Loss:  2.925733 (3.4890)  Time: 0.491s,  260.91/s  (0.469s,  272.94/s)  LR: 1.000e-05  Data: 0.008 (0.009)
2024-04-07 14:23:53,841 - train - INFO - Train: 154 [ 250/781 ( 32%)]  Loss:  3.151010 (3.4769)  Time: 0.482s,  265.43/s  (0.465s,  275.43/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:24:17,484 - train - INFO - Train: 154 [ 300/781 ( 38%)]  Loss:  3.345359 (3.4753)  Time: 0.367s,  348.59/s  (0.466s,  274.64/s)  LR: 1.000e-05  Data: 0.005 (0.008)
2024-04-07 14:24:40,926 - train - INFO - Train: 154 [ 350/781 ( 45%)]  Loss:  3.426165 (3.4678)  Time: 0.486s,  263.46/s  (0.466s,  274.41/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:25:03,554 - train - INFO - Train: 154 [ 400/781 ( 51%)]  Loss:  3.002708 (3.4563)  Time: 0.497s,  257.47/s  (0.465s,  275.43/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:25:27,327 - train - INFO - Train: 154 [ 450/781 ( 58%)]  Loss:  3.650456 (3.4566)  Time: 0.504s,  254.05/s  (0.466s,  274.73/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:25:51,088 - train - INFO - Train: 154 [ 500/781 ( 64%)]  Loss:  2.918673 (3.4591)  Time: 0.505s,  253.58/s  (0.467s,  274.19/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:26:15,026 - train - INFO - Train: 154 [ 550/781 ( 71%)]  Loss:  3.594707 (3.4670)  Time: 0.527s,  242.74/s  (0.468s,  273.55/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:26:38,666 - train - INFO - Train: 154 [ 600/781 ( 77%)]  Loss:  3.585231 (3.4671)  Time: 0.485s,  264.01/s  (0.468s,  273.32/s)  LR: 1.000e-05  Data: 0.005 (0.008)
2024-04-07 14:27:02,265 - train - INFO - Train: 154 [ 650/781 ( 83%)]  Loss:  3.733932 (3.4696)  Time: 0.495s,  258.84/s  (0.469s,  273.16/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:27:24,932 - train - INFO - Train: 154 [ 700/781 ( 90%)]  Loss:  3.273118 (3.4722)  Time: 0.479s,  267.15/s  (0.468s,  273.79/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:27:46,649 - train - INFO - Train: 154 [ 750/781 ( 96%)]  Loss:  3.662855 (3.4751)  Time: 0.439s,  291.88/s  (0.465s,  275.09/s)  LR: 1.000e-05  Data: 0.005 (0.008)
2024-04-07 14:27:58,893 - train - INFO - Train: 154 [ 780/781 (100%)]  Loss:  3.733619 (3.4756)  Time: 0.418s,  306.45/s  (0.463s,  276.40/s)  LR: 1.000e-05  Data: 0.000 (0.008)
2024-04-07 14:27:58,895 - train - INFO - True
2024-04-07 14:27:58,897 - train - INFO - alphas:tensor([0.8489, 0.0052, 0.0125, 0.0229, 0.1105], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,898 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,898 - train - INFO - True
2024-04-07 14:27:58,899 - train - INFO - alphas:tensor([0.4712, 0.0011, 0.0039, 0.0208, 0.5030], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,900 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,900 - train - INFO - True
2024-04-07 14:27:58,902 - train - INFO - alphas:tensor([0.5286, 0.0028, 0.0179, 0.4507], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,903 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,903 - train - INFO - True
2024-04-07 14:27:58,905 - train - INFO - alphas:tensor([0.4446, 0.0030, 0.0104, 0.5421], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,905 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,906 - train - INFO - True
2024-04-07 14:27:58,907 - train - INFO - alphas:tensor([0.4532, 0.0014, 0.0142, 0.5312], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,908 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,908 - train - INFO - True
2024-04-07 14:27:58,909 - train - INFO - alphas:tensor([0.5646, 0.0030, 0.0107, 0.4217], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,911 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,911 - train - INFO - True
2024-04-07 14:27:58,912 - train - INFO - alphas:tensor([0.6404, 0.0010, 0.0018, 0.0106, 0.3461], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,914 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,914 - train - INFO - True
2024-04-07 14:27:58,915 - train - INFO - alphas:tensor([2.0268e-01, 4.2190e-04, 2.7977e-04, 1.1670e-02, 7.8495e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,916 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,917 - train - INFO - True
2024-04-07 14:27:58,918 - train - INFO - alphas:tensor([2.0651e-01, 2.1570e-04, 3.6344e-04, 7.2583e-03, 7.8565e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,919 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,919 - train - INFO - True
2024-04-07 14:27:58,920 - train - INFO - alphas:tensor([2.0857e-01, 1.0776e-04, 2.8255e-04, 9.4094e-03, 7.8163e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,921 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,921 - train - INFO - True
2024-04-07 14:27:58,923 - train - INFO - alphas:tensor([1.9714e-01, 3.1191e-04, 3.1003e-04, 1.2500e-02, 7.8973e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,924 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,924 - train - INFO - True
2024-04-07 14:27:58,925 - train - INFO - alphas:tensor([6.1806e-01, 2.1146e-04, 7.8097e-04, 8.6558e-03, 3.7229e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,927 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,927 - train - INFO - True
2024-04-07 14:27:58,928 - train - INFO - alphas:tensor([7.5924e-01, 3.1495e-04, 5.0386e-04, 4.3097e-03, 2.3563e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,933 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,933 - train - INFO - True
2024-04-07 14:27:58,934 - train - INFO - alphas:tensor([0.2619, 0.0014, 0.0015, 0.0345, 0.7007], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,937 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,937 - train - INFO - True
2024-04-07 14:27:58,938 - train - INFO - alphas:tensor([2.7030e-01, 4.1216e-04, 6.8070e-04, 2.6749e-02, 7.0186e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,941 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,941 - train - INFO - True
2024-04-07 14:27:58,942 - train - INFO - alphas:tensor([2.9420e-01, 2.7380e-04, 7.4331e-04, 2.3245e-02, 6.8154e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,945 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,945 - train - INFO - True
2024-04-07 14:27:58,946 - train - INFO - alphas:tensor([2.6420e-01, 5.6190e-04, 9.4420e-04, 2.1629e-02, 7.1266e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,948 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,949 - train - INFO - True
2024-04-07 14:27:58,950 - train - INFO - alphas:tensor([2.9545e-01, 3.2090e-04, 1.2913e-03, 2.4502e-02, 6.7844e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,952 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,952 - train - INFO - True
2024-04-07 14:27:58,953 - train - INFO - alphas:tensor([0.2573, 0.0013, 0.0021, 0.0270, 0.7123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,956 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,956 - train - INFO - True
2024-04-07 14:27:58,957 - train - INFO - alphas:tensor([6.6971e-01, 1.3131e-04, 4.4676e-04, 1.0651e-02, 3.1906e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,961 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,961 - train - INFO - True
2024-04-07 14:27:58,962 - train - INFO - alphas:tensor([5.9388e-01, 1.1448e-04, 2.0977e-04, 9.8984e-03, 3.9590e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,971 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,971 - train - INFO - True
2024-04-07 14:27:58,972 - train - INFO - alphas:tensor([4.5075e-01, 8.8836e-05, 7.1218e-04, 1.8688e-02, 5.2976e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,976 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,977 - train - INFO - True
2024-04-07 14:27:58,977 - train - INFO - alphas:tensor([4.6223e-01, 9.7786e-05, 2.2561e-04, 1.6182e-02, 5.2127e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,982 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,982 - train - INFO - True
2024-04-07 14:27:58,983 - train - INFO - alphas:tensor([4.7843e-01, 7.8885e-05, 2.3497e-04, 1.4704e-02, 5.0655e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,987 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,987 - train - INFO - True
2024-04-07 14:27:58,988 - train - INFO - alphas:tensor([4.3884e-01, 1.0184e-04, 4.7177e-04, 1.7261e-02, 5.4333e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:58,992 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:58,992 - train - INFO - True
2024-04-07 14:27:58,993 - train - INFO - alphas:tensor([5.9718e-01, 8.1850e-05, 3.7420e-04, 8.3362e-03, 3.9402e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:59,001 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:59,001 - train - INFO - True
2024-04-07 14:27:59,002 - train - INFO - alphas:tensor([7.9931e-01, 4.9480e-05, 2.3127e-04, 4.7012e-03, 1.9571e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:59,021 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:59,021 - train - INFO - True
2024-04-07 14:27:59,022 - train - INFO - alphas:tensor([4.1041e-01, 1.4940e-04, 4.8783e-04, 2.6964e-02, 5.6199e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:59,032 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:59,032 - train - INFO - True
2024-04-07 14:27:59,033 - train - INFO - alphas:tensor([4.1537e-01, 5.7456e-05, 3.1574e-04, 1.7826e-02, 5.6644e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:59,043 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:59,043 - train - INFO - True
2024-04-07 14:27:59,044 - train - INFO - alphas:tensor([4.4719e-01, 7.7774e-05, 2.2537e-04, 2.1086e-02, 5.3143e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:59,054 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:59,054 - train - INFO - True
2024-04-07 14:27:59,055 - train - INFO - alphas:tensor([4.0870e-01, 1.0452e-04, 3.9381e-04, 2.0481e-02, 5.7032e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:59,065 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:59,065 - train - INFO - True
2024-04-07 14:27:59,066 - train - INFO - alphas:tensor([7.5929e-01, 4.1075e-05, 1.0408e-04, 3.7590e-03, 2.3681e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:59,085 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:59,086 - train - INFO - True
2024-04-07 14:27:59,087 - train - INFO - alphas:tensor([0.6074, 0.0009, 0.0021, 0.0264, 0.3633], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:27:59,164 - train - INFO - tau:0.2170448966728076
2024-04-07 14:27:59,164 - train - INFO - avg block size:10.06060606060606
2024-04-07 14:27:59,165 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 14:27:59,165 - train - INFO - lasso_alpha:4.0172596640327134e-07
2024-04-07 14:27:59,372 - train - INFO - Test: [   0/78]  Time: 0.204 (0.204)  Loss:  0.9551 (0.9551)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 14:28:02,801 - train - INFO - Test: [  50/78]  Time: 0.074 (0.071)  Loss:  1.5176 (1.5400)  Acc@1: 67.1875 (66.1918)  Acc@5: 89.0625 (86.5196)
2024-04-07 14:28:04,453 - train - INFO - Test: [  78/78]  Time: 0.054 (0.067)  Loss:  1.8623 (1.5585)  Acc@1: 50.0000 (65.7600)  Acc@5: 87.5000 (86.1800)
2024-04-07 14:28:05,169 - train - INFO - Train: 155 [   0/781 (  0%)]  Loss:  3.762147 (3.7621)  Time: 0.636s,  201.34/s  (0.636s,  201.34/s)  LR: 1.000e-05  Data: 0.172 (0.172)
2024-04-07 14:28:26,770 - train - INFO - Train: 155 [  50/781 (  6%)]  Loss:  3.296903 (3.4780)  Time: 0.497s,  257.45/s  (0.436s,  293.59/s)  LR: 1.000e-05  Data: 0.006 (0.009)
2024-04-07 14:28:47,944 - train - INFO - Train: 155 [ 100/781 ( 13%)]  Loss:  3.672916 (3.4831)  Time: 0.397s,  322.15/s  (0.430s,  297.82/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:29:08,620 - train - INFO - Train: 155 [ 150/781 ( 19%)]  Loss:  3.402411 (3.4746)  Time: 0.512s,  249.94/s  (0.424s,  301.61/s)  LR: 1.000e-05  Data: 0.009 (0.007)
2024-04-07 14:29:29,425 - train - INFO - Train: 155 [ 200/781 ( 26%)]  Loss:  3.763059 (3.4652)  Time: 0.354s,  361.75/s  (0.422s,  303.09/s)  LR: 1.000e-05  Data: 0.005 (0.007)
2024-04-07 14:29:51,018 - train - INFO - Train: 155 [ 250/781 ( 32%)]  Loss:  3.497112 (3.4637)  Time: 0.431s,  296.87/s  (0.424s,  301.73/s)  LR: 1.000e-05  Data: 0.008 (0.007)
2024-04-07 14:30:10,921 - train - INFO - Train: 155 [ 300/781 ( 38%)]  Loss:  2.992579 (3.4565)  Time: 0.489s,  261.80/s  (0.420s,  304.86/s)  LR: 1.000e-05  Data: 0.008 (0.007)
2024-04-07 14:30:35,402 - train - INFO - Train: 155 [ 350/781 ( 45%)]  Loss:  3.775916 (3.4567)  Time: 0.523s,  244.65/s  (0.430s,  297.82/s)  LR: 1.000e-05  Data: 0.009 (0.007)
2024-04-07 14:30:59,169 - train - INFO - Train: 155 [ 400/781 ( 51%)]  Loss:  3.349391 (3.4530)  Time: 0.476s,  269.05/s  (0.435s,  293.93/s)  LR: 1.000e-05  Data: 0.008 (0.007)
2024-04-07 14:31:22,821 - train - INFO - Train: 155 [ 450/781 ( 58%)]  Loss:  3.716219 (3.4519)  Time: 0.451s,  283.93/s  (0.440s,  291.15/s)  LR: 1.000e-05  Data: 0.007 (0.007)
2024-04-07 14:31:45,363 - train - INFO - Train: 155 [ 500/781 ( 64%)]  Loss:  3.026762 (3.4459)  Time: 0.479s,  267.05/s  (0.441s,  290.42/s)  LR: 1.000e-05  Data: 0.008 (0.007)
2024-04-07 14:32:07,909 - train - INFO - Train: 155 [ 550/781 ( 71%)]  Loss:  3.673182 (3.4448)  Time: 0.403s,  317.72/s  (0.442s,  289.81/s)  LR: 1.000e-05  Data: 0.006 (0.007)
2024-04-07 14:32:30,338 - train - INFO - Train: 155 [ 600/781 ( 77%)]  Loss:  3.196897 (3.4456)  Time: 0.468s,  273.58/s  (0.442s,  289.44/s)  LR: 1.000e-05  Data: 0.005 (0.007)
2024-04-07 14:32:53,964 - train - INFO - Train: 155 [ 650/781 ( 83%)]  Loss:  3.630882 (3.4457)  Time: 0.504s,  254.02/s  (0.445s,  287.92/s)  LR: 1.000e-05  Data: 0.009 (0.007)
2024-04-07 14:33:17,641 - train - INFO - Train: 155 [ 700/781 ( 90%)]  Loss:  3.348687 (3.4420)  Time: 0.459s,  278.69/s  (0.447s,  286.59/s)  LR: 1.000e-05  Data: 0.008 (0.007)
2024-04-07 14:33:40,748 - train - INFO - Train: 155 [ 750/781 ( 96%)]  Loss:  3.397092 (3.4417)  Time: 0.482s,  265.47/s  (0.448s,  285.93/s)  LR: 1.000e-05  Data: 0.008 (0.007)
2024-04-07 14:33:54,547 - train - INFO - Train: 155 [ 780/781 (100%)]  Loss:  3.302876 (3.4392)  Time: 0.447s,  286.36/s  (0.448s,  285.63/s)  LR: 1.000e-05  Data: 0.000 (0.007)
2024-04-07 14:33:54,548 - train - INFO - True
2024-04-07 14:33:54,549 - train - INFO - alphas:tensor([0.8519, 0.0050, 0.0120, 0.0222, 0.1089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,550 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,550 - train - INFO - True
2024-04-07 14:33:54,551 - train - INFO - alphas:tensor([0.4717, 0.0010, 0.0037, 0.0202, 0.5034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,552 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,552 - train - INFO - True
2024-04-07 14:33:54,553 - train - INFO - alphas:tensor([0.5292, 0.0027, 0.0174, 0.4507], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,554 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,554 - train - INFO - True
2024-04-07 14:33:54,555 - train - INFO - alphas:tensor([0.4446, 0.0028, 0.0100, 0.5426], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,555 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,555 - train - INFO - True
2024-04-07 14:33:54,556 - train - INFO - alphas:tensor([0.4530, 0.0013, 0.0137, 0.5320], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,557 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,557 - train - INFO - True
2024-04-07 14:33:54,558 - train - INFO - alphas:tensor([0.5650, 0.0028, 0.0103, 0.4218], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,559 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,559 - train - INFO - True
2024-04-07 14:33:54,560 - train - INFO - alphas:tensor([0.6421, 0.0009, 0.0017, 0.0102, 0.3450], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,561 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,561 - train - INFO - True
2024-04-07 14:33:54,562 - train - INFO - alphas:tensor([2.0195e-01, 3.9409e-04, 2.6010e-04, 1.1283e-02, 7.8612e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,563 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,563 - train - INFO - True
2024-04-07 14:33:54,564 - train - INFO - alphas:tensor([2.0556e-01, 1.9995e-04, 3.3842e-04, 6.9709e-03, 7.8693e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,565 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,565 - train - INFO - True
2024-04-07 14:33:54,566 - train - INFO - alphas:tensor([2.0759e-01, 9.9276e-05, 2.6258e-04, 9.0714e-03, 7.8298e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,566 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,567 - train - INFO - True
2024-04-07 14:33:54,568 - train - INFO - alphas:tensor([1.9563e-01, 2.8962e-04, 2.8808e-04, 1.2066e-02, 7.9173e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,568 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,568 - train - INFO - True
2024-04-07 14:33:54,569 - train - INFO - alphas:tensor([6.1868e-01, 1.9552e-04, 7.3225e-04, 8.3193e-03, 3.7207e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,570 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,571 - train - INFO - True
2024-04-07 14:33:54,571 - train - INFO - alphas:tensor([7.6103e-01, 2.9231e-04, 4.7010e-04, 4.1086e-03, 2.3410e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,575 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,575 - train - INFO - True
2024-04-07 14:33:54,576 - train - INFO - alphas:tensor([0.2622, 0.0014, 0.0014, 0.0337, 0.7013], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,578 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,578 - train - INFO - True
2024-04-07 14:33:54,579 - train - INFO - alphas:tensor([2.6957e-01, 3.8442e-04, 6.3892e-04, 2.6096e-02, 7.0331e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,581 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,581 - train - INFO - True
2024-04-07 14:33:54,582 - train - INFO - alphas:tensor([2.9250e-01, 2.5405e-04, 6.9807e-04, 2.2637e-02, 6.8391e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,584 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,584 - train - INFO - True
2024-04-07 14:33:54,585 - train - INFO - alphas:tensor([2.6383e-01, 5.2521e-04, 8.8885e-04, 2.1049e-02, 7.1371e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,587 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,587 - train - INFO - True
2024-04-07 14:33:54,588 - train - INFO - alphas:tensor([2.9481e-01, 2.9824e-04, 1.2192e-03, 2.3907e-02, 6.7976e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,590 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,590 - train - INFO - True
2024-04-07 14:33:54,591 - train - INFO - alphas:tensor([0.2567, 0.0012, 0.0020, 0.0264, 0.7137], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,592 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,593 - train - INFO - True
2024-04-07 14:33:54,593 - train - INFO - alphas:tensor([6.7108e-01, 1.2089e-04, 4.1694e-04, 1.0270e-02, 3.1811e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,597 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,597 - train - INFO - True
2024-04-07 14:33:54,598 - train - INFO - alphas:tensor([5.9467e-01, 1.0516e-04, 1.9397e-04, 9.5318e-03, 3.9550e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,605 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,605 - train - INFO - True
2024-04-07 14:33:54,606 - train - INFO - alphas:tensor([4.5113e-01, 8.1538e-05, 6.6769e-04, 1.8153e-02, 5.2997e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,610 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,610 - train - INFO - True
2024-04-07 14:33:54,611 - train - INFO - alphas:tensor([4.6284e-01, 8.9814e-05, 2.0904e-04, 1.5668e-02, 5.2119e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,615 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,615 - train - INFO - True
2024-04-07 14:33:54,616 - train - INFO - alphas:tensor([4.7993e-01, 7.2231e-05, 2.1823e-04, 1.4258e-02, 5.0552e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,620 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,620 - train - INFO - True
2024-04-07 14:33:54,621 - train - INFO - alphas:tensor([4.3944e-01, 9.3663e-05, 4.4068e-04, 1.6750e-02, 5.4328e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,624 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,625 - train - INFO - True
2024-04-07 14:33:54,625 - train - INFO - alphas:tensor([5.9780e-01, 7.5019e-05, 3.4817e-04, 8.0386e-03, 3.9373e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,633 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,633 - train - INFO - True
2024-04-07 14:33:54,634 - train - INFO - alphas:tensor([8.0033e-01, 4.5098e-05, 2.1437e-04, 4.5043e-03, 1.9490e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,654 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,655 - train - INFO - True
2024-04-07 14:33:54,656 - train - INFO - alphas:tensor([4.1076e-01, 1.3802e-04, 4.5527e-04, 2.6318e-02, 5.6233e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,666 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,666 - train - INFO - True
2024-04-07 14:33:54,667 - train - INFO - alphas:tensor([4.1538e-01, 5.2498e-05, 2.9368e-04, 1.7352e-02, 5.6693e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,677 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,677 - train - INFO - True
2024-04-07 14:33:54,678 - train - INFO - alphas:tensor([4.4799e-01, 7.1304e-05, 2.0871e-04, 2.0536e-02, 5.3119e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,688 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,688 - train - INFO - True
2024-04-07 14:33:54,689 - train - INFO - alphas:tensor([4.0905e-01, 9.6200e-05, 3.6734e-04, 1.9897e-02, 5.7059e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,699 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,699 - train - INFO - True
2024-04-07 14:33:54,700 - train - INFO - alphas:tensor([7.5926e-01, 3.7484e-05, 9.5956e-05, 3.6050e-03, 2.3700e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,719 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,719 - train - INFO - True
2024-04-07 14:33:54,720 - train - INFO - alphas:tensor([0.6077, 0.0009, 0.0020, 0.0258, 0.3637], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:33:54,798 - train - INFO - tau:0.21487444770607952
2024-04-07 14:33:54,798 - train - INFO - avg block size:10.06060606060606
2024-04-07 14:33:54,798 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 14:33:55,015 - train - INFO - Test: [   0/78]  Time: 0.213 (0.213)  Loss:  0.9561 (0.9561)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.9688 (92.9688)
2024-04-07 14:33:57,837 - train - INFO - Test: [  50/78]  Time: 0.051 (0.060)  Loss:  1.5518 (1.5399)  Acc@1: 67.9688 (66.7126)  Acc@5: 89.8438 (86.5196)
2024-04-07 14:33:59,437 - train - INFO - Test: [  78/78]  Time: 0.048 (0.059)  Loss:  1.8359 (1.5583)  Acc@1: 56.2500 (66.1200)  Acc@5: 87.5000 (86.2500)
2024-04-07 14:34:00,197 - train - INFO - Train: 156 [   0/781 (  0%)]  Loss:  3.479124 (3.4791)  Time: 0.677s,  189.07/s  (0.677s,  189.07/s)  LR: 1.000e-05  Data: 0.158 (0.158)
2024-04-07 14:34:23,802 - train - INFO - Train: 156 [  50/781 (  6%)]  Loss:  3.194497 (3.4454)  Time: 0.398s,  321.36/s  (0.476s,  268.85/s)  LR: 1.000e-05  Data: 0.011 (0.011)
2024-04-07 14:34:47,055 - train - INFO - Train: 156 [ 100/781 ( 13%)]  Loss:  3.256351 (3.4406)  Time: 0.498s,  256.87/s  (0.471s,  271.98/s)  LR: 1.000e-05  Data: 0.007 (0.009)
2024-04-07 14:35:10,122 - train - INFO - Train: 156 [ 150/781 ( 19%)]  Loss:  3.232435 (3.4371)  Time: 0.497s,  257.42/s  (0.468s,  273.77/s)  LR: 1.000e-05  Data: 0.009 (0.009)
2024-04-07 14:35:33,264 - train - INFO - Train: 156 [ 200/781 ( 26%)]  Loss:  3.367139 (3.4354)  Time: 0.503s,  254.65/s  (0.466s,  274.46/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:35:56,925 - train - INFO - Train: 156 [ 250/781 ( 32%)]  Loss:  3.793527 (3.4355)  Time: 0.405s,  316.05/s  (0.468s,  273.67/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:36:20,415 - train - INFO - Train: 156 [ 300/781 ( 38%)]  Loss:  3.112225 (3.4316)  Time: 0.453s,  282.34/s  (0.468s,  273.47/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:36:42,998 - train - INFO - Train: 156 [ 350/781 ( 45%)]  Loss:  3.391945 (3.4341)  Time: 0.488s,  262.05/s  (0.466s,  274.84/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:37:05,984 - train - INFO - Train: 156 [ 400/781 ( 51%)]  Loss:  3.307022 (3.4326)  Time: 0.410s,  311.88/s  (0.465s,  275.29/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:37:29,012 - train - INFO - Train: 156 [ 450/781 ( 58%)]  Loss:  3.172409 (3.4296)  Time: 0.495s,  258.40/s  (0.464s,  275.58/s)  LR: 1.000e-05  Data: 0.010 (0.008)
2024-04-07 14:37:52,727 - train - INFO - Train: 156 [ 500/781 ( 64%)]  Loss:  3.077005 (3.4342)  Time: 0.464s,  276.01/s  (0.465s,  275.00/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:38:16,874 - train - INFO - Train: 156 [ 550/781 ( 71%)]  Loss:  3.142522 (3.4376)  Time: 0.379s,  337.56/s  (0.467s,  274.07/s)  LR: 1.000e-05  Data: 0.005 (0.008)
2024-04-07 14:38:40,458 - train - INFO - Train: 156 [ 600/781 ( 77%)]  Loss:  3.336588 (3.4372)  Time: 0.500s,  256.05/s  (0.467s,  273.84/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:39:04,298 - train - INFO - Train: 156 [ 650/781 ( 83%)]  Loss:  3.583272 (3.4437)  Time: 0.501s,  255.34/s  (0.468s,  273.42/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:39:27,499 - train - INFO - Train: 156 [ 700/781 ( 90%)]  Loss:  3.496093 (3.4416)  Time: 0.474s,  270.12/s  (0.468s,  273.60/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:39:51,379 - train - INFO - Train: 156 [ 750/781 ( 96%)]  Loss:  3.286296 (3.4452)  Time: 0.502s,  255.14/s  (0.468s,  273.22/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:40:04,613 - train - INFO - Train: 156 [ 780/781 (100%)]  Loss:  3.373832 (3.4448)  Time: 0.445s,  287.82/s  (0.467s,  273.83/s)  LR: 1.000e-05  Data: 0.000 (0.008)
2024-04-07 14:40:04,613 - train - INFO - True
2024-04-07 14:40:04,615 - train - INFO - alphas:tensor([0.8549, 0.0048, 0.0116, 0.0215, 0.1072], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,615 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,616 - train - INFO - True
2024-04-07 14:40:04,617 - train - INFO - alphas:tensor([0.4718, 0.0009, 0.0035, 0.0196, 0.5041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,617 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,617 - train - INFO - True
2024-04-07 14:40:04,618 - train - INFO - alphas:tensor([0.5299, 0.0025, 0.0169, 0.4507], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,619 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,620 - train - INFO - True
2024-04-07 14:40:04,621 - train - INFO - alphas:tensor([0.4443, 0.0027, 0.0097, 0.5433], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,622 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,631 - train - INFO - True
2024-04-07 14:40:04,632 - train - INFO - alphas:tensor([0.4537, 0.0012, 0.0133, 0.5318], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,632 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,632 - train - INFO - True
2024-04-07 14:40:04,633 - train - INFO - alphas:tensor([0.5660, 0.0027, 0.0099, 0.4213], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,634 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,634 - train - INFO - True
2024-04-07 14:40:04,635 - train - INFO - alphas:tensor([0.6434, 0.0009, 0.0016, 0.0099, 0.3442], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,636 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,636 - train - INFO - True
2024-04-07 14:40:04,637 - train - INFO - alphas:tensor([2.0023e-01, 3.6717e-04, 2.4134e-04, 1.0890e-02, 7.8827e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,638 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,638 - train - INFO - True
2024-04-07 14:40:04,639 - train - INFO - alphas:tensor([2.0423e-01, 1.8495e-04, 3.1528e-04, 6.6979e-03, 7.8857e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,640 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,640 - train - INFO - True
2024-04-07 14:40:04,641 - train - INFO - alphas:tensor([2.0634e-01, 9.1144e-05, 2.4384e-04, 8.7398e-03, 7.8459e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,641 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,641 - train - INFO - True
2024-04-07 14:40:04,642 - train - INFO - alphas:tensor([1.9420e-01, 2.6896e-04, 2.6743e-04, 1.1643e-02, 7.9362e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,643 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,643 - train - INFO - True
2024-04-07 14:40:04,644 - train - INFO - alphas:tensor([6.1925e-01, 1.8092e-04, 6.8649e-04, 8.0048e-03, 3.7188e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,645 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,645 - train - INFO - True
2024-04-07 14:40:04,646 - train - INFO - alphas:tensor([7.6253e-01, 2.7150e-04, 4.3899e-04, 3.9195e-03, 2.3284e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,649 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,650 - train - INFO - True
2024-04-07 14:40:04,650 - train - INFO - alphas:tensor([0.2611, 0.0013, 0.0014, 0.0330, 0.7032], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,652 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,652 - train - INFO - True
2024-04-07 14:40:04,653 - train - INFO - alphas:tensor([2.6946e-01, 3.5848e-04, 5.9968e-04, 2.5445e-02, 7.0414e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,655 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,655 - train - INFO - True
2024-04-07 14:40:04,656 - train - INFO - alphas:tensor([2.9209e-01, 2.3573e-04, 6.5531e-04, 2.2047e-02, 6.8497e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,658 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,658 - train - INFO - True
2024-04-07 14:40:04,659 - train - INFO - alphas:tensor([2.6363e-01, 4.9196e-04, 8.3642e-04, 2.0468e-02, 7.1457e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,661 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,661 - train - INFO - True
2024-04-07 14:40:04,662 - train - INFO - alphas:tensor([2.9508e-01, 2.7770e-04, 1.1519e-03, 2.3297e-02, 6.8020e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,664 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,664 - train - INFO - True
2024-04-07 14:40:04,665 - train - INFO - alphas:tensor([0.2562, 0.0012, 0.0019, 0.0257, 0.7150], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,667 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,667 - train - INFO - True
2024-04-07 14:40:04,668 - train - INFO - alphas:tensor([6.7187e-01, 1.1132e-04, 3.8923e-04, 9.9200e-03, 3.1771e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,671 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,671 - train - INFO - True
2024-04-07 14:40:04,672 - train - INFO - alphas:tensor([5.9501e-01, 9.6594e-05, 1.7967e-04, 9.1859e-03, 3.9553e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,680 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,680 - train - INFO - True
2024-04-07 14:40:04,681 - train - INFO - alphas:tensor([4.5164e-01, 7.4722e-05, 6.2603e-04, 1.7613e-02, 5.3005e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,685 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,685 - train - INFO - True
2024-04-07 14:40:04,685 - train - INFO - alphas:tensor([4.6303e-01, 8.2444e-05, 1.9375e-04, 1.5207e-02, 5.2149e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,689 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,690 - train - INFO - True
2024-04-07 14:40:04,690 - train - INFO - alphas:tensor([4.8034e-01, 6.6205e-05, 2.0214e-04, 1.3796e-02, 5.0559e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,694 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,694 - train - INFO - True
2024-04-07 14:40:04,695 - train - INFO - alphas:tensor([4.3909e-01, 8.5920e-05, 4.1118e-04, 1.6249e-02, 5.4416e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,699 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,699 - train - INFO - True
2024-04-07 14:40:04,700 - train - INFO - alphas:tensor([5.9817e-01, 6.8813e-05, 3.2411e-04, 7.7374e-03, 3.9370e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,707 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,708 - train - INFO - True
2024-04-07 14:40:04,708 - train - INFO - alphas:tensor([8.0120e-01, 4.1181e-05, 1.9913e-04, 4.3232e-03, 1.9424e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,728 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,728 - train - INFO - True
2024-04-07 14:40:04,729 - train - INFO - alphas:tensor([4.1134e-01, 1.2726e-04, 4.2510e-04, 2.5727e-02, 5.6238e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,739 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,739 - train - INFO - True
2024-04-07 14:40:04,740 - train - INFO - alphas:tensor([4.1569e-01, 4.7936e-05, 2.7353e-04, 1.6869e-02, 5.6712e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,750 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,750 - train - INFO - True
2024-04-07 14:40:04,751 - train - INFO - alphas:tensor([4.4898e-01, 6.5288e-05, 1.9324e-04, 2.0012e-02, 5.3075e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,761 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,761 - train - INFO - True
2024-04-07 14:40:04,762 - train - INFO - alphas:tensor([4.0908e-01, 8.8430e-05, 3.4239e-04, 1.9381e-02, 5.7110e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,772 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,772 - train - INFO - True
2024-04-07 14:40:04,773 - train - INFO - alphas:tensor([7.5998e-01, 3.4155e-05, 8.8337e-05, 3.4508e-03, 2.3645e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,793 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,793 - train - INFO - True
2024-04-07 14:40:04,794 - train - INFO - alphas:tensor([0.6087, 0.0008, 0.0019, 0.0252, 0.3634], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:40:04,872 - train - INFO - tau:0.21272570322901874
2024-04-07 14:40:04,872 - train - INFO - avg block size:10.06060606060606
2024-04-07 14:40:04,872 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 14:40:04,872 - train - INFO - lasso_alpha:3.6520542400297393e-07
2024-04-07 14:40:05,051 - train - INFO - Test: [   0/78]  Time: 0.175 (0.175)  Loss:  0.9609 (0.9609)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 14:40:08,224 - train - INFO - Test: [  50/78]  Time: 0.060 (0.066)  Loss:  1.5596 (1.5435)  Acc@1: 65.6250 (66.3756)  Acc@5: 88.2812 (86.5196)
2024-04-07 14:40:09,887 - train - INFO - Test: [  78/78]  Time: 0.073 (0.063)  Loss:  1.8164 (1.5616)  Acc@1: 50.0000 (66.0000)  Acc@5: 93.7500 (86.2100)
2024-04-07 14:40:10,599 - train - INFO - Train: 157 [   0/781 (  0%)]  Loss:  3.477112 (3.4771)  Time: 0.608s,  210.56/s  (0.608s,  210.56/s)  LR: 1.000e-05  Data: 0.176 (0.176)
2024-04-07 14:40:32,220 - train - INFO - Train: 157 [  50/781 (  6%)]  Loss:  3.650727 (3.4683)  Time: 0.496s,  258.21/s  (0.436s,  293.68/s)  LR: 1.000e-05  Data: 0.006 (0.010)
2024-04-07 14:40:55,245 - train - INFO - Train: 157 [ 100/781 ( 13%)]  Loss:  3.421574 (3.4590)  Time: 0.493s,  259.85/s  (0.448s,  285.70/s)  LR: 1.000e-05  Data: 0.007 (0.009)
2024-04-07 14:41:18,767 - train - INFO - Train: 157 [ 150/781 ( 19%)]  Loss:  3.463140 (3.4484)  Time: 0.499s,  256.41/s  (0.455s,  281.04/s)  LR: 1.000e-05  Data: 0.009 (0.009)
2024-04-07 14:41:41,382 - train - INFO - Train: 157 [ 200/781 ( 26%)]  Loss:  3.272499 (3.4423)  Time: 0.465s,  275.28/s  (0.455s,  281.53/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:42:03,535 - train - INFO - Train: 157 [ 250/781 ( 32%)]  Loss:  3.044753 (3.4409)  Time: 0.392s,  326.92/s  (0.452s,  282.98/s)  LR: 1.000e-05  Data: 0.005 (0.008)
2024-04-07 14:42:27,101 - train - INFO - Train: 157 [ 300/781 ( 38%)]  Loss:  3.333458 (3.4538)  Time: 0.473s,  270.56/s  (0.455s,  281.02/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:42:50,182 - train - INFO - Train: 157 [ 350/781 ( 45%)]  Loss:  3.297771 (3.4500)  Time: 0.451s,  284.05/s  (0.456s,  280.48/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:43:13,202 - train - INFO - Train: 157 [ 400/781 ( 51%)]  Loss:  3.210640 (3.4485)  Time: 0.425s,  301.01/s  (0.457s,  280.18/s)  LR: 1.000e-05  Data: 0.010 (0.008)
2024-04-07 14:43:36,835 - train - INFO - Train: 157 [ 450/781 ( 58%)]  Loss:  3.702039 (3.4424)  Time: 0.497s,  257.31/s  (0.459s,  279.11/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:44:00,570 - train - INFO - Train: 157 [ 500/781 ( 64%)]  Loss:  3.859843 (3.4400)  Time: 0.490s,  261.16/s  (0.460s,  278.14/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:44:23,908 - train - INFO - Train: 157 [ 550/781 ( 71%)]  Loss:  3.575526 (3.4414)  Time: 0.486s,  263.64/s  (0.461s,  277.78/s)  LR: 1.000e-05  Data: 0.011 (0.008)
2024-04-07 14:44:46,437 - train - INFO - Train: 157 [ 600/781 ( 77%)]  Loss:  3.285646 (3.4444)  Time: 0.466s,  274.81/s  (0.460s,  278.29/s)  LR: 1.000e-05  Data: 0.005 (0.008)
2024-04-07 14:45:09,927 - train - INFO - Train: 157 [ 650/781 ( 83%)]  Loss:  3.635593 (3.4508)  Time: 0.496s,  257.84/s  (0.461s,  277.84/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:45:33,321 - train - INFO - Train: 157 [ 700/781 ( 90%)]  Loss:  3.392244 (3.4492)  Time: 0.408s,  313.49/s  (0.461s,  277.54/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:45:55,492 - train - INFO - Train: 157 [ 750/781 ( 96%)]  Loss:  3.840235 (3.4494)  Time: 0.344s,  372.46/s  (0.460s,  278.25/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:46:09,541 - train - INFO - Train: 157 [ 780/781 (100%)]  Loss:  3.785957 (3.4490)  Time: 0.457s,  280.13/s  (0.460s,  278.06/s)  LR: 1.000e-05  Data: 0.000 (0.008)
2024-04-07 14:46:09,542 - train - INFO - True
2024-04-07 14:46:09,545 - train - INFO - alphas:tensor([0.8578, 0.0046, 0.0112, 0.0209, 0.1056], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,546 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,546 - train - INFO - True
2024-04-07 14:46:09,548 - train - INFO - alphas:tensor([0.4711, 0.0009, 0.0033, 0.0191, 0.5056], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,548 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,548 - train - INFO - True
2024-04-07 14:46:09,550 - train - INFO - alphas:tensor([0.5299, 0.0024, 0.0164, 0.4513], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,552 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,552 - train - INFO - True
2024-04-07 14:46:09,553 - train - INFO - alphas:tensor([0.4446, 0.0025, 0.0093, 0.5435], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,554 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,555 - train - INFO - True
2024-04-07 14:46:09,556 - train - INFO - alphas:tensor([0.4535, 0.0011, 0.0128, 0.5325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,557 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,557 - train - INFO - True
2024-04-07 14:46:09,559 - train - INFO - alphas:tensor([0.5666, 0.0026, 0.0096, 0.4212], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,560 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,561 - train - INFO - True
2024-04-07 14:46:09,562 - train - INFO - alphas:tensor([0.6446, 0.0008, 0.0016, 0.0095, 0.3435], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,564 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,564 - train - INFO - True
2024-04-07 14:46:09,566 - train - INFO - alphas:tensor([1.9949e-01, 3.4270e-04, 2.2404e-04, 1.0516e-02, 7.8943e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,567 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,567 - train - INFO - True
2024-04-07 14:46:09,569 - train - INFO - alphas:tensor([2.0295e-01, 1.7107e-04, 2.9321e-04, 6.4221e-03, 7.9016e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,570 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,570 - train - INFO - True
2024-04-07 14:46:09,571 - train - INFO - alphas:tensor([2.0503e-01, 8.3721e-05, 2.2656e-04, 8.4230e-03, 7.8623e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,572 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,573 - train - INFO - True
2024-04-07 14:46:09,574 - train - INFO - alphas:tensor([1.9334e-01, 2.4986e-04, 2.4871e-04, 1.1283e-02, 7.9488e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,575 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,575 - train - INFO - True
2024-04-07 14:46:09,577 - train - INFO - alphas:tensor([6.2055e-01, 1.6713e-04, 6.4357e-04, 7.6996e-03, 3.7094e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,578 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,579 - train - INFO - True
2024-04-07 14:46:09,580 - train - INFO - alphas:tensor([7.6416e-01, 2.5169e-04, 4.0948e-04, 3.7363e-03, 2.3144e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,585 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,586 - train - INFO - True
2024-04-07 14:46:09,587 - train - INFO - alphas:tensor([0.2605, 0.0012, 0.0013, 0.0324, 0.7046], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,590 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,590 - train - INFO - True
2024-04-07 14:46:09,591 - train - INFO - alphas:tensor([2.6893e-01, 3.3438e-04, 5.6188e-04, 2.4781e-02, 7.0540e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,594 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,594 - train - INFO - True
2024-04-07 14:46:09,595 - train - INFO - alphas:tensor([2.9199e-01, 2.1884e-04, 6.1456e-04, 2.1467e-02, 6.8571e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,598 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,598 - train - INFO - True
2024-04-07 14:46:09,599 - train - INFO - alphas:tensor([2.6306e-01, 4.6007e-04, 7.8538e-04, 1.9894e-02, 7.1580e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,602 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,602 - train - INFO - True
2024-04-07 14:46:09,603 - train - INFO - alphas:tensor([2.9449e-01, 2.5802e-04, 1.0876e-03, 2.2722e-02, 6.8144e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,606 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,606 - train - INFO - True
2024-04-07 14:46:09,607 - train - INFO - alphas:tensor([0.2552, 0.0011, 0.0018, 0.0250, 0.7169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,610 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,610 - train - INFO - True
2024-04-07 14:46:09,611 - train - INFO - alphas:tensor([6.7257e-01, 1.0264e-04, 3.6257e-04, 9.5764e-03, 3.1739e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,615 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,616 - train - INFO - True
2024-04-07 14:46:09,617 - train - INFO - alphas:tensor([5.9541e-01, 8.8672e-05, 1.6588e-04, 8.8426e-03, 3.9549e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,626 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,626 - train - INFO - True
2024-04-07 14:46:09,627 - train - INFO - alphas:tensor([4.5216e-01, 6.8421e-05, 5.8613e-04, 1.7090e-02, 5.3010e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,632 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,632 - train - INFO - True
2024-04-07 14:46:09,633 - train - INFO - alphas:tensor([4.6350e-01, 7.5672e-05, 1.7944e-04, 1.4744e-02, 5.2150e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,637 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,638 - train - INFO - True
2024-04-07 14:46:09,638 - train - INFO - alphas:tensor([4.8107e-01, 6.0586e-05, 1.8694e-04, 1.3342e-02, 5.0534e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,643 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,643 - train - INFO - True
2024-04-07 14:46:09,644 - train - INFO - alphas:tensor([4.3932e-01, 7.8890e-05, 3.8362e-04, 1.5757e-02, 5.4446e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,648 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,648 - train - INFO - True
2024-04-07 14:46:09,649 - train - INFO - alphas:tensor([5.9843e-01, 6.3030e-05, 3.0203e-04, 7.4441e-03, 3.9376e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,658 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,659 - train - INFO - True
2024-04-07 14:46:09,659 - train - INFO - alphas:tensor([8.0249e-01, 3.7491e-05, 1.8442e-04, 4.1301e-03, 1.9316e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,679 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,679 - train - INFO - True
2024-04-07 14:46:09,680 - train - INFO - alphas:tensor([4.1116e-01, 1.1724e-04, 3.9730e-04, 2.5154e-02, 5.6317e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,690 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,690 - train - INFO - True
2024-04-07 14:46:09,691 - train - INFO - alphas:tensor([4.1598e-01, 4.3745e-05, 2.5409e-04, 1.6378e-02, 5.6735e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,701 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,701 - train - INFO - True
2024-04-07 14:46:09,702 - train - INFO - alphas:tensor([4.4915e-01, 5.9708e-05, 1.7914e-04, 1.9484e-02, 5.3113e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,712 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,712 - train - INFO - True
2024-04-07 14:46:09,713 - train - INFO - alphas:tensor([4.0955e-01, 8.1112e-05, 3.1860e-04, 1.8875e-02, 5.7118e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,723 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,723 - train - INFO - True
2024-04-07 14:46:09,724 - train - INFO - alphas:tensor([7.6037e-01, 3.1073e-05, 8.1220e-05, 3.3000e-03, 2.3622e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,744 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,744 - train - INFO - True
2024-04-07 14:46:09,745 - train - INFO - alphas:tensor([0.6092, 0.0008, 0.0018, 0.0246, 0.3636], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:46:09,822 - train - INFO - tau:0.21059844619672854
2024-04-07 14:46:09,822 - train - INFO - avg block size:10.06060606060606
2024-04-07 14:46:09,823 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 14:46:10,027 - train - INFO - Test: [   0/78]  Time: 0.200 (0.200)  Loss:  0.9429 (0.9429)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 14:46:12,996 - train - INFO - Test: [  50/78]  Time: 0.052 (0.062)  Loss:  1.5439 (1.5419)  Acc@1: 68.7500 (66.2837)  Acc@5: 88.2812 (86.5196)
2024-04-07 14:46:14,823 - train - INFO - Test: [  78/78]  Time: 0.046 (0.063)  Loss:  1.7930 (1.5598)  Acc@1: 56.2500 (65.9700)  Acc@5: 93.7500 (86.1900)
2024-04-07 14:46:15,537 - train - INFO - Train: 158 [   0/781 (  0%)]  Loss:  3.552681 (3.5527)  Time: 0.634s,  201.98/s  (0.634s,  201.98/s)  LR: 1.000e-05  Data: 0.161 (0.161)
2024-04-07 14:46:38,743 - train - INFO - Train: 158 [  50/781 (  6%)]  Loss:  3.576352 (3.4748)  Time: 0.495s,  258.61/s  (0.467s,  273.85/s)  LR: 1.000e-05  Data: 0.009 (0.011)
2024-04-07 14:47:02,104 - train - INFO - Train: 158 [ 100/781 ( 13%)]  Loss:  3.496913 (3.4553)  Time: 0.433s,  295.55/s  (0.467s,  273.91/s)  LR: 1.000e-05  Data: 0.006 (0.009)
2024-04-07 14:47:24,837 - train - INFO - Train: 158 [ 150/781 ( 19%)]  Loss:  3.619304 (3.4608)  Time: 0.491s,  260.71/s  (0.463s,  276.39/s)  LR: 1.000e-05  Data: 0.008 (0.009)
2024-04-07 14:47:48,385 - train - INFO - Train: 158 [ 200/781 ( 26%)]  Loss:  3.439624 (3.4627)  Time: 0.432s,  296.20/s  (0.465s,  275.24/s)  LR: 1.000e-05  Data: 0.005 (0.008)
2024-04-07 14:48:11,203 - train - INFO - Train: 158 [ 250/781 ( 32%)]  Loss:  3.366473 (3.4602)  Time: 0.504s,  254.19/s  (0.463s,  276.27/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:48:32,750 - train - INFO - Train: 158 [ 300/781 ( 38%)]  Loss:  3.456439 (3.4595)  Time: 0.495s,  258.36/s  (0.458s,  279.52/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:48:56,439 - train - INFO - Train: 158 [ 350/781 ( 45%)]  Loss:  3.261498 (3.4640)  Time: 0.491s,  260.85/s  (0.460s,  278.15/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:49:19,583 - train - INFO - Train: 158 [ 400/781 ( 51%)]  Loss:  3.443347 (3.4573)  Time: 0.520s,  245.99/s  (0.461s,  277.95/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:49:42,775 - train - INFO - Train: 158 [ 450/781 ( 58%)]  Loss:  3.617442 (3.4611)  Time: 0.495s,  258.34/s  (0.461s,  277.73/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:50:06,768 - train - INFO - Train: 158 [ 500/781 ( 64%)]  Loss:  3.508530 (3.4641)  Time: 0.493s,  259.55/s  (0.463s,  276.59/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:50:28,988 - train - INFO - Train: 158 [ 550/781 ( 71%)]  Loss:  3.191271 (3.4676)  Time: 0.527s,  242.85/s  (0.461s,  277.59/s)  LR: 1.000e-05  Data: 0.005 (0.008)
2024-04-07 14:50:52,121 - train - INFO - Train: 158 [ 600/781 ( 77%)]  Loss:  3.632692 (3.4648)  Time: 0.468s,  273.67/s  (0.461s,  277.52/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:51:15,193 - train - INFO - Train: 158 [ 650/781 ( 83%)]  Loss:  3.228204 (3.4648)  Time: 0.459s,  278.78/s  (0.461s,  277.51/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:51:38,175 - train - INFO - Train: 158 [ 700/781 ( 90%)]  Loss:  3.163975 (3.4659)  Time: 0.379s,  337.32/s  (0.461s,  277.58/s)  LR: 1.000e-05  Data: 0.006 (0.008)
2024-04-07 14:52:01,173 - train - INFO - Train: 158 [ 750/781 ( 96%)]  Loss:  3.439367 (3.4667)  Time: 0.506s,  252.73/s  (0.461s,  277.63/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:52:15,353 - train - INFO - Train: 158 [ 780/781 (100%)]  Loss:  3.062572 (3.4665)  Time: 0.470s,  272.17/s  (0.461s,  277.36/s)  LR: 1.000e-05  Data: 0.000 (0.008)
2024-04-07 14:52:15,353 - train - INFO - True
2024-04-07 14:52:15,354 - train - INFO - alphas:tensor([0.8606, 0.0044, 0.0108, 0.0202, 0.1041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,355 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,355 - train - INFO - True
2024-04-07 14:52:15,356 - train - INFO - alphas:tensor([0.4718, 0.0008, 0.0032, 0.0185, 0.5057], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,356 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,356 - train - INFO - True
2024-04-07 14:52:15,357 - train - INFO - alphas:tensor([0.5309, 0.0023, 0.0159, 0.4509], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,357 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,358 - train - INFO - True
2024-04-07 14:52:15,358 - train - INFO - alphas:tensor([0.4445, 0.0024, 0.0090, 0.5441], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,359 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,359 - train - INFO - True
2024-04-07 14:52:15,360 - train - INFO - alphas:tensor([0.4535, 0.0011, 0.0124, 0.5331], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,360 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,360 - train - INFO - True
2024-04-07 14:52:15,361 - train - INFO - alphas:tensor([0.5674, 0.0024, 0.0092, 0.4209], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,361 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,362 - train - INFO - True
2024-04-07 14:52:15,362 - train - INFO - alphas:tensor([0.6458, 0.0008, 0.0015, 0.0091, 0.3428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,363 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,363 - train - INFO - True
2024-04-07 14:52:15,364 - train - INFO - alphas:tensor([1.9798e-01, 3.1940e-04, 2.0763e-04, 1.0154e-02, 7.9134e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,365 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,365 - train - INFO - True
2024-04-07 14:52:15,365 - train - INFO - alphas:tensor([2.0151e-01, 1.5804e-04, 2.7245e-04, 6.1631e-03, 7.9189e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,366 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,366 - train - INFO - True
2024-04-07 14:52:15,367 - train - INFO - alphas:tensor([2.0352e-01, 7.6672e-05, 2.0972e-04, 8.1023e-03, 7.8810e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,367 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,367 - train - INFO - True
2024-04-07 14:52:15,368 - train - INFO - alphas:tensor([1.9197e-01, 2.3189e-04, 2.3067e-04, 1.0890e-02, 7.9667e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,369 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,369 - train - INFO - True
2024-04-07 14:52:15,369 - train - INFO - alphas:tensor([6.2108e-01, 1.5421e-04, 6.0159e-04, 7.4024e-03, 3.7076e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,370 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,370 - train - INFO - True
2024-04-07 14:52:15,371 - train - INFO - alphas:tensor([7.6566e-01, 2.3317e-04, 3.8106e-04, 3.5547e-03, 2.3017e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,374 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,374 - train - INFO - True
2024-04-07 14:52:15,375 - train - INFO - alphas:tensor([0.2603, 0.0011, 0.0012, 0.0316, 0.7058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,376 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,376 - train - INFO - True
2024-04-07 14:52:15,377 - train - INFO - alphas:tensor([2.6891e-01, 3.1129e-04, 5.2628e-04, 2.4152e-02, 7.0610e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,378 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,378 - train - INFO - True
2024-04-07 14:52:15,380 - train - INFO - alphas:tensor([2.9135e-01, 2.0306e-04, 5.7583e-04, 2.0879e-02, 6.8699e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,382 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,382 - train - INFO - True
2024-04-07 14:52:15,383 - train - INFO - alphas:tensor([2.6302e-01, 4.3107e-04, 7.3955e-04, 1.9342e-02, 7.1646e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,384 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,384 - train - INFO - True
2024-04-07 14:52:15,385 - train - INFO - alphas:tensor([2.9414e-01, 2.3989e-04, 1.0267e-03, 2.2141e-02, 6.8246e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,386 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,386 - train - INFO - True
2024-04-07 14:52:15,387 - train - INFO - alphas:tensor([0.2550, 0.0010, 0.0017, 0.0244, 0.7178], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,389 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,389 - train - INFO - True
2024-04-07 14:52:15,389 - train - INFO - alphas:tensor([6.7316e-01, 9.4315e-05, 3.3803e-04, 9.2338e-03, 3.1718e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,392 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,392 - train - INFO - True
2024-04-07 14:52:15,393 - train - INFO - alphas:tensor([5.9602e-01, 8.1409e-05, 1.5329e-04, 8.5073e-03, 3.9524e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,398 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,398 - train - INFO - True
2024-04-07 14:52:15,399 - train - INFO - alphas:tensor([4.5199e-01, 6.2651e-05, 5.4803e-04, 1.6571e-02, 5.3083e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,402 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,402 - train - INFO - True
2024-04-07 14:52:15,402 - train - INFO - alphas:tensor([4.6388e-01, 6.9278e-05, 1.6582e-04, 1.4272e-02, 5.2161e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,405 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,405 - train - INFO - True
2024-04-07 14:52:15,406 - train - INFO - alphas:tensor([4.8118e-01, 5.5410e-05, 1.7295e-04, 1.2913e-02, 5.0568e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,408 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,409 - train - INFO - True
2024-04-07 14:52:15,409 - train - INFO - alphas:tensor([4.3994e-01, 7.2231e-05, 3.5779e-04, 1.5269e-02, 5.4436e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,412 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,412 - train - INFO - True
2024-04-07 14:52:15,413 - train - INFO - alphas:tensor([5.9875e-01, 5.7822e-05, 2.8122e-04, 7.1770e-03, 3.9373e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,418 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,418 - train - INFO - True
2024-04-07 14:52:15,418 - train - INFO - alphas:tensor([8.0353e-01, 3.4089e-05, 1.7082e-04, 3.9500e-03, 1.9232e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,431 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,431 - train - INFO - True
2024-04-07 14:52:15,432 - train - INFO - alphas:tensor([4.1208e-01, 1.0801e-04, 3.7040e-04, 2.4551e-02, 5.6289e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,439 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,439 - train - INFO - True
2024-04-07 14:52:15,440 - train - INFO - alphas:tensor([4.1625e-01, 3.9816e-05, 2.3602e-04, 1.5897e-02, 5.6758e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,446 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,446 - train - INFO - True
2024-04-07 14:52:15,447 - train - INFO - alphas:tensor([4.4881e-01, 5.4608e-05, 1.6580e-04, 1.8962e-02, 5.3201e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,454 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,454 - train - INFO - True
2024-04-07 14:52:15,454 - train - INFO - alphas:tensor([4.0985e-01, 7.4325e-05, 2.9630e-04, 1.8387e-02, 5.7139e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,461 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,461 - train - INFO - True
2024-04-07 14:52:15,462 - train - INFO - alphas:tensor([7.6100e-01, 2.8204e-05, 7.4667e-05, 3.1503e-03, 2.3575e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,474 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,474 - train - INFO - True
2024-04-07 14:52:15,475 - train - INFO - alphas:tensor([0.6103, 0.0007, 0.0017, 0.0241, 0.3632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:52:15,551 - train - INFO - tau:0.20849246173476127
2024-04-07 14:52:15,551 - train - INFO - avg block size:10.06060606060606
2024-04-07 14:52:15,552 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 14:52:15,552 - train - INFO - lasso_alpha:3.3200493091179444e-07
2024-04-07 14:52:15,754 - train - INFO - Test: [   0/78]  Time: 0.199 (0.199)  Loss:  0.9531 (0.9531)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 14:52:19,003 - train - INFO - Test: [  50/78]  Time: 0.074 (0.068)  Loss:  1.5557 (1.5414)  Acc@1: 67.1875 (66.2224)  Acc@5: 87.5000 (86.5043)
2024-04-07 14:52:20,550 - train - INFO - Test: [  78/78]  Time: 0.049 (0.063)  Loss:  1.8301 (1.5616)  Acc@1: 56.2500 (65.9300)  Acc@5: 93.7500 (86.2000)
2024-04-07 14:52:21,214 - train - INFO - Train: 159 [   0/781 (  0%)]  Loss:  3.531689 (3.5317)  Time: 0.584s,  219.24/s  (0.584s,  219.24/s)  LR: 1.000e-05  Data: 0.182 (0.182)
2024-04-07 14:52:44,955 - train - INFO - Train: 159 [  50/781 (  6%)]  Loss:  3.298133 (3.4192)  Time: 0.501s,  255.56/s  (0.477s,  268.38/s)  LR: 1.000e-05  Data: 0.008 (0.011)
2024-04-07 14:53:08,339 - train - INFO - Train: 159 [ 100/781 ( 13%)]  Loss:  2.999944 (3.3998)  Time: 0.495s,  258.66/s  (0.472s,  270.99/s)  LR: 1.000e-05  Data: 0.008 (0.010)
2024-04-07 14:53:31,183 - train - INFO - Train: 159 [ 150/781 ( 19%)]  Loss:  3.502883 (3.4177)  Time: 0.467s,  273.95/s  (0.467s,  273.97/s)  LR: 1.000e-05  Data: 0.005 (0.009)
2024-04-07 14:53:53,952 - train - INFO - Train: 159 [ 200/781 ( 26%)]  Loss:  3.315901 (3.4335)  Time: 0.580s,  220.53/s  (0.464s,  275.71/s)  LR: 1.000e-05  Data: 0.013 (0.008)
2024-04-07 14:54:17,644 - train - INFO - Train: 159 [ 250/781 ( 32%)]  Loss:  3.623715 (3.4436)  Time: 0.485s,  264.12/s  (0.466s,  274.58/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:54:40,888 - train - INFO - Train: 159 [ 300/781 ( 38%)]  Loss:  3.507280 (3.4424)  Time: 0.457s,  280.31/s  (0.466s,  274.71/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:55:03,196 - train - INFO - Train: 159 [ 350/781 ( 45%)]  Loss:  3.742080 (3.4404)  Time: 0.496s,  258.16/s  (0.463s,  276.39/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:55:26,608 - train - INFO - Train: 159 [ 400/781 ( 51%)]  Loss:  3.114087 (3.4424)  Time: 0.416s,  307.88/s  (0.464s,  276.01/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:55:49,408 - train - INFO - Train: 159 [ 450/781 ( 58%)]  Loss:  3.669934 (3.4381)  Time: 0.425s,  301.53/s  (0.463s,  276.52/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:56:12,686 - train - INFO - Train: 159 [ 500/781 ( 64%)]  Loss:  3.512084 (3.4405)  Time: 0.443s,  288.73/s  (0.463s,  276.37/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:56:36,443 - train - INFO - Train: 159 [ 550/781 ( 71%)]  Loss:  3.544159 (3.4406)  Time: 0.506s,  252.92/s  (0.464s,  275.73/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:57:00,254 - train - INFO - Train: 159 [ 600/781 ( 77%)]  Loss:  3.222386 (3.4440)  Time: 0.488s,  262.30/s  (0.465s,  275.14/s)  LR: 1.000e-05  Data: 0.008 (0.008)
2024-04-07 14:57:23,596 - train - INFO - Train: 159 [ 650/781 ( 83%)]  Loss:  3.708647 (3.4472)  Time: 0.506s,  252.89/s  (0.465s,  275.06/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:57:46,819 - train - INFO - Train: 159 [ 700/781 ( 90%)]  Loss:  3.605752 (3.4490)  Time: 0.462s,  277.02/s  (0.465s,  275.10/s)  LR: 1.000e-05  Data: 0.007 (0.008)
2024-04-07 14:58:10,678 - train - INFO - Train: 159 [ 750/781 ( 96%)]  Loss:  3.614055 (3.4499)  Time: 0.471s,  271.80/s  (0.466s,  274.64/s)  LR: 1.000e-05  Data: 0.009 (0.008)
2024-04-07 14:58:24,779 - train - INFO - Train: 159 [ 780/781 (100%)]  Loss:  3.526808 (3.4512)  Time: 0.398s,  321.38/s  (0.466s,  274.55/s)  LR: 1.000e-05  Data: 0.000 (0.008)
2024-04-07 14:58:24,779 - train - INFO - True
2024-04-07 14:58:24,781 - train - INFO - alphas:tensor([0.8636, 0.0041, 0.0103, 0.0196, 0.1024], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,781 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,781 - train - INFO - True
2024-04-07 14:58:24,782 - train - INFO - alphas:tensor([0.4722, 0.0008, 0.0030, 0.0180, 0.5060], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,782 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,782 - train - INFO - True
2024-04-07 14:58:24,783 - train - INFO - alphas:tensor([0.5316, 0.0022, 0.0154, 0.4509], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,783 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,784 - train - INFO - True
2024-04-07 14:58:24,784 - train - INFO - alphas:tensor([0.4445, 0.0023, 0.0086, 0.5445], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,785 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,785 - train - INFO - True
2024-04-07 14:58:24,785 - train - INFO - alphas:tensor([0.4535, 0.0010, 0.0120, 0.5335], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,786 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,786 - train - INFO - True
2024-04-07 14:58:24,786 - train - INFO - alphas:tensor([0.5675, 0.0023, 0.0089, 0.4213], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,787 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,787 - train - INFO - True
2024-04-07 14:58:24,788 - train - INFO - alphas:tensor([0.6473, 0.0007, 0.0014, 0.0088, 0.3418], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,789 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,789 - train - INFO - True
2024-04-07 14:58:24,789 - train - INFO - alphas:tensor([1.9655e-01, 2.9697e-04, 1.9201e-04, 9.7855e-03, 7.9317e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,790 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,790 - train - INFO - True
2024-04-07 14:58:24,790 - train - INFO - alphas:tensor([2.0014e-01, 1.4598e-04, 2.5283e-04, 5.9042e-03, 7.9356e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,791 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,791 - train - INFO - True
2024-04-07 14:58:24,792 - train - INFO - alphas:tensor([2.0209e-01, 7.0379e-05, 1.9450e-04, 7.7907e-03, 7.8985e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,792 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,792 - train - INFO - True
2024-04-07 14:58:24,793 - train - INFO - alphas:tensor([1.9088e-01, 2.1500e-04, 2.1392e-04, 1.0515e-02, 7.9817e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,793 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,794 - train - INFO - True
2024-04-07 14:58:24,794 - train - INFO - alphas:tensor([6.2167e-01, 1.4242e-04, 5.6374e-04, 7.1172e-03, 3.7051e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,795 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,795 - train - INFO - True
2024-04-07 14:58:24,796 - train - INFO - alphas:tensor([7.6705e-01, 2.1574e-04, 3.5473e-04, 3.3905e-03, 2.2899e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,798 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,798 - train - INFO - True
2024-04-07 14:58:24,799 - train - INFO - alphas:tensor([0.2597, 0.0011, 0.0011, 0.0309, 0.7072], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,800 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,800 - train - INFO - True
2024-04-07 14:58:24,801 - train - INFO - alphas:tensor([2.6820e-01, 2.8967e-04, 4.9171e-04, 2.3491e-02, 7.0752e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,802 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,802 - train - INFO - True
2024-04-07 14:58:24,803 - train - INFO - alphas:tensor([2.9045e-01, 1.8799e-04, 5.3946e-04, 2.0329e-02, 6.8849e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,804 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,804 - train - INFO - True
2024-04-07 14:58:24,805 - train - INFO - alphas:tensor([2.6251e-01, 4.0280e-04, 6.9468e-04, 1.8797e-02, 7.1760e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,806 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,806 - train - INFO - True
2024-04-07 14:58:24,807 - train - INFO - alphas:tensor([2.9351e-01, 2.2260e-04, 9.6768e-04, 2.1593e-02, 6.8371e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,808 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,808 - train - INFO - True
2024-04-07 14:58:24,809 - train - INFO - alphas:tensor([0.2542, 0.0010, 0.0016, 0.0238, 0.7194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,810 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,810 - train - INFO - True
2024-04-07 14:58:24,811 - train - INFO - alphas:tensor([6.7416e-01, 8.6669e-05, 3.1450e-04, 8.8971e-03, 3.1654e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,813 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,813 - train - INFO - True
2024-04-07 14:58:24,814 - train - INFO - alphas:tensor([5.9678e-01, 7.4653e-05, 1.4133e-04, 8.1752e-03, 3.9483e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,818 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,818 - train - INFO - True
2024-04-07 14:58:24,819 - train - INFO - alphas:tensor([4.5250e-01, 5.7233e-05, 5.1261e-04, 1.6083e-02, 5.3085e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,822 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,822 - train - INFO - True
2024-04-07 14:58:24,822 - train - INFO - alphas:tensor([4.6406e-01, 6.3432e-05, 1.5321e-04, 1.3805e-02, 5.2192e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,825 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,825 - train - INFO - True
2024-04-07 14:58:24,825 - train - INFO - alphas:tensor([4.8176e-01, 5.0636e-05, 1.5998e-04, 1.2497e-02, 5.0553e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,828 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,828 - train - INFO - True
2024-04-07 14:58:24,829 - train - INFO - alphas:tensor([4.4022e-01, 6.6304e-05, 3.3366e-04, 1.4805e-02, 5.4458e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,831 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,831 - train - INFO - True
2024-04-07 14:58:24,832 - train - INFO - alphas:tensor([5.9862e-01, 5.2775e-05, 2.6163e-04, 6.9084e-03, 3.9416e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,836 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,837 - train - INFO - True
2024-04-07 14:58:24,837 - train - INFO - alphas:tensor([8.0446e-01, 3.0947e-05, 1.5787e-04, 3.7800e-03, 1.9157e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,852 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,852 - train - INFO - True
2024-04-07 14:58:24,853 - train - INFO - alphas:tensor([4.1199e-01, 9.9702e-05, 3.4601e-04, 2.3984e-02, 5.6358e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,860 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,861 - train - INFO - True
2024-04-07 14:58:24,861 - train - INFO - alphas:tensor([4.1680e-01, 3.6215e-05, 2.1874e-04, 1.5419e-02, 5.6753e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,868 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,869 - train - INFO - True
2024-04-07 14:58:24,869 - train - INFO - alphas:tensor([4.4785e-01, 5.0018e-05, 1.5382e-04, 1.8485e-02, 5.3346e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,876 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,877 - train - INFO - True
2024-04-07 14:58:24,877 - train - INFO - alphas:tensor([4.0964e-01, 6.8097e-05, 2.7521e-04, 1.7882e-02, 5.7213e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,884 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,884 - train - INFO - True
2024-04-07 14:58:24,885 - train - INFO - alphas:tensor([7.6174e-01, 2.5589e-05, 6.8588e-05, 3.0029e-03, 2.3516e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,898 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,898 - train - INFO - True
2024-04-07 14:58:24,899 - train - INFO - alphas:tensor([0.6108, 0.0007, 0.0016, 0.0236, 0.3633], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:58:24,946 - train - INFO - tau:0.20640753711741366
2024-04-07 14:58:24,946 - train - INFO - avg block size:10.06060606060606
2024-04-07 14:58:24,947 - train - INFO - current latency ratio:tensor(0.2449)
2024-04-07 14:58:25,121 - train - INFO - Test: [   0/78]  Time: 0.172 (0.172)  Loss:  0.9712 (0.9712)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 14:58:28,120 - train - INFO - Test: [  50/78]  Time: 0.054 (0.062)  Loss:  1.5566 (1.5459)  Acc@1: 67.9688 (66.0692)  Acc@5: 87.5000 (86.3205)
2024-04-07 14:58:29,609 - train - INFO - Test: [  78/78]  Time: 0.055 (0.059)  Loss:  1.8643 (1.5657)  Acc@1: 50.0000 (65.7300)  Acc@5: 87.5000 (85.9800)
2024-04-07 14:58:29,689 - train - INFO - *** Best metric: 66.12 (epoch 155)
