2024-04-06 21:27:26,436 - train - INFO - Training with a single process on 1 GPUs.
2024-04-06 21:27:36,401 - train - INFO - Model vit_9_12_64 created, param count:2766144
2024-04-06 21:27:36,431 - train - INFO - Using native Torch AMP. Training in mixed precision.
2024-04-06 21:27:36,431 - train - INFO - Scheduled epochs: 160
2024-04-06 21:27:36,747 - train - INFO - Verifying teacher model
2024-04-06 21:27:39,233 - train - INFO - Test: [   0/78]  Time: 2.485 (2.485)  Loss:  0.9009 (0.9009)  Acc@1: 82.0312 (82.0312)  Acc@5: 94.5312 (94.5312)
2024-04-06 21:27:42,781 - train - INFO - Test: [  50/78]  Time: 0.042 (0.118)  Loss:  1.7285 (1.6075)  Acc@1: 58.5938 (63.1127)  Acc@5: 83.5938 (84.9112)
2024-04-06 21:27:43,973 - train - INFO - Test: [  78/78]  Time: 0.068 (0.091)  Loss:  1.8408 (1.6375)  Acc@1: 56.2500 (62.6500)  Acc@5: 75.0000 (84.3200)
2024-04-06 21:27:43,974 - train - INFO - Verifying initial model
2024-04-06 21:27:44,976 - train - INFO - Test: [   0/78]  Time: 1.001 (1.001)  Loss:  5.3594 (5.3594)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
2024-04-06 21:27:52,809 - train - INFO - Test: [  50/78]  Time: 0.085 (0.173)  Loss:  5.3398 (5.2082)  Acc@1:  0.0000 ( 1.2102)  Acc@5:  0.0000 ( 5.0398)
2024-04-06 21:27:56,695 - train - INFO - Test: [  78/78]  Time: 0.051 (0.161)  Loss:  5.0898 (5.2248)  Acc@1:  0.0000 ( 0.9800)  Acc@5:  0.0000 ( 4.1400)
2024-04-06 21:27:58,688 - train - INFO - Train: 0 [   0/781 (  0%)]  Loss:  5.336673 (5.3367)  Time: 1.990s,   64.31/s  (1.990s,   64.31/s)  LR: 1.000e-06  Data: 0.417 (0.417)
2024-04-06 21:28:45,611 - train - INFO - Train: 0 [  50/781 (  6%)]  Loss:  5.300611 (5.3230)  Time: 0.997s,  128.37/s  (0.959s,  133.46/s)  LR: 1.000e-06  Data: 0.010 (0.016)
2024-04-06 21:29:30,545 - train - INFO - Train: 0 [ 100/781 ( 13%)]  Loss:  5.325736 (5.3197)  Time: 0.925s,  138.38/s  (0.929s,  137.76/s)  LR: 1.000e-06  Data: 0.005 (0.012)
2024-04-06 21:30:16,482 - train - INFO - Train: 0 [ 150/781 ( 19%)]  Loss:  5.316051 (5.3188)  Time: 0.841s,  152.24/s  (0.926s,  138.27/s)  LR: 1.000e-06  Data: 0.009 (0.010)
2024-04-06 21:31:02,586 - train - INFO - Train: 0 [ 200/781 ( 26%)]  Loss:  5.344341 (5.3193)  Time: 0.826s,  154.92/s  (0.925s,  138.41/s)  LR: 1.000e-06  Data: 0.005 (0.010)
2024-04-06 21:31:48,026 - train - INFO - Train: 0 [ 250/781 ( 32%)]  Loss:  5.323534 (5.3174)  Time: 0.810s,  157.99/s  (0.922s,  138.89/s)  LR: 1.000e-06  Data: 0.008 (0.009)
2024-04-06 21:32:36,769 - train - INFO - Train: 0 [ 300/781 ( 38%)]  Loss:  5.304840 (5.3165)  Time: 0.837s,  152.85/s  (0.930s,  137.57/s)  LR: 1.000e-06  Data: 0.007 (0.009)
2024-04-06 21:33:22,663 - train - INFO - Train: 0 [ 350/781 ( 45%)]  Loss:  5.295053 (5.3160)  Time: 0.818s,  156.41/s  (0.929s,  137.83/s)  LR: 1.000e-06  Data: 0.005 (0.009)
2024-04-06 21:34:07,175 - train - INFO - Train: 0 [ 400/781 ( 51%)]  Loss:  5.306694 (5.3153)  Time: 0.786s,  162.87/s  (0.924s,  138.55/s)  LR: 1.000e-06  Data: 0.006 (0.009)
2024-04-06 21:34:53,219 - train - INFO - Train: 0 [ 450/781 ( 58%)]  Loss:  5.319454 (5.3146)  Time: 1.093s,  117.15/s  (0.924s,  138.60/s)  LR: 1.000e-06  Data: 0.008 (0.009)
2024-04-06 21:35:38,661 - train - INFO - Train: 0 [ 500/781 ( 64%)]  Loss:  5.293317 (5.3137)  Time: 0.901s,  142.10/s  (0.922s,  138.82/s)  LR: 1.000e-06  Data: 0.009 (0.009)
2024-04-06 21:36:24,300 - train - INFO - Train: 0 [ 550/781 ( 71%)]  Loss:  5.317171 (5.3128)  Time: 1.073s,  119.28/s  (0.921s,  138.95/s)  LR: 1.000e-06  Data: 0.008 (0.009)
2024-04-06 21:37:09,858 - train - INFO - Train: 0 [ 600/781 ( 77%)]  Loss:  5.299723 (5.3120)  Time: 0.849s,  150.71/s  (0.920s,  139.07/s)  LR: 1.000e-06  Data: 0.008 (0.009)
2024-04-06 21:37:54,837 - train - INFO - Train: 0 [ 650/781 ( 83%)]  Loss:  5.306880 (5.3109)  Time: 1.100s,  116.41/s  (0.919s,  139.32/s)  LR: 1.000e-06  Data: 0.009 (0.009)
2024-04-06 21:38:40,836 - train - INFO - Train: 0 [ 700/781 ( 90%)]  Loss:  5.291200 (5.3102)  Time: 1.075s,  119.09/s  (0.919s,  139.30/s)  LR: 1.000e-06  Data: 0.008 (0.009)
2024-04-06 21:39:25,959 - train - INFO - Train: 0 [ 750/781 ( 96%)]  Loss:  5.278983 (5.3094)  Time: 0.855s,  149.64/s  (0.918s,  139.47/s)  LR: 1.000e-06  Data: 0.009 (0.009)
2024-04-06 21:39:52,419 - train - INFO - Train: 0 [ 780/781 (100%)]  Loss:  5.301353 (5.3089)  Time: 0.848s,  151.02/s  (0.916s,  139.68/s)  LR: 1.000e-06  Data: 0.000 (0.009)
2024-04-06 21:39:52,419 - train - INFO - True
2024-04-06 21:39:52,448 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,466 - train - INFO - True
2024-04-06 21:39:52,467 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,496 - train - INFO - True
2024-04-06 21:39:52,497 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,525 - train - INFO - True
2024-04-06 21:39:52,526 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,554 - train - INFO - True
2024-04-06 21:39:52,556 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,584 - train - INFO - True
2024-04-06 21:39:52,586 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,614 - train - INFO - True
2024-04-06 21:39:52,615 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,643 - train - INFO - True
2024-04-06 21:39:52,644 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,672 - train - INFO - True
2024-04-06 21:39:52,673 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,703 - train - INFO - True
2024-04-06 21:39:52,704 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,732 - train - INFO - True
2024-04-06 21:39:52,733 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,761 - train - INFO - True
2024-04-06 21:39:52,762 - train - INFO - alphas:tensor([0.2001, 0.2001, 0.2000, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,791 - train - INFO - True
2024-04-06 21:39:52,791 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,820 - train - INFO - True
2024-04-06 21:39:52,821 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,849 - train - INFO - True
2024-04-06 21:39:52,850 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,878 - train - INFO - True
2024-04-06 21:39:52,879 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,907 - train - INFO - True
2024-04-06 21:39:52,908 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,936 - train - INFO - True
2024-04-06 21:39:52,937 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.2000, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,965 - train - INFO - True
2024-04-06 21:39:52,966 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:52,994 - train - INFO - True
2024-04-06 21:39:52,995 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,023 - train - INFO - True
2024-04-06 21:39:53,024 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,050 - train - INFO - True
2024-04-06 21:39:53,051 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,075 - train - INFO - True
2024-04-06 21:39:53,076 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,098 - train - INFO - True
2024-04-06 21:39:53,099 - train - INFO - alphas:tensor([0.2002, 0.2000, 0.1999, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,119 - train - INFO - True
2024-04-06 21:39:53,120 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,139 - train - INFO - True
2024-04-06 21:39:53,140 - train - INFO - alphas:tensor([0.2002, 0.2000, 0.2000, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,158 - train - INFO - True
2024-04-06 21:39:53,159 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,176 - train - INFO - True
2024-04-06 21:39:53,177 - train - INFO - alphas:tensor([0.2001, 0.1999, 0.1999, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,194 - train - INFO - True
2024-04-06 21:39:53,194 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,211 - train - INFO - True
2024-04-06 21:39:53,212 - train - INFO - alphas:tensor([0.2002, 0.2001, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,228 - train - INFO - True
2024-04-06 21:39:53,229 - train - INFO - alphas:tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,238 - train - INFO - True
2024-04-06 21:39:53,238 - train - INFO - alphas:tensor([0.2000, 0.2001, 0.2000, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,249 - train - INFO - True
2024-04-06 21:39:53,249 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,266 - train - INFO - True
2024-04-06 21:39:53,267 - train - INFO - alphas:tensor([0.2002, 0.2002, 0.1999, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,284 - train - INFO - True
2024-04-06 21:39:53,284 - train - INFO - alphas:tensor([0.2000, 0.2000, 0.2001, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,293 - train - INFO - True
2024-04-06 21:39:53,294 - train - INFO - alphas:tensor([0.1999, 0.1999, 0.2000, 0.2001, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,302 - train - INFO - True
2024-04-06 21:39:53,303 - train - INFO - alphas:tensor([0.2502, 0.2500, 0.2499, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:39:53,320 - train - INFO - avg block size:1.5135135135135136
2024-04-06 21:39:53,320 - train - INFO - current latency ratio:tensor(0.9056)
2024-04-06 21:39:53,531 - train - INFO - Test: [   0/78]  Time: 0.207 (0.207)  Loss:  5.1680 (5.1680)  Acc@1:  0.7812 ( 0.7812)  Acc@5:  7.8125 ( 7.8125)
2024-04-06 21:39:58,042 - train - INFO - Test: [  50/78]  Time: 0.090 (0.093)  Loss:  5.3164 (5.1839)  Acc@1:  0.0000 ( 1.3940)  Acc@5:  1.5625 ( 6.5104)
2024-04-06 21:40:00,522 - train - INFO - Test: [  78/78]  Time: 0.055 (0.091)  Loss:  4.9844 (5.1843)  Acc@1:  0.0000 ( 1.4000)  Acc@5:  0.0000 ( 6.0300)
2024-04-06 21:40:01,811 - train - INFO - Train: 1 [   0/781 (  0%)]  Loss:  5.305011 (5.3050)  Time: 1.219s,  104.96/s  (1.219s,  104.96/s)  LR: 5.090e-05  Data: 0.158 (0.158)
2024-04-06 21:40:48,132 - train - INFO - Train: 1 [  50/781 (  6%)]  Loss:  5.242572 (5.2721)  Time: 0.860s,  148.78/s  (0.932s,  137.32/s)  LR: 5.090e-05  Data: 0.009 (0.012)
2024-04-06 21:41:34,208 - train - INFO - Train: 1 [ 100/781 ( 13%)]  Loss:  5.192552 (5.2514)  Time: 1.111s,  115.16/s  (0.927s,  138.10/s)  LR: 5.090e-05  Data: 0.009 (0.010)
2024-04-06 21:42:20,536 - train - INFO - Train: 1 [ 150/781 ( 19%)]  Loss:  5.127788 (5.2304)  Time: 1.102s,  116.10/s  (0.927s,  138.12/s)  LR: 5.090e-05  Data: 0.006 (0.010)
2024-04-06 21:43:07,409 - train - INFO - Train: 1 [ 200/781 ( 26%)]  Loss:  5.187922 (5.2095)  Time: 0.808s,  158.38/s  (0.929s,  137.72/s)  LR: 5.090e-05  Data: 0.004 (0.009)
2024-04-06 21:43:53,791 - train - INFO - Train: 1 [ 250/781 ( 32%)]  Loss:  5.101547 (5.1892)  Time: 0.849s,  150.83/s  (0.929s,  137.78/s)  LR: 5.090e-05  Data: 0.009 (0.009)
2024-04-06 21:44:40,835 - train - INFO - Train: 1 [ 300/781 ( 38%)]  Loss:  5.037466 (5.1699)  Time: 0.796s,  160.88/s  (0.931s,  137.49/s)  LR: 5.090e-05  Data: 0.005 (0.009)
2024-04-06 21:45:27,566 - train - INFO - Train: 1 [ 350/781 ( 45%)]  Loss:  5.044949 (5.1527)  Time: 1.068s,  119.81/s  (0.932s,  137.41/s)  LR: 5.090e-05  Data: 0.009 (0.009)
2024-04-06 21:46:13,525 - train - INFO - Train: 1 [ 400/781 ( 51%)]  Loss:  5.122958 (5.1371)  Time: 0.851s,  150.44/s  (0.930s,  137.64/s)  LR: 5.090e-05  Data: 0.008 (0.009)
2024-04-06 21:46:59,434 - train - INFO - Train: 1 [ 450/781 ( 58%)]  Loss:  4.978192 (5.1226)  Time: 0.816s,  156.91/s  (0.929s,  137.83/s)  LR: 5.090e-05  Data: 0.004 (0.008)
2024-04-06 21:47:45,497 - train - INFO - Train: 1 [ 500/781 ( 64%)]  Loss:  4.928103 (5.1081)  Time: 1.092s,  117.26/s  (0.928s,  137.94/s)  LR: 5.090e-05  Data: 0.009 (0.008)
2024-04-06 21:48:32,816 - train - INFO - Train: 1 [ 550/781 ( 71%)]  Loss:  4.939293 (5.0961)  Time: 1.045s,  122.46/s  (0.930s,  137.69/s)  LR: 5.090e-05  Data: 0.015 (0.008)
2024-04-06 21:49:20,866 - train - INFO - Train: 1 [ 600/781 ( 77%)]  Loss:  4.756433 (5.0850)  Time: 0.826s,  154.93/s  (0.932s,  137.31/s)  LR: 5.090e-05  Data: 0.006 (0.008)
2024-04-06 21:50:08,206 - train - INFO - Train: 1 [ 650/781 ( 83%)]  Loss:  5.147636 (5.0741)  Time: 1.090s,  117.40/s  (0.933s,  137.14/s)  LR: 5.090e-05  Data: 0.009 (0.008)
2024-04-06 21:50:54,161 - train - INFO - Train: 1 [ 700/781 ( 90%)]  Loss:  5.087844 (5.0659)  Time: 1.047s,  122.29/s  (0.932s,  137.29/s)  LR: 5.090e-05  Data: 0.013 (0.008)
2024-04-06 21:51:39,681 - train - INFO - Train: 1 [ 750/781 ( 96%)]  Loss:  5.022375 (5.0565)  Time: 1.102s,  116.11/s  (0.931s,  137.51/s)  LR: 5.090e-05  Data: 0.009 (0.008)
2024-04-06 21:52:07,841 - train - INFO - Train: 1 [ 780/781 (100%)]  Loss:  5.011888 (5.0500)  Time: 0.824s,  155.32/s  (0.931s,  137.47/s)  LR: 5.090e-05  Data: 0.000 (0.008)
2024-04-06 21:52:07,842 - train - INFO - True
2024-04-06 21:52:07,844 - train - INFO - alphas:tensor([0.2120, 0.2120, 0.1922, 0.1920, 0.1919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:07,881 - train - INFO - True
2024-04-06 21:52:07,883 - train - INFO - alphas:tensor([0.2099, 0.2097, 0.1940, 0.1932, 0.1932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:07,914 - train - INFO - True
2024-04-06 21:52:07,915 - train - INFO - alphas:tensor([0.2153, 0.2140, 0.1909, 0.1899, 0.1898], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:07,943 - train - INFO - True
2024-04-06 21:52:07,944 - train - INFO - alphas:tensor([0.2138, 0.2123, 0.1925, 0.1909, 0.1905], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:07,972 - train - INFO - True
2024-04-06 21:52:07,973 - train - INFO - alphas:tensor([0.2143, 0.2142, 0.1907, 0.1905, 0.1903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,001 - train - INFO - True
2024-04-06 21:52:08,002 - train - INFO - alphas:tensor([0.2141, 0.2122, 0.1920, 0.1909, 0.1908], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,030 - train - INFO - True
2024-04-06 21:52:08,031 - train - INFO - alphas:tensor([0.2136, 0.2133, 0.1910, 0.1910, 0.1910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,059 - train - INFO - True
2024-04-06 21:52:08,060 - train - INFO - alphas:tensor([0.2136, 0.2106, 0.1925, 0.1917, 0.1915], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,089 - train - INFO - True
2024-04-06 21:52:08,090 - train - INFO - alphas:tensor([0.2137, 0.2132, 0.1907, 0.1909, 0.1914], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,118 - train - INFO - True
2024-04-06 21:52:08,119 - train - INFO - alphas:tensor([0.2121, 0.2089, 0.1937, 0.1929, 0.1924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,148 - train - INFO - True
2024-04-06 21:52:08,149 - train - INFO - alphas:tensor([0.2138, 0.2114, 0.1923, 0.1908, 0.1916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,177 - train - INFO - True
2024-04-06 21:52:08,178 - train - INFO - alphas:tensor([0.2118, 0.2059, 0.1952, 0.1936, 0.1935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,206 - train - INFO - True
2024-04-06 21:52:08,207 - train - INFO - alphas:tensor([0.2119, 0.2124, 0.1923, 0.1918, 0.1916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,225 - train - INFO - True
2024-04-06 21:52:08,226 - train - INFO - alphas:tensor([0.2113, 0.2085, 0.1941, 0.1931, 0.1930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,254 - train - INFO - True
2024-04-06 21:52:08,255 - train - INFO - alphas:tensor([0.2132, 0.2104, 0.1938, 0.1915, 0.1911], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,283 - train - INFO - True
2024-04-06 21:52:08,284 - train - INFO - alphas:tensor([0.2092, 0.2067, 0.1948, 0.1945, 0.1947], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,313 - train - INFO - True
2024-04-06 21:52:08,314 - train - INFO - alphas:tensor([0.2116, 0.2116, 0.1925, 0.1923, 0.1920], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,342 - train - INFO - True
2024-04-06 21:52:08,343 - train - INFO - alphas:tensor([0.2124, 0.2090, 0.1923, 0.1933, 0.1930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,371 - train - INFO - True
2024-04-06 21:52:08,372 - train - INFO - alphas:tensor([0.2104, 0.2077, 0.1950, 0.1936, 0.1934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,400 - train - INFO - True
2024-04-06 21:52:08,401 - train - INFO - alphas:tensor([0.2080, 0.2042, 0.1970, 0.1953, 0.1954], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,429 - train - INFO - True
2024-04-06 21:52:08,430 - train - INFO - alphas:tensor([0.2117, 0.2107, 0.1932, 0.1923, 0.1921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,458 - train - INFO - True
2024-04-06 21:52:08,459 - train - INFO - alphas:tensor([0.2113, 0.2078, 0.1938, 0.1934, 0.1938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,487 - train - INFO - True
2024-04-06 21:52:08,488 - train - INFO - alphas:tensor([0.2098, 0.2073, 0.1945, 0.1942, 0.1942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,516 - train - INFO - True
2024-04-06 21:52:08,517 - train - INFO - alphas:tensor([0.2040, 0.2018, 0.1981, 0.1982, 0.1979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,546 - train - INFO - True
2024-04-06 21:52:08,547 - train - INFO - alphas:tensor([0.2131, 0.2123, 0.1921, 0.1913, 0.1913], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,575 - train - INFO - True
2024-04-06 21:52:08,576 - train - INFO - alphas:tensor([0.2131, 0.2082, 0.1935, 0.1923, 0.1929], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,604 - train - INFO - True
2024-04-06 21:52:08,605 - train - INFO - alphas:tensor([0.2094, 0.2061, 0.1962, 0.1948, 0.1935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,632 - train - INFO - True
2024-04-06 21:52:08,633 - train - INFO - alphas:tensor([0.2062, 0.2028, 0.1973, 0.1967, 0.1971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,658 - train - INFO - True
2024-04-06 21:52:08,659 - train - INFO - alphas:tensor([0.2123, 0.2112, 0.1923, 0.1920, 0.1921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,682 - train - INFO - True
2024-04-06 21:52:08,683 - train - INFO - alphas:tensor([0.2114, 0.2085, 0.1935, 0.1935, 0.1932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,704 - train - INFO - True
2024-04-06 21:52:08,705 - train - INFO - alphas:tensor([0.2084, 0.2068, 0.1965, 0.1947, 0.1936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,724 - train - INFO - True
2024-04-06 21:52:08,725 - train - INFO - alphas:tensor([0.2103, 0.2054, 0.1955, 0.1939, 0.1948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,744 - train - INFO - True
2024-04-06 21:52:08,745 - train - INFO - alphas:tensor([0.2099, 0.2100, 0.1932, 0.1934, 0.1934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,757 - train - INFO - True
2024-04-06 21:52:08,757 - train - INFO - alphas:tensor([0.2097, 0.2080, 0.1939, 0.1943, 0.1942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,779 - train - INFO - True
2024-04-06 21:52:08,780 - train - INFO - alphas:tensor([0.2112, 0.2084, 0.1956, 0.1925, 0.1923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,800 - train - INFO - True
2024-04-06 21:52:08,801 - train - INFO - alphas:tensor([0.2088, 0.2058, 0.1958, 0.1948, 0.1948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,820 - train - INFO - True
2024-04-06 21:52:08,821 - train - INFO - alphas:tensor([0.2697, 0.2491, 0.2403, 0.2409], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 21:52:08,839 - train - INFO - avg block size:1.054054054054054
2024-04-06 21:52:08,839 - train - INFO - current latency ratio:tensor(0.9653)
2024-04-06 21:52:09,084 - train - INFO - Test: [   0/78]  Time: 0.242 (0.242)  Loss:  3.3086 (3.3086)  Acc@1: 46.0938 (46.0938)  Acc@5: 75.0000 (75.0000)
2024-04-06 21:52:13,680 - train - INFO - Test: [  50/78]  Time: 0.088 (0.095)  Loss:  4.0430 (4.1105)  Acc@1: 25.0000 (18.9185)  Acc@5: 46.0938 (41.3756)
2024-04-06 21:52:16,307 - train - INFO - Test: [  78/78]  Time: 0.055 (0.094)  Loss:  4.0859 (4.0948)  Acc@1: 12.5000 (18.7300)  Acc@5: 43.7500 (41.6300)
2024-04-06 21:52:17,595 - train - INFO - Train: 2 [   0/781 (  0%)]  Loss:  4.991206 (4.9912)  Time: 1.226s,  104.42/s  (1.226s,  104.42/s)  LR: 1.008e-04  Data: 0.189 (0.189)
2024-04-06 21:53:03,582 - train - INFO - Train: 2 [  50/781 (  6%)]  Loss:  5.030072 (4.9221)  Time: 0.770s,  166.13/s  (0.926s,  138.27/s)  LR: 1.008e-04  Data: 0.004 (0.011)
2024-04-06 21:53:49,396 - train - INFO - Train: 2 [ 100/781 ( 13%)]  Loss:  4.988201 (4.9126)  Time: 1.103s,  116.02/s  (0.921s,  138.98/s)  LR: 1.008e-04  Data: 0.008 (0.009)
2024-04-06 21:54:36,288 - train - INFO - Train: 2 [ 150/781 ( 19%)]  Loss:  4.860048 (4.8912)  Time: 0.823s,  155.56/s  (0.927s,  138.14/s)  LR: 1.008e-04  Data: 0.008 (0.009)
2024-04-06 21:55:21,782 - train - INFO - Train: 2 [ 200/781 ( 26%)]  Loss:  4.960278 (4.8778)  Time: 0.850s,  150.67/s  (0.922s,  138.77/s)  LR: 1.008e-04  Data: 0.004 (0.008)
2024-04-06 21:56:09,095 - train - INFO - Train: 2 [ 250/781 ( 32%)]  Loss:  4.976381 (4.8712)  Time: 0.819s,  156.27/s  (0.927s,  138.06/s)  LR: 1.008e-04  Data: 0.007 (0.008)
2024-04-06 21:56:55,856 - train - INFO - Train: 2 [ 300/781 ( 38%)]  Loss:  4.676555 (4.8650)  Time: 0.780s,  164.15/s  (0.928s,  137.86/s)  LR: 1.008e-04  Data: 0.004 (0.008)
2024-04-06 21:57:41,886 - train - INFO - Train: 2 [ 350/781 ( 45%)]  Loss:  4.525564 (4.8532)  Time: 0.962s,  133.13/s  (0.927s,  138.03/s)  LR: 1.008e-04  Data: 0.005 (0.008)
2024-04-06 21:58:28,253 - train - INFO - Train: 2 [ 400/781 ( 51%)]  Loss:  4.772824 (4.8481)  Time: 1.063s,  120.44/s  (0.927s,  138.03/s)  LR: 1.008e-04  Data: 0.007 (0.008)
2024-04-06 21:59:13,908 - train - INFO - Train: 2 [ 450/781 ( 58%)]  Loss:  4.518845 (4.8404)  Time: 0.852s,  150.30/s  (0.926s,  138.26/s)  LR: 1.008e-04  Data: 0.007 (0.008)
2024-04-06 22:00:00,025 - train - INFO - Train: 2 [ 500/781 ( 64%)]  Loss:  4.529738 (4.8327)  Time: 0.860s,  148.80/s  (0.925s,  138.31/s)  LR: 1.008e-04  Data: 0.009 (0.008)
2024-04-06 22:00:47,031 - train - INFO - Train: 2 [ 550/781 ( 71%)]  Loss:  4.906682 (4.8282)  Time: 1.091s,  117.35/s  (0.927s,  138.12/s)  LR: 1.008e-04  Data: 0.008 (0.008)
2024-04-06 22:01:35,322 - train - INFO - Train: 2 [ 600/781 ( 77%)]  Loss:  4.818946 (4.8213)  Time: 0.819s,  156.34/s  (0.930s,  137.63/s)  LR: 1.008e-04  Data: 0.008 (0.008)
2024-04-06 22:02:21,673 - train - INFO - Train: 2 [ 650/781 ( 83%)]  Loss:  4.720860 (4.8142)  Time: 0.825s,  155.11/s  (0.930s,  137.67/s)  LR: 1.008e-04  Data: 0.008 (0.008)
2024-04-06 22:03:08,563 - train - INFO - Train: 2 [ 700/781 ( 90%)]  Loss:  4.503013 (4.8059)  Time: 0.827s,  154.80/s  (0.930s,  137.58/s)  LR: 1.008e-04  Data: 0.010 (0.008)
2024-04-06 22:03:57,190 - train - INFO - Train: 2 [ 750/781 ( 96%)]  Loss:  4.823325 (4.8005)  Time: 0.897s,  142.65/s  (0.933s,  137.17/s)  LR: 1.008e-04  Data: 0.009 (0.008)
2024-04-06 22:04:25,313 - train - INFO - Train: 2 [ 780/781 (100%)]  Loss:  4.311245 (4.7964)  Time: 0.825s,  155.11/s  (0.933s,  137.15/s)  LR: 1.008e-04  Data: 0.000 (0.008)
2024-04-06 22:04:25,314 - train - INFO - True
2024-04-06 22:04:25,315 - train - INFO - alphas:tensor([0.2212, 0.2191, 0.1860, 0.1868, 0.1869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,346 - train - INFO - True
2024-04-06 22:04:25,347 - train - INFO - alphas:tensor([0.2208, 0.2159, 0.1873, 0.1873, 0.1886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,374 - train - INFO - True
2024-04-06 22:04:25,375 - train - INFO - alphas:tensor([0.2424, 0.2358, 0.1754, 0.1732, 0.1732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,399 - train - INFO - True
2024-04-06 22:04:25,400 - train - INFO - alphas:tensor([0.2419, 0.2284, 0.1773, 0.1766, 0.1758], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,427 - train - INFO - True
2024-04-06 22:04:25,428 - train - INFO - alphas:tensor([0.2336, 0.2294, 0.1787, 0.1791, 0.1793], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,448 - train - INFO - True
2024-04-06 22:04:25,449 - train - INFO - alphas:tensor([0.2341, 0.2228, 0.1814, 0.1808, 0.1809], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,468 - train - INFO - True
2024-04-06 22:04:25,469 - train - INFO - alphas:tensor([0.2356, 0.2319, 0.1776, 0.1774, 0.1776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,487 - train - INFO - True
2024-04-06 22:04:25,488 - train - INFO - alphas:tensor([0.2339, 0.2244, 0.1832, 0.1795, 0.1791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,506 - train - INFO - True
2024-04-06 22:04:25,507 - train - INFO - alphas:tensor([0.2357, 0.2304, 0.1772, 0.1777, 0.1790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,524 - train - INFO - True
2024-04-06 22:04:25,525 - train - INFO - alphas:tensor([0.2332, 0.2210, 0.1830, 0.1814, 0.1815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,542 - train - INFO - True
2024-04-06 22:04:25,543 - train - INFO - alphas:tensor([0.2364, 0.2263, 0.1795, 0.1779, 0.1799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,583 - train - INFO - True
2024-04-06 22:04:25,586 - train - INFO - alphas:tensor([0.2311, 0.2137, 0.1864, 0.1852, 0.1837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,622 - train - INFO - True
2024-04-06 22:04:25,623 - train - INFO - alphas:tensor([0.2305, 0.2257, 0.1808, 0.1814, 0.1816], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,653 - train - INFO - True
2024-04-06 22:04:25,654 - train - INFO - alphas:tensor([0.2329, 0.2148, 0.1849, 0.1834, 0.1840], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,681 - train - INFO - True
2024-04-06 22:04:25,682 - train - INFO - alphas:tensor([0.2351, 0.2233, 0.1837, 0.1792, 0.1787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,706 - train - INFO - True
2024-04-06 22:04:25,707 - train - INFO - alphas:tensor([0.2260, 0.2150, 0.1877, 0.1849, 0.1863], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,729 - train - INFO - True
2024-04-06 22:04:25,730 - train - INFO - alphas:tensor([0.2273, 0.2226, 0.1829, 0.1835, 0.1837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,751 - train - INFO - True
2024-04-06 22:04:25,752 - train - INFO - alphas:tensor([0.2324, 0.2161, 0.1832, 0.1839, 0.1843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,771 - train - INFO - True
2024-04-06 22:04:25,772 - train - INFO - alphas:tensor([0.2326, 0.2222, 0.1838, 0.1810, 0.1804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,790 - train - INFO - True
2024-04-06 22:04:25,791 - train - INFO - alphas:tensor([0.2253, 0.2126, 0.1894, 0.1860, 0.1867], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,809 - train - INFO - True
2024-04-06 22:04:25,810 - train - INFO - alphas:tensor([0.2296, 0.2229, 0.1825, 0.1824, 0.1826], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,827 - train - INFO - True
2024-04-06 22:04:25,828 - train - INFO - alphas:tensor([0.2356, 0.2162, 0.1824, 0.1827, 0.1831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,845 - train - INFO - True
2024-04-06 22:04:25,846 - train - INFO - alphas:tensor([0.2329, 0.2199, 0.1829, 0.1821, 0.1822], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,867 - train - INFO - True
2024-04-06 22:04:25,869 - train - INFO - alphas:tensor([0.2175, 0.2074, 0.1923, 0.1912, 0.1916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,889 - train - INFO - True
2024-04-06 22:04:25,890 - train - INFO - alphas:tensor([0.2301, 0.2236, 0.1813, 0.1823, 0.1827], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,909 - train - INFO - True
2024-04-06 22:04:25,910 - train - INFO - alphas:tensor([0.2348, 0.2151, 0.1846, 0.1819, 0.1836], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,929 - train - INFO - True
2024-04-06 22:04:25,929 - train - INFO - alphas:tensor([0.2372, 0.2225, 0.1830, 0.1797, 0.1775], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,947 - train - INFO - True
2024-04-06 22:04:25,948 - train - INFO - alphas:tensor([0.2238, 0.2112, 0.1899, 0.1874, 0.1877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,965 - train - INFO - True
2024-04-06 22:04:25,966 - train - INFO - alphas:tensor([0.2293, 0.2242, 0.1817, 0.1823, 0.1825], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:25,985 - train - INFO - True
2024-04-06 22:04:25,986 - train - INFO - alphas:tensor([0.2326, 0.2185, 0.1833, 0.1826, 0.1830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:26,006 - train - INFO - True
2024-04-06 22:04:26,007 - train - INFO - alphas:tensor([0.2403, 0.2284, 0.1797, 0.1762, 0.1753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:26,028 - train - INFO - True
2024-04-06 22:04:26,029 - train - INFO - alphas:tensor([0.2287, 0.2154, 0.1877, 0.1837, 0.1844], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:26,049 - train - INFO - True
2024-04-06 22:04:26,050 - train - INFO - alphas:tensor([0.2240, 0.2220, 0.1841, 0.1847, 0.1852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:26,068 - train - INFO - True
2024-04-06 22:04:26,069 - train - INFO - alphas:tensor([0.2235, 0.2156, 0.1866, 0.1871, 0.1872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:26,087 - train - INFO - True
2024-04-06 22:04:26,088 - train - INFO - alphas:tensor([0.2398, 0.2310, 0.1771, 0.1762, 0.1759], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:26,106 - train - INFO - True
2024-04-06 22:04:26,107 - train - INFO - alphas:tensor([0.2271, 0.2182, 0.1855, 0.1844, 0.1848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:26,125 - train - INFO - True
2024-04-06 22:04:26,126 - train - INFO - alphas:tensor([0.2983, 0.2427, 0.2283, 0.2308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:04:26,146 - train - INFO - avg block size:1.0
2024-04-06 22:04:26,147 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 22:04:26,390 - train - INFO - Test: [   0/78]  Time: 0.239 (0.239)  Loss:  2.5352 (2.5352)  Acc@1: 57.0312 (57.0312)  Acc@5: 78.1250 (78.1250)
2024-04-06 22:04:31,076 - train - INFO - Test: [  50/78]  Time: 0.085 (0.097)  Loss:  3.4727 (3.5510)  Acc@1: 34.3750 (27.9871)  Acc@5: 58.5938 (52.6195)
2024-04-06 22:04:33,510 - train - INFO - Test: [  78/78]  Time: 0.055 (0.093)  Loss:  3.7051 (3.5272)  Acc@1: 12.5000 (27.9000)  Acc@5: 43.7500 (53.5500)
2024-04-06 22:04:34,744 - train - INFO - Train: 3 [   0/781 (  0%)]  Loss:  4.764723 (4.7647)  Time: 1.162s,  110.15/s  (1.162s,  110.15/s)  LR: 1.507e-04  Data: 0.182 (0.182)
2024-04-06 22:05:21,095 - train - INFO - Train: 3 [  50/781 (  6%)]  Loss:  4.527878 (4.7055)  Time: 1.072s,  119.41/s  (0.932s,  137.40/s)  LR: 1.507e-04  Data: 0.009 (0.012)
2024-04-06 22:06:08,160 - train - INFO - Train: 3 [ 100/781 ( 13%)]  Loss:  4.430243 (4.7218)  Time: 1.089s,  117.53/s  (0.936s,  136.70/s)  LR: 1.507e-04  Data: 0.009 (0.010)
2024-04-06 22:06:55,355 - train - INFO - Train: 3 [ 150/781 ( 19%)]  Loss:  4.724802 (4.6845)  Time: 0.842s,  152.03/s  (0.939s,  136.34/s)  LR: 1.507e-04  Data: 0.008 (0.009)
2024-04-06 22:07:42,704 - train - INFO - Train: 3 [ 200/781 ( 26%)]  Loss:  4.338862 (4.6582)  Time: 0.835s,  153.26/s  (0.941s,  136.04/s)  LR: 1.507e-04  Data: 0.007 (0.009)
2024-04-06 22:08:29,494 - train - INFO - Train: 3 [ 250/781 ( 32%)]  Loss:  4.690128 (4.6538)  Time: 0.869s,  147.36/s  (0.940s,  136.19/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-06 22:09:16,389 - train - INFO - Train: 3 [ 300/781 ( 38%)]  Loss:  4.293526 (4.6430)  Time: 0.861s,  148.73/s  (0.940s,  136.24/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-06 22:10:02,449 - train - INFO - Train: 3 [ 350/781 ( 45%)]  Loss:  4.612906 (4.6347)  Time: 0.896s,  142.83/s  (0.937s,  136.62/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-06 22:10:49,466 - train - INFO - Train: 3 [ 400/781 ( 51%)]  Loss:  4.623981 (4.6188)  Time: 1.126s,  113.70/s  (0.937s,  136.56/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-06 22:11:36,406 - train - INFO - Train: 3 [ 450/781 ( 58%)]  Loss:  4.402076 (4.6121)  Time: 1.063s,  120.43/s  (0.937s,  136.53/s)  LR: 1.507e-04  Data: 0.009 (0.008)
2024-04-06 22:12:22,562 - train - INFO - Train: 3 [ 500/781 ( 64%)]  Loss:  4.571231 (4.5990)  Time: 0.839s,  152.50/s  (0.936s,  136.74/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-06 22:13:09,334 - train - INFO - Train: 3 [ 550/781 ( 71%)]  Loss:  4.264570 (4.5915)  Time: 0.871s,  146.98/s  (0.936s,  136.75/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-06 22:13:55,815 - train - INFO - Train: 3 [ 600/781 ( 77%)]  Loss:  4.755934 (4.5825)  Time: 0.858s,  149.20/s  (0.935s,  136.83/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-06 22:14:41,148 - train - INFO - Train: 3 [ 650/781 ( 83%)]  Loss:  4.348668 (4.5738)  Time: 0.886s,  144.40/s  (0.933s,  137.16/s)  LR: 1.507e-04  Data: 0.010 (0.008)
2024-04-06 22:15:27,468 - train - INFO - Train: 3 [ 700/781 ( 90%)]  Loss:  4.770750 (4.5720)  Time: 0.845s,  151.54/s  (0.933s,  137.23/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-06 22:16:13,491 - train - INFO - Train: 3 [ 750/781 ( 96%)]  Loss:  4.721567 (4.5642)  Time: 1.030s,  124.24/s  (0.932s,  137.35/s)  LR: 1.507e-04  Data: 0.005 (0.008)
2024-04-06 22:16:41,023 - train - INFO - Train: 3 [ 780/781 (100%)]  Loss:  4.659201 (4.5614)  Time: 0.863s,  148.38/s  (0.931s,  137.43/s)  LR: 1.507e-04  Data: 0.000 (0.008)
2024-04-06 22:16:41,024 - train - INFO - True
2024-04-06 22:16:41,026 - train - INFO - alphas:tensor([0.2292, 0.2244, 0.1807, 0.1826, 0.1831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,069 - train - INFO - tau:0.99
2024-04-06 22:16:41,069 - train - INFO - True
2024-04-06 22:16:41,070 - train - INFO - alphas:tensor([0.2302, 0.2194, 0.1809, 0.1835, 0.1861], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,104 - train - INFO - tau:0.99
2024-04-06 22:16:41,104 - train - INFO - True
2024-04-06 22:16:41,105 - train - INFO - alphas:tensor([0.2805, 0.2571, 0.1563, 0.1530, 0.1531], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,134 - train - INFO - tau:0.99
2024-04-06 22:16:41,134 - train - INFO - True
2024-04-06 22:16:41,135 - train - INFO - alphas:tensor([0.2846, 0.2397, 0.1584, 0.1593, 0.1579], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,163 - train - INFO - tau:0.99
2024-04-06 22:16:41,163 - train - INFO - True
2024-04-06 22:16:41,164 - train - INFO - alphas:tensor([0.2630, 0.2454, 0.1623, 0.1640, 0.1653], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,192 - train - INFO - tau:0.99
2024-04-06 22:16:41,192 - train - INFO - True
2024-04-06 22:16:41,193 - train - INFO - alphas:tensor([0.2649, 0.2314, 0.1677, 0.1678, 0.1682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,221 - train - INFO - tau:0.99
2024-04-06 22:16:41,221 - train - INFO - True
2024-04-06 22:16:41,222 - train - INFO - alphas:tensor([0.2705, 0.2508, 0.1590, 0.1596, 0.1602], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,250 - train - INFO - tau:0.99
2024-04-06 22:16:41,251 - train - INFO - True
2024-04-06 22:16:41,252 - train - INFO - alphas:tensor([0.2649, 0.2379, 0.1698, 0.1643, 0.1631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,280 - train - INFO - tau:0.99
2024-04-06 22:16:41,280 - train - INFO - True
2024-04-06 22:16:41,281 - train - INFO - alphas:tensor([0.2726, 0.2502, 0.1579, 0.1588, 0.1606], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,309 - train - INFO - tau:0.99
2024-04-06 22:16:41,309 - train - INFO - True
2024-04-06 22:16:41,310 - train - INFO - alphas:tensor([0.2726, 0.2328, 0.1657, 0.1642, 0.1646], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,338 - train - INFO - tau:0.99
2024-04-06 22:16:41,338 - train - INFO - True
2024-04-06 22:16:41,339 - train - INFO - alphas:tensor([0.2736, 0.2425, 0.1607, 0.1602, 0.1631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,367 - train - INFO - tau:0.99
2024-04-06 22:16:41,367 - train - INFO - True
2024-04-06 22:16:41,368 - train - INFO - alphas:tensor([0.2617, 0.2219, 0.1743, 0.1725, 0.1695], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,396 - train - INFO - tau:0.99
2024-04-06 22:16:41,396 - train - INFO - True
2024-04-06 22:16:41,397 - train - INFO - alphas:tensor([0.2668, 0.2447, 0.1613, 0.1631, 0.1641], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,426 - train - INFO - tau:0.99
2024-04-06 22:16:41,426 - train - INFO - True
2024-04-06 22:16:41,427 - train - INFO - alphas:tensor([0.2751, 0.2230, 0.1684, 0.1663, 0.1671], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,455 - train - INFO - tau:0.99
2024-04-06 22:16:41,455 - train - INFO - True
2024-04-06 22:16:41,456 - train - INFO - alphas:tensor([0.2692, 0.2361, 0.1687, 0.1630, 0.1631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,484 - train - INFO - tau:0.99
2024-04-06 22:16:41,484 - train - INFO - True
2024-04-06 22:16:41,485 - train - INFO - alphas:tensor([0.2524, 0.2236, 0.1769, 0.1722, 0.1749], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,513 - train - INFO - tau:0.99
2024-04-06 22:16:41,514 - train - INFO - True
2024-04-06 22:16:41,514 - train - INFO - alphas:tensor([0.2584, 0.2387, 0.1661, 0.1677, 0.1691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,543 - train - INFO - tau:0.99
2024-04-06 22:16:41,543 - train - INFO - True
2024-04-06 22:16:41,544 - train - INFO - alphas:tensor([0.2707, 0.2217, 0.1698, 0.1689, 0.1689], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,572 - train - INFO - tau:0.99
2024-04-06 22:16:41,572 - train - INFO - True
2024-04-06 22:16:41,573 - train - INFO - alphas:tensor([0.2674, 0.2377, 0.1678, 0.1641, 0.1631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,601 - train - INFO - tau:0.99
2024-04-06 22:16:41,601 - train - INFO - True
2024-04-06 22:16:41,602 - train - INFO - alphas:tensor([0.2528, 0.2198, 0.1785, 0.1741, 0.1749], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,630 - train - INFO - tau:0.99
2024-04-06 22:16:41,630 - train - INFO - True
2024-04-06 22:16:41,631 - train - INFO - alphas:tensor([0.2557, 0.2326, 0.1689, 0.1708, 0.1721], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,659 - train - INFO - tau:0.99
2024-04-06 22:16:41,660 - train - INFO - True
2024-04-06 22:16:41,660 - train - INFO - alphas:tensor([0.2746, 0.2190, 0.1683, 0.1687, 0.1694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,689 - train - INFO - tau:0.99
2024-04-06 22:16:41,689 - train - INFO - True
2024-04-06 22:16:41,690 - train - INFO - alphas:tensor([0.2727, 0.2335, 0.1655, 0.1639, 0.1643], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,718 - train - INFO - tau:0.99
2024-04-06 22:16:41,718 - train - INFO - True
2024-04-06 22:16:41,719 - train - INFO - alphas:tensor([0.2414, 0.2144, 0.1834, 0.1801, 0.1808], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,747 - train - INFO - tau:0.99
2024-04-06 22:16:41,747 - train - INFO - True
2024-04-06 22:16:41,748 - train - INFO - alphas:tensor([0.2539, 0.2324, 0.1682, 0.1723, 0.1732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,776 - train - INFO - tau:0.99
2024-04-06 22:16:41,776 - train - INFO - True
2024-04-06 22:16:41,777 - train - INFO - alphas:tensor([0.2696, 0.2185, 0.1718, 0.1687, 0.1713], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,805 - train - INFO - tau:0.99
2024-04-06 22:16:41,805 - train - INFO - True
2024-04-06 22:16:41,806 - train - INFO - alphas:tensor([0.2827, 0.2387, 0.1624, 0.1590, 0.1572], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,832 - train - INFO - tau:0.99
2024-04-06 22:16:41,832 - train - INFO - True
2024-04-06 22:16:41,833 - train - INFO - alphas:tensor([0.2558, 0.2205, 0.1776, 0.1735, 0.1726], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,856 - train - INFO - tau:0.99
2024-04-06 22:16:41,857 - train - INFO - True
2024-04-06 22:16:41,857 - train - INFO - alphas:tensor([0.2534, 0.2340, 0.1692, 0.1713, 0.1721], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,879 - train - INFO - tau:0.99
2024-04-06 22:16:41,879 - train - INFO - True
2024-04-06 22:16:41,880 - train - INFO - alphas:tensor([0.2680, 0.2261, 0.1687, 0.1675, 0.1698], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,900 - train - INFO - tau:0.99
2024-04-06 22:16:41,900 - train - INFO - True
2024-04-06 22:16:41,901 - train - INFO - alphas:tensor([0.2853, 0.2486, 0.1571, 0.1545, 0.1546], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,920 - train - INFO - tau:0.99
2024-04-06 22:16:41,920 - train - INFO - True
2024-04-06 22:16:41,921 - train - INFO - alphas:tensor([0.2647, 0.2287, 0.1721, 0.1670, 0.1675], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,939 - train - INFO - tau:0.99
2024-04-06 22:16:41,939 - train - INFO - True
2024-04-06 22:16:41,940 - train - INFO - alphas:tensor([0.2454, 0.2353, 0.1713, 0.1732, 0.1748], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,957 - train - INFO - tau:0.99
2024-04-06 22:16:41,958 - train - INFO - True
2024-04-06 22:16:41,958 - train - INFO - alphas:tensor([0.2493, 0.2227, 0.1752, 0.1762, 0.1766], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,976 - train - INFO - tau:0.99
2024-04-06 22:16:41,976 - train - INFO - True
2024-04-06 22:16:41,977 - train - INFO - alphas:tensor([0.2811, 0.2506, 0.1556, 0.1562, 0.1565], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:41,994 - train - INFO - tau:0.99
2024-04-06 22:16:41,994 - train - INFO - True
2024-04-06 22:16:41,995 - train - INFO - alphas:tensor([0.2633, 0.2351, 0.1667, 0.1668, 0.1680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:42,012 - train - INFO - tau:0.99
2024-04-06 22:16:42,012 - train - INFO - True
2024-04-06 22:16:42,013 - train - INFO - alphas:tensor([0.3413, 0.2257, 0.2142, 0.2188], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:16:42,029 - train - INFO - tau:0.99
2024-04-06 22:16:42,029 - train - INFO - avg block size:1.0
2024-04-06 22:16:42,030 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 22:16:42,293 - train - INFO - Test: [   0/78]  Time: 0.261 (0.261)  Loss:  1.9346 (1.9346)  Acc@1: 61.7188 (61.7188)  Acc@5: 81.2500 (81.2500)
2024-04-06 22:16:46,850 - train - INFO - Test: [  50/78]  Time: 0.090 (0.094)  Loss:  2.7832 (3.0016)  Acc@1: 47.6562 (37.1630)  Acc@5: 68.7500 (63.5417)
2024-04-06 22:16:49,474 - train - INFO - Test: [  78/78]  Time: 0.078 (0.094)  Loss:  3.0801 (2.9861)  Acc@1: 25.0000 (37.2500)  Acc@5: 56.2500 (63.8200)
2024-04-06 22:16:50,757 - train - INFO - Train: 4 [   0/781 (  0%)]  Loss:  4.607831 (4.6078)  Time: 1.079s,  118.67/s  (1.079s,  118.67/s)  LR: 2.006e-04  Data: 0.174 (0.174)
2024-04-06 22:17:36,969 - train - INFO - Train: 4 [  50/781 (  6%)]  Loss:  4.700283 (4.4639)  Time: 1.081s,  118.41/s  (0.927s,  138.04/s)  LR: 2.006e-04  Data: 0.008 (0.011)
2024-04-06 22:18:23,923 - train - INFO - Train: 4 [ 100/781 ( 13%)]  Loss:  4.044246 (4.4513)  Time: 1.012s,  126.45/s  (0.933s,  137.18/s)  LR: 2.006e-04  Data: 0.005 (0.009)
2024-04-06 22:19:09,870 - train - INFO - Train: 4 [ 150/781 ( 19%)]  Loss:  4.279052 (4.4489)  Time: 0.937s,  136.57/s  (0.928s,  137.87/s)  LR: 2.006e-04  Data: 0.009 (0.009)
2024-04-06 22:19:56,917 - train - INFO - Train: 4 [ 200/781 ( 26%)]  Loss:  4.316358 (4.4410)  Time: 1.125s,  113.74/s  (0.932s,  137.41/s)  LR: 2.006e-04  Data: 0.008 (0.008)
2024-04-06 22:20:43,414 - train - INFO - Train: 4 [ 250/781 ( 32%)]  Loss:  4.073009 (4.4486)  Time: 0.812s,  157.67/s  (0.931s,  137.46/s)  LR: 2.006e-04  Data: 0.004 (0.008)
2024-04-06 22:21:28,930 - train - INFO - Train: 4 [ 300/781 ( 38%)]  Loss:  4.779838 (4.4428)  Time: 0.817s,  156.63/s  (0.928s,  137.97/s)  LR: 2.006e-04  Data: 0.004 (0.008)
2024-04-06 22:22:14,088 - train - INFO - Train: 4 [ 350/781 ( 45%)]  Loss:  4.753905 (4.4422)  Time: 0.966s,  132.52/s  (0.924s,  138.50/s)  LR: 2.006e-04  Data: 0.006 (0.008)
2024-04-06 22:22:59,095 - train - INFO - Train: 4 [ 400/781 ( 51%)]  Loss:  4.004552 (4.4308)  Time: 0.876s,  146.07/s  (0.921s,  138.95/s)  LR: 2.006e-04  Data: 0.009 (0.008)
2024-04-06 22:23:45,261 - train - INFO - Train: 4 [ 450/781 ( 58%)]  Loss:  3.884065 (4.4202)  Time: 1.017s,  125.92/s  (0.921s,  138.91/s)  LR: 2.006e-04  Data: 0.007 (0.008)
2024-04-06 22:24:30,317 - train - INFO - Train: 4 [ 500/781 ( 64%)]  Loss:  4.323265 (4.4161)  Time: 0.845s,  151.49/s  (0.919s,  139.22/s)  LR: 2.006e-04  Data: 0.007 (0.008)
2024-04-06 22:25:17,324 - train - INFO - Train: 4 [ 550/781 ( 71%)]  Loss:  4.478848 (4.4019)  Time: 0.846s,  151.30/s  (0.921s,  138.94/s)  LR: 2.006e-04  Data: 0.004 (0.008)
2024-04-06 22:26:04,965 - train - INFO - Train: 4 [ 600/781 ( 77%)]  Loss:  4.004050 (4.3919)  Time: 0.997s,  128.41/s  (0.924s,  138.54/s)  LR: 2.006e-04  Data: 0.007 (0.008)
2024-04-06 22:26:52,560 - train - INFO - Train: 4 [ 650/781 ( 83%)]  Loss:  4.315714 (4.3807)  Time: 0.840s,  152.46/s  (0.926s,  138.22/s)  LR: 2.006e-04  Data: 0.007 (0.008)
2024-04-06 22:27:39,352 - train - INFO - Train: 4 [ 700/781 ( 90%)]  Loss:  4.574131 (4.3749)  Time: 1.009s,  126.90/s  (0.927s,  138.12/s)  LR: 2.006e-04  Data: 0.006 (0.008)
2024-04-06 22:28:27,209 - train - INFO - Train: 4 [ 750/781 ( 96%)]  Loss:  3.987146 (4.3676)  Time: 1.086s,  117.86/s  (0.929s,  137.82/s)  LR: 2.006e-04  Data: 0.020 (0.008)
2024-04-06 22:28:55,689 - train - INFO - Train: 4 [ 780/781 (100%)]  Loss:  3.978437 (4.3625)  Time: 0.860s,  148.78/s  (0.930s,  137.70/s)  LR: 2.006e-04  Data: 0.000 (0.008)
2024-04-06 22:28:55,690 - train - INFO - True
2024-04-06 22:28:55,692 - train - INFO - alphas:tensor([0.2393, 0.2305, 0.1741, 0.1774, 0.1787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:55,716 - train - INFO - tau:0.9801
2024-04-06 22:28:55,716 - train - INFO - True
2024-04-06 22:28:55,717 - train - INFO - alphas:tensor([0.2417, 0.2220, 0.1738, 0.1792, 0.1833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:55,747 - train - INFO - tau:0.9801
2024-04-06 22:28:55,747 - train - INFO - True
2024-04-06 22:28:55,748 - train - INFO - alphas:tensor([0.3324, 0.2597, 0.1374, 0.1350, 0.1355], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:55,769 - train - INFO - tau:0.9801
2024-04-06 22:28:55,770 - train - INFO - True
2024-04-06 22:28:55,770 - train - INFO - alphas:tensor([0.3399, 0.2337, 0.1405, 0.1434, 0.1424], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:55,790 - train - INFO - tau:0.9801
2024-04-06 22:28:55,791 - train - INFO - True
2024-04-06 22:28:55,791 - train - INFO - alphas:tensor([0.3031, 0.2511, 0.1455, 0.1488, 0.1515], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:55,811 - train - INFO - tau:0.9801
2024-04-06 22:28:55,811 - train - INFO - True
2024-04-06 22:28:55,812 - train - INFO - alphas:tensor([0.3092, 0.2306, 0.1518, 0.1534, 0.1550], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:55,831 - train - INFO - tau:0.9801
2024-04-06 22:28:55,831 - train - INFO - True
2024-04-06 22:28:55,831 - train - INFO - alphas:tensor([0.3214, 0.2574, 0.1390, 0.1403, 0.1419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:55,850 - train - INFO - tau:0.9801
2024-04-06 22:28:55,851 - train - INFO - True
2024-04-06 22:28:55,851 - train - INFO - alphas:tensor([0.3099, 0.2436, 0.1530, 0.1476, 0.1460], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:55,870 - train - INFO - tau:0.9801
2024-04-06 22:28:55,870 - train - INFO - True
2024-04-06 22:28:55,871 - train - INFO - alphas:tensor([0.3202, 0.2509, 0.1402, 0.1430, 0.1456], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:55,889 - train - INFO - tau:0.9801
2024-04-06 22:28:55,889 - train - INFO - True
2024-04-06 22:28:55,889 - train - INFO - alphas:tensor([0.3280, 0.2309, 0.1473, 0.1461, 0.1476], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:55,910 - train - INFO - tau:0.9801
2024-04-06 22:28:55,910 - train - INFO - True
2024-04-06 22:28:55,911 - train - INFO - alphas:tensor([0.3315, 0.2486, 0.1382, 0.1392, 0.1425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:55,932 - train - INFO - tau:0.9801
2024-04-06 22:28:55,932 - train - INFO - True
2024-04-06 22:28:55,933 - train - INFO - alphas:tensor([0.3119, 0.2279, 0.1559, 0.1539, 0.1504], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:55,952 - train - INFO - tau:0.9801
2024-04-06 22:28:55,952 - train - INFO - True
2024-04-06 22:28:55,953 - train - INFO - alphas:tensor([0.3211, 0.2490, 0.1402, 0.1439, 0.1458], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:55,971 - train - INFO - tau:0.9801
2024-04-06 22:28:55,972 - train - INFO - True
2024-04-06 22:28:55,972 - train - INFO - alphas:tensor([0.3414, 0.2197, 0.1470, 0.1454, 0.1465], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:55,991 - train - INFO - tau:0.9801
2024-04-06 22:28:55,991 - train - INFO - True
2024-04-06 22:28:55,991 - train - INFO - alphas:tensor([0.3232, 0.2428, 0.1483, 0.1424, 0.1433], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,010 - train - INFO - tau:0.9801
2024-04-06 22:28:56,010 - train - INFO - True
2024-04-06 22:28:56,010 - train - INFO - alphas:tensor([0.2974, 0.2301, 0.1603, 0.1543, 0.1579], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,029 - train - INFO - tau:0.9801
2024-04-06 22:28:56,029 - train - INFO - True
2024-04-06 22:28:56,030 - train - INFO - alphas:tensor([0.3096, 0.2464, 0.1447, 0.1483, 0.1511], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,052 - train - INFO - tau:0.9801
2024-04-06 22:28:56,052 - train - INFO - True
2024-04-06 22:28:56,053 - train - INFO - alphas:tensor([0.3305, 0.2182, 0.1515, 0.1503, 0.1495], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,074 - train - INFO - tau:0.9801
2024-04-06 22:28:56,074 - train - INFO - True
2024-04-06 22:28:56,075 - train - INFO - alphas:tensor([0.3221, 0.2434, 0.1474, 0.1439, 0.1432], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,094 - train - INFO - tau:0.9801
2024-04-06 22:28:56,094 - train - INFO - True
2024-04-06 22:28:56,095 - train - INFO - alphas:tensor([0.2978, 0.2238, 0.1628, 0.1579, 0.1578], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,114 - train - INFO - tau:0.9801
2024-04-06 22:28:56,114 - train - INFO - True
2024-04-06 22:28:56,114 - train - INFO - alphas:tensor([0.2959, 0.2360, 0.1531, 0.1561, 0.1589], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,133 - train - INFO - tau:0.9801
2024-04-06 22:28:56,133 - train - INFO - True
2024-04-06 22:28:56,134 - train - INFO - alphas:tensor([0.3313, 0.2121, 0.1512, 0.1521, 0.1533], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,153 - train - INFO - tau:0.9801
2024-04-06 22:28:56,153 - train - INFO - True
2024-04-06 22:28:56,153 - train - INFO - alphas:tensor([0.3331, 0.2374, 0.1440, 0.1426, 0.1430], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,172 - train - INFO - tau:0.9801
2024-04-06 22:28:56,172 - train - INFO - True
2024-04-06 22:28:56,173 - train - INFO - alphas:tensor([0.2828, 0.2184, 0.1698, 0.1641, 0.1650], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,193 - train - INFO - tau:0.9801
2024-04-06 22:28:56,193 - train - INFO - True
2024-04-06 22:28:56,194 - train - INFO - alphas:tensor([0.2929, 0.2358, 0.1519, 0.1585, 0.1609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,215 - train - INFO - tau:0.9801
2024-04-06 22:28:56,215 - train - INFO - True
2024-04-06 22:28:56,216 - train - INFO - alphas:tensor([0.3215, 0.2130, 0.1563, 0.1528, 0.1564], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,235 - train - INFO - tau:0.9801
2024-04-06 22:28:56,235 - train - INFO - True
2024-04-06 22:28:56,236 - train - INFO - alphas:tensor([0.3478, 0.2372, 0.1399, 0.1378, 0.1372], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,254 - train - INFO - tau:0.9801
2024-04-06 22:28:56,254 - train - INFO - True
2024-04-06 22:28:56,255 - train - INFO - alphas:tensor([0.3052, 0.2236, 0.1606, 0.1561, 0.1544], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,273 - train - INFO - tau:0.9801
2024-04-06 22:28:56,273 - train - INFO - True
2024-04-06 22:28:56,273 - train - INFO - alphas:tensor([0.2882, 0.2387, 0.1544, 0.1584, 0.1603], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,290 - train - INFO - tau:0.9801
2024-04-06 22:28:56,290 - train - INFO - True
2024-04-06 22:28:56,291 - train - INFO - alphas:tensor([0.3207, 0.2205, 0.1522, 0.1515, 0.1551], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,308 - train - INFO - tau:0.9801
2024-04-06 22:28:56,308 - train - INFO - True
2024-04-06 22:28:56,308 - train - INFO - alphas:tensor([0.3474, 0.2447, 0.1362, 0.1352, 0.1364], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,326 - train - INFO - tau:0.9801
2024-04-06 22:28:56,326 - train - INFO - True
2024-04-06 22:28:56,327 - train - INFO - alphas:tensor([0.3177, 0.2326, 0.1523, 0.1484, 0.1490], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,345 - train - INFO - tau:0.9801
2024-04-06 22:28:56,345 - train - INFO - True
2024-04-06 22:28:56,346 - train - INFO - alphas:tensor([0.2754, 0.2436, 0.1569, 0.1606, 0.1635], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,369 - train - INFO - tau:0.9801
2024-04-06 22:28:56,369 - train - INFO - True
2024-04-06 22:28:56,370 - train - INFO - alphas:tensor([0.2928, 0.2244, 0.1597, 0.1610, 0.1621], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,389 - train - INFO - tau:0.9801
2024-04-06 22:28:56,389 - train - INFO - True
2024-04-06 22:28:56,390 - train - INFO - alphas:tensor([0.3391, 0.2467, 0.1359, 0.1387, 0.1396], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,409 - train - INFO - tau:0.9801
2024-04-06 22:28:56,409 - train - INFO - True
2024-04-06 22:28:56,410 - train - INFO - alphas:tensor([0.3151, 0.2378, 0.1475, 0.1486, 0.1510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,429 - train - INFO - tau:0.9801
2024-04-06 22:28:56,429 - train - INFO - True
2024-04-06 22:28:56,430 - train - INFO - alphas:tensor([0.3918, 0.2007, 0.2001, 0.2074], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:28:56,448 - train - INFO - tau:0.9801
2024-04-06 22:28:56,448 - train - INFO - avg block size:1.0
2024-04-06 22:28:56,449 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 22:28:56,720 - train - INFO - Test: [   0/78]  Time: 0.267 (0.267)  Loss:  1.6045 (1.6045)  Acc@1: 63.2812 (63.2812)  Acc@5: 85.1562 (85.1562)
2024-04-06 22:29:01,571 - train - INFO - Test: [  50/78]  Time: 0.108 (0.100)  Loss:  2.3867 (2.4717)  Acc@1: 49.2188 (45.9406)  Acc@5: 76.5625 (72.8860)
2024-04-06 22:29:04,262 - train - INFO - Test: [  78/78]  Time: 0.056 (0.099)  Loss:  2.7031 (2.4781)  Acc@1: 37.5000 (45.7800)  Acc@5: 68.7500 (72.6500)
2024-04-06 22:29:05,369 - train - INFO - Train: 5 [   0/781 (  0%)]  Loss:  3.759786 (3.7598)  Time: 1.037s,  123.42/s  (1.037s,  123.42/s)  LR: 2.505e-04  Data: 0.194 (0.194)
2024-04-06 22:29:51,781 - train - INFO - Train: 5 [  50/781 (  6%)]  Loss:  4.552395 (4.2801)  Time: 1.013s,  126.37/s  (0.930s,  137.60/s)  LR: 2.505e-04  Data: 0.009 (0.011)
2024-04-06 22:30:39,063 - train - INFO - Train: 5 [ 100/781 ( 13%)]  Loss:  4.022481 (4.2647)  Time: 0.956s,  133.85/s  (0.938s,  136.48/s)  LR: 2.505e-04  Data: 0.010 (0.009)
2024-04-06 22:31:26,923 - train - INFO - Train: 5 [ 150/781 ( 19%)]  Loss:  4.015572 (4.2243)  Time: 0.876s,  146.18/s  (0.944s,  135.56/s)  LR: 2.505e-04  Data: 0.009 (0.009)
2024-04-06 22:32:14,120 - train - INFO - Train: 5 [ 200/781 ( 26%)]  Loss:  4.121634 (4.2243)  Time: 1.037s,  123.42/s  (0.944s,  135.57/s)  LR: 2.505e-04  Data: 0.011 (0.008)
2024-04-06 22:33:00,125 - train - INFO - Train: 5 [ 250/781 ( 32%)]  Loss:  4.525913 (4.2113)  Time: 0.846s,  151.29/s  (0.939s,  136.26/s)  LR: 2.505e-04  Data: 0.005 (0.008)
2024-04-06 22:33:45,833 - train - INFO - Train: 5 [ 300/781 ( 38%)]  Loss:  4.337472 (4.1904)  Time: 0.838s,  152.82/s  (0.935s,  136.87/s)  LR: 2.505e-04  Data: 0.005 (0.008)
2024-04-06 22:34:33,445 - train - INFO - Train: 5 [ 350/781 ( 45%)]  Loss:  4.168786 (4.1751)  Time: 1.064s,  120.31/s  (0.938s,  136.52/s)  LR: 2.505e-04  Data: 0.008 (0.008)
2024-04-06 22:35:20,410 - train - INFO - Train: 5 [ 400/781 ( 51%)]  Loss:  4.494539 (4.1698)  Time: 0.868s,  147.47/s  (0.938s,  136.49/s)  LR: 2.505e-04  Data: 0.007 (0.008)
2024-04-06 22:36:07,640 - train - INFO - Train: 5 [ 450/781 ( 58%)]  Loss:  4.327137 (4.1669)  Time: 0.876s,  146.14/s  (0.939s,  136.38/s)  LR: 2.505e-04  Data: 0.008 (0.008)
2024-04-06 22:36:55,690 - train - INFO - Train: 5 [ 500/781 ( 64%)]  Loss:  3.949754 (4.1539)  Time: 0.951s,  134.54/s  (0.941s,  136.06/s)  LR: 2.505e-04  Data: 0.005 (0.008)
2024-04-06 22:37:42,436 - train - INFO - Train: 5 [ 550/781 ( 71%)]  Loss:  3.424587 (4.1448)  Time: 1.121s,  114.19/s  (0.940s,  136.13/s)  LR: 2.505e-04  Data: 0.005 (0.008)
2024-04-06 22:38:28,936 - train - INFO - Train: 5 [ 600/781 ( 77%)]  Loss:  4.290792 (4.1393)  Time: 1.094s,  117.02/s  (0.939s,  136.26/s)  LR: 2.505e-04  Data: 0.005 (0.008)
2024-04-06 22:39:16,037 - train - INFO - Train: 5 [ 650/781 ( 83%)]  Loss:  3.397487 (4.1319)  Time: 1.047s,  122.30/s  (0.940s,  136.23/s)  LR: 2.505e-04  Data: 0.005 (0.008)
2024-04-06 22:40:03,610 - train - INFO - Train: 5 [ 700/781 ( 90%)]  Loss:  4.101751 (4.1274)  Time: 0.949s,  134.87/s  (0.940s,  136.11/s)  LR: 2.505e-04  Data: 0.012 (0.007)
2024-04-06 22:40:52,029 - train - INFO - Train: 5 [ 750/781 ( 96%)]  Loss:  4.047551 (4.1227)  Time: 0.839s,  152.55/s  (0.942s,  135.84/s)  LR: 2.505e-04  Data: 0.006 (0.007)
2024-04-06 22:41:20,027 - train - INFO - Train: 5 [ 780/781 (100%)]  Loss:  4.369642 (4.1233)  Time: 0.834s,  153.47/s  (0.942s,  135.89/s)  LR: 2.505e-04  Data: 0.000 (0.008)
2024-04-06 22:41:20,037 - train - INFO - True
2024-04-06 22:41:20,038 - train - INFO - alphas:tensor([0.2523, 0.2373, 0.1661, 0.1710, 0.1733], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,066 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,067 - train - INFO - True
2024-04-06 22:41:20,068 - train - INFO - alphas:tensor([0.2577, 0.2215, 0.1662, 0.1743, 0.1802], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,096 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,096 - train - INFO - True
2024-04-06 22:41:20,097 - train - INFO - alphas:tensor([0.3899, 0.2418, 0.1232, 0.1220, 0.1231], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,125 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,125 - train - INFO - True
2024-04-06 22:41:20,126 - train - INFO - alphas:tensor([0.3949, 0.2153, 0.1267, 0.1315, 0.1316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,154 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,154 - train - INFO - True
2024-04-06 22:41:20,155 - train - INFO - alphas:tensor([0.3497, 0.2373, 0.1327, 0.1382, 0.1421], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,184 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,184 - train - INFO - True
2024-04-06 22:41:20,185 - train - INFO - alphas:tensor([0.3607, 0.2184, 0.1370, 0.1408, 0.1430], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,215 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,215 - train - INFO - True
2024-04-06 22:41:20,216 - train - INFO - alphas:tensor([0.3916, 0.2418, 0.1201, 0.1218, 0.1246], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,244 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,244 - train - INFO - True
2024-04-06 22:41:20,245 - train - INFO - alphas:tensor([0.3756, 0.2327, 0.1340, 0.1294, 0.1283], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,273 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,274 - train - INFO - True
2024-04-06 22:41:20,275 - train - INFO - alphas:tensor([0.3750, 0.2302, 0.1272, 0.1320, 0.1355], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,303 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,303 - train - INFO - True
2024-04-06 22:41:20,304 - train - INFO - alphas:tensor([0.3919, 0.2137, 0.1309, 0.1306, 0.1330], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,332 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,332 - train - INFO - True
2024-04-06 22:41:20,333 - train - INFO - alphas:tensor([0.4104, 0.2294, 0.1173, 0.1195, 0.1233], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,361 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,361 - train - INFO - True
2024-04-06 22:41:20,362 - train - INFO - alphas:tensor([0.3795, 0.2197, 0.1354, 0.1343, 0.1310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,390 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,391 - train - INFO - True
2024-04-06 22:41:20,392 - train - INFO - alphas:tensor([0.3831, 0.2288, 0.1246, 0.1301, 0.1333], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,421 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,421 - train - INFO - True
2024-04-06 22:41:20,422 - train - INFO - alphas:tensor([0.4151, 0.1989, 0.1286, 0.1279, 0.1295], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,450 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,450 - train - INFO - True
2024-04-06 22:41:20,451 - train - INFO - alphas:tensor([0.3977, 0.2301, 0.1272, 0.1217, 0.1232], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,480 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,480 - train - INFO - True
2024-04-06 22:41:20,481 - train - INFO - alphas:tensor([0.3606, 0.2254, 0.1403, 0.1347, 0.1390], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,509 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,509 - train - INFO - True
2024-04-06 22:41:20,510 - train - INFO - alphas:tensor([0.3754, 0.2304, 0.1263, 0.1319, 0.1360], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,538 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,538 - train - INFO - True
2024-04-06 22:41:20,539 - train - INFO - alphas:tensor([0.4068, 0.1985, 0.1321, 0.1318, 0.1308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,567 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,567 - train - INFO - True
2024-04-06 22:41:20,568 - train - INFO - alphas:tensor([0.3993, 0.2266, 0.1265, 0.1241, 0.1235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,595 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,595 - train - INFO - True
2024-04-06 22:41:20,595 - train - INFO - alphas:tensor([0.3591, 0.2181, 0.1441, 0.1397, 0.1390], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,621 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,621 - train - INFO - True
2024-04-06 22:41:20,622 - train - INFO - alphas:tensor([0.3530, 0.2268, 0.1355, 0.1403, 0.1444], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,643 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,644 - train - INFO - True
2024-04-06 22:41:20,644 - train - INFO - alphas:tensor([0.4046, 0.1933, 0.1327, 0.1340, 0.1354], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,665 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,665 - train - INFO - True
2024-04-06 22:41:20,665 - train - INFO - alphas:tensor([0.4187, 0.2200, 0.1204, 0.1202, 0.1207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,685 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,685 - train - INFO - True
2024-04-06 22:41:20,685 - train - INFO - alphas:tensor([0.3465, 0.2130, 0.1504, 0.1445, 0.1456], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,704 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,704 - train - INFO - True
2024-04-06 22:41:20,705 - train - INFO - alphas:tensor([0.3467, 0.2262, 0.1351, 0.1442, 0.1478], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,724 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,724 - train - INFO - True
2024-04-06 22:41:20,725 - train - INFO - alphas:tensor([0.3909, 0.1958, 0.1380, 0.1355, 0.1399], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,745 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,745 - train - INFO - True
2024-04-06 22:41:20,746 - train - INFO - alphas:tensor([0.4367, 0.2094, 0.1184, 0.1175, 0.1179], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,765 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,765 - train - INFO - True
2024-04-06 22:41:20,766 - train - INFO - alphas:tensor([0.3754, 0.2136, 0.1393, 0.1367, 0.1349], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,787 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,787 - train - INFO - True
2024-04-06 22:41:20,788 - train - INFO - alphas:tensor([0.3358, 0.2291, 0.1400, 0.1461, 0.1491], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,810 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,810 - train - INFO - True
2024-04-06 22:41:20,811 - train - INFO - alphas:tensor([0.3901, 0.2011, 0.1346, 0.1350, 0.1392], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,830 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,830 - train - INFO - True
2024-04-06 22:41:20,831 - train - INFO - alphas:tensor([0.4303, 0.2129, 0.1179, 0.1184, 0.1205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,849 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,849 - train - INFO - True
2024-04-06 22:41:20,850 - train - INFO - alphas:tensor([0.3912, 0.2131, 0.1332, 0.1310, 0.1315], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,868 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,868 - train - INFO - True
2024-04-06 22:41:20,868 - train - INFO - alphas:tensor([0.3198, 0.2403, 0.1410, 0.1472, 0.1517], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,886 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,886 - train - INFO - True
2024-04-06 22:41:20,887 - train - INFO - alphas:tensor([0.3572, 0.2135, 0.1409, 0.1433, 0.1451], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,906 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,906 - train - INFO - True
2024-04-06 22:41:20,907 - train - INFO - alphas:tensor([0.4191, 0.2150, 0.1183, 0.1231, 0.1246], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,928 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,928 - train - INFO - True
2024-04-06 22:41:20,929 - train - INFO - alphas:tensor([0.3852, 0.2181, 0.1296, 0.1321, 0.1350], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,949 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,949 - train - INFO - True
2024-04-06 22:41:20,950 - train - INFO - alphas:tensor([0.4447, 0.1744, 0.1855, 0.1953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:41:20,969 - train - INFO - tau:0.9702989999999999
2024-04-06 22:41:20,969 - train - INFO - avg block size:1.0
2024-04-06 22:41:20,970 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 22:41:21,230 - train - INFO - Test: [   0/78]  Time: 0.257 (0.257)  Loss:  1.1699 (1.1699)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.9688 (92.9688)
2024-04-06 22:41:26,562 - train - INFO - Test: [  50/78]  Time: 0.108 (0.110)  Loss:  2.1602 (2.1121)  Acc@1: 55.4688 (52.5429)  Acc@5: 78.1250 (77.8799)
2024-04-06 22:41:29,410 - train - INFO - Test: [  78/78]  Time: 0.076 (0.107)  Loss:  1.5713 (2.1457)  Acc@1: 56.2500 (51.6100)  Acc@5: 100.0000 (77.1700)
2024-04-06 22:41:30,747 - train - INFO - Train: 6 [   0/781 (  0%)]  Loss:  3.793219 (3.7932)  Time: 1.253s,  102.19/s  (1.253s,  102.19/s)  LR: 3.004e-04  Data: 0.183 (0.183)
2024-04-06 22:42:17,690 - train - INFO - Train: 6 [  50/781 (  6%)]  Loss:  4.311744 (3.9751)  Time: 1.132s,  113.12/s  (0.945s,  135.45/s)  LR: 3.004e-04  Data: 0.005 (0.011)
2024-04-06 22:43:06,431 - train - INFO - Train: 6 [ 100/781 ( 13%)]  Loss:  4.387019 (3.9950)  Time: 0.849s,  150.77/s  (0.960s,  133.37/s)  LR: 3.004e-04  Data: 0.005 (0.009)
2024-04-06 22:43:53,745 - train - INFO - Train: 6 [ 150/781 ( 19%)]  Loss:  4.361190 (4.0534)  Time: 0.919s,  139.34/s  (0.955s,  133.99/s)  LR: 3.004e-04  Data: 0.005 (0.009)
2024-04-06 22:44:41,459 - train - INFO - Train: 6 [ 200/781 ( 26%)]  Loss:  3.628835 (4.0651)  Time: 1.015s,  126.13/s  (0.955s,  134.03/s)  LR: 3.004e-04  Data: 0.005 (0.009)
2024-04-06 22:45:28,826 - train - INFO - Train: 6 [ 250/781 ( 32%)]  Loss:  3.589215 (4.0444)  Time: 0.923s,  138.61/s  (0.953s,  134.25/s)  LR: 3.004e-04  Data: 0.005 (0.008)
2024-04-06 22:46:14,414 - train - INFO - Train: 6 [ 300/781 ( 38%)]  Loss:  4.128985 (4.0356)  Time: 0.857s,  149.33/s  (0.947s,  135.23/s)  LR: 3.004e-04  Data: 0.006 (0.008)
2024-04-06 22:47:02,569 - train - INFO - Train: 6 [ 350/781 ( 45%)]  Loss:  3.333777 (4.0304)  Time: 1.049s,  122.01/s  (0.949s,  134.90/s)  LR: 3.004e-04  Data: 0.009 (0.008)
2024-04-06 22:47:50,446 - train - INFO - Train: 6 [ 400/781 ( 51%)]  Loss:  3.860987 (4.0326)  Time: 1.019s,  125.60/s  (0.950s,  134.75/s)  LR: 3.004e-04  Data: 0.005 (0.008)
2024-04-06 22:48:37,223 - train - INFO - Train: 6 [ 450/781 ( 58%)]  Loss:  3.946230 (4.0313)  Time: 1.075s,  119.04/s  (0.948s,  134.97/s)  LR: 3.004e-04  Data: 0.007 (0.008)
2024-04-06 22:49:25,070 - train - INFO - Train: 6 [ 500/781 ( 64%)]  Loss:  4.236448 (4.0212)  Time: 0.865s,  147.94/s  (0.949s,  134.85/s)  LR: 3.004e-04  Data: 0.008 (0.008)
2024-04-06 22:50:12,308 - train - INFO - Train: 6 [ 550/781 ( 71%)]  Loss:  3.211446 (4.0134)  Time: 0.833s,  153.57/s  (0.949s,  134.91/s)  LR: 3.004e-04  Data: 0.005 (0.008)
2024-04-06 22:50:59,665 - train - INFO - Train: 6 [ 600/781 ( 77%)]  Loss:  4.168132 (4.0148)  Time: 0.900s,  142.15/s  (0.949s,  134.93/s)  LR: 3.004e-04  Data: 0.006 (0.008)
2024-04-06 22:51:46,965 - train - INFO - Train: 6 [ 650/781 ( 83%)]  Loss:  3.523609 (4.0101)  Time: 1.100s,  116.32/s  (0.948s,  134.96/s)  LR: 3.004e-04  Data: 0.009 (0.008)
2024-04-06 22:52:33,625 - train - INFO - Train: 6 [ 700/781 ( 90%)]  Loss:  4.153005 (3.9960)  Time: 1.099s,  116.45/s  (0.947s,  135.11/s)  LR: 3.004e-04  Data: 0.009 (0.008)
2024-04-06 22:53:23,571 - train - INFO - Train: 6 [ 750/781 ( 96%)]  Loss:  3.309730 (3.9929)  Time: 1.098s,  116.59/s  (0.951s,  134.63/s)  LR: 3.004e-04  Data: 0.011 (0.008)
2024-04-06 22:53:51,981 - train - INFO - Train: 6 [ 780/781 (100%)]  Loss:  4.122405 (3.9911)  Time: 1.114s,  114.95/s  (0.951s,  134.65/s)  LR: 3.004e-04  Data: 0.000 (0.008)
2024-04-06 22:53:51,983 - train - INFO - True
2024-04-06 22:53:51,985 - train - INFO - alphas:tensor([0.2639, 0.2408, 0.1600, 0.1661, 0.1691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,029 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,029 - train - INFO - True
2024-04-06 22:53:52,031 - train - INFO - alphas:tensor([0.2750, 0.2194, 0.1587, 0.1694, 0.1775], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,065 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,065 - train - INFO - True
2024-04-06 22:53:52,066 - train - INFO - alphas:tensor([0.4413, 0.2180, 0.1131, 0.1129, 0.1147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,095 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,095 - train - INFO - True
2024-04-06 22:53:52,096 - train - INFO - alphas:tensor([0.4401, 0.1963, 0.1164, 0.1229, 0.1242], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,122 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,122 - train - INFO - True
2024-04-06 22:53:52,123 - train - INFO - alphas:tensor([0.3909, 0.2166, 0.1244, 0.1316, 0.1366], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,146 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,146 - train - INFO - True
2024-04-06 22:53:52,147 - train - INFO - alphas:tensor([0.4108, 0.2015, 0.1246, 0.1301, 0.1330], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,169 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,169 - train - INFO - True
2024-04-06 22:53:52,170 - train - INFO - alphas:tensor([0.4671, 0.2103, 0.1048, 0.1071, 0.1107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,190 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,190 - train - INFO - True
2024-04-06 22:53:52,191 - train - INFO - alphas:tensor([0.4487, 0.2083, 0.1166, 0.1135, 0.1129], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,210 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,210 - train - INFO - True
2024-04-06 22:53:52,210 - train - INFO - alphas:tensor([0.4257, 0.2042, 0.1175, 0.1239, 0.1288], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,228 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,228 - train - INFO - True
2024-04-06 22:53:52,229 - train - INFO - alphas:tensor([0.4512, 0.1923, 0.1169, 0.1182, 0.1214], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,246 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,246 - train - INFO - True
2024-04-06 22:53:52,247 - train - INFO - alphas:tensor([0.4942, 0.1948, 0.1003, 0.1034, 0.1073], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,264 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,264 - train - INFO - True
2024-04-06 22:53:52,265 - train - INFO - alphas:tensor([0.4522, 0.1981, 0.1175, 0.1174, 0.1148], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,286 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,286 - train - INFO - True
2024-04-06 22:53:52,287 - train - INFO - alphas:tensor([0.4415, 0.1999, 0.1129, 0.1205, 0.1252], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,306 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,306 - train - INFO - True
2024-04-06 22:53:52,307 - train - INFO - alphas:tensor([0.4839, 0.1740, 0.1130, 0.1134, 0.1157], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,325 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,325 - train - INFO - True
2024-04-06 22:53:52,326 - train - INFO - alphas:tensor([0.4779, 0.2031, 0.1088, 0.1042, 0.1061], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,343 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,343 - train - INFO - True
2024-04-06 22:53:52,344 - train - INFO - alphas:tensor([0.4309, 0.2080, 0.1219, 0.1173, 0.1219], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,361 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,361 - train - INFO - True
2024-04-06 22:53:52,362 - train - INFO - alphas:tensor([0.4402, 0.2029, 0.1121, 0.1197, 0.1252], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,378 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,378 - train - INFO - True
2024-04-06 22:53:52,379 - train - INFO - alphas:tensor([0.4819, 0.1737, 0.1144, 0.1153, 0.1147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,396 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,396 - train - INFO - True
2024-04-06 22:53:52,396 - train - INFO - alphas:tensor([0.4829, 0.1955, 0.1080, 0.1067, 0.1069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,415 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,415 - train - INFO - True
2024-04-06 22:53:52,416 - train - INFO - alphas:tensor([0.4257, 0.2005, 0.1270, 0.1236, 0.1232], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,437 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,437 - train - INFO - True
2024-04-06 22:53:52,437 - train - INFO - alphas:tensor([0.4138, 0.2046, 0.1213, 0.1277, 0.1326], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,457 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,457 - train - INFO - True
2024-04-06 22:53:52,457 - train - INFO - alphas:tensor([0.4781, 0.1703, 0.1155, 0.1172, 0.1189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,476 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,476 - train - INFO - True
2024-04-06 22:53:52,476 - train - INFO - alphas:tensor([0.5139, 0.1865, 0.0990, 0.0999, 0.1007], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,494 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,494 - train - INFO - True
2024-04-06 22:53:52,494 - train - INFO - alphas:tensor([0.4258, 0.1941, 0.1300, 0.1244, 0.1258], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,511 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,511 - train - INFO - True
2024-04-06 22:53:52,512 - train - INFO - alphas:tensor([0.4049, 0.2060, 0.1206, 0.1319, 0.1366], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,528 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,528 - train - INFO - True
2024-04-06 22:53:52,529 - train - INFO - alphas:tensor([0.4635, 0.1720, 0.1210, 0.1192, 0.1243], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,546 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,546 - train - INFO - True
2024-04-06 22:53:52,547 - train - INFO - alphas:tensor([0.5255, 0.1745, 0.0994, 0.0997, 0.1009], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,568 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,569 - train - INFO - True
2024-04-06 22:53:52,569 - train - INFO - alphas:tensor([0.4539, 0.1901, 0.1199, 0.1187, 0.1173], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,589 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,589 - train - INFO - True
2024-04-06 22:53:52,589 - train - INFO - alphas:tensor([0.3877, 0.2097, 0.1270, 0.1355, 0.1401], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,608 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,608 - train - INFO - True
2024-04-06 22:53:52,609 - train - INFO - alphas:tensor([0.4630, 0.1760, 0.1176, 0.1194, 0.1240], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,627 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,627 - train - INFO - True
2024-04-06 22:53:52,628 - train - INFO - alphas:tensor([0.5122, 0.1769, 0.1014, 0.1034, 0.1062], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,645 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,645 - train - INFO - True
2024-04-06 22:53:52,646 - train - INFO - alphas:tensor([0.4678, 0.1838, 0.1164, 0.1155, 0.1165], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,662 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,663 - train - INFO - True
2024-04-06 22:53:52,663 - train - INFO - alphas:tensor([0.3722, 0.2189, 0.1283, 0.1371, 0.1436], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,680 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,680 - train - INFO - True
2024-04-06 22:53:52,681 - train - INFO - alphas:tensor([0.4353, 0.1866, 0.1225, 0.1266, 0.1291], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,697 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,698 - train - INFO - True
2024-04-06 22:53:52,698 - train - INFO - alphas:tensor([0.4987, 0.1791, 0.1025, 0.1088, 0.1110], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,719 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,719 - train - INFO - True
2024-04-06 22:53:52,720 - train - INFO - alphas:tensor([0.4585, 0.1877, 0.1142, 0.1180, 0.1216], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,740 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,740 - train - INFO - True
2024-04-06 22:53:52,741 - train - INFO - alphas:tensor([0.4887, 0.1534, 0.1729, 0.1850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 22:53:52,760 - train - INFO - tau:0.96059601
2024-04-06 22:53:52,760 - train - INFO - avg block size:1.0
2024-04-06 22:53:52,761 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 22:53:52,761 - train - INFO - lasso_alpha:1.1000000000000001e-05
2024-04-06 22:53:53,024 - train - INFO - Test: [   0/78]  Time: 0.259 (0.259)  Loss:  1.1416 (1.1416)  Acc@1: 78.1250 (78.1250)  Acc@5: 90.6250 (90.6250)
2024-04-06 22:53:57,724 - train - INFO - Test: [  50/78]  Time: 0.137 (0.097)  Loss:  2.1699 (1.9173)  Acc@1: 50.0000 (55.8977)  Acc@5: 78.9062 (80.2849)
2024-04-06 22:54:00,970 - train - INFO - Test: [  78/78]  Time: 0.079 (0.104)  Loss:  1.9072 (1.9529)  Acc@1: 37.5000 (55.0100)  Acc@5: 93.7500 (79.7500)
2024-04-06 22:54:02,439 - train - INFO - Train: 7 [   0/781 (  0%)]  Loss:  4.157028 (4.1570)  Time: 1.371s,   93.34/s  (1.371s,   93.34/s)  LR: 3.503e-04  Data: 0.169 (0.169)
2024-04-06 22:54:50,703 - train - INFO - Train: 7 [  50/781 (  6%)]  Loss:  4.307908 (3.9393)  Time: 0.853s,  150.05/s  (0.973s,  131.52/s)  LR: 3.503e-04  Data: 0.007 (0.012)
2024-04-06 22:55:38,185 - train - INFO - Train: 7 [ 100/781 ( 13%)]  Loss:  4.279420 (3.9081)  Time: 0.850s,  150.56/s  (0.962s,  133.12/s)  LR: 3.503e-04  Data: 0.009 (0.010)
2024-04-06 22:56:25,256 - train - INFO - Train: 7 [ 150/781 ( 19%)]  Loss:  4.474855 (3.9323)  Time: 1.088s,  117.69/s  (0.955s,  134.05/s)  LR: 3.503e-04  Data: 0.010 (0.009)
2024-04-06 22:57:11,672 - train - INFO - Train: 7 [ 200/781 ( 26%)]  Loss:  4.265027 (3.9092)  Time: 0.793s,  161.51/s  (0.948s,  134.99/s)  LR: 3.503e-04  Data: 0.006 (0.009)
2024-04-06 22:58:00,098 - train - INFO - Train: 7 [ 250/781 ( 32%)]  Loss:  3.674361 (3.9064)  Time: 0.851s,  150.46/s  (0.952s,  134.42/s)  LR: 3.503e-04  Data: 0.011 (0.009)
2024-04-06 22:58:48,069 - train - INFO - Train: 7 [ 300/781 ( 38%)]  Loss:  3.997854 (3.8967)  Time: 0.822s,  155.71/s  (0.953s,  134.25/s)  LR: 3.503e-04  Data: 0.006 (0.009)
2024-04-06 22:59:36,727 - train - INFO - Train: 7 [ 350/781 ( 45%)]  Loss:  4.110481 (3.8928)  Time: 1.146s,  111.70/s  (0.956s,  133.86/s)  LR: 3.503e-04  Data: 0.009 (0.009)
2024-04-06 23:00:23,924 - train - INFO - Train: 7 [ 400/781 ( 51%)]  Loss:  3.536614 (3.8978)  Time: 1.078s,  118.77/s  (0.955s,  134.07/s)  LR: 3.503e-04  Data: 0.008 (0.009)
2024-04-06 23:01:09,909 - train - INFO - Train: 7 [ 450/781 ( 58%)]  Loss:  3.491169 (3.9092)  Time: 0.848s,  150.97/s  (0.951s,  134.62/s)  LR: 3.503e-04  Data: 0.007 (0.009)
2024-04-06 23:01:57,419 - train - INFO - Train: 7 [ 500/781 ( 64%)]  Loss:  4.231986 (3.9003)  Time: 0.836s,  153.08/s  (0.951s,  134.63/s)  LR: 3.503e-04  Data: 0.007 (0.009)
2024-04-06 23:02:44,134 - train - INFO - Train: 7 [ 550/781 ( 71%)]  Loss:  4.278546 (3.8998)  Time: 1.087s,  117.73/s  (0.949s,  134.84/s)  LR: 3.503e-04  Data: 0.009 (0.009)
2024-04-06 23:03:30,997 - train - INFO - Train: 7 [ 600/781 ( 77%)]  Loss:  4.400009 (3.8944)  Time: 0.862s,  148.41/s  (0.948s,  134.98/s)  LR: 3.503e-04  Data: 0.009 (0.009)
2024-04-06 23:04:17,878 - train - INFO - Train: 7 [ 650/781 ( 83%)]  Loss:  4.260679 (3.9008)  Time: 0.872s,  146.74/s  (0.947s,  135.10/s)  LR: 3.503e-04  Data: 0.008 (0.009)
2024-04-06 23:05:04,419 - train - INFO - Train: 7 [ 700/781 ( 90%)]  Loss:  3.774227 (3.8946)  Time: 0.809s,  158.28/s  (0.946s,  135.27/s)  LR: 3.503e-04  Data: 0.008 (0.009)
2024-04-06 23:05:50,484 - train - INFO - Train: 7 [ 750/781 ( 96%)]  Loss:  4.312024 (3.9032)  Time: 0.850s,  150.65/s  (0.945s,  135.51/s)  LR: 3.503e-04  Data: 0.008 (0.009)
2024-04-06 23:06:18,737 - train - INFO - Train: 7 [ 780/781 (100%)]  Loss:  3.069378 (3.9024)  Time: 1.063s,  120.41/s  (0.944s,  135.52/s)  LR: 3.503e-04  Data: 0.000 (0.008)
2024-04-06 23:06:18,738 - train - INFO - True
2024-04-06 23:06:18,740 - train - INFO - alphas:tensor([0.2724, 0.2413, 0.1563, 0.1632, 0.1669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:18,774 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:18,774 - train - INFO - True
2024-04-06 23:06:18,775 - train - INFO - alphas:tensor([0.2928, 0.2137, 0.1521, 0.1655, 0.1758], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:18,804 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:18,805 - train - INFO - True
2024-04-06 23:06:18,805 - train - INFO - alphas:tensor([0.4869, 0.1954, 0.1046, 0.1056, 0.1076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:18,834 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:18,834 - train - INFO - True
2024-04-06 23:06:18,835 - train - INFO - alphas:tensor([0.4804, 0.1786, 0.1077, 0.1155, 0.1179], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:18,863 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:18,863 - train - INFO - True
2024-04-06 23:06:18,864 - train - INFO - alphas:tensor([0.4243, 0.1971, 0.1182, 0.1272, 0.1332], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:18,892 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:18,892 - train - INFO - True
2024-04-06 23:06:18,893 - train - INFO - alphas:tensor([0.4571, 0.1833, 0.1139, 0.1209, 0.1247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:18,921 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:18,921 - train - INFO - True
2024-04-06 23:06:18,922 - train - INFO - alphas:tensor([0.5346, 0.1802, 0.0918, 0.0946, 0.0988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:18,950 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:18,951 - train - INFO - True
2024-04-06 23:06:18,951 - train - INFO - alphas:tensor([0.5181, 0.1812, 0.1013, 0.0998, 0.0996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:18,980 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:18,980 - train - INFO - True
2024-04-06 23:06:18,981 - train - INFO - alphas:tensor([0.4621, 0.1823, 0.1107, 0.1193, 0.1255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,009 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,009 - train - INFO - True
2024-04-06 23:06:19,010 - train - INFO - alphas:tensor([0.5016, 0.1719, 0.1059, 0.1083, 0.1123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,038 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,038 - train - INFO - True
2024-04-06 23:06:19,039 - train - INFO - alphas:tensor([0.5637, 0.1642, 0.0869, 0.0905, 0.0948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,068 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,068 - train - INFO - True
2024-04-06 23:06:19,069 - train - INFO - alphas:tensor([0.5175, 0.1733, 0.1028, 0.1041, 0.1022], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,097 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,097 - train - INFO - True
2024-04-06 23:06:19,098 - train - INFO - alphas:tensor([0.4852, 0.1754, 0.1047, 0.1142, 0.1205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,126 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,126 - train - INFO - True
2024-04-06 23:06:19,127 - train - INFO - alphas:tensor([0.5391, 0.1525, 0.1008, 0.1025, 0.1051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,156 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,156 - train - INFO - True
2024-04-06 23:06:19,157 - train - INFO - alphas:tensor([0.5468, 0.1751, 0.0941, 0.0908, 0.0932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,185 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,185 - train - INFO - True
2024-04-06 23:06:19,186 - train - INFO - alphas:tensor([0.4953, 0.1838, 0.1071, 0.1043, 0.1095], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,214 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,214 - train - INFO - True
2024-04-06 23:06:19,215 - train - INFO - alphas:tensor([0.4865, 0.1781, 0.1031, 0.1125, 0.1197], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,243 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,244 - train - INFO - True
2024-04-06 23:06:19,245 - train - INFO - alphas:tensor([0.5431, 0.1506, 0.1009, 0.1026, 0.1029], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,273 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,273 - train - INFO - True
2024-04-06 23:06:19,274 - train - INFO - alphas:tensor([0.5585, 0.1646, 0.0920, 0.0922, 0.0927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,302 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,302 - train - INFO - True
2024-04-06 23:06:19,303 - train - INFO - alphas:tensor([0.4906, 0.1766, 0.1118, 0.1104, 0.1106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,331 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,332 - train - INFO - True
2024-04-06 23:06:19,332 - train - INFO - alphas:tensor([0.4647, 0.1800, 0.1108, 0.1191, 0.1254], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,361 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,361 - train - INFO - True
2024-04-06 23:06:19,362 - train - INFO - alphas:tensor([0.5411, 0.1474, 0.1017, 0.1039, 0.1059], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,390 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,390 - train - INFO - True
2024-04-06 23:06:19,391 - train - INFO - alphas:tensor([0.5945, 0.1542, 0.0825, 0.0838, 0.0850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,419 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,419 - train - INFO - True
2024-04-06 23:06:19,420 - train - INFO - alphas:tensor([0.5007, 0.1690, 0.1121, 0.1082, 0.1100], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,449 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,449 - train - INFO - True
2024-04-06 23:06:19,450 - train - INFO - alphas:tensor([0.4568, 0.1817, 0.1096, 0.1230, 0.1289], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,477 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,477 - train - INFO - True
2024-04-06 23:06:19,478 - train - INFO - alphas:tensor([0.5298, 0.1490, 0.1056, 0.1051, 0.1105], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,503 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,503 - train - INFO - True
2024-04-06 23:06:19,504 - train - INFO - alphas:tensor([0.5990, 0.1444, 0.0839, 0.0854, 0.0872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,527 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,527 - train - INFO - True
2024-04-06 23:06:19,527 - train - INFO - alphas:tensor([0.5251, 0.1641, 0.1035, 0.1039, 0.1033], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,548 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,549 - train - INFO - True
2024-04-06 23:06:19,549 - train - INFO - alphas:tensor([0.4373, 0.1836, 0.1173, 0.1278, 0.1340], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,569 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,569 - train - INFO - True
2024-04-06 23:06:19,570 - train - INFO - alphas:tensor([0.5270, 0.1520, 0.1035, 0.1062, 0.1113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,588 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,588 - train - INFO - True
2024-04-06 23:06:19,589 - train - INFO - alphas:tensor([0.5813, 0.1471, 0.0874, 0.0903, 0.0939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,609 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,609 - train - INFO - True
2024-04-06 23:06:19,609 - train - INFO - alphas:tensor([0.5373, 0.1556, 0.1012, 0.1023, 0.1036], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,631 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,631 - train - INFO - True
2024-04-06 23:06:19,631 - train - INFO - alphas:tensor([0.4205, 0.1906, 0.1187, 0.1308, 0.1393], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,651 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,651 - train - INFO - True
2024-04-06 23:06:19,652 - train - INFO - alphas:tensor([0.5053, 0.1597, 0.1067, 0.1124, 0.1159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,671 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,671 - train - INFO - True
2024-04-06 23:06:19,672 - train - INFO - alphas:tensor([0.5627, 0.1503, 0.0899, 0.0971, 0.1000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,689 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,689 - train - INFO - True
2024-04-06 23:06:19,690 - train - INFO - alphas:tensor([0.5195, 0.1605, 0.1018, 0.1070, 0.1111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,707 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,707 - train - INFO - True
2024-04-06 23:06:19,708 - train - INFO - alphas:tensor([0.5232, 0.1368, 0.1630, 0.1770], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:06:19,729 - train - INFO - tau:0.9509900498999999
2024-04-06 23:06:19,729 - train - INFO - avg block size:1.0
2024-04-06 23:06:19,729 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 23:06:19,991 - train - INFO - Test: [   0/78]  Time: 0.258 (0.258)  Loss:  1.1484 (1.1484)  Acc@1: 75.0000 (75.0000)  Acc@5: 89.8438 (89.8438)
2024-04-06 23:06:24,675 - train - INFO - Test: [  50/78]  Time: 0.088 (0.097)  Loss:  2.1152 (1.8471)  Acc@1: 51.5625 (57.2917)  Acc@5: 79.6875 (81.1887)
2024-04-06 23:06:27,593 - train - INFO - Test: [  78/78]  Time: 0.059 (0.099)  Loss:  1.7793 (1.8673)  Acc@1: 56.2500 (56.7000)  Acc@5: 93.7500 (80.8000)
2024-04-06 23:06:28,929 - train - INFO - Train: 8 [   0/781 (  0%)]  Loss:  3.631875 (3.6319)  Time: 1.260s,  101.61/s  (1.260s,  101.61/s)  LR: 4.002e-04  Data: 0.186 (0.186)
2024-04-06 23:07:15,016 - train - INFO - Train: 8 [  50/781 (  6%)]  Loss:  4.327312 (3.7795)  Time: 0.833s,  153.71/s  (0.928s,  137.88/s)  LR: 4.002e-04  Data: 0.006 (0.012)
2024-04-06 23:08:01,224 - train - INFO - Train: 8 [ 100/781 ( 13%)]  Loss:  4.164157 (3.8217)  Time: 0.831s,  154.07/s  (0.926s,  138.19/s)  LR: 4.002e-04  Data: 0.007 (0.010)
2024-04-06 23:08:48,041 - train - INFO - Train: 8 [ 150/781 ( 19%)]  Loss:  4.507497 (3.8309)  Time: 0.867s,  147.69/s  (0.930s,  137.70/s)  LR: 4.002e-04  Data: 0.007 (0.009)
2024-04-06 23:09:36,568 - train - INFO - Train: 8 [ 200/781 ( 26%)]  Loss:  3.114069 (3.8385)  Time: 1.094s,  117.02/s  (0.940s,  136.20/s)  LR: 4.002e-04  Data: 0.008 (0.009)
2024-04-06 23:10:23,752 - train - INFO - Train: 8 [ 250/781 ( 32%)]  Loss:  4.364197 (3.8291)  Time: 0.852s,  150.29/s  (0.941s,  136.09/s)  LR: 4.002e-04  Data: 0.009 (0.009)
2024-04-06 23:11:10,135 - train - INFO - Train: 8 [ 300/781 ( 38%)]  Loss:  3.536818 (3.8235)  Time: 0.844s,  151.74/s  (0.938s,  136.40/s)  LR: 4.002e-04  Data: 0.006 (0.009)
2024-04-06 23:11:56,411 - train - INFO - Train: 8 [ 350/781 ( 45%)]  Loss:  3.307185 (3.8259)  Time: 0.843s,  151.77/s  (0.937s,  136.67/s)  LR: 4.002e-04  Data: 0.008 (0.008)
2024-04-06 23:12:43,779 - train - INFO - Train: 8 [ 400/781 ( 51%)]  Loss:  3.322906 (3.8126)  Time: 0.850s,  150.56/s  (0.938s,  136.48/s)  LR: 4.002e-04  Data: 0.009 (0.008)
2024-04-06 23:13:31,298 - train - INFO - Train: 8 [ 450/781 ( 58%)]  Loss:  3.742134 (3.8181)  Time: 0.809s,  158.21/s  (0.939s,  136.28/s)  LR: 4.002e-04  Data: 0.004 (0.008)
2024-04-06 23:14:18,314 - train - INFO - Train: 8 [ 500/781 ( 64%)]  Loss:  4.340284 (3.8268)  Time: 0.824s,  155.26/s  (0.939s,  136.26/s)  LR: 4.002e-04  Data: 0.006 (0.008)
2024-04-06 23:15:05,045 - train - INFO - Train: 8 [ 550/781 ( 71%)]  Loss:  4.157191 (3.8313)  Time: 0.855s,  149.62/s  (0.939s,  136.32/s)  LR: 4.002e-04  Data: 0.008 (0.008)
2024-04-06 23:15:50,483 - train - INFO - Train: 8 [ 600/781 ( 77%)]  Loss:  3.997998 (3.8380)  Time: 1.111s,  115.18/s  (0.936s,  136.69/s)  LR: 4.002e-04  Data: 0.008 (0.008)
2024-04-06 23:16:36,629 - train - INFO - Train: 8 [ 650/781 ( 83%)]  Loss:  3.187180 (3.8395)  Time: 0.800s,  160.07/s  (0.935s,  136.84/s)  LR: 4.002e-04  Data: 0.004 (0.008)
2024-04-06 23:17:23,588 - train - INFO - Train: 8 [ 700/781 ( 90%)]  Loss:  4.248354 (3.8456)  Time: 0.854s,  149.84/s  (0.936s,  136.80/s)  LR: 4.002e-04  Data: 0.007 (0.008)
2024-04-06 23:18:11,572 - train - INFO - Train: 8 [ 750/781 ( 96%)]  Loss:  3.423774 (3.8480)  Time: 0.863s,  148.28/s  (0.937s,  136.57/s)  LR: 4.002e-04  Data: 0.009 (0.008)
2024-04-06 23:18:39,943 - train - INFO - Train: 8 [ 780/781 (100%)]  Loss:  3.325136 (3.8449)  Time: 1.123s,  113.97/s  (0.938s,  136.52/s)  LR: 4.002e-04  Data: 0.000 (0.008)
2024-04-06 23:18:39,945 - train - INFO - True
2024-04-06 23:18:39,947 - train - INFO - alphas:tensor([0.2798, 0.2395, 0.1534, 0.1615, 0.1658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:39,982 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:39,982 - train - INFO - True
2024-04-06 23:18:39,983 - train - INFO - alphas:tensor([0.3085, 0.2073, 0.1461, 0.1625, 0.1756], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,026 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,026 - train - INFO - True
2024-04-06 23:18:40,027 - train - INFO - alphas:tensor([0.5254, 0.1761, 0.0976, 0.0993, 0.1016], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,056 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,056 - train - INFO - True
2024-04-06 23:18:40,057 - train - INFO - alphas:tensor([0.5155, 0.1620, 0.1005, 0.1093, 0.1127], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,085 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,085 - train - INFO - True
2024-04-06 23:18:40,086 - train - INFO - alphas:tensor([0.4509, 0.1804, 0.1135, 0.1240, 0.1313], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,115 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,115 - train - INFO - True
2024-04-06 23:18:40,116 - train - INFO - alphas:tensor([0.4977, 0.1667, 0.1053, 0.1129, 0.1174], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,144 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,144 - train - INFO - True
2024-04-06 23:18:40,145 - train - INFO - alphas:tensor([0.5919, 0.1536, 0.0810, 0.0843, 0.0891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,176 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,176 - train - INFO - True
2024-04-06 23:18:40,177 - train - INFO - alphas:tensor([0.5785, 0.1567, 0.0884, 0.0880, 0.0884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,206 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,206 - train - INFO - True
2024-04-06 23:18:40,207 - train - INFO - alphas:tensor([0.4933, 0.1631, 0.1051, 0.1155, 0.1231], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,235 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,235 - train - INFO - True
2024-04-06 23:18:40,236 - train - INFO - alphas:tensor([0.5444, 0.1546, 0.0967, 0.0998, 0.1045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,265 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,265 - train - INFO - True
2024-04-06 23:18:40,266 - train - INFO - alphas:tensor([0.6180, 0.1402, 0.0766, 0.0804, 0.0849], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,294 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,294 - train - INFO - True
2024-04-06 23:18:40,295 - train - INFO - alphas:tensor([0.5710, 0.1510, 0.0915, 0.0938, 0.0927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,323 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,324 - train - INFO - True
2024-04-06 23:18:40,325 - train - INFO - alphas:tensor([0.5146, 0.1568, 0.0991, 0.1108, 0.1187], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,355 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,355 - train - INFO - True
2024-04-06 23:18:40,356 - train - INFO - alphas:tensor([0.5803, 0.1353, 0.0919, 0.0946, 0.0980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,384 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,384 - train - INFO - True
2024-04-06 23:18:40,385 - train - INFO - alphas:tensor([0.6020, 0.1514, 0.0828, 0.0806, 0.0832], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,414 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,414 - train - INFO - True
2024-04-06 23:18:40,415 - train - INFO - alphas:tensor([0.5443, 0.1641, 0.0962, 0.0948, 0.1006], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,443 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,443 - train - INFO - True
2024-04-06 23:18:40,444 - train - INFO - alphas:tensor([0.5223, 0.1565, 0.0964, 0.1080, 0.1169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,472 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,472 - train - INFO - True
2024-04-06 23:18:40,474 - train - INFO - alphas:tensor([0.5891, 0.1327, 0.0908, 0.0932, 0.0943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,502 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,502 - train - INFO - True
2024-04-06 23:18:40,503 - train - INFO - alphas:tensor([0.6200, 0.1392, 0.0796, 0.0799, 0.0813], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,531 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,531 - train - INFO - True
2024-04-06 23:18:40,532 - train - INFO - alphas:tensor([0.5425, 0.1557, 0.1001, 0.1002, 0.1014], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,563 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,563 - train - INFO - True
2024-04-06 23:18:40,564 - train - INFO - alphas:tensor([0.5023, 0.1598, 0.1032, 0.1136, 0.1211], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,593 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,593 - train - INFO - True
2024-04-06 23:18:40,594 - train - INFO - alphas:tensor([0.5933, 0.1287, 0.0899, 0.0926, 0.0954], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,622 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,622 - train - INFO - True
2024-04-06 23:18:40,623 - train - INFO - alphas:tensor([0.6543, 0.1301, 0.0702, 0.0718, 0.0736], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,651 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,652 - train - INFO - True
2024-04-06 23:18:40,653 - train - INFO - alphas:tensor([0.5599, 0.1471, 0.0981, 0.0962, 0.0987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,681 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,681 - train - INFO - True
2024-04-06 23:18:40,682 - train - INFO - alphas:tensor([0.4945, 0.1606, 0.1023, 0.1177, 0.1249], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,709 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,709 - train - INFO - True
2024-04-06 23:18:40,710 - train - INFO - alphas:tensor([0.5799, 0.1312, 0.0937, 0.0948, 0.1004], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,734 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,734 - train - INFO - True
2024-04-06 23:18:40,735 - train - INFO - alphas:tensor([0.6543, 0.1219, 0.0724, 0.0745, 0.0769], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,757 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,757 - train - INFO - True
2024-04-06 23:18:40,758 - train - INFO - alphas:tensor([0.5839, 0.1394, 0.0910, 0.0927, 0.0930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,781 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,781 - train - INFO - True
2024-04-06 23:18:40,782 - train - INFO - alphas:tensor([0.4775, 0.1599, 0.1098, 0.1224, 0.1305], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,801 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,801 - train - INFO - True
2024-04-06 23:18:40,802 - train - INFO - alphas:tensor([0.5808, 0.1309, 0.0916, 0.0956, 0.1012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,821 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,821 - train - INFO - True
2024-04-06 23:18:40,822 - train - INFO - alphas:tensor([0.6345, 0.1241, 0.0764, 0.0803, 0.0847], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,843 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,843 - train - INFO - True
2024-04-06 23:18:40,844 - train - INFO - alphas:tensor([0.5936, 0.1329, 0.0888, 0.0912, 0.0934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,864 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,864 - train - INFO - True
2024-04-06 23:18:40,865 - train - INFO - alphas:tensor([0.4583, 0.1646, 0.1116, 0.1272, 0.1383], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,883 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,883 - train - INFO - True
2024-04-06 23:18:40,884 - train - INFO - alphas:tensor([0.5585, 0.1375, 0.0950, 0.1022, 0.1067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,902 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,902 - train - INFO - True
2024-04-06 23:18:40,903 - train - INFO - alphas:tensor([0.6094, 0.1296, 0.0802, 0.0885, 0.0923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,920 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,920 - train - INFO - True
2024-04-06 23:18:40,921 - train - INFO - alphas:tensor([0.5666, 0.1389, 0.0924, 0.0986, 0.1035], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,940 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,940 - train - INFO - True
2024-04-06 23:18:40,941 - train - INFO - alphas:tensor([0.5492, 0.1249, 0.1551, 0.1707], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:18:40,963 - train - INFO - tau:0.9414801494009999
2024-04-06 23:18:40,963 - train - INFO - avg block size:1.0
2024-04-06 23:18:40,963 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 23:18:40,964 - train - INFO - lasso_alpha:1.2100000000000003e-05
2024-04-06 23:18:41,212 - train - INFO - Test: [   0/78]  Time: 0.244 (0.244)  Loss:  1.0508 (1.0508)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.1875 (92.1875)
2024-04-06 23:18:46,351 - train - INFO - Test: [  50/78]  Time: 0.084 (0.106)  Loss:  1.9521 (1.7916)  Acc@1: 55.4688 (58.0576)  Acc@5: 82.8125 (81.7402)
2024-04-06 23:18:49,106 - train - INFO - Test: [  78/78]  Time: 0.062 (0.103)  Loss:  1.4385 (1.8063)  Acc@1: 56.2500 (57.8100)  Acc@5: 100.0000 (81.2200)
2024-04-06 23:18:50,378 - train - INFO - Train: 9 [   0/781 (  0%)]  Loss:  4.288044 (4.2880)  Time: 1.197s,  106.94/s  (1.197s,  106.94/s)  LR: 4.501e-04  Data: 0.193 (0.193)
2024-04-06 23:19:38,140 - train - INFO - Train: 9 [  50/781 (  6%)]  Loss:  4.384276 (3.8580)  Time: 1.086s,  117.91/s  (0.960s,  133.34/s)  LR: 4.501e-04  Data: 0.007 (0.011)
2024-04-06 23:20:26,802 - train - INFO - Train: 9 [ 100/781 ( 13%)]  Loss:  4.111571 (3.8651)  Time: 0.985s,  129.96/s  (0.967s,  132.43/s)  LR: 4.501e-04  Data: 0.005 (0.010)
2024-04-06 23:21:12,709 - train - INFO - Train: 9 [ 150/781 ( 19%)]  Loss:  3.379429 (3.8658)  Time: 1.062s,  120.51/s  (0.950s,  134.67/s)  LR: 4.501e-04  Data: 0.008 (0.009)
2024-04-06 23:21:58,531 - train - INFO - Train: 9 [ 200/781 ( 26%)]  Loss:  4.168746 (3.8884)  Time: 0.863s,  148.33/s  (0.942s,  135.88/s)  LR: 4.501e-04  Data: 0.008 (0.009)
2024-04-06 23:22:45,481 - train - INFO - Train: 9 [ 250/781 ( 32%)]  Loss:  4.248308 (3.8987)  Time: 1.110s,  115.30/s  (0.941s,  135.97/s)  LR: 4.501e-04  Data: 0.009 (0.009)
2024-04-06 23:23:31,440 - train - INFO - Train: 9 [ 300/781 ( 38%)]  Loss:  3.309784 (3.8838)  Time: 0.858s,  149.18/s  (0.938s,  136.50/s)  LR: 4.501e-04  Data: 0.008 (0.009)
2024-04-06 23:24:20,134 - train - INFO - Train: 9 [ 350/781 ( 45%)]  Loss:  3.335404 (3.8715)  Time: 0.851s,  150.36/s  (0.943s,  135.76/s)  LR: 4.501e-04  Data: 0.009 (0.009)
2024-04-06 23:25:05,446 - train - INFO - Train: 9 [ 400/781 ( 51%)]  Loss:  4.039684 (3.8613)  Time: 0.879s,  145.55/s  (0.938s,  136.42/s)  LR: 4.501e-04  Data: 0.009 (0.009)
2024-04-06 23:25:53,435 - train - INFO - Train: 9 [ 450/781 ( 58%)]  Loss:  3.587705 (3.8584)  Time: 1.095s,  116.86/s  (0.941s,  136.07/s)  LR: 4.501e-04  Data: 0.019 (0.009)
2024-04-06 23:26:39,534 - train - INFO - Train: 9 [ 500/781 ( 64%)]  Loss:  4.206336 (3.8484)  Time: 1.017s,  125.89/s  (0.939s,  136.35/s)  LR: 4.501e-04  Data: 0.008 (0.009)
2024-04-06 23:27:26,053 - train - INFO - Train: 9 [ 550/781 ( 71%)]  Loss:  3.365844 (3.8472)  Time: 0.848s,  150.93/s  (0.938s,  136.46/s)  LR: 4.501e-04  Data: 0.008 (0.009)
2024-04-06 23:28:13,184 - train - INFO - Train: 9 [ 600/781 ( 77%)]  Loss:  3.523130 (3.8595)  Time: 1.143s,  111.97/s  (0.938s,  136.40/s)  LR: 4.501e-04  Data: 0.010 (0.009)
2024-04-06 23:29:00,023 - train - INFO - Train: 9 [ 650/781 ( 83%)]  Loss:  3.769928 (3.8592)  Time: 1.062s,  120.49/s  (0.938s,  136.42/s)  LR: 4.501e-04  Data: 0.007 (0.009)
2024-04-06 23:29:46,035 - train - INFO - Train: 9 [ 700/781 ( 90%)]  Loss:  3.256350 (3.8548)  Time: 1.110s,  115.30/s  (0.937s,  136.61/s)  LR: 4.501e-04  Data: 0.008 (0.009)
2024-04-06 23:30:32,544 - train - INFO - Train: 9 [ 750/781 ( 96%)]  Loss:  3.410552 (3.8574)  Time: 0.849s,  150.74/s  (0.937s,  136.68/s)  LR: 4.501e-04  Data: 0.008 (0.009)
2024-04-06 23:30:59,870 - train - INFO - Train: 9 [ 780/781 (100%)]  Loss:  3.458689 (3.8626)  Time: 0.807s,  158.59/s  (0.936s,  136.82/s)  LR: 4.501e-04  Data: 0.000 (0.009)
2024-04-06 23:30:59,871 - train - INFO - True
2024-04-06 23:30:59,873 - train - INFO - alphas:tensor([0.2861, 0.2349, 0.1517, 0.1612, 0.1661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:30:59,919 - train - INFO - tau:0.9320653479069899
2024-04-06 23:30:59,920 - train - INFO - True
2024-04-06 23:30:59,920 - train - INFO - alphas:tensor([0.3246, 0.1990, 0.1407, 0.1598, 0.1759], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:30:59,940 - train - INFO - tau:0.9320653479069899
2024-04-06 23:30:59,940 - train - INFO - True
2024-04-06 23:30:59,941 - train - INFO - alphas:tensor([0.5585, 0.1602, 0.0913, 0.0937, 0.0963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:30:59,959 - train - INFO - tau:0.9320653479069899
2024-04-06 23:30:59,960 - train - INFO - True
2024-04-06 23:30:59,960 - train - INFO - alphas:tensor([0.5474, 0.1463, 0.0942, 0.1040, 0.1081], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:30:59,978 - train - INFO - tau:0.9320653479069899
2024-04-06 23:30:59,978 - train - INFO - True
2024-04-06 23:30:59,979 - train - INFO - alphas:tensor([0.4728, 0.1658, 0.1094, 0.1218, 0.1302], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:30:59,995 - train - INFO - tau:0.9320653479069899
2024-04-06 23:30:59,996 - train - INFO - True
2024-04-06 23:30:59,996 - train - INFO - alphas:tensor([0.5357, 0.1519, 0.0966, 0.1053, 0.1104], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,013 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,013 - train - INFO - True
2024-04-06 23:31:00,014 - train - INFO - alphas:tensor([0.6364, 0.1331, 0.0727, 0.0763, 0.0815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,031 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,031 - train - INFO - True
2024-04-06 23:31:00,032 - train - INFO - alphas:tensor([0.6266, 0.1366, 0.0780, 0.0788, 0.0799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,053 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,053 - train - INFO - True
2024-04-06 23:31:00,053 - train - INFO - alphas:tensor([0.5152, 0.1481, 0.1008, 0.1132, 0.1227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,073 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,073 - train - INFO - True
2024-04-06 23:31:00,074 - train - INFO - alphas:tensor([0.5791, 0.1398, 0.0891, 0.0934, 0.0986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,092 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,093 - train - INFO - True
2024-04-06 23:31:00,093 - train - INFO - alphas:tensor([0.6586, 0.1226, 0.0684, 0.0729, 0.0775], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,112 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,112 - train - INFO - True
2024-04-06 23:31:00,113 - train - INFO - alphas:tensor([0.6106, 0.1336, 0.0831, 0.0866, 0.0860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,131 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,131 - train - INFO - True
2024-04-06 23:31:00,132 - train - INFO - alphas:tensor([0.5370, 0.1423, 0.0946, 0.1082, 0.1179], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,150 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,150 - train - INFO - True
2024-04-06 23:31:00,151 - train - INFO - alphas:tensor([0.6131, 0.1223, 0.0845, 0.0880, 0.0921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,168 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,168 - train - INFO - True
2024-04-06 23:31:00,169 - train - INFO - alphas:tensor([0.6405, 0.1344, 0.0748, 0.0734, 0.0769], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,186 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,186 - train - INFO - True
2024-04-06 23:31:00,187 - train - INFO - alphas:tensor([0.5793, 0.1471, 0.0888, 0.0891, 0.0958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,208 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,208 - train - INFO - True
2024-04-06 23:31:00,209 - train - INFO - alphas:tensor([0.5434, 0.1413, 0.0923, 0.1062, 0.1169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,229 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,229 - train - INFO - True
2024-04-06 23:31:00,229 - train - INFO - alphas:tensor([0.6234, 0.1182, 0.0835, 0.0867, 0.0883], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,248 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,248 - train - INFO - True
2024-04-06 23:31:00,249 - train - INFO - alphas:tensor([0.6630, 0.1211, 0.0707, 0.0715, 0.0737], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,266 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,266 - train - INFO - True
2024-04-06 23:31:00,267 - train - INFO - alphas:tensor([0.5805, 0.1386, 0.0914, 0.0934, 0.0961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,284 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,284 - train - INFO - True
2024-04-06 23:31:00,285 - train - INFO - alphas:tensor([0.5253, 0.1442, 0.0985, 0.1113, 0.1207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,302 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,302 - train - INFO - True
2024-04-06 23:31:00,302 - train - INFO - alphas:tensor([0.6294, 0.1146, 0.0821, 0.0854, 0.0885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,321 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,321 - train - INFO - True
2024-04-06 23:31:00,321 - train - INFO - alphas:tensor([0.6948, 0.1130, 0.0620, 0.0640, 0.0662], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,342 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,342 - train - INFO - True
2024-04-06 23:31:00,343 - train - INFO - alphas:tensor([0.6035, 0.1277, 0.0880, 0.0886, 0.0921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,363 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,364 - train - INFO - True
2024-04-06 23:31:00,364 - train - INFO - alphas:tensor([0.5221, 0.1431, 0.0970, 0.1147, 0.1231], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,384 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,384 - train - INFO - True
2024-04-06 23:31:00,384 - train - INFO - alphas:tensor([0.6214, 0.1159, 0.0842, 0.0861, 0.0923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,402 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,403 - train - INFO - True
2024-04-06 23:31:00,403 - train - INFO - alphas:tensor([0.6918, 0.1062, 0.0644, 0.0672, 0.0704], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,421 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,421 - train - INFO - True
2024-04-06 23:31:00,421 - train - INFO - alphas:tensor([0.6214, 0.1232, 0.0822, 0.0858, 0.0874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,438 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,438 - train - INFO - True
2024-04-06 23:31:00,439 - train - INFO - alphas:tensor([0.5025, 0.1418, 0.1049, 0.1204, 0.1304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,456 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,456 - train - INFO - True
2024-04-06 23:31:00,457 - train - INFO - alphas:tensor([0.6202, 0.1149, 0.0826, 0.0882, 0.0942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,473 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,473 - train - INFO - True
2024-04-06 23:31:00,474 - train - INFO - alphas:tensor([0.6696, 0.1089, 0.0687, 0.0737, 0.0791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,495 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,496 - train - INFO - True
2024-04-06 23:31:00,496 - train - INFO - alphas:tensor([0.6299, 0.1164, 0.0810, 0.0848, 0.0879], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,516 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,517 - train - INFO - True
2024-04-06 23:31:00,517 - train - INFO - alphas:tensor([0.4808, 0.1452, 0.1073, 0.1264, 0.1403], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,536 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,536 - train - INFO - True
2024-04-06 23:31:00,537 - train - INFO - alphas:tensor([0.5958, 0.1221, 0.0869, 0.0947, 0.1005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,555 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,555 - train - INFO - True
2024-04-06 23:31:00,556 - train - INFO - alphas:tensor([0.6414, 0.1147, 0.0736, 0.0827, 0.0876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,573 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,573 - train - INFO - True
2024-04-06 23:31:00,574 - train - INFO - alphas:tensor([0.6004, 0.1232, 0.0853, 0.0928, 0.0983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,591 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,591 - train - INFO - True
2024-04-06 23:31:00,591 - train - INFO - alphas:tensor([0.5679, 0.1163, 0.1494, 0.1664], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:31:00,608 - train - INFO - tau:0.9320653479069899
2024-04-06 23:31:00,608 - train - INFO - avg block size:1.0
2024-04-06 23:31:00,609 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 23:31:00,840 - train - INFO - Test: [   0/78]  Time: 0.228 (0.228)  Loss:  0.9116 (0.9116)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-06 23:31:05,805 - train - INFO - Test: [  50/78]  Time: 0.086 (0.102)  Loss:  1.9336 (1.7948)  Acc@1: 56.2500 (57.8738)  Acc@5: 77.3438 (81.7708)
2024-04-06 23:31:08,216 - train - INFO - Test: [  78/78]  Time: 0.059 (0.096)  Loss:  1.6797 (1.8110)  Acc@1: 62.5000 (57.9500)  Acc@5: 100.0000 (81.3700)
2024-04-06 23:31:09,344 - train - INFO - Train: 10 [   0/781 (  0%)]  Loss:  3.276075 (3.2761)  Time: 1.056s,  121.18/s  (1.056s,  121.18/s)  LR: 4.946e-04  Data: 0.198 (0.198)
2024-04-06 23:31:55,047 - train - INFO - Train: 10 [  50/781 (  6%)]  Loss:  3.823066 (3.8059)  Time: 0.839s,  152.59/s  (0.917s,  139.61/s)  LR: 4.946e-04  Data: 0.008 (0.011)
2024-04-06 23:32:41,834 - train - INFO - Train: 10 [ 100/781 ( 13%)]  Loss:  3.434951 (3.8120)  Time: 1.069s,  119.76/s  (0.926s,  138.20/s)  LR: 4.946e-04  Data: 0.008 (0.010)
2024-04-06 23:33:30,373 - train - INFO - Train: 10 [ 150/781 ( 19%)]  Loss:  4.130700 (3.8214)  Time: 1.125s,  113.82/s  (0.941s,  136.04/s)  LR: 4.946e-04  Data: 0.014 (0.009)
2024-04-06 23:34:16,551 - train - INFO - Train: 10 [ 200/781 ( 26%)]  Loss:  3.437976 (3.8189)  Time: 1.083s,  118.23/s  (0.937s,  136.66/s)  LR: 4.946e-04  Data: 0.007 (0.009)
2024-04-06 23:35:02,510 - train - INFO - Train: 10 [ 250/781 ( 32%)]  Loss:  3.519780 (3.8176)  Time: 0.850s,  150.59/s  (0.933s,  137.17/s)  LR: 4.946e-04  Data: 0.008 (0.009)
2024-04-06 23:35:48,397 - train - INFO - Train: 10 [ 300/781 ( 38%)]  Loss:  3.750295 (3.8241)  Time: 0.866s,  147.84/s  (0.931s,  137.55/s)  LR: 4.946e-04  Data: 0.008 (0.008)
2024-04-06 23:36:34,670 - train - INFO - Train: 10 [ 350/781 ( 45%)]  Loss:  4.341199 (3.8352)  Time: 1.082s,  118.35/s  (0.930s,  137.66/s)  LR: 4.946e-04  Data: 0.007 (0.008)
2024-04-06 23:37:21,421 - train - INFO - Train: 10 [ 400/781 ( 51%)]  Loss:  4.117459 (3.8448)  Time: 1.051s,  121.82/s  (0.930s,  137.56/s)  LR: 4.946e-04  Data: 0.007 (0.008)
2024-04-06 23:38:09,083 - train - INFO - Train: 10 [ 450/781 ( 58%)]  Loss:  3.521920 (3.8508)  Time: 1.031s,  124.17/s  (0.933s,  137.19/s)  LR: 4.946e-04  Data: 0.006 (0.008)
2024-04-06 23:38:56,761 - train - INFO - Train: 10 [ 500/781 ( 64%)]  Loss:  3.257613 (3.8487)  Time: 0.773s,  165.52/s  (0.935s,  136.89/s)  LR: 4.946e-04  Data: 0.006 (0.008)
2024-04-06 23:39:43,417 - train - INFO - Train: 10 [ 550/781 ( 71%)]  Loss:  3.529908 (3.8480)  Time: 0.876s,  146.19/s  (0.935s,  136.92/s)  LR: 4.946e-04  Data: 0.007 (0.008)
2024-04-06 23:40:30,476 - train - INFO - Train: 10 [ 600/781 ( 77%)]  Loss:  3.825661 (3.8442)  Time: 0.767s,  166.99/s  (0.935s,  136.84/s)  LR: 4.946e-04  Data: 0.005 (0.008)
2024-04-06 23:41:16,044 - train - INFO - Train: 10 [ 650/781 ( 83%)]  Loss:  3.616456 (3.8442)  Time: 0.922s,  138.80/s  (0.934s,  137.11/s)  LR: 4.946e-04  Data: 0.012 (0.008)
2024-04-06 23:42:03,282 - train - INFO - Train: 10 [ 700/781 ( 90%)]  Loss:  4.451321 (3.8474)  Time: 0.817s,  156.58/s  (0.934s,  137.00/s)  LR: 4.946e-04  Data: 0.006 (0.008)
2024-04-06 23:42:49,394 - train - INFO - Train: 10 [ 750/781 ( 96%)]  Loss:  3.264398 (3.8489)  Time: 0.790s,  162.13/s  (0.934s,  137.11/s)  LR: 4.946e-04  Data: 0.006 (0.008)
2024-04-06 23:43:18,187 - train - INFO - Train: 10 [ 780/781 (100%)]  Loss:  4.263067 (3.8490)  Time: 0.956s,  133.84/s  (0.935s,  136.97/s)  LR: 4.946e-04  Data: 0.000 (0.008)
2024-04-06 23:43:18,188 - train - INFO - True
2024-04-06 23:43:18,190 - train - INFO - alphas:tensor([0.2923, 0.2290, 0.1505, 0.1613, 0.1669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,234 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,235 - train - INFO - True
2024-04-06 23:43:18,236 - train - INFO - alphas:tensor([0.3393, 0.1877, 0.1364, 0.1587, 0.1779], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,271 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,271 - train - INFO - True
2024-04-06 23:43:18,272 - train - INFO - alphas:tensor([0.5897, 0.1459, 0.0852, 0.0881, 0.0910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,301 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,301 - train - INFO - True
2024-04-06 23:43:18,302 - train - INFO - alphas:tensor([0.5775, 0.1325, 0.0880, 0.0984, 0.1035], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,328 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,328 - train - INFO - True
2024-04-06 23:43:18,329 - train - INFO - alphas:tensor([0.4900, 0.1530, 0.1064, 0.1205, 0.1302], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,353 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,353 - train - INFO - True
2024-04-06 23:43:18,354 - train - INFO - alphas:tensor([0.5668, 0.1392, 0.0899, 0.0993, 0.1049], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,376 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,376 - train - INFO - True
2024-04-06 23:43:18,377 - train - INFO - alphas:tensor([0.6704, 0.1182, 0.0660, 0.0699, 0.0754], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,397 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,397 - train - INFO - True
2024-04-06 23:43:18,398 - train - INFO - alphas:tensor([0.6655, 0.1200, 0.0698, 0.0716, 0.0731], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,419 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,419 - train - INFO - True
2024-04-06 23:43:18,420 - train - INFO - alphas:tensor([0.5322, 0.1357, 0.0974, 0.1118, 0.1230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,440 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,441 - train - INFO - True
2024-04-06 23:43:18,441 - train - INFO - alphas:tensor([0.6069, 0.1271, 0.0832, 0.0885, 0.0945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,460 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,460 - train - INFO - True
2024-04-06 23:43:18,461 - train - INFO - alphas:tensor([0.6891, 0.1086, 0.0626, 0.0674, 0.0723], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,479 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,479 - train - INFO - True
2024-04-06 23:43:18,480 - train - INFO - alphas:tensor([0.6447, 0.1192, 0.0755, 0.0801, 0.0804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,497 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,497 - train - INFO - True
2024-04-06 23:43:18,498 - train - INFO - alphas:tensor([0.5536, 0.1295, 0.0912, 0.1070, 0.1187], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,514 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,514 - train - INFO - True
2024-04-06 23:43:18,515 - train - INFO - alphas:tensor([0.6347, 0.1126, 0.0797, 0.0843, 0.0888], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,532 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,532 - train - INFO - True
2024-04-06 23:43:18,532 - train - INFO - alphas:tensor([0.6721, 0.1198, 0.0684, 0.0679, 0.0718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,553 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,553 - train - INFO - True
2024-04-06 23:43:18,554 - train - INFO - alphas:tensor([0.6084, 0.1323, 0.0825, 0.0845, 0.0923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,574 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,574 - train - INFO - True
2024-04-06 23:43:18,575 - train - INFO - alphas:tensor([0.5603, 0.1283, 0.0886, 0.1050, 0.1176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,594 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,594 - train - INFO - True
2024-04-06 23:43:18,595 - train - INFO - alphas:tensor([0.6481, 0.1076, 0.0779, 0.0820, 0.0844], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,613 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,613 - train - INFO - True
2024-04-06 23:43:18,614 - train - INFO - alphas:tensor([0.6965, 0.1069, 0.0637, 0.0652, 0.0677], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,631 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,631 - train - INFO - True
2024-04-06 23:43:18,632 - train - INFO - alphas:tensor([0.6085, 0.1239, 0.0854, 0.0891, 0.0931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,649 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,649 - train - INFO - True
2024-04-06 23:43:18,649 - train - INFO - alphas:tensor([0.5449, 0.1299, 0.0944, 0.1098, 0.1210], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,667 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,667 - train - INFO - True
2024-04-06 23:43:18,668 - train - INFO - alphas:tensor([0.6601, 0.1030, 0.0750, 0.0789, 0.0829], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,686 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,686 - train - INFO - True
2024-04-06 23:43:18,687 - train - INFO - alphas:tensor([0.7238, 0.1007, 0.0560, 0.0583, 0.0611], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,704 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,704 - train - INFO - True
2024-04-06 23:43:18,705 - train - INFO - alphas:tensor([0.6324, 0.1140, 0.0814, 0.0838, 0.0884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,724 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,725 - train - INFO - True
2024-04-06 23:43:18,725 - train - INFO - alphas:tensor([0.5394, 0.1297, 0.0937, 0.1134, 0.1238], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,746 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,746 - train - INFO - True
2024-04-06 23:43:18,747 - train - INFO - alphas:tensor([0.6510, 0.1044, 0.0774, 0.0802, 0.0869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,767 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,767 - train - INFO - True
2024-04-06 23:43:18,767 - train - INFO - alphas:tensor([0.7157, 0.0955, 0.0593, 0.0626, 0.0670], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,786 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,786 - train - INFO - True
2024-04-06 23:43:18,787 - train - INFO - alphas:tensor([0.6462, 0.1102, 0.0767, 0.0818, 0.0851], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,804 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,804 - train - INFO - True
2024-04-06 23:43:18,805 - train - INFO - alphas:tensor([0.5213, 0.1278, 0.1009, 0.1189, 0.1312], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,822 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,822 - train - INFO - True
2024-04-06 23:43:18,823 - train - INFO - alphas:tensor([0.6471, 0.1033, 0.0764, 0.0832, 0.0899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,841 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,841 - train - INFO - True
2024-04-06 23:43:18,842 - train - INFO - alphas:tensor([0.6906, 0.0989, 0.0640, 0.0700, 0.0765], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,859 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,859 - train - INFO - True
2024-04-06 23:43:18,859 - train - INFO - alphas:tensor([0.6535, 0.1049, 0.0754, 0.0810, 0.0852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,879 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,879 - train - INFO - True
2024-04-06 23:43:18,880 - train - INFO - alphas:tensor([0.4971, 0.1293, 0.1038, 0.1265, 0.1434], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,901 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,901 - train - INFO - True
2024-04-06 23:43:18,902 - train - INFO - alphas:tensor([0.6213, 0.1100, 0.0815, 0.0902, 0.0970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,921 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,921 - train - INFO - True
2024-04-06 23:43:18,922 - train - INFO - alphas:tensor([0.6622, 0.1045, 0.0690, 0.0790, 0.0853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,941 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,941 - train - INFO - True
2024-04-06 23:43:18,941 - train - INFO - alphas:tensor([0.6268, 0.1104, 0.0795, 0.0883, 0.0951], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,959 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,959 - train - INFO - True
2024-04-06 23:43:18,960 - train - INFO - alphas:tensor([0.5826, 0.1094, 0.1450, 0.1630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:43:18,977 - train - INFO - tau:0.92274469442792
2024-04-06 23:43:18,977 - train - INFO - avg block size:1.0
2024-04-06 23:43:18,977 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 23:43:18,977 - train - INFO - lasso_alpha:1.3310000000000005e-05
2024-04-06 23:43:19,174 - train - INFO - Test: [   0/78]  Time: 0.194 (0.194)  Loss:  1.0576 (1.0576)  Acc@1: 76.5625 (76.5625)  Acc@5: 90.6250 (90.6250)
2024-04-06 23:43:24,100 - train - INFO - Test: [  50/78]  Time: 0.088 (0.100)  Loss:  1.8555 (1.7742)  Acc@1: 56.2500 (58.2567)  Acc@5: 82.0312 (82.0159)
2024-04-06 23:43:26,887 - train - INFO - Test: [  78/78]  Time: 0.064 (0.100)  Loss:  1.6357 (1.8093)  Acc@1: 62.5000 (57.7200)  Acc@5: 93.7500 (81.5600)
2024-04-06 23:43:28,245 - train - INFO - Train: 11 [   0/781 (  0%)]  Loss:  4.363838 (4.3638)  Time: 1.284s,   99.70/s  (1.284s,   99.70/s)  LR: 4.935e-04  Data: 0.211 (0.211)
2024-04-06 23:44:14,376 - train - INFO - Train: 11 [  50/781 (  6%)]  Loss:  3.631547 (3.8859)  Time: 0.876s,  146.05/s  (0.930s,  137.68/s)  LR: 4.935e-04  Data: 0.007 (0.011)
2024-04-06 23:45:01,513 - train - INFO - Train: 11 [ 100/781 ( 13%)]  Loss:  3.546855 (3.8520)  Time: 0.833s,  153.65/s  (0.936s,  136.73/s)  LR: 4.935e-04  Data: 0.011 (0.010)
2024-04-06 23:45:48,297 - train - INFO - Train: 11 [ 150/781 ( 19%)]  Loss:  4.303113 (3.8369)  Time: 1.054s,  121.46/s  (0.936s,  136.76/s)  LR: 4.935e-04  Data: 0.020 (0.009)
2024-04-06 23:46:35,821 - train - INFO - Train: 11 [ 200/781 ( 26%)]  Loss:  3.786788 (3.8502)  Time: 1.061s,  120.63/s  (0.940s,  136.23/s)  LR: 4.935e-04  Data: 0.007 (0.009)
2024-04-06 23:47:22,839 - train - INFO - Train: 11 [ 250/781 ( 32%)]  Loss:  3.411032 (3.8375)  Time: 0.874s,  146.39/s  (0.940s,  136.21/s)  LR: 4.935e-04  Data: 0.008 (0.009)
2024-04-06 23:48:09,551 - train - INFO - Train: 11 [ 300/781 ( 38%)]  Loss:  4.361657 (3.8473)  Time: 1.078s,  118.74/s  (0.939s,  136.34/s)  LR: 4.935e-04  Data: 0.009 (0.009)
2024-04-06 23:48:55,848 - train - INFO - Train: 11 [ 350/781 ( 45%)]  Loss:  3.646168 (3.8452)  Time: 0.939s,  136.34/s  (0.937s,  136.61/s)  LR: 4.935e-04  Data: 0.006 (0.009)
2024-04-06 23:49:42,916 - train - INFO - Train: 11 [ 400/781 ( 51%)]  Loss:  3.587752 (3.8502)  Time: 0.840s,  152.32/s  (0.938s,  136.53/s)  LR: 4.935e-04  Data: 0.010 (0.008)
2024-04-06 23:50:28,112 - train - INFO - Train: 11 [ 450/781 ( 58%)]  Loss:  3.741321 (3.8449)  Time: 0.775s,  165.15/s  (0.934s,  137.08/s)  LR: 4.935e-04  Data: 0.005 (0.008)
2024-04-06 23:51:13,635 - train - INFO - Train: 11 [ 500/781 ( 64%)]  Loss:  4.045697 (3.8531)  Time: 0.773s,  165.59/s  (0.931s,  137.42/s)  LR: 4.935e-04  Data: 0.005 (0.008)
2024-04-06 23:51:59,630 - train - INFO - Train: 11 [ 550/781 ( 71%)]  Loss:  3.638105 (3.8505)  Time: 0.855s,  149.68/s  (0.930s,  137.58/s)  LR: 4.935e-04  Data: 0.008 (0.008)
2024-04-06 23:52:44,772 - train - INFO - Train: 11 [ 600/781 ( 77%)]  Loss:  3.851315 (3.8488)  Time: 0.863s,  148.25/s  (0.928s,  137.92/s)  LR: 4.935e-04  Data: 0.008 (0.008)
2024-04-06 23:53:32,328 - train - INFO - Train: 11 [ 650/781 ( 83%)]  Loss:  3.936589 (3.8472)  Time: 0.833s,  153.59/s  (0.930s,  137.65/s)  LR: 4.935e-04  Data: 0.007 (0.009)
2024-04-06 23:54:19,281 - train - INFO - Train: 11 [ 700/781 ( 90%)]  Loss:  3.817063 (3.8450)  Time: 1.017s,  125.89/s  (0.931s,  137.56/s)  LR: 4.935e-04  Data: 0.013 (0.008)
2024-04-06 23:55:07,123 - train - INFO - Train: 11 [ 750/781 ( 96%)]  Loss:  4.053198 (3.8420)  Time: 1.015s,  126.11/s  (0.932s,  137.30/s)  LR: 4.935e-04  Data: 0.012 (0.008)
2024-04-06 23:55:33,917 - train - INFO - Train: 11 [ 780/781 (100%)]  Loss:  4.291404 (3.8405)  Time: 0.798s,  160.31/s  (0.931s,  137.52/s)  LR: 4.935e-04  Data: 0.000 (0.008)
2024-04-06 23:55:33,918 - train - INFO - True
2024-04-06 23:55:33,920 - train - INFO - alphas:tensor([0.2968, 0.2232, 0.1495, 0.1620, 0.1685], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:33,976 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:33,976 - train - INFO - True
2024-04-06 23:55:33,977 - train - INFO - alphas:tensor([0.3497, 0.1778, 0.1332, 0.1586, 0.1807], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,010 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,010 - train - INFO - True
2024-04-06 23:55:34,011 - train - INFO - alphas:tensor([0.6115, 0.1357, 0.0811, 0.0843, 0.0874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,039 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,040 - train - INFO - True
2024-04-06 23:55:34,040 - train - INFO - alphas:tensor([0.5994, 0.1224, 0.0833, 0.0947, 0.1002], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,066 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,066 - train - INFO - True
2024-04-06 23:55:34,067 - train - INFO - alphas:tensor([0.5018, 0.1425, 0.1043, 0.1199, 0.1314], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,091 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,091 - train - INFO - True
2024-04-06 23:55:34,092 - train - INFO - alphas:tensor([0.5890, 0.1291, 0.0851, 0.0951, 0.1016], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,114 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,114 - train - INFO - True
2024-04-06 23:55:34,114 - train - INFO - alphas:tensor([0.6968, 0.1064, 0.0606, 0.0652, 0.0710], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,135 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,135 - train - INFO - True
2024-04-06 23:55:34,136 - train - INFO - alphas:tensor([0.6942, 0.1077, 0.0637, 0.0663, 0.0682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,155 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,155 - train - INFO - True
2024-04-06 23:55:34,156 - train - INFO - alphas:tensor([0.5437, 0.1262, 0.0949, 0.1113, 0.1239], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,174 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,174 - train - INFO - True
2024-04-06 23:55:34,175 - train - INFO - alphas:tensor([0.6257, 0.1183, 0.0794, 0.0851, 0.0915], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,192 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,192 - train - INFO - True
2024-04-06 23:55:34,193 - train - INFO - alphas:tensor([0.7060, 0.1004, 0.0592, 0.0645, 0.0699], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,210 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,210 - train - INFO - True
2024-04-06 23:55:34,210 - train - INFO - alphas:tensor([0.6648, 0.1092, 0.0713, 0.0769, 0.0779], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,227 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,227 - train - INFO - True
2024-04-06 23:55:34,228 - train - INFO - alphas:tensor([0.5648, 0.1205, 0.0887, 0.1063, 0.1198], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,248 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,248 - train - INFO - True
2024-04-06 23:55:34,249 - train - INFO - alphas:tensor([0.6539, 0.1045, 0.0752, 0.0804, 0.0860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,269 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,269 - train - INFO - True
2024-04-06 23:55:34,270 - train - INFO - alphas:tensor([0.6930, 0.1100, 0.0640, 0.0643, 0.0688], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,289 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,289 - train - INFO - True
2024-04-06 23:55:34,289 - train - INFO - alphas:tensor([0.6249, 0.1216, 0.0792, 0.0827, 0.0915], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,307 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,308 - train - INFO - True
2024-04-06 23:55:34,308 - train - INFO - alphas:tensor([0.5719, 0.1186, 0.0859, 0.1047, 0.1190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,325 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,325 - train - INFO - True
2024-04-06 23:55:34,326 - train - INFO - alphas:tensor([0.6670, 0.0993, 0.0736, 0.0784, 0.0817], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,343 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,343 - train - INFO - True
2024-04-06 23:55:34,344 - train - INFO - alphas:tensor([0.7142, 0.0987, 0.0599, 0.0620, 0.0653], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,360 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,360 - train - INFO - True
2024-04-06 23:55:34,361 - train - INFO - alphas:tensor([0.6199, 0.1154, 0.0824, 0.0883, 0.0939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,378 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,378 - train - INFO - True
2024-04-06 23:55:34,378 - train - INFO - alphas:tensor([0.5548, 0.1198, 0.0923, 0.1099, 0.1230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,397 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,397 - train - INFO - True
2024-04-06 23:55:34,397 - train - INFO - alphas:tensor([0.6828, 0.0938, 0.0699, 0.0745, 0.0790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,418 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,418 - train - INFO - True
2024-04-06 23:55:34,419 - train - INFO - alphas:tensor([0.7386, 0.0938, 0.0529, 0.0558, 0.0589], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,438 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,438 - train - INFO - True
2024-04-06 23:55:34,439 - train - INFO - alphas:tensor([0.6468, 0.1043, 0.0780, 0.0823, 0.0886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,457 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,457 - train - INFO - True
2024-04-06 23:55:34,457 - train - INFO - alphas:tensor([0.5521, 0.1184, 0.0908, 0.1132, 0.1254], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,474 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,474 - train - INFO - True
2024-04-06 23:55:34,475 - train - INFO - alphas:tensor([0.6718, 0.0954, 0.0725, 0.0765, 0.0837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,492 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,492 - train - INFO - True
2024-04-06 23:55:34,492 - train - INFO - alphas:tensor([0.7325, 0.0876, 0.0554, 0.0597, 0.0648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,509 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,509 - train - INFO - True
2024-04-06 23:55:34,510 - train - INFO - alphas:tensor([0.6603, 0.1015, 0.0731, 0.0799, 0.0853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,527 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,527 - train - INFO - True
2024-04-06 23:55:34,527 - train - INFO - alphas:tensor([0.5326, 0.1161, 0.0983, 0.1191, 0.1339], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,547 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,547 - train - INFO - True
2024-04-06 23:55:34,548 - train - INFO - alphas:tensor([0.6656, 0.0954, 0.0723, 0.0793, 0.0873], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,568 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,569 - train - INFO - True
2024-04-06 23:55:34,569 - train - INFO - alphas:tensor([0.7043, 0.0907, 0.0611, 0.0681, 0.0758], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,588 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,589 - train - INFO - True
2024-04-06 23:55:34,589 - train - INFO - alphas:tensor([0.6712, 0.0952, 0.0713, 0.0786, 0.0837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,608 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,608 - train - INFO - True
2024-04-06 23:55:34,608 - train - INFO - alphas:tensor([0.5091, 0.1163, 0.1008, 0.1271, 0.1467], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,626 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,626 - train - INFO - True
2024-04-06 23:55:34,626 - train - INFO - alphas:tensor([0.6387, 0.1011, 0.0771, 0.0875, 0.0957], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,643 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,643 - train - INFO - True
2024-04-06 23:55:34,644 - train - INFO - alphas:tensor([0.6741, 0.0972, 0.0659, 0.0777, 0.0851], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,660 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,660 - train - INFO - True
2024-04-06 23:55:34,661 - train - INFO - alphas:tensor([0.6436, 0.1005, 0.0756, 0.0862, 0.0940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,678 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,679 - train - INFO - True
2024-04-06 23:55:34,679 - train - INFO - alphas:tensor([0.5938, 0.1045, 0.1413, 0.1605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-06 23:55:34,701 - train - INFO - tau:0.9135172474836407
2024-04-06 23:55:34,701 - train - INFO - avg block size:1.0
2024-04-06 23:55:34,701 - train - INFO - current latency ratio:tensor(1.)
2024-04-06 23:55:34,948 - train - INFO - Test: [   0/78]  Time: 0.244 (0.244)  Loss:  0.9907 (0.9907)  Acc@1: 78.9062 (78.9062)  Acc@5: 92.1875 (92.1875)
2024-04-06 23:55:39,635 - train - INFO - Test: [  50/78]  Time: 0.084 (0.097)  Loss:  1.8848 (1.7330)  Acc@1: 53.9062 (59.3750)  Acc@5: 79.6875 (82.5980)
2024-04-06 23:55:42,210 - train - INFO - Test: [  78/78]  Time: 0.079 (0.095)  Loss:  1.6924 (1.7732)  Acc@1: 56.2500 (58.3400)  Acc@5: 93.7500 (82.0200)
2024-04-06 23:55:43,557 - train - INFO - Train: 12 [   0/781 (  0%)]  Loss:  3.389537 (3.3895)  Time: 1.255s,  101.96/s  (1.255s,  101.96/s)  LR: 4.923e-04  Data: 0.203 (0.203)
2024-04-06 23:56:29,316 - train - INFO - Train: 12 [  50/781 (  6%)]  Loss:  4.199874 (3.9607)  Time: 0.863s,  148.39/s  (0.922s,  138.86/s)  LR: 4.923e-04  Data: 0.009 (0.012)
2024-04-06 23:57:13,730 - train - INFO - Train: 12 [ 100/781 ( 13%)]  Loss:  3.972301 (3.9215)  Time: 1.021s,  125.31/s  (0.905s,  141.41/s)  LR: 4.923e-04  Data: 0.005 (0.010)
2024-04-06 23:58:01,053 - train - INFO - Train: 12 [ 150/781 ( 19%)]  Loss:  4.204420 (3.8910)  Time: 0.831s,  154.00/s  (0.919s,  139.30/s)  LR: 4.923e-04  Data: 0.006 (0.009)
2024-04-06 23:58:49,594 - train - INFO - Train: 12 [ 200/781 ( 26%)]  Loss:  3.875196 (3.8873)  Time: 1.101s,  116.31/s  (0.932s,  137.37/s)  LR: 4.923e-04  Data: 0.010 (0.009)
2024-04-06 23:59:35,520 - train - INFO - Train: 12 [ 250/781 ( 32%)]  Loss:  3.659166 (3.8876)  Time: 0.849s,  150.77/s  (0.929s,  137.76/s)  LR: 4.923e-04  Data: 0.008 (0.009)
2024-04-07 00:00:23,249 - train - INFO - Train: 12 [ 300/781 ( 38%)]  Loss:  3.586874 (3.8787)  Time: 1.076s,  118.91/s  (0.933s,  137.14/s)  LR: 4.923e-04  Data: 0.008 (0.009)
2024-04-07 00:01:08,602 - train - INFO - Train: 12 [ 350/781 ( 45%)]  Loss:  3.663530 (3.8700)  Time: 1.054s,  121.44/s  (0.930s,  137.69/s)  LR: 4.923e-04  Data: 0.008 (0.009)
2024-04-07 00:01:54,733 - train - INFO - Train: 12 [ 400/781 ( 51%)]  Loss:  3.616363 (3.8677)  Time: 0.851s,  150.41/s  (0.929s,  137.82/s)  LR: 4.923e-04  Data: 0.008 (0.009)
2024-04-07 00:02:41,381 - train - INFO - Train: 12 [ 450/781 ( 58%)]  Loss:  3.508312 (3.8712)  Time: 0.861s,  148.74/s  (0.929s,  137.75/s)  LR: 4.923e-04  Data: 0.008 (0.009)
2024-04-07 00:03:28,606 - train - INFO - Train: 12 [ 500/781 ( 64%)]  Loss:  4.239027 (3.8683)  Time: 0.824s,  155.34/s  (0.931s,  137.53/s)  LR: 4.923e-04  Data: 0.006 (0.009)
2024-04-07 00:04:14,712 - train - INFO - Train: 12 [ 550/781 ( 71%)]  Loss:  3.227381 (3.8596)  Time: 1.080s,  118.56/s  (0.930s,  137.64/s)  LR: 4.923e-04  Data: 0.008 (0.009)
2024-04-07 00:05:00,678 - train - INFO - Train: 12 [ 600/781 ( 77%)]  Loss:  3.535315 (3.8572)  Time: 1.112s,  115.15/s  (0.929s,  137.78/s)  LR: 4.923e-04  Data: 0.009 (0.009)
2024-04-07 00:05:45,663 - train - INFO - Train: 12 [ 650/781 ( 83%)]  Loss:  3.359784 (3.8544)  Time: 1.054s,  121.41/s  (0.927s,  138.11/s)  LR: 4.923e-04  Data: 0.008 (0.009)
2024-04-07 00:06:33,152 - train - INFO - Train: 12 [ 700/781 ( 90%)]  Loss:  4.044986 (3.8554)  Time: 0.867s,  147.70/s  (0.928s,  137.87/s)  LR: 4.923e-04  Data: 0.008 (0.009)
2024-04-07 00:07:20,683 - train - INFO - Train: 12 [ 750/781 ( 96%)]  Loss:  3.245815 (3.8509)  Time: 0.835s,  153.24/s  (0.930s,  137.65/s)  LR: 4.923e-04  Data: 0.009 (0.008)
2024-04-07 00:07:48,074 - train - INFO - Train: 12 [ 780/781 (100%)]  Loss:  3.799551 (3.8544)  Time: 0.861s,  148.59/s  (0.929s,  137.75/s)  LR: 4.923e-04  Data: 0.000 (0.008)
2024-04-07 00:07:48,075 - train - INFO - True
2024-04-07 00:07:48,077 - train - INFO - alphas:tensor([0.3003, 0.2163, 0.1495, 0.1635, 0.1704], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,112 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,112 - train - INFO - True
2024-04-07 00:07:48,113 - train - INFO - alphas:tensor([0.3581, 0.1696, 0.1306, 0.1580, 0.1837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,142 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,142 - train - INFO - True
2024-04-07 00:07:48,143 - train - INFO - alphas:tensor([0.6321, 0.1267, 0.0769, 0.0805, 0.0838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,169 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,169 - train - INFO - True
2024-04-07 00:07:48,170 - train - INFO - alphas:tensor([0.6190, 0.1143, 0.0790, 0.0908, 0.0969], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,194 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,194 - train - INFO - True
2024-04-07 00:07:48,195 - train - INFO - alphas:tensor([0.5138, 0.1327, 0.1020, 0.1193, 0.1321], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,217 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,217 - train - INFO - True
2024-04-07 00:07:48,217 - train - INFO - alphas:tensor([0.6101, 0.1207, 0.0802, 0.0910, 0.0981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,238 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,238 - train - INFO - True
2024-04-07 00:07:48,239 - train - INFO - alphas:tensor([0.7171, 0.0975, 0.0567, 0.0612, 0.0675], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,259 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,259 - train - INFO - True
2024-04-07 00:07:48,260 - train - INFO - alphas:tensor([0.7145, 0.0987, 0.0594, 0.0626, 0.0648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,281 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,281 - train - INFO - True
2024-04-07 00:07:48,282 - train - INFO - alphas:tensor([0.5545, 0.1179, 0.0924, 0.1106, 0.1246], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,302 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,302 - train - INFO - True
2024-04-07 00:07:48,303 - train - INFO - alphas:tensor([0.6420, 0.1116, 0.0757, 0.0818, 0.0890], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,322 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,322 - train - INFO - True
2024-04-07 00:07:48,322 - train - INFO - alphas:tensor([0.7221, 0.0933, 0.0560, 0.0613, 0.0673], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,340 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,340 - train - INFO - True
2024-04-07 00:07:48,341 - train - INFO - alphas:tensor([0.6830, 0.1004, 0.0673, 0.0739, 0.0755], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,358 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,358 - train - INFO - True
2024-04-07 00:07:48,359 - train - INFO - alphas:tensor([0.5733, 0.1127, 0.0865, 0.1061, 0.1214], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,377 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,378 - train - INFO - True
2024-04-07 00:07:48,378 - train - INFO - alphas:tensor([0.6676, 0.0978, 0.0718, 0.0782, 0.0845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,399 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,399 - train - INFO - True
2024-04-07 00:07:48,400 - train - INFO - alphas:tensor([0.7077, 0.1023, 0.0608, 0.0621, 0.0672], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,419 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,419 - train - INFO - True
2024-04-07 00:07:48,419 - train - INFO - alphas:tensor([0.6355, 0.1137, 0.0764, 0.0820, 0.0924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,437 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,437 - train - INFO - True
2024-04-07 00:07:48,438 - train - INFO - alphas:tensor([0.5799, 0.1115, 0.0838, 0.1045, 0.1204], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,455 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,455 - train - INFO - True
2024-04-07 00:07:48,456 - train - INFO - alphas:tensor([0.6817, 0.0931, 0.0698, 0.0756, 0.0796], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,473 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,473 - train - INFO - True
2024-04-07 00:07:48,473 - train - INFO - alphas:tensor([0.7290, 0.0922, 0.0566, 0.0592, 0.0630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,490 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,490 - train - INFO - True
2024-04-07 00:07:48,491 - train - INFO - alphas:tensor([0.6303, 0.1069, 0.0797, 0.0880, 0.0951], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,512 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,512 - train - INFO - True
2024-04-07 00:07:48,513 - train - INFO - alphas:tensor([0.5653, 0.1117, 0.0898, 0.1093, 0.1239], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,532 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,532 - train - INFO - True
2024-04-07 00:07:48,533 - train - INFO - alphas:tensor([0.6980, 0.0878, 0.0662, 0.0716, 0.0765], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,551 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,551 - train - INFO - True
2024-04-07 00:07:48,552 - train - INFO - alphas:tensor([0.7490, 0.0881, 0.0508, 0.0541, 0.0580], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,570 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,570 - train - INFO - True
2024-04-07 00:07:48,571 - train - INFO - alphas:tensor([0.6554, 0.0979, 0.0752, 0.0816, 0.0899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,588 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,588 - train - INFO - True
2024-04-07 00:07:48,588 - train - INFO - alphas:tensor([0.5605, 0.1100, 0.0886, 0.1132, 0.1277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,605 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,605 - train - INFO - True
2024-04-07 00:07:48,606 - train - INFO - alphas:tensor([0.6875, 0.0882, 0.0686, 0.0738, 0.0819], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,627 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,627 - train - INFO - True
2024-04-07 00:07:48,628 - train - INFO - alphas:tensor([0.7413, 0.0821, 0.0535, 0.0585, 0.0645], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,648 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,648 - train - INFO - True
2024-04-07 00:07:48,649 - train - INFO - alphas:tensor([0.6698, 0.0938, 0.0702, 0.0792, 0.0869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,668 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,668 - train - INFO - True
2024-04-07 00:07:48,669 - train - INFO - alphas:tensor([0.5423, 0.1066, 0.0961, 0.1191, 0.1359], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,687 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,687 - train - INFO - True
2024-04-07 00:07:48,688 - train - INFO - alphas:tensor([0.6795, 0.0889, 0.0691, 0.0769, 0.0857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,705 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,705 - train - INFO - True
2024-04-07 00:07:48,706 - train - INFO - alphas:tensor([0.7161, 0.0844, 0.0582, 0.0662, 0.0751], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,722 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,722 - train - INFO - True
2024-04-07 00:07:48,723 - train - INFO - alphas:tensor([0.6835, 0.0880, 0.0685, 0.0767, 0.0833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,744 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,744 - train - INFO - True
2024-04-07 00:07:48,745 - train - INFO - alphas:tensor([0.5189, 0.1062, 0.0983, 0.1271, 0.1495], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,765 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,765 - train - INFO - True
2024-04-07 00:07:48,766 - train - INFO - alphas:tensor([0.6533, 0.0931, 0.0738, 0.0851, 0.0947], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,785 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,785 - train - INFO - True
2024-04-07 00:07:48,786 - train - INFO - alphas:tensor([0.6839, 0.0905, 0.0634, 0.0767, 0.0855], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,804 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,804 - train - INFO - True
2024-04-07 00:07:48,805 - train - INFO - alphas:tensor([0.6531, 0.0944, 0.0732, 0.0853, 0.0940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,822 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,822 - train - INFO - True
2024-04-07 00:07:48,822 - train - INFO - alphas:tensor([0.6025, 0.1006, 0.1384, 0.1585], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:07:48,839 - train - INFO - tau:0.9043820750088043
2024-04-07 00:07:48,839 - train - INFO - avg block size:1.0
2024-04-07 00:07:48,840 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 00:07:48,840 - train - INFO - lasso_alpha:1.4641000000000006e-05
2024-04-07 00:07:49,078 - train - INFO - Test: [   0/78]  Time: 0.235 (0.235)  Loss:  1.0107 (1.0107)  Acc@1: 78.1250 (78.1250)  Acc@5: 95.3125 (95.3125)
2024-04-07 00:07:53,851 - train - INFO - Test: [  50/78]  Time: 0.089 (0.098)  Loss:  1.8232 (1.7490)  Acc@1: 52.3438 (59.2525)  Acc@5: 82.8125 (82.1232)
2024-04-07 00:07:56,251 - train - INFO - Test: [  78/78]  Time: 0.058 (0.094)  Loss:  1.8242 (1.7709)  Acc@1: 62.5000 (58.9700)  Acc@5: 81.2500 (81.6400)
2024-04-07 00:07:57,376 - train - INFO - Train: 13 [   0/781 (  0%)]  Loss:  3.838801 (3.8388)  Time: 1.059s,  120.87/s  (1.059s,  120.87/s)  LR: 4.910e-04  Data: 0.178 (0.178)
2024-04-07 00:08:45,826 - train - INFO - Train: 13 [  50/781 (  6%)]  Loss:  4.268328 (3.8378)  Time: 0.873s,  146.61/s  (0.971s,  131.86/s)  LR: 4.910e-04  Data: 0.008 (0.012)
2024-04-07 00:09:34,172 - train - INFO - Train: 13 [ 100/781 ( 13%)]  Loss:  3.973338 (3.8724)  Time: 0.816s,  156.93/s  (0.969s,  132.12/s)  LR: 4.910e-04  Data: 0.008 (0.010)
2024-04-07 00:10:20,377 - train - INFO - Train: 13 [ 150/781 ( 19%)]  Loss:  3.535627 (3.8752)  Time: 0.900s,  142.28/s  (0.954s,  134.17/s)  LR: 4.910e-04  Data: 0.009 (0.010)
2024-04-07 00:11:06,912 - train - INFO - Train: 13 [ 200/781 ( 26%)]  Loss:  3.373697 (3.8489)  Time: 1.079s,  118.66/s  (0.948s,  134.99/s)  LR: 4.910e-04  Data: 0.009 (0.009)
2024-04-07 00:11:52,872 - train - INFO - Train: 13 [ 250/781 ( 32%)]  Loss:  4.347099 (3.8437)  Time: 0.866s,  147.78/s  (0.942s,  135.82/s)  LR: 4.910e-04  Data: 0.008 (0.009)
2024-04-07 00:12:39,759 - train - INFO - Train: 13 [ 300/781 ( 38%)]  Loss:  3.533891 (3.8424)  Time: 0.832s,  153.93/s  (0.942s,  135.93/s)  LR: 4.910e-04  Data: 0.009 (0.009)
2024-04-07 00:13:25,841 - train - INFO - Train: 13 [ 350/781 ( 45%)]  Loss:  4.140702 (3.8334)  Time: 0.900s,  142.23/s  (0.939s,  136.35/s)  LR: 4.910e-04  Data: 0.008 (0.009)
2024-04-07 00:14:13,427 - train - INFO - Train: 13 [ 400/781 ( 51%)]  Loss:  3.645158 (3.8269)  Time: 0.838s,  152.81/s  (0.940s,  136.11/s)  LR: 4.910e-04  Data: 0.007 (0.009)
2024-04-07 00:14:58,310 - train - INFO - Train: 13 [ 450/781 ( 58%)]  Loss:  3.825596 (3.8296)  Time: 0.849s,  150.82/s  (0.936s,  136.80/s)  LR: 4.910e-04  Data: 0.007 (0.009)
2024-04-07 00:15:45,455 - train - INFO - Train: 13 [ 500/781 ( 64%)]  Loss:  3.303233 (3.8293)  Time: 0.871s,  146.94/s  (0.936s,  136.70/s)  LR: 4.910e-04  Data: 0.011 (0.008)
2024-04-07 00:16:30,723 - train - INFO - Train: 13 [ 550/781 ( 71%)]  Loss:  3.313262 (3.8327)  Time: 0.927s,  138.01/s  (0.934s,  137.11/s)  LR: 4.910e-04  Data: 0.016 (0.008)
2024-04-07 00:17:17,270 - train - INFO - Train: 13 [ 600/781 ( 77%)]  Loss:  3.659524 (3.8348)  Time: 0.815s,  157.00/s  (0.933s,  137.14/s)  LR: 4.910e-04  Data: 0.005 (0.008)
2024-04-07 00:18:04,574 - train - INFO - Train: 13 [ 650/781 ( 83%)]  Loss:  3.326481 (3.8334)  Time: 0.859s,  149.04/s  (0.934s,  137.00/s)  LR: 4.910e-04  Data: 0.020 (0.008)
2024-04-07 00:18:50,757 - train - INFO - Train: 13 [ 700/781 ( 90%)]  Loss:  4.379730 (3.8310)  Time: 1.070s,  119.65/s  (0.934s,  137.11/s)  LR: 4.910e-04  Data: 0.005 (0.008)
2024-04-07 00:19:36,935 - train - INFO - Train: 13 [ 750/781 ( 96%)]  Loss:  3.800144 (3.8352)  Time: 0.856s,  149.51/s  (0.933s,  137.21/s)  LR: 4.910e-04  Data: 0.005 (0.008)
2024-04-07 00:20:04,768 - train - INFO - Train: 13 [ 780/781 (100%)]  Loss:  3.090189 (3.8382)  Time: 0.801s,  159.88/s  (0.933s,  137.24/s)  LR: 4.910e-04  Data: 0.000 (0.008)
2024-04-07 00:20:04,769 - train - INFO - True
2024-04-07 00:20:04,771 - train - INFO - alphas:tensor([0.3031, 0.2104, 0.1492, 0.1648, 0.1725], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:04,829 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:04,829 - train - INFO - True
2024-04-07 00:20:04,830 - train - INFO - alphas:tensor([0.3649, 0.1604, 0.1285, 0.1587, 0.1874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:04,865 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:04,865 - train - INFO - True
2024-04-07 00:20:04,866 - train - INFO - alphas:tensor([0.6472, 0.1202, 0.0737, 0.0777, 0.0812], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:04,895 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:04,895 - train - INFO - True
2024-04-07 00:20:04,896 - train - INFO - alphas:tensor([0.6348, 0.1068, 0.0758, 0.0881, 0.0946], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:04,924 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:04,925 - train - INFO - True
2024-04-07 00:20:04,926 - train - INFO - alphas:tensor([0.5190, 0.1266, 0.1008, 0.1196, 0.1340], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:04,954 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:04,954 - train - INFO - True
2024-04-07 00:20:04,955 - train - INFO - alphas:tensor([0.6237, 0.1141, 0.0773, 0.0886, 0.0962], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:04,983 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:04,983 - train - INFO - True
2024-04-07 00:20:04,984 - train - INFO - alphas:tensor([0.7313, 0.0913, 0.0536, 0.0587, 0.0650], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,012 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,012 - train - INFO - True
2024-04-07 00:20:05,013 - train - INFO - alphas:tensor([0.7321, 0.0914, 0.0554, 0.0593, 0.0617], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,041 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,041 - train - INFO - True
2024-04-07 00:20:05,042 - train - INFO - alphas:tensor([0.5600, 0.1118, 0.0910, 0.1109, 0.1264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,070 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,070 - train - INFO - True
2024-04-07 00:20:05,071 - train - INFO - alphas:tensor([0.6537, 0.1056, 0.0731, 0.0799, 0.0878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,099 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,100 - train - INFO - True
2024-04-07 00:20:05,101 - train - INFO - alphas:tensor([0.7306, 0.0882, 0.0541, 0.0602, 0.0668], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,129 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,129 - train - INFO - True
2024-04-07 00:20:05,130 - train - INFO - alphas:tensor([0.6924, 0.0946, 0.0654, 0.0725, 0.0750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,158 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,158 - train - INFO - True
2024-04-07 00:20:05,159 - train - INFO - alphas:tensor([0.5822, 0.1052, 0.0842, 0.1057, 0.1227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,187 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,187 - train - INFO - True
2024-04-07 00:20:05,188 - train - INFO - alphas:tensor([0.6771, 0.0929, 0.0694, 0.0767, 0.0839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,216 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,216 - train - INFO - True
2024-04-07 00:20:05,217 - train - INFO - alphas:tensor([0.7195, 0.0959, 0.0580, 0.0604, 0.0662], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,245 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,245 - train - INFO - True
2024-04-07 00:20:05,246 - train - INFO - alphas:tensor([0.6457, 0.1057, 0.0739, 0.0813, 0.0934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,274 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,275 - train - INFO - True
2024-04-07 00:20:05,276 - train - INFO - alphas:tensor([0.5853, 0.1047, 0.0825, 0.1048, 0.1227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,304 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,304 - train - INFO - True
2024-04-07 00:20:05,305 - train - INFO - alphas:tensor([0.6913, 0.0880, 0.0674, 0.0742, 0.0791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,333 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,333 - train - INFO - True
2024-04-07 00:20:05,334 - train - INFO - alphas:tensor([0.7368, 0.0876, 0.0548, 0.0581, 0.0627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,362 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,362 - train - INFO - True
2024-04-07 00:20:05,363 - train - INFO - alphas:tensor([0.6345, 0.1008, 0.0783, 0.0887, 0.0977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,391 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,391 - train - INFO - True
2024-04-07 00:20:05,392 - train - INFO - alphas:tensor([0.5701, 0.1051, 0.0886, 0.1099, 0.1263], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,420 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,421 - train - INFO - True
2024-04-07 00:20:05,422 - train - INFO - alphas:tensor([0.7075, 0.0831, 0.0639, 0.0700, 0.0755], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,450 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,450 - train - INFO - True
2024-04-07 00:20:05,451 - train - INFO - alphas:tensor([0.7535, 0.0845, 0.0497, 0.0538, 0.0585], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,479 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,479 - train - INFO - True
2024-04-07 00:20:05,480 - train - INFO - alphas:tensor([0.6552, 0.0931, 0.0742, 0.0837, 0.0937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,508 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,508 - train - INFO - True
2024-04-07 00:20:05,509 - train - INFO - alphas:tensor([0.5648, 0.1035, 0.0875, 0.1139, 0.1303], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,537 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,537 - train - INFO - True
2024-04-07 00:20:05,538 - train - INFO - alphas:tensor([0.7014, 0.0819, 0.0654, 0.0710, 0.0803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,565 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,565 - train - INFO - True
2024-04-07 00:20:05,566 - train - INFO - alphas:tensor([0.7433, 0.0791, 0.0528, 0.0589, 0.0659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,592 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,592 - train - INFO - True
2024-04-07 00:20:05,593 - train - INFO - alphas:tensor([0.6758, 0.0879, 0.0680, 0.0795, 0.0888], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,615 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,615 - train - INFO - True
2024-04-07 00:20:05,616 - train - INFO - alphas:tensor([0.5449, 0.1006, 0.0950, 0.1201, 0.1394], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,637 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,637 - train - INFO - True
2024-04-07 00:20:05,638 - train - INFO - alphas:tensor([0.6880, 0.0841, 0.0669, 0.0757, 0.0854], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,657 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,657 - train - INFO - True
2024-04-07 00:20:05,658 - train - INFO - alphas:tensor([0.7198, 0.0801, 0.0574, 0.0662, 0.0764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,676 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,676 - train - INFO - True
2024-04-07 00:20:05,677 - train - INFO - alphas:tensor([0.6895, 0.0823, 0.0667, 0.0768, 0.0846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,694 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,694 - train - INFO - True
2024-04-07 00:20:05,695 - train - INFO - alphas:tensor([0.5237, 0.0984, 0.0964, 0.1279, 0.1535], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,712 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,712 - train - INFO - True
2024-04-07 00:20:05,712 - train - INFO - alphas:tensor([0.6631, 0.0873, 0.0713, 0.0837, 0.0946], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,729 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,729 - train - INFO - True
2024-04-07 00:20:05,730 - train - INFO - alphas:tensor([0.6914, 0.0847, 0.0613, 0.0760, 0.0866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,752 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,752 - train - INFO - True
2024-04-07 00:20:05,752 - train - INFO - alphas:tensor([0.6622, 0.0883, 0.0706, 0.0843, 0.0946], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,772 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,772 - train - INFO - True
2024-04-07 00:20:05,773 - train - INFO - alphas:tensor([0.6104, 0.0972, 0.1357, 0.1568], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:20:05,791 - train - INFO - tau:0.8953382542587163
2024-04-07 00:20:05,791 - train - INFO - avg block size:1.0
2024-04-07 00:20:05,791 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 00:20:06,035 - train - INFO - Test: [   0/78]  Time: 0.240 (0.240)  Loss:  0.8271 (0.8271)  Acc@1: 82.8125 (82.8125)  Acc@5: 94.5312 (94.5312)
2024-04-07 00:20:11,025 - train - INFO - Test: [  50/78]  Time: 0.083 (0.103)  Loss:  1.9951 (1.7221)  Acc@1: 50.7812 (59.6201)  Acc@5: 82.0312 (82.5521)
2024-04-07 00:20:13,582 - train - INFO - Test: [  78/78]  Time: 0.053 (0.099)  Loss:  1.6699 (1.7618)  Acc@1: 50.0000 (58.4900)  Acc@5: 93.7500 (81.8100)
2024-04-07 00:20:14,915 - train - INFO - Train: 14 [   0/781 (  0%)]  Loss:  4.200397 (4.2004)  Time: 1.262s,  101.39/s  (1.262s,  101.39/s)  LR: 4.895e-04  Data: 0.182 (0.182)
2024-04-07 00:21:02,277 - train - INFO - Train: 14 [  50/781 (  6%)]  Loss:  3.242496 (3.8102)  Time: 0.840s,  152.44/s  (0.953s,  134.26/s)  LR: 4.895e-04  Data: 0.008 (0.011)
2024-04-07 00:21:51,171 - train - INFO - Train: 14 [ 100/781 ( 13%)]  Loss:  4.495595 (3.8361)  Time: 0.835s,  153.37/s  (0.966s,  132.57/s)  LR: 4.895e-04  Data: 0.006 (0.010)
2024-04-07 00:22:37,727 - train - INFO - Train: 14 [ 150/781 ( 19%)]  Loss:  4.262709 (3.8300)  Time: 0.834s,  153.54/s  (0.954s,  134.16/s)  LR: 4.895e-04  Data: 0.007 (0.009)
2024-04-07 00:23:24,953 - train - INFO - Train: 14 [ 200/781 ( 26%)]  Loss:  3.962249 (3.8249)  Time: 0.858s,  149.26/s  (0.952s,  134.49/s)  LR: 4.895e-04  Data: 0.008 (0.009)
2024-04-07 00:24:13,376 - train - INFO - Train: 14 [ 250/781 ( 32%)]  Loss:  3.291515 (3.8180)  Time: 1.075s,  119.12/s  (0.955s,  134.02/s)  LR: 4.895e-04  Data: 0.009 (0.009)
2024-04-07 00:25:00,817 - train - INFO - Train: 14 [ 300/781 ( 38%)]  Loss:  3.033621 (3.8179)  Time: 1.070s,  119.58/s  (0.954s,  134.17/s)  LR: 4.895e-04  Data: 0.010 (0.009)
2024-04-07 00:25:46,530 - train - INFO - Train: 14 [ 350/781 ( 45%)]  Loss:  3.229276 (3.8190)  Time: 0.828s,  154.50/s  (0.948s,  134.97/s)  LR: 4.895e-04  Data: 0.007 (0.009)
2024-04-07 00:26:32,866 - train - INFO - Train: 14 [ 400/781 ( 51%)]  Loss:  4.510829 (3.8227)  Time: 0.833s,  153.63/s  (0.946s,  135.36/s)  LR: 4.895e-04  Data: 0.007 (0.009)
2024-04-07 00:27:18,394 - train - INFO - Train: 14 [ 450/781 ( 58%)]  Loss:  3.712553 (3.8181)  Time: 0.848s,  150.96/s  (0.942s,  135.92/s)  LR: 4.895e-04  Data: 0.006 (0.009)
2024-04-07 00:28:06,554 - train - INFO - Train: 14 [ 500/781 ( 64%)]  Loss:  3.746496 (3.8187)  Time: 1.071s,  119.48/s  (0.944s,  135.61/s)  LR: 4.895e-04  Data: 0.009 (0.009)
2024-04-07 00:28:53,224 - train - INFO - Train: 14 [ 550/781 ( 71%)]  Loss:  4.008755 (3.8259)  Time: 1.069s,  119.68/s  (0.943s,  135.75/s)  LR: 4.895e-04  Data: 0.007 (0.009)
2024-04-07 00:29:38,636 - train - INFO - Train: 14 [ 600/781 ( 77%)]  Loss:  4.071581 (3.8250)  Time: 0.848s,  150.96/s  (0.940s,  136.16/s)  LR: 4.895e-04  Data: 0.006 (0.009)
2024-04-07 00:30:26,395 - train - INFO - Train: 14 [ 650/781 ( 83%)]  Loss:  4.004171 (3.8314)  Time: 0.828s,  154.61/s  (0.941s,  136.00/s)  LR: 4.895e-04  Data: 0.006 (0.009)
2024-04-07 00:31:12,226 - train - INFO - Train: 14 [ 700/781 ( 90%)]  Loss:  3.458302 (3.8334)  Time: 0.862s,  148.55/s  (0.939s,  136.25/s)  LR: 4.895e-04  Data: 0.007 (0.009)
2024-04-07 00:31:58,382 - train - INFO - Train: 14 [ 750/781 ( 96%)]  Loss:  4.366794 (3.8341)  Time: 0.838s,  152.72/s  (0.938s,  136.41/s)  LR: 4.895e-04  Data: 0.007 (0.009)
2024-04-07 00:32:24,709 - train - INFO - Train: 14 [ 780/781 (100%)]  Loss:  4.259227 (3.8364)  Time: 0.846s,  151.30/s  (0.936s,  136.75/s)  LR: 4.895e-04  Data: 0.000 (0.008)
2024-04-07 00:32:24,710 - train - INFO - True
2024-04-07 00:32:24,712 - train - INFO - alphas:tensor([0.3054, 0.2035, 0.1495, 0.1666, 0.1750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:24,741 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:24,742 - train - INFO - True
2024-04-07 00:32:24,743 - train - INFO - alphas:tensor([0.3724, 0.1517, 0.1256, 0.1587, 0.1916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:24,769 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:24,769 - train - INFO - True
2024-04-07 00:32:24,770 - train - INFO - alphas:tensor([0.6621, 0.1135, 0.0707, 0.0750, 0.0786], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:24,804 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:24,804 - train - INFO - True
2024-04-07 00:32:24,805 - train - INFO - alphas:tensor([0.6499, 0.1001, 0.0725, 0.0852, 0.0923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:24,826 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:24,826 - train - INFO - True
2024-04-07 00:32:24,827 - train - INFO - alphas:tensor([0.5251, 0.1199, 0.0996, 0.1197, 0.1357], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:24,847 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:24,847 - train - INFO - True
2024-04-07 00:32:24,848 - train - INFO - alphas:tensor([0.6348, 0.1087, 0.0750, 0.0867, 0.0948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:24,866 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:24,866 - train - INFO - True
2024-04-07 00:32:24,867 - train - INFO - alphas:tensor([0.7424, 0.0860, 0.0514, 0.0568, 0.0633], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:24,885 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:24,885 - train - INFO - True
2024-04-07 00:32:24,886 - train - INFO - alphas:tensor([0.7416, 0.0874, 0.0530, 0.0576, 0.0602], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:24,903 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:24,903 - train - INFO - True
2024-04-07 00:32:24,903 - train - INFO - alphas:tensor([0.5683, 0.1058, 0.0891, 0.1098, 0.1269], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:24,920 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:24,920 - train - INFO - True
2024-04-07 00:32:24,921 - train - INFO - alphas:tensor([0.6636, 0.1005, 0.0709, 0.0783, 0.0867], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:24,941 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:24,941 - train - INFO - True
2024-04-07 00:32:24,942 - train - INFO - alphas:tensor([0.7395, 0.0832, 0.0523, 0.0590, 0.0661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:24,962 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:24,962 - train - INFO - True
2024-04-07 00:32:24,963 - train - INFO - alphas:tensor([0.7010, 0.0898, 0.0631, 0.0714, 0.0746], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:24,981 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:24,982 - train - INFO - True
2024-04-07 00:32:24,982 - train - INFO - alphas:tensor([0.5883, 0.0997, 0.0829, 0.1055, 0.1236], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,000 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,000 - train - INFO - True
2024-04-07 00:32:25,001 - train - INFO - alphas:tensor([0.6873, 0.0877, 0.0667, 0.0751, 0.0832], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,018 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,018 - train - INFO - True
2024-04-07 00:32:25,018 - train - INFO - alphas:tensor([0.7255, 0.0919, 0.0566, 0.0597, 0.0662], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,035 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,035 - train - INFO - True
2024-04-07 00:32:25,036 - train - INFO - alphas:tensor([0.6480, 0.1015, 0.0727, 0.0821, 0.0956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,052 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,053 - train - INFO - True
2024-04-07 00:32:25,053 - train - INFO - alphas:tensor([0.5919, 0.0990, 0.0804, 0.1045, 0.1242], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,070 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,070 - train - INFO - True
2024-04-07 00:32:25,071 - train - INFO - alphas:tensor([0.6990, 0.0837, 0.0651, 0.0732, 0.0790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,092 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,092 - train - INFO - True
2024-04-07 00:32:25,093 - train - INFO - alphas:tensor([0.7442, 0.0835, 0.0531, 0.0570, 0.0622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,112 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,113 - train - INFO - True
2024-04-07 00:32:25,113 - train - INFO - alphas:tensor([0.6403, 0.0954, 0.0760, 0.0884, 0.0999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,132 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,132 - train - INFO - True
2024-04-07 00:32:25,133 - train - INFO - alphas:tensor([0.5734, 0.0995, 0.0873, 0.1107, 0.1291], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,150 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,150 - train - INFO - True
2024-04-07 00:32:25,151 - train - INFO - alphas:tensor([0.7196, 0.0783, 0.0609, 0.0674, 0.0738], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,168 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,168 - train - INFO - True
2024-04-07 00:32:25,168 - train - INFO - alphas:tensor([0.7595, 0.0808, 0.0483, 0.0530, 0.0583], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,185 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,185 - train - INFO - True
2024-04-07 00:32:25,186 - train - INFO - alphas:tensor([0.6596, 0.0876, 0.0719, 0.0844, 0.0965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,203 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,203 - train - INFO - True
2024-04-07 00:32:25,203 - train - INFO - alphas:tensor([0.5692, 0.0976, 0.0860, 0.1142, 0.1331], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,221 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,221 - train - INFO - True
2024-04-07 00:32:25,222 - train - INFO - alphas:tensor([0.7093, 0.0779, 0.0635, 0.0697, 0.0797], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,243 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,243 - train - INFO - True
2024-04-07 00:32:25,244 - train - INFO - alphas:tensor([0.7463, 0.0760, 0.0519, 0.0590, 0.0668], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,262 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,262 - train - INFO - True
2024-04-07 00:32:25,263 - train - INFO - alphas:tensor([0.6769, 0.0837, 0.0669, 0.0808, 0.0916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,281 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,281 - train - INFO - True
2024-04-07 00:32:25,282 - train - INFO - alphas:tensor([0.5501, 0.0944, 0.0932, 0.1204, 0.1420], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,299 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,299 - train - INFO - True
2024-04-07 00:32:25,299 - train - INFO - alphas:tensor([0.6980, 0.0793, 0.0645, 0.0738, 0.0845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,316 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,316 - train - INFO - True
2024-04-07 00:32:25,317 - train - INFO - alphas:tensor([0.7242, 0.0762, 0.0556, 0.0662, 0.0777], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,333 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,333 - train - INFO - True
2024-04-07 00:32:25,334 - train - INFO - alphas:tensor([0.6933, 0.0786, 0.0645, 0.0773, 0.0863], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,350 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,351 - train - INFO - True
2024-04-07 00:32:25,351 - train - INFO - alphas:tensor([0.5259, 0.0925, 0.0949, 0.1292, 0.1575], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,372 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,372 - train - INFO - True
2024-04-07 00:32:25,373 - train - INFO - alphas:tensor([0.6698, 0.0825, 0.0694, 0.0832, 0.0951], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,393 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,393 - train - INFO - True
2024-04-07 00:32:25,393 - train - INFO - alphas:tensor([0.6977, 0.0796, 0.0595, 0.0756, 0.0876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,412 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,412 - train - INFO - True
2024-04-07 00:32:25,413 - train - INFO - alphas:tensor([0.6717, 0.0822, 0.0680, 0.0833, 0.0948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,431 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,431 - train - INFO - True
2024-04-07 00:32:25,432 - train - INFO - alphas:tensor([0.6173, 0.0941, 0.1333, 0.1552], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:32:25,448 - train - INFO - tau:0.8863848717161291
2024-04-07 00:32:25,449 - train - INFO - avg block size:1.0
2024-04-07 00:32:25,449 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 00:32:25,449 - train - INFO - lasso_alpha:1.610510000000001e-05
2024-04-07 00:32:25,664 - train - INFO - Test: [   0/78]  Time: 0.212 (0.212)  Loss:  0.9131 (0.9131)  Acc@1: 82.0312 (82.0312)  Acc@5: 94.5312 (94.5312)
2024-04-07 00:32:30,017 - train - INFO - Test: [  50/78]  Time: 0.088 (0.089)  Loss:  1.8740 (1.7277)  Acc@1: 57.8125 (59.8652)  Acc@5: 82.0312 (82.6440)
2024-04-07 00:32:32,408 - train - INFO - Test: [  78/78]  Time: 0.052 (0.088)  Loss:  2.1055 (1.7711)  Acc@1: 50.0000 (58.6400)  Acc@5: 75.0000 (82.0100)
2024-04-07 00:32:33,663 - train - INFO - Train: 15 [   0/781 (  0%)]  Loss:  4.375972 (4.3760)  Time: 1.184s,  108.15/s  (1.184s,  108.15/s)  LR: 4.880e-04  Data: 0.195 (0.195)
2024-04-07 00:33:20,810 - train - INFO - Train: 15 [  50/781 (  6%)]  Loss:  3.246209 (3.7861)  Time: 1.088s,  117.64/s  (0.948s,  135.07/s)  LR: 4.880e-04  Data: 0.016 (0.011)
2024-04-07 00:34:09,207 - train - INFO - Train: 15 [ 100/781 ( 13%)]  Loss:  3.528618 (3.8442)  Time: 0.851s,  150.40/s  (0.958s,  133.66/s)  LR: 4.880e-04  Data: 0.008 (0.010)
2024-04-07 00:34:56,925 - train - INFO - Train: 15 [ 150/781 ( 19%)]  Loss:  3.696929 (3.8101)  Time: 0.836s,  153.03/s  (0.957s,  133.81/s)  LR: 4.880e-04  Data: 0.005 (0.009)
2024-04-07 00:35:42,932 - train - INFO - Train: 15 [ 200/781 ( 26%)]  Loss:  4.051190 (3.8155)  Time: 0.860s,  148.82/s  (0.947s,  135.09/s)  LR: 4.880e-04  Data: 0.008 (0.009)
2024-04-07 00:36:29,756 - train - INFO - Train: 15 [ 250/781 ( 32%)]  Loss:  4.173677 (3.8300)  Time: 0.803s,  159.33/s  (0.945s,  135.41/s)  LR: 4.880e-04  Data: 0.005 (0.009)
2024-04-07 00:37:15,582 - train - INFO - Train: 15 [ 300/781 ( 38%)]  Loss:  4.406560 (3.8446)  Time: 0.859s,  149.03/s  (0.941s,  136.10/s)  LR: 4.880e-04  Data: 0.009 (0.009)
2024-04-07 00:38:02,127 - train - INFO - Train: 15 [ 350/781 ( 45%)]  Loss:  3.301636 (3.8263)  Time: 1.054s,  121.49/s  (0.939s,  136.30/s)  LR: 4.880e-04  Data: 0.009 (0.009)
2024-04-07 00:38:48,993 - train - INFO - Train: 15 [ 400/781 ( 51%)]  Loss:  4.358025 (3.8337)  Time: 0.830s,  154.29/s  (0.939s,  136.33/s)  LR: 4.880e-04  Data: 0.005 (0.009)
2024-04-07 00:39:37,962 - train - INFO - Train: 15 [ 450/781 ( 58%)]  Loss:  3.658145 (3.8368)  Time: 1.138s,  112.45/s  (0.943s,  135.68/s)  LR: 4.880e-04  Data: 0.008 (0.009)
2024-04-07 00:40:25,875 - train - INFO - Train: 15 [ 500/781 ( 64%)]  Loss:  3.960969 (3.8368)  Time: 1.088s,  117.69/s  (0.945s,  135.47/s)  LR: 4.880e-04  Data: 0.009 (0.009)
2024-04-07 00:41:11,985 - train - INFO - Train: 15 [ 550/781 ( 71%)]  Loss:  3.799873 (3.8327)  Time: 0.853s,  150.02/s  (0.943s,  135.76/s)  LR: 4.880e-04  Data: 0.009 (0.009)
2024-04-07 00:41:57,739 - train - INFO - Train: 15 [ 600/781 ( 77%)]  Loss:  3.537591 (3.8313)  Time: 1.099s,  116.44/s  (0.940s,  136.10/s)  LR: 4.880e-04  Data: 0.009 (0.008)
2024-04-07 00:42:43,944 - train - INFO - Train: 15 [ 650/781 ( 83%)]  Loss:  4.106008 (3.8362)  Time: 1.100s,  116.33/s  (0.939s,  136.28/s)  LR: 4.880e-04  Data: 0.019 (0.008)
2024-04-07 00:43:30,441 - train - INFO - Train: 15 [ 700/781 ( 90%)]  Loss:  3.766841 (3.8380)  Time: 0.853s,  150.13/s  (0.939s,  136.38/s)  LR: 4.880e-04  Data: 0.007 (0.008)
2024-04-07 00:44:18,160 - train - INFO - Train: 15 [ 750/781 ( 96%)]  Loss:  3.901429 (3.8377)  Time: 1.059s,  120.83/s  (0.940s,  136.23/s)  LR: 4.880e-04  Data: 0.008 (0.008)
2024-04-07 00:44:45,634 - train - INFO - Train: 15 [ 780/781 (100%)]  Loss:  3.206979 (3.8371)  Time: 0.858s,  149.12/s  (0.939s,  136.36/s)  LR: 4.880e-04  Data: 0.000 (0.008)
2024-04-07 00:44:45,635 - train - INFO - True
2024-04-07 00:44:45,637 - train - INFO - alphas:tensor([0.3062, 0.1975, 0.1498, 0.1686, 0.1779], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:45,679 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:45,680 - train - INFO - True
2024-04-07 00:44:45,681 - train - INFO - alphas:tensor([0.3763, 0.1449, 0.1235, 0.1595, 0.1959], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:45,715 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:45,715 - train - INFO - True
2024-04-07 00:44:45,716 - train - INFO - alphas:tensor([0.6747, 0.1079, 0.0682, 0.0727, 0.0765], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:45,745 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:45,745 - train - INFO - True
2024-04-07 00:44:45,746 - train - INFO - alphas:tensor([0.6614, 0.0943, 0.0701, 0.0833, 0.0908], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:45,774 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:45,774 - train - INFO - True
2024-04-07 00:44:45,775 - train - INFO - alphas:tensor([0.5302, 0.1142, 0.0986, 0.1198, 0.1372], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:45,803 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:45,803 - train - INFO - True
2024-04-07 00:44:45,804 - train - INFO - alphas:tensor([0.6443, 0.1041, 0.0727, 0.0851, 0.0938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:45,832 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:45,833 - train - INFO - True
2024-04-07 00:44:45,834 - train - INFO - alphas:tensor([0.7508, 0.0823, 0.0496, 0.0551, 0.0622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:45,862 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:45,862 - train - INFO - True
2024-04-07 00:44:45,863 - train - INFO - alphas:tensor([0.7527, 0.0825, 0.0504, 0.0556, 0.0588], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:45,891 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:45,891 - train - INFO - True
2024-04-07 00:44:45,892 - train - INFO - alphas:tensor([0.5725, 0.1010, 0.0877, 0.1100, 0.1288], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:45,920 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:45,920 - train - INFO - True
2024-04-07 00:44:45,921 - train - INFO - alphas:tensor([0.6729, 0.0957, 0.0686, 0.0769, 0.0859], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:45,949 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:45,949 - train - INFO - True
2024-04-07 00:44:45,950 - train - INFO - alphas:tensor([0.7439, 0.0797, 0.0513, 0.0586, 0.0665], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:45,978 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:45,978 - train - INFO - True
2024-04-07 00:44:45,979 - train - INFO - alphas:tensor([0.7092, 0.0848, 0.0611, 0.0705, 0.0744], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,007 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,007 - train - INFO - True
2024-04-07 00:44:46,008 - train - INFO - alphas:tensor([0.5923, 0.0955, 0.0811, 0.1057, 0.1254], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,036 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,037 - train - INFO - True
2024-04-07 00:44:46,037 - train - INFO - alphas:tensor([0.6933, 0.0835, 0.0655, 0.0742, 0.0834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,066 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,066 - train - INFO - True
2024-04-07 00:44:46,067 - train - INFO - alphas:tensor([0.7283, 0.0889, 0.0556, 0.0598, 0.0673], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,095 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,095 - train - INFO - True
2024-04-07 00:44:46,096 - train - INFO - alphas:tensor([0.6475, 0.0976, 0.0721, 0.0838, 0.0990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,124 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,124 - train - INFO - True
2024-04-07 00:44:46,125 - train - INFO - alphas:tensor([0.5992, 0.0924, 0.0785, 0.1043, 0.1256], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,155 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,156 - train - INFO - True
2024-04-07 00:44:46,157 - train - INFO - alphas:tensor([0.7052, 0.0795, 0.0637, 0.0726, 0.0789], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,185 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,185 - train - INFO - True
2024-04-07 00:44:46,186 - train - INFO - alphas:tensor([0.7486, 0.0796, 0.0523, 0.0567, 0.0628], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,215 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,215 - train - INFO - True
2024-04-07 00:44:46,216 - train - INFO - alphas:tensor([0.6401, 0.0903, 0.0753, 0.0901, 0.1043], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,244 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,244 - train - INFO - True
2024-04-07 00:44:46,245 - train - INFO - alphas:tensor([0.5746, 0.0948, 0.0863, 0.1117, 0.1325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,273 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,273 - train - INFO - True
2024-04-07 00:44:46,274 - train - INFO - alphas:tensor([0.7258, 0.0747, 0.0592, 0.0665, 0.0738], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,302 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,302 - train - INFO - True
2024-04-07 00:44:46,303 - train - INFO - alphas:tensor([0.7641, 0.0778, 0.0469, 0.0525, 0.0587], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,331 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,332 - train - INFO - True
2024-04-07 00:44:46,333 - train - INFO - alphas:tensor([0.6590, 0.0834, 0.0715, 0.0859, 0.1002], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,361 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,361 - train - INFO - True
2024-04-07 00:44:46,362 - train - INFO - alphas:tensor([0.5726, 0.0918, 0.0846, 0.1150, 0.1361], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,390 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,390 - train - INFO - True
2024-04-07 00:44:46,391 - train - INFO - alphas:tensor([0.7191, 0.0737, 0.0608, 0.0680, 0.0785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,419 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,419 - train - INFO - True
2024-04-07 00:44:46,420 - train - INFO - alphas:tensor([0.7504, 0.0719, 0.0508, 0.0587, 0.0682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,445 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,445 - train - INFO - True
2024-04-07 00:44:46,446 - train - INFO - alphas:tensor([0.6763, 0.0796, 0.0657, 0.0826, 0.0958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,469 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,469 - train - INFO - True
2024-04-07 00:44:46,470 - train - INFO - alphas:tensor([0.5505, 0.0892, 0.0922, 0.1220, 0.1461], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,491 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,491 - train - INFO - True
2024-04-07 00:44:46,492 - train - INFO - alphas:tensor([0.7013, 0.0754, 0.0632, 0.0740, 0.0862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,512 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,512 - train - INFO - True
2024-04-07 00:44:46,513 - train - INFO - alphas:tensor([0.7242, 0.0736, 0.0551, 0.0670, 0.0801], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,532 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,532 - train - INFO - True
2024-04-07 00:44:46,532 - train - INFO - alphas:tensor([0.6921, 0.0755, 0.0637, 0.0785, 0.0902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,550 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,550 - train - INFO - True
2024-04-07 00:44:46,551 - train - INFO - alphas:tensor([0.5274, 0.0874, 0.0935, 0.1302, 0.1615], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,568 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,568 - train - INFO - True
2024-04-07 00:44:46,568 - train - INFO - alphas:tensor([0.6727, 0.0795, 0.0682, 0.0832, 0.0965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,588 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,588 - train - INFO - True
2024-04-07 00:44:46,589 - train - INFO - alphas:tensor([0.6966, 0.0775, 0.0592, 0.0766, 0.0901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,609 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,610 - train - INFO - True
2024-04-07 00:44:46,610 - train - INFO - alphas:tensor([0.6733, 0.0775, 0.0669, 0.0843, 0.0980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,630 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,630 - train - INFO - True
2024-04-07 00:44:46,631 - train - INFO - alphas:tensor([0.6256, 0.0906, 0.1304, 0.1534], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:44:46,649 - train - INFO - tau:0.8775210229989678
2024-04-07 00:44:46,649 - train - INFO - avg block size:1.0
2024-04-07 00:44:46,650 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 00:44:46,902 - train - INFO - Test: [   0/78]  Time: 0.249 (0.249)  Loss:  0.9761 (0.9761)  Acc@1: 81.2500 (81.2500)  Acc@5: 92.9688 (92.9688)
2024-04-07 00:44:51,601 - train - INFO - Test: [  50/78]  Time: 0.088 (0.097)  Loss:  1.9639 (1.7428)  Acc@1: 54.6875 (59.1759)  Acc@5: 79.6875 (82.1691)
2024-04-07 00:44:53,982 - train - INFO - Test: [  78/78]  Time: 0.059 (0.093)  Loss:  1.5586 (1.7703)  Acc@1: 56.2500 (58.5600)  Acc@5: 93.7500 (81.7400)
2024-04-07 00:44:55,290 - train - INFO - Train: 16 [   0/781 (  0%)]  Loss:  4.217245 (4.2172)  Time: 1.238s,  103.36/s  (1.238s,  103.36/s)  LR: 4.864e-04  Data: 0.184 (0.184)
2024-04-07 00:45:42,447 - train - INFO - Train: 16 [  50/781 (  6%)]  Loss:  3.602420 (3.7906)  Time: 1.075s,  119.03/s  (0.949s,  134.89/s)  LR: 4.864e-04  Data: 0.008 (0.012)
2024-04-07 00:46:29,314 - train - INFO - Train: 16 [ 100/781 ( 13%)]  Loss:  3.732239 (3.7794)  Time: 0.821s,  155.88/s  (0.943s,  135.71/s)  LR: 4.864e-04  Data: 0.006 (0.010)
2024-04-07 00:47:17,514 - train - INFO - Train: 16 [ 150/781 ( 19%)]  Loss:  3.716661 (3.8163)  Time: 1.094s,  116.99/s  (0.950s,  134.73/s)  LR: 4.864e-04  Data: 0.008 (0.009)
2024-04-07 00:48:04,068 - train - INFO - Train: 16 [ 200/781 ( 26%)]  Loss:  3.552341 (3.8397)  Time: 1.066s,  120.03/s  (0.945s,  135.40/s)  LR: 4.864e-04  Data: 0.011 (0.009)
2024-04-07 00:48:50,010 - train - INFO - Train: 16 [ 250/781 ( 32%)]  Loss:  4.307090 (3.8424)  Time: 0.764s,  167.47/s  (0.940s,  136.16/s)  LR: 4.864e-04  Data: 0.005 (0.009)
2024-04-07 00:49:36,238 - train - INFO - Train: 16 [ 300/781 ( 38%)]  Loss:  4.367399 (3.8441)  Time: 1.002s,  127.71/s  (0.937s,  136.54/s)  LR: 4.864e-04  Data: 0.005 (0.009)
2024-04-07 00:50:23,765 - train - INFO - Train: 16 [ 350/781 ( 45%)]  Loss:  3.780874 (3.8370)  Time: 0.805s,  158.97/s  (0.939s,  136.27/s)  LR: 4.864e-04  Data: 0.005 (0.009)
2024-04-07 00:51:10,528 - train - INFO - Train: 16 [ 400/781 ( 51%)]  Loss:  4.253495 (3.8385)  Time: 0.816s,  156.79/s  (0.939s,  136.34/s)  LR: 4.864e-04  Data: 0.008 (0.009)
2024-04-07 00:51:57,810 - train - INFO - Train: 16 [ 450/781 ( 58%)]  Loss:  3.943141 (3.8384)  Time: 0.922s,  138.75/s  (0.940s,  136.23/s)  LR: 4.864e-04  Data: 0.008 (0.008)
2024-04-07 00:52:44,238 - train - INFO - Train: 16 [ 500/781 ( 64%)]  Loss:  3.533107 (3.8365)  Time: 0.851s,  150.36/s  (0.938s,  136.39/s)  LR: 4.864e-04  Data: 0.008 (0.008)
2024-04-07 00:53:32,076 - train - INFO - Train: 16 [ 550/781 ( 71%)]  Loss:  3.687500 (3.8315)  Time: 1.034s,  123.80/s  (0.940s,  136.15/s)  LR: 4.864e-04  Data: 0.012 (0.008)
2024-04-07 00:54:19,187 - train - INFO - Train: 16 [ 600/781 ( 77%)]  Loss:  4.466320 (3.8343)  Time: 0.854s,  149.87/s  (0.940s,  136.13/s)  LR: 4.864e-04  Data: 0.008 (0.008)
2024-04-07 00:55:05,560 - train - INFO - Train: 16 [ 650/781 ( 83%)]  Loss:  3.068620 (3.8349)  Time: 1.090s,  117.44/s  (0.939s,  136.27/s)  LR: 4.864e-04  Data: 0.008 (0.008)
2024-04-07 00:55:52,357 - train - INFO - Train: 16 [ 700/781 ( 90%)]  Loss:  4.101122 (3.8289)  Time: 1.069s,  119.69/s  (0.939s,  136.31/s)  LR: 4.864e-04  Data: 0.007 (0.008)
2024-04-07 00:56:39,440 - train - INFO - Train: 16 [ 750/781 ( 96%)]  Loss:  4.083017 (3.8311)  Time: 0.874s,  146.41/s  (0.939s,  136.28/s)  LR: 4.864e-04  Data: 0.011 (0.008)
2024-04-07 00:57:07,369 - train - INFO - Train: 16 [ 780/781 (100%)]  Loss:  3.418254 (3.8340)  Time: 0.850s,  150.63/s  (0.939s,  136.33/s)  LR: 4.864e-04  Data: 0.000 (0.008)
2024-04-07 00:57:07,370 - train - INFO - True
2024-04-07 00:57:07,372 - train - INFO - alphas:tensor([0.3070, 0.1922, 0.1499, 0.1704, 0.1805], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,417 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,417 - train - INFO - True
2024-04-07 00:57:07,418 - train - INFO - alphas:tensor([0.3789, 0.1391, 0.1220, 0.1600, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,453 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,453 - train - INFO - True
2024-04-07 00:57:07,454 - train - INFO - alphas:tensor([0.6854, 0.1037, 0.0659, 0.0705, 0.0744], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,484 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,484 - train - INFO - True
2024-04-07 00:57:07,485 - train - INFO - alphas:tensor([0.6716, 0.0898, 0.0679, 0.0813, 0.0894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,511 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,511 - train - INFO - True
2024-04-07 00:57:07,512 - train - INFO - alphas:tensor([0.5360, 0.1084, 0.0971, 0.1198, 0.1386], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,535 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,536 - train - INFO - True
2024-04-07 00:57:07,536 - train - INFO - alphas:tensor([0.6531, 0.0997, 0.0706, 0.0836, 0.0930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,558 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,558 - train - INFO - True
2024-04-07 00:57:07,559 - train - INFO - alphas:tensor([0.7590, 0.0781, 0.0481, 0.0538, 0.0610], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,579 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,579 - train - INFO - True
2024-04-07 00:57:07,580 - train - INFO - alphas:tensor([0.7606, 0.0786, 0.0485, 0.0543, 0.0579], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,599 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,599 - train - INFO - True
2024-04-07 00:57:07,600 - train - INFO - alphas:tensor([0.5758, 0.0969, 0.0866, 0.1102, 0.1305], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,618 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,618 - train - INFO - True
2024-04-07 00:57:07,619 - train - INFO - alphas:tensor([0.6803, 0.0915, 0.0670, 0.0759, 0.0852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,636 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,636 - train - INFO - True
2024-04-07 00:57:07,637 - train - INFO - alphas:tensor([0.7479, 0.0763, 0.0505, 0.0583, 0.0669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,655 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,655 - train - INFO - True
2024-04-07 00:57:07,656 - train - INFO - alphas:tensor([0.7119, 0.0817, 0.0602, 0.0709, 0.0753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,677 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,677 - train - INFO - True
2024-04-07 00:57:07,678 - train - INFO - alphas:tensor([0.5945, 0.0912, 0.0800, 0.1066, 0.1278], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,698 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,698 - train - INFO - True
2024-04-07 00:57:07,699 - train - INFO - alphas:tensor([0.6976, 0.0800, 0.0643, 0.0738, 0.0842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,718 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,718 - train - INFO - True
2024-04-07 00:57:07,718 - train - INFO - alphas:tensor([0.7319, 0.0857, 0.0545, 0.0598, 0.0681], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,736 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,737 - train - INFO - True
2024-04-07 00:57:07,737 - train - INFO - alphas:tensor([0.6481, 0.0934, 0.0714, 0.0849, 0.1021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,754 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,754 - train - INFO - True
2024-04-07 00:57:07,755 - train - INFO - alphas:tensor([0.6001, 0.0885, 0.0777, 0.1054, 0.1283], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,772 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,772 - train - INFO - True
2024-04-07 00:57:07,772 - train - INFO - alphas:tensor([0.7066, 0.0769, 0.0634, 0.0728, 0.0802], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,789 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,789 - train - INFO - True
2024-04-07 00:57:07,790 - train - INFO - alphas:tensor([0.7520, 0.0768, 0.0512, 0.0564, 0.0635], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,811 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,811 - train - INFO - True
2024-04-07 00:57:07,812 - train - INFO - alphas:tensor([0.6373, 0.0865, 0.0750, 0.0923, 0.1089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,831 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,831 - train - INFO - True
2024-04-07 00:57:07,832 - train - INFO - alphas:tensor([0.5785, 0.0895, 0.0852, 0.1120, 0.1349], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,851 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,851 - train - INFO - True
2024-04-07 00:57:07,852 - train - INFO - alphas:tensor([0.7326, 0.0714, 0.0573, 0.0653, 0.0734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,870 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,870 - train - INFO - True
2024-04-07 00:57:07,871 - train - INFO - alphas:tensor([0.7648, 0.0756, 0.0466, 0.0530, 0.0601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,888 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,888 - train - INFO - True
2024-04-07 00:57:07,889 - train - INFO - alphas:tensor([0.6585, 0.0796, 0.0702, 0.0878, 0.1039], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,905 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,905 - train - INFO - True
2024-04-07 00:57:07,906 - train - INFO - alphas:tensor([0.5761, 0.0871, 0.0829, 0.1153, 0.1386], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,927 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,927 - train - INFO - True
2024-04-07 00:57:07,928 - train - INFO - alphas:tensor([0.7240, 0.0704, 0.0595, 0.0672, 0.0789], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,948 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,948 - train - INFO - True
2024-04-07 00:57:07,948 - train - INFO - alphas:tensor([0.7519, 0.0692, 0.0496, 0.0594, 0.0699], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,967 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,967 - train - INFO - True
2024-04-07 00:57:07,968 - train - INFO - alphas:tensor([0.6748, 0.0768, 0.0643, 0.0842, 0.0999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:07,985 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:07,985 - train - INFO - True
2024-04-07 00:57:07,986 - train - INFO - alphas:tensor([0.5524, 0.0844, 0.0907, 0.1229, 0.1496], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:08,003 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:08,003 - train - INFO - True
2024-04-07 00:57:08,004 - train - INFO - alphas:tensor([0.7057, 0.0719, 0.0619, 0.0737, 0.0867], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:08,022 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:08,022 - train - INFO - True
2024-04-07 00:57:08,023 - train - INFO - alphas:tensor([0.7296, 0.0700, 0.0534, 0.0664, 0.0807], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:08,044 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:08,044 - train - INFO - True
2024-04-07 00:57:08,044 - train - INFO - alphas:tensor([0.6972, 0.0721, 0.0617, 0.0782, 0.0909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:08,063 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:08,064 - train - INFO - True
2024-04-07 00:57:08,064 - train - INFO - alphas:tensor([0.5270, 0.0826, 0.0926, 0.1318, 0.1660], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:08,082 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:08,082 - train - INFO - True
2024-04-07 00:57:08,083 - train - INFO - alphas:tensor([0.6720, 0.0766, 0.0678, 0.0843, 0.0993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:08,100 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:08,100 - train - INFO - True
2024-04-07 00:57:08,101 - train - INFO - alphas:tensor([0.6990, 0.0738, 0.0582, 0.0771, 0.0919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:08,117 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:08,117 - train - INFO - True
2024-04-07 00:57:08,118 - train - INFO - alphas:tensor([0.6757, 0.0743, 0.0657, 0.0845, 0.0998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:08,134 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:08,134 - train - INFO - True
2024-04-07 00:57:08,135 - train - INFO - alphas:tensor([0.6305, 0.0885, 0.1285, 0.1525], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 00:57:08,151 - train - INFO - tau:0.8687458127689781
2024-04-07 00:57:08,151 - train - INFO - avg block size:1.0
2024-04-07 00:57:08,152 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 00:57:08,152 - train - INFO - lasso_alpha:1.771561000000001e-05
2024-04-07 00:57:08,376 - train - INFO - Test: [   0/78]  Time: 0.221 (0.221)  Loss:  1.0518 (1.0518)  Acc@1: 76.5625 (76.5625)  Acc@5: 89.0625 (89.0625)
2024-04-07 00:57:12,847 - train - INFO - Test: [  50/78]  Time: 0.086 (0.092)  Loss:  1.8037 (1.7347)  Acc@1: 58.5938 (59.0227)  Acc@5: 84.3750 (82.4295)
2024-04-07 00:57:15,237 - train - INFO - Test: [  78/78]  Time: 0.052 (0.090)  Loss:  1.7100 (1.7536)  Acc@1: 50.0000 (58.6800)  Acc@5: 100.0000 (82.2500)
2024-04-07 00:57:16,556 - train - INFO - Train: 17 [   0/781 (  0%)]  Loss:  4.413975 (4.4140)  Time: 1.247s,  102.66/s  (1.247s,  102.66/s)  LR: 4.846e-04  Data: 0.199 (0.199)
2024-04-07 00:58:00,951 - train - INFO - Train: 17 [  50/781 (  6%)]  Loss:  3.234615 (3.9624)  Time: 1.091s,  117.30/s  (0.895s,  143.03/s)  LR: 4.846e-04  Data: 0.007 (0.012)
2024-04-07 00:58:47,832 - train - INFO - Train: 17 [ 100/781 ( 13%)]  Loss:  3.291897 (3.9136)  Time: 0.842s,  152.04/s  (0.916s,  139.73/s)  LR: 4.846e-04  Data: 0.007 (0.010)
2024-04-07 00:59:34,351 - train - INFO - Train: 17 [ 150/781 ( 19%)]  Loss:  3.839458 (3.9086)  Time: 0.840s,  152.33/s  (0.921s,  139.01/s)  LR: 4.846e-04  Data: 0.007 (0.009)
2024-04-07 01:00:21,064 - train - INFO - Train: 17 [ 200/781 ( 26%)]  Loss:  3.769632 (3.8906)  Time: 1.092s,  117.17/s  (0.924s,  138.51/s)  LR: 4.846e-04  Data: 0.005 (0.009)
2024-04-07 01:01:08,898 - train - INFO - Train: 17 [ 250/781 ( 32%)]  Loss:  3.591279 (3.8724)  Time: 0.827s,  154.80/s  (0.931s,  137.55/s)  LR: 4.846e-04  Data: 0.007 (0.009)
2024-04-07 01:01:55,053 - train - INFO - Train: 17 [ 300/781 ( 38%)]  Loss:  2.987658 (3.8525)  Time: 1.109s,  115.45/s  (0.929s,  137.73/s)  LR: 4.846e-04  Data: 0.007 (0.009)
2024-04-07 01:02:41,784 - train - INFO - Train: 17 [ 350/781 ( 45%)]  Loss:  3.403277 (3.8589)  Time: 1.089s,  117.59/s  (0.930s,  137.62/s)  LR: 4.846e-04  Data: 0.008 (0.009)
2024-04-07 01:03:31,371 - train - INFO - Train: 17 [ 400/781 ( 51%)]  Loss:  3.754496 (3.8506)  Time: 1.059s,  120.86/s  (0.938s,  136.49/s)  LR: 4.846e-04  Data: 0.006 (0.009)
2024-04-07 01:04:17,097 - train - INFO - Train: 17 [ 450/781 ( 58%)]  Loss:  3.470925 (3.8489)  Time: 1.087s,  117.77/s  (0.935s,  136.87/s)  LR: 4.846e-04  Data: 0.008 (0.009)
2024-04-07 01:05:04,740 - train - INFO - Train: 17 [ 500/781 ( 64%)]  Loss:  3.265467 (3.8458)  Time: 0.855s,  149.69/s  (0.937s,  136.61/s)  LR: 4.846e-04  Data: 0.008 (0.009)
2024-04-07 01:05:53,251 - train - INFO - Train: 17 [ 550/781 ( 71%)]  Loss:  3.385482 (3.8539)  Time: 0.836s,  153.16/s  (0.940s,  136.17/s)  LR: 4.846e-04  Data: 0.007 (0.009)
2024-04-07 01:06:39,389 - train - INFO - Train: 17 [ 600/781 ( 77%)]  Loss:  4.100792 (3.8531)  Time: 0.870s,  147.20/s  (0.939s,  136.38/s)  LR: 4.846e-04  Data: 0.008 (0.009)
2024-04-07 01:07:25,858 - train - INFO - Train: 17 [ 650/781 ( 83%)]  Loss:  3.514272 (3.8510)  Time: 0.851s,  150.47/s  (0.938s,  136.49/s)  LR: 4.846e-04  Data: 0.008 (0.009)
2024-04-07 01:08:12,332 - train - INFO - Train: 17 [ 700/781 ( 90%)]  Loss:  3.969627 (3.8509)  Time: 0.876s,  146.19/s  (0.937s,  136.57/s)  LR: 4.846e-04  Data: 0.008 (0.009)
2024-04-07 01:09:00,740 - train - INFO - Train: 17 [ 750/781 ( 96%)]  Loss:  4.189496 (3.8527)  Time: 0.857s,  149.29/s  (0.939s,  136.27/s)  LR: 4.846e-04  Data: 0.008 (0.008)
2024-04-07 01:09:30,220 - train - INFO - Train: 17 [ 780/781 (100%)]  Loss:  4.367110 (3.8551)  Time: 1.085s,  117.92/s  (0.941s,  136.03/s)  LR: 4.846e-04  Data: 0.000 (0.009)
2024-04-07 01:09:30,220 - train - INFO - True
2024-04-07 01:09:30,223 - train - INFO - alphas:tensor([0.3064, 0.1877, 0.1503, 0.1723, 0.1833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,268 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,268 - train - INFO - True
2024-04-07 01:09:30,269 - train - INFO - alphas:tensor([0.3803, 0.1327, 0.1207, 0.1612, 0.2051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,304 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,304 - train - INFO - True
2024-04-07 01:09:30,305 - train - INFO - alphas:tensor([0.6942, 0.0996, 0.0641, 0.0689, 0.0731], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,335 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,335 - train - INFO - True
2024-04-07 01:09:30,336 - train - INFO - alphas:tensor([0.6789, 0.0868, 0.0661, 0.0798, 0.0884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,365 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,365 - train - INFO - True
2024-04-07 01:09:30,366 - train - INFO - alphas:tensor([0.5364, 0.1055, 0.0965, 0.1206, 0.1410], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,394 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,394 - train - INFO - True
2024-04-07 01:09:30,395 - train - INFO - alphas:tensor([0.6579, 0.0970, 0.0694, 0.0829, 0.0928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,424 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,424 - train - INFO - True
2024-04-07 01:09:30,425 - train - INFO - alphas:tensor([0.7636, 0.0758, 0.0468, 0.0530, 0.0607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,453 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,453 - train - INFO - True
2024-04-07 01:09:30,454 - train - INFO - alphas:tensor([0.7625, 0.0769, 0.0478, 0.0542, 0.0585], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,482 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,483 - train - INFO - True
2024-04-07 01:09:30,484 - train - INFO - alphas:tensor([0.5802, 0.0928, 0.0851, 0.1101, 0.1319], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,512 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,512 - train - INFO - True
2024-04-07 01:09:30,513 - train - INFO - alphas:tensor([0.6869, 0.0878, 0.0655, 0.0748, 0.0850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,541 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,542 - train - INFO - True
2024-04-07 01:09:30,542 - train - INFO - alphas:tensor([0.7502, 0.0743, 0.0499, 0.0583, 0.0673], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,571 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,571 - train - INFO - True
2024-04-07 01:09:30,572 - train - INFO - alphas:tensor([0.7157, 0.0785, 0.0588, 0.0708, 0.0761], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,600 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,600 - train - INFO - True
2024-04-07 01:09:30,601 - train - INFO - alphas:tensor([0.5990, 0.0870, 0.0785, 0.1063, 0.1293], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,630 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,630 - train - INFO - True
2024-04-07 01:09:30,631 - train - INFO - alphas:tensor([0.7017, 0.0775, 0.0631, 0.0734, 0.0843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,659 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,659 - train - INFO - True
2024-04-07 01:09:30,660 - train - INFO - alphas:tensor([0.7341, 0.0827, 0.0539, 0.0599, 0.0694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,688 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,689 - train - INFO - True
2024-04-07 01:09:30,690 - train - INFO - alphas:tensor([0.6453, 0.0897, 0.0709, 0.0872, 0.1069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,718 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,718 - train - INFO - True
2024-04-07 01:09:30,719 - train - INFO - alphas:tensor([0.6005, 0.0858, 0.0771, 0.1057, 0.1309], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,747 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,747 - train - INFO - True
2024-04-07 01:09:30,748 - train - INFO - alphas:tensor([0.7098, 0.0736, 0.0622, 0.0728, 0.0816], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,777 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,777 - train - INFO - True
2024-04-07 01:09:30,778 - train - INFO - alphas:tensor([0.7498, 0.0749, 0.0511, 0.0580, 0.0662], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,806 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,806 - train - INFO - True
2024-04-07 01:09:30,807 - train - INFO - alphas:tensor([0.6305, 0.0838, 0.0748, 0.0955, 0.1154], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,835 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,836 - train - INFO - True
2024-04-07 01:09:30,837 - train - INFO - alphas:tensor([0.5800, 0.0853, 0.0842, 0.1127, 0.1377], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,865 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,865 - train - INFO - True
2024-04-07 01:09:30,866 - train - INFO - alphas:tensor([0.7363, 0.0684, 0.0565, 0.0650, 0.0738], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,894 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,894 - train - INFO - True
2024-04-07 01:09:30,895 - train - INFO - alphas:tensor([0.7653, 0.0738, 0.0462, 0.0533, 0.0614], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,920 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,920 - train - INFO - True
2024-04-07 01:09:30,921 - train - INFO - alphas:tensor([0.6552, 0.0759, 0.0693, 0.0902, 0.1093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,944 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,944 - train - INFO - True
2024-04-07 01:09:30,945 - train - INFO - alphas:tensor([0.5766, 0.0826, 0.0818, 0.1168, 0.1423], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,966 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,966 - train - INFO - True
2024-04-07 01:09:30,967 - train - INFO - alphas:tensor([0.7265, 0.0677, 0.0589, 0.0671, 0.0799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:30,987 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:30,987 - train - INFO - True
2024-04-07 01:09:30,988 - train - INFO - alphas:tensor([0.7504, 0.0671, 0.0496, 0.0604, 0.0724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:31,009 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:31,009 - train - INFO - True
2024-04-07 01:09:31,010 - train - INFO - alphas:tensor([0.6699, 0.0742, 0.0641, 0.0863, 0.1054], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:31,031 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:31,031 - train - INFO - True
2024-04-07 01:09:31,032 - train - INFO - alphas:tensor([0.5544, 0.0798, 0.0892, 0.1235, 0.1531], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:31,052 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:31,052 - train - INFO - True
2024-04-07 01:09:31,052 - train - INFO - alphas:tensor([0.7100, 0.0683, 0.0605, 0.0734, 0.0878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:31,071 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:31,071 - train - INFO - True
2024-04-07 01:09:31,072 - train - INFO - alphas:tensor([0.7315, 0.0671, 0.0525, 0.0666, 0.0824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:31,089 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:31,090 - train - INFO - True
2024-04-07 01:09:31,090 - train - INFO - alphas:tensor([0.6943, 0.0696, 0.0615, 0.0798, 0.0948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:31,111 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:31,111 - train - INFO - True
2024-04-07 01:09:31,112 - train - INFO - alphas:tensor([0.5288, 0.0776, 0.0909, 0.1326, 0.1701], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:31,133 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:31,133 - train - INFO - True
2024-04-07 01:09:31,134 - train - INFO - alphas:tensor([0.6715, 0.0748, 0.0668, 0.0849, 0.1020], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:31,153 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:31,153 - train - INFO - True
2024-04-07 01:09:31,154 - train - INFO - alphas:tensor([0.7007, 0.0714, 0.0570, 0.0772, 0.0937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:31,172 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:31,172 - train - INFO - True
2024-04-07 01:09:31,173 - train - INFO - alphas:tensor([0.6768, 0.0712, 0.0642, 0.0854, 0.1024], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:31,190 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:31,190 - train - INFO - True
2024-04-07 01:09:31,191 - train - INFO - alphas:tensor([0.6362, 0.0859, 0.1267, 0.1512], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:09:31,208 - train - INFO - tau:0.8600583546412883
2024-04-07 01:09:31,208 - train - INFO - avg block size:1.0
2024-04-07 01:09:31,208 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 01:09:31,464 - train - INFO - Test: [   0/78]  Time: 0.253 (0.253)  Loss:  1.0703 (1.0703)  Acc@1: 77.3438 (77.3438)  Acc@5: 91.4062 (91.4062)
2024-04-07 01:09:36,041 - train - INFO - Test: [  50/78]  Time: 0.088 (0.095)  Loss:  1.9492 (1.7349)  Acc@1: 57.0312 (59.5129)  Acc@5: 82.0312 (82.1844)
2024-04-07 01:09:38,654 - train - INFO - Test: [  78/78]  Time: 0.055 (0.094)  Loss:  1.5674 (1.7685)  Acc@1: 50.0000 (58.8400)  Acc@5: 100.0000 (81.6800)
2024-04-07 01:09:39,841 - train - INFO - Train: 18 [   0/781 (  0%)]  Loss:  4.090752 (4.0908)  Time: 1.120s,  114.31/s  (1.120s,  114.31/s)  LR: 4.828e-04  Data: 0.178 (0.178)
2024-04-07 01:10:27,228 - train - INFO - Train: 18 [  50/781 (  6%)]  Loss:  4.181066 (3.8860)  Time: 0.906s,  141.36/s  (0.951s,  134.58/s)  LR: 4.828e-04  Data: 0.010 (0.011)
2024-04-07 01:11:14,578 - train - INFO - Train: 18 [ 100/781 ( 13%)]  Loss:  3.398897 (3.8445)  Time: 0.860s,  148.92/s  (0.949s,  134.87/s)  LR: 4.828e-04  Data: 0.009 (0.010)
2024-04-07 01:12:03,112 - train - INFO - Train: 18 [ 150/781 ( 19%)]  Loss:  3.350859 (3.8314)  Time: 0.858s,  149.19/s  (0.956s,  133.86/s)  LR: 4.828e-04  Data: 0.007 (0.009)
2024-04-07 01:12:50,166 - train - INFO - Train: 18 [ 200/781 ( 26%)]  Loss:  3.689698 (3.8328)  Time: 1.054s,  121.38/s  (0.952s,  134.39/s)  LR: 4.828e-04  Data: 0.007 (0.009)
2024-04-07 01:13:37,720 - train - INFO - Train: 18 [ 250/781 ( 32%)]  Loss:  4.180654 (3.8224)  Time: 0.825s,  155.20/s  (0.952s,  134.43/s)  LR: 4.828e-04  Data: 0.007 (0.009)
2024-04-07 01:14:25,312 - train - INFO - Train: 18 [ 300/781 ( 38%)]  Loss:  4.407232 (3.8237)  Time: 1.111s,  115.23/s  (0.952s,  134.44/s)  LR: 4.828e-04  Data: 0.010 (0.009)
2024-04-07 01:15:11,628 - train - INFO - Train: 18 [ 350/781 ( 45%)]  Loss:  3.839898 (3.8335)  Time: 0.808s,  158.36/s  (0.948s,  134.96/s)  LR: 4.828e-04  Data: 0.012 (0.009)
2024-04-07 01:15:58,714 - train - INFO - Train: 18 [ 400/781 ( 51%)]  Loss:  3.900700 (3.8365)  Time: 1.012s,  126.54/s  (0.948s,  135.08/s)  LR: 4.828e-04  Data: 0.006 (0.009)
2024-04-07 01:16:44,890 - train - INFO - Train: 18 [ 450/781 ( 58%)]  Loss:  4.486553 (3.8520)  Time: 0.856s,  149.59/s  (0.945s,  135.46/s)  LR: 4.828e-04  Data: 0.008 (0.009)
2024-04-07 01:17:30,760 - train - INFO - Train: 18 [ 500/781 ( 64%)]  Loss:  3.408260 (3.8447)  Time: 1.021s,  125.42/s  (0.942s,  135.86/s)  LR: 4.828e-04  Data: 0.005 (0.009)
2024-04-07 01:18:17,508 - train - INFO - Train: 18 [ 550/781 ( 71%)]  Loss:  4.082119 (3.8518)  Time: 1.120s,  114.27/s  (0.942s,  135.95/s)  LR: 4.828e-04  Data: 0.007 (0.008)
2024-04-07 01:19:04,622 - train - INFO - Train: 18 [ 600/781 ( 77%)]  Loss:  3.358384 (3.8508)  Time: 1.120s,  114.30/s  (0.942s,  135.94/s)  LR: 4.828e-04  Data: 0.008 (0.008)
2024-04-07 01:19:52,275 - train - INFO - Train: 18 [ 650/781 ( 83%)]  Loss:  3.446166 (3.8473)  Time: 0.832s,  153.89/s  (0.942s,  135.82/s)  LR: 4.828e-04  Data: 0.006 (0.008)
2024-04-07 01:20:39,063 - train - INFO - Train: 18 [ 700/781 ( 90%)]  Loss:  4.463235 (3.8466)  Time: 1.132s,  113.07/s  (0.942s,  135.89/s)  LR: 4.828e-04  Data: 0.009 (0.008)
2024-04-07 01:21:24,743 - train - INFO - Train: 18 [ 750/781 ( 96%)]  Loss:  3.562783 (3.8429)  Time: 0.843s,  151.79/s  (0.940s,  136.16/s)  LR: 4.828e-04  Data: 0.007 (0.008)
2024-04-07 01:21:52,285 - train - INFO - Train: 18 [ 780/781 (100%)]  Loss:  4.042050 (3.8459)  Time: 1.084s,  118.09/s  (0.939s,  136.28/s)  LR: 4.828e-04  Data: 0.000 (0.008)
2024-04-07 01:21:52,286 - train - INFO - True
2024-04-07 01:21:52,288 - train - INFO - alphas:tensor([0.3051, 0.1821, 0.1509, 0.1751, 0.1868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,331 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,331 - train - INFO - True
2024-04-07 01:21:52,332 - train - INFO - alphas:tensor([0.3810, 0.1272, 0.1193, 0.1623, 0.2102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,366 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,366 - train - INFO - True
2024-04-07 01:21:52,367 - train - INFO - alphas:tensor([0.7017, 0.0965, 0.0624, 0.0675, 0.0718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,396 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,396 - train - INFO - True
2024-04-07 01:21:52,397 - train - INFO - alphas:tensor([0.6861, 0.0833, 0.0644, 0.0786, 0.0876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,423 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,423 - train - INFO - True
2024-04-07 01:21:52,424 - train - INFO - alphas:tensor([0.5390, 0.1007, 0.0961, 0.1213, 0.1429], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,448 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,448 - train - INFO - True
2024-04-07 01:21:52,449 - train - INFO - alphas:tensor([0.6659, 0.0928, 0.0676, 0.0818, 0.0921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,470 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,470 - train - INFO - True
2024-04-07 01:21:52,471 - train - INFO - alphas:tensor([0.7672, 0.0736, 0.0460, 0.0526, 0.0606], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,492 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,492 - train - INFO - True
2024-04-07 01:21:52,493 - train - INFO - alphas:tensor([0.7667, 0.0741, 0.0469, 0.0537, 0.0586], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,512 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,512 - train - INFO - True
2024-04-07 01:21:52,513 - train - INFO - alphas:tensor([0.5815, 0.0897, 0.0843, 0.1106, 0.1340], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,531 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,531 - train - INFO - True
2024-04-07 01:21:52,532 - train - INFO - alphas:tensor([0.6896, 0.0852, 0.0645, 0.0748, 0.0858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,550 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,550 - train - INFO - True
2024-04-07 01:21:52,550 - train - INFO - alphas:tensor([0.7508, 0.0726, 0.0494, 0.0586, 0.0685], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,567 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,567 - train - INFO - True
2024-04-07 01:21:52,568 - train - INFO - alphas:tensor([0.7139, 0.0764, 0.0589, 0.0722, 0.0785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,585 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,585 - train - INFO - True
2024-04-07 01:21:52,586 - train - INFO - alphas:tensor([0.6004, 0.0840, 0.0778, 0.1065, 0.1313], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,607 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,607 - train - INFO - True
2024-04-07 01:21:52,608 - train - INFO - alphas:tensor([0.7043, 0.0752, 0.0619, 0.0734, 0.0852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,628 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,628 - train - INFO - True
2024-04-07 01:21:52,628 - train - INFO - alphas:tensor([0.7330, 0.0809, 0.0537, 0.0608, 0.0716], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,647 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,647 - train - INFO - True
2024-04-07 01:21:52,648 - train - INFO - alphas:tensor([0.6428, 0.0861, 0.0705, 0.0890, 0.1115], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,665 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,665 - train - INFO - True
2024-04-07 01:21:52,666 - train - INFO - alphas:tensor([0.6016, 0.0823, 0.0761, 0.1064, 0.1335], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,683 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,683 - train - INFO - True
2024-04-07 01:21:52,683 - train - INFO - alphas:tensor([0.7082, 0.0723, 0.0622, 0.0739, 0.0834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,700 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,700 - train - INFO - True
2024-04-07 01:21:52,701 - train - INFO - alphas:tensor([0.7521, 0.0725, 0.0503, 0.0579, 0.0673], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,718 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,718 - train - INFO - True
2024-04-07 01:21:52,718 - train - INFO - alphas:tensor([0.6293, 0.0799, 0.0737, 0.0972, 0.1199], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,735 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,735 - train - INFO - True
2024-04-07 01:21:52,736 - train - INFO - alphas:tensor([0.5806, 0.0816, 0.0833, 0.1136, 0.1409], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,752 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,753 - train - INFO - True
2024-04-07 01:21:52,753 - train - INFO - alphas:tensor([0.7386, 0.0663, 0.0557, 0.0648, 0.0746], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,770 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,770 - train - INFO - True
2024-04-07 01:21:52,771 - train - INFO - alphas:tensor([0.7645, 0.0722, 0.0461, 0.0540, 0.0631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,787 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,787 - train - INFO - True
2024-04-07 01:21:52,788 - train - INFO - alphas:tensor([0.6514, 0.0723, 0.0687, 0.0928, 0.1147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,809 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,809 - train - INFO - True
2024-04-07 01:21:52,810 - train - INFO - alphas:tensor([0.5756, 0.0791, 0.0812, 0.1180, 0.1461], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,830 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,830 - train - INFO - True
2024-04-07 01:21:52,831 - train - INFO - alphas:tensor([0.7296, 0.0653, 0.0579, 0.0668, 0.0804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,850 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,850 - train - INFO - True
2024-04-07 01:21:52,851 - train - INFO - alphas:tensor([0.7499, 0.0653, 0.0492, 0.0610, 0.0745], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,869 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,869 - train - INFO - True
2024-04-07 01:21:52,869 - train - INFO - alphas:tensor([0.6686, 0.0699, 0.0633, 0.0882, 0.1101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,887 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,887 - train - INFO - True
2024-04-07 01:21:52,887 - train - INFO - alphas:tensor([0.5516, 0.0763, 0.0890, 0.1252, 0.1579], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,904 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,904 - train - INFO - True
2024-04-07 01:21:52,905 - train - INFO - alphas:tensor([0.7096, 0.0660, 0.0604, 0.0741, 0.0899], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,922 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,922 - train - INFO - True
2024-04-07 01:21:52,922 - train - INFO - alphas:tensor([0.7297, 0.0655, 0.0522, 0.0675, 0.0852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,939 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,939 - train - INFO - True
2024-04-07 01:21:52,940 - train - INFO - alphas:tensor([0.6918, 0.0665, 0.0613, 0.0817, 0.0987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,959 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,960 - train - INFO - True
2024-04-07 01:21:52,960 - train - INFO - alphas:tensor([0.5264, 0.0735, 0.0905, 0.1343, 0.1754], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:52,980 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:52,981 - train - INFO - True
2024-04-07 01:21:52,981 - train - INFO - alphas:tensor([0.6738, 0.0713, 0.0655, 0.0850, 0.1044], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:53,000 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:53,000 - train - INFO - True
2024-04-07 01:21:53,001 - train - INFO - alphas:tensor([0.7049, 0.0684, 0.0553, 0.0770, 0.0945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:53,019 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:53,019 - train - INFO - True
2024-04-07 01:21:53,020 - train - INFO - alphas:tensor([0.6804, 0.0677, 0.0629, 0.0852, 0.1038], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:53,037 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:53,037 - train - INFO - True
2024-04-07 01:21:53,037 - train - INFO - alphas:tensor([0.6412, 0.0841, 0.1248, 0.1499], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:21:53,054 - train - INFO - tau:0.8514577710948754
2024-04-07 01:21:53,054 - train - INFO - avg block size:1.0
2024-04-07 01:21:53,054 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 01:21:53,055 - train - INFO - lasso_alpha:1.9487171000000013e-05
2024-04-07 01:21:53,303 - train - INFO - Test: [   0/78]  Time: 0.245 (0.245)  Loss:  1.0977 (1.0977)  Acc@1: 75.7812 (75.7812)  Acc@5: 88.2812 (88.2812)
2024-04-07 01:21:57,975 - train - INFO - Test: [  50/78]  Time: 0.089 (0.096)  Loss:  1.9785 (1.7512)  Acc@1: 52.3438 (59.0993)  Acc@5: 81.2500 (82.2917)
2024-04-07 01:22:00,714 - train - INFO - Test: [  78/78]  Time: 0.053 (0.097)  Loss:  1.5176 (1.7744)  Acc@1: 62.5000 (59.0400)  Acc@5: 93.7500 (81.8900)
2024-04-07 01:22:01,808 - train - INFO - Train: 19 [   0/781 (  0%)]  Loss:  4.354771 (4.3548)  Time: 1.025s,  124.92/s  (1.025s,  124.92/s)  LR: 4.809e-04  Data: 0.173 (0.173)
2024-04-07 01:22:48,270 - train - INFO - Train: 19 [  50/781 (  6%)]  Loss:  3.559138 (3.9084)  Time: 1.084s,  118.05/s  (0.931s,  137.47/s)  LR: 4.809e-04  Data: 0.009 (0.011)
2024-04-07 01:23:35,712 - train - INFO - Train: 19 [ 100/781 ( 13%)]  Loss:  3.106373 (3.8910)  Time: 0.861s,  148.60/s  (0.940s,  136.19/s)  LR: 4.809e-04  Data: 0.011 (0.010)
2024-04-07 01:24:21,938 - train - INFO - Train: 19 [ 150/781 ( 19%)]  Loss:  3.672843 (3.8769)  Time: 0.855s,  149.78/s  (0.935s,  136.93/s)  LR: 4.809e-04  Data: 0.008 (0.009)
2024-04-07 01:25:07,419 - train - INFO - Train: 19 [ 200/781 ( 26%)]  Loss:  3.963326 (3.8619)  Time: 0.831s,  154.01/s  (0.929s,  137.86/s)  LR: 4.809e-04  Data: 0.007 (0.009)
2024-04-07 01:25:56,576 - train - INFO - Train: 19 [ 250/781 ( 32%)]  Loss:  3.516939 (3.8646)  Time: 1.075s,  119.03/s  (0.939s,  136.26/s)  LR: 4.809e-04  Data: 0.011 (0.009)
2024-04-07 01:26:44,191 - train - INFO - Train: 19 [ 300/781 ( 38%)]  Loss:  3.279060 (3.8616)  Time: 1.048s,  122.14/s  (0.942s,  135.95/s)  LR: 4.809e-04  Data: 0.006 (0.009)
2024-04-07 01:27:30,250 - train - INFO - Train: 19 [ 350/781 ( 45%)]  Loss:  4.185046 (3.8531)  Time: 1.085s,  118.02/s  (0.939s,  136.37/s)  LR: 4.809e-04  Data: 0.007 (0.009)
2024-04-07 01:28:17,126 - train - INFO - Train: 19 [ 400/781 ( 51%)]  Loss:  4.401917 (3.8627)  Time: 1.118s,  114.45/s  (0.938s,  136.39/s)  LR: 4.809e-04  Data: 0.008 (0.009)
2024-04-07 01:29:05,405 - train - INFO - Train: 19 [ 450/781 ( 58%)]  Loss:  4.055999 (3.8608)  Time: 1.082s,  118.33/s  (0.941s,  135.96/s)  LR: 4.809e-04  Data: 0.008 (0.009)
2024-04-07 01:29:51,949 - train - INFO - Train: 19 [ 500/781 ( 64%)]  Loss:  3.223876 (3.8536)  Time: 0.831s,  154.04/s  (0.940s,  136.11/s)  LR: 4.809e-04  Data: 0.008 (0.009)
2024-04-07 01:30:39,521 - train - INFO - Train: 19 [ 550/781 ( 71%)]  Loss:  3.364268 (3.8544)  Time: 0.851s,  150.33/s  (0.941s,  135.97/s)  LR: 4.809e-04  Data: 0.007 (0.008)
2024-04-07 01:31:26,120 - train - INFO - Train: 19 [ 600/781 ( 77%)]  Loss:  3.254019 (3.8576)  Time: 0.852s,  150.32/s  (0.941s,  136.08/s)  LR: 4.809e-04  Data: 0.009 (0.008)
2024-04-07 01:32:13,098 - train - INFO - Train: 19 [ 650/781 ( 83%)]  Loss:  4.205206 (3.8632)  Time: 0.860s,  148.83/s  (0.941s,  136.09/s)  LR: 4.809e-04  Data: 0.008 (0.008)
2024-04-07 01:33:01,789 - train - INFO - Train: 19 [ 700/781 ( 90%)]  Loss:  3.844118 (3.8683)  Time: 0.854s,  149.93/s  (0.943s,  135.75/s)  LR: 4.809e-04  Data: 0.008 (0.008)
2024-04-07 01:33:50,118 - train - INFO - Train: 19 [ 750/781 ( 96%)]  Loss:  4.139464 (3.8706)  Time: 1.101s,  116.28/s  (0.944s,  135.52/s)  LR: 4.809e-04  Data: 0.009 (0.008)
2024-04-07 01:34:18,124 - train - INFO - Train: 19 [ 780/781 (100%)]  Loss:  3.314863 (3.8714)  Time: 1.136s,  112.63/s  (0.944s,  135.58/s)  LR: 4.809e-04  Data: 0.000 (0.008)
2024-04-07 01:34:18,125 - train - INFO - True
2024-04-07 01:34:18,127 - train - INFO - alphas:tensor([0.3046, 0.1773, 0.1514, 0.1772, 0.1895], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,169 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,169 - train - INFO - True
2024-04-07 01:34:18,171 - train - INFO - alphas:tensor([0.3803, 0.1228, 0.1177, 0.1635, 0.2157], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,204 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,204 - train - INFO - True
2024-04-07 01:34:18,205 - train - INFO - alphas:tensor([0.7091, 0.0935, 0.0607, 0.0661, 0.0705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,234 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,234 - train - INFO - True
2024-04-07 01:34:18,235 - train - INFO - alphas:tensor([0.6929, 0.0799, 0.0629, 0.0774, 0.0870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,264 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,264 - train - INFO - True
2024-04-07 01:34:18,265 - train - INFO - alphas:tensor([0.5398, 0.0975, 0.0954, 0.1219, 0.1454], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,293 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,293 - train - INFO - True
2024-04-07 01:34:18,294 - train - INFO - alphas:tensor([0.6701, 0.0902, 0.0661, 0.0812, 0.0924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,322 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,322 - train - INFO - True
2024-04-07 01:34:18,323 - train - INFO - alphas:tensor([0.7699, 0.0720, 0.0452, 0.0522, 0.0607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,351 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,351 - train - INFO - True
2024-04-07 01:34:18,352 - train - INFO - alphas:tensor([0.7675, 0.0727, 0.0465, 0.0540, 0.0593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,380 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,381 - train - INFO - True
2024-04-07 01:34:18,381 - train - INFO - alphas:tensor([0.5839, 0.0864, 0.0831, 0.1107, 0.1359], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,410 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,410 - train - INFO - True
2024-04-07 01:34:18,411 - train - INFO - alphas:tensor([0.6923, 0.0828, 0.0637, 0.0745, 0.0867], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,439 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,439 - train - INFO - True
2024-04-07 01:34:18,440 - train - INFO - alphas:tensor([0.7522, 0.0705, 0.0490, 0.0587, 0.0696], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,468 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,468 - train - INFO - True
2024-04-07 01:34:18,469 - train - INFO - alphas:tensor([0.7114, 0.0750, 0.0593, 0.0734, 0.0809], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,497 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,497 - train - INFO - True
2024-04-07 01:34:18,498 - train - INFO - alphas:tensor([0.6030, 0.0811, 0.0762, 0.1065, 0.1333], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,526 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,526 - train - INFO - True
2024-04-07 01:34:18,527 - train - INFO - alphas:tensor([0.7059, 0.0727, 0.0613, 0.0736, 0.0865], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,556 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,556 - train - INFO - True
2024-04-07 01:34:18,557 - train - INFO - alphas:tensor([0.7305, 0.0796, 0.0537, 0.0621, 0.0741], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,585 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,585 - train - INFO - True
2024-04-07 01:34:18,586 - train - INFO - alphas:tensor([0.6383, 0.0831, 0.0704, 0.0916, 0.1166], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,614 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,614 - train - INFO - True
2024-04-07 01:34:18,615 - train - INFO - alphas:tensor([0.6034, 0.0789, 0.0750, 0.1069, 0.1359], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,643 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,643 - train - INFO - True
2024-04-07 01:34:18,644 - train - INFO - alphas:tensor([0.7101, 0.0695, 0.0614, 0.0741, 0.0849], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,672 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,673 - train - INFO - True
2024-04-07 01:34:18,674 - train - INFO - alphas:tensor([0.7489, 0.0709, 0.0506, 0.0596, 0.0701], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,703 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,703 - train - INFO - True
2024-04-07 01:34:18,704 - train - INFO - alphas:tensor([0.6206, 0.0768, 0.0737, 0.1011, 0.1279], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,732 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,732 - train - INFO - True
2024-04-07 01:34:18,733 - train - INFO - alphas:tensor([0.5773, 0.0790, 0.0830, 0.1156, 0.1450], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,761 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,761 - train - INFO - True
2024-04-07 01:34:18,762 - train - INFO - alphas:tensor([0.7375, 0.0641, 0.0557, 0.0659, 0.0767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,790 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,790 - train - INFO - True
2024-04-07 01:34:18,791 - train - INFO - alphas:tensor([0.7638, 0.0701, 0.0461, 0.0550, 0.0650], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,819 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,819 - train - INFO - True
2024-04-07 01:34:18,820 - train - INFO - alphas:tensor([0.6421, 0.0701, 0.0685, 0.0972, 0.1221], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,844 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,845 - train - INFO - True
2024-04-07 01:34:18,845 - train - INFO - alphas:tensor([0.5743, 0.0753, 0.0805, 0.1194, 0.1504], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,868 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,868 - train - INFO - True
2024-04-07 01:34:18,869 - train - INFO - alphas:tensor([0.7328, 0.0626, 0.0567, 0.0665, 0.0814], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,890 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,890 - train - INFO - True
2024-04-07 01:34:18,891 - train - INFO - alphas:tensor([0.7436, 0.0646, 0.0501, 0.0631, 0.0786], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,912 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,912 - train - INFO - True
2024-04-07 01:34:18,913 - train - INFO - alphas:tensor([0.6556, 0.0680, 0.0643, 0.0929, 0.1191], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,934 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,934 - train - INFO - True
2024-04-07 01:34:18,935 - train - INFO - alphas:tensor([0.5512, 0.0716, 0.0877, 0.1268, 0.1626], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,954 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,954 - train - INFO - True
2024-04-07 01:34:18,955 - train - INFO - alphas:tensor([0.7070, 0.0646, 0.0604, 0.0751, 0.0930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,973 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,974 - train - INFO - True
2024-04-07 01:34:18,974 - train - INFO - alphas:tensor([0.7287, 0.0636, 0.0520, 0.0682, 0.0875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:18,992 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:18,992 - train - INFO - True
2024-04-07 01:34:18,993 - train - INFO - alphas:tensor([0.6875, 0.0640, 0.0610, 0.0841, 0.1034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:19,009 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:19,009 - train - INFO - True
2024-04-07 01:34:19,010 - train - INFO - alphas:tensor([0.5254, 0.0701, 0.0892, 0.1355, 0.1799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:19,027 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:19,027 - train - INFO - True
2024-04-07 01:34:19,028 - train - INFO - alphas:tensor([0.6738, 0.0684, 0.0651, 0.0857, 0.1070], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:19,044 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:19,044 - train - INFO - True
2024-04-07 01:34:19,045 - train - INFO - alphas:tensor([0.7026, 0.0667, 0.0552, 0.0781, 0.0974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:19,062 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:19,062 - train - INFO - True
2024-04-07 01:34:19,063 - train - INFO - alphas:tensor([0.6775, 0.0651, 0.0624, 0.0871, 0.1079], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:19,084 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:19,084 - train - INFO - True
2024-04-07 01:34:19,085 - train - INFO - alphas:tensor([0.6465, 0.0818, 0.1230, 0.1486], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:34:19,106 - train - INFO - tau:0.8429431933839266
2024-04-07 01:34:19,106 - train - INFO - avg block size:1.0
2024-04-07 01:34:19,106 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 01:34:19,350 - train - INFO - Test: [   0/78]  Time: 0.240 (0.240)  Loss:  0.9258 (0.9258)  Acc@1: 78.1250 (78.1250)  Acc@5: 93.7500 (93.7500)
2024-04-07 01:34:23,839 - train - INFO - Test: [  50/78]  Time: 0.088 (0.093)  Loss:  1.8926 (1.7242)  Acc@1: 53.9062 (59.8805)  Acc@5: 83.5938 (82.8431)
2024-04-07 01:34:26,389 - train - INFO - Test: [  78/78]  Time: 0.078 (0.092)  Loss:  2.1465 (1.7647)  Acc@1: 56.2500 (59.1200)  Acc@5: 87.5000 (82.0300)
2024-04-07 01:34:27,789 - train - INFO - Train: 20 [   0/781 (  0%)]  Loss:  3.472052 (3.4721)  Time: 1.305s,   98.08/s  (1.305s,   98.08/s)  LR: 4.788e-04  Data: 0.211 (0.211)
2024-04-07 01:35:13,812 - train - INFO - Train: 20 [  50/781 (  6%)]  Loss:  3.366854 (3.7665)  Time: 1.026s,  124.72/s  (0.928s,  137.93/s)  LR: 4.788e-04  Data: 0.005 (0.013)
2024-04-07 01:36:01,034 - train - INFO - Train: 20 [ 100/781 ( 13%)]  Loss:  3.565887 (3.7953)  Time: 0.859s,  148.98/s  (0.936s,  136.74/s)  LR: 4.788e-04  Data: 0.009 (0.010)
2024-04-07 01:36:47,592 - train - INFO - Train: 20 [ 150/781 ( 19%)]  Loss:  4.293546 (3.8559)  Time: 0.862s,  148.53/s  (0.934s,  136.98/s)  LR: 4.788e-04  Data: 0.020 (0.010)
2024-04-07 01:37:34,076 - train - INFO - Train: 20 [ 200/781 ( 26%)]  Loss:  4.447896 (3.8482)  Time: 0.849s,  150.84/s  (0.933s,  137.15/s)  LR: 4.788e-04  Data: 0.008 (0.009)
2024-04-07 01:38:21,202 - train - INFO - Train: 20 [ 250/781 ( 32%)]  Loss:  3.880820 (3.8604)  Time: 1.088s,  117.65/s  (0.935s,  136.88/s)  LR: 4.788e-04  Data: 0.010 (0.009)
2024-04-07 01:39:09,602 - train - INFO - Train: 20 [ 300/781 ( 38%)]  Loss:  4.350734 (3.8840)  Time: 1.079s,  118.59/s  (0.941s,  136.09/s)  LR: 4.788e-04  Data: 0.009 (0.009)
2024-04-07 01:39:55,427 - train - INFO - Train: 20 [ 350/781 ( 45%)]  Loss:  4.009011 (3.8897)  Time: 1.077s,  118.87/s  (0.937s,  136.59/s)  LR: 4.788e-04  Data: 0.007 (0.009)
2024-04-07 01:40:42,578 - train - INFO - Train: 20 [ 400/781 ( 51%)]  Loss:  4.284212 (3.8766)  Time: 1.109s,  115.39/s  (0.938s,  136.48/s)  LR: 4.788e-04  Data: 0.008 (0.009)
2024-04-07 01:41:28,572 - train - INFO - Train: 20 [ 450/781 ( 58%)]  Loss:  3.794508 (3.8751)  Time: 0.851s,  150.37/s  (0.936s,  136.77/s)  LR: 4.788e-04  Data: 0.008 (0.009)
2024-04-07 01:42:12,890 - train - INFO - Train: 20 [ 500/781 ( 64%)]  Loss:  3.930269 (3.8837)  Time: 0.835s,  153.35/s  (0.931s,  137.50/s)  LR: 4.788e-04  Data: 0.007 (0.009)
2024-04-07 01:42:58,626 - train - INFO - Train: 20 [ 550/781 ( 71%)]  Loss:  3.428260 (3.8850)  Time: 0.821s,  155.91/s  (0.929s,  137.72/s)  LR: 4.788e-04  Data: 0.004 (0.009)
2024-04-07 01:43:43,872 - train - INFO - Train: 20 [ 600/781 ( 77%)]  Loss:  4.079660 (3.8868)  Time: 0.856s,  149.56/s  (0.927s,  138.02/s)  LR: 4.788e-04  Data: 0.008 (0.009)
2024-04-07 01:44:30,602 - train - INFO - Train: 20 [ 650/781 ( 83%)]  Loss:  3.499705 (3.8791)  Time: 1.092s,  117.24/s  (0.928s,  137.94/s)  LR: 4.788e-04  Data: 0.009 (0.009)
2024-04-07 01:45:16,469 - train - INFO - Train: 20 [ 700/781 ( 90%)]  Loss:  3.480989 (3.8755)  Time: 0.837s,  152.96/s  (0.927s,  138.05/s)  LR: 4.788e-04  Data: 0.006 (0.009)
2024-04-07 01:46:03,360 - train - INFO - Train: 20 [ 750/781 ( 96%)]  Loss:  4.165378 (3.8723)  Time: 1.096s,  116.80/s  (0.928s,  137.95/s)  LR: 4.788e-04  Data: 0.018 (0.009)
2024-04-07 01:46:31,368 - train - INFO - Train: 20 [ 780/781 (100%)]  Loss:  4.461443 (3.8682)  Time: 1.081s,  118.45/s  (0.928s,  137.92/s)  LR: 4.788e-04  Data: 0.000 (0.008)
2024-04-07 01:46:31,369 - train - INFO - True
2024-04-07 01:46:31,372 - train - INFO - alphas:tensor([0.3024, 0.1734, 0.1520, 0.1794, 0.1927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,416 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,416 - train - INFO - True
2024-04-07 01:46:31,418 - train - INFO - alphas:tensor([0.3798, 0.1189, 0.1159, 0.1645, 0.2209], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,452 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,453 - train - INFO - True
2024-04-07 01:46:31,454 - train - INFO - alphas:tensor([0.7149, 0.0909, 0.0595, 0.0651, 0.0696], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,483 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,483 - train - INFO - True
2024-04-07 01:46:31,484 - train - INFO - alphas:tensor([0.6966, 0.0781, 0.0615, 0.0768, 0.0870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,510 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,510 - train - INFO - True
2024-04-07 01:46:31,511 - train - INFO - alphas:tensor([0.5407, 0.0940, 0.0947, 0.1227, 0.1479], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,535 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,535 - train - INFO - True
2024-04-07 01:46:31,536 - train - INFO - alphas:tensor([0.6720, 0.0882, 0.0653, 0.0812, 0.0932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,557 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,557 - train - INFO - True
2024-04-07 01:46:31,558 - train - INFO - alphas:tensor([0.7750, 0.0694, 0.0440, 0.0514, 0.0602], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,578 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,578 - train - INFO - True
2024-04-07 01:46:31,579 - train - INFO - alphas:tensor([0.7703, 0.0708, 0.0454, 0.0537, 0.0598], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,598 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,598 - train - INFO - True
2024-04-07 01:46:31,599 - train - INFO - alphas:tensor([0.5850, 0.0834, 0.0826, 0.1111, 0.1379], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,617 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,617 - train - INFO - True
2024-04-07 01:46:31,618 - train - INFO - alphas:tensor([0.6950, 0.0797, 0.0631, 0.0744, 0.0878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,635 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,635 - train - INFO - True
2024-04-07 01:46:31,635 - train - INFO - alphas:tensor([0.7522, 0.0687, 0.0490, 0.0592, 0.0710], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,653 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,653 - train - INFO - True
2024-04-07 01:46:31,653 - train - INFO - alphas:tensor([0.7115, 0.0729, 0.0586, 0.0741, 0.0829], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,675 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,675 - train - INFO - True
2024-04-07 01:46:31,676 - train - INFO - alphas:tensor([0.6037, 0.0782, 0.0753, 0.1073, 0.1355], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,695 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,695 - train - INFO - True
2024-04-07 01:46:31,696 - train - INFO - alphas:tensor([0.7052, 0.0710, 0.0610, 0.0743, 0.0885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,714 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,714 - train - INFO - True
2024-04-07 01:46:31,715 - train - INFO - alphas:tensor([0.7291, 0.0777, 0.0536, 0.0630, 0.0765], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,733 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,733 - train - INFO - True
2024-04-07 01:46:31,733 - train - INFO - alphas:tensor([0.6355, 0.0801, 0.0695, 0.0934, 0.1215], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,750 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,750 - train - INFO - True
2024-04-07 01:46:31,751 - train - INFO - alphas:tensor([0.6028, 0.0759, 0.0742, 0.1079, 0.1391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,767 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,767 - train - INFO - True
2024-04-07 01:46:31,768 - train - INFO - alphas:tensor([0.7135, 0.0665, 0.0603, 0.0739, 0.0858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,785 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,785 - train - INFO - True
2024-04-07 01:46:31,786 - train - INFO - alphas:tensor([0.7454, 0.0697, 0.0509, 0.0612, 0.0728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,807 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,807 - train - INFO - True
2024-04-07 01:46:31,808 - train - INFO - alphas:tensor([0.6168, 0.0737, 0.0724, 0.1032, 0.1339], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,827 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,827 - train - INFO - True
2024-04-07 01:46:31,828 - train - INFO - alphas:tensor([0.5781, 0.0763, 0.0816, 0.1161, 0.1480], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,846 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,846 - train - INFO - True
2024-04-07 01:46:31,847 - train - INFO - alphas:tensor([0.7414, 0.0618, 0.0544, 0.0653, 0.0771], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,864 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,864 - train - INFO - True
2024-04-07 01:46:31,865 - train - INFO - alphas:tensor([0.7626, 0.0686, 0.0458, 0.0558, 0.0672], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,882 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,882 - train - INFO - True
2024-04-07 01:46:31,883 - train - INFO - alphas:tensor([0.6356, 0.0666, 0.0674, 0.1006, 0.1298], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,900 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,900 - train - INFO - True
2024-04-07 01:46:31,901 - train - INFO - alphas:tensor([0.5715, 0.0723, 0.0800, 0.1211, 0.1551], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,922 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,922 - train - INFO - True
2024-04-07 01:46:31,923 - train - INFO - alphas:tensor([0.7306, 0.0619, 0.0562, 0.0675, 0.0838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,942 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,942 - train - INFO - True
2024-04-07 01:46:31,943 - train - INFO - alphas:tensor([0.7450, 0.0620, 0.0492, 0.0634, 0.0804], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,961 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,961 - train - INFO - True
2024-04-07 01:46:31,962 - train - INFO - alphas:tensor([0.6535, 0.0653, 0.0631, 0.0938, 0.1243], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,979 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,979 - train - INFO - True
2024-04-07 01:46:31,980 - train - INFO - alphas:tensor([0.5511, 0.0688, 0.0864, 0.1276, 0.1661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:31,997 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:31,997 - train - INFO - True
2024-04-07 01:46:31,998 - train - INFO - alphas:tensor([0.7104, 0.0618, 0.0593, 0.0745, 0.0939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:32,016 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:32,016 - train - INFO - True
2024-04-07 01:46:32,017 - train - INFO - alphas:tensor([0.7311, 0.0603, 0.0509, 0.0684, 0.0893], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:32,038 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:32,038 - train - INFO - True
2024-04-07 01:46:32,039 - train - INFO - alphas:tensor([0.6863, 0.0611, 0.0600, 0.0850, 0.1076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:32,058 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:32,058 - train - INFO - True
2024-04-07 01:46:32,058 - train - INFO - alphas:tensor([0.5224, 0.0666, 0.0883, 0.1371, 0.1855], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:32,076 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:32,076 - train - INFO - True
2024-04-07 01:46:32,077 - train - INFO - alphas:tensor([0.6723, 0.0656, 0.0641, 0.0869, 0.1111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:32,094 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:32,094 - train - INFO - True
2024-04-07 01:46:32,095 - train - INFO - alphas:tensor([0.7018, 0.0648, 0.0544, 0.0788, 0.1002], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:32,112 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:32,112 - train - INFO - True
2024-04-07 01:46:32,112 - train - INFO - alphas:tensor([0.6757, 0.0625, 0.0617, 0.0885, 0.1116], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:32,129 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:32,129 - train - INFO - True
2024-04-07 01:46:32,130 - train - INFO - alphas:tensor([0.6501, 0.0802, 0.1216, 0.1481], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:46:32,147 - train - INFO - tau:0.8345137614500874
2024-04-07 01:46:32,147 - train - INFO - avg block size:1.0
2024-04-07 01:46:32,147 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 01:46:32,147 - train - INFO - lasso_alpha:2.1435888100000015e-05
2024-04-07 01:46:32,429 - train - INFO - Test: [   0/78]  Time: 0.278 (0.278)  Loss:  1.1260 (1.1260)  Acc@1: 77.3438 (77.3438)  Acc@5: 91.4062 (91.4062)
2024-04-07 01:46:37,606 - train - INFO - Test: [  50/78]  Time: 0.104 (0.107)  Loss:  1.9473 (1.7213)  Acc@1: 52.3438 (59.6507)  Acc@5: 77.3438 (82.4449)
2024-04-07 01:46:40,004 - train - INFO - Test: [  78/78]  Time: 0.053 (0.099)  Loss:  1.7617 (1.7445)  Acc@1: 62.5000 (59.1900)  Acc@5: 81.2500 (82.1700)
2024-04-07 01:46:41,116 - train - INFO - Train: 21 [   0/781 (  0%)]  Loss:  4.362669 (4.3627)  Time: 1.038s,  123.33/s  (1.038s,  123.33/s)  LR: 4.767e-04  Data: 0.190 (0.190)
2024-04-07 01:47:29,023 - train - INFO - Train: 21 [  50/781 (  6%)]  Loss:  3.971545 (3.8766)  Time: 1.017s,  125.81/s  (0.960s,  133.38/s)  LR: 4.767e-04  Data: 0.006 (0.012)
2024-04-07 01:48:16,951 - train - INFO - Train: 21 [ 100/781 ( 13%)]  Loss:  4.307895 (3.8408)  Time: 0.806s,  158.87/s  (0.959s,  133.46/s)  LR: 4.767e-04  Data: 0.004 (0.010)
2024-04-07 01:49:03,702 - train - INFO - Train: 21 [ 150/781 ( 19%)]  Loss:  4.282542 (3.8642)  Time: 1.029s,  124.43/s  (0.951s,  134.58/s)  LR: 4.767e-04  Data: 0.005 (0.009)
2024-04-07 01:49:51,635 - train - INFO - Train: 21 [ 200/781 ( 26%)]  Loss:  4.253094 (3.8808)  Time: 1.096s,  116.75/s  (0.953s,  134.31/s)  LR: 4.767e-04  Data: 0.008 (0.009)
2024-04-07 01:50:38,003 - train - INFO - Train: 21 [ 250/781 ( 32%)]  Loss:  4.334326 (3.8958)  Time: 0.848s,  150.95/s  (0.948s,  135.04/s)  LR: 4.767e-04  Data: 0.007 (0.009)
2024-04-07 01:51:24,431 - train - INFO - Train: 21 [ 300/781 ( 38%)]  Loss:  3.354872 (3.8814)  Time: 1.138s,  112.50/s  (0.945s,  135.50/s)  LR: 4.767e-04  Data: 0.008 (0.009)
2024-04-07 01:52:11,633 - train - INFO - Train: 21 [ 350/781 ( 45%)]  Loss:  4.253835 (3.8941)  Time: 0.850s,  150.55/s  (0.945s,  135.51/s)  LR: 4.767e-04  Data: 0.008 (0.009)
2024-04-07 01:52:59,025 - train - INFO - Train: 21 [ 400/781 ( 51%)]  Loss:  3.321115 (3.8950)  Time: 0.855s,  149.65/s  (0.945s,  135.45/s)  LR: 4.767e-04  Data: 0.008 (0.009)
2024-04-07 01:53:47,207 - train - INFO - Train: 21 [ 450/781 ( 58%)]  Loss:  4.370501 (3.8905)  Time: 1.082s,  118.29/s  (0.947s,  135.16/s)  LR: 4.767e-04  Data: 0.016 (0.009)
2024-04-07 01:54:34,970 - train - INFO - Train: 21 [ 500/781 ( 64%)]  Loss:  4.275551 (3.8865)  Time: 0.803s,  159.40/s  (0.948s,  135.04/s)  LR: 4.767e-04  Data: 0.004 (0.009)
2024-04-07 01:55:23,474 - train - INFO - Train: 21 [ 550/781 ( 71%)]  Loss:  4.120857 (3.8788)  Time: 1.050s,  121.92/s  (0.950s,  134.76/s)  LR: 4.767e-04  Data: 0.005 (0.009)
2024-04-07 01:56:09,394 - train - INFO - Train: 21 [ 600/781 ( 77%)]  Loss:  4.346640 (3.8697)  Time: 0.816s,  156.91/s  (0.947s,  135.13/s)  LR: 4.767e-04  Data: 0.005 (0.008)
2024-04-07 01:56:56,493 - train - INFO - Train: 21 [ 650/781 ( 83%)]  Loss:  4.003071 (3.8696)  Time: 0.872s,  146.87/s  (0.947s,  135.19/s)  LR: 4.767e-04  Data: 0.008 (0.008)
2024-04-07 01:57:42,909 - train - INFO - Train: 21 [ 700/781 ( 90%)]  Loss:  3.268495 (3.8693)  Time: 0.821s,  155.86/s  (0.945s,  135.38/s)  LR: 4.767e-04  Data: 0.006 (0.008)
2024-04-07 01:58:29,282 - train - INFO - Train: 21 [ 750/781 ( 96%)]  Loss:  4.269895 (3.8715)  Time: 1.063s,  120.38/s  (0.944s,  135.55/s)  LR: 4.767e-04  Data: 0.008 (0.008)
2024-04-07 01:58:56,325 - train - INFO - Train: 21 [ 780/781 (100%)]  Loss:  4.147005 (3.8717)  Time: 0.856s,  149.61/s  (0.943s,  135.79/s)  LR: 4.767e-04  Data: 0.000 (0.008)
2024-04-07 01:58:56,326 - train - INFO - True
2024-04-07 01:58:56,328 - train - INFO - alphas:tensor([0.2986, 0.1691, 0.1531, 0.1825, 0.1967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,369 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,369 - train - INFO - True
2024-04-07 01:58:56,370 - train - INFO - alphas:tensor([0.3784, 0.1138, 0.1146, 0.1661, 0.2272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,403 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,403 - train - INFO - True
2024-04-07 01:58:56,404 - train - INFO - alphas:tensor([0.7200, 0.0886, 0.0584, 0.0642, 0.0689], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,432 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,432 - train - INFO - True
2024-04-07 01:58:56,433 - train - INFO - alphas:tensor([0.7009, 0.0753, 0.0605, 0.0764, 0.0869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,458 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,458 - train - INFO - True
2024-04-07 01:58:56,459 - train - INFO - alphas:tensor([0.5416, 0.0916, 0.0937, 0.1232, 0.1500], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,482 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,482 - train - INFO - True
2024-04-07 01:58:56,483 - train - INFO - alphas:tensor([0.6732, 0.0858, 0.0650, 0.0814, 0.0945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,505 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,505 - train - INFO - True
2024-04-07 01:58:56,505 - train - INFO - alphas:tensor([0.7756, 0.0679, 0.0438, 0.0517, 0.0610], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,525 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,525 - train - INFO - True
2024-04-07 01:58:56,526 - train - INFO - alphas:tensor([0.7673, 0.0703, 0.0457, 0.0550, 0.0618], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,545 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,545 - train - INFO - True
2024-04-07 01:58:56,546 - train - INFO - alphas:tensor([0.5879, 0.0805, 0.0813, 0.1109, 0.1395], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,567 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,567 - train - INFO - True
2024-04-07 01:58:56,568 - train - INFO - alphas:tensor([0.6985, 0.0780, 0.0616, 0.0739, 0.0879], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,588 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,588 - train - INFO - True
2024-04-07 01:58:56,589 - train - INFO - alphas:tensor([0.7504, 0.0675, 0.0488, 0.0603, 0.0730], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,608 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,608 - train - INFO - True
2024-04-07 01:58:56,608 - train - INFO - alphas:tensor([0.7094, 0.0708, 0.0583, 0.0758, 0.0856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,626 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,627 - train - INFO - True
2024-04-07 01:58:56,627 - train - INFO - alphas:tensor([0.6035, 0.0752, 0.0745, 0.1083, 0.1385], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,644 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,644 - train - INFO - True
2024-04-07 01:58:56,645 - train - INFO - alphas:tensor([0.7051, 0.0688, 0.0606, 0.0752, 0.0903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,662 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,662 - train - INFO - True
2024-04-07 01:58:56,662 - train - INFO - alphas:tensor([0.7231, 0.0772, 0.0544, 0.0653, 0.0800], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,679 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,679 - train - INFO - True
2024-04-07 01:58:56,680 - train - INFO - alphas:tensor([0.6254, 0.0774, 0.0701, 0.0976, 0.1295], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,699 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,699 - train - INFO - True
2024-04-07 01:58:56,700 - train - INFO - alphas:tensor([0.6042, 0.0734, 0.0729, 0.1081, 0.1414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,721 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,721 - train - INFO - True
2024-04-07 01:58:56,722 - train - INFO - alphas:tensor([0.7132, 0.0646, 0.0601, 0.0744, 0.0877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,741 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,741 - train - INFO - True
2024-04-07 01:58:56,742 - train - INFO - alphas:tensor([0.7420, 0.0686, 0.0509, 0.0627, 0.0759], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,761 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,761 - train - INFO - True
2024-04-07 01:58:56,762 - train - INFO - alphas:tensor([0.6119, 0.0704, 0.0710, 0.1057, 0.1410], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,779 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,779 - train - INFO - True
2024-04-07 01:58:56,780 - train - INFO - alphas:tensor([0.5761, 0.0735, 0.0809, 0.1173, 0.1522], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,797 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,797 - train - INFO - True
2024-04-07 01:58:56,798 - train - INFO - alphas:tensor([0.7404, 0.0607, 0.0538, 0.0659, 0.0792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,814 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,814 - train - INFO - True
2024-04-07 01:58:56,815 - train - INFO - alphas:tensor([0.7573, 0.0685, 0.0460, 0.0575, 0.0706], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,833 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,833 - train - INFO - True
2024-04-07 01:58:56,834 - train - INFO - alphas:tensor([0.6272, 0.0635, 0.0669, 0.1039, 0.1386], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,855 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,855 - train - INFO - True
2024-04-07 01:58:56,856 - train - INFO - alphas:tensor([0.5697, 0.0698, 0.0792, 0.1223, 0.1591], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,875 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,875 - train - INFO - True
2024-04-07 01:58:56,876 - train - INFO - alphas:tensor([0.7321, 0.0597, 0.0554, 0.0673, 0.0855], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,894 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,895 - train - INFO - True
2024-04-07 01:58:56,895 - train - INFO - alphas:tensor([0.7452, 0.0602, 0.0484, 0.0638, 0.0825], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,913 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,913 - train - INFO - True
2024-04-07 01:58:56,913 - train - INFO - alphas:tensor([0.6465, 0.0630, 0.0626, 0.0966, 0.1314], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,930 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,930 - train - INFO - True
2024-04-07 01:58:56,931 - train - INFO - alphas:tensor([0.5445, 0.0658, 0.0864, 0.1306, 0.1728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,948 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,948 - train - INFO - True
2024-04-07 01:58:56,948 - train - INFO - alphas:tensor([0.7061, 0.0600, 0.0598, 0.0762, 0.0980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,965 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,965 - train - INFO - True
2024-04-07 01:58:56,966 - train - INFO - alphas:tensor([0.7271, 0.0589, 0.0512, 0.0699, 0.0929], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:56,986 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:56,986 - train - INFO - True
2024-04-07 01:58:56,987 - train - INFO - alphas:tensor([0.6802, 0.0592, 0.0595, 0.0875, 0.1136], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:57,008 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:57,008 - train - INFO - True
2024-04-07 01:58:57,008 - train - INFO - alphas:tensor([0.5207, 0.0625, 0.0874, 0.1384, 0.1910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:57,028 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:57,028 - train - INFO - True
2024-04-07 01:58:57,028 - train - INFO - alphas:tensor([0.6677, 0.0646, 0.0639, 0.0884, 0.1153], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:57,046 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:57,046 - train - INFO - True
2024-04-07 01:58:57,047 - train - INFO - alphas:tensor([0.7010, 0.0630, 0.0535, 0.0796, 0.1028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:57,064 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:57,065 - train - INFO - True
2024-04-07 01:58:57,065 - train - INFO - alphas:tensor([0.6731, 0.0603, 0.0611, 0.0899, 0.1156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:57,082 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:57,083 - train - INFO - True
2024-04-07 01:58:57,083 - train - INFO - alphas:tensor([0.6548, 0.0783, 0.1199, 0.1471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 01:58:57,100 - train - INFO - tau:0.8261686238355865
2024-04-07 01:58:57,100 - train - INFO - avg block size:1.0
2024-04-07 01:58:57,100 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 01:58:57,345 - train - INFO - Test: [   0/78]  Time: 0.241 (0.241)  Loss:  0.9067 (0.9067)  Acc@1: 79.6875 (79.6875)  Acc@5: 95.3125 (95.3125)
2024-04-07 01:59:01,938 - train - INFO - Test: [  50/78]  Time: 0.085 (0.095)  Loss:  2.1074 (1.7688)  Acc@1: 49.2188 (58.3027)  Acc@5: 78.1250 (82.4295)
2024-04-07 01:59:04,518 - train - INFO - Test: [  78/78]  Time: 0.054 (0.094)  Loss:  2.3262 (1.7943)  Acc@1: 43.7500 (57.8200)  Acc@5: 87.5000 (81.8900)
2024-04-07 01:59:05,841 - train - INFO - Train: 22 [   0/781 (  0%)]  Loss:  3.397964 (3.3980)  Time: 1.255s,  102.01/s  (1.255s,  102.01/s)  LR: 4.744e-04  Data: 0.172 (0.172)
2024-04-07 01:59:51,823 - train - INFO - Train: 22 [  50/781 (  6%)]  Loss:  4.298365 (3.9775)  Time: 0.984s,  130.06/s  (0.926s,  138.20/s)  LR: 4.744e-04  Data: 0.008 (0.011)
2024-04-07 02:00:37,477 - train - INFO - Train: 22 [ 100/781 ( 13%)]  Loss:  4.120411 (3.9555)  Time: 1.085s,  117.94/s  (0.920s,  139.18/s)  LR: 4.744e-04  Data: 0.006 (0.010)
2024-04-07 02:01:24,722 - train - INFO - Train: 22 [ 150/781 ( 19%)]  Loss:  4.360475 (3.9491)  Time: 1.045s,  122.52/s  (0.928s,  137.93/s)  LR: 4.744e-04  Data: 0.007 (0.009)
2024-04-07 02:02:10,423 - train - INFO - Train: 22 [ 200/781 ( 26%)]  Loss:  3.956730 (3.9551)  Time: 0.862s,  148.51/s  (0.925s,  138.45/s)  LR: 4.744e-04  Data: 0.009 (0.009)
2024-04-07 02:02:57,087 - train - INFO - Train: 22 [ 250/781 ( 32%)]  Loss:  4.241418 (3.9431)  Time: 1.095s,  116.94/s  (0.926s,  138.19/s)  LR: 4.744e-04  Data: 0.009 (0.009)
2024-04-07 02:03:44,458 - train - INFO - Train: 22 [ 300/781 ( 38%)]  Loss:  3.267910 (3.9273)  Time: 0.920s,  139.15/s  (0.930s,  137.67/s)  LR: 4.744e-04  Data: 0.010 (0.009)
2024-04-07 02:04:29,221 - train - INFO - Train: 22 [ 350/781 ( 45%)]  Loss:  4.351861 (3.9140)  Time: 0.865s,  147.95/s  (0.925s,  138.40/s)  LR: 4.744e-04  Data: 0.009 (0.008)
2024-04-07 02:05:16,971 - train - INFO - Train: 22 [ 400/781 ( 51%)]  Loss:  3.789659 (3.9071)  Time: 0.860s,  148.76/s  (0.929s,  137.84/s)  LR: 4.744e-04  Data: 0.009 (0.008)
2024-04-07 02:06:02,868 - train - INFO - Train: 22 [ 450/781 ( 58%)]  Loss:  3.849639 (3.9023)  Time: 0.828s,  154.51/s  (0.927s,  138.02/s)  LR: 4.744e-04  Data: 0.008 (0.008)
2024-04-07 02:06:49,247 - train - INFO - Train: 22 [ 500/781 ( 64%)]  Loss:  3.473121 (3.8982)  Time: 0.851s,  150.50/s  (0.927s,  138.02/s)  LR: 4.744e-04  Data: 0.009 (0.008)
2024-04-07 02:07:35,102 - train - INFO - Train: 22 [ 550/781 ( 71%)]  Loss:  3.945371 (3.8926)  Time: 0.851s,  150.46/s  (0.926s,  138.16/s)  LR: 4.744e-04  Data: 0.008 (0.008)
2024-04-07 02:08:20,985 - train - INFO - Train: 22 [ 600/781 ( 77%)]  Loss:  4.319862 (3.8885)  Time: 1.067s,  119.98/s  (0.926s,  138.27/s)  LR: 4.744e-04  Data: 0.009 (0.008)
2024-04-07 02:09:06,720 - train - INFO - Train: 22 [ 650/781 ( 83%)]  Loss:  4.108066 (3.8792)  Time: 1.108s,  115.47/s  (0.925s,  138.39/s)  LR: 4.744e-04  Data: 0.023 (0.008)
2024-04-07 02:09:52,960 - train - INFO - Train: 22 [ 700/781 ( 90%)]  Loss:  4.148793 (3.8776)  Time: 1.016s,  125.97/s  (0.925s,  138.40/s)  LR: 4.744e-04  Data: 0.006 (0.008)
2024-04-07 02:10:39,091 - train - INFO - Train: 22 [ 750/781 ( 96%)]  Loss:  3.639853 (3.8794)  Time: 1.040s,  123.09/s  (0.925s,  138.42/s)  LR: 4.744e-04  Data: 0.012 (0.008)
2024-04-07 02:11:06,435 - train - INFO - Train: 22 [ 780/781 (100%)]  Loss:  4.344314 (3.8813)  Time: 1.094s,  116.96/s  (0.924s,  138.49/s)  LR: 4.744e-04  Data: 0.000 (0.008)
2024-04-07 02:11:06,436 - train - INFO - True
2024-04-07 02:11:06,439 - train - INFO - alphas:tensor([0.2960, 0.1651, 0.1536, 0.1852, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,483 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,483 - train - INFO - True
2024-04-07 02:11:06,484 - train - INFO - alphas:tensor([0.3765, 0.1100, 0.1138, 0.1670, 0.2326], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,519 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,519 - train - INFO - True
2024-04-07 02:11:06,520 - train - INFO - alphas:tensor([0.7255, 0.0863, 0.0571, 0.0631, 0.0680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,550 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,550 - train - INFO - True
2024-04-07 02:11:06,551 - train - INFO - alphas:tensor([0.7050, 0.0732, 0.0594, 0.0756, 0.0867], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,577 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,577 - train - INFO - True
2024-04-07 02:11:06,578 - train - INFO - alphas:tensor([0.5397, 0.0895, 0.0934, 0.1243, 0.1531], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,601 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,601 - train - INFO - True
2024-04-07 02:11:06,602 - train - INFO - alphas:tensor([0.6754, 0.0833, 0.0643, 0.0814, 0.0956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,624 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,624 - train - INFO - True
2024-04-07 02:11:06,625 - train - INFO - alphas:tensor([0.7769, 0.0666, 0.0433, 0.0517, 0.0615], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,646 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,646 - train - INFO - True
2024-04-07 02:11:06,647 - train - INFO - alphas:tensor([0.7642, 0.0705, 0.0456, 0.0559, 0.0637], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,668 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,668 - train - INFO - True
2024-04-07 02:11:06,668 - train - INFO - alphas:tensor([0.5845, 0.0787, 0.0811, 0.1124, 0.1433], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,688 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,688 - train - INFO - True
2024-04-07 02:11:06,688 - train - INFO - alphas:tensor([0.6994, 0.0762, 0.0611, 0.0741, 0.0893], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,706 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,706 - train - INFO - True
2024-04-07 02:11:06,707 - train - INFO - alphas:tensor([0.7505, 0.0654, 0.0486, 0.0609, 0.0747], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,724 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,724 - train - INFO - True
2024-04-07 02:11:06,725 - train - INFO - alphas:tensor([0.7029, 0.0702, 0.0591, 0.0782, 0.0896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,742 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,742 - train - INFO - True
2024-04-07 02:11:06,742 - train - INFO - alphas:tensor([0.6039, 0.0727, 0.0736, 0.1087, 0.1410], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,759 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,759 - train - INFO - True
2024-04-07 02:11:06,760 - train - INFO - alphas:tensor([0.7052, 0.0667, 0.0601, 0.0757, 0.0923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,776 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,776 - train - INFO - True
2024-04-07 02:11:06,777 - train - INFO - alphas:tensor([0.7208, 0.0753, 0.0542, 0.0668, 0.0828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,797 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,797 - train - INFO - True
2024-04-07 02:11:06,798 - train - INFO - alphas:tensor([0.6202, 0.0748, 0.0696, 0.0999, 0.1355], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,818 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,818 - train - INFO - True
2024-04-07 02:11:06,819 - train - INFO - alphas:tensor([0.6022, 0.0712, 0.0723, 0.1095, 0.1449], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,838 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,838 - train - INFO - True
2024-04-07 02:11:06,839 - train - INFO - alphas:tensor([0.7123, 0.0628, 0.0597, 0.0751, 0.0900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,856 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,856 - train - INFO - True
2024-04-07 02:11:06,857 - train - INFO - alphas:tensor([0.7389, 0.0673, 0.0509, 0.0642, 0.0787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,874 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,874 - train - INFO - True
2024-04-07 02:11:06,875 - train - INFO - alphas:tensor([0.6079, 0.0674, 0.0692, 0.1076, 0.1479], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,891 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,892 - train - INFO - True
2024-04-07 02:11:06,892 - train - INFO - alphas:tensor([0.5749, 0.0709, 0.0798, 0.1185, 0.1558], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,909 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,909 - train - INFO - True
2024-04-07 02:11:06,910 - train - INFO - alphas:tensor([0.7385, 0.0593, 0.0540, 0.0669, 0.0814], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,928 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,928 - train - INFO - True
2024-04-07 02:11:06,928 - train - INFO - alphas:tensor([0.7539, 0.0680, 0.0461, 0.0587, 0.0733], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,950 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,950 - train - INFO - True
2024-04-07 02:11:06,950 - train - INFO - alphas:tensor([0.6217, 0.0614, 0.0661, 0.1057, 0.1451], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,970 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,970 - train - INFO - True
2024-04-07 02:11:06,971 - train - INFO - alphas:tensor([0.5677, 0.0670, 0.0786, 0.1234, 0.1632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:06,989 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:06,989 - train - INFO - True
2024-04-07 02:11:06,990 - train - INFO - alphas:tensor([0.7311, 0.0583, 0.0553, 0.0678, 0.0875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:07,008 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:07,008 - train - INFO - True
2024-04-07 02:11:07,008 - train - INFO - alphas:tensor([0.7441, 0.0583, 0.0479, 0.0647, 0.0849], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:07,025 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:07,025 - train - INFO - True
2024-04-07 02:11:07,026 - train - INFO - alphas:tensor([0.6443, 0.0605, 0.0606, 0.0976, 0.1369], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:07,043 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:07,043 - train - INFO - True
2024-04-07 02:11:07,044 - train - INFO - alphas:tensor([0.5419, 0.0628, 0.0858, 0.1319, 0.1776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:07,060 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:07,060 - train - INFO - True
2024-04-07 02:11:07,061 - train - INFO - alphas:tensor([0.7053, 0.0578, 0.0596, 0.0768, 0.1005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:07,078 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:07,078 - train - INFO - True
2024-04-07 02:11:07,078 - train - INFO - alphas:tensor([0.7273, 0.0564, 0.0502, 0.0705, 0.0955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:07,100 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:07,100 - train - INFO - True
2024-04-07 02:11:07,101 - train - INFO - alphas:tensor([0.6756, 0.0572, 0.0590, 0.0899, 0.1182], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:07,120 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:07,120 - train - INFO - True
2024-04-07 02:11:07,121 - train - INFO - alphas:tensor([0.5192, 0.0602, 0.0859, 0.1391, 0.1955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:07,139 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:07,139 - train - INFO - True
2024-04-07 02:11:07,140 - train - INFO - alphas:tensor([0.6694, 0.0618, 0.0624, 0.0885, 0.1179], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:07,158 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:07,158 - train - INFO - True
2024-04-07 02:11:07,158 - train - INFO - alphas:tensor([0.7006, 0.0613, 0.0527, 0.0799, 0.1054], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:07,175 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:07,175 - train - INFO - True
2024-04-07 02:11:07,176 - train - INFO - alphas:tensor([0.6715, 0.0578, 0.0602, 0.0912, 0.1193], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:07,193 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:07,193 - train - INFO - True
2024-04-07 02:11:07,193 - train - INFO - alphas:tensor([0.6591, 0.0762, 0.1183, 0.1463], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:11:07,210 - train - INFO - tau:0.8179069375972307
2024-04-07 02:11:07,210 - train - INFO - avg block size:1.0
2024-04-07 02:11:07,210 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 02:11:07,210 - train - INFO - lasso_alpha:2.357947691000002e-05
2024-04-07 02:11:07,465 - train - INFO - Test: [   0/78]  Time: 0.251 (0.251)  Loss:  1.0703 (1.0703)  Acc@1: 76.5625 (76.5625)  Acc@5: 91.4062 (91.4062)
2024-04-07 02:11:11,981 - train - INFO - Test: [  50/78]  Time: 0.088 (0.093)  Loss:  1.9805 (1.7472)  Acc@1: 53.1250 (59.4516)  Acc@5: 77.3438 (82.2763)
2024-04-07 02:11:14,715 - train - INFO - Test: [  78/78]  Time: 0.057 (0.095)  Loss:  1.9170 (1.7702)  Acc@1: 56.2500 (58.9600)  Acc@5: 81.2500 (82.1400)
2024-04-07 02:11:15,828 - train - INFO - Train: 23 [   0/781 (  0%)]  Loss:  3.875656 (3.8757)  Time: 1.038s,  123.30/s  (1.038s,  123.30/s)  LR: 4.721e-04  Data: 0.192 (0.192)
2024-04-07 02:12:01,224 - train - INFO - Train: 23 [  50/781 (  6%)]  Loss:  4.282940 (3.8886)  Time: 0.848s,  150.89/s  (0.910s,  140.59/s)  LR: 4.721e-04  Data: 0.008 (0.012)
2024-04-07 02:12:45,606 - train - INFO - Train: 23 [ 100/781 ( 13%)]  Loss:  3.422486 (3.8730)  Time: 0.844s,  151.69/s  (0.899s,  142.36/s)  LR: 4.721e-04  Data: 0.009 (0.010)
2024-04-07 02:13:31,564 - train - INFO - Train: 23 [ 150/781 ( 19%)]  Loss:  3.215603 (3.8594)  Time: 0.846s,  151.37/s  (0.906s,  141.32/s)  LR: 4.721e-04  Data: 0.008 (0.009)
2024-04-07 02:14:16,732 - train - INFO - Train: 23 [ 200/781 ( 26%)]  Loss:  4.032812 (3.8515)  Time: 0.857s,  149.35/s  (0.905s,  141.41/s)  LR: 4.721e-04  Data: 0.008 (0.009)
2024-04-07 02:15:00,927 - train - INFO - Train: 23 [ 250/781 ( 32%)]  Loss:  4.030018 (3.8671)  Time: 0.841s,  152.19/s  (0.901s,  142.08/s)  LR: 4.721e-04  Data: 0.008 (0.009)
2024-04-07 02:15:45,122 - train - INFO - Train: 23 [ 300/781 ( 38%)]  Loss:  3.289378 (3.8456)  Time: 0.851s,  150.34/s  (0.898s,  142.53/s)  LR: 4.721e-04  Data: 0.008 (0.009)
2024-04-07 02:16:30,818 - train - INFO - Train: 23 [ 350/781 ( 45%)]  Loss:  4.229298 (3.8478)  Time: 0.878s,  145.72/s  (0.900s,  142.17/s)  LR: 4.721e-04  Data: 0.008 (0.009)
2024-04-07 02:17:15,683 - train - INFO - Train: 23 [ 400/781 ( 51%)]  Loss:  3.221833 (3.8404)  Time: 0.831s,  153.99/s  (0.900s,  142.23/s)  LR: 4.721e-04  Data: 0.007 (0.008)
2024-04-07 02:18:01,072 - train - INFO - Train: 23 [ 450/781 ( 58%)]  Loss:  3.518573 (3.8475)  Time: 0.853s,  150.03/s  (0.901s,  142.09/s)  LR: 4.721e-04  Data: 0.008 (0.008)
2024-04-07 02:18:45,189 - train - INFO - Train: 23 [ 500/781 ( 64%)]  Loss:  3.682453 (3.8565)  Time: 0.864s,  148.07/s  (0.899s,  142.39/s)  LR: 4.721e-04  Data: 0.008 (0.008)
2024-04-07 02:19:30,758 - train - INFO - Train: 23 [ 550/781 ( 71%)]  Loss:  3.660896 (3.8581)  Time: 1.093s,  117.16/s  (0.900s,  142.21/s)  LR: 4.721e-04  Data: 0.009 (0.008)
2024-04-07 02:20:15,621 - train - INFO - Train: 23 [ 600/781 ( 77%)]  Loss:  4.072656 (3.8632)  Time: 0.848s,  150.90/s  (0.900s,  142.25/s)  LR: 4.721e-04  Data: 0.007 (0.008)
2024-04-07 02:21:02,041 - train - INFO - Train: 23 [ 650/781 ( 83%)]  Loss:  3.876773 (3.8553)  Time: 1.066s,  120.07/s  (0.902s,  141.90/s)  LR: 4.721e-04  Data: 0.009 (0.008)
2024-04-07 02:21:48,304 - train - INFO - Train: 23 [ 700/781 ( 90%)]  Loss:  3.768844 (3.8629)  Time: 0.861s,  148.67/s  (0.904s,  141.64/s)  LR: 4.721e-04  Data: 0.009 (0.008)
2024-04-07 02:22:34,537 - train - INFO - Train: 23 [ 750/781 ( 96%)]  Loss:  4.379629 (3.8651)  Time: 1.069s,  119.78/s  (0.905s,  141.42/s)  LR: 4.721e-04  Data: 0.008 (0.008)
2024-04-07 02:23:02,252 - train - INFO - Train: 23 [ 780/781 (100%)]  Loss:  3.473456 (3.8683)  Time: 0.851s,  150.37/s  (0.906s,  141.31/s)  LR: 4.721e-04  Data: 0.000 (0.008)
2024-04-07 02:23:02,253 - train - INFO - True
2024-04-07 02:23:02,255 - train - INFO - alphas:tensor([0.2921, 0.1609, 0.1542, 0.1884, 0.2044], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,299 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,300 - train - INFO - True
2024-04-07 02:23:02,301 - train - INFO - alphas:tensor([0.3730, 0.1067, 0.1127, 0.1678, 0.2399], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,336 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,336 - train - INFO - True
2024-04-07 02:23:02,337 - train - INFO - alphas:tensor([0.7286, 0.0849, 0.0563, 0.0626, 0.0676], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,366 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,366 - train - INFO - True
2024-04-07 02:23:02,367 - train - INFO - alphas:tensor([0.7063, 0.0716, 0.0590, 0.0757, 0.0875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,395 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,396 - train - INFO - True
2024-04-07 02:23:02,396 - train - INFO - alphas:tensor([0.5388, 0.0864, 0.0931, 0.1254, 0.1563], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,425 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,425 - train - INFO - True
2024-04-07 02:23:02,426 - train - INFO - alphas:tensor([0.6722, 0.0818, 0.0648, 0.0830, 0.0982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,454 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,454 - train - INFO - True
2024-04-07 02:23:02,455 - train - INFO - alphas:tensor([0.7791, 0.0651, 0.0427, 0.0514, 0.0617], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,483 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,483 - train - INFO - True
2024-04-07 02:23:02,484 - train - INFO - alphas:tensor([0.7597, 0.0703, 0.0462, 0.0575, 0.0663], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,512 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,512 - train - INFO - True
2024-04-07 02:23:02,513 - train - INFO - alphas:tensor([0.5859, 0.0759, 0.0801, 0.1127, 0.1454], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,541 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,541 - train - INFO - True
2024-04-07 02:23:02,542 - train - INFO - alphas:tensor([0.7012, 0.0744, 0.0602, 0.0740, 0.0902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,570 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,570 - train - INFO - True
2024-04-07 02:23:02,571 - train - INFO - alphas:tensor([0.7455, 0.0652, 0.0489, 0.0626, 0.0777], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,599 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,599 - train - INFO - True
2024-04-07 02:23:02,600 - train - INFO - alphas:tensor([0.6940, 0.0694, 0.0601, 0.0816, 0.0949], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,628 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,629 - train - INFO - True
2024-04-07 02:23:02,630 - train - INFO - alphas:tensor([0.6025, 0.0700, 0.0733, 0.1099, 0.1442], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,658 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,658 - train - INFO - True
2024-04-07 02:23:02,659 - train - INFO - alphas:tensor([0.7033, 0.0649, 0.0603, 0.0768, 0.0947], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,687 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,687 - train - INFO - True
2024-04-07 02:23:02,688 - train - INFO - alphas:tensor([0.7168, 0.0744, 0.0543, 0.0683, 0.0862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,716 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,716 - train - INFO - True
2024-04-07 02:23:02,717 - train - INFO - alphas:tensor([0.6107, 0.0725, 0.0698, 0.1029, 0.1441], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,745 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,745 - train - INFO - True
2024-04-07 02:23:02,746 - train - INFO - alphas:tensor([0.5998, 0.0690, 0.0719, 0.1106, 0.1487], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,774 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,774 - train - INFO - True
2024-04-07 02:23:02,775 - train - INFO - alphas:tensor([0.7062, 0.0625, 0.0602, 0.0771, 0.0941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,803 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,803 - train - INFO - True
2024-04-07 02:23:02,804 - train - INFO - alphas:tensor([0.7332, 0.0657, 0.0513, 0.0667, 0.0830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,832 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,833 - train - INFO - True
2024-04-07 02:23:02,834 - train - INFO - alphas:tensor([0.5952, 0.0659, 0.0696, 0.1113, 0.1580], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,862 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,862 - train - INFO - True
2024-04-07 02:23:02,863 - train - INFO - alphas:tensor([0.5692, 0.0685, 0.0798, 0.1209, 0.1616], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,891 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,892 - train - INFO - True
2024-04-07 02:23:02,892 - train - INFO - alphas:tensor([0.7343, 0.0579, 0.0546, 0.0687, 0.0845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,921 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,921 - train - INFO - True
2024-04-07 02:23:02,922 - train - INFO - alphas:tensor([0.7512, 0.0662, 0.0461, 0.0602, 0.0762], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,950 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,950 - train - INFO - True
2024-04-07 02:23:02,951 - train - INFO - alphas:tensor([0.6137, 0.0584, 0.0649, 0.1086, 0.1544], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:02,978 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:02,978 - train - INFO - True
2024-04-07 02:23:02,979 - train - INFO - alphas:tensor([0.5610, 0.0650, 0.0787, 0.1258, 0.1694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:03,004 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:03,004 - train - INFO - True
2024-04-07 02:23:03,005 - train - INFO - alphas:tensor([0.7245, 0.0572, 0.0563, 0.0700, 0.0920], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:03,027 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:03,027 - train - INFO - True
2024-04-07 02:23:03,028 - train - INFO - alphas:tensor([0.7408, 0.0571, 0.0477, 0.0660, 0.0885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:03,049 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:03,050 - train - INFO - True
2024-04-07 02:23:03,050 - train - INFO - alphas:tensor([0.6326, 0.0590, 0.0607, 0.1015, 0.1463], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:03,071 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:03,071 - train - INFO - True
2024-04-07 02:23:03,072 - train - INFO - alphas:tensor([0.5379, 0.0609, 0.0848, 0.1334, 0.1829], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:03,092 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:03,092 - train - INFO - True
2024-04-07 02:23:03,093 - train - INFO - alphas:tensor([0.6996, 0.0566, 0.0595, 0.0792, 0.1051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:03,112 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:03,112 - train - INFO - True
2024-04-07 02:23:03,113 - train - INFO - alphas:tensor([0.7259, 0.0547, 0.0495, 0.0714, 0.0984], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:03,131 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:03,131 - train - INFO - True
2024-04-07 02:23:03,132 - train - INFO - alphas:tensor([0.6720, 0.0553, 0.0580, 0.0914, 0.1233], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:03,149 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:03,149 - train - INFO - True
2024-04-07 02:23:03,150 - train - INFO - alphas:tensor([0.5138, 0.0575, 0.0851, 0.1411, 0.2026], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:03,171 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:03,171 - train - INFO - True
2024-04-07 02:23:03,172 - train - INFO - alphas:tensor([0.6615, 0.0596, 0.0639, 0.0911, 0.1239], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:03,192 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:03,192 - train - INFO - True
2024-04-07 02:23:03,192 - train - INFO - alphas:tensor([0.6989, 0.0595, 0.0518, 0.0811, 0.1088], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:03,211 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:03,211 - train - INFO - True
2024-04-07 02:23:03,212 - train - INFO - alphas:tensor([0.6659, 0.0557, 0.0599, 0.0932, 0.1253], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:03,230 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:03,230 - train - INFO - True
2024-04-07 02:23:03,231 - train - INFO - alphas:tensor([0.6625, 0.0749, 0.1169, 0.1457], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:23:03,248 - train - INFO - tau:0.8097278682212583
2024-04-07 02:23:03,248 - train - INFO - avg block size:1.0
2024-04-07 02:23:03,248 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 02:23:03,504 - train - INFO - Test: [   0/78]  Time: 0.253 (0.253)  Loss:  0.8936 (0.8936)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 02:23:08,107 - train - INFO - Test: [  50/78]  Time: 0.085 (0.095)  Loss:  1.8135 (1.6987)  Acc@1: 60.1562 (60.4320)  Acc@5: 82.8125 (82.9197)
2024-04-07 02:23:10,502 - train - INFO - Test: [  78/78]  Time: 0.054 (0.092)  Loss:  2.1641 (1.7353)  Acc@1: 43.7500 (59.7400)  Acc@5: 75.0000 (82.3500)
2024-04-07 02:23:11,721 - train - INFO - Train: 24 [   0/781 (  0%)]  Loss:  4.455303 (4.4553)  Time: 1.147s,  111.55/s  (1.147s,  111.55/s)  LR: 4.697e-04  Data: 0.175 (0.175)
2024-04-07 02:23:58,356 - train - INFO - Train: 24 [  50/781 (  6%)]  Loss:  3.962541 (3.8828)  Time: 0.798s,  160.36/s  (0.937s,  136.62/s)  LR: 4.697e-04  Data: 0.007 (0.011)
2024-04-07 02:24:43,075 - train - INFO - Train: 24 [ 100/781 ( 13%)]  Loss:  4.379881 (3.8695)  Time: 1.080s,  118.51/s  (0.916s,  139.76/s)  LR: 4.697e-04  Data: 0.007 (0.010)
2024-04-07 02:25:28,431 - train - INFO - Train: 24 [ 150/781 ( 19%)]  Loss:  3.169224 (3.8744)  Time: 0.856s,  149.59/s  (0.913s,  140.21/s)  LR: 4.697e-04  Data: 0.009 (0.009)
2024-04-07 02:26:12,878 - train - INFO - Train: 24 [ 200/781 ( 26%)]  Loss:  4.256924 (3.8461)  Time: 0.853s,  149.98/s  (0.907s,  141.13/s)  LR: 4.697e-04  Data: 0.008 (0.009)
2024-04-07 02:26:57,006 - train - INFO - Train: 24 [ 250/781 ( 32%)]  Loss:  4.097692 (3.8589)  Time: 0.859s,  149.09/s  (0.902s,  141.89/s)  LR: 4.697e-04  Data: 0.008 (0.009)
2024-04-07 02:27:40,906 - train - INFO - Train: 24 [ 300/781 ( 38%)]  Loss:  3.890046 (3.8691)  Time: 0.848s,  150.98/s  (0.898s,  142.53/s)  LR: 4.697e-04  Data: 0.008 (0.009)
2024-04-07 02:28:25,756 - train - INFO - Train: 24 [ 350/781 ( 45%)]  Loss:  3.301365 (3.8604)  Time: 0.849s,  150.83/s  (0.898s,  142.55/s)  LR: 4.697e-04  Data: 0.008 (0.008)
2024-04-07 02:29:10,993 - train - INFO - Train: 24 [ 400/781 ( 51%)]  Loss:  3.163176 (3.8514)  Time: 1.084s,  118.03/s  (0.899s,  142.42/s)  LR: 4.697e-04  Data: 0.009 (0.008)
2024-04-07 02:29:55,476 - train - INFO - Train: 24 [ 450/781 ( 58%)]  Loss:  3.848405 (3.8508)  Time: 1.110s,  115.30/s  (0.898s,  142.58/s)  LR: 4.697e-04  Data: 0.008 (0.008)
2024-04-07 02:30:40,515 - train - INFO - Train: 24 [ 500/781 ( 64%)]  Loss:  4.308391 (3.8526)  Time: 0.831s,  153.95/s  (0.898s,  142.53/s)  LR: 4.697e-04  Data: 0.007 (0.008)
2024-04-07 02:31:25,058 - train - INFO - Train: 24 [ 550/781 ( 71%)]  Loss:  3.493729 (3.8542)  Time: 1.023s,  125.17/s  (0.897s,  142.63/s)  LR: 4.697e-04  Data: 0.005 (0.008)
2024-04-07 02:32:10,650 - train - INFO - Train: 24 [ 600/781 ( 77%)]  Loss:  3.164308 (3.8595)  Time: 0.878s,  145.71/s  (0.899s,  142.44/s)  LR: 4.697e-04  Data: 0.010 (0.008)
2024-04-07 02:32:54,124 - train - INFO - Train: 24 [ 650/781 ( 83%)]  Loss:  4.094862 (3.8612)  Time: 0.836s,  153.06/s  (0.896s,  142.80/s)  LR: 4.697e-04  Data: 0.007 (0.008)
2024-04-07 02:33:38,818 - train - INFO - Train: 24 [ 700/781 ( 90%)]  Loss:  3.921184 (3.8624)  Time: 0.862s,  148.50/s  (0.896s,  142.83/s)  LR: 4.697e-04  Data: 0.009 (0.008)
2024-04-07 02:34:23,559 - train - INFO - Train: 24 [ 750/781 ( 96%)]  Loss:  3.942060 (3.8643)  Time: 1.022s,  125.28/s  (0.896s,  142.84/s)  LR: 4.697e-04  Data: 0.005 (0.008)
2024-04-07 02:34:51,691 - train - INFO - Train: 24 [ 780/781 (100%)]  Loss:  4.442041 (3.8710)  Time: 0.839s,  152.53/s  (0.898s,  142.59/s)  LR: 4.697e-04  Data: 0.000 (0.008)
2024-04-07 02:34:51,692 - train - INFO - True
2024-04-07 02:34:51,700 - train - INFO - alphas:tensor([0.2879, 0.1575, 0.1546, 0.1916, 0.2084], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:51,738 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:51,738 - train - INFO - True
2024-04-07 02:34:51,739 - train - INFO - alphas:tensor([0.3686, 0.1036, 0.1112, 0.1696, 0.2470], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:51,774 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:51,774 - train - INFO - True
2024-04-07 02:34:51,775 - train - INFO - alphas:tensor([0.7336, 0.0827, 0.0553, 0.0617, 0.0668], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:51,805 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:51,805 - train - INFO - True
2024-04-07 02:34:51,806 - train - INFO - alphas:tensor([0.7090, 0.0695, 0.0582, 0.0754, 0.0879], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:51,832 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:51,832 - train - INFO - True
2024-04-07 02:34:51,833 - train - INFO - alphas:tensor([0.5385, 0.0847, 0.0925, 0.1259, 0.1584], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:51,857 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:51,857 - train - INFO - True
2024-04-07 02:34:51,858 - train - INFO - alphas:tensor([0.6712, 0.0801, 0.0646, 0.0839, 0.1002], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:51,881 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:51,881 - train - INFO - True
2024-04-07 02:34:51,881 - train - INFO - alphas:tensor([0.7786, 0.0644, 0.0424, 0.0518, 0.0627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:51,902 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:51,902 - train - INFO - True
2024-04-07 02:34:51,903 - train - INFO - alphas:tensor([0.7566, 0.0696, 0.0463, 0.0588, 0.0687], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:51,922 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:51,922 - train - INFO - True
2024-04-07 02:34:51,922 - train - INFO - alphas:tensor([0.5842, 0.0743, 0.0794, 0.1136, 0.1485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:51,940 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:51,941 - train - INFO - True
2024-04-07 02:34:51,941 - train - INFO - alphas:tensor([0.6989, 0.0725, 0.0608, 0.0751, 0.0927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:51,958 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:51,959 - train - INFO - True
2024-04-07 02:34:51,959 - train - INFO - alphas:tensor([0.7474, 0.0633, 0.0481, 0.0626, 0.0786], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:51,976 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:51,976 - train - INFO - True
2024-04-07 02:34:51,977 - train - INFO - alphas:tensor([0.6913, 0.0671, 0.0597, 0.0836, 0.0983], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:51,996 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:51,996 - train - INFO - True
2024-04-07 02:34:51,997 - train - INFO - alphas:tensor([0.6023, 0.0678, 0.0724, 0.1104, 0.1471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,017 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,017 - train - INFO - True
2024-04-07 02:34:52,018 - train - INFO - alphas:tensor([0.7028, 0.0629, 0.0596, 0.0776, 0.0972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,037 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,037 - train - INFO - True
2024-04-07 02:34:52,038 - train - INFO - alphas:tensor([0.7129, 0.0738, 0.0540, 0.0698, 0.0895], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,056 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,056 - train - INFO - True
2024-04-07 02:34:52,057 - train - INFO - alphas:tensor([0.6062, 0.0694, 0.0686, 0.1050, 0.1508], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,074 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,074 - train - INFO - True
2024-04-07 02:34:52,075 - train - INFO - alphas:tensor([0.5972, 0.0668, 0.0713, 0.1118, 0.1528], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,091 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,091 - train - INFO - True
2024-04-07 02:34:52,092 - train - INFO - alphas:tensor([0.7074, 0.0599, 0.0592, 0.0772, 0.0963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,109 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,109 - train - INFO - True
2024-04-07 02:34:52,109 - train - INFO - alphas:tensor([0.7282, 0.0649, 0.0513, 0.0686, 0.0870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,126 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,127 - train - INFO - True
2024-04-07 02:34:52,127 - train - INFO - alphas:tensor([0.5875, 0.0623, 0.0685, 0.1144, 0.1673], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,150 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,150 - train - INFO - True
2024-04-07 02:34:52,151 - train - INFO - alphas:tensor([0.5674, 0.0663, 0.0787, 0.1219, 0.1658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,170 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,170 - train - INFO - True
2024-04-07 02:34:52,171 - train - INFO - alphas:tensor([0.7343, 0.0558, 0.0540, 0.0692, 0.0866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,189 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,189 - train - INFO - True
2024-04-07 02:34:52,190 - train - INFO - alphas:tensor([0.7478, 0.0650, 0.0463, 0.0615, 0.0794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,207 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,207 - train - INFO - True
2024-04-07 02:34:52,208 - train - INFO - alphas:tensor([0.6029, 0.0560, 0.0641, 0.1122, 0.1647], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,225 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,225 - train - INFO - True
2024-04-07 02:34:52,226 - train - INFO - alphas:tensor([0.5592, 0.0622, 0.0775, 0.1269, 0.1742], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,242 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,242 - train - INFO - True
2024-04-07 02:34:52,243 - train - INFO - alphas:tensor([0.7211, 0.0557, 0.0562, 0.0713, 0.0958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,262 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,263 - train - INFO - True
2024-04-07 02:34:52,263 - train - INFO - alphas:tensor([0.7377, 0.0560, 0.0475, 0.0672, 0.0916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,284 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,284 - train - INFO - True
2024-04-07 02:34:52,285 - train - INFO - alphas:tensor([0.6283, 0.0566, 0.0590, 0.1027, 0.1534], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,304 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,304 - train - INFO - True
2024-04-07 02:34:52,305 - train - INFO - alphas:tensor([0.5375, 0.0575, 0.0832, 0.1342, 0.1877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,322 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,323 - train - INFO - True
2024-04-07 02:34:52,323 - train - INFO - alphas:tensor([0.6989, 0.0544, 0.0588, 0.0800, 0.1078], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,340 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,340 - train - INFO - True
2024-04-07 02:34:52,341 - train - INFO - alphas:tensor([0.7218, 0.0535, 0.0494, 0.0728, 0.1024], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,357 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,357 - train - INFO - True
2024-04-07 02:34:52,358 - train - INFO - alphas:tensor([0.6639, 0.0537, 0.0579, 0.0940, 0.1305], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,374 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,374 - train - INFO - True
2024-04-07 02:34:52,375 - train - INFO - alphas:tensor([0.5112, 0.0547, 0.0843, 0.1422, 0.2077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,391 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,391 - train - INFO - True
2024-04-07 02:34:52,392 - train - INFO - alphas:tensor([0.6578, 0.0576, 0.0633, 0.0925, 0.1288], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,408 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,408 - train - INFO - True
2024-04-07 02:34:52,408 - train - INFO - alphas:tensor([0.6986, 0.0579, 0.0509, 0.0812, 0.1114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,428 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,428 - train - INFO - True
2024-04-07 02:34:52,430 - train - INFO - alphas:tensor([0.6638, 0.0538, 0.0588, 0.0941, 0.1294], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,450 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,450 - train - INFO - True
2024-04-07 02:34:52,451 - train - INFO - alphas:tensor([0.6662, 0.0732, 0.1156, 0.1450], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:34:52,469 - train - INFO - tau:0.8016305895390458
2024-04-07 02:34:52,469 - train - INFO - avg block size:1.0
2024-04-07 02:34:52,470 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 02:34:52,470 - train - INFO - lasso_alpha:2.5937424601000023e-05
2024-04-07 02:34:52,692 - train - INFO - Test: [   0/78]  Time: 0.218 (0.218)  Loss:  0.9761 (0.9761)  Acc@1: 77.3438 (77.3438)  Acc@5: 92.1875 (92.1875)
2024-04-07 02:34:57,043 - train - INFO - Test: [  50/78]  Time: 0.089 (0.090)  Loss:  1.7861 (1.7256)  Acc@1: 57.8125 (59.7426)  Acc@5: 83.5938 (82.7512)
2024-04-07 02:34:59,439 - train - INFO - Test: [  78/78]  Time: 0.058 (0.088)  Loss:  1.6543 (1.7539)  Acc@1: 56.2500 (59.0100)  Acc@5: 93.7500 (82.3700)
2024-04-07 02:35:00,734 - train - INFO - Train: 25 [   0/781 (  0%)]  Loss:  3.594200 (3.5942)  Time: 1.223s,  104.69/s  (1.223s,  104.69/s)  LR: 4.672e-04  Data: 0.186 (0.186)
2024-04-07 02:35:45,381 - train - INFO - Train: 25 [  50/781 (  6%)]  Loss:  3.889257 (3.7791)  Time: 0.852s,  150.22/s  (0.899s,  142.32/s)  LR: 4.672e-04  Data: 0.008 (0.011)
2024-04-07 02:36:30,502 - train - INFO - Train: 25 [ 100/781 ( 13%)]  Loss:  3.820627 (3.8312)  Time: 0.839s,  152.53/s  (0.901s,  142.09/s)  LR: 4.672e-04  Data: 0.008 (0.010)
2024-04-07 02:37:15,628 - train - INFO - Train: 25 [ 150/781 ( 19%)]  Loss:  3.855503 (3.8302)  Time: 1.092s,  117.22/s  (0.901s,  142.00/s)  LR: 4.672e-04  Data: 0.007 (0.009)
2024-04-07 02:38:01,222 - train - INFO - Train: 25 [ 200/781 ( 26%)]  Loss:  4.443029 (3.8630)  Time: 1.084s,  118.07/s  (0.904s,  141.59/s)  LR: 4.672e-04  Data: 0.009 (0.009)
2024-04-07 02:38:46,248 - train - INFO - Train: 25 [ 250/781 ( 32%)]  Loss:  3.707663 (3.8686)  Time: 1.063s,  120.45/s  (0.903s,  141.70/s)  LR: 4.672e-04  Data: 0.006 (0.009)
2024-04-07 02:39:31,852 - train - INFO - Train: 25 [ 300/781 ( 38%)]  Loss:  3.407793 (3.8588)  Time: 1.076s,  118.93/s  (0.905s,  141.48/s)  LR: 4.672e-04  Data: 0.007 (0.009)
2024-04-07 02:40:16,817 - train - INFO - Train: 25 [ 350/781 ( 45%)]  Loss:  3.210178 (3.8598)  Time: 0.860s,  148.79/s  (0.904s,  141.60/s)  LR: 4.672e-04  Data: 0.008 (0.009)
2024-04-07 02:41:00,897 - train - INFO - Train: 25 [ 400/781 ( 51%)]  Loss:  4.339234 (3.8647)  Time: 0.853s,  149.98/s  (0.901s,  142.04/s)  LR: 4.672e-04  Data: 0.008 (0.008)
2024-04-07 02:41:47,276 - train - INFO - Train: 25 [ 450/781 ( 58%)]  Loss:  3.934702 (3.8600)  Time: 0.866s,  147.81/s  (0.904s,  141.58/s)  LR: 4.672e-04  Data: 0.008 (0.008)
2024-04-07 02:42:34,068 - train - INFO - Train: 25 [ 500/781 ( 64%)]  Loss:  3.304595 (3.8518)  Time: 1.020s,  125.52/s  (0.907s,  141.08/s)  LR: 4.672e-04  Data: 0.005 (0.008)
2024-04-07 02:43:19,301 - train - INFO - Train: 25 [ 550/781 ( 71%)]  Loss:  3.692500 (3.8519)  Time: 0.844s,  151.63/s  (0.907s,  141.12/s)  LR: 4.672e-04  Data: 0.008 (0.008)
2024-04-07 02:44:04,049 - train - INFO - Train: 25 [ 600/781 ( 77%)]  Loss:  4.394520 (3.8611)  Time: 1.026s,  124.75/s  (0.906s,  141.28/s)  LR: 4.672e-04  Data: 0.005 (0.008)
2024-04-07 02:44:48,279 - train - INFO - Train: 25 [ 650/781 ( 83%)]  Loss:  4.218295 (3.8650)  Time: 0.867s,  147.57/s  (0.904s,  141.53/s)  LR: 4.672e-04  Data: 0.008 (0.008)
2024-04-07 02:45:33,205 - train - INFO - Train: 25 [ 700/781 ( 90%)]  Loss:  3.936957 (3.8653)  Time: 1.009s,  126.81/s  (0.904s,  141.60/s)  LR: 4.672e-04  Data: 0.005 (0.008)
2024-04-07 02:46:18,176 - train - INFO - Train: 25 [ 750/781 ( 96%)]  Loss:  3.837828 (3.8575)  Time: 1.099s,  116.52/s  (0.904s,  141.65/s)  LR: 4.672e-04  Data: 0.009 (0.008)
2024-04-07 02:46:45,941 - train - INFO - Train: 25 [ 780/781 (100%)]  Loss:  3.761523 (3.8572)  Time: 0.836s,  153.06/s  (0.904s,  141.52/s)  LR: 4.672e-04  Data: 0.000 (0.008)
2024-04-07 02:46:45,942 - train - INFO - True
2024-04-07 02:46:45,944 - train - INFO - alphas:tensor([0.2859, 0.1549, 0.1544, 0.1934, 0.2114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:45,988 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:45,988 - train - INFO - True
2024-04-07 02:46:45,990 - train - INFO - alphas:tensor([0.3664, 0.1011, 0.1099, 0.1701, 0.2525], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,024 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,025 - train - INFO - True
2024-04-07 02:46:46,026 - train - INFO - alphas:tensor([0.7337, 0.0823, 0.0551, 0.0618, 0.0671], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,055 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,055 - train - INFO - True
2024-04-07 02:46:46,056 - train - INFO - alphas:tensor([0.7074, 0.0683, 0.0583, 0.0763, 0.0896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,082 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,083 - train - INFO - True
2024-04-07 02:46:46,083 - train - INFO - alphas:tensor([0.5352, 0.0820, 0.0923, 0.1278, 0.1627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,107 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,107 - train - INFO - True
2024-04-07 02:46:46,108 - train - INFO - alphas:tensor([0.6711, 0.0786, 0.0639, 0.0844, 0.1019], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,130 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,130 - train - INFO - True
2024-04-07 02:46:46,131 - train - INFO - alphas:tensor([0.7782, 0.0638, 0.0421, 0.0523, 0.0635], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,151 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,151 - train - INFO - True
2024-04-07 02:46:46,152 - train - INFO - alphas:tensor([0.7515, 0.0692, 0.0469, 0.0607, 0.0718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,171 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,171 - train - INFO - True
2024-04-07 02:46:46,172 - train - INFO - alphas:tensor([0.5834, 0.0723, 0.0790, 0.1141, 0.1513], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,190 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,190 - train - INFO - True
2024-04-07 02:46:46,191 - train - INFO - alphas:tensor([0.7009, 0.0703, 0.0601, 0.0749, 0.0938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,208 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,208 - train - INFO - True
2024-04-07 02:46:46,209 - train - INFO - alphas:tensor([0.7466, 0.0614, 0.0481, 0.0634, 0.0805], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,227 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,227 - train - INFO - True
2024-04-07 02:46:46,227 - train - INFO - alphas:tensor([0.6868, 0.0654, 0.0598, 0.0855, 0.1025], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,249 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,249 - train - INFO - True
2024-04-07 02:46:46,250 - train - INFO - alphas:tensor([0.6009, 0.0655, 0.0720, 0.1114, 0.1503], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,269 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,269 - train - INFO - True
2024-04-07 02:46:46,270 - train - INFO - alphas:tensor([0.7012, 0.0612, 0.0593, 0.0784, 0.0999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,289 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,289 - train - INFO - True
2024-04-07 02:46:46,289 - train - INFO - alphas:tensor([0.7079, 0.0725, 0.0543, 0.0718, 0.0934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,307 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,307 - train - INFO - True
2024-04-07 02:46:46,308 - train - INFO - alphas:tensor([0.5985, 0.0659, 0.0682, 0.1080, 0.1594], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,325 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,325 - train - INFO - True
2024-04-07 02:46:46,325 - train - INFO - alphas:tensor([0.5950, 0.0645, 0.0708, 0.1130, 0.1567], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,344 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,345 - train - INFO - True
2024-04-07 02:46:46,345 - train - INFO - alphas:tensor([0.7059, 0.0583, 0.0587, 0.0782, 0.0988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,366 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,366 - train - INFO - True
2024-04-07 02:46:46,367 - train - INFO - alphas:tensor([0.7252, 0.0630, 0.0512, 0.0701, 0.0905], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,386 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,386 - train - INFO - True
2024-04-07 02:46:46,386 - train - INFO - alphas:tensor([0.5801, 0.0598, 0.0669, 0.1169, 0.1763], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,404 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,405 - train - INFO - True
2024-04-07 02:46:46,405 - train - INFO - alphas:tensor([0.5594, 0.0644, 0.0789, 0.1248, 0.1725], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,422 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,422 - train - INFO - True
2024-04-07 02:46:46,423 - train - INFO - alphas:tensor([0.7305, 0.0545, 0.0540, 0.0708, 0.0902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,440 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,440 - train - INFO - True
2024-04-07 02:46:46,440 - train - INFO - alphas:tensor([0.7422, 0.0645, 0.0465, 0.0634, 0.0834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,461 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,461 - train - INFO - True
2024-04-07 02:46:46,462 - train - INFO - alphas:tensor([0.5967, 0.0532, 0.0627, 0.1142, 0.1732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,482 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,482 - train - INFO - True
2024-04-07 02:46:46,482 - train - INFO - alphas:tensor([0.5557, 0.0601, 0.0772, 0.1281, 0.1789], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,501 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,501 - train - INFO - True
2024-04-07 02:46:46,502 - train - INFO - alphas:tensor([0.7225, 0.0529, 0.0553, 0.0714, 0.0980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,519 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,519 - train - INFO - True
2024-04-07 02:46:46,520 - train - INFO - alphas:tensor([0.7331, 0.0548, 0.0473, 0.0687, 0.0961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,537 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,537 - train - INFO - True
2024-04-07 02:46:46,537 - train - INFO - alphas:tensor([0.6165, 0.0549, 0.0591, 0.1063, 0.1633], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,554 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,554 - train - INFO - True
2024-04-07 02:46:46,555 - train - INFO - alphas:tensor([0.5303, 0.0554, 0.0830, 0.1368, 0.1945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,571 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,571 - train - INFO - True
2024-04-07 02:46:46,572 - train - INFO - alphas:tensor([0.6949, 0.0530, 0.0584, 0.0817, 0.1121], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,588 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,588 - train - INFO - True
2024-04-07 02:46:46,589 - train - INFO - alphas:tensor([0.7210, 0.0521, 0.0489, 0.0730, 0.1050], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,606 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,606 - train - INFO - True
2024-04-07 02:46:46,607 - train - INFO - alphas:tensor([0.6593, 0.0523, 0.0568, 0.0954, 0.1362], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,628 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,628 - train - INFO - True
2024-04-07 02:46:46,629 - train - INFO - alphas:tensor([0.5069, 0.0516, 0.0839, 0.1436, 0.2141], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,649 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,649 - train - INFO - True
2024-04-07 02:46:46,650 - train - INFO - alphas:tensor([0.6534, 0.0550, 0.0632, 0.0942, 0.1341], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,668 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,668 - train - INFO - True
2024-04-07 02:46:46,669 - train - INFO - alphas:tensor([0.6972, 0.0555, 0.0502, 0.0823, 0.1148], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,686 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,686 - train - INFO - True
2024-04-07 02:46:46,687 - train - INFO - alphas:tensor([0.6558, 0.0524, 0.0586, 0.0971, 0.1361], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,704 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,704 - train - INFO - True
2024-04-07 02:46:46,705 - train - INFO - alphas:tensor([0.6709, 0.0714, 0.1140, 0.1438], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:46:46,721 - train - INFO - tau:0.7936142836436553
2024-04-07 02:46:46,721 - train - INFO - avg block size:1.0
2024-04-07 02:46:46,721 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 02:46:46,976 - train - INFO - Test: [   0/78]  Time: 0.252 (0.252)  Loss:  0.9736 (0.9736)  Acc@1: 79.6875 (79.6875)  Acc@5: 93.7500 (93.7500)
2024-04-07 02:46:51,430 - train - INFO - Test: [  50/78]  Time: 0.087 (0.092)  Loss:  1.9941 (1.7210)  Acc@1: 53.9062 (59.4822)  Acc@5: 81.2500 (82.6440)
2024-04-07 02:46:53,812 - train - INFO - Test: [  78/78]  Time: 0.056 (0.090)  Loss:  1.9443 (1.7472)  Acc@1: 56.2500 (58.9600)  Acc@5: 87.5000 (82.2100)
2024-04-07 02:46:55,197 - train - INFO - Train: 26 [   0/781 (  0%)]  Loss:  4.411603 (4.4116)  Time: 1.244s,  102.91/s  (1.244s,  102.91/s)  LR: 4.646e-04  Data: 0.195 (0.195)
2024-04-07 02:47:41,332 - train - INFO - Train: 26 [  50/781 (  6%)]  Loss:  3.707682 (3.9093)  Time: 1.105s,  115.85/s  (0.929s,  137.79/s)  LR: 4.646e-04  Data: 0.009 (0.012)
2024-04-07 02:48:26,580 - train - INFO - Train: 26 [ 100/781 ( 13%)]  Loss:  4.139657 (3.9091)  Time: 0.831s,  153.96/s  (0.917s,  139.58/s)  LR: 4.646e-04  Data: 0.007 (0.009)
2024-04-07 02:49:13,285 - train - INFO - Train: 26 [ 150/781 ( 19%)]  Loss:  3.927627 (3.9214)  Time: 0.852s,  150.17/s  (0.923s,  138.72/s)  LR: 4.646e-04  Data: 0.008 (0.009)
2024-04-07 02:49:58,679 - train - INFO - Train: 26 [ 200/781 ( 26%)]  Loss:  3.551330 (3.9089)  Time: 0.840s,  152.33/s  (0.919s,  139.28/s)  LR: 4.646e-04  Data: 0.007 (0.009)
2024-04-07 02:50:43,774 - train - INFO - Train: 26 [ 250/781 ( 32%)]  Loss:  3.763359 (3.9018)  Time: 0.841s,  152.27/s  (0.916s,  139.80/s)  LR: 4.646e-04  Data: 0.009 (0.009)
2024-04-07 02:51:29,150 - train - INFO - Train: 26 [ 300/781 ( 38%)]  Loss:  3.936966 (3.9042)  Time: 1.069s,  119.73/s  (0.914s,  140.01/s)  LR: 4.646e-04  Data: 0.007 (0.009)
2024-04-07 02:52:17,053 - train - INFO - Train: 26 [ 350/781 ( 45%)]  Loss:  4.314503 (3.9048)  Time: 0.823s,  155.49/s  (0.920s,  139.06/s)  LR: 4.646e-04  Data: 0.006 (0.009)
2024-04-07 02:53:02,747 - train - INFO - Train: 26 [ 400/781 ( 51%)]  Loss:  3.566773 (3.9075)  Time: 1.093s,  117.13/s  (0.920s,  139.18/s)  LR: 4.646e-04  Data: 0.007 (0.009)
2024-04-07 02:53:49,870 - train - INFO - Train: 26 [ 450/781 ( 58%)]  Loss:  4.187852 (3.9057)  Time: 1.074s,  119.16/s  (0.922s,  138.80/s)  LR: 4.646e-04  Data: 0.008 (0.009)
2024-04-07 02:54:36,519 - train - INFO - Train: 26 [ 500/781 ( 64%)]  Loss:  3.376111 (3.8995)  Time: 0.863s,  148.30/s  (0.923s,  138.64/s)  LR: 4.646e-04  Data: 0.008 (0.009)
2024-04-07 02:55:23,039 - train - INFO - Train: 26 [ 550/781 ( 71%)]  Loss:  4.224517 (3.8984)  Time: 1.089s,  117.56/s  (0.924s,  138.54/s)  LR: 4.646e-04  Data: 0.008 (0.009)
2024-04-07 02:56:08,535 - train - INFO - Train: 26 [ 600/781 ( 77%)]  Loss:  4.099246 (3.8892)  Time: 0.833s,  153.75/s  (0.923s,  138.72/s)  LR: 4.646e-04  Data: 0.006 (0.009)
2024-04-07 02:56:54,906 - train - INFO - Train: 26 [ 650/781 ( 83%)]  Loss:  3.892159 (3.8826)  Time: 0.834s,  153.41/s  (0.923s,  138.66/s)  LR: 4.646e-04  Data: 0.007 (0.008)
2024-04-07 02:57:40,586 - train - INFO - Train: 26 [ 700/781 ( 90%)]  Loss:  4.498583 (3.8785)  Time: 0.828s,  154.52/s  (0.922s,  138.77/s)  LR: 4.646e-04  Data: 0.008 (0.008)
2024-04-07 02:58:27,781 - train - INFO - Train: 26 [ 750/781 ( 96%)]  Loss:  3.803311 (3.8764)  Time: 1.110s,  115.29/s  (0.924s,  138.55/s)  LR: 4.646e-04  Data: 0.009 (0.008)
2024-04-07 02:58:55,634 - train - INFO - Train: 26 [ 780/781 (100%)]  Loss:  3.534003 (3.8808)  Time: 0.838s,  152.73/s  (0.924s,  138.53/s)  LR: 4.646e-04  Data: 0.000 (0.008)
2024-04-07 02:58:55,634 - train - INFO - True
2024-04-07 02:58:55,636 - train - INFO - alphas:tensor([0.2801, 0.1506, 0.1557, 0.1973, 0.2164], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:55,664 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:55,664 - train - INFO - True
2024-04-07 02:58:55,665 - train - INFO - alphas:tensor([0.3608, 0.0976, 0.1088, 0.1720, 0.2608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:55,693 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:55,693 - train - INFO - True
2024-04-07 02:58:55,694 - train - INFO - alphas:tensor([0.7373, 0.0807, 0.0541, 0.0612, 0.0666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:55,722 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:55,722 - train - INFO - True
2024-04-07 02:58:55,723 - train - INFO - alphas:tensor([0.7077, 0.0671, 0.0579, 0.0766, 0.0907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:55,751 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:55,751 - train - INFO - True
2024-04-07 02:58:55,752 - train - INFO - alphas:tensor([0.5331, 0.0795, 0.0925, 0.1292, 0.1658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:55,780 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:55,780 - train - INFO - True
2024-04-07 02:58:55,781 - train - INFO - alphas:tensor([0.6701, 0.0772, 0.0637, 0.0849, 0.1041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:55,810 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:55,810 - train - INFO - True
2024-04-07 02:58:55,811 - train - INFO - alphas:tensor([0.7791, 0.0627, 0.0416, 0.0524, 0.0641], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:55,839 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:55,839 - train - INFO - True
2024-04-07 02:58:55,840 - train - INFO - alphas:tensor([0.7480, 0.0681, 0.0471, 0.0623, 0.0745], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:55,868 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:55,868 - train - INFO - True
2024-04-07 02:58:55,869 - train - INFO - alphas:tensor([0.5796, 0.0706, 0.0789, 0.1156, 0.1553], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:55,897 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:55,897 - train - INFO - True
2024-04-07 02:58:55,898 - train - INFO - alphas:tensor([0.6971, 0.0694, 0.0605, 0.0762, 0.0967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:55,926 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:55,926 - train - INFO - True
2024-04-07 02:58:55,927 - train - INFO - alphas:tensor([0.7432, 0.0604, 0.0483, 0.0647, 0.0834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:55,955 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:55,956 - train - INFO - True
2024-04-07 02:58:55,957 - train - INFO - alphas:tensor([0.6791, 0.0648, 0.0600, 0.0881, 0.1080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:55,985 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:55,985 - train - INFO - True
2024-04-07 02:58:55,987 - train - INFO - alphas:tensor([0.5983, 0.0639, 0.0715, 0.1124, 0.1540], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,015 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,015 - train - INFO - True
2024-04-07 02:58:56,016 - train - INFO - alphas:tensor([0.6999, 0.0593, 0.0589, 0.0791, 0.1028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,044 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,044 - train - INFO - True
2024-04-07 02:58:56,045 - train - INFO - alphas:tensor([0.7052, 0.0708, 0.0538, 0.0730, 0.0972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,073 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,073 - train - INFO - True
2024-04-07 02:58:56,074 - train - INFO - alphas:tensor([0.5940, 0.0621, 0.0672, 0.1099, 0.1668], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,102 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,102 - train - INFO - True
2024-04-07 02:58:56,103 - train - INFO - alphas:tensor([0.5913, 0.0626, 0.0706, 0.1145, 0.1610], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,131 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,131 - train - INFO - True
2024-04-07 02:58:56,132 - train - INFO - alphas:tensor([0.7014, 0.0572, 0.0587, 0.0799, 0.1028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,161 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,161 - train - INFO - True
2024-04-07 02:58:56,162 - train - INFO - alphas:tensor([0.7199, 0.0620, 0.0514, 0.0719, 0.0949], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,190 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,190 - train - INFO - True
2024-04-07 02:58:56,191 - train - INFO - alphas:tensor([0.5748, 0.0570, 0.0656, 0.1184, 0.1842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,219 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,219 - train - INFO - True
2024-04-07 02:58:56,220 - train - INFO - alphas:tensor([0.5589, 0.0622, 0.0778, 0.1252, 0.1759], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,246 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,246 - train - INFO - True
2024-04-07 02:58:56,247 - train - INFO - alphas:tensor([0.7267, 0.0531, 0.0543, 0.0722, 0.0937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,271 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,271 - train - INFO - True
2024-04-07 02:58:56,272 - train - INFO - alphas:tensor([0.7387, 0.0632, 0.0464, 0.0649, 0.0869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,294 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,294 - train - INFO - True
2024-04-07 02:58:56,295 - train - INFO - alphas:tensor([0.5904, 0.0506, 0.0609, 0.1159, 0.1822], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,315 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,315 - train - INFO - True
2024-04-07 02:58:56,316 - train - INFO - alphas:tensor([0.5505, 0.0580, 0.0763, 0.1300, 0.1852], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,335 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,335 - train - INFO - True
2024-04-07 02:58:56,336 - train - INFO - alphas:tensor([0.7192, 0.0517, 0.0550, 0.0724, 0.1017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,354 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,354 - train - INFO - True
2024-04-07 02:58:56,355 - train - INFO - alphas:tensor([0.7335, 0.0529, 0.0465, 0.0691, 0.0980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,372 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,372 - train - INFO - True
2024-04-07 02:58:56,373 - train - INFO - alphas:tensor([0.6143, 0.0517, 0.0571, 0.1072, 0.1697], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,389 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,389 - train - INFO - True
2024-04-07 02:58:56,390 - train - INFO - alphas:tensor([0.5245, 0.0538, 0.0823, 0.1385, 0.2009], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,406 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,406 - train - INFO - True
2024-04-07 02:58:56,407 - train - INFO - alphas:tensor([0.6915, 0.0513, 0.0581, 0.0831, 0.1161], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,423 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,423 - train - INFO - True
2024-04-07 02:58:56,424 - train - INFO - alphas:tensor([0.7238, 0.0497, 0.0474, 0.0725, 0.1067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,440 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,440 - train - INFO - True
2024-04-07 02:58:56,440 - train - INFO - alphas:tensor([0.6550, 0.0498, 0.0560, 0.0972, 0.1419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,456 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,456 - train - INFO - True
2024-04-07 02:58:56,457 - train - INFO - alphas:tensor([0.5015, 0.0495, 0.0828, 0.1450, 0.2211], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,473 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,473 - train - INFO - True
2024-04-07 02:58:56,474 - train - INFO - alphas:tensor([0.6458, 0.0528, 0.0631, 0.0970, 0.1413], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,490 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,490 - train - INFO - True
2024-04-07 02:58:56,490 - train - INFO - alphas:tensor([0.6935, 0.0538, 0.0501, 0.0837, 0.1189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,507 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,507 - train - INFO - True
2024-04-07 02:58:56,507 - train - INFO - alphas:tensor([0.6509, 0.0502, 0.0581, 0.0989, 0.1419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,523 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,524 - train - INFO - True
2024-04-07 02:58:56,524 - train - INFO - alphas:tensor([0.6723, 0.0707, 0.1130, 0.1440], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 02:58:56,540 - train - INFO - tau:0.7856781408072188
2024-04-07 02:58:56,540 - train - INFO - avg block size:1.0
2024-04-07 02:58:56,541 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 02:58:56,541 - train - INFO - lasso_alpha:2.8531167061100026e-05
2024-04-07 02:58:56,759 - train - INFO - Test: [   0/78]  Time: 0.215 (0.215)  Loss:  0.9644 (0.9644)  Acc@1: 78.9062 (78.9062)  Acc@5: 92.9688 (92.9688)
2024-04-07 02:59:01,014 - train - INFO - Test: [  50/78]  Time: 0.087 (0.088)  Loss:  2.0078 (1.7235)  Acc@1: 53.1250 (60.1256)  Acc@5: 82.0312 (83.2108)
2024-04-07 02:59:03,386 - train - INFO - Test: [  78/78]  Time: 0.053 (0.087)  Loss:  1.9541 (1.7626)  Acc@1: 50.0000 (59.1500)  Acc@5: 81.2500 (82.5000)
2024-04-07 02:59:04,709 - train - INFO - Train: 27 [   0/781 (  0%)]  Loss:  3.533568 (3.5336)  Time: 1.250s,  102.42/s  (1.250s,  102.42/s)  LR: 4.619e-04  Data: 0.184 (0.184)
2024-04-07 02:59:51,131 - train - INFO - Train: 27 [  50/781 (  6%)]  Loss:  4.326250 (3.9228)  Time: 0.850s,  150.65/s  (0.935s,  136.94/s)  LR: 4.619e-04  Data: 0.008 (0.011)
2024-04-07 03:00:36,168 - train - INFO - Train: 27 [ 100/781 ( 13%)]  Loss:  3.361786 (3.8884)  Time: 0.830s,  154.19/s  (0.918s,  139.45/s)  LR: 4.619e-04  Data: 0.007 (0.010)
2024-04-07 03:01:22,361 - train - INFO - Train: 27 [ 150/781 ( 19%)]  Loss:  4.130395 (3.8811)  Time: 0.864s,  148.20/s  (0.920s,  139.15/s)  LR: 4.619e-04  Data: 0.010 (0.009)
2024-04-07 03:02:08,311 - train - INFO - Train: 27 [ 200/781 ( 26%)]  Loss:  3.296800 (3.8882)  Time: 0.845s,  151.41/s  (0.920s,  139.19/s)  LR: 4.619e-04  Data: 0.008 (0.009)
2024-04-07 03:02:54,952 - train - INFO - Train: 27 [ 250/781 ( 32%)]  Loss:  3.875756 (3.8962)  Time: 1.137s,  112.62/s  (0.922s,  138.79/s)  LR: 4.619e-04  Data: 0.008 (0.009)
2024-04-07 03:03:41,213 - train - INFO - Train: 27 [ 300/781 ( 38%)]  Loss:  4.294821 (3.8842)  Time: 0.835s,  153.36/s  (0.923s,  138.72/s)  LR: 4.619e-04  Data: 0.007 (0.009)
2024-04-07 03:04:26,418 - train - INFO - Train: 27 [ 350/781 ( 45%)]  Loss:  4.085101 (3.8831)  Time: 0.847s,  151.21/s  (0.920s,  139.12/s)  LR: 4.619e-04  Data: 0.008 (0.008)
2024-04-07 03:05:12,152 - train - INFO - Train: 27 [ 400/781 ( 51%)]  Loss:  4.334852 (3.8806)  Time: 1.080s,  118.50/s  (0.919s,  139.22/s)  LR: 4.619e-04  Data: 0.012 (0.008)
2024-04-07 03:05:58,627 - train - INFO - Train: 27 [ 450/781 ( 58%)]  Loss:  4.435777 (3.8745)  Time: 1.116s,  114.65/s  (0.921s,  139.05/s)  LR: 4.619e-04  Data: 0.008 (0.008)
2024-04-07 03:06:45,214 - train - INFO - Train: 27 [ 500/781 ( 64%)]  Loss:  3.463675 (3.8700)  Time: 0.851s,  150.46/s  (0.922s,  138.88/s)  LR: 4.619e-04  Data: 0.008 (0.008)
2024-04-07 03:07:30,947 - train - INFO - Train: 27 [ 550/781 ( 71%)]  Loss:  4.285025 (3.8659)  Time: 0.948s,  134.97/s  (0.921s,  138.98/s)  LR: 4.619e-04  Data: 0.008 (0.008)
2024-04-07 03:08:16,150 - train - INFO - Train: 27 [ 600/781 ( 77%)]  Loss:  4.348813 (3.8688)  Time: 0.834s,  153.44/s  (0.920s,  139.19/s)  LR: 4.619e-04  Data: 0.006 (0.008)
2024-04-07 03:09:02,230 - train - INFO - Train: 27 [ 650/781 ( 83%)]  Loss:  3.810416 (3.8719)  Time: 0.969s,  132.09/s  (0.920s,  139.17/s)  LR: 4.619e-04  Data: 0.008 (0.008)
2024-04-07 03:09:49,054 - train - INFO - Train: 27 [ 700/781 ( 90%)]  Loss:  3.324206 (3.8716)  Time: 0.799s,  160.12/s  (0.921s,  138.99/s)  LR: 4.619e-04  Data: 0.005 (0.008)
2024-04-07 03:10:35,946 - train - INFO - Train: 27 [ 750/781 ( 96%)]  Loss:  3.641369 (3.8667)  Time: 1.134s,  112.84/s  (0.922s,  138.82/s)  LR: 4.619e-04  Data: 0.013 (0.008)
2024-04-07 03:11:03,271 - train - INFO - Train: 27 [ 780/781 (100%)]  Loss:  3.567896 (3.8708)  Time: 1.108s,  115.49/s  (0.922s,  138.89/s)  LR: 4.619e-04  Data: 0.000 (0.008)
2024-04-07 03:11:03,272 - train - INFO - True
2024-04-07 03:11:03,274 - train - INFO - alphas:tensor([0.2736, 0.1468, 0.1575, 0.2009, 0.2212], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,319 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,319 - train - INFO - True
2024-04-07 03:11:03,320 - train - INFO - alphas:tensor([0.3544, 0.0952, 0.1080, 0.1733, 0.2691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,355 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,355 - train - INFO - True
2024-04-07 03:11:03,356 - train - INFO - alphas:tensor([0.7393, 0.0799, 0.0535, 0.0608, 0.0665], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,386 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,386 - train - INFO - True
2024-04-07 03:11:03,387 - train - INFO - alphas:tensor([0.7066, 0.0660, 0.0577, 0.0774, 0.0923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,413 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,413 - train - INFO - True
2024-04-07 03:11:03,414 - train - INFO - alphas:tensor([0.5294, 0.0780, 0.0922, 0.1304, 0.1700], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,438 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,438 - train - INFO - True
2024-04-07 03:11:03,439 - train - INFO - alphas:tensor([0.6666, 0.0757, 0.0642, 0.0864, 0.1072], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,460 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,460 - train - INFO - True
2024-04-07 03:11:03,461 - train - INFO - alphas:tensor([0.7773, 0.0623, 0.0417, 0.0532, 0.0655], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,481 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,482 - train - INFO - True
2024-04-07 03:11:03,482 - train - INFO - alphas:tensor([0.7393, 0.0688, 0.0480, 0.0650, 0.0789], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,504 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,504 - train - INFO - True
2024-04-07 03:11:03,505 - train - INFO - alphas:tensor([0.5762, 0.0685, 0.0788, 0.1172, 0.1593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,525 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,526 - train - INFO - True
2024-04-07 03:11:03,526 - train - INFO - alphas:tensor([0.6967, 0.0678, 0.0598, 0.0769, 0.0987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,546 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,546 - train - INFO - True
2024-04-07 03:11:03,547 - train - INFO - alphas:tensor([0.7387, 0.0594, 0.0488, 0.0664, 0.0868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,565 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,566 - train - INFO - True
2024-04-07 03:11:03,566 - train - INFO - alphas:tensor([0.6700, 0.0640, 0.0607, 0.0913, 0.1140], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,584 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,584 - train - INFO - True
2024-04-07 03:11:03,585 - train - INFO - alphas:tensor([0.5935, 0.0624, 0.0716, 0.1139, 0.1585], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,602 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,602 - train - INFO - True
2024-04-07 03:11:03,602 - train - INFO - alphas:tensor([0.6931, 0.0585, 0.0595, 0.0815, 0.1074], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,619 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,619 - train - INFO - True
2024-04-07 03:11:03,620 - train - INFO - alphas:tensor([0.7012, 0.0693, 0.0537, 0.0747, 0.1011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,636 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,636 - train - INFO - True
2024-04-07 03:11:03,637 - train - INFO - alphas:tensor([0.5864, 0.0596, 0.0661, 0.1122, 0.1757], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,656 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,656 - train - INFO - True
2024-04-07 03:11:03,657 - train - INFO - alphas:tensor([0.5881, 0.0614, 0.0699, 0.1156, 0.1649], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,678 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,678 - train - INFO - True
2024-04-07 03:11:03,678 - train - INFO - alphas:tensor([0.7001, 0.0548, 0.0583, 0.0810, 0.1058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,698 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,698 - train - INFO - True
2024-04-07 03:11:03,699 - train - INFO - alphas:tensor([0.7122, 0.0609, 0.0518, 0.0748, 0.1004], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,717 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,717 - train - INFO - True
2024-04-07 03:11:03,718 - train - INFO - alphas:tensor([0.5600, 0.0546, 0.0648, 0.1233, 0.1973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,735 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,735 - train - INFO - True
2024-04-07 03:11:03,736 - train - INFO - alphas:tensor([0.5529, 0.0598, 0.0775, 0.1275, 0.1823], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,753 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,753 - train - INFO - True
2024-04-07 03:11:03,754 - train - INFO - alphas:tensor([0.7229, 0.0517, 0.0544, 0.0736, 0.0974], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,770 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,770 - train - INFO - True
2024-04-07 03:11:03,771 - train - INFO - alphas:tensor([0.7319, 0.0629, 0.0467, 0.0670, 0.0916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,788 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,788 - train - INFO - True
2024-04-07 03:11:03,789 - train - INFO - alphas:tensor([0.5792, 0.0490, 0.0598, 0.1181, 0.1939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,809 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,809 - train - INFO - True
2024-04-07 03:11:03,810 - train - INFO - alphas:tensor([0.5455, 0.0551, 0.0760, 0.1320, 0.1914], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,830 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,830 - train - INFO - True
2024-04-07 03:11:03,831 - train - INFO - alphas:tensor([0.7147, 0.0502, 0.0548, 0.0743, 0.1059], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,849 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,850 - train - INFO - True
2024-04-07 03:11:03,850 - train - INFO - alphas:tensor([0.7258, 0.0522, 0.0471, 0.0716, 0.1032], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,868 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,868 - train - INFO - True
2024-04-07 03:11:03,869 - train - INFO - alphas:tensor([0.6032, 0.0500, 0.0564, 0.1095, 0.1809], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,885 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,886 - train - INFO - True
2024-04-07 03:11:03,886 - train - INFO - alphas:tensor([0.5205, 0.0515, 0.0810, 0.1399, 0.2071], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,903 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,903 - train - INFO - True
2024-04-07 03:11:03,903 - train - INFO - alphas:tensor([0.6850, 0.0503, 0.0576, 0.0850, 0.1221], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,920 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,920 - train - INFO - True
2024-04-07 03:11:03,921 - train - INFO - alphas:tensor([0.7187, 0.0488, 0.0472, 0.0743, 0.1110], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,937 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,937 - train - INFO - True
2024-04-07 03:11:03,938 - train - INFO - alphas:tensor([0.6488, 0.0478, 0.0549, 0.0993, 0.1492], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,960 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,960 - train - INFO - True
2024-04-07 03:11:03,961 - train - INFO - alphas:tensor([0.4998, 0.0469, 0.0813, 0.1456, 0.2264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,980 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,980 - train - INFO - True
2024-04-07 03:11:03,981 - train - INFO - alphas:tensor([0.6430, 0.0513, 0.0624, 0.0974, 0.1458], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:03,999 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:03,999 - train - INFO - True
2024-04-07 03:11:04,000 - train - INFO - alphas:tensor([0.6959, 0.0522, 0.0483, 0.0831, 0.1206], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:04,018 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:04,018 - train - INFO - True
2024-04-07 03:11:04,019 - train - INFO - alphas:tensor([0.6476, 0.0480, 0.0571, 0.1001, 0.1471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:04,035 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:04,035 - train - INFO - True
2024-04-07 03:11:04,036 - train - INFO - alphas:tensor([0.6767, 0.0688, 0.1115, 0.1429], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:11:04,052 - train - INFO - tau:0.7778213593991465
2024-04-07 03:11:04,052 - train - INFO - avg block size:1.0
2024-04-07 03:11:04,053 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 03:11:04,307 - train - INFO - Test: [   0/78]  Time: 0.251 (0.251)  Loss:  0.9912 (0.9912)  Acc@1: 78.1250 (78.1250)  Acc@5: 93.7500 (93.7500)
2024-04-07 03:11:08,936 - train - INFO - Test: [  50/78]  Time: 0.086 (0.096)  Loss:  1.8770 (1.6853)  Acc@1: 57.8125 (60.1409)  Acc@5: 79.6875 (83.0882)
2024-04-07 03:11:11,317 - train - INFO - Test: [  78/78]  Time: 0.053 (0.092)  Loss:  1.6133 (1.7212)  Acc@1: 62.5000 (59.6600)  Acc@5: 87.5000 (82.5400)
2024-04-07 03:11:12,631 - train - INFO - Train: 28 [   0/781 (  0%)]  Loss:  3.664883 (3.6649)  Time: 1.245s,  102.85/s  (1.245s,  102.85/s)  LR: 4.591e-04  Data: 0.179 (0.179)
2024-04-07 03:11:59,171 - train - INFO - Train: 28 [  50/781 (  6%)]  Loss:  3.347293 (3.8882)  Time: 0.867s,  147.61/s  (0.937s,  136.62/s)  LR: 4.591e-04  Data: 0.009 (0.011)
2024-04-07 03:12:46,941 - train - INFO - Train: 28 [ 100/781 ( 13%)]  Loss:  4.022065 (3.8778)  Time: 1.052s,  121.64/s  (0.946s,  135.30/s)  LR: 4.591e-04  Data: 0.010 (0.010)
2024-04-07 03:13:34,367 - train - INFO - Train: 28 [ 150/781 ( 19%)]  Loss:  3.412122 (3.8953)  Time: 0.850s,  150.67/s  (0.947s,  135.18/s)  LR: 4.591e-04  Data: 0.008 (0.009)
2024-04-07 03:14:20,874 - train - INFO - Train: 28 [ 200/781 ( 26%)]  Loss:  4.378424 (3.8673)  Time: 0.861s,  148.63/s  (0.943s,  135.78/s)  LR: 4.591e-04  Data: 0.009 (0.009)
2024-04-07 03:15:06,990 - train - INFO - Train: 28 [ 250/781 ( 32%)]  Loss:  4.334276 (3.8913)  Time: 1.061s,  120.63/s  (0.939s,  136.37/s)  LR: 4.591e-04  Data: 0.009 (0.009)
2024-04-07 03:15:52,695 - train - INFO - Train: 28 [ 300/781 ( 38%)]  Loss:  4.045917 (3.8961)  Time: 0.841s,  152.23/s  (0.935s,  136.96/s)  LR: 4.591e-04  Data: 0.008 (0.009)
2024-04-07 03:16:39,629 - train - INFO - Train: 28 [ 350/781 ( 45%)]  Loss:  4.226638 (3.8887)  Time: 1.023s,  125.10/s  (0.935s,  136.88/s)  LR: 4.591e-04  Data: 0.006 (0.009)
2024-04-07 03:17:25,066 - train - INFO - Train: 28 [ 400/781 ( 51%)]  Loss:  4.091448 (3.8886)  Time: 1.083s,  118.19/s  (0.932s,  137.36/s)  LR: 4.591e-04  Data: 0.019 (0.009)
2024-04-07 03:18:10,031 - train - INFO - Train: 28 [ 450/781 ( 58%)]  Loss:  4.192607 (3.8830)  Time: 0.794s,  161.14/s  (0.928s,  137.90/s)  LR: 4.591e-04  Data: 0.004 (0.009)
2024-04-07 03:18:55,801 - train - INFO - Train: 28 [ 500/781 ( 64%)]  Loss:  4.372294 (3.8910)  Time: 0.848s,  150.92/s  (0.927s,  138.09/s)  LR: 4.591e-04  Data: 0.008 (0.009)
2024-04-07 03:19:41,382 - train - INFO - Train: 28 [ 550/781 ( 71%)]  Loss:  3.113222 (3.8917)  Time: 0.858s,  149.27/s  (0.926s,  138.30/s)  LR: 4.591e-04  Data: 0.008 (0.008)
2024-04-07 03:20:29,230 - train - INFO - Train: 28 [ 600/781 ( 77%)]  Loss:  3.538950 (3.8905)  Time: 0.847s,  151.04/s  (0.928s,  137.91/s)  LR: 4.591e-04  Data: 0.009 (0.008)
2024-04-07 03:21:13,706 - train - INFO - Train: 28 [ 650/781 ( 83%)]  Loss:  3.139339 (3.8778)  Time: 0.816s,  156.91/s  (0.925s,  138.35/s)  LR: 4.591e-04  Data: 0.009 (0.008)
2024-04-07 03:21:59,558 - train - INFO - Train: 28 [ 700/781 ( 90%)]  Loss:  3.694746 (3.8757)  Time: 0.767s,  166.86/s  (0.925s,  138.44/s)  LR: 4.591e-04  Data: 0.006 (0.008)
2024-04-07 03:22:45,615 - train - INFO - Train: 28 [ 750/781 ( 96%)]  Loss:  4.525432 (3.8809)  Time: 0.795s,  160.91/s  (0.924s,  138.47/s)  LR: 4.591e-04  Data: 0.006 (0.008)
2024-04-07 03:23:13,641 - train - INFO - Train: 28 [ 780/781 (100%)]  Loss:  4.476834 (3.8814)  Time: 0.844s,  151.74/s  (0.925s,  138.42/s)  LR: 4.591e-04  Data: 0.000 (0.008)
2024-04-07 03:23:13,642 - train - INFO - True
2024-04-07 03:23:13,644 - train - INFO - alphas:tensor([0.2690, 0.1437, 0.1583, 0.2038, 0.2252], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:13,689 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:13,689 - train - INFO - True
2024-04-07 03:23:13,690 - train - INFO - alphas:tensor([0.3520, 0.0925, 0.1065, 0.1736, 0.2754], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:13,725 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:13,725 - train - INFO - True
2024-04-07 03:23:13,726 - train - INFO - alphas:tensor([0.7404, 0.0789, 0.0532, 0.0608, 0.0667], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:13,756 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:13,756 - train - INFO - True
2024-04-07 03:23:13,757 - train - INFO - alphas:tensor([0.7059, 0.0647, 0.0575, 0.0780, 0.0940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:13,783 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:13,784 - train - INFO - True
2024-04-07 03:23:13,784 - train - INFO - alphas:tensor([0.5251, 0.0764, 0.0921, 0.1321, 0.1743], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:13,808 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:13,808 - train - INFO - True
2024-04-07 03:23:13,809 - train - INFO - alphas:tensor([0.6662, 0.0740, 0.0635, 0.0869, 0.1095], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:13,831 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:13,831 - train - INFO - True
2024-04-07 03:23:13,832 - train - INFO - alphas:tensor([0.7766, 0.0615, 0.0413, 0.0538, 0.0667], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:13,852 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:13,852 - train - INFO - True
2024-04-07 03:23:13,853 - train - INFO - alphas:tensor([0.7355, 0.0679, 0.0481, 0.0665, 0.0819], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:13,872 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:13,872 - train - INFO - True
2024-04-07 03:23:13,873 - train - INFO - alphas:tensor([0.5753, 0.0666, 0.0779, 0.1178, 0.1624], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:13,891 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:13,891 - train - INFO - True
2024-04-07 03:23:13,892 - train - INFO - alphas:tensor([0.6941, 0.0665, 0.0597, 0.0781, 0.1016], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:13,909 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:13,909 - train - INFO - True
2024-04-07 03:23:13,910 - train - INFO - alphas:tensor([0.7358, 0.0586, 0.0489, 0.0673, 0.0894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:13,928 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:13,928 - train - INFO - True
2024-04-07 03:23:13,929 - train - INFO - alphas:tensor([0.6657, 0.0616, 0.0607, 0.0932, 0.1188], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:13,950 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:13,950 - train - INFO - True
2024-04-07 03:23:13,951 - train - INFO - alphas:tensor([0.5931, 0.0605, 0.0705, 0.1145, 0.1614], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:13,971 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:13,971 - train - INFO - True
2024-04-07 03:23:13,971 - train - INFO - alphas:tensor([0.6943, 0.0567, 0.0587, 0.0812, 0.1090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:13,990 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:13,990 - train - INFO - True
2024-04-07 03:23:13,991 - train - INFO - alphas:tensor([0.6960, 0.0680, 0.0535, 0.0766, 0.1058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,009 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,009 - train - INFO - True
2024-04-07 03:23:14,010 - train - INFO - alphas:tensor([0.5776, 0.0579, 0.0652, 0.1146, 0.1847], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,027 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,027 - train - INFO - True
2024-04-07 03:23:14,028 - train - INFO - alphas:tensor([0.5851, 0.0588, 0.0692, 0.1169, 0.1700], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,044 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,044 - train - INFO - True
2024-04-07 03:23:14,045 - train - INFO - alphas:tensor([0.6944, 0.0539, 0.0590, 0.0825, 0.1102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,062 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,062 - train - INFO - True
2024-04-07 03:23:14,063 - train - INFO - alphas:tensor([0.7100, 0.0593, 0.0512, 0.0757, 0.1038], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,084 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,084 - train - INFO - True
2024-04-07 03:23:14,085 - train - INFO - alphas:tensor([0.5599, 0.0520, 0.0628, 0.1228, 0.2025], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,104 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,105 - train - INFO - True
2024-04-07 03:23:14,105 - train - INFO - alphas:tensor([0.5510, 0.0573, 0.0765, 0.1282, 0.1871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,124 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,124 - train - INFO - True
2024-04-07 03:23:14,125 - train - INFO - alphas:tensor([0.7219, 0.0497, 0.0541, 0.0740, 0.1003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,142 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,142 - train - INFO - True
2024-04-07 03:23:14,143 - train - INFO - alphas:tensor([0.7247, 0.0628, 0.0473, 0.0691, 0.0961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,160 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,160 - train - INFO - True
2024-04-07 03:23:14,160 - train - INFO - alphas:tensor([0.5725, 0.0467, 0.0585, 0.1195, 0.2028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,177 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,177 - train - INFO - True
2024-04-07 03:23:14,178 - train - INFO - alphas:tensor([0.5418, 0.0527, 0.0751, 0.1334, 0.1971], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,195 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,195 - train - INFO - True
2024-04-07 03:23:14,195 - train - INFO - alphas:tensor([0.7071, 0.0496, 0.0552, 0.0763, 0.1119], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,216 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,216 - train - INFO - True
2024-04-07 03:23:14,216 - train - INFO - alphas:tensor([0.7238, 0.0504, 0.0466, 0.0725, 0.1067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,237 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,237 - train - INFO - True
2024-04-07 03:23:14,238 - train - INFO - alphas:tensor([0.5958, 0.0477, 0.0552, 0.1117, 0.1895], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,257 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,257 - train - INFO - True
2024-04-07 03:23:14,258 - train - INFO - alphas:tensor([0.5158, 0.0486, 0.0804, 0.1412, 0.2139], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,276 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,276 - train - INFO - True
2024-04-07 03:23:14,277 - train - INFO - alphas:tensor([0.6807, 0.0483, 0.0574, 0.0864, 0.1271], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,294 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,295 - train - INFO - True
2024-04-07 03:23:14,295 - train - INFO - alphas:tensor([0.7185, 0.0471, 0.0462, 0.0744, 0.1137], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,312 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,312 - train - INFO - True
2024-04-07 03:23:14,313 - train - INFO - alphas:tensor([0.6417, 0.0457, 0.0542, 0.1016, 0.1566], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,330 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,330 - train - INFO - True
2024-04-07 03:23:14,330 - train - INFO - alphas:tensor([0.4929, 0.0446, 0.0808, 0.1477, 0.2339], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,347 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,347 - train - INFO - True
2024-04-07 03:23:14,348 - train - INFO - alphas:tensor([0.6341, 0.0498, 0.0623, 0.0999, 0.1539], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,364 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,365 - train - INFO - True
2024-04-07 03:23:14,365 - train - INFO - alphas:tensor([0.6931, 0.0506, 0.0478, 0.0844, 0.1241], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,385 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,385 - train - INFO - True
2024-04-07 03:23:14,386 - train - INFO - alphas:tensor([0.6417, 0.0461, 0.0562, 0.1024, 0.1535], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,407 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,407 - train - INFO - True
2024-04-07 03:23:14,408 - train - INFO - alphas:tensor([0.6803, 0.0672, 0.1102, 0.1423], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:23:14,427 - train - INFO - tau:0.7700431458051551
2024-04-07 03:23:14,427 - train - INFO - avg block size:1.0
2024-04-07 03:23:14,427 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 03:23:14,427 - train - INFO - lasso_alpha:3.138428376721003e-05
2024-04-07 03:23:14,654 - train - INFO - Test: [   0/78]  Time: 0.223 (0.223)  Loss:  1.0059 (1.0059)  Acc@1: 81.2500 (81.2500)  Acc@5: 94.5312 (94.5312)
2024-04-07 03:23:18,985 - train - INFO - Test: [  50/78]  Time: 0.088 (0.089)  Loss:  1.8633 (1.7116)  Acc@1: 57.0312 (60.3554)  Acc@5: 81.2500 (82.9657)
2024-04-07 03:23:21,383 - train - INFO - Test: [  78/78]  Time: 0.059 (0.088)  Loss:  1.8867 (1.7427)  Acc@1: 50.0000 (59.3200)  Acc@5: 93.7500 (82.5000)
2024-04-07 03:23:22,726 - train - INFO - Train: 29 [   0/781 (  0%)]  Loss:  4.206940 (4.2069)  Time: 1.275s,  100.41/s  (1.275s,  100.41/s)  LR: 4.562e-04  Data: 0.194 (0.194)
2024-04-07 03:24:07,869 - train - INFO - Train: 29 [  50/781 (  6%)]  Loss:  3.947645 (3.8373)  Time: 0.848s,  150.86/s  (0.910s,  140.64/s)  LR: 4.562e-04  Data: 0.008 (0.011)
2024-04-07 03:24:53,726 - train - INFO - Train: 29 [ 100/781 ( 13%)]  Loss:  3.605438 (3.8608)  Time: 0.825s,  155.23/s  (0.914s,  140.11/s)  LR: 4.562e-04  Data: 0.006 (0.009)
2024-04-07 03:25:40,786 - train - INFO - Train: 29 [ 150/781 ( 19%)]  Loss:  3.581114 (3.8604)  Time: 0.822s,  155.76/s  (0.923s,  138.72/s)  LR: 4.562e-04  Data: 0.006 (0.009)
2024-04-07 03:26:25,979 - train - INFO - Train: 29 [ 200/781 ( 26%)]  Loss:  4.403611 (3.8544)  Time: 1.090s,  117.38/s  (0.918s,  139.43/s)  LR: 4.562e-04  Data: 0.009 (0.009)
2024-04-07 03:27:12,496 - train - INFO - Train: 29 [ 250/781 ( 32%)]  Loss:  3.490298 (3.8633)  Time: 1.109s,  115.37/s  (0.920s,  139.06/s)  LR: 4.562e-04  Data: 0.008 (0.009)
2024-04-07 03:27:58,519 - train - INFO - Train: 29 [ 300/781 ( 38%)]  Loss:  4.410306 (3.8827)  Time: 1.126s,  113.70/s  (0.920s,  139.06/s)  LR: 4.562e-04  Data: 0.008 (0.008)
2024-04-07 03:28:43,561 - train - INFO - Train: 29 [ 350/781 ( 45%)]  Loss:  3.945835 (3.8840)  Time: 0.837s,  152.91/s  (0.918s,  139.48/s)  LR: 4.562e-04  Data: 0.008 (0.009)
2024-04-07 03:29:30,994 - train - INFO - Train: 29 [ 400/781 ( 51%)]  Loss:  4.096130 (3.8834)  Time: 1.102s,  116.18/s  (0.922s,  138.90/s)  LR: 4.562e-04  Data: 0.009 (0.009)
2024-04-07 03:30:18,296 - train - INFO - Train: 29 [ 450/781 ( 58%)]  Loss:  4.313987 (3.8886)  Time: 1.047s,  122.21/s  (0.924s,  138.49/s)  LR: 4.562e-04  Data: 0.007 (0.008)
2024-04-07 03:31:03,186 - train - INFO - Train: 29 [ 500/781 ( 64%)]  Loss:  4.473237 (3.8810)  Time: 0.849s,  150.84/s  (0.922s,  138.89/s)  LR: 4.562e-04  Data: 0.021 (0.008)
2024-04-07 03:31:49,113 - train - INFO - Train: 29 [ 550/781 ( 71%)]  Loss:  4.206852 (3.8843)  Time: 1.081s,  118.43/s  (0.921s,  138.93/s)  LR: 4.562e-04  Data: 0.007 (0.008)
2024-04-07 03:32:36,121 - train - INFO - Train: 29 [ 600/781 ( 77%)]  Loss:  3.359583 (3.8833)  Time: 0.837s,  152.90/s  (0.923s,  138.70/s)  LR: 4.562e-04  Data: 0.008 (0.008)
2024-04-07 03:33:23,611 - train - INFO - Train: 29 [ 650/781 ( 83%)]  Loss:  4.475893 (3.8851)  Time: 0.837s,  152.92/s  (0.925s,  138.39/s)  LR: 4.562e-04  Data: 0.010 (0.008)
2024-04-07 03:34:09,524 - train - INFO - Train: 29 [ 700/781 ( 90%)]  Loss:  3.195218 (3.8807)  Time: 1.026s,  124.80/s  (0.924s,  138.46/s)  LR: 4.562e-04  Data: 0.006 (0.008)
2024-04-07 03:34:55,653 - train - INFO - Train: 29 [ 750/781 ( 96%)]  Loss:  4.094664 (3.8767)  Time: 0.851s,  150.42/s  (0.924s,  138.48/s)  LR: 4.562e-04  Data: 0.008 (0.008)
2024-04-07 03:35:22,906 - train - INFO - Train: 29 [ 780/781 (100%)]  Loss:  4.127629 (3.8751)  Time: 0.812s,  157.55/s  (0.924s,  138.57/s)  LR: 4.562e-04  Data: 0.000 (0.008)
2024-04-07 03:35:22,907 - train - INFO - True
2024-04-07 03:35:22,909 - train - INFO - alphas:tensor([0.2631, 0.1406, 0.1589, 0.2074, 0.2301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:22,948 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:22,948 - train - INFO - True
2024-04-07 03:35:22,949 - train - INFO - alphas:tensor([0.3470, 0.0901, 0.1058, 0.1747, 0.2825], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:22,981 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:22,981 - train - INFO - True
2024-04-07 03:35:22,983 - train - INFO - alphas:tensor([0.7419, 0.0778, 0.0527, 0.0607, 0.0669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,010 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,010 - train - INFO - True
2024-04-07 03:35:23,011 - train - INFO - alphas:tensor([0.7033, 0.0640, 0.0575, 0.0790, 0.0962], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,036 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,036 - train - INFO - True
2024-04-07 03:35:23,037 - train - INFO - alphas:tensor([0.5236, 0.0737, 0.0915, 0.1332, 0.1780], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,060 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,060 - train - INFO - True
2024-04-07 03:35:23,061 - train - INFO - alphas:tensor([0.6649, 0.0719, 0.0634, 0.0879, 0.1119], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,082 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,082 - train - INFO - True
2024-04-07 03:35:23,083 - train - INFO - alphas:tensor([0.7761, 0.0609, 0.0410, 0.0542, 0.0678], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,104 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,104 - train - INFO - True
2024-04-07 03:35:23,105 - train - INFO - alphas:tensor([0.7267, 0.0680, 0.0492, 0.0693, 0.0868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,126 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,126 - train - INFO - True
2024-04-07 03:35:23,127 - train - INFO - alphas:tensor([0.5739, 0.0646, 0.0774, 0.1185, 0.1657], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,146 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,146 - train - INFO - True
2024-04-07 03:35:23,147 - train - INFO - alphas:tensor([0.6925, 0.0650, 0.0597, 0.0788, 0.1040], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,165 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,166 - train - INFO - True
2024-04-07 03:35:23,166 - train - INFO - alphas:tensor([0.7314, 0.0578, 0.0491, 0.0689, 0.0928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,184 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,184 - train - INFO - True
2024-04-07 03:35:23,184 - train - INFO - alphas:tensor([0.6572, 0.0600, 0.0611, 0.0964, 0.1253], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,201 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,201 - train - INFO - True
2024-04-07 03:35:23,202 - train - INFO - alphas:tensor([0.5895, 0.0585, 0.0699, 0.1160, 0.1661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,218 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,219 - train - INFO - True
2024-04-07 03:35:23,219 - train - INFO - alphas:tensor([0.6906, 0.0553, 0.0585, 0.0825, 0.1131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,235 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,235 - train - INFO - True
2024-04-07 03:35:23,236 - train - INFO - alphas:tensor([0.6886, 0.0670, 0.0542, 0.0790, 0.1112], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,252 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,252 - train - INFO - True
2024-04-07 03:35:23,252 - train - INFO - alphas:tensor([0.5696, 0.0550, 0.0642, 0.1169, 0.1942], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,269 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,269 - train - INFO - True
2024-04-07 03:35:23,270 - train - INFO - alphas:tensor([0.5830, 0.0569, 0.0687, 0.1176, 0.1738], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,285 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,286 - train - INFO - True
2024-04-07 03:35:23,286 - train - INFO - alphas:tensor([0.6894, 0.0531, 0.0589, 0.0840, 0.1146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,302 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,302 - train - INFO - True
2024-04-07 03:35:23,303 - train - INFO - alphas:tensor([0.7036, 0.0584, 0.0514, 0.0777, 0.1088], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,319 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,319 - train - INFO - True
2024-04-07 03:35:23,319 - train - INFO - alphas:tensor([0.5482, 0.0494, 0.0618, 0.1259, 0.2147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,335 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,335 - train - INFO - True
2024-04-07 03:35:23,336 - train - INFO - alphas:tensor([0.5440, 0.0554, 0.0766, 0.1304, 0.1936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,352 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,352 - train - INFO - True
2024-04-07 03:35:23,352 - train - INFO - alphas:tensor([0.7177, 0.0485, 0.0541, 0.0753, 0.1044], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,368 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,368 - train - INFO - True
2024-04-07 03:35:23,369 - train - INFO - alphas:tensor([0.7194, 0.0620, 0.0473, 0.0707, 0.1005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,385 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,385 - train - INFO - True
2024-04-07 03:35:23,385 - train - INFO - alphas:tensor([0.5638, 0.0441, 0.0575, 0.1214, 0.2133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,402 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,402 - train - INFO - True
2024-04-07 03:35:23,402 - train - INFO - alphas:tensor([0.5346, 0.0510, 0.0748, 0.1354, 0.2041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,419 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,419 - train - INFO - True
2024-04-07 03:35:23,420 - train - INFO - alphas:tensor([0.7011, 0.0490, 0.0551, 0.0776, 0.1172], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,436 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,436 - train - INFO - True
2024-04-07 03:35:23,437 - train - INFO - alphas:tensor([0.7210, 0.0493, 0.0458, 0.0735, 0.1104], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,453 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,453 - train - INFO - True
2024-04-07 03:35:23,454 - train - INFO - alphas:tensor([0.5891, 0.0457, 0.0535, 0.1129, 0.1988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,470 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,471 - train - INFO - True
2024-04-07 03:35:23,471 - train - INFO - alphas:tensor([0.5084, 0.0461, 0.0797, 0.1434, 0.2224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,488 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,488 - train - INFO - True
2024-04-07 03:35:23,488 - train - INFO - alphas:tensor([0.6726, 0.0472, 0.0576, 0.0889, 0.1337], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,505 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,505 - train - INFO - True
2024-04-07 03:35:23,506 - train - INFO - alphas:tensor([0.7115, 0.0462, 0.0464, 0.0766, 0.1194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,522 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,522 - train - INFO - True
2024-04-07 03:35:23,523 - train - INFO - alphas:tensor([0.6335, 0.0439, 0.0532, 0.1040, 0.1654], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,539 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,539 - train - INFO - True
2024-04-07 03:35:23,540 - train - INFO - alphas:tensor([0.4864, 0.0425, 0.0796, 0.1494, 0.2421], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,556 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,556 - train - INFO - True
2024-04-07 03:35:23,557 - train - INFO - alphas:tensor([0.6251, 0.0481, 0.0622, 0.1022, 0.1624], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,573 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,573 - train - INFO - True
2024-04-07 03:35:23,574 - train - INFO - alphas:tensor([0.6875, 0.0498, 0.0474, 0.0857, 0.1295], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,591 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,591 - train - INFO - True
2024-04-07 03:35:23,591 - train - INFO - alphas:tensor([0.6329, 0.0442, 0.0560, 0.1051, 0.1618], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,608 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,608 - train - INFO - True
2024-04-07 03:35:23,609 - train - INFO - alphas:tensor([0.6829, 0.0661, 0.1091, 0.1419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:35:23,626 - train - INFO - tau:0.7623427143471035
2024-04-07 03:35:23,626 - train - INFO - avg block size:1.0
2024-04-07 03:35:23,626 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 03:35:23,843 - train - INFO - Test: [   0/78]  Time: 0.213 (0.213)  Loss:  0.9194 (0.9194)  Acc@1: 83.5938 (83.5938)  Acc@5: 92.9688 (92.9688)
2024-04-07 03:35:28,211 - train - INFO - Test: [  50/78]  Time: 0.089 (0.090)  Loss:  1.8076 (1.7353)  Acc@1: 59.3750 (59.7273)  Acc@5: 82.0312 (82.4602)
2024-04-07 03:35:30,628 - train - INFO - Test: [  78/78]  Time: 0.060 (0.089)  Loss:  1.9551 (1.7685)  Acc@1: 56.2500 (58.4800)  Acc@5: 93.7500 (82.1200)
2024-04-07 03:35:31,709 - train - INFO - Train: 30 [   0/781 (  0%)]  Loss:  4.368018 (4.3680)  Time: 1.016s,  126.01/s  (1.016s,  126.01/s)  LR: 4.532e-04  Data: 0.215 (0.215)
2024-04-07 03:36:17,984 - train - INFO - Train: 30 [  50/781 (  6%)]  Loss:  4.390143 (3.8824)  Time: 0.850s,  150.66/s  (0.927s,  138.04/s)  LR: 4.532e-04  Data: 0.008 (0.013)
2024-04-07 03:37:05,182 - train - INFO - Train: 30 [ 100/781 ( 13%)]  Loss:  3.778907 (3.9177)  Time: 1.075s,  119.12/s  (0.935s,  136.83/s)  LR: 4.532e-04  Data: 0.008 (0.011)
2024-04-07 03:37:52,196 - train - INFO - Train: 30 [ 150/781 ( 19%)]  Loss:  3.891039 (3.9317)  Time: 1.029s,  124.34/s  (0.937s,  136.60/s)  LR: 4.532e-04  Data: 0.005 (0.010)
2024-04-07 03:38:38,165 - train - INFO - Train: 30 [ 200/781 ( 26%)]  Loss:  3.768582 (3.9078)  Time: 0.851s,  150.40/s  (0.933s,  137.24/s)  LR: 4.532e-04  Data: 0.009 (0.010)
2024-04-07 03:39:23,497 - train - INFO - Train: 30 [ 250/781 ( 32%)]  Loss:  4.151058 (3.9075)  Time: 0.828s,  154.60/s  (0.927s,  138.01/s)  LR: 4.532e-04  Data: 0.008 (0.009)
2024-04-07 03:40:10,020 - train - INFO - Train: 30 [ 300/781 ( 38%)]  Loss:  4.431719 (3.9179)  Time: 1.110s,  115.28/s  (0.928s,  137.94/s)  LR: 4.532e-04  Data: 0.018 (0.009)
2024-04-07 03:40:56,834 - train - INFO - Train: 30 [ 350/781 ( 45%)]  Loss:  3.919194 (3.9065)  Time: 0.824s,  155.39/s  (0.929s,  137.76/s)  LR: 4.532e-04  Data: 0.005 (0.009)
2024-04-07 03:41:43,154 - train - INFO - Train: 30 [ 400/781 ( 51%)]  Loss:  4.012501 (3.9075)  Time: 1.103s,  116.04/s  (0.929s,  137.81/s)  LR: 4.532e-04  Data: 0.016 (0.009)
2024-04-07 03:42:29,544 - train - INFO - Train: 30 [ 450/781 ( 58%)]  Loss:  3.971213 (3.8992)  Time: 0.853s,  150.03/s  (0.929s,  137.83/s)  LR: 4.532e-04  Data: 0.008 (0.009)
2024-04-07 03:43:15,160 - train - INFO - Train: 30 [ 500/781 ( 64%)]  Loss:  4.424042 (3.9037)  Time: 0.843s,  151.89/s  (0.927s,  138.07/s)  LR: 4.532e-04  Data: 0.009 (0.009)
2024-04-07 03:44:03,269 - train - INFO - Train: 30 [ 550/781 ( 71%)]  Loss:  3.940352 (3.8998)  Time: 1.089s,  117.54/s  (0.930s,  137.60/s)  LR: 4.532e-04  Data: 0.008 (0.009)
2024-04-07 03:44:49,898 - train - INFO - Train: 30 [ 600/781 ( 77%)]  Loss:  4.062179 (3.9039)  Time: 1.079s,  118.62/s  (0.930s,  137.57/s)  LR: 4.532e-04  Data: 0.008 (0.009)
2024-04-07 03:45:36,517 - train - INFO - Train: 30 [ 650/781 ( 83%)]  Loss:  3.413431 (3.9024)  Time: 1.093s,  117.11/s  (0.931s,  137.55/s)  LR: 4.532e-04  Data: 0.008 (0.009)
2024-04-07 03:46:23,496 - train - INFO - Train: 30 [ 700/781 ( 90%)]  Loss:  4.359169 (3.8981)  Time: 0.818s,  156.47/s  (0.931s,  137.46/s)  LR: 4.532e-04  Data: 0.005 (0.009)
2024-04-07 03:47:11,486 - train - INFO - Train: 30 [ 750/781 ( 96%)]  Loss:  3.307978 (3.8925)  Time: 1.097s,  116.73/s  (0.933s,  137.18/s)  LR: 4.532e-04  Data: 0.008 (0.009)
2024-04-07 03:47:39,100 - train - INFO - Train: 30 [ 780/781 (100%)]  Loss:  4.126582 (3.8900)  Time: 0.815s,  157.09/s  (0.933s,  137.25/s)  LR: 4.532e-04  Data: 0.000 (0.009)
2024-04-07 03:47:39,102 - train - INFO - True
2024-04-07 03:47:39,104 - train - INFO - alphas:tensor([0.2572, 0.1373, 0.1595, 0.2108, 0.2351], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,149 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,149 - train - INFO - True
2024-04-07 03:47:39,150 - train - INFO - alphas:tensor([0.3432, 0.0874, 0.1042, 0.1750, 0.2902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,185 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,185 - train - INFO - True
2024-04-07 03:47:39,186 - train - INFO - alphas:tensor([0.7428, 0.0771, 0.0525, 0.0607, 0.0669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,216 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,216 - train - INFO - True
2024-04-07 03:47:39,217 - train - INFO - alphas:tensor([0.7001, 0.0634, 0.0576, 0.0802, 0.0986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,243 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,243 - train - INFO - True
2024-04-07 03:47:39,244 - train - INFO - alphas:tensor([0.5179, 0.0727, 0.0919, 0.1349, 0.1827], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,268 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,268 - train - INFO - True
2024-04-07 03:47:39,269 - train - INFO - alphas:tensor([0.6610, 0.0706, 0.0638, 0.0893, 0.1153], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,290 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,290 - train - INFO - True
2024-04-07 03:47:39,291 - train - INFO - alphas:tensor([0.7740, 0.0605, 0.0410, 0.0551, 0.0694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,311 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,312 - train - INFO - True
2024-04-07 03:47:39,312 - train - INFO - alphas:tensor([0.7175, 0.0684, 0.0497, 0.0722, 0.0923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,331 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,331 - train - INFO - True
2024-04-07 03:47:39,332 - train - INFO - alphas:tensor([0.5683, 0.0634, 0.0772, 0.1202, 0.1709], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,353 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,353 - train - INFO - True
2024-04-07 03:47:39,354 - train - INFO - alphas:tensor([0.6878, 0.0639, 0.0602, 0.0803, 0.1077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,375 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,375 - train - INFO - True
2024-04-07 03:47:39,376 - train - INFO - alphas:tensor([0.7271, 0.0571, 0.0491, 0.0705, 0.0962], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,397 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,397 - train - INFO - True
2024-04-07 03:47:39,398 - train - INFO - alphas:tensor([0.6480, 0.0589, 0.0608, 0.0999, 0.1324], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,419 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,419 - train - INFO - True
2024-04-07 03:47:39,421 - train - INFO - alphas:tensor([0.5871, 0.0572, 0.0692, 0.1168, 0.1698], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,442 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,442 - train - INFO - True
2024-04-07 03:47:39,443 - train - INFO - alphas:tensor([0.6855, 0.0542, 0.0587, 0.0841, 0.1174], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,464 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,465 - train - INFO - True
2024-04-07 03:47:39,465 - train - INFO - alphas:tensor([0.6822, 0.0660, 0.0541, 0.0813, 0.1164], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,485 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,486 - train - INFO - True
2024-04-07 03:47:39,486 - train - INFO - alphas:tensor([0.5596, 0.0532, 0.0629, 0.1197, 0.2045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,505 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,505 - train - INFO - True
2024-04-07 03:47:39,506 - train - INFO - alphas:tensor([0.5819, 0.0551, 0.0674, 0.1181, 0.1775], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,524 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,524 - train - INFO - True
2024-04-07 03:47:39,525 - train - INFO - alphas:tensor([0.6854, 0.0508, 0.0590, 0.0859, 0.1188], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,542 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,542 - train - INFO - True
2024-04-07 03:47:39,542 - train - INFO - alphas:tensor([0.6961, 0.0573, 0.0514, 0.0803, 0.1149], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,559 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,559 - train - INFO - True
2024-04-07 03:47:39,560 - train - INFO - alphas:tensor([0.5422, 0.0473, 0.0601, 0.1264, 0.2240], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,582 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,582 - train - INFO - True
2024-04-07 03:47:39,582 - train - INFO - alphas:tensor([0.5401, 0.0528, 0.0756, 0.1319, 0.1996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,606 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,606 - train - INFO - True
2024-04-07 03:47:39,607 - train - INFO - alphas:tensor([0.7134, 0.0469, 0.0538, 0.0769, 0.1090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,628 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,628 - train - INFO - True
2024-04-07 03:47:39,629 - train - INFO - alphas:tensor([0.7182, 0.0602, 0.0466, 0.0712, 0.1038], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,650 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,650 - train - INFO - True
2024-04-07 03:47:39,651 - train - INFO - alphas:tensor([0.5596, 0.0419, 0.0550, 0.1217, 0.2218], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,670 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,671 - train - INFO - True
2024-04-07 03:47:39,672 - train - INFO - alphas:tensor([0.5323, 0.0486, 0.0736, 0.1359, 0.2096], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,694 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,694 - train - INFO - True
2024-04-07 03:47:39,695 - train - INFO - alphas:tensor([0.6976, 0.0473, 0.0552, 0.0789, 0.1211], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,715 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,715 - train - INFO - True
2024-04-07 03:47:39,716 - train - INFO - alphas:tensor([0.7154, 0.0484, 0.0457, 0.0752, 0.1154], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,737 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,737 - train - INFO - True
2024-04-07 03:47:39,738 - train - INFO - alphas:tensor([0.5797, 0.0442, 0.0523, 0.1145, 0.2093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,759 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,759 - train - INFO - True
2024-04-07 03:47:39,759 - train - INFO - alphas:tensor([0.5055, 0.0437, 0.0781, 0.1445, 0.2283], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,779 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,779 - train - INFO - True
2024-04-07 03:47:39,780 - train - INFO - alphas:tensor([0.6721, 0.0450, 0.0570, 0.0890, 0.1369], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,798 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,798 - train - INFO - True
2024-04-07 03:47:39,799 - train - INFO - alphas:tensor([0.7094, 0.0448, 0.0452, 0.0774, 0.1232], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,816 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,816 - train - INFO - True
2024-04-07 03:47:39,817 - train - INFO - alphas:tensor([0.6265, 0.0420, 0.0523, 0.1056, 0.1736], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,834 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,834 - train - INFO - True
2024-04-07 03:47:39,834 - train - INFO - alphas:tensor([0.4815, 0.0405, 0.0787, 0.1499, 0.2494], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,850 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,850 - train - INFO - True
2024-04-07 03:47:39,851 - train - INFO - alphas:tensor([0.6207, 0.0452, 0.0613, 0.1034, 0.1694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,867 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,867 - train - INFO - True
2024-04-07 03:47:39,867 - train - INFO - alphas:tensor([0.6876, 0.0483, 0.0462, 0.0855, 0.1323], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,883 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,883 - train - INFO - True
2024-04-07 03:47:39,884 - train - INFO - alphas:tensor([0.6311, 0.0422, 0.0541, 0.1058, 0.1669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,900 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,900 - train - INFO - True
2024-04-07 03:47:39,901 - train - INFO - alphas:tensor([0.6848, 0.0649, 0.1083, 0.1421], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:47:39,916 - train - INFO - tau:0.7547192872036325
2024-04-07 03:47:39,916 - train - INFO - avg block size:1.0
2024-04-07 03:47:39,917 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 03:47:39,917 - train - INFO - lasso_alpha:3.452271214393104e-05
2024-04-07 03:47:40,165 - train - INFO - Test: [   0/78]  Time: 0.245 (0.245)  Loss:  0.9580 (0.9580)  Acc@1: 78.9062 (78.9062)  Acc@5: 93.7500 (93.7500)
2024-04-07 03:47:44,798 - train - INFO - Test: [  50/78]  Time: 0.087 (0.096)  Loss:  1.9551 (1.7092)  Acc@1: 54.6875 (59.7733)  Acc@5: 80.4688 (83.3333)
2024-04-07 03:47:47,361 - train - INFO - Test: [  78/78]  Time: 0.053 (0.094)  Loss:  1.7900 (1.7338)  Acc@1: 62.5000 (59.4300)  Acc@5: 81.2500 (82.6700)
2024-04-07 03:47:48,714 - train - INFO - Train: 31 [   0/781 (  0%)]  Loss:  3.959374 (3.9594)  Time: 1.276s,  100.31/s  (1.276s,  100.31/s)  LR: 4.501e-04  Data: 0.198 (0.198)
2024-04-07 03:48:34,347 - train - INFO - Train: 31 [  50/781 (  6%)]  Loss:  3.555063 (3.8100)  Time: 0.988s,  129.58/s  (0.920s,  139.17/s)  LR: 4.501e-04  Data: 0.005 (0.012)
2024-04-07 03:49:19,331 - train - INFO - Train: 31 [ 100/781 ( 13%)]  Loss:  4.480688 (3.8436)  Time: 1.053s,  121.61/s  (0.910s,  140.69/s)  LR: 4.501e-04  Data: 0.007 (0.010)
2024-04-07 03:50:03,999 - train - INFO - Train: 31 [ 150/781 ( 19%)]  Loss:  3.501014 (3.8354)  Time: 0.854s,  149.80/s  (0.904s,  141.54/s)  LR: 4.501e-04  Data: 0.009 (0.009)
2024-04-07 03:50:49,084 - train - INFO - Train: 31 [ 200/781 ( 26%)]  Loss:  3.525869 (3.8505)  Time: 0.801s,  159.89/s  (0.904s,  141.64/s)  LR: 4.501e-04  Data: 0.005 (0.008)
2024-04-07 03:51:36,904 - train - INFO - Train: 31 [ 250/781 ( 32%)]  Loss:  4.376093 (3.8422)  Time: 0.837s,  152.92/s  (0.914s,  140.02/s)  LR: 4.501e-04  Data: 0.009 (0.009)
2024-04-07 03:52:22,072 - train - INFO - Train: 31 [ 300/781 ( 38%)]  Loss:  4.169918 (3.8587)  Time: 1.061s,  120.60/s  (0.912s,  140.29/s)  LR: 4.501e-04  Data: 0.009 (0.008)
2024-04-07 03:53:09,391 - train - INFO - Train: 31 [ 350/781 ( 45%)]  Loss:  4.494784 (3.8699)  Time: 1.058s,  120.95/s  (0.917s,  139.55/s)  LR: 4.501e-04  Data: 0.007 (0.008)
2024-04-07 03:53:54,561 - train - INFO - Train: 31 [ 400/781 ( 51%)]  Loss:  4.345337 (3.8744)  Time: 0.818s,  156.49/s  (0.915s,  139.82/s)  LR: 4.501e-04  Data: 0.008 (0.008)
2024-04-07 03:54:40,159 - train - INFO - Train: 31 [ 450/781 ( 58%)]  Loss:  4.283962 (3.8721)  Time: 0.754s,  169.78/s  (0.915s,  139.88/s)  LR: 4.501e-04  Data: 0.005 (0.008)
2024-04-07 03:55:26,355 - train - INFO - Train: 31 [ 500/781 ( 64%)]  Loss:  4.138333 (3.8826)  Time: 0.769s,  166.52/s  (0.916s,  139.74/s)  LR: 4.501e-04  Data: 0.005 (0.008)
2024-04-07 03:56:11,465 - train - INFO - Train: 31 [ 550/781 ( 71%)]  Loss:  4.174573 (3.8826)  Time: 0.821s,  155.91/s  (0.915s,  139.93/s)  LR: 4.501e-04  Data: 0.009 (0.008)
2024-04-07 03:56:56,645 - train - INFO - Train: 31 [ 600/781 ( 77%)]  Loss:  3.981916 (3.8793)  Time: 0.854s,  149.90/s  (0.914s,  140.08/s)  LR: 4.501e-04  Data: 0.007 (0.008)
2024-04-07 03:57:41,945 - train - INFO - Train: 31 [ 650/781 ( 83%)]  Loss:  3.310873 (3.8753)  Time: 1.099s,  116.47/s  (0.913s,  140.17/s)  LR: 4.501e-04  Data: 0.019 (0.008)
2024-04-07 03:58:29,063 - train - INFO - Train: 31 [ 700/781 ( 90%)]  Loss:  3.926948 (3.8795)  Time: 0.791s,  161.90/s  (0.915s,  139.85/s)  LR: 4.501e-04  Data: 0.006 (0.008)
2024-04-07 03:59:14,407 - train - INFO - Train: 31 [ 750/781 ( 96%)]  Loss:  4.218972 (3.8794)  Time: 1.031s,  124.13/s  (0.915s,  139.94/s)  LR: 4.501e-04  Data: 0.012 (0.008)
2024-04-07 03:59:41,014 - train - INFO - Train: 31 [ 780/781 (100%)]  Loss:  3.584754 (3.8807)  Time: 0.838s,  152.74/s  (0.914s,  140.10/s)  LR: 4.501e-04  Data: 0.000 (0.008)
2024-04-07 03:59:41,015 - train - INFO - True
2024-04-07 03:59:41,017 - train - INFO - alphas:tensor([0.2492, 0.1337, 0.1607, 0.2154, 0.2410], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,062 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,062 - train - INFO - True
2024-04-07 03:59:41,063 - train - INFO - alphas:tensor([0.3344, 0.0849, 0.1028, 0.1772, 0.3007], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,098 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,098 - train - INFO - True
2024-04-07 03:59:41,099 - train - INFO - alphas:tensor([0.7407, 0.0775, 0.0527, 0.0613, 0.0678], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,128 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,129 - train - INFO - True
2024-04-07 03:59:41,130 - train - INFO - alphas:tensor([0.6956, 0.0632, 0.0579, 0.0818, 0.1016], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,158 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,158 - train - INFO - True
2024-04-07 03:59:41,159 - train - INFO - alphas:tensor([0.5142, 0.0707, 0.0916, 0.1366, 0.1870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,187 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,187 - train - INFO - True
2024-04-07 03:59:41,188 - train - INFO - alphas:tensor([0.6594, 0.0687, 0.0635, 0.0903, 0.1181], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,216 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,216 - train - INFO - True
2024-04-07 03:59:41,217 - train - INFO - alphas:tensor([0.7724, 0.0600, 0.0410, 0.0558, 0.0707], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,245 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,245 - train - INFO - True
2024-04-07 03:59:41,246 - train - INFO - alphas:tensor([0.7100, 0.0679, 0.0501, 0.0747, 0.0973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,275 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,275 - train - INFO - True
2024-04-07 03:59:41,276 - train - INFO - alphas:tensor([0.5661, 0.0618, 0.0766, 0.1210, 0.1745], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,304 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,304 - train - INFO - True
2024-04-07 03:59:41,305 - train - INFO - alphas:tensor([0.6843, 0.0626, 0.0600, 0.0815, 0.1117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,333 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,333 - train - INFO - True
2024-04-07 03:59:41,334 - train - INFO - alphas:tensor([0.7198, 0.0564, 0.0496, 0.0731, 0.1011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,362 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,362 - train - INFO - True
2024-04-07 03:59:41,363 - train - INFO - alphas:tensor([0.6356, 0.0578, 0.0610, 0.1040, 0.1416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,392 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,392 - train - INFO - True
2024-04-07 03:59:41,393 - train - INFO - alphas:tensor([0.5824, 0.0555, 0.0689, 0.1182, 0.1750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,421 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,421 - train - INFO - True
2024-04-07 03:59:41,422 - train - INFO - alphas:tensor([0.6805, 0.0521, 0.0589, 0.0859, 0.1225], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,450 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,450 - train - INFO - True
2024-04-07 03:59:41,451 - train - INFO - alphas:tensor([0.6739, 0.0652, 0.0542, 0.0840, 0.1227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,479 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,479 - train - INFO - True
2024-04-07 03:59:41,480 - train - INFO - alphas:tensor([0.5443, 0.0516, 0.0624, 0.1233, 0.2184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,508 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,509 - train - INFO - True
2024-04-07 03:59:41,509 - train - INFO - alphas:tensor([0.5747, 0.0539, 0.0672, 0.1202, 0.1840], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,538 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,538 - train - INFO - True
2024-04-07 03:59:41,539 - train - INFO - alphas:tensor([0.6809, 0.0490, 0.0588, 0.0875, 0.1238], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,567 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,567 - train - INFO - True
2024-04-07 03:59:41,568 - train - INFO - alphas:tensor([0.6849, 0.0566, 0.0521, 0.0837, 0.1227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,596 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,596 - train - INFO - True
2024-04-07 03:59:41,597 - train - INFO - alphas:tensor([0.5314, 0.0448, 0.0586, 0.1286, 0.2366], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,625 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,625 - train - INFO - True
2024-04-07 03:59:41,626 - train - INFO - alphas:tensor([0.5318, 0.0508, 0.0753, 0.1346, 0.2075], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,654 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,655 - train - INFO - True
2024-04-07 03:59:41,655 - train - INFO - alphas:tensor([0.7045, 0.0468, 0.0550, 0.0792, 0.1145], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,684 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,684 - train - INFO - True
2024-04-07 03:59:41,685 - train - INFO - alphas:tensor([0.7087, 0.0597, 0.0473, 0.0742, 0.1101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,713 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,713 - train - INFO - True
2024-04-07 03:59:41,714 - train - INFO - alphas:tensor([0.5457, 0.0400, 0.0538, 0.1239, 0.2366], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,742 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,742 - train - INFO - True
2024-04-07 03:59:41,743 - train - INFO - alphas:tensor([0.5256, 0.0467, 0.0730, 0.1380, 0.2168], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,769 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,769 - train - INFO - True
2024-04-07 03:59:41,770 - train - INFO - alphas:tensor([0.6884, 0.0464, 0.0556, 0.0813, 0.1283], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,793 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,794 - train - INFO - True
2024-04-07 03:59:41,794 - train - INFO - alphas:tensor([0.7088, 0.0471, 0.0457, 0.0773, 0.1211], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,816 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,816 - train - INFO - True
2024-04-07 03:59:41,817 - train - INFO - alphas:tensor([0.5704, 0.0424, 0.0508, 0.1158, 0.2206], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,838 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,838 - train - INFO - True
2024-04-07 03:59:41,839 - train - INFO - alphas:tensor([0.4979, 0.0418, 0.0771, 0.1464, 0.2368], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,860 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,860 - train - INFO - True
2024-04-07 03:59:41,861 - train - INFO - alphas:tensor([0.6619, 0.0445, 0.0574, 0.0914, 0.1447], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,881 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,881 - train - INFO - True
2024-04-07 03:59:41,881 - train - INFO - alphas:tensor([0.7041, 0.0434, 0.0450, 0.0787, 0.1288], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,900 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,900 - train - INFO - True
2024-04-07 03:59:41,901 - train - INFO - alphas:tensor([0.6134, 0.0406, 0.0517, 0.1096, 0.1848], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,919 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,919 - train - INFO - True
2024-04-07 03:59:41,920 - train - INFO - alphas:tensor([0.4747, 0.0390, 0.0777, 0.1511, 0.2574], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,938 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,938 - train - INFO - True
2024-04-07 03:59:41,938 - train - INFO - alphas:tensor([0.6158, 0.0431, 0.0606, 0.1044, 0.1761], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,955 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,955 - train - INFO - True
2024-04-07 03:59:41,956 - train - INFO - alphas:tensor([0.6832, 0.0475, 0.0454, 0.0867, 0.1372], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,973 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,973 - train - INFO - True
2024-04-07 03:59:41,973 - train - INFO - alphas:tensor([0.6241, 0.0412, 0.0531, 0.1073, 0.1743], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:41,993 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:41,993 - train - INFO - True
2024-04-07 03:59:41,993 - train - INFO - alphas:tensor([0.6868, 0.0641, 0.1074, 0.1418], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 03:59:42,014 - train - INFO - tau:0.7471720943315961
2024-04-07 03:59:42,014 - train - INFO - avg block size:1.0
2024-04-07 03:59:42,014 - train - INFO - current latency ratio:tensor(1.)
2024-04-07 03:59:42,261 - train - INFO - Test: [   0/78]  Time: 0.243 (0.243)  Loss:  0.9307 (0.9307)  Acc@1: 81.2500 (81.2500)  Acc@5: 94.5312 (94.5312)
2024-04-07 03:59:46,731 - train - INFO - Test: [  50/78]  Time: 0.088 (0.092)  Loss:  1.8252 (1.7277)  Acc@1: 58.5938 (59.8346)  Acc@5: 82.0312 (82.8125)
2024-04-07 03:59:49,109 - train - INFO - Test: [  78/78]  Time: 0.053 (0.090)  Loss:  1.5381 (1.7548)  Acc@1: 56.2500 (59.2200)  Acc@5: 87.5000 (82.3700)
2024-04-07 03:59:50,182 - train - INFO - Train: 32 [   0/781 (  0%)]  Loss:  3.503735 (3.5037)  Time: 1.002s,  127.73/s  (1.002s,  127.73/s)  LR: 4.470e-04  Data: 0.169 (0.169)
2024-04-07 04:00:34,965 - train - INFO - Train: 32 [  50/781 (  6%)]  Loss:  4.142303 (3.9537)  Time: 0.850s,  150.54/s  (0.898s,  142.58/s)  LR: 4.470e-04  Data: 0.009 (0.012)
2024-04-07 04:01:19,625 - train - INFO - Train: 32 [ 100/781 ( 13%)]  Loss:  3.505431 (3.8952)  Time: 0.837s,  152.86/s  (0.895s,  142.94/s)  LR: 4.470e-04  Data: 0.008 (0.010)
2024-04-07 04:02:05,216 - train - INFO - Train: 32 [ 150/781 ( 19%)]  Loss:  4.614806 (3.8770)  Time: 1.062s,  120.56/s  (0.901s,  142.08/s)  LR: 4.470e-04  Data: 0.009 (0.009)
2024-04-07 04:02:48,885 - train - INFO - Train: 32 [ 200/781 ( 26%)]  Loss:  3.939157 (3.8749)  Time: 0.849s,  150.83/s  (0.894s,  143.17/s)  LR: 4.470e-04  Data: 0.007 (0.009)
2024-04-07 04:03:32,690 - train - INFO - Train: 32 [ 250/781 ( 32%)]  Loss:  4.155734 (3.8877)  Time: 1.075s,  119.11/s  (0.890s,  143.75/s)  LR: 4.470e-04  Data: 0.008 (0.009)
2024-04-07 04:04:18,132 - train - INFO - Train: 32 [ 300/781 ( 38%)]  Loss:  3.936680 (3.8834)  Time: 1.024s,  124.94/s  (0.893s,  143.26/s)  LR: 4.470e-04  Data: 0.006 (0.009)
2024-04-07 04:05:03,051 - train - INFO - Train: 32 [ 350/781 ( 45%)]  Loss:  3.955854 (3.8991)  Time: 1.009s,  126.81/s  (0.894s,  143.15/s)  LR: 4.470e-04  Data: 0.005 (0.008)
2024-04-07 04:05:49,245 - train - INFO - Train: 32 [ 400/781 ( 51%)]  Loss:  4.261062 (3.8983)  Time: 1.012s,  126.52/s  (0.898s,  142.56/s)  LR: 4.470e-04  Data: 0.005 (0.008)
2024-04-07 04:06:33,713 - train - INFO - Train: 32 [ 450/781 ( 58%)]  Loss:  3.665254 (3.8919)  Time: 0.847s,  151.19/s  (0.897s,  142.71/s)  LR: 4.470e-04  Data: 0.008 (0.008)
2024-04-07 04:07:19,132 - train - INFO - Train: 32 [ 500/781 ( 64%)]  Loss:  4.367110 (3.8858)  Time: 0.839s,  152.65/s  (0.898s,  142.53/s)  LR: 4.470e-04  Data: 0.008 (0.008)
2024-04-07 04:08:04,241 - train - INFO - Train: 32 [ 550/781 ( 71%)]  Loss:  4.283169 (3.8949)  Time: 0.834s,  153.50/s  (0.898s,  142.47/s)  LR: 4.470e-04  Data: 0.008 (0.008)
2024-04-07 04:08:48,835 - train - INFO - Train: 32 [ 600/781 ( 77%)]  Loss:  3.289406 (3.8927)  Time: 0.851s,  150.40/s  (0.898s,  142.56/s)  LR: 4.470e-04  Data: 0.010 (0.008)
2024-04-07 04:09:34,332 - train - INFO - Train: 32 [ 650/781 ( 83%)]  Loss:  4.402086 (3.8938)  Time: 0.838s,  152.67/s  (0.899s,  142.41/s)  LR: 4.470e-04  Data: 0.007 (0.008)
2024-04-07 04:10:18,998 - train - INFO - Train: 32 [ 700/781 ( 90%)]  Loss:  4.316698 (3.8940)  Time: 0.820s,  156.15/s  (0.898s,  142.47/s)  LR: 4.470e-04  Data: 0.007 (0.008)
2024-04-07 04:11:04,931 - train - INFO - Train: 32 [ 750/781 ( 96%)]  Loss:  3.694104 (3.8980)  Time: 0.841s,  152.27/s  (0.900s,  142.26/s)  LR: 4.470e-04  Data: 0.008 (0.008)
2024-04-07 04:11:32,828 - train - INFO - Train: 32 [ 780/781 (100%)]  Loss:  4.147893 (3.8943)  Time: 0.850s,  150.62/s  (0.901s,  142.08/s)  LR: 4.470e-04  Data: 0.000 (0.008)
2024-04-07 04:11:32,829 - train - INFO - True
2024-04-07 04:11:32,844 - train - INFO - alphas:tensor([0.2436, 0.1309, 0.1608, 0.2189, 0.2457], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:32,875 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:32,875 - train - INFO - True
2024-04-07 04:11:32,876 - train - INFO - alphas:tensor([0.3317, 0.0830, 0.1015, 0.1772, 0.3066], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:32,913 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:32,913 - train - INFO - True
2024-04-07 04:11:32,914 - train - INFO - alphas:tensor([0.7412, 0.0766, 0.0525, 0.0615, 0.0682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:32,945 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:32,945 - train - INFO - True
2024-04-07 04:11:32,946 - train - INFO - alphas:tensor([0.6925, 0.0627, 0.0578, 0.0830, 0.1039], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:32,974 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:32,974 - train - INFO - True
2024-04-07 04:11:32,975 - train - INFO - alphas:tensor([0.5104, 0.0688, 0.0909, 0.1379, 0.1919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,003 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,003 - train - INFO - True
2024-04-07 04:11:33,004 - train - INFO - alphas:tensor([0.6516, 0.0681, 0.0644, 0.0929, 0.1230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,032 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,032 - train - INFO - True
2024-04-07 04:11:33,033 - train - INFO - alphas:tensor([0.7705, 0.0596, 0.0408, 0.0566, 0.0725], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,064 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,064 - train - INFO - True
2024-04-07 04:11:33,065 - train - INFO - alphas:tensor([0.7033, 0.0669, 0.0500, 0.0774, 0.1023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,093 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,093 - train - INFO - True
2024-04-07 04:11:33,094 - train - INFO - alphas:tensor([0.5610, 0.0603, 0.0766, 0.1227, 0.1794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,122 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,122 - train - INFO - True
2024-04-07 04:11:33,123 - train - INFO - alphas:tensor([0.6827, 0.0612, 0.0595, 0.0823, 0.1143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,151 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,151 - train - INFO - True
2024-04-07 04:11:33,152 - train - INFO - alphas:tensor([0.7144, 0.0563, 0.0497, 0.0749, 0.1046], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,180 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,180 - train - INFO - True
2024-04-07 04:11:33,181 - train - INFO - alphas:tensor([0.6277, 0.0560, 0.0608, 0.1067, 0.1487], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,209 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,210 - train - INFO - True
2024-04-07 04:11:33,210 - train - INFO - alphas:tensor([0.5789, 0.0537, 0.0682, 0.1196, 0.1796], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,239 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,239 - train - INFO - True
2024-04-07 04:11:33,240 - train - INFO - alphas:tensor([0.6769, 0.0511, 0.0587, 0.0869, 0.1264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,268 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,268 - train - INFO - True
2024-04-07 04:11:33,269 - train - INFO - alphas:tensor([0.6714, 0.0639, 0.0534, 0.0847, 0.1267], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,297 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,297 - train - INFO - True
2024-04-07 04:11:33,298 - train - INFO - alphas:tensor([0.5399, 0.0483, 0.0605, 0.1245, 0.2268], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,326 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,326 - train - INFO - True
2024-04-07 04:11:33,327 - train - INFO - alphas:tensor([0.5705, 0.0523, 0.0662, 0.1213, 0.1896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,355 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,355 - train - INFO - True
2024-04-07 04:11:33,356 - train - INFO - alphas:tensor([0.6760, 0.0478, 0.0587, 0.0890, 0.1285], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,384 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,385 - train - INFO - True
2024-04-07 04:11:33,385 - train - INFO - alphas:tensor([0.6817, 0.0550, 0.0515, 0.0850, 0.1268], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,414 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,414 - train - INFO - True
2024-04-07 04:11:33,415 - train - INFO - alphas:tensor([0.5238, 0.0425, 0.0565, 0.1298, 0.2473], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,443 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,443 - train - INFO - True
2024-04-07 04:11:33,444 - train - INFO - alphas:tensor([0.5272, 0.0494, 0.0743, 0.1359, 0.2132], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,472 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,472 - train - INFO - True
2024-04-07 04:11:33,473 - train - INFO - alphas:tensor([0.6976, 0.0461, 0.0549, 0.0813, 0.1202], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,502 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,502 - train - INFO - True
2024-04-07 04:11:33,503 - train - INFO - alphas:tensor([0.7043, 0.0590, 0.0464, 0.0756, 0.1146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,531 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,531 - train - INFO - True
2024-04-07 04:11:33,532 - train - INFO - alphas:tensor([0.5413, 0.0382, 0.0515, 0.1237, 0.2454], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,560 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,560 - train - INFO - True
2024-04-07 04:11:33,561 - train - INFO - alphas:tensor([0.5209, 0.0447, 0.0719, 0.1392, 0.2232], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,589 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,589 - train - INFO - True
2024-04-07 04:11:33,590 - train - INFO - alphas:tensor([0.6854, 0.0447, 0.0550, 0.0824, 0.1325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,619 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,619 - train - INFO - True
2024-04-07 04:11:33,620 - train - INFO - alphas:tensor([0.7113, 0.0449, 0.0442, 0.0765, 0.1230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,648 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,648 - train - INFO - True
2024-04-07 04:11:33,649 - train - INFO - alphas:tensor([0.5700, 0.0400, 0.0481, 0.1157, 0.2261], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,677 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,677 - train - INFO - True
2024-04-07 04:11:33,678 - train - INFO - alphas:tensor([0.4928, 0.0396, 0.0758, 0.1471, 0.2447], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,705 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,705 - train - INFO - True
2024-04-07 04:11:33,706 - train - INFO - alphas:tensor([0.6564, 0.0424, 0.0569, 0.0930, 0.1514], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,730 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,730 - train - INFO - True
2024-04-07 04:11:33,731 - train - INFO - alphas:tensor([0.7018, 0.0420, 0.0442, 0.0790, 0.1330], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,753 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,753 - train - INFO - True
2024-04-07 04:11:33,754 - train - INFO - alphas:tensor([0.6119, 0.0383, 0.0499, 0.1098, 0.1901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,777 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,777 - train - INFO - True
2024-04-07 04:11:33,778 - train - INFO - alphas:tensor([0.4669, 0.0372, 0.0765, 0.1526, 0.2669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,798 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,798 - train - INFO - True
2024-04-07 04:11:33,798 - train - INFO - alphas:tensor([0.6072, 0.0414, 0.0604, 0.1057, 0.1853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,817 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,817 - train - INFO - True
2024-04-07 04:11:33,818 - train - INFO - alphas:tensor([0.6790, 0.0461, 0.0449, 0.0880, 0.1421], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,836 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,836 - train - INFO - True
2024-04-07 04:11:33,836 - train - INFO - alphas:tensor([0.6149, 0.0399, 0.0525, 0.1095, 0.1832], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,853 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,853 - train - INFO - True
2024-04-07 04:11:33,854 - train - INFO - alphas:tensor([0.6903, 0.0626, 0.1059, 0.1412], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:11:33,871 - train - INFO - tau:0.7397003733882802
2024-04-07 04:11:33,871 - train - INFO - avg block size:1.4054054054054055
2024-04-07 04:11:33,871 - train - INFO - current latency ratio:tensor(0.9646)
2024-04-07 04:11:33,871 - train - INFO - lasso_alpha:3.7974983358324144e-05
2024-04-07 04:11:34,124 - train - INFO - Test: [   0/78]  Time: 0.249 (0.249)  Loss:  0.9736 (0.9736)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 04:11:38,583 - train - INFO - Test: [  50/78]  Time: 0.087 (0.092)  Loss:  1.7598 (1.7013)  Acc@1: 56.2500 (60.4167)  Acc@5: 82.8125 (82.6900)
2024-04-07 04:11:40,974 - train - INFO - Test: [  78/78]  Time: 0.053 (0.090)  Loss:  1.8389 (1.7252)  Acc@1: 50.0000 (59.8600)  Acc@5: 93.7500 (82.3300)
2024-04-07 04:11:42,067 - train - INFO - Train: 33 [   0/781 (  0%)]  Loss:  4.229280 (4.2293)  Time: 1.018s,  125.73/s  (1.018s,  125.73/s)  LR: 4.438e-04  Data: 0.185 (0.185)
2024-04-07 04:12:27,820 - train - INFO - Train: 33 [  50/781 (  6%)]  Loss:  4.558535 (3.9346)  Time: 0.811s,  157.80/s  (0.917s,  139.58/s)  LR: 4.438e-04  Data: 0.004 (0.011)
2024-04-07 04:13:14,884 - train - INFO - Train: 33 [ 100/781 ( 13%)]  Loss:  4.532964 (3.8621)  Time: 0.843s,  151.90/s  (0.929s,  137.78/s)  LR: 4.438e-04  Data: 0.008 (0.010)
2024-04-07 04:14:01,069 - train - INFO - Train: 33 [ 150/781 ( 19%)]  Loss:  4.110772 (3.8835)  Time: 0.865s,  148.06/s  (0.927s,  138.04/s)  LR: 4.438e-04  Data: 0.009 (0.009)
2024-04-07 04:14:46,250 - train - INFO - Train: 33 [ 200/781 ( 26%)]  Loss:  4.215117 (3.8710)  Time: 0.849s,  150.84/s  (0.921s,  138.92/s)  LR: 4.438e-04  Data: 0.009 (0.009)
2024-04-07 04:15:30,973 - train - INFO - Train: 33 [ 250/781 ( 32%)]  Loss:  4.044326 (3.8692)  Time: 0.837s,  152.86/s  (0.916s,  139.74/s)  LR: 4.438e-04  Data: 0.007 (0.009)
2024-04-07 04:16:16,027 - train - INFO - Train: 33 [ 300/781 ( 38%)]  Loss:  3.531237 (3.8651)  Time: 1.110s,  115.36/s  (0.914s,  140.12/s)  LR: 4.438e-04  Data: 0.006 (0.009)
2024-04-07 04:17:00,572 - train - INFO - Train: 33 [ 350/781 ( 45%)]  Loss:  3.745785 (3.8672)  Time: 0.846s,  151.37/s  (0.910s,  140.61/s)  LR: 4.438e-04  Data: 0.008 (0.008)
2024-04-07 04:17:45,076 - train - INFO - Train: 33 [ 400/781 ( 51%)]  Loss:  4.383780 (3.8693)  Time: 0.827s,  154.71/s  (0.908s,  141.01/s)  LR: 4.438e-04  Data: 0.006 (0.008)
2024-04-07 04:18:28,748 - train - INFO - Train: 33 [ 450/781 ( 58%)]  Loss:  4.254280 (3.8714)  Time: 0.859s,  148.96/s  (0.904s,  141.60/s)  LR: 4.438e-04  Data: 0.008 (0.008)
2024-04-07 04:19:13,251 - train - INFO - Train: 33 [ 500/781 ( 64%)]  Loss:  3.573880 (3.8804)  Time: 0.861s,  148.59/s  (0.903s,  141.82/s)  LR: 4.438e-04  Data: 0.008 (0.008)
2024-04-07 04:19:58,765 - train - INFO - Train: 33 [ 550/781 ( 71%)]  Loss:  4.176425 (3.8777)  Time: 0.851s,  150.35/s  (0.903s,  141.71/s)  LR: 4.438e-04  Data: 0.009 (0.008)
2024-04-07 04:20:42,978 - train - INFO - Train: 33 [ 600/781 ( 77%)]  Loss:  3.411914 (3.8828)  Time: 0.847s,  151.05/s  (0.902s,  141.96/s)  LR: 4.438e-04  Data: 0.009 (0.008)
2024-04-07 04:21:28,085 - train - INFO - Train: 33 [ 650/781 ( 83%)]  Loss:  3.434016 (3.8903)  Time: 0.797s,  160.58/s  (0.902s,  141.95/s)  LR: 4.438e-04  Data: 0.004 (0.008)
2024-04-07 04:22:12,573 - train - INFO - Train: 33 [ 700/781 ( 90%)]  Loss:  3.896626 (3.8933)  Time: 1.121s,  114.15/s  (0.901s,  142.09/s)  LR: 4.438e-04  Data: 0.008 (0.008)
2024-04-07 04:22:56,806 - train - INFO - Train: 33 [ 750/781 ( 96%)]  Loss:  4.537598 (3.8998)  Time: 0.838s,  152.72/s  (0.900s,  142.26/s)  LR: 4.438e-04  Data: 0.008 (0.008)
2024-04-07 04:23:24,492 - train - INFO - Train: 33 [ 780/781 (100%)]  Loss:  4.022408 (3.9011)  Time: 0.828s,  154.50/s  (0.901s,  142.12/s)  LR: 4.438e-04  Data: 0.000 (0.008)
2024-04-07 04:23:24,493 - train - INFO - True
2024-04-07 04:23:24,495 - train - INFO - alphas:tensor([0.2361, 0.1272, 0.1619, 0.2230, 0.2518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,519 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,519 - train - INFO - True
2024-04-07 04:23:24,521 - train - INFO - alphas:tensor([0.3256, 0.0803, 0.1002, 0.1786, 0.3153], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,559 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,559 - train - INFO - True
2024-04-07 04:23:24,560 - train - INFO - alphas:tensor([0.7402, 0.0767, 0.0525, 0.0618, 0.0687], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,592 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,592 - train - INFO - True
2024-04-07 04:23:24,593 - train - INFO - alphas:tensor([0.6881, 0.0623, 0.0581, 0.0846, 0.1069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,621 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,621 - train - INFO - True
2024-04-07 04:23:24,622 - train - INFO - alphas:tensor([0.5046, 0.0670, 0.0912, 0.1399, 0.1973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,646 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,646 - train - INFO - True
2024-04-07 04:23:24,647 - train - INFO - alphas:tensor([0.6475, 0.0667, 0.0643, 0.0944, 0.1272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,670 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,670 - train - INFO - True
2024-04-07 04:23:24,671 - train - INFO - alphas:tensor([0.7676, 0.0594, 0.0410, 0.0576, 0.0744], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,692 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,692 - train - INFO - True
2024-04-07 04:23:24,693 - train - INFO - alphas:tensor([0.6918, 0.0667, 0.0512, 0.0811, 0.1092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,712 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,713 - train - INFO - True
2024-04-07 04:23:24,713 - train - INFO - alphas:tensor([0.5575, 0.0589, 0.0758, 0.1240, 0.1838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,732 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,732 - train - INFO - True
2024-04-07 04:23:24,733 - train - INFO - alphas:tensor([0.6789, 0.0598, 0.0598, 0.0835, 0.1179], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,750 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,750 - train - INFO - True
2024-04-07 04:23:24,751 - train - INFO - alphas:tensor([0.7119, 0.0550, 0.0492, 0.0759, 0.1080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,768 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,768 - train - INFO - True
2024-04-07 04:23:24,768 - train - INFO - alphas:tensor([0.6182, 0.0546, 0.0607, 0.1098, 0.1567], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,785 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,785 - train - INFO - True
2024-04-07 04:23:24,786 - train - INFO - alphas:tensor([0.5760, 0.0521, 0.0676, 0.1203, 0.1839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,802 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,802 - train - INFO - True
2024-04-07 04:23:24,803 - train - INFO - alphas:tensor([0.6703, 0.0497, 0.0589, 0.0887, 0.1323], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,824 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,824 - train - INFO - True
2024-04-07 04:23:24,825 - train - INFO - alphas:tensor([0.6599, 0.0637, 0.0541, 0.0881, 0.1343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,844 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,844 - train - INFO - True
2024-04-07 04:23:24,845 - train - INFO - alphas:tensor([0.5260, 0.0466, 0.0595, 0.1280, 0.2398], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,863 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,863 - train - INFO - True
2024-04-07 04:23:24,864 - train - INFO - alphas:tensor([0.5654, 0.0511, 0.0658, 0.1228, 0.1949], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,881 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,881 - train - INFO - True
2024-04-07 04:23:24,882 - train - INFO - alphas:tensor([0.6740, 0.0461, 0.0581, 0.0899, 0.1319], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,899 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,899 - train - INFO - True
2024-04-07 04:23:24,900 - train - INFO - alphas:tensor([0.6727, 0.0539, 0.0515, 0.0875, 0.1343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,916 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,916 - train - INFO - True
2024-04-07 04:23:24,917 - train - INFO - alphas:tensor([0.5136, 0.0410, 0.0547, 0.1312, 0.2596], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,934 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,934 - train - INFO - True
2024-04-07 04:23:24,934 - train - INFO - alphas:tensor([0.5207, 0.0465, 0.0736, 0.1379, 0.2214], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,953 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,953 - train - INFO - True
2024-04-07 04:23:24,954 - train - INFO - alphas:tensor([0.6900, 0.0448, 0.0548, 0.0836, 0.1268], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,975 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,975 - train - INFO - True
2024-04-07 04:23:24,975 - train - INFO - alphas:tensor([0.6930, 0.0580, 0.0468, 0.0791, 0.1230], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:24,995 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:24,995 - train - INFO - True
2024-04-07 04:23:24,996 - train - INFO - alphas:tensor([0.5269, 0.0366, 0.0503, 0.1258, 0.2604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:25,015 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:25,015 - train - INFO - True
2024-04-07 04:23:25,015 - train - INFO - alphas:tensor([0.5108, 0.0433, 0.0717, 0.1418, 0.2323], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:25,033 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:25,033 - train - INFO - True
2024-04-07 04:23:25,034 - train - INFO - alphas:tensor([0.6764, 0.0435, 0.0551, 0.0842, 0.1408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:25,051 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:25,051 - train - INFO - True
2024-04-07 04:23:25,051 - train - INFO - alphas:tensor([0.6995, 0.0443, 0.0448, 0.0797, 0.1316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:25,070 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:25,070 - train - INFO - True
2024-04-07 04:23:25,071 - train - INFO - alphas:tensor([0.5530, 0.0385, 0.0472, 0.1183, 0.2430], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:25,091 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:25,091 - train - INFO - True
2024-04-07 04:23:25,092 - train - INFO - alphas:tensor([0.4866, 0.0377, 0.0745, 0.1487, 0.2525], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:25,111 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:25,111 - train - INFO - True
2024-04-07 04:23:25,112 - train - INFO - alphas:tensor([0.6488, 0.0406, 0.0565, 0.0949, 0.1592], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:25,130 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:25,130 - train - INFO - True
2024-04-07 04:23:25,131 - train - INFO - alphas:tensor([0.6975, 0.0407, 0.0433, 0.0802, 0.1384], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:25,148 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:25,148 - train - INFO - True
2024-04-07 04:23:25,149 - train - INFO - alphas:tensor([0.5998, 0.0368, 0.0491, 0.1124, 0.2020], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:25,166 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:25,166 - train - INFO - True
2024-04-07 04:23:25,166 - train - INFO - alphas:tensor([0.4603, 0.0349, 0.0753, 0.1535, 0.2759], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:25,183 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:25,183 - train - INFO - True
2024-04-07 04:23:25,184 - train - INFO - alphas:tensor([0.5996, 0.0398, 0.0596, 0.1074, 0.1935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:25,205 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:25,205 - train - INFO - True
2024-04-07 04:23:25,206 - train - INFO - alphas:tensor([0.6737, 0.0449, 0.0445, 0.0893, 0.1477], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:25,226 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:25,227 - train - INFO - True
2024-04-07 04:23:25,227 - train - INFO - alphas:tensor([0.6052, 0.0382, 0.0513, 0.1120, 0.1933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:25,247 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:25,247 - train - INFO - True
2024-04-07 04:23:25,247 - train - INFO - alphas:tensor([0.6920, 0.0614, 0.1052, 0.1414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:23:25,266 - train - INFO - tau:0.7323033696543974
2024-04-07 04:23:25,266 - train - INFO - avg block size:1.4054054054054055
2024-04-07 04:23:25,266 - train - INFO - current latency ratio:tensor(0.9646)
2024-04-07 04:23:25,524 - train - INFO - Test: [   0/78]  Time: 0.255 (0.255)  Loss:  1.0068 (1.0068)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.9688 (92.9688)
2024-04-07 04:23:30,170 - train - INFO - Test: [  50/78]  Time: 0.088 (0.096)  Loss:  1.8398 (1.7302)  Acc@1: 55.4688 (59.6967)  Acc@5: 84.3750 (82.6746)
2024-04-07 04:23:32,527 - train - INFO - Test: [  78/78]  Time: 0.053 (0.092)  Loss:  2.0859 (1.7512)  Acc@1: 43.7500 (59.3000)  Acc@5: 87.5000 (82.3200)
2024-04-07 04:23:33,820 - train - INFO - Train: 34 [   0/781 (  0%)]  Loss:  4.448409 (4.4484)  Time: 1.232s,  103.88/s  (1.232s,  103.88/s)  LR: 4.405e-04  Data: 0.186 (0.186)
2024-04-07 04:24:18,445 - train - INFO - Train: 34 [  50/781 (  6%)]  Loss:  3.633227 (3.9254)  Time: 0.804s,  159.25/s  (0.899s,  142.36/s)  LR: 4.405e-04  Data: 0.006 (0.011)
2024-04-07 04:25:03,807 - train - INFO - Train: 34 [ 100/781 ( 13%)]  Loss:  4.258934 (3.9497)  Time: 0.852s,  150.19/s  (0.903s,  141.73/s)  LR: 4.405e-04  Data: 0.009 (0.010)
2024-04-07 04:25:46,996 - train - INFO - Train: 34 [ 150/781 ( 19%)]  Loss:  3.924899 (3.9299)  Time: 0.802s,  159.55/s  (0.890s,  143.81/s)  LR: 4.405e-04  Data: 0.007 (0.009)
2024-04-07 04:26:31,428 - train - INFO - Train: 34 [ 200/781 ( 26%)]  Loss:  3.676959 (3.9222)  Time: 0.860s,  148.82/s  (0.890s,  143.87/s)  LR: 4.405e-04  Data: 0.009 (0.009)
2024-04-07 04:27:19,533 - train - INFO - Train: 34 [ 250/781 ( 32%)]  Loss:  3.875242 (3.9223)  Time: 0.866s,  147.89/s  (0.904s,  141.57/s)  LR: 4.405e-04  Data: 0.007 (0.008)
2024-04-07 04:28:05,339 - train - INFO - Train: 34 [ 300/781 ( 38%)]  Loss:  3.320996 (3.9278)  Time: 1.098s,  116.57/s  (0.906s,  141.26/s)  LR: 4.405e-04  Data: 0.013 (0.008)
2024-04-07 04:28:48,505 - train - INFO - Train: 34 [ 350/781 ( 45%)]  Loss:  4.177035 (3.9276)  Time: 1.105s,  115.86/s  (0.900s,  142.22/s)  LR: 4.405e-04  Data: 0.012 (0.008)
2024-04-07 04:29:33,693 - train - INFO - Train: 34 [ 400/781 ( 51%)]  Loss:  3.294875 (3.9254)  Time: 0.834s,  153.55/s  (0.900s,  142.15/s)  LR: 4.405e-04  Data: 0.007 (0.008)
2024-04-07 04:30:20,880 - train - INFO - Train: 34 [ 450/781 ( 58%)]  Loss:  4.055670 (3.9286)  Time: 1.087s,  117.72/s  (0.905s,  141.39/s)  LR: 4.405e-04  Data: 0.008 (0.008)
2024-04-07 04:31:07,258 - train - INFO - Train: 34 [ 500/781 ( 64%)]  Loss:  3.357905 (3.9171)  Time: 0.838s,  152.71/s  (0.907s,  141.05/s)  LR: 4.405e-04  Data: 0.007 (0.008)
2024-04-07 04:31:52,782 - train - INFO - Train: 34 [ 550/781 ( 71%)]  Loss:  4.535035 (3.9174)  Time: 0.835s,  153.29/s  (0.908s,  141.01/s)  LR: 4.405e-04  Data: 0.007 (0.008)
2024-04-07 04:32:37,330 - train - INFO - Train: 34 [ 600/781 ( 77%)]  Loss:  4.283507 (3.9229)  Time: 0.846s,  151.28/s  (0.906s,  141.22/s)  LR: 4.405e-04  Data: 0.009 (0.008)
2024-04-07 04:33:22,988 - train - INFO - Train: 34 [ 650/781 ( 83%)]  Loss:  3.521438 (3.9218)  Time: 1.092s,  117.25/s  (0.907s,  141.14/s)  LR: 4.405e-04  Data: 0.008 (0.008)
2024-04-07 04:34:07,194 - train - INFO - Train: 34 [ 700/781 ( 90%)]  Loss:  3.230527 (3.9239)  Time: 0.857s,  149.43/s  (0.905s,  141.40/s)  LR: 4.405e-04  Data: 0.008 (0.008)
2024-04-07 04:34:51,262 - train - INFO - Train: 34 [ 750/781 ( 96%)]  Loss:  4.362111 (3.9233)  Time: 0.822s,  155.79/s  (0.904s,  141.65/s)  LR: 4.405e-04  Data: 0.006 (0.008)
2024-04-07 04:35:18,372 - train - INFO - Train: 34 [ 780/781 (100%)]  Loss:  4.421785 (3.9276)  Time: 1.006s,  127.18/s  (0.904s,  141.65/s)  LR: 4.405e-04  Data: 0.000 (0.008)
2024-04-07 04:35:18,373 - train - INFO - True
2024-04-07 04:35:18,375 - train - INFO - alphas:tensor([0.2286, 0.1243, 0.1622, 0.2273, 0.2576], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,399 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,399 - train - INFO - True
2024-04-07 04:35:18,400 - train - INFO - alphas:tensor([0.3189, 0.0776, 0.0988, 0.1792, 0.3255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,421 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,421 - train - INFO - True
2024-04-07 04:35:18,423 - train - INFO - alphas:tensor([0.7389, 0.0766, 0.0525, 0.0623, 0.0696], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,457 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,457 - train - INFO - True
2024-04-07 04:35:18,458 - train - INFO - alphas:tensor([0.6842, 0.0613, 0.0584, 0.0861, 0.1099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,488 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,488 - train - INFO - True
2024-04-07 04:35:18,489 - train - INFO - alphas:tensor([0.4982, 0.0651, 0.0914, 0.1421, 0.2032], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,514 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,515 - train - INFO - True
2024-04-07 04:35:18,515 - train - INFO - alphas:tensor([0.6439, 0.0650, 0.0643, 0.0957, 0.1312], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,539 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,539 - train - INFO - True
2024-04-07 04:35:18,540 - train - INFO - alphas:tensor([0.7648, 0.0593, 0.0409, 0.0587, 0.0763], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,562 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,562 - train - INFO - True
2024-04-07 04:35:18,563 - train - INFO - alphas:tensor([0.6830, 0.0659, 0.0518, 0.0837, 0.1156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,583 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,583 - train - INFO - True
2024-04-07 04:35:18,584 - train - INFO - alphas:tensor([0.5515, 0.0577, 0.0759, 0.1256, 0.1894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,603 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,603 - train - INFO - True
2024-04-07 04:35:18,603 - train - INFO - alphas:tensor([0.6739, 0.0591, 0.0601, 0.0850, 0.1220], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,621 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,622 - train - INFO - True
2024-04-07 04:35:18,622 - train - INFO - alphas:tensor([0.7072, 0.0540, 0.0492, 0.0775, 0.1122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,639 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,640 - train - INFO - True
2024-04-07 04:35:18,640 - train - INFO - alphas:tensor([0.6109, 0.0528, 0.0600, 0.1121, 0.1643], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,657 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,657 - train - INFO - True
2024-04-07 04:35:18,657 - train - INFO - alphas:tensor([0.5694, 0.0505, 0.0674, 0.1226, 0.1901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,674 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,674 - train - INFO - True
2024-04-07 04:35:18,674 - train - INFO - alphas:tensor([0.6664, 0.0482, 0.0586, 0.0899, 0.1370], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,691 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,691 - train - INFO - True
2024-04-07 04:35:18,691 - train - INFO - alphas:tensor([0.6535, 0.0621, 0.0538, 0.0902, 0.1405], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,708 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,708 - train - INFO - True
2024-04-07 04:35:18,708 - train - INFO - alphas:tensor([0.5210, 0.0444, 0.0575, 0.1283, 0.2487], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,725 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,725 - train - INFO - True
2024-04-07 04:35:18,726 - train - INFO - alphas:tensor([0.5607, 0.0490, 0.0648, 0.1245, 0.2010], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,742 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,742 - train - INFO - True
2024-04-07 04:35:18,743 - train - INFO - alphas:tensor([0.6672, 0.0452, 0.0582, 0.0914, 0.1380], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,759 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,759 - train - INFO - True
2024-04-07 04:35:18,760 - train - INFO - alphas:tensor([0.6647, 0.0526, 0.0511, 0.0901, 0.1414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,776 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,776 - train - INFO - True
2024-04-07 04:35:18,777 - train - INFO - alphas:tensor([0.5053, 0.0392, 0.0526, 0.1315, 0.2714], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,793 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,793 - train - INFO - True
2024-04-07 04:35:18,794 - train - INFO - alphas:tensor([0.5173, 0.0445, 0.0722, 0.1387, 0.2274], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,810 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,810 - train - INFO - True
2024-04-07 04:35:18,811 - train - INFO - alphas:tensor([0.6859, 0.0428, 0.0546, 0.0846, 0.1321], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,828 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,828 - train - INFO - True
2024-04-07 04:35:18,828 - train - INFO - alphas:tensor([0.6889, 0.0561, 0.0463, 0.0804, 0.1282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,845 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,845 - train - INFO - True
2024-04-07 04:35:18,845 - train - INFO - alphas:tensor([0.5205, 0.0345, 0.0482, 0.1260, 0.2708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,862 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,862 - train - INFO - True
2024-04-07 04:35:18,862 - train - INFO - alphas:tensor([0.5044, 0.0414, 0.0707, 0.1431, 0.2404], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,879 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,879 - train - INFO - True
2024-04-07 04:35:18,879 - train - INFO - alphas:tensor([0.6699, 0.0418, 0.0549, 0.0856, 0.1477], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,896 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,896 - train - INFO - True
2024-04-07 04:35:18,897 - train - INFO - alphas:tensor([0.6925, 0.0428, 0.0445, 0.0818, 0.1384], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,913 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,913 - train - INFO - True
2024-04-07 04:35:18,914 - train - INFO - alphas:tensor([0.5428, 0.0363, 0.0456, 0.1197, 0.2555], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,930 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,930 - train - INFO - True
2024-04-07 04:35:18,931 - train - INFO - alphas:tensor([0.4788, 0.0361, 0.0733, 0.1502, 0.2616], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,947 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,947 - train - INFO - True
2024-04-07 04:35:18,948 - train - INFO - alphas:tensor([0.6376, 0.0391, 0.0569, 0.0976, 0.1689], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,964 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,964 - train - INFO - True
2024-04-07 04:35:18,965 - train - INFO - alphas:tensor([0.6940, 0.0396, 0.0429, 0.0810, 0.1425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,981 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,981 - train - INFO - True
2024-04-07 04:35:18,982 - train - INFO - alphas:tensor([0.5947, 0.0345, 0.0473, 0.1131, 0.2103], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:18,998 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:18,998 - train - INFO - True
2024-04-07 04:35:18,999 - train - INFO - alphas:tensor([0.4560, 0.0335, 0.0736, 0.1537, 0.2832], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:19,016 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:19,016 - train - INFO - True
2024-04-07 04:35:19,016 - train - INFO - alphas:tensor([0.5934, 0.0378, 0.0583, 0.1087, 0.2018], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:19,033 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:19,033 - train - INFO - True
2024-04-07 04:35:19,033 - train - INFO - alphas:tensor([0.6718, 0.0436, 0.0430, 0.0896, 0.1519], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:19,050 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:19,050 - train - INFO - True
2024-04-07 04:35:19,050 - train - INFO - alphas:tensor([0.6021, 0.0364, 0.0498, 0.1122, 0.1996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:19,066 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:19,066 - train - INFO - True
2024-04-07 04:35:19,067 - train - INFO - alphas:tensor([0.6936, 0.0604, 0.1044, 0.1416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:35:19,083 - train - INFO - tau:0.7249803359578534
2024-04-07 04:35:19,083 - train - INFO - avg block size:1.8108108108108107
2024-04-07 04:35:19,083 - train - INFO - current latency ratio:tensor(0.9504)
2024-04-07 04:35:19,083 - train - INFO - lasso_alpha:4.177248169415656e-05
2024-04-07 04:35:19,336 - train - INFO - Test: [   0/78]  Time: 0.250 (0.250)  Loss:  1.0791 (1.0791)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
2024-04-07 04:35:24,031 - train - INFO - Test: [  50/78]  Time: 0.084 (0.097)  Loss:  1.8359 (1.7212)  Acc@1: 58.5938 (60.0184)  Acc@5: 82.8125 (82.7972)
2024-04-07 04:35:26,413 - train - INFO - Test: [  78/78]  Time: 0.053 (0.093)  Loss:  1.9990 (1.7404)  Acc@1: 50.0000 (59.6400)  Acc@5: 81.2500 (82.4700)
2024-04-07 04:35:27,742 - train - INFO - Train: 35 [   0/781 (  0%)]  Loss:  3.695039 (3.6950)  Time: 1.255s,  102.01/s  (1.255s,  102.01/s)  LR: 4.371e-04  Data: 0.185 (0.185)
2024-04-07 04:36:12,379 - train - INFO - Train: 35 [  50/781 (  6%)]  Loss:  4.492076 (3.9272)  Time: 0.807s,  158.68/s  (0.900s,  142.25/s)  LR: 4.371e-04  Data: 0.005 (0.011)
2024-04-07 04:36:56,503 - train - INFO - Train: 35 [ 100/781 ( 13%)]  Loss:  4.033062 (3.8958)  Time: 0.863s,  148.30/s  (0.891s,  143.62/s)  LR: 4.371e-04  Data: 0.009 (0.009)
2024-04-07 04:37:41,387 - train - INFO - Train: 35 [ 150/781 ( 19%)]  Loss:  4.115320 (3.9053)  Time: 0.867s,  147.68/s  (0.893s,  143.28/s)  LR: 4.371e-04  Data: 0.008 (0.009)
2024-04-07 04:38:26,918 - train - INFO - Train: 35 [ 200/781 ( 26%)]  Loss:  3.888909 (3.9036)  Time: 0.844s,  151.58/s  (0.898s,  142.60/s)  LR: 4.371e-04  Data: 0.009 (0.009)
2024-04-07 04:39:12,575 - train - INFO - Train: 35 [ 250/781 ( 32%)]  Loss:  4.419875 (3.9181)  Time: 0.835s,  153.33/s  (0.901s,  142.11/s)  LR: 4.371e-04  Data: 0.007 (0.009)
2024-04-07 04:39:58,324 - train - INFO - Train: 35 [ 300/781 ( 38%)]  Loss:  4.531068 (3.9319)  Time: 1.046s,  122.34/s  (0.903s,  141.74/s)  LR: 4.371e-04  Data: 0.005 (0.008)
2024-04-07 04:40:44,276 - train - INFO - Train: 35 [ 350/781 ( 45%)]  Loss:  3.245174 (3.9346)  Time: 0.865s,  147.92/s  (0.905s,  141.38/s)  LR: 4.371e-04  Data: 0.008 (0.008)
2024-04-07 04:41:28,568 - train - INFO - Train: 35 [ 400/781 ( 51%)]  Loss:  3.823027 (3.9320)  Time: 0.817s,  156.70/s  (0.903s,  141.76/s)  LR: 4.371e-04  Data: 0.006 (0.008)
2024-04-07 04:42:13,938 - train - INFO - Train: 35 [ 450/781 ( 58%)]  Loss:  4.551754 (3.9357)  Time: 1.065s,  120.19/s  (0.903s,  141.69/s)  LR: 4.371e-04  Data: 0.009 (0.008)
2024-04-07 04:43:01,013 - train - INFO - Train: 35 [ 500/781 ( 64%)]  Loss:  3.804284 (3.9382)  Time: 0.867s,  147.62/s  (0.907s,  141.09/s)  LR: 4.371e-04  Data: 0.008 (0.008)
2024-04-07 04:43:44,985 - train - INFO - Train: 35 [ 550/781 ( 71%)]  Loss:  3.780831 (3.9318)  Time: 0.837s,  152.86/s  (0.905s,  141.49/s)  LR: 4.371e-04  Data: 0.007 (0.008)
2024-04-07 04:44:30,756 - train - INFO - Train: 35 [ 600/781 ( 77%)]  Loss:  4.283188 (3.9320)  Time: 1.016s,  126.02/s  (0.906s,  141.35/s)  LR: 4.371e-04  Data: 0.005 (0.008)
2024-04-07 04:45:16,754 - train - INFO - Train: 35 [ 650/781 ( 83%)]  Loss:  4.545354 (3.9302)  Time: 0.844s,  151.72/s  (0.907s,  141.18/s)  LR: 4.371e-04  Data: 0.008 (0.008)
2024-04-07 04:46:02,130 - train - INFO - Train: 35 [ 700/781 ( 90%)]  Loss:  4.106403 (3.9240)  Time: 1.112s,  115.09/s  (0.907s,  141.17/s)  LR: 4.371e-04  Data: 0.008 (0.008)
2024-04-07 04:46:47,434 - train - INFO - Train: 35 [ 750/781 ( 96%)]  Loss:  4.055158 (3.9254)  Time: 1.090s,  117.45/s  (0.907s,  141.17/s)  LR: 4.371e-04  Data: 0.009 (0.008)
2024-04-07 04:47:14,510 - train - INFO - Train: 35 [ 780/781 (100%)]  Loss:  3.370574 (3.9210)  Time: 0.849s,  150.70/s  (0.907s,  141.20/s)  LR: 4.371e-04  Data: 0.000 (0.008)
2024-04-07 04:47:14,511 - train - INFO - True
2024-04-07 04:47:14,512 - train - INFO - alphas:tensor([0.2214, 0.1206, 0.1627, 0.2316, 0.2637], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,533 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,534 - train - INFO - True
2024-04-07 04:47:14,535 - train - INFO - alphas:tensor([0.3128, 0.0755, 0.0980, 0.1800, 0.3337], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,553 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,554 - train - INFO - True
2024-04-07 04:47:14,555 - train - INFO - alphas:tensor([0.7361, 0.0769, 0.0529, 0.0633, 0.0708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,586 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,587 - train - INFO - True
2024-04-07 04:47:14,588 - train - INFO - alphas:tensor([0.6764, 0.0616, 0.0593, 0.0884, 0.1143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,615 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,615 - train - INFO - True
2024-04-07 04:47:14,616 - train - INFO - alphas:tensor([0.4925, 0.0629, 0.0911, 0.1442, 0.2093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,641 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,641 - train - INFO - True
2024-04-07 04:47:14,642 - train - INFO - alphas:tensor([0.6352, 0.0638, 0.0649, 0.0988, 0.1373], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,665 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,665 - train - INFO - True
2024-04-07 04:47:14,665 - train - INFO - alphas:tensor([0.7596, 0.0597, 0.0413, 0.0601, 0.0793], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,686 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,686 - train - INFO - True
2024-04-07 04:47:14,687 - train - INFO - alphas:tensor([0.6680, 0.0660, 0.0527, 0.0886, 0.1248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,707 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,707 - train - INFO - True
2024-04-07 04:47:14,708 - train - INFO - alphas:tensor([0.5471, 0.0558, 0.0755, 0.1271, 0.1945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,726 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,726 - train - INFO - True
2024-04-07 04:47:14,727 - train - INFO - alphas:tensor([0.6715, 0.0573, 0.0597, 0.0859, 0.1257], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,744 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,744 - train - INFO - True
2024-04-07 04:47:14,745 - train - INFO - alphas:tensor([0.6999, 0.0533, 0.0495, 0.0798, 0.1175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,766 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,766 - train - INFO - True
2024-04-07 04:47:14,766 - train - INFO - alphas:tensor([0.6003, 0.0512, 0.0597, 0.1153, 0.1735], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,787 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,787 - train - INFO - True
2024-04-07 04:47:14,788 - train - INFO - alphas:tensor([0.5646, 0.0494, 0.0670, 0.1237, 0.1952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,807 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,807 - train - INFO - True
2024-04-07 04:47:14,808 - train - INFO - alphas:tensor([0.6614, 0.0465, 0.0582, 0.0916, 0.1422], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,826 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,826 - train - INFO - True
2024-04-07 04:47:14,827 - train - INFO - alphas:tensor([0.6452, 0.0611, 0.0535, 0.0926, 0.1476], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,844 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,844 - train - INFO - True
2024-04-07 04:47:14,845 - train - INFO - alphas:tensor([0.5119, 0.0425, 0.0555, 0.1303, 0.2598], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,862 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,862 - train - INFO - True
2024-04-07 04:47:14,862 - train - INFO - alphas:tensor([0.5547, 0.0475, 0.0640, 0.1257, 0.2081], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,884 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,884 - train - INFO - True
2024-04-07 04:47:14,885 - train - INFO - alphas:tensor([0.6600, 0.0438, 0.0577, 0.0933, 0.1452], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,905 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,905 - train - INFO - True
2024-04-07 04:47:14,905 - train - INFO - alphas:tensor([0.6535, 0.0522, 0.0514, 0.0932, 0.1497], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,925 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,925 - train - INFO - True
2024-04-07 04:47:14,926 - train - INFO - alphas:tensor([0.4973, 0.0372, 0.0506, 0.1322, 0.2828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,943 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,943 - train - INFO - True
2024-04-07 04:47:14,944 - train - INFO - alphas:tensor([0.5076, 0.0431, 0.0715, 0.1412, 0.2366], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,961 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,961 - train - INFO - True
2024-04-07 04:47:14,962 - train - INFO - alphas:tensor([0.6754, 0.0413, 0.0548, 0.0875, 0.1409], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:14,980 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:14,980 - train - INFO - True
2024-04-07 04:47:14,981 - train - INFO - alphas:tensor([0.6802, 0.0553, 0.0461, 0.0830, 0.1354], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,002 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,002 - train - INFO - True
2024-04-07 04:47:15,002 - train - INFO - alphas:tensor([0.5123, 0.0329, 0.0464, 0.1258, 0.2825], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,021 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,021 - train - INFO - True
2024-04-07 04:47:15,022 - train - INFO - alphas:tensor([0.4990, 0.0395, 0.0694, 0.1440, 0.2480], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,040 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,040 - train - INFO - True
2024-04-07 04:47:15,041 - train - INFO - alphas:tensor([0.6625, 0.0398, 0.0544, 0.0874, 0.1559], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,058 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,058 - train - INFO - True
2024-04-07 04:47:15,059 - train - INFO - alphas:tensor([0.6839, 0.0417, 0.0445, 0.0842, 0.1457], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,076 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,076 - train - INFO - True
2024-04-07 04:47:15,076 - train - INFO - alphas:tensor([0.5362, 0.0344, 0.0435, 0.1198, 0.2661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,093 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,093 - train - INFO - True
2024-04-07 04:47:15,094 - train - INFO - alphas:tensor([0.4707, 0.0343, 0.0724, 0.1517, 0.2709], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,110 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,110 - train - INFO - True
2024-04-07 04:47:15,111 - train - INFO - alphas:tensor([0.6307, 0.0369, 0.0564, 0.0993, 0.1768], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,128 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,129 - train - INFO - True
2024-04-07 04:47:15,129 - train - INFO - alphas:tensor([0.6895, 0.0385, 0.0419, 0.0818, 0.1483], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,150 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,150 - train - INFO - True
2024-04-07 04:47:15,151 - train - INFO - alphas:tensor([0.5900, 0.0322, 0.0451, 0.1134, 0.2193], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,170 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,170 - train - INFO - True
2024-04-07 04:47:15,171 - train - INFO - alphas:tensor([0.4470, 0.0318, 0.0721, 0.1550, 0.2941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,189 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,189 - train - INFO - True
2024-04-07 04:47:15,189 - train - INFO - alphas:tensor([0.5837, 0.0355, 0.0578, 0.1107, 0.2123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,207 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,207 - train - INFO - True
2024-04-07 04:47:15,207 - train - INFO - alphas:tensor([0.6681, 0.0419, 0.0422, 0.0905, 0.1573], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,224 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,224 - train - INFO - True
2024-04-07 04:47:15,224 - train - INFO - alphas:tensor([0.5952, 0.0345, 0.0483, 0.1140, 0.2079], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,241 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,241 - train - INFO - True
2024-04-07 04:47:15,241 - train - INFO - alphas:tensor([0.6964, 0.0591, 0.1033, 0.1412], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:47:15,258 - train - INFO - tau:0.7177305325982748
2024-04-07 04:47:15,258 - train - INFO - avg block size:1.8108108108108107
2024-04-07 04:47:15,258 - train - INFO - current latency ratio:tensor(0.9504)
2024-04-07 04:47:15,502 - train - INFO - Test: [   0/78]  Time: 0.241 (0.241)  Loss:  1.0479 (1.0479)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.9688 (92.9688)
2024-04-07 04:47:19,830 - train - INFO - Test: [  50/78]  Time: 0.089 (0.090)  Loss:  2.0078 (1.7189)  Acc@1: 51.5625 (59.6661)  Acc@5: 80.4688 (82.4295)
2024-04-07 04:47:22,207 - train - INFO - Test: [  78/78]  Time: 0.054 (0.088)  Loss:  1.8350 (1.7393)  Acc@1: 50.0000 (59.1100)  Acc@5: 81.2500 (82.0500)
2024-04-07 04:47:23,528 - train - INFO - Train: 36 [   0/781 (  0%)]  Loss:  3.350113 (3.3501)  Time: 1.259s,  101.64/s  (1.259s,  101.64/s)  LR: 4.336e-04  Data: 0.195 (0.195)
2024-04-07 04:48:11,164 - train - INFO - Train: 36 [  50/781 (  6%)]  Loss:  4.419652 (3.9098)  Time: 0.849s,  150.68/s  (0.959s,  133.51/s)  LR: 4.336e-04  Data: 0.008 (0.012)
2024-04-07 04:48:55,529 - train - INFO - Train: 36 [ 100/781 ( 13%)]  Loss:  4.548530 (3.9350)  Time: 0.853s,  150.15/s  (0.923s,  138.63/s)  LR: 4.336e-04  Data: 0.009 (0.010)
2024-04-07 04:49:40,165 - train - INFO - Train: 36 [ 150/781 ( 19%)]  Loss:  3.228124 (3.9378)  Time: 1.031s,  124.14/s  (0.913s,  140.17/s)  LR: 4.336e-04  Data: 0.019 (0.009)
2024-04-07 04:50:24,568 - train - INFO - Train: 36 [ 200/781 ( 26%)]  Loss:  4.398044 (3.9254)  Time: 0.856s,  149.60/s  (0.907s,  141.13/s)  LR: 4.336e-04  Data: 0.007 (0.009)
2024-04-07 04:51:11,077 - train - INFO - Train: 36 [ 250/781 ( 32%)]  Loss:  4.512909 (3.9148)  Time: 0.851s,  150.37/s  (0.912s,  140.42/s)  LR: 4.336e-04  Data: 0.008 (0.009)
2024-04-07 04:51:56,088 - train - INFO - Train: 36 [ 300/781 ( 38%)]  Loss:  4.318191 (3.9127)  Time: 1.016s,  126.03/s  (0.910s,  140.71/s)  LR: 4.336e-04  Data: 0.005 (0.009)
2024-04-07 04:52:40,350 - train - INFO - Train: 36 [ 350/781 ( 45%)]  Loss:  3.527151 (3.9173)  Time: 1.058s,  120.97/s  (0.906s,  141.25/s)  LR: 4.336e-04  Data: 0.008 (0.009)
2024-04-07 04:53:26,028 - train - INFO - Train: 36 [ 400/781 ( 51%)]  Loss:  3.844131 (3.9163)  Time: 0.867s,  147.57/s  (0.907s,  141.11/s)  LR: 4.336e-04  Data: 0.011 (0.009)
2024-04-07 04:54:13,217 - train - INFO - Train: 36 [ 450/781 ( 58%)]  Loss:  3.504851 (3.9186)  Time: 0.832s,  153.89/s  (0.911s,  140.48/s)  LR: 4.336e-04  Data: 0.007 (0.009)
2024-04-07 04:54:58,036 - train - INFO - Train: 36 [ 500/781 ( 64%)]  Loss:  4.049566 (3.9141)  Time: 0.839s,  152.58/s  (0.910s,  140.71/s)  LR: 4.336e-04  Data: 0.008 (0.009)
2024-04-07 04:55:43,782 - train - INFO - Train: 36 [ 550/781 ( 71%)]  Loss:  4.517440 (3.9114)  Time: 1.085s,  117.98/s  (0.910s,  140.64/s)  LR: 4.336e-04  Data: 0.008 (0.008)
2024-04-07 04:56:30,318 - train - INFO - Train: 36 [ 600/781 ( 77%)]  Loss:  4.245532 (3.9114)  Time: 1.024s,  125.04/s  (0.912s,  140.37/s)  LR: 4.336e-04  Data: 0.006 (0.008)
2024-04-07 04:57:16,196 - train - INFO - Train: 36 [ 650/781 ( 83%)]  Loss:  3.328799 (3.9104)  Time: 1.006s,  127.28/s  (0.912s,  140.30/s)  LR: 4.336e-04  Data: 0.005 (0.008)
2024-04-07 04:58:02,078 - train - INFO - Train: 36 [ 700/781 ( 90%)]  Loss:  3.197096 (3.9110)  Time: 0.842s,  152.03/s  (0.913s,  140.25/s)  LR: 4.336e-04  Data: 0.008 (0.008)
2024-04-07 04:58:47,093 - train - INFO - Train: 36 [ 750/781 ( 96%)]  Loss:  3.563810 (3.9151)  Time: 0.845s,  151.39/s  (0.912s,  140.37/s)  LR: 4.336e-04  Data: 0.008 (0.008)
2024-04-07 04:59:13,842 - train - INFO - Train: 36 [ 780/781 (100%)]  Loss:  4.293406 (3.9145)  Time: 0.846s,  151.22/s  (0.911s,  140.49/s)  LR: 4.336e-04  Data: 0.000 (0.008)
2024-04-07 04:59:13,843 - train - INFO - True
2024-04-07 04:59:13,846 - train - INFO - alphas:tensor([0.2143, 0.1175, 0.1631, 0.2360, 0.2691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:13,869 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:13,870 - train - INFO - True
2024-04-07 04:59:13,871 - train - INFO - alphas:tensor([0.3068, 0.0743, 0.0967, 0.1797, 0.3425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:13,891 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:13,891 - train - INFO - True
2024-04-07 04:59:13,892 - train - INFO - alphas:tensor([0.7359, 0.0766, 0.0526, 0.0635, 0.0714], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:13,926 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:13,926 - train - INFO - True
2024-04-07 04:59:13,927 - train - INFO - alphas:tensor([0.6723, 0.0608, 0.0594, 0.0899, 0.1176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:13,956 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:13,956 - train - INFO - True
2024-04-07 04:59:13,957 - train - INFO - alphas:tensor([0.4872, 0.0617, 0.0907, 0.1456, 0.2150], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:13,983 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:13,983 - train - INFO - True
2024-04-07 04:59:13,984 - train - INFO - alphas:tensor([0.6273, 0.0630, 0.0653, 0.1012, 0.1432], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,007 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,007 - train - INFO - True
2024-04-07 04:59:14,008 - train - INFO - alphas:tensor([0.7567, 0.0594, 0.0413, 0.0612, 0.0814], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,030 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,030 - train - INFO - True
2024-04-07 04:59:14,031 - train - INFO - alphas:tensor([0.6601, 0.0644, 0.0526, 0.0914, 0.1315], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,051 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,051 - train - INFO - True
2024-04-07 04:59:14,051 - train - INFO - alphas:tensor([0.5454, 0.0537, 0.0746, 0.1276, 0.1987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,070 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,070 - train - INFO - True
2024-04-07 04:59:14,071 - train - INFO - alphas:tensor([0.6662, 0.0564, 0.0600, 0.0873, 0.1301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,089 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,089 - train - INFO - True
2024-04-07 04:59:14,090 - train - INFO - alphas:tensor([0.6941, 0.0523, 0.0497, 0.0816, 0.1223], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,111 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,111 - train - INFO - True
2024-04-07 04:59:14,112 - train - INFO - alphas:tensor([0.5919, 0.0491, 0.0590, 0.1179, 0.1821], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,132 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,132 - train - INFO - True
2024-04-07 04:59:14,133 - train - INFO - alphas:tensor([0.5593, 0.0481, 0.0663, 0.1251, 0.2012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,152 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,152 - train - INFO - True
2024-04-07 04:59:14,153 - train - INFO - alphas:tensor([0.6555, 0.0450, 0.0581, 0.0927, 0.1487], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,171 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,171 - train - INFO - True
2024-04-07 04:59:14,172 - train - INFO - alphas:tensor([0.6373, 0.0599, 0.0530, 0.0945, 0.1552], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,189 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,189 - train - INFO - True
2024-04-07 04:59:14,190 - train - INFO - alphas:tensor([0.5034, 0.0403, 0.0533, 0.1313, 0.2716], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,206 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,206 - train - INFO - True
2024-04-07 04:59:14,207 - train - INFO - alphas:tensor([0.5477, 0.0460, 0.0638, 0.1273, 0.2152], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,224 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,224 - train - INFO - True
2024-04-07 04:59:14,225 - train - INFO - alphas:tensor([0.6557, 0.0417, 0.0571, 0.0941, 0.1513], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,241 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,241 - train - INFO - True
2024-04-07 04:59:14,242 - train - INFO - alphas:tensor([0.6484, 0.0504, 0.0504, 0.0949, 0.1560], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,259 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,259 - train - INFO - True
2024-04-07 04:59:14,260 - train - INFO - alphas:tensor([0.4936, 0.0347, 0.0480, 0.1317, 0.2921], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,281 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,281 - train - INFO - True
2024-04-07 04:59:14,282 - train - INFO - alphas:tensor([0.5014, 0.0415, 0.0705, 0.1424, 0.2443], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,301 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,301 - train - INFO - True
2024-04-07 04:59:14,302 - train - INFO - alphas:tensor([0.6697, 0.0399, 0.0547, 0.0886, 0.1472], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,320 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,320 - train - INFO - True
2024-04-07 04:59:14,320 - train - INFO - alphas:tensor([0.6734, 0.0542, 0.0456, 0.0845, 0.1423], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,338 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,338 - train - INFO - True
2024-04-07 04:59:14,338 - train - INFO - alphas:tensor([0.5073, 0.0307, 0.0443, 0.1253, 0.2924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,355 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,355 - train - INFO - True
2024-04-07 04:59:14,355 - train - INFO - alphas:tensor([0.4950, 0.0375, 0.0678, 0.1445, 0.2553], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,371 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,371 - train - INFO - True
2024-04-07 04:59:14,372 - train - INFO - alphas:tensor([0.6554, 0.0384, 0.0539, 0.0886, 0.1636], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,388 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,388 - train - INFO - True
2024-04-07 04:59:14,389 - train - INFO - alphas:tensor([0.6777, 0.0405, 0.0437, 0.0855, 0.1525], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,406 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,406 - train - INFO - True
2024-04-07 04:59:14,407 - train - INFO - alphas:tensor([0.5295, 0.0331, 0.0417, 0.1195, 0.2762], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,428 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,428 - train - INFO - True
2024-04-07 04:59:14,428 - train - INFO - alphas:tensor([0.4663, 0.0329, 0.0706, 0.1517, 0.2784], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,447 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,447 - train - INFO - True
2024-04-07 04:59:14,448 - train - INFO - alphas:tensor([0.6266, 0.0356, 0.0554, 0.0998, 0.1826], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,466 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,466 - train - INFO - True
2024-04-07 04:59:14,467 - train - INFO - alphas:tensor([0.6826, 0.0377, 0.0415, 0.0833, 0.1550], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,485 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,485 - train - INFO - True
2024-04-07 04:59:14,485 - train - INFO - alphas:tensor([0.5802, 0.0308, 0.0439, 0.1150, 0.2301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,502 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,502 - train - INFO - True
2024-04-07 04:59:14,503 - train - INFO - alphas:tensor([0.4413, 0.0304, 0.0705, 0.1554, 0.3025], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,520 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,520 - train - INFO - True
2024-04-07 04:59:14,520 - train - INFO - alphas:tensor([0.5753, 0.0338, 0.0570, 0.1116, 0.2223], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,537 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,537 - train - INFO - True
2024-04-07 04:59:14,538 - train - INFO - alphas:tensor([0.6645, 0.0408, 0.0415, 0.0910, 0.1622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,558 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,558 - train - INFO - True
2024-04-07 04:59:14,558 - train - INFO - alphas:tensor([0.5881, 0.0331, 0.0476, 0.1149, 0.2163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,579 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,579 - train - INFO - True
2024-04-07 04:59:14,579 - train - INFO - alphas:tensor([0.6977, 0.0583, 0.1027, 0.1414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 04:59:14,598 - train - INFO - tau:0.7105532272722921
2024-04-07 04:59:14,598 - train - INFO - avg block size:1.8108108108108107
2024-04-07 04:59:14,599 - train - INFO - current latency ratio:tensor(0.9504)
2024-04-07 04:59:14,599 - train - INFO - lasso_alpha:4.594972986357222e-05
2024-04-07 04:59:14,848 - train - INFO - Test: [   0/78]  Time: 0.245 (0.245)  Loss:  1.0771 (1.0771)  Acc@1: 78.1250 (78.1250)  Acc@5: 92.9688 (92.9688)
2024-04-07 04:59:19,320 - train - INFO - Test: [  50/78]  Time: 0.089 (0.092)  Loss:  1.8467 (1.7161)  Acc@1: 60.1562 (59.6967)  Acc@5: 81.2500 (82.8278)
2024-04-07 04:59:21,716 - train - INFO - Test: [  78/78]  Time: 0.054 (0.090)  Loss:  1.5898 (1.7399)  Acc@1: 50.0000 (59.4200)  Acc@5: 93.7500 (82.3200)
2024-04-07 04:59:23,045 - train - INFO - Train: 37 [   0/781 (  0%)]  Loss:  4.233259 (4.2333)  Time: 1.256s,  101.91/s  (1.256s,  101.91/s)  LR: 4.300e-04  Data: 0.186 (0.186)
2024-04-07 05:00:07,800 - train - INFO - Train: 37 [  50/781 (  6%)]  Loss:  4.340293 (3.9390)  Time: 0.850s,  150.62/s  (0.902s,  141.88/s)  LR: 4.300e-04  Data: 0.007 (0.011)
2024-04-07 05:00:54,093 - train - INFO - Train: 37 [ 100/781 ( 13%)]  Loss:  3.412490 (3.9331)  Time: 1.114s,  114.95/s  (0.914s,  140.06/s)  LR: 4.300e-04  Data: 0.009 (0.009)
2024-04-07 05:01:39,799 - train - INFO - Train: 37 [ 150/781 ( 19%)]  Loss:  4.162500 (3.9467)  Time: 1.130s,  113.25/s  (0.914s,  140.05/s)  LR: 4.300e-04  Data: 0.007 (0.009)
2024-04-07 05:02:24,982 - train - INFO - Train: 37 [ 200/781 ( 26%)]  Loss:  3.248168 (3.9477)  Time: 0.989s,  129.48/s  (0.911s,  140.45/s)  LR: 4.300e-04  Data: 0.005 (0.009)
2024-04-07 05:03:09,748 - train - INFO - Train: 37 [ 250/781 ( 32%)]  Loss:  4.124028 (3.9394)  Time: 0.761s,  168.25/s  (0.908s,  140.95/s)  LR: 4.300e-04  Data: 0.005 (0.009)
2024-04-07 05:03:55,559 - train - INFO - Train: 37 [ 300/781 ( 38%)]  Loss:  3.989121 (3.9235)  Time: 0.783s,  163.49/s  (0.909s,  140.74/s)  LR: 4.300e-04  Data: 0.007 (0.009)
2024-04-07 05:04:40,228 - train - INFO - Train: 37 [ 350/781 ( 45%)]  Loss:  3.554048 (3.9357)  Time: 0.812s,  157.64/s  (0.907s,  141.10/s)  LR: 4.300e-04  Data: 0.008 (0.008)
2024-04-07 05:05:24,882 - train - INFO - Train: 37 [ 400/781 ( 51%)]  Loss:  3.632458 (3.9335)  Time: 0.849s,  150.83/s  (0.905s,  141.37/s)  LR: 4.300e-04  Data: 0.009 (0.008)
2024-04-07 05:06:09,747 - train - INFO - Train: 37 [ 450/781 ( 58%)]  Loss:  4.331394 (3.9392)  Time: 0.832s,  153.81/s  (0.905s,  141.51/s)  LR: 4.300e-04  Data: 0.007 (0.008)
2024-04-07 05:06:54,455 - train - INFO - Train: 37 [ 500/781 ( 64%)]  Loss:  3.506161 (3.9400)  Time: 0.848s,  150.91/s  (0.903s,  141.68/s)  LR: 4.300e-04  Data: 0.008 (0.008)
2024-04-07 05:07:37,997 - train - INFO - Train: 37 [ 550/781 ( 71%)]  Loss:  4.165142 (3.9475)  Time: 0.825s,  155.24/s  (0.901s,  142.14/s)  LR: 4.300e-04  Data: 0.007 (0.008)
2024-04-07 05:08:23,494 - train - INFO - Train: 37 [ 600/781 ( 77%)]  Loss:  3.419579 (3.9462)  Time: 0.811s,  157.90/s  (0.901s,  142.02/s)  LR: 4.300e-04  Data: 0.007 (0.008)
2024-04-07 05:09:08,182 - train - INFO - Train: 37 [ 650/781 ( 83%)]  Loss:  3.732103 (3.9460)  Time: 0.869s,  147.32/s  (0.901s,  142.11/s)  LR: 4.300e-04  Data: 0.009 (0.008)
2024-04-07 05:09:53,608 - train - INFO - Train: 37 [ 700/781 ( 90%)]  Loss:  4.389191 (3.9443)  Time: 1.085s,  117.99/s  (0.901s,  142.02/s)  LR: 4.300e-04  Data: 0.008 (0.008)
2024-04-07 05:10:40,411 - train - INFO - Train: 37 [ 750/781 ( 96%)]  Loss:  4.572984 (3.9407)  Time: 1.122s,  114.07/s  (0.904s,  141.66/s)  LR: 4.300e-04  Data: 0.008 (0.008)
2024-04-07 05:11:07,499 - train - INFO - Train: 37 [ 780/781 (100%)]  Loss:  3.665918 (3.9426)  Time: 0.741s,  172.79/s  (0.904s,  141.66/s)  LR: 4.300e-04  Data: 0.000 (0.008)
2024-04-07 05:11:07,499 - train - INFO - True
2024-04-07 05:11:07,501 - train - INFO - alphas:tensor([0.2065, 0.1143, 0.1644, 0.2400, 0.2747], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,514 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,515 - train - INFO - True
2024-04-07 05:11:07,515 - train - INFO - alphas:tensor([0.3018, 0.0725, 0.0960, 0.1798, 0.3498], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,528 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,528 - train - INFO - True
2024-04-07 05:11:07,529 - train - INFO - alphas:tensor([0.7326, 0.0769, 0.0531, 0.0645, 0.0728], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,553 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,553 - train - INFO - True
2024-04-07 05:11:07,554 - train - INFO - alphas:tensor([0.6648, 0.0607, 0.0600, 0.0923, 0.1222], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,576 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,576 - train - INFO - True
2024-04-07 05:11:07,577 - train - INFO - alphas:tensor([0.4811, 0.0600, 0.0903, 0.1474, 0.2212], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,597 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,597 - train - INFO - True
2024-04-07 05:11:07,598 - train - INFO - alphas:tensor([0.6235, 0.0618, 0.0647, 0.1024, 0.1475], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,617 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,617 - train - INFO - True
2024-04-07 05:11:07,618 - train - INFO - alphas:tensor([0.7534, 0.0590, 0.0413, 0.0626, 0.0839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,636 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,636 - train - INFO - True
2024-04-07 05:11:07,636 - train - INFO - alphas:tensor([0.6472, 0.0641, 0.0532, 0.0954, 0.1401], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,654 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,654 - train - INFO - True
2024-04-07 05:11:07,654 - train - INFO - alphas:tensor([0.5369, 0.0528, 0.0747, 0.1300, 0.2056], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,672 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,672 - train - INFO - True
2024-04-07 05:11:07,673 - train - INFO - alphas:tensor([0.6592, 0.0546, 0.0607, 0.0894, 0.1361], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,689 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,689 - train - INFO - True
2024-04-07 05:11:07,690 - train - INFO - alphas:tensor([0.6857, 0.0517, 0.0500, 0.0844, 0.1282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,706 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,706 - train - INFO - True
2024-04-07 05:11:07,707 - train - INFO - alphas:tensor([0.5781, 0.0476, 0.0586, 0.1220, 0.1937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,723 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,723 - train - INFO - True
2024-04-07 05:11:07,724 - train - INFO - alphas:tensor([0.5536, 0.0463, 0.0660, 0.1266, 0.2075], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,740 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,740 - train - INFO - True
2024-04-07 05:11:07,741 - train - INFO - alphas:tensor([0.6501, 0.0438, 0.0577, 0.0937, 0.1547], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,757 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,757 - train - INFO - True
2024-04-07 05:11:07,757 - train - INFO - alphas:tensor([0.6279, 0.0587, 0.0525, 0.0969, 0.1640], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,773 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,773 - train - INFO - True
2024-04-07 05:11:07,774 - train - INFO - alphas:tensor([0.4896, 0.0387, 0.0519, 0.1343, 0.2855], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,790 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,790 - train - INFO - True
2024-04-07 05:11:07,791 - train - INFO - alphas:tensor([0.5421, 0.0445, 0.0628, 0.1287, 0.2219], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,807 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,807 - train - INFO - True
2024-04-07 05:11:07,808 - train - INFO - alphas:tensor([0.6501, 0.0401, 0.0568, 0.0956, 0.1574], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,824 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,824 - train - INFO - True
2024-04-07 05:11:07,825 - train - INFO - alphas:tensor([0.6351, 0.0497, 0.0504, 0.0988, 0.1660], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,841 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,841 - train - INFO - True
2024-04-07 05:11:07,842 - train - INFO - alphas:tensor([0.4777, 0.0331, 0.0472, 0.1337, 0.3082], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,858 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,858 - train - INFO - True
2024-04-07 05:11:07,859 - train - INFO - alphas:tensor([0.4953, 0.0401, 0.0693, 0.1433, 0.2520], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,876 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,876 - train - INFO - True
2024-04-07 05:11:07,876 - train - INFO - alphas:tensor([0.6622, 0.0383, 0.0542, 0.0904, 0.1549], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,893 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,893 - train - INFO - True
2024-04-07 05:11:07,894 - train - INFO - alphas:tensor([0.6599, 0.0537, 0.0459, 0.0884, 0.1520], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,911 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,911 - train - INFO - True
2024-04-07 05:11:07,911 - train - INFO - alphas:tensor([0.4934, 0.0294, 0.0429, 0.1266, 0.3077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,928 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,928 - train - INFO - True
2024-04-07 05:11:07,929 - train - INFO - alphas:tensor([0.4854, 0.0360, 0.0674, 0.1462, 0.2650], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,945 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,945 - train - INFO - True
2024-04-07 05:11:07,946 - train - INFO - alphas:tensor([0.6461, 0.0375, 0.0543, 0.0901, 0.1722], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,962 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,962 - train - INFO - True
2024-04-07 05:11:07,963 - train - INFO - alphas:tensor([0.6676, 0.0396, 0.0439, 0.0878, 0.1612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,980 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,980 - train - INFO - True
2024-04-07 05:11:07,980 - train - INFO - alphas:tensor([0.5174, 0.0313, 0.0404, 0.1206, 0.2902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:07,997 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:07,997 - train - INFO - True
2024-04-07 05:11:07,998 - train - INFO - alphas:tensor([0.4561, 0.0310, 0.0691, 0.1538, 0.2900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:08,015 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:08,015 - train - INFO - True
2024-04-07 05:11:08,015 - train - INFO - alphas:tensor([0.6133, 0.0343, 0.0555, 0.1028, 0.1941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:08,032 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:08,032 - train - INFO - True
2024-04-07 05:11:08,033 - train - INFO - alphas:tensor([0.6760, 0.0367, 0.0408, 0.0848, 0.1617], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:08,049 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:08,050 - train - INFO - True
2024-04-07 05:11:08,050 - train - INFO - alphas:tensor([0.5695, 0.0291, 0.0429, 0.1169, 0.2416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:08,067 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:08,067 - train - INFO - True
2024-04-07 05:11:08,068 - train - INFO - alphas:tensor([0.4334, 0.0287, 0.0687, 0.1560, 0.3133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:08,084 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:08,084 - train - INFO - True
2024-04-07 05:11:08,085 - train - INFO - alphas:tensor([0.5625, 0.0318, 0.0566, 0.1132, 0.2360], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:08,102 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:08,102 - train - INFO - True
2024-04-07 05:11:08,103 - train - INFO - alphas:tensor([0.6566, 0.0396, 0.0410, 0.0928, 0.1700], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:08,119 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:08,119 - train - INFO - True
2024-04-07 05:11:08,120 - train - INFO - alphas:tensor([0.5784, 0.0312, 0.0465, 0.1171, 0.2269], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:08,137 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:08,137 - train - INFO - True
2024-04-07 05:11:08,137 - train - INFO - alphas:tensor([0.6981, 0.0573, 0.1026, 0.1421], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:11:08,154 - train - INFO - tau:0.7034476949995692
2024-04-07 05:11:08,154 - train - INFO - avg block size:1.8108108108108107
2024-04-07 05:11:08,154 - train - INFO - current latency ratio:tensor(0.9504)
2024-04-07 05:11:08,411 - train - INFO - Test: [   0/78]  Time: 0.253 (0.253)  Loss:  0.8721 (0.8721)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.9688 (92.9688)
2024-04-07 05:11:12,769 - train - INFO - Test: [  50/78]  Time: 0.088 (0.090)  Loss:  1.7773 (1.7160)  Acc@1: 60.1562 (59.7426)  Acc@5: 83.5938 (82.7359)
2024-04-07 05:11:15,163 - train - INFO - Test: [  78/78]  Time: 0.059 (0.089)  Loss:  1.6445 (1.7360)  Acc@1: 56.2500 (59.5200)  Acc@5: 93.7500 (82.3900)
2024-04-07 05:11:16,496 - train - INFO - Train: 38 [   0/781 (  0%)]  Loss:  3.715039 (3.7150)  Time: 1.262s,  101.41/s  (1.262s,  101.41/s)  LR: 4.264e-04  Data: 0.186 (0.186)
2024-04-07 05:12:01,509 - train - INFO - Train: 38 [  50/781 (  6%)]  Loss:  3.768830 (3.8463)  Time: 0.819s,  156.27/s  (0.907s,  141.07/s)  LR: 4.264e-04  Data: 0.014 (0.012)
2024-04-07 05:12:46,783 - train - INFO - Train: 38 [ 100/781 ( 13%)]  Loss:  4.373384 (3.9036)  Time: 1.062s,  120.48/s  (0.906s,  141.22/s)  LR: 4.264e-04  Data: 0.010 (0.010)
2024-04-07 05:13:33,560 - train - INFO - Train: 38 [ 150/781 ( 19%)]  Loss:  4.254628 (3.9186)  Time: 0.850s,  150.59/s  (0.916s,  139.73/s)  LR: 4.264e-04  Data: 0.007 (0.009)
2024-04-07 05:14:18,362 - train - INFO - Train: 38 [ 200/781 ( 26%)]  Loss:  3.937537 (3.9203)  Time: 0.857s,  149.43/s  (0.911s,  140.50/s)  LR: 4.264e-04  Data: 0.008 (0.009)
2024-04-07 05:15:04,457 - train - INFO - Train: 38 [ 250/781 ( 32%)]  Loss:  4.109797 (3.9282)  Time: 0.819s,  156.21/s  (0.913s,  140.17/s)  LR: 4.264e-04  Data: 0.006 (0.009)
2024-04-07 05:15:48,318 - train - INFO - Train: 38 [ 300/781 ( 38%)]  Loss:  3.947580 (3.9097)  Time: 0.841s,  152.22/s  (0.907s,  141.09/s)  LR: 4.264e-04  Data: 0.009 (0.009)
2024-04-07 05:16:34,207 - train - INFO - Train: 38 [ 350/781 ( 45%)]  Loss:  4.455722 (3.9029)  Time: 1.004s,  127.47/s  (0.909s,  140.86/s)  LR: 4.264e-04  Data: 0.009 (0.009)
2024-04-07 05:17:18,892 - train - INFO - Train: 38 [ 400/781 ( 51%)]  Loss:  4.191369 (3.9074)  Time: 1.121s,  114.15/s  (0.907s,  141.15/s)  LR: 4.264e-04  Data: 0.008 (0.008)
2024-04-07 05:18:03,627 - train - INFO - Train: 38 [ 450/781 ( 58%)]  Loss:  4.171212 (3.9143)  Time: 1.088s,  117.69/s  (0.905s,  141.36/s)  LR: 4.264e-04  Data: 0.008 (0.008)
2024-04-07 05:18:48,714 - train - INFO - Train: 38 [ 500/781 ( 64%)]  Loss:  3.390339 (3.9036)  Time: 0.848s,  151.02/s  (0.905s,  141.42/s)  LR: 4.264e-04  Data: 0.010 (0.008)
2024-04-07 05:19:34,901 - train - INFO - Train: 38 [ 550/781 ( 71%)]  Loss:  4.468192 (3.9046)  Time: 1.052s,  121.68/s  (0.907s,  141.16/s)  LR: 4.264e-04  Data: 0.007 (0.008)
2024-04-07 05:20:21,512 - train - INFO - Train: 38 [ 600/781 ( 77%)]  Loss:  4.211055 (3.9118)  Time: 0.842s,  152.07/s  (0.909s,  140.83/s)  LR: 4.264e-04  Data: 0.007 (0.008)
2024-04-07 05:21:05,991 - train - INFO - Train: 38 [ 650/781 ( 83%)]  Loss:  3.930105 (3.9181)  Time: 0.794s,  161.25/s  (0.907s,  141.06/s)  LR: 4.264e-04  Data: 0.004 (0.008)
2024-04-07 05:21:50,734 - train - INFO - Train: 38 [ 700/781 ( 90%)]  Loss:  3.885309 (3.9225)  Time: 0.857s,  149.33/s  (0.907s,  141.20/s)  LR: 4.264e-04  Data: 0.009 (0.008)
2024-04-07 05:22:35,433 - train - INFO - Train: 38 [ 750/781 ( 96%)]  Loss:  4.067418 (3.9194)  Time: 0.855s,  149.66/s  (0.906s,  141.33/s)  LR: 4.264e-04  Data: 0.009 (0.008)
2024-04-07 05:23:01,866 - train - INFO - Train: 38 [ 780/781 (100%)]  Loss:  3.546690 (3.9189)  Time: 1.070s,  119.67/s  (0.905s,  141.48/s)  LR: 4.264e-04  Data: 0.000 (0.008)
2024-04-07 05:23:01,867 - train - INFO - True
2024-04-07 05:23:01,869 - train - INFO - alphas:tensor([0.1984, 0.1108, 0.1638, 0.2448, 0.2821], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:01,893 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:01,893 - train - INFO - True
2024-04-07 05:23:01,895 - train - INFO - alphas:tensor([0.2939, 0.0704, 0.0936, 0.1813, 0.3608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:01,915 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:01,915 - train - INFO - True
2024-04-07 05:23:01,916 - train - INFO - alphas:tensor([0.7305, 0.0768, 0.0533, 0.0653, 0.0741], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:01,951 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:01,951 - train - INFO - True
2024-04-07 05:23:01,952 - train - INFO - alphas:tensor([0.6581, 0.0599, 0.0606, 0.0947, 0.1267], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:01,981 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:01,981 - train - INFO - True
2024-04-07 05:23:01,982 - train - INFO - alphas:tensor([0.4750, 0.0586, 0.0900, 0.1491, 0.2273], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,008 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,008 - train - INFO - True
2024-04-07 05:23:02,009 - train - INFO - alphas:tensor([0.6159, 0.0604, 0.0650, 0.1048, 0.1538], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,032 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,032 - train - INFO - True
2024-04-07 05:23:02,033 - train - INFO - alphas:tensor([0.7502, 0.0585, 0.0412, 0.0637, 0.0864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,055 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,055 - train - INFO - True
2024-04-07 05:23:02,056 - train - INFO - alphas:tensor([0.6376, 0.0630, 0.0531, 0.0985, 0.1478], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,076 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,076 - train - INFO - True
2024-04-07 05:23:02,077 - train - INFO - alphas:tensor([0.5318, 0.0514, 0.0743, 0.1313, 0.2112], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,096 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,096 - train - INFO - True
2024-04-07 05:23:02,096 - train - INFO - alphas:tensor([0.6514, 0.0538, 0.0611, 0.0918, 0.1420], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,114 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,114 - train - INFO - True
2024-04-07 05:23:02,115 - train - INFO - alphas:tensor([0.6787, 0.0511, 0.0498, 0.0865, 0.1339], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,132 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,132 - train - INFO - True
2024-04-07 05:23:02,133 - train - INFO - alphas:tensor([0.5686, 0.0461, 0.0575, 0.1246, 0.2031], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,153 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,153 - train - INFO - True
2024-04-07 05:23:02,154 - train - INFO - alphas:tensor([0.5501, 0.0444, 0.0650, 0.1273, 0.2132], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,175 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,175 - train - INFO - True
2024-04-07 05:23:02,175 - train - INFO - alphas:tensor([0.6431, 0.0427, 0.0577, 0.0958, 0.1607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,195 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,195 - train - INFO - True
2024-04-07 05:23:02,195 - train - INFO - alphas:tensor([0.6214, 0.0575, 0.0519, 0.0986, 0.1707], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,214 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,214 - train - INFO - True
2024-04-07 05:23:02,214 - train - INFO - alphas:tensor([0.4829, 0.0365, 0.0500, 0.1347, 0.2958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,232 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,232 - train - INFO - True
2024-04-07 05:23:02,233 - train - INFO - alphas:tensor([0.5374, 0.0431, 0.0622, 0.1295, 0.2277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,249 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,249 - train - INFO - True
2024-04-07 05:23:02,250 - train - INFO - alphas:tensor([0.6448, 0.0389, 0.0565, 0.0964, 0.1633], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,266 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,266 - train - INFO - True
2024-04-07 05:23:02,267 - train - INFO - alphas:tensor([0.6287, 0.0483, 0.0497, 0.1001, 0.1732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,284 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,284 - train - INFO - True
2024-04-07 05:23:02,285 - train - INFO - alphas:tensor([0.4708, 0.0317, 0.0450, 0.1334, 0.3191], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,302 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,302 - train - INFO - True
2024-04-07 05:23:02,303 - train - INFO - alphas:tensor([0.4887, 0.0379, 0.0686, 0.1444, 0.2604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,324 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,324 - train - INFO - True
2024-04-07 05:23:02,325 - train - INFO - alphas:tensor([0.6540, 0.0370, 0.0541, 0.0920, 0.1629], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,344 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,344 - train - INFO - True
2024-04-07 05:23:02,345 - train - INFO - alphas:tensor([0.6537, 0.0520, 0.0452, 0.0902, 0.1589], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,363 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,363 - train - INFO - True
2024-04-07 05:23:02,364 - train - INFO - alphas:tensor([0.4917, 0.0279, 0.0405, 0.1249, 0.3151], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,381 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,381 - train - INFO - True
2024-04-07 05:23:02,382 - train - INFO - alphas:tensor([0.4799, 0.0342, 0.0660, 0.1467, 0.2732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,398 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,398 - train - INFO - True
2024-04-07 05:23:02,399 - train - INFO - alphas:tensor([0.6393, 0.0359, 0.0534, 0.0912, 0.1802], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,415 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,415 - train - INFO - True
2024-04-07 05:23:02,416 - train - INFO - alphas:tensor([0.6640, 0.0380, 0.0426, 0.0886, 0.1667], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,433 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,433 - train - INFO - True
2024-04-07 05:23:02,433 - train - INFO - alphas:tensor([0.5124, 0.0297, 0.0383, 0.1200, 0.2995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,454 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,454 - train - INFO - True
2024-04-07 05:23:02,454 - train - INFO - alphas:tensor([0.4514, 0.0291, 0.0673, 0.1541, 0.2980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,474 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,474 - train - INFO - True
2024-04-07 05:23:02,475 - train - INFO - alphas:tensor([0.6088, 0.0324, 0.0541, 0.1032, 0.2014], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,493 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,493 - train - INFO - True
2024-04-07 05:23:02,494 - train - INFO - alphas:tensor([0.6731, 0.0355, 0.0395, 0.0851, 0.1669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,512 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,512 - train - INFO - True
2024-04-07 05:23:02,513 - train - INFO - alphas:tensor([0.5630, 0.0279, 0.0413, 0.1175, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,529 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,530 - train - INFO - True
2024-04-07 05:23:02,530 - train - INFO - alphas:tensor([0.4275, 0.0270, 0.0671, 0.1560, 0.3224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,547 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,547 - train - INFO - True
2024-04-07 05:23:02,548 - train - INFO - alphas:tensor([0.5583, 0.0298, 0.0545, 0.1134, 0.2440], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,564 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,564 - train - INFO - True
2024-04-07 05:23:02,565 - train - INFO - alphas:tensor([0.6528, 0.0382, 0.0398, 0.0932, 0.1759], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,583 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,583 - train - INFO - True
2024-04-07 05:23:02,584 - train - INFO - alphas:tensor([0.5715, 0.0294, 0.0452, 0.1179, 0.2359], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,605 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,605 - train - INFO - True
2024-04-07 05:23:02,605 - train - INFO - alphas:tensor([0.6990, 0.0564, 0.1020, 0.1425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:23:02,624 - train - INFO - tau:0.6964132180495735
2024-04-07 05:23:02,625 - train - INFO - avg block size:1.8108108108108107
2024-04-07 05:23:02,625 - train - INFO - current latency ratio:tensor(0.9504)
2024-04-07 05:23:02,625 - train - INFO - lasso_alpha:5.0544702849929444e-05
2024-04-07 05:23:02,872 - train - INFO - Test: [   0/78]  Time: 0.243 (0.243)  Loss:  0.9600 (0.9600)  Acc@1: 80.4688 (80.4688)  Acc@5: 94.5312 (94.5312)
2024-04-07 05:23:07,349 - train - INFO - Test: [  50/78]  Time: 0.087 (0.093)  Loss:  1.9102 (1.6872)  Acc@1: 54.6875 (61.0600)  Acc@5: 80.4688 (83.1495)
2024-04-07 05:23:09,736 - train - INFO - Test: [  78/78]  Time: 0.053 (0.090)  Loss:  1.8457 (1.7179)  Acc@1: 56.2500 (60.0600)  Acc@5: 100.0000 (82.6900)
2024-04-07 05:23:11,085 - train - INFO - Train: 39 [   0/781 (  0%)]  Loss:  4.512355 (4.5124)  Time: 1.273s,  100.52/s  (1.273s,  100.52/s)  LR: 4.227e-04  Data: 0.187 (0.187)
2024-04-07 05:23:56,477 - train - INFO - Train: 39 [  50/781 (  6%)]  Loss:  4.376443 (3.9221)  Time: 0.852s,  150.20/s  (0.915s,  139.89/s)  LR: 4.227e-04  Data: 0.007 (0.012)
2024-04-07 05:24:41,924 - train - INFO - Train: 39 [ 100/781 ( 13%)]  Loss:  4.177518 (3.9395)  Time: 0.856s,  149.48/s  (0.912s,  140.35/s)  LR: 4.227e-04  Data: 0.008 (0.010)
2024-04-07 05:25:26,178 - train - INFO - Train: 39 [ 150/781 ( 19%)]  Loss:  3.976259 (3.9409)  Time: 0.850s,  150.59/s  (0.903s,  141.74/s)  LR: 4.227e-04  Data: 0.008 (0.009)
2024-04-07 05:26:11,329 - train - INFO - Train: 39 [ 200/781 ( 26%)]  Loss:  4.002270 (3.9430)  Time: 1.026s,  124.75/s  (0.903s,  141.74/s)  LR: 4.227e-04  Data: 0.012 (0.009)
2024-04-07 05:26:56,591 - train - INFO - Train: 39 [ 250/781 ( 32%)]  Loss:  4.413364 (3.9337)  Time: 0.839s,  152.51/s  (0.903s,  141.68/s)  LR: 4.227e-04  Data: 0.008 (0.009)
2024-04-07 05:27:41,587 - train - INFO - Train: 39 [ 300/781 ( 38%)]  Loss:  3.885869 (3.9354)  Time: 1.033s,  123.90/s  (0.903s,  141.77/s)  LR: 4.227e-04  Data: 0.010 (0.009)
2024-04-07 05:28:28,173 - train - INFO - Train: 39 [ 350/781 ( 45%)]  Loss:  3.560018 (3.9345)  Time: 0.883s,  144.89/s  (0.907s,  141.13/s)  LR: 4.227e-04  Data: 0.007 (0.008)
2024-04-07 05:29:08,110 - train - INFO - Train: 39 [ 400/781 ( 51%)]  Loss:  4.254373 (3.9278)  Time: 0.821s,  155.98/s  (0.893s,  143.26/s)  LR: 4.227e-04  Data: 0.009 (0.008)
2024-04-07 05:29:46,828 - train - INFO - Train: 39 [ 450/781 ( 58%)]  Loss:  4.024307 (3.9220)  Time: 0.766s,  167.06/s  (0.880s,  145.41/s)  LR: 4.227e-04  Data: 0.006 (0.008)
2024-04-07 05:30:25,718 - train - INFO - Train: 39 [ 500/781 ( 64%)]  Loss:  3.870635 (3.9177)  Time: 0.768s,  166.73/s  (0.870s,  147.12/s)  LR: 4.227e-04  Data: 0.005 (0.008)
2024-04-07 05:31:04,981 - train - INFO - Train: 39 [ 550/781 ( 71%)]  Loss:  3.848806 (3.9238)  Time: 0.762s,  167.88/s  (0.862s,  148.43/s)  LR: 4.227e-04  Data: 0.005 (0.008)
2024-04-07 05:31:43,526 - train - INFO - Train: 39 [ 600/781 ( 77%)]  Loss:  3.298614 (3.9260)  Time: 0.812s,  157.58/s  (0.855s,  149.75/s)  LR: 4.227e-04  Data: 0.007 (0.007)
2024-04-07 05:32:22,628 - train - INFO - Train: 39 [ 650/781 ( 83%)]  Loss:  4.027655 (3.9336)  Time: 0.772s,  165.85/s  (0.849s,  150.74/s)  LR: 4.227e-04  Data: 0.005 (0.007)
2024-04-07 05:33:03,269 - train - INFO - Train: 39 [ 700/781 ( 90%)]  Loss:  4.309855 (3.9348)  Time: 0.801s,  159.77/s  (0.847s,  151.20/s)  LR: 4.227e-04  Data: 0.010 (0.007)
2024-04-07 05:33:48,414 - train - INFO - Train: 39 [ 750/781 ( 96%)]  Loss:  4.552143 (3.9363)  Time: 0.833s,  153.67/s  (0.850s,  150.53/s)  LR: 4.227e-04  Data: 0.007 (0.007)
2024-04-07 05:34:15,643 - train - INFO - Train: 39 [ 780/781 (100%)]  Loss:  3.749686 (3.9382)  Time: 1.069s,  119.69/s  (0.853s,  150.15/s)  LR: 4.227e-04  Data: 0.000 (0.007)
2024-04-07 05:34:15,644 - train - INFO - True
2024-04-07 05:34:15,647 - train - INFO - alphas:tensor([0.1898, 0.1072, 0.1637, 0.2500, 0.2893], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,671 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,671 - train - INFO - True
2024-04-07 05:34:15,672 - train - INFO - alphas:tensor([0.2869, 0.0687, 0.0926, 0.1814, 0.3704], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,693 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,693 - train - INFO - True
2024-04-07 05:34:15,694 - train - INFO - alphas:tensor([0.7275, 0.0772, 0.0536, 0.0663, 0.0754], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,743 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,743 - train - INFO - True
2024-04-07 05:34:15,744 - train - INFO - alphas:tensor([0.6518, 0.0590, 0.0609, 0.0970, 0.1314], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,772 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,772 - train - INFO - True
2024-04-07 05:34:15,773 - train - INFO - alphas:tensor([0.4703, 0.0563, 0.0893, 0.1506, 0.2335], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,798 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,798 - train - INFO - True
2024-04-07 05:34:15,798 - train - INFO - alphas:tensor([0.6082, 0.0584, 0.0652, 0.1076, 0.1606], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,821 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,821 - train - INFO - True
2024-04-07 05:34:15,822 - train - INFO - alphas:tensor([0.7432, 0.0588, 0.0418, 0.0659, 0.0903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,843 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,844 - train - INFO - True
2024-04-07 05:34:15,844 - train - INFO - alphas:tensor([0.6232, 0.0612, 0.0532, 0.1031, 0.1593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,865 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,865 - train - INFO - True
2024-04-07 05:34:15,866 - train - INFO - alphas:tensor([0.5263, 0.0496, 0.0739, 0.1328, 0.2174], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,885 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,886 - train - INFO - True
2024-04-07 05:34:15,886 - train - INFO - alphas:tensor([0.6447, 0.0528, 0.0610, 0.0934, 0.1481], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,905 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,905 - train - INFO - True
2024-04-07 05:34:15,906 - train - INFO - alphas:tensor([0.6681, 0.0513, 0.0502, 0.0897, 0.1407], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,923 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,923 - train - INFO - True
2024-04-07 05:34:15,924 - train - INFO - alphas:tensor([0.5575, 0.0438, 0.0568, 0.1276, 0.2144], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,941 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,941 - train - INFO - True
2024-04-07 05:34:15,941 - train - INFO - alphas:tensor([0.5442, 0.0427, 0.0647, 0.1286, 0.2197], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,958 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,958 - train - INFO - True
2024-04-07 05:34:15,959 - train - INFO - alphas:tensor([0.6397, 0.0409, 0.0566, 0.0962, 0.1666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,975 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,975 - train - INFO - True
2024-04-07 05:34:15,976 - train - INFO - alphas:tensor([0.6081, 0.0566, 0.0518, 0.1019, 0.1816], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:15,996 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:15,996 - train - INFO - True
2024-04-07 05:34:15,997 - train - INFO - alphas:tensor([0.4720, 0.0351, 0.0483, 0.1356, 0.3090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,017 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,017 - train - INFO - True
2024-04-07 05:34:16,018 - train - INFO - alphas:tensor([0.5322, 0.0415, 0.0616, 0.1305, 0.2342], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,037 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,037 - train - INFO - True
2024-04-07 05:34:16,037 - train - INFO - alphas:tensor([0.6383, 0.0373, 0.0559, 0.0977, 0.1709], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,055 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,055 - train - INFO - True
2024-04-07 05:34:16,056 - train - INFO - alphas:tensor([0.6184, 0.0471, 0.0494, 0.1026, 0.1825], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,073 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,073 - train - INFO - True
2024-04-07 05:34:16,073 - train - INFO - alphas:tensor([0.4604, 0.0299, 0.0429, 0.1340, 0.3328], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,090 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,090 - train - INFO - True
2024-04-07 05:34:16,091 - train - INFO - alphas:tensor([0.4815, 0.0362, 0.0675, 0.1453, 0.2694], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,108 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,108 - train - INFO - True
2024-04-07 05:34:16,108 - train - INFO - alphas:tensor([0.6440, 0.0361, 0.0538, 0.0945, 0.1716], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,125 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,125 - train - INFO - True
2024-04-07 05:34:16,126 - train - INFO - alphas:tensor([0.6422, 0.0518, 0.0452, 0.0925, 0.1682], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,147 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,147 - train - INFO - True
2024-04-07 05:34:16,148 - train - INFO - alphas:tensor([0.4795, 0.0264, 0.0386, 0.1254, 0.3301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,168 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,168 - train - INFO - True
2024-04-07 05:34:16,169 - train - INFO - alphas:tensor([0.4706, 0.0324, 0.0650, 0.1480, 0.2839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,187 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,187 - train - INFO - True
2024-04-07 05:34:16,188 - train - INFO - alphas:tensor([0.6290, 0.0348, 0.0532, 0.0927, 0.1904], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,205 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,205 - train - INFO - True
2024-04-07 05:34:16,206 - train - INFO - alphas:tensor([0.6563, 0.0368, 0.0417, 0.0902, 0.1750], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,223 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,223 - train - INFO - True
2024-04-07 05:34:16,224 - train - INFO - alphas:tensor([0.5025, 0.0280, 0.0363, 0.1197, 0.3135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,240 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,240 - train - INFO - True
2024-04-07 05:34:16,241 - train - INFO - alphas:tensor([0.4423, 0.0275, 0.0661, 0.1551, 0.3090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,258 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,258 - train - INFO - True
2024-04-07 05:34:16,258 - train - INFO - alphas:tensor([0.5960, 0.0307, 0.0537, 0.1051, 0.2144], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,276 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,276 - train - INFO - True
2024-04-07 05:34:16,277 - train - INFO - alphas:tensor([0.6648, 0.0343, 0.0389, 0.0864, 0.1757], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,298 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,298 - train - INFO - True
2024-04-07 05:34:16,298 - train - INFO - alphas:tensor([0.5552, 0.0262, 0.0395, 0.1178, 0.2612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,317 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,318 - train - INFO - True
2024-04-07 05:34:16,318 - train - INFO - alphas:tensor([0.4182, 0.0254, 0.0658, 0.1569, 0.3337], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,336 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,336 - train - INFO - True
2024-04-07 05:34:16,337 - train - INFO - alphas:tensor([0.5474, 0.0279, 0.0534, 0.1135, 0.2578], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,354 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,354 - train - INFO - True
2024-04-07 05:34:16,355 - train - INFO - alphas:tensor([0.6463, 0.0374, 0.0391, 0.0942, 0.1830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,372 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,372 - train - INFO - True
2024-04-07 05:34:16,372 - train - INFO - alphas:tensor([0.5643, 0.0275, 0.0436, 0.1194, 0.2452], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,389 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,389 - train - INFO - True
2024-04-07 05:34:16,390 - train - INFO - alphas:tensor([0.6987, 0.0559, 0.1019, 0.1435], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:34:16,407 - train - INFO - tau:0.6894490858690777
2024-04-07 05:34:16,407 - train - INFO - avg block size:1.8108108108108107
2024-04-07 05:34:16,407 - train - INFO - current latency ratio:tensor(0.9504)
2024-04-07 05:34:16,655 - train - INFO - Test: [   0/78]  Time: 0.245 (0.245)  Loss:  1.0625 (1.0625)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.1875 (92.1875)
2024-04-07 05:34:20,979 - train - INFO - Test: [  50/78]  Time: 0.085 (0.090)  Loss:  1.7070 (1.7052)  Acc@1: 60.9375 (60.6311)  Acc@5: 87.5000 (83.2414)
2024-04-07 05:34:23,349 - train - INFO - Test: [  78/78]  Time: 0.052 (0.088)  Loss:  1.5703 (1.7253)  Acc@1: 62.5000 (59.9900)  Acc@5: 100.0000 (82.8900)
2024-04-07 05:34:24,595 - train - INFO - Train: 40 [   0/781 (  0%)]  Loss:  4.276001 (4.2760)  Time: 1.182s,  108.33/s  (1.182s,  108.33/s)  LR: 4.189e-04  Data: 0.204 (0.204)
2024-04-07 05:35:09,545 - train - INFO - Train: 40 [  50/781 (  6%)]  Loss:  3.680842 (3.9730)  Time: 0.817s,  156.74/s  (0.905s,  141.51/s)  LR: 4.189e-04  Data: 0.008 (0.012)
2024-04-07 05:35:54,530 - train - INFO - Train: 40 [ 100/781 ( 13%)]  Loss:  3.356769 (3.9527)  Time: 0.874s,  146.49/s  (0.902s,  141.89/s)  LR: 4.189e-04  Data: 0.009 (0.010)
2024-04-07 05:36:40,680 - train - INFO - Train: 40 [ 150/781 ( 19%)]  Loss:  4.004705 (3.9478)  Time: 1.014s,  126.22/s  (0.909s,  140.81/s)  LR: 4.189e-04  Data: 0.005 (0.009)
2024-04-07 05:37:28,762 - train - INFO - Train: 40 [ 200/781 ( 26%)]  Loss:  4.223587 (3.9522)  Time: 0.816s,  156.91/s  (0.922s,  138.81/s)  LR: 4.189e-04  Data: 0.007 (0.009)
2024-04-07 05:38:12,629 - train - INFO - Train: 40 [ 250/781 ( 32%)]  Loss:  3.583713 (3.9412)  Time: 0.860s,  148.88/s  (0.913s,  140.17/s)  LR: 4.189e-04  Data: 0.022 (0.009)
2024-04-07 05:38:56,938 - train - INFO - Train: 40 [ 300/781 ( 38%)]  Loss:  3.849150 (3.9384)  Time: 1.040s,  123.08/s  (0.909s,  140.86/s)  LR: 4.189e-04  Data: 0.009 (0.009)
2024-04-07 05:39:42,558 - train - INFO - Train: 40 [ 350/781 ( 45%)]  Loss:  4.108026 (3.9420)  Time: 0.865s,  147.95/s  (0.909s,  140.78/s)  LR: 4.189e-04  Data: 0.008 (0.009)
2024-04-07 05:40:28,148 - train - INFO - Train: 40 [ 400/781 ( 51%)]  Loss:  4.530072 (3.9390)  Time: 1.031s,  124.17/s  (0.910s,  140.73/s)  LR: 4.189e-04  Data: 0.005 (0.009)
2024-04-07 05:41:14,475 - train - INFO - Train: 40 [ 450/781 ( 58%)]  Loss:  3.486416 (3.9400)  Time: 0.834s,  153.44/s  (0.911s,  140.44/s)  LR: 4.189e-04  Data: 0.007 (0.008)
2024-04-07 05:42:00,570 - train - INFO - Train: 40 [ 500/781 ( 64%)]  Loss:  3.253114 (3.9381)  Time: 1.062s,  120.54/s  (0.912s,  140.28/s)  LR: 4.189e-04  Data: 0.008 (0.008)
2024-04-07 05:42:45,783 - train - INFO - Train: 40 [ 550/781 ( 71%)]  Loss:  3.171028 (3.9398)  Time: 0.841s,  152.27/s  (0.912s,  140.40/s)  LR: 4.189e-04  Data: 0.009 (0.008)
2024-04-07 05:43:32,000 - train - INFO - Train: 40 [ 600/781 ( 77%)]  Loss:  3.471534 (3.9441)  Time: 0.821s,  155.86/s  (0.913s,  140.23/s)  LR: 4.189e-04  Data: 0.005 (0.008)
2024-04-07 05:44:17,391 - train - INFO - Train: 40 [ 650/781 ( 83%)]  Loss:  4.227855 (3.9440)  Time: 1.112s,  115.07/s  (0.912s,  140.29/s)  LR: 4.189e-04  Data: 0.019 (0.008)
2024-04-07 05:45:02,505 - train - INFO - Train: 40 [ 700/781 ( 90%)]  Loss:  4.214400 (3.9475)  Time: 0.846s,  151.25/s  (0.912s,  140.40/s)  LR: 4.189e-04  Data: 0.009 (0.008)
2024-04-07 05:45:48,200 - train - INFO - Train: 40 [ 750/781 ( 96%)]  Loss:  4.522824 (3.9474)  Time: 1.076s,  119.00/s  (0.912s,  140.38/s)  LR: 4.189e-04  Data: 0.007 (0.008)
2024-04-07 05:46:14,983 - train - INFO - Train: 40 [ 780/781 (100%)]  Loss:  4.404963 (3.9461)  Time: 0.832s,  153.90/s  (0.911s,  140.49/s)  LR: 4.189e-04  Data: 0.000 (0.008)
2024-04-07 05:46:14,984 - train - INFO - True
2024-04-07 05:46:14,987 - train - INFO - alphas:tensor([0.1824, 0.1040, 0.1641, 0.2540, 0.2956], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,011 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,011 - train - INFO - True
2024-04-07 05:46:15,012 - train - INFO - alphas:tensor([0.2812, 0.0667, 0.0915, 0.1813, 0.3794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,033 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,033 - train - INFO - True
2024-04-07 05:46:15,034 - train - INFO - alphas:tensor([0.7249, 0.0774, 0.0539, 0.0672, 0.0766], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,068 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,068 - train - INFO - True
2024-04-07 05:46:15,069 - train - INFO - alphas:tensor([0.6457, 0.0583, 0.0610, 0.0990, 0.1359], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,098 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,099 - train - INFO - True
2024-04-07 05:46:15,100 - train - INFO - alphas:tensor([0.4644, 0.0548, 0.0891, 0.1519, 0.2397], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,125 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,125 - train - INFO - True
2024-04-07 05:46:15,126 - train - INFO - alphas:tensor([0.6011, 0.0575, 0.0652, 0.1095, 0.1667], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,150 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,150 - train - INFO - True
2024-04-07 05:46:15,151 - train - INFO - alphas:tensor([0.7393, 0.0588, 0.0419, 0.0671, 0.0929], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,172 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,172 - train - INFO - True
2024-04-07 05:46:15,173 - train - INFO - alphas:tensor([0.6139, 0.0595, 0.0529, 0.1062, 0.1676], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,193 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,193 - train - INFO - True
2024-04-07 05:46:15,194 - train - INFO - alphas:tensor([0.5225, 0.0481, 0.0730, 0.1336, 0.2228], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,213 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,213 - train - INFO - True
2024-04-07 05:46:15,214 - train - INFO - alphas:tensor([0.6403, 0.0509, 0.0609, 0.0946, 0.1532], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,232 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,232 - train - INFO - True
2024-04-07 05:46:15,233 - train - INFO - alphas:tensor([0.6642, 0.0501, 0.0497, 0.0908, 0.1452], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,250 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,250 - train - INFO - True
2024-04-07 05:46:15,250 - train - INFO - alphas:tensor([0.5482, 0.0418, 0.0560, 0.1297, 0.2242], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,271 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,271 - train - INFO - True
2024-04-07 05:46:15,272 - train - INFO - alphas:tensor([0.5369, 0.0412, 0.0641, 0.1308, 0.2270], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,291 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,291 - train - INFO - True
2024-04-07 05:46:15,292 - train - INFO - alphas:tensor([0.6359, 0.0387, 0.0563, 0.0970, 0.1721], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,311 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,311 - train - INFO - True
2024-04-07 05:46:15,311 - train - INFO - alphas:tensor([0.6015, 0.0554, 0.0507, 0.1030, 0.1894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,329 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,329 - train - INFO - True
2024-04-07 05:46:15,329 - train - INFO - alphas:tensor([0.4630, 0.0333, 0.0466, 0.1361, 0.3210], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,346 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,346 - train - INFO - True
2024-04-07 05:46:15,347 - train - INFO - alphas:tensor([0.5240, 0.0399, 0.0611, 0.1324, 0.2426], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,363 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,363 - train - INFO - True
2024-04-07 05:46:15,364 - train - INFO - alphas:tensor([0.6333, 0.0356, 0.0549, 0.0991, 0.1771], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,385 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,385 - train - INFO - True
2024-04-07 05:46:15,386 - train - INFO - alphas:tensor([0.6091, 0.0454, 0.0486, 0.1046, 0.1923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,406 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,406 - train - INFO - True
2024-04-07 05:46:15,406 - train - INFO - alphas:tensor([0.4514, 0.0281, 0.0416, 0.1341, 0.3448], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,425 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,425 - train - INFO - True
2024-04-07 05:46:15,426 - train - INFO - alphas:tensor([0.4745, 0.0347, 0.0664, 0.1463, 0.2782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,443 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,443 - train - INFO - True
2024-04-07 05:46:15,444 - train - INFO - alphas:tensor([0.6388, 0.0339, 0.0532, 0.0951, 0.1790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,461 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,461 - train - INFO - True
2024-04-07 05:46:15,461 - train - INFO - alphas:tensor([0.6334, 0.0507, 0.0449, 0.0949, 0.1761], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,478 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,478 - train - INFO - True
2024-04-07 05:46:15,478 - train - INFO - alphas:tensor([0.4749, 0.0252, 0.0364, 0.1239, 0.3397], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,500 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,500 - train - INFO - True
2024-04-07 05:46:15,501 - train - INFO - alphas:tensor([0.4628, 0.0312, 0.0640, 0.1487, 0.2933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,520 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,520 - train - INFO - True
2024-04-07 05:46:15,521 - train - INFO - alphas:tensor([0.6213, 0.0329, 0.0525, 0.0937, 0.1996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,539 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,539 - train - INFO - True
2024-04-07 05:46:15,540 - train - INFO - alphas:tensor([0.6469, 0.0359, 0.0413, 0.0918, 0.1841], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,558 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,558 - train - INFO - True
2024-04-07 05:46:15,559 - train - INFO - alphas:tensor([0.4924, 0.0265, 0.0348, 0.1194, 0.3268], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,576 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,576 - train - INFO - True
2024-04-07 05:46:15,577 - train - INFO - alphas:tensor([0.4347, 0.0262, 0.0644, 0.1553, 0.3194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,593 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,594 - train - INFO - True
2024-04-07 05:46:15,594 - train - INFO - alphas:tensor([0.5846, 0.0292, 0.0529, 0.1067, 0.2267], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,616 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,616 - train - INFO - True
2024-04-07 05:46:15,616 - train - INFO - alphas:tensor([0.6603, 0.0329, 0.0379, 0.0866, 0.1823], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,636 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,636 - train - INFO - True
2024-04-07 05:46:15,637 - train - INFO - alphas:tensor([0.5468, 0.0251, 0.0381, 0.1177, 0.2723], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,655 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,655 - train - INFO - True
2024-04-07 05:46:15,656 - train - INFO - alphas:tensor([0.4122, 0.0243, 0.0639, 0.1561, 0.3435], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,674 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,674 - train - INFO - True
2024-04-07 05:46:15,674 - train - INFO - alphas:tensor([0.5440, 0.0265, 0.0518, 0.1123, 0.2654], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,691 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,691 - train - INFO - True
2024-04-07 05:46:15,692 - train - INFO - alphas:tensor([0.6401, 0.0364, 0.0382, 0.0953, 0.1900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,709 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,709 - train - INFO - True
2024-04-07 05:46:15,709 - train - INFO - alphas:tensor([0.5559, 0.0261, 0.0420, 0.1203, 0.2558], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,728 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,728 - train - INFO - True
2024-04-07 05:46:15,729 - train - INFO - alphas:tensor([0.7000, 0.0548, 0.1013, 0.1439], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:46:15,750 - train - INFO - tau:0.682554595010387
2024-04-07 05:46:15,750 - train - INFO - avg block size:1.8108108108108107
2024-04-07 05:46:15,750 - train - INFO - current latency ratio:tensor(0.9504)
2024-04-07 05:46:15,751 - train - INFO - lasso_alpha:5.5599173134922395e-05
2024-04-07 05:46:15,967 - train - INFO - Test: [   0/78]  Time: 0.213 (0.213)  Loss:  0.9932 (0.9932)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.1875 (92.1875)
2024-04-07 05:46:20,373 - train - INFO - Test: [  50/78]  Time: 0.087 (0.091)  Loss:  1.8984 (1.7022)  Acc@1: 58.5938 (60.4473)  Acc@5: 81.2500 (82.9044)
2024-04-07 05:46:22,763 - train - INFO - Test: [  78/78]  Time: 0.059 (0.089)  Loss:  1.8994 (1.7327)  Acc@1: 50.0000 (59.7400)  Acc@5: 93.7500 (82.4100)
2024-04-07 05:46:24,025 - train - INFO - Train: 41 [   0/781 (  0%)]  Loss:  4.266013 (4.2660)  Time: 1.193s,  107.27/s  (1.193s,  107.27/s)  LR: 4.151e-04  Data: 0.194 (0.194)
2024-04-07 05:47:08,211 - train - INFO - Train: 41 [  50/781 (  6%)]  Loss:  3.305602 (4.0218)  Time: 0.847s,  151.20/s  (0.890s,  143.86/s)  LR: 4.151e-04  Data: 0.008 (0.011)
2024-04-07 05:47:51,605 - train - INFO - Train: 41 [ 100/781 ( 13%)]  Loss:  4.009147 (3.9635)  Time: 0.848s,  150.93/s  (0.879s,  145.63/s)  LR: 4.151e-04  Data: 0.007 (0.009)
2024-04-07 05:48:37,022 - train - INFO - Train: 41 [ 150/781 ( 19%)]  Loss:  4.438768 (3.9838)  Time: 0.840s,  152.39/s  (0.889s,  144.04/s)  LR: 4.151e-04  Data: 0.005 (0.009)
2024-04-07 05:49:22,153 - train - INFO - Train: 41 [ 200/781 ( 26%)]  Loss:  3.948174 (3.9550)  Time: 0.768s,  166.68/s  (0.892s,  143.48/s)  LR: 4.151e-04  Data: 0.005 (0.009)
2024-04-07 05:50:06,592 - train - INFO - Train: 41 [ 250/781 ( 32%)]  Loss:  4.531892 (3.9654)  Time: 0.868s,  147.44/s  (0.891s,  143.59/s)  LR: 4.151e-04  Data: 0.007 (0.009)
2024-04-07 05:50:50,943 - train - INFO - Train: 41 [ 300/781 ( 38%)]  Loss:  3.783450 (3.9599)  Time: 0.852s,  150.16/s  (0.891s,  143.71/s)  LR: 4.151e-04  Data: 0.008 (0.009)
2024-04-07 05:51:35,601 - train - INFO - Train: 41 [ 350/781 ( 45%)]  Loss:  3.639647 (3.9631)  Time: 0.853s,  150.04/s  (0.891s,  143.65/s)  LR: 4.151e-04  Data: 0.016 (0.009)
2024-04-07 05:52:20,148 - train - INFO - Train: 41 [ 400/781 ( 51%)]  Loss:  3.622545 (3.9601)  Time: 0.827s,  154.72/s  (0.891s,  143.65/s)  LR: 4.151e-04  Data: 0.007 (0.009)
2024-04-07 05:53:07,560 - train - INFO - Train: 41 [ 450/781 ( 58%)]  Loss:  3.886870 (3.9666)  Time: 0.846s,  151.27/s  (0.897s,  142.64/s)  LR: 4.151e-04  Data: 0.008 (0.009)
2024-04-07 05:53:53,684 - train - INFO - Train: 41 [ 500/781 ( 64%)]  Loss:  3.981129 (3.9607)  Time: 0.865s,  147.91/s  (0.900s,  142.24/s)  LR: 4.151e-04  Data: 0.008 (0.008)
2024-04-07 05:54:40,014 - train - INFO - Train: 41 [ 550/781 ( 71%)]  Loss:  4.299274 (3.9681)  Time: 1.030s,  124.25/s  (0.902s,  141.86/s)  LR: 4.151e-04  Data: 0.018 (0.008)
2024-04-07 05:55:24,829 - train - INFO - Train: 41 [ 600/781 ( 77%)]  Loss:  4.305023 (3.9682)  Time: 0.841s,  152.21/s  (0.902s,  141.94/s)  LR: 4.151e-04  Data: 0.008 (0.008)
2024-04-07 05:56:08,377 - train - INFO - Train: 41 [ 650/781 ( 83%)]  Loss:  4.446627 (3.9597)  Time: 0.844s,  151.63/s  (0.899s,  142.31/s)  LR: 4.151e-04  Data: 0.008 (0.008)
2024-04-07 05:56:51,529 - train - INFO - Train: 41 [ 700/781 ( 90%)]  Loss:  4.291951 (3.9592)  Time: 0.847s,  151.08/s  (0.897s,  142.73/s)  LR: 4.151e-04  Data: 0.007 (0.008)
2024-04-07 05:57:36,425 - train - INFO - Train: 41 [ 750/781 ( 96%)]  Loss:  3.273896 (3.9554)  Time: 0.844s,  151.64/s  (0.897s,  142.71/s)  LR: 4.151e-04  Data: 0.008 (0.008)
2024-04-07 05:58:03,029 - train - INFO - Train: 41 [ 780/781 (100%)]  Loss:  4.502892 (3.9552)  Time: 0.836s,  153.04/s  (0.897s,  142.78/s)  LR: 4.151e-04  Data: 0.000 (0.008)
2024-04-07 05:58:03,030 - train - INFO - True
2024-04-07 05:58:03,033 - train - INFO - alphas:tensor([0.1746, 0.1007, 0.1636, 0.2585, 0.3026], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,069 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,069 - train - INFO - True
2024-04-07 05:58:03,070 - train - INFO - alphas:tensor([0.2730, 0.0645, 0.0903, 0.1820, 0.3902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,093 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,093 - train - INFO - True
2024-04-07 05:58:03,094 - train - INFO - alphas:tensor([0.7198, 0.0781, 0.0547, 0.0687, 0.0787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,131 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,131 - train - INFO - True
2024-04-07 05:58:03,132 - train - INFO - alphas:tensor([0.6362, 0.0580, 0.0619, 0.1019, 0.1420], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,163 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,163 - train - INFO - True
2024-04-07 05:58:03,164 - train - INFO - alphas:tensor([0.4568, 0.0532, 0.0887, 0.1539, 0.2473], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,192 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,192 - train - INFO - True
2024-04-07 05:58:03,193 - train - INFO - alphas:tensor([0.5940, 0.0557, 0.0653, 0.1115, 0.1734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,222 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,222 - train - INFO - True
2024-04-07 05:58:03,223 - train - INFO - alphas:tensor([0.7348, 0.0582, 0.0417, 0.0688, 0.0965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,251 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,251 - train - INFO - True
2024-04-07 05:58:03,252 - train - INFO - alphas:tensor([0.6028, 0.0584, 0.0522, 0.1093, 0.1772], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,280 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,280 - train - INFO - True
2024-04-07 05:58:03,281 - train - INFO - alphas:tensor([0.5132, 0.0467, 0.0728, 0.1359, 0.2315], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,310 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,310 - train - INFO - True
2024-04-07 05:58:03,311 - train - INFO - alphas:tensor([0.6320, 0.0499, 0.0610, 0.0968, 0.1604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,339 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,339 - train - INFO - True
2024-04-07 05:58:03,340 - train - INFO - alphas:tensor([0.6559, 0.0491, 0.0497, 0.0931, 0.1522], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,369 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,369 - train - INFO - True
2024-04-07 05:58:03,370 - train - INFO - alphas:tensor([0.5373, 0.0400, 0.0543, 0.1322, 0.2362], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,398 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,398 - train - INFO - True
2024-04-07 05:58:03,399 - train - INFO - alphas:tensor([0.5302, 0.0399, 0.0638, 0.1317, 0.2344], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,427 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,427 - train - INFO - True
2024-04-07 05:58:03,428 - train - INFO - alphas:tensor([0.6279, 0.0374, 0.0561, 0.0983, 0.1802], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,457 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,457 - train - INFO - True
2024-04-07 05:58:03,458 - train - INFO - alphas:tensor([0.5894, 0.0547, 0.0503, 0.1058, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,486 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,486 - train - INFO - True
2024-04-07 05:58:03,487 - train - INFO - alphas:tensor([0.4532, 0.0315, 0.0448, 0.1370, 0.3334], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,515 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,516 - train - INFO - True
2024-04-07 05:58:03,516 - train - INFO - alphas:tensor([0.5175, 0.0387, 0.0601, 0.1333, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,545 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,545 - train - INFO - True
2024-04-07 05:58:03,546 - train - INFO - alphas:tensor([0.6237, 0.0343, 0.0547, 0.1005, 0.1868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,574 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,574 - train - INFO - True
2024-04-07 05:58:03,575 - train - INFO - alphas:tensor([0.5986, 0.0441, 0.0477, 0.1067, 0.2029], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,604 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,604 - train - INFO - True
2024-04-07 05:58:03,605 - train - INFO - alphas:tensor([0.4431, 0.0269, 0.0395, 0.1334, 0.3570], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,633 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,633 - train - INFO - True
2024-04-07 05:58:03,634 - train - INFO - alphas:tensor([0.4679, 0.0334, 0.0648, 0.1472, 0.2868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,662 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,663 - train - INFO - True
2024-04-07 05:58:03,663 - train - INFO - alphas:tensor([0.6270, 0.0330, 0.0526, 0.0973, 0.1901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,692 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,692 - train - INFO - True
2024-04-07 05:58:03,693 - train - INFO - alphas:tensor([0.6225, 0.0493, 0.0446, 0.0974, 0.1863], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,721 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,721 - train - INFO - True
2024-04-07 05:58:03,722 - train - INFO - alphas:tensor([0.4623, 0.0238, 0.0347, 0.1238, 0.3554], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,751 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,751 - train - INFO - True
2024-04-07 05:58:03,752 - train - INFO - alphas:tensor([0.4554, 0.0293, 0.0621, 0.1491, 0.3040], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,780 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,780 - train - INFO - True
2024-04-07 05:58:03,781 - train - INFO - alphas:tensor([0.6129, 0.0311, 0.0524, 0.0940, 0.2096], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,810 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,810 - train - INFO - True
2024-04-07 05:58:03,811 - train - INFO - alphas:tensor([0.6400, 0.0342, 0.0405, 0.0932, 0.1920], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,838 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,838 - train - INFO - True
2024-04-07 05:58:03,839 - train - INFO - alphas:tensor([0.4889, 0.0246, 0.0327, 0.1176, 0.3363], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,864 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,864 - train - INFO - True
2024-04-07 05:58:03,865 - train - INFO - alphas:tensor([0.4280, 0.0244, 0.0630, 0.1554, 0.3292], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,888 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,888 - train - INFO - True
2024-04-07 05:58:03,889 - train - INFO - alphas:tensor([0.5801, 0.0274, 0.0513, 0.1064, 0.2348], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,910 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,910 - train - INFO - True
2024-04-07 05:58:03,910 - train - INFO - alphas:tensor([0.6505, 0.0317, 0.0373, 0.0885, 0.1920], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,930 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,930 - train - INFO - True
2024-04-07 05:58:03,931 - train - INFO - alphas:tensor([0.5356, 0.0232, 0.0369, 0.1192, 0.2851], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,950 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,950 - train - INFO - True
2024-04-07 05:58:03,950 - train - INFO - alphas:tensor([0.4029, 0.0229, 0.0627, 0.1566, 0.3550], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,968 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,968 - train - INFO - True
2024-04-07 05:58:03,969 - train - INFO - alphas:tensor([0.5324, 0.0250, 0.0510, 0.1131, 0.2785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:03,986 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:03,986 - train - INFO - True
2024-04-07 05:58:03,986 - train - INFO - alphas:tensor([0.6329, 0.0350, 0.0374, 0.0961, 0.1986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:04,004 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:04,004 - train - INFO - True
2024-04-07 05:58:04,004 - train - INFO - alphas:tensor([0.5494, 0.0244, 0.0404, 0.1205, 0.2654], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:04,025 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:04,025 - train - INFO - True
2024-04-07 05:58:04,026 - train - INFO - alphas:tensor([0.7017, 0.0538, 0.1003, 0.1441], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 05:58:04,045 - train - INFO - tau:0.6757290490602831
2024-04-07 05:58:04,045 - train - INFO - avg block size:1.8108108108108107
2024-04-07 05:58:04,045 - train - INFO - current latency ratio:tensor(0.9504)
2024-04-07 05:58:04,254 - train - INFO - Test: [   0/78]  Time: 0.206 (0.206)  Loss:  0.9995 (0.9995)  Acc@1: 82.0312 (82.0312)  Acc@5: 92.9688 (92.9688)
2024-04-07 05:58:08,757 - train - INFO - Test: [  50/78]  Time: 0.087 (0.092)  Loss:  1.9824 (1.6880)  Acc@1: 53.1250 (60.1103)  Acc@5: 77.3438 (82.6134)
2024-04-07 05:58:11,138 - train - INFO - Test: [  78/78]  Time: 0.054 (0.090)  Loss:  1.6484 (1.7234)  Acc@1: 56.2500 (59.3100)  Acc@5: 93.7500 (82.2900)
2024-04-07 05:58:12,428 - train - INFO - Train: 42 [   0/781 (  0%)]  Loss:  3.667400 (3.6674)  Time: 1.223s,  104.69/s  (1.223s,  104.69/s)  LR: 4.112e-04  Data: 0.164 (0.164)
2024-04-07 05:58:57,376 - train - INFO - Train: 42 [  50/781 (  6%)]  Loss:  3.721062 (3.9151)  Time: 0.843s,  151.85/s  (0.905s,  141.39/s)  LR: 4.112e-04  Data: 0.008 (0.011)
2024-04-07 05:59:41,486 - train - INFO - Train: 42 [ 100/781 ( 13%)]  Loss:  4.443044 (3.9298)  Time: 1.077s,  118.89/s  (0.894s,  143.20/s)  LR: 4.112e-04  Data: 0.008 (0.009)
2024-04-07 06:00:25,558 - train - INFO - Train: 42 [ 150/781 ( 19%)]  Loss:  4.451918 (3.9406)  Time: 1.026s,  124.78/s  (0.890s,  143.86/s)  LR: 4.112e-04  Data: 0.006 (0.009)
2024-04-07 06:01:11,017 - train - INFO - Train: 42 [ 200/781 ( 26%)]  Loss:  4.191546 (3.9473)  Time: 0.856s,  149.57/s  (0.895s,  143.09/s)  LR: 4.112e-04  Data: 0.008 (0.009)
2024-04-07 06:01:56,600 - train - INFO - Train: 42 [ 250/781 ( 32%)]  Loss:  4.063697 (3.9375)  Time: 0.861s,  148.59/s  (0.898s,  142.55/s)  LR: 4.112e-04  Data: 0.009 (0.008)
2024-04-07 06:02:42,358 - train - INFO - Train: 42 [ 300/781 ( 38%)]  Loss:  3.977118 (3.9564)  Time: 1.105s,  115.83/s  (0.901s,  142.10/s)  LR: 4.112e-04  Data: 0.008 (0.008)
2024-04-07 06:03:27,089 - train - INFO - Train: 42 [ 350/781 ( 45%)]  Loss:  4.476657 (3.9732)  Time: 0.830s,  154.21/s  (0.900s,  142.24/s)  LR: 4.112e-04  Data: 0.007 (0.008)
2024-04-07 06:04:12,673 - train - INFO - Train: 42 [ 400/781 ( 51%)]  Loss:  4.483559 (3.9753)  Time: 0.832s,  153.78/s  (0.901s,  142.01/s)  LR: 4.112e-04  Data: 0.008 (0.008)
2024-04-07 06:04:56,653 - train - INFO - Train: 42 [ 450/781 ( 58%)]  Loss:  3.551309 (3.9734)  Time: 0.847s,  151.10/s  (0.899s,  142.39/s)  LR: 4.112e-04  Data: 0.008 (0.008)
2024-04-07 06:05:42,279 - train - INFO - Train: 42 [ 500/781 ( 64%)]  Loss:  3.269879 (3.9752)  Time: 0.791s,  161.89/s  (0.900s,  142.17/s)  LR: 4.112e-04  Data: 0.006 (0.008)
2024-04-07 06:06:26,024 - train - INFO - Train: 42 [ 550/781 ( 71%)]  Loss:  4.303709 (3.9637)  Time: 0.841s,  152.27/s  (0.898s,  142.54/s)  LR: 4.112e-04  Data: 0.008 (0.008)
2024-04-07 06:07:09,791 - train - INFO - Train: 42 [ 600/781 ( 77%)]  Loss:  4.050982 (3.9637)  Time: 0.850s,  150.58/s  (0.896s,  142.84/s)  LR: 4.112e-04  Data: 0.007 (0.008)
2024-04-07 06:07:56,923 - train - INFO - Train: 42 [ 650/781 ( 83%)]  Loss:  4.306768 (3.9676)  Time: 0.841s,  152.13/s  (0.900s,  142.27/s)  LR: 4.112e-04  Data: 0.007 (0.008)
2024-04-07 06:08:42,026 - train - INFO - Train: 42 [ 700/781 ( 90%)]  Loss:  3.426225 (3.9583)  Time: 0.822s,  155.77/s  (0.900s,  142.25/s)  LR: 4.112e-04  Data: 0.006 (0.008)
2024-04-07 06:09:27,386 - train - INFO - Train: 42 [ 750/781 ( 96%)]  Loss:  3.422014 (3.9589)  Time: 0.840s,  152.32/s  (0.900s,  142.17/s)  LR: 4.112e-04  Data: 0.007 (0.008)
2024-04-07 06:09:54,027 - train - INFO - Train: 42 [ 780/781 (100%)]  Loss:  3.469004 (3.9600)  Time: 0.849s,  150.83/s  (0.900s,  142.24/s)  LR: 4.112e-04  Data: 0.000 (0.008)
2024-04-07 06:09:54,028 - train - INFO - True
2024-04-07 06:09:54,031 - train - INFO - alphas:tensor([0.1664, 0.0972, 0.1626, 0.2638, 0.3099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,053 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,053 - train - INFO - True
2024-04-07 06:09:54,054 - train - INFO - alphas:tensor([0.2668, 0.0625, 0.0889, 0.1812, 0.4006], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,074 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,074 - train - INFO - True
2024-04-07 06:09:54,075 - train - INFO - alphas:tensor([0.7155, 0.0788, 0.0553, 0.0700, 0.0805], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,108 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,109 - train - INFO - True
2024-04-07 06:09:54,110 - train - INFO - alphas:tensor([0.6280, 0.0573, 0.0623, 0.1046, 0.1479], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,138 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,138 - train - INFO - True
2024-04-07 06:09:54,139 - train - INFO - alphas:tensor([0.4495, 0.0513, 0.0884, 0.1560, 0.2549], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,165 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,165 - train - INFO - True
2024-04-07 06:09:54,165 - train - INFO - alphas:tensor([0.5862, 0.0542, 0.0652, 0.1136, 0.1807], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,189 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,189 - train - INFO - True
2024-04-07 06:09:54,189 - train - INFO - alphas:tensor([0.7294, 0.0581, 0.0419, 0.0705, 0.1001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,211 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,211 - train - INFO - True
2024-04-07 06:09:54,212 - train - INFO - alphas:tensor([0.5930, 0.0565, 0.0517, 0.1116, 0.1871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,233 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,233 - train - INFO - True
2024-04-07 06:09:54,234 - train - INFO - alphas:tensor([0.5113, 0.0454, 0.0717, 0.1357, 0.2359], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,254 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,254 - train - INFO - True
2024-04-07 06:09:54,255 - train - INFO - alphas:tensor([0.6278, 0.0487, 0.0605, 0.0976, 0.1655], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,273 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,274 - train - INFO - True
2024-04-07 06:09:54,274 - train - INFO - alphas:tensor([0.6455, 0.0485, 0.0502, 0.0958, 0.1599], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,292 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,292 - train - INFO - True
2024-04-07 06:09:54,293 - train - INFO - alphas:tensor([0.5293, 0.0386, 0.0529, 0.1339, 0.2454], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,310 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,310 - train - INFO - True
2024-04-07 06:09:54,310 - train - INFO - alphas:tensor([0.5254, 0.0386, 0.0625, 0.1325, 0.2409], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,327 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,327 - train - INFO - True
2024-04-07 06:09:54,328 - train - INFO - alphas:tensor([0.6218, 0.0359, 0.0552, 0.0997, 0.1874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,344 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,344 - train - INFO - True
2024-04-07 06:09:54,344 - train - INFO - alphas:tensor([0.5808, 0.0539, 0.0497, 0.1075, 0.2082], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,364 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,364 - train - INFO - True
2024-04-07 06:09:54,364 - train - INFO - alphas:tensor([0.4467, 0.0304, 0.0426, 0.1360, 0.3443], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,384 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,385 - train - INFO - True
2024-04-07 06:09:54,385 - train - INFO - alphas:tensor([0.5102, 0.0371, 0.0592, 0.1347, 0.2588], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,404 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,404 - train - INFO - True
2024-04-07 06:09:54,405 - train - INFO - alphas:tensor([0.6169, 0.0330, 0.0544, 0.1016, 0.1941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,422 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,423 - train - INFO - True
2024-04-07 06:09:54,423 - train - INFO - alphas:tensor([0.5889, 0.0420, 0.0468, 0.1091, 0.2131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,440 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,440 - train - INFO - True
2024-04-07 06:09:54,441 - train - INFO - alphas:tensor([0.4417, 0.0259, 0.0375, 0.1306, 0.3643], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,457 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,457 - train - INFO - True
2024-04-07 06:09:54,458 - train - INFO - alphas:tensor([0.4584, 0.0320, 0.0638, 0.1485, 0.2973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,474 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,474 - train - INFO - True
2024-04-07 06:09:54,475 - train - INFO - alphas:tensor([0.6192, 0.0308, 0.0519, 0.0988, 0.1992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,491 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,492 - train - INFO - True
2024-04-07 06:09:54,492 - train - INFO - alphas:tensor([0.6160, 0.0476, 0.0436, 0.0985, 0.1943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,513 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,513 - train - INFO - True
2024-04-07 06:09:54,514 - train - INFO - alphas:tensor([0.4559, 0.0226, 0.0326, 0.1226, 0.3664], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,534 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,534 - train - INFO - True
2024-04-07 06:09:54,535 - train - INFO - alphas:tensor([0.4491, 0.0277, 0.0605, 0.1492, 0.3134], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,553 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,553 - train - INFO - True
2024-04-07 06:09:54,554 - train - INFO - alphas:tensor([0.6057, 0.0298, 0.0513, 0.0948, 0.2185], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,572 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,572 - train - INFO - True
2024-04-07 06:09:54,572 - train - INFO - alphas:tensor([0.6345, 0.0328, 0.0392, 0.0942, 0.1993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,589 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,589 - train - INFO - True
2024-04-07 06:09:54,590 - train - INFO - alphas:tensor([0.4824, 0.0228, 0.0310, 0.1172, 0.3466], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,607 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,607 - train - INFO - True
2024-04-07 06:09:54,607 - train - INFO - alphas:tensor([0.4192, 0.0231, 0.0611, 0.1560, 0.3407], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,624 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,624 - train - INFO - True
2024-04-07 06:09:54,625 - train - INFO - alphas:tensor([0.5701, 0.0260, 0.0503, 0.1071, 0.2466], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,642 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,642 - train - INFO - True
2024-04-07 06:09:54,643 - train - INFO - alphas:tensor([0.6480, 0.0302, 0.0360, 0.0883, 0.1976], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,664 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,664 - train - INFO - True
2024-04-07 06:09:54,665 - train - INFO - alphas:tensor([0.5317, 0.0220, 0.0346, 0.1180, 0.2938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,684 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,684 - train - INFO - True
2024-04-07 06:09:54,685 - train - INFO - alphas:tensor([0.3973, 0.0213, 0.0606, 0.1554, 0.3654], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,703 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,703 - train - INFO - True
2024-04-07 06:09:54,704 - train - INFO - alphas:tensor([0.5246, 0.0229, 0.0488, 0.1127, 0.2910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,721 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,722 - train - INFO - True
2024-04-07 06:09:54,722 - train - INFO - alphas:tensor([0.6280, 0.0341, 0.0365, 0.0969, 0.2045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,739 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,739 - train - INFO - True
2024-04-07 06:09:54,740 - train - INFO - alphas:tensor([0.5449, 0.0228, 0.0386, 0.1199, 0.2738], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,756 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,756 - train - INFO - True
2024-04-07 06:09:54,757 - train - INFO - alphas:tensor([0.7031, 0.0528, 0.0998, 0.1443], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:09:54,773 - train - INFO - tau:0.6689717585696803
2024-04-07 06:09:54,773 - train - INFO - avg block size:1.8108108108108107
2024-04-07 06:09:54,773 - train - INFO - current latency ratio:tensor(0.9504)
2024-04-07 06:09:54,773 - train - INFO - lasso_alpha:6.115909044841464e-05
2024-04-07 06:09:55,019 - train - INFO - Test: [   0/78]  Time: 0.243 (0.243)  Loss:  0.9126 (0.9126)  Acc@1: 81.2500 (81.2500)  Acc@5: 91.4062 (91.4062)
2024-04-07 06:09:59,350 - train - INFO - Test: [  50/78]  Time: 0.083 (0.090)  Loss:  1.7578 (1.7237)  Acc@1: 61.7188 (59.8652)  Acc@5: 82.0312 (82.7206)
2024-04-07 06:10:01,658 - train - INFO - Test: [  78/78]  Time: 0.052 (0.087)  Loss:  1.8779 (1.7508)  Acc@1: 56.2500 (59.5400)  Acc@5: 93.7500 (82.3400)
2024-04-07 06:10:02,980 - train - INFO - Train: 43 [   0/781 (  0%)]  Loss:  4.226553 (4.2266)  Time: 1.253s,  102.12/s  (1.253s,  102.12/s)  LR: 4.072e-04  Data: 0.176 (0.176)
2024-04-07 06:10:47,420 - train - INFO - Train: 43 [  50/781 (  6%)]  Loss:  3.758406 (4.0258)  Time: 0.838s,  152.69/s  (0.896s,  142.87/s)  LR: 4.072e-04  Data: 0.008 (0.012)
2024-04-07 06:11:32,459 - train - INFO - Train: 43 [ 100/781 ( 13%)]  Loss:  3.412709 (4.0250)  Time: 0.836s,  153.16/s  (0.898s,  142.49/s)  LR: 4.072e-04  Data: 0.008 (0.010)
2024-04-07 06:12:17,571 - train - INFO - Train: 43 [ 150/781 ( 19%)]  Loss:  4.392066 (4.0187)  Time: 0.807s,  158.53/s  (0.900s,  142.29/s)  LR: 4.072e-04  Data: 0.006 (0.009)
2024-04-07 06:13:01,885 - train - INFO - Train: 43 [ 200/781 ( 26%)]  Loss:  4.334608 (4.0172)  Time: 0.841s,  152.14/s  (0.896s,  142.81/s)  LR: 4.072e-04  Data: 0.006 (0.009)
2024-04-07 06:13:47,457 - train - INFO - Train: 43 [ 250/781 ( 32%)]  Loss:  4.141493 (4.0131)  Time: 0.848s,  150.99/s  (0.899s,  142.33/s)  LR: 4.072e-04  Data: 0.007 (0.009)
2024-04-07 06:14:31,480 - train - INFO - Train: 43 [ 300/781 ( 38%)]  Loss:  4.408554 (3.9879)  Time: 0.884s,  144.85/s  (0.896s,  142.83/s)  LR: 4.072e-04  Data: 0.009 (0.009)
2024-04-07 06:15:15,526 - train - INFO - Train: 43 [ 350/781 ( 45%)]  Loss:  4.687731 (3.9836)  Time: 0.833s,  153.58/s  (0.894s,  143.18/s)  LR: 4.072e-04  Data: 0.008 (0.009)
2024-04-07 06:15:57,934 - train - INFO - Train: 43 [ 400/781 ( 51%)]  Loss:  3.256888 (3.9747)  Time: 0.848s,  151.03/s  (0.888s,  144.10/s)  LR: 4.072e-04  Data: 0.008 (0.008)
2024-04-07 06:16:42,152 - train - INFO - Train: 43 [ 450/781 ( 58%)]  Loss:  3.552330 (3.9709)  Time: 0.809s,  158.29/s  (0.888s,  144.17/s)  LR: 4.072e-04  Data: 0.006 (0.008)
2024-04-07 06:17:26,171 - train - INFO - Train: 43 [ 500/781 ( 64%)]  Loss:  4.218747 (3.9654)  Time: 0.806s,  158.79/s  (0.887s,  144.29/s)  LR: 4.072e-04  Data: 0.005 (0.008)
2024-04-07 06:18:09,891 - train - INFO - Train: 43 [ 550/781 ( 71%)]  Loss:  3.472952 (3.9677)  Time: 0.850s,  150.68/s  (0.886s,  144.48/s)  LR: 4.072e-04  Data: 0.008 (0.008)
2024-04-07 06:18:53,000 - train - INFO - Train: 43 [ 600/781 ( 77%)]  Loss:  3.786870 (3.9668)  Time: 1.060s,  120.75/s  (0.884s,  144.80/s)  LR: 4.072e-04  Data: 0.008 (0.008)
2024-04-07 06:19:39,641 - train - INFO - Train: 43 [ 650/781 ( 83%)]  Loss:  3.835108 (3.9665)  Time: 1.032s,  124.02/s  (0.888s,  144.19/s)  LR: 4.072e-04  Data: 0.008 (0.008)
2024-04-07 06:20:22,974 - train - INFO - Train: 43 [ 700/781 ( 90%)]  Loss:  3.531828 (3.9675)  Time: 1.080s,  118.46/s  (0.886s,  144.44/s)  LR: 4.072e-04  Data: 0.009 (0.008)
2024-04-07 06:21:06,896 - train - INFO - Train: 43 [ 750/781 ( 96%)]  Loss:  3.762565 (3.9726)  Time: 0.808s,  158.37/s  (0.886s,  144.52/s)  LR: 4.072e-04  Data: 0.006 (0.008)
2024-04-07 06:21:34,851 - train - INFO - Train: 43 [ 780/781 (100%)]  Loss:  3.716845 (3.9718)  Time: 0.762s,  167.92/s  (0.887s,  144.23/s)  LR: 4.072e-04  Data: 0.000 (0.008)
2024-04-07 06:21:34,851 - train - INFO - True
2024-04-07 06:21:34,852 - train - INFO - alphas:tensor([0.1580, 0.0936, 0.1628, 0.2685, 0.3172], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:34,867 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:34,867 - train - INFO - True
2024-04-07 06:21:34,868 - train - INFO - alphas:tensor([0.2601, 0.0609, 0.0880, 0.1816, 0.4094], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:34,882 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:34,882 - train - INFO - True
2024-04-07 06:21:34,883 - train - INFO - alphas:tensor([0.7103, 0.0800, 0.0558, 0.0715, 0.0825], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:34,911 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:34,911 - train - INFO - True
2024-04-07 06:21:34,912 - train - INFO - alphas:tensor([0.6193, 0.0570, 0.0626, 0.1073, 0.1538], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:34,940 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:34,940 - train - INFO - True
2024-04-07 06:21:34,941 - train - INFO - alphas:tensor([0.4407, 0.0492, 0.0880, 0.1582, 0.2639], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:34,969 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:34,970 - train - INFO - True
2024-04-07 06:21:34,971 - train - INFO - alphas:tensor([0.5774, 0.0525, 0.0654, 0.1157, 0.1889], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:34,999 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:34,999 - train - INFO - True
2024-04-07 06:21:35,000 - train - INFO - alphas:tensor([0.7199, 0.0585, 0.0427, 0.0733, 0.1056], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,028 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,028 - train - INFO - True
2024-04-07 06:21:35,029 - train - INFO - alphas:tensor([0.5787, 0.0558, 0.0514, 0.1151, 0.1990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,057 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,057 - train - INFO - True
2024-04-07 06:21:35,058 - train - INFO - alphas:tensor([0.5029, 0.0437, 0.0715, 0.1374, 0.2445], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,086 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,086 - train - INFO - True
2024-04-07 06:21:35,087 - train - INFO - alphas:tensor([0.6208, 0.0470, 0.0603, 0.0992, 0.1726], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,115 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,115 - train - INFO - True
2024-04-07 06:21:35,116 - train - INFO - alphas:tensor([0.6360, 0.0476, 0.0501, 0.0984, 0.1679], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,144 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,144 - train - INFO - True
2024-04-07 06:21:35,145 - train - INFO - alphas:tensor([0.5160, 0.0368, 0.0518, 0.1364, 0.2591], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,173 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,174 - train - INFO - True
2024-04-07 06:21:35,175 - train - INFO - alphas:tensor([0.5172, 0.0368, 0.0619, 0.1342, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,203 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,203 - train - INFO - True
2024-04-07 06:21:35,204 - train - INFO - alphas:tensor([0.6150, 0.0347, 0.0543, 0.1009, 0.1952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,232 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,232 - train - INFO - True
2024-04-07 06:21:35,233 - train - INFO - alphas:tensor([0.5712, 0.0525, 0.0488, 0.1096, 0.2179], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,261 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,261 - train - INFO - True
2024-04-07 06:21:35,262 - train - INFO - alphas:tensor([0.4365, 0.0289, 0.0405, 0.1366, 0.3575], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,290 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,290 - train - INFO - True
2024-04-07 06:21:35,291 - train - INFO - alphas:tensor([0.5019, 0.0358, 0.0585, 0.1360, 0.2679], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,319 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,319 - train - INFO - True
2024-04-07 06:21:35,320 - train - INFO - alphas:tensor([0.6100, 0.0317, 0.0537, 0.1026, 0.2020], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,348 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,349 - train - INFO - True
2024-04-07 06:21:35,349 - train - INFO - alphas:tensor([0.5781, 0.0407, 0.0461, 0.1112, 0.2240], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,378 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,378 - train - INFO - True
2024-04-07 06:21:35,379 - train - INFO - alphas:tensor([0.4271, 0.0248, 0.0359, 0.1321, 0.3801], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,407 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,407 - train - INFO - True
2024-04-07 06:21:35,408 - train - INFO - alphas:tensor([0.4511, 0.0306, 0.0623, 0.1494, 0.3067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,435 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,435 - train - INFO - True
2024-04-07 06:21:35,436 - train - INFO - alphas:tensor([0.6092, 0.0294, 0.0515, 0.1001, 0.2099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,461 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,461 - train - INFO - True
2024-04-07 06:21:35,462 - train - INFO - alphas:tensor([0.6051, 0.0464, 0.0429, 0.1008, 0.2047], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,485 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,485 - train - INFO - True
2024-04-07 06:21:35,485 - train - INFO - alphas:tensor([0.4483, 0.0213, 0.0308, 0.1212, 0.3785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,506 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,506 - train - INFO - True
2024-04-07 06:21:35,507 - train - INFO - alphas:tensor([0.4403, 0.0263, 0.0590, 0.1499, 0.3245], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,528 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,528 - train - INFO - True
2024-04-07 06:21:35,529 - train - INFO - alphas:tensor([0.5932, 0.0284, 0.0505, 0.0962, 0.2316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,550 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,550 - train - INFO - True
2024-04-07 06:21:35,550 - train - INFO - alphas:tensor([0.6238, 0.0316, 0.0387, 0.0964, 0.2095], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,571 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,571 - train - INFO - True
2024-04-07 06:21:35,571 - train - INFO - alphas:tensor([0.4692, 0.0215, 0.0296, 0.1177, 0.3619], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,590 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,590 - train - INFO - True
2024-04-07 06:21:35,591 - train - INFO - alphas:tensor([0.4125, 0.0218, 0.0595, 0.1558, 0.3504], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,609 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,609 - train - INFO - True
2024-04-07 06:21:35,610 - train - INFO - alphas:tensor([0.5601, 0.0246, 0.0488, 0.1076, 0.2589], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,627 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,627 - train - INFO - True
2024-04-07 06:21:35,628 - train - INFO - alphas:tensor([0.6377, 0.0296, 0.0356, 0.0897, 0.2074], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,644 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,644 - train - INFO - True
2024-04-07 06:21:35,645 - train - INFO - alphas:tensor([0.5175, 0.0206, 0.0333, 0.1193, 0.3092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,662 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,662 - train - INFO - True
2024-04-07 06:21:35,663 - train - INFO - alphas:tensor([0.3879, 0.0203, 0.0589, 0.1553, 0.3775], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,684 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,684 - train - INFO - True
2024-04-07 06:21:35,685 - train - INFO - alphas:tensor([0.5131, 0.0213, 0.0475, 0.1124, 0.3057], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,704 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,705 - train - INFO - True
2024-04-07 06:21:35,705 - train - INFO - alphas:tensor([0.6217, 0.0329, 0.0356, 0.0976, 0.2123], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,724 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,724 - train - INFO - True
2024-04-07 06:21:35,724 - train - INFO - alphas:tensor([0.5319, 0.0216, 0.0373, 0.1220, 0.2873], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,742 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,742 - train - INFO - True
2024-04-07 06:21:35,743 - train - INFO - alphas:tensor([0.7018, 0.0524, 0.1000, 0.1458], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:21:35,759 - train - INFO - tau:0.6622820409839835
2024-04-07 06:21:35,760 - train - INFO - avg block size:1.8108108108108107
2024-04-07 06:21:35,760 - train - INFO - current latency ratio:tensor(0.9504)
2024-04-07 06:21:36,012 - train - INFO - Test: [   0/78]  Time: 0.249 (0.249)  Loss:  0.9824 (0.9824)  Acc@1: 79.6875 (79.6875)  Acc@5: 94.5312 (94.5312)
2024-04-07 06:21:40,449 - train - INFO - Test: [  50/78]  Time: 0.085 (0.092)  Loss:  2.0078 (1.7083)  Acc@1: 53.9062 (60.4626)  Acc@5: 82.0312 (83.0423)
2024-04-07 06:21:42,824 - train - INFO - Test: [  78/78]  Time: 0.054 (0.089)  Loss:  1.7744 (1.7311)  Acc@1: 50.0000 (60.1000)  Acc@5: 87.5000 (82.5500)
2024-04-07 06:21:44,197 - train - INFO - Train: 44 [   0/781 (  0%)]  Loss:  3.252047 (3.2520)  Time: 1.298s,   98.65/s  (1.298s,   98.65/s)  LR: 4.031e-04  Data: 0.194 (0.194)
2024-04-07 06:22:31,263 - train - INFO - Train: 44 [  50/781 (  6%)]  Loss:  4.430969 (3.8822)  Time: 1.091s,  117.29/s  (0.948s,  134.98/s)  LR: 4.031e-04  Data: 0.008 (0.012)
2024-04-07 06:23:15,556 - train - INFO - Train: 44 [ 100/781 ( 13%)]  Loss:  4.105564 (3.9022)  Time: 0.861s,  148.58/s  (0.917s,  139.53/s)  LR: 4.031e-04  Data: 0.008 (0.010)
2024-04-07 06:23:59,207 - train - INFO - Train: 44 [ 150/781 ( 19%)]  Loss:  4.000186 (3.9316)  Time: 0.836s,  153.05/s  (0.903s,  141.80/s)  LR: 4.031e-04  Data: 0.008 (0.009)
2024-04-07 06:24:44,751 - train - INFO - Train: 44 [ 200/781 ( 26%)]  Loss:  4.498724 (3.9249)  Time: 0.836s,  153.15/s  (0.905s,  141.48/s)  LR: 4.031e-04  Data: 0.009 (0.009)
2024-04-07 06:25:29,087 - train - INFO - Train: 44 [ 250/781 ( 32%)]  Loss:  4.414200 (3.9381)  Time: 0.847s,  151.14/s  (0.901s,  142.05/s)  LR: 4.031e-04  Data: 0.009 (0.009)
2024-04-07 06:26:13,314 - train - INFO - Train: 44 [ 300/781 ( 38%)]  Loss:  4.394830 (3.9406)  Time: 1.063s,  120.45/s  (0.898s,  142.48/s)  LR: 4.031e-04  Data: 0.009 (0.009)
2024-04-07 06:26:56,870 - train - INFO - Train: 44 [ 350/781 ( 45%)]  Loss:  3.523911 (3.9327)  Time: 0.842s,  152.04/s  (0.894s,  143.10/s)  LR: 4.031e-04  Data: 0.009 (0.009)
2024-04-07 06:27:41,843 - train - INFO - Train: 44 [ 400/781 ( 51%)]  Loss:  4.513000 (3.9397)  Time: 1.084s,  118.03/s  (0.895s,  143.00/s)  LR: 4.031e-04  Data: 0.008 (0.008)
2024-04-07 06:28:25,582 - train - INFO - Train: 44 [ 450/781 ( 58%)]  Loss:  4.602890 (3.9470)  Time: 0.847s,  151.19/s  (0.893s,  143.36/s)  LR: 4.031e-04  Data: 0.007 (0.008)
2024-04-07 06:29:11,619 - train - INFO - Train: 44 [ 500/781 ( 64%)]  Loss:  3.368589 (3.9497)  Time: 1.110s,  115.29/s  (0.896s,  142.92/s)  LR: 4.031e-04  Data: 0.008 (0.008)
2024-04-07 06:29:56,601 - train - INFO - Train: 44 [ 550/781 ( 71%)]  Loss:  3.291876 (3.9516)  Time: 0.833s,  153.61/s  (0.896s,  142.86/s)  LR: 4.031e-04  Data: 0.009 (0.008)
2024-04-07 06:30:40,785 - train - INFO - Train: 44 [ 600/781 ( 77%)]  Loss:  3.798049 (3.9465)  Time: 0.831s,  154.02/s  (0.895s,  143.02/s)  LR: 4.031e-04  Data: 0.007 (0.008)
2024-04-07 06:31:24,451 - train - INFO - Train: 44 [ 650/781 ( 83%)]  Loss:  4.452217 (3.9534)  Time: 0.830s,  154.19/s  (0.893s,  143.29/s)  LR: 4.031e-04  Data: 0.008 (0.008)
2024-04-07 06:32:09,413 - train - INFO - Train: 44 [ 700/781 ( 90%)]  Loss:  4.421045 (3.9565)  Time: 0.836s,  153.13/s  (0.894s,  143.22/s)  LR: 4.031e-04  Data: 0.008 (0.008)
2024-04-07 06:32:54,213 - train - INFO - Train: 44 [ 750/781 ( 96%)]  Loss:  3.818933 (3.9617)  Time: 0.850s,  150.64/s  (0.894s,  143.20/s)  LR: 4.031e-04  Data: 0.008 (0.008)
2024-04-07 06:33:21,318 - train - INFO - Train: 44 [ 780/781 (100%)]  Loss:  3.442928 (3.9567)  Time: 0.834s,  153.41/s  (0.894s,  143.14/s)  LR: 4.031e-04  Data: 0.000 (0.008)
2024-04-07 06:33:21,319 - train - INFO - True
2024-04-07 06:33:21,321 - train - INFO - alphas:tensor([0.1500, 0.0899, 0.1608, 0.2741, 0.3251], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,345 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,345 - train - INFO - True
2024-04-07 06:33:21,347 - train - INFO - alphas:tensor([0.2543, 0.0590, 0.0862, 0.1812, 0.4194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,378 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,379 - train - INFO - True
2024-04-07 06:33:21,380 - train - INFO - alphas:tensor([0.7048, 0.0806, 0.0566, 0.0732, 0.0849], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,423 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,423 - train - INFO - True
2024-04-07 06:33:21,424 - train - INFO - alphas:tensor([0.6092, 0.0562, 0.0633, 0.1106, 0.1607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,458 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,458 - train - INFO - True
2024-04-07 06:33:21,459 - train - INFO - alphas:tensor([0.4353, 0.0477, 0.0875, 0.1590, 0.2705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,489 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,489 - train - INFO - True
2024-04-07 06:33:21,490 - train - INFO - alphas:tensor([0.5700, 0.0513, 0.0649, 0.1173, 0.1965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,518 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,518 - train - INFO - True
2024-04-07 06:33:21,519 - train - INFO - alphas:tensor([0.7161, 0.0578, 0.0423, 0.0748, 0.1090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,547 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,547 - train - INFO - True
2024-04-07 06:33:21,548 - train - INFO - alphas:tensor([0.5714, 0.0534, 0.0505, 0.1166, 0.2081], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,576 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,576 - train - INFO - True
2024-04-07 06:33:21,577 - train - INFO - alphas:tensor([0.4962, 0.0425, 0.0708, 0.1387, 0.2518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,605 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,605 - train - INFO - True
2024-04-07 06:33:21,606 - train - INFO - alphas:tensor([0.6147, 0.0456, 0.0601, 0.1005, 0.1792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,634 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,634 - train - INFO - True
2024-04-07 06:33:21,635 - train - INFO - alphas:tensor([0.6287, 0.0468, 0.0498, 0.1000, 0.1748], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,663 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,664 - train - INFO - True
2024-04-07 06:33:21,665 - train - INFO - alphas:tensor([0.5104, 0.0352, 0.0502, 0.1368, 0.2674], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,693 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,693 - train - INFO - True
2024-04-07 06:33:21,694 - train - INFO - alphas:tensor([0.5133, 0.0356, 0.0611, 0.1343, 0.2558], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,722 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,722 - train - INFO - True
2024-04-07 06:33:21,723 - train - INFO - alphas:tensor([0.6110, 0.0328, 0.0532, 0.1011, 0.2019], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,751 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,751 - train - INFO - True
2024-04-07 06:33:21,752 - train - INFO - alphas:tensor([0.5608, 0.0509, 0.0482, 0.1115, 0.2286], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,780 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,780 - train - INFO - True
2024-04-07 06:33:21,781 - train - INFO - alphas:tensor([0.4261, 0.0273, 0.0389, 0.1362, 0.3715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,809 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,809 - train - INFO - True
2024-04-07 06:33:21,810 - train - INFO - alphas:tensor([0.4989, 0.0344, 0.0571, 0.1353, 0.2743], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,838 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,839 - train - INFO - True
2024-04-07 06:33:21,839 - train - INFO - alphas:tensor([0.6054, 0.0302, 0.0526, 0.1026, 0.2092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,868 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,868 - train - INFO - True
2024-04-07 06:33:21,869 - train - INFO - alphas:tensor([0.5692, 0.0391, 0.0452, 0.1127, 0.2338], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,897 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,897 - train - INFO - True
2024-04-07 06:33:21,898 - train - INFO - alphas:tensor([0.4194, 0.0234, 0.0338, 0.1309, 0.3925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,926 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,926 - train - INFO - True
2024-04-07 06:33:21,927 - train - INFO - alphas:tensor([0.4439, 0.0290, 0.0605, 0.1494, 0.3172], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,955 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,955 - train - INFO - True
2024-04-07 06:33:21,956 - train - INFO - alphas:tensor([0.6042, 0.0277, 0.0502, 0.0996, 0.2184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:21,984 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:21,984 - train - INFO - True
2024-04-07 06:33:21,985 - train - INFO - alphas:tensor([0.5959, 0.0449, 0.0418, 0.1019, 0.2155], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,013 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,013 - train - INFO - True
2024-04-07 06:33:22,014 - train - INFO - alphas:tensor([0.4393, 0.0202, 0.0293, 0.1210, 0.3901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,042 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,043 - train - INFO - True
2024-04-07 06:33:22,043 - train - INFO - alphas:tensor([0.4330, 0.0250, 0.0578, 0.1498, 0.3344], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,072 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,072 - train - INFO - True
2024-04-07 06:33:22,073 - train - INFO - alphas:tensor([0.5841, 0.0267, 0.0497, 0.0962, 0.2433], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,101 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,101 - train - INFO - True
2024-04-07 06:33:22,102 - train - INFO - alphas:tensor([0.6200, 0.0304, 0.0373, 0.0957, 0.2167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,130 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,130 - train - INFO - True
2024-04-07 06:33:22,131 - train - INFO - alphas:tensor([0.4670, 0.0202, 0.0275, 0.1153, 0.3700], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,159 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,159 - train - INFO - True
2024-04-07 06:33:22,160 - train - INFO - alphas:tensor([0.4022, 0.0203, 0.0580, 0.1561, 0.3634], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,185 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,185 - train - INFO - True
2024-04-07 06:33:22,185 - train - INFO - alphas:tensor([0.5541, 0.0227, 0.0471, 0.1069, 0.2692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,208 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,208 - train - INFO - True
2024-04-07 06:33:22,209 - train - INFO - alphas:tensor([0.6328, 0.0286, 0.0347, 0.0892, 0.2148], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,230 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,230 - train - INFO - True
2024-04-07 06:33:22,231 - train - INFO - alphas:tensor([0.5123, 0.0196, 0.0313, 0.1183, 0.3185], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,251 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,251 - train - INFO - True
2024-04-07 06:33:22,252 - train - INFO - alphas:tensor([0.3799, 0.0190, 0.0570, 0.1547, 0.3895], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,261 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,262 - train - INFO - True
2024-04-07 06:33:22,262 - train - INFO - alphas:tensor([0.5057, 0.0198, 0.0456, 0.1120, 0.3169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,280 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,280 - train - INFO - True
2024-04-07 06:33:22,281 - train - INFO - alphas:tensor([0.6149, 0.0317, 0.0344, 0.0982, 0.2208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,298 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,299 - train - INFO - True
2024-04-07 06:33:22,299 - train - INFO - alphas:tensor([0.5271, 0.0202, 0.0356, 0.1209, 0.2963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,319 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,320 - train - INFO - True
2024-04-07 06:33:22,320 - train - INFO - alphas:tensor([0.7042, 0.0513, 0.0989, 0.1456], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:33:22,340 - train - INFO - tau:0.6556592205741436
2024-04-07 06:33:22,340 - train - INFO - avg block size:2.2162162162162162
2024-04-07 06:33:22,340 - train - INFO - current latency ratio:tensor(0.9150)
2024-04-07 06:33:22,340 - train - INFO - lasso_alpha:6.727499949325611e-05
2024-04-07 06:33:22,560 - train - INFO - Test: [   0/78]  Time: 0.217 (0.217)  Loss:  0.9204 (0.9204)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.1875 (92.1875)
2024-04-07 06:33:26,853 - train - INFO - Test: [  50/78]  Time: 0.086 (0.088)  Loss:  1.8184 (1.6942)  Acc@1: 56.2500 (60.1256)  Acc@5: 81.2500 (83.0423)
2024-04-07 06:33:29,222 - train - INFO - Test: [  78/78]  Time: 0.057 (0.087)  Loss:  1.7148 (1.7177)  Acc@1: 56.2500 (59.8300)  Acc@5: 87.5000 (82.5200)
2024-04-07 06:33:30,572 - train - INFO - Train: 45 [   0/781 (  0%)]  Loss:  4.249817 (4.2498)  Time: 1.285s,   99.60/s  (1.285s,   99.60/s)  LR: 3.990e-04  Data: 0.201 (0.201)
2024-04-07 06:34:15,756 - train - INFO - Train: 45 [  50/781 (  6%)]  Loss:  3.896126 (3.9562)  Time: 0.844s,  151.72/s  (0.911s,  140.49/s)  LR: 3.990e-04  Data: 0.008 (0.011)
2024-04-07 06:35:04,915 - train - INFO - Train: 45 [ 100/781 ( 13%)]  Loss:  3.788943 (4.0083)  Time: 0.873s,  146.63/s  (0.947s,  135.19/s)  LR: 3.990e-04  Data: 0.008 (0.010)
2024-04-07 06:35:49,180 - train - INFO - Train: 45 [ 150/781 ( 19%)]  Loss:  4.445268 (3.9774)  Time: 1.065s,  120.23/s  (0.926s,  138.17/s)  LR: 3.990e-04  Data: 0.013 (0.009)
2024-04-07 06:36:33,182 - train - INFO - Train: 45 [ 200/781 ( 26%)]  Loss:  4.488712 (3.9627)  Time: 0.759s,  168.58/s  (0.915s,  139.91/s)  LR: 3.990e-04  Data: 0.005 (0.009)
2024-04-07 06:37:16,428 - train - INFO - Train: 45 [ 250/781 ( 32%)]  Loss:  4.522928 (3.9656)  Time: 0.785s,  163.01/s  (0.905s,  141.45/s)  LR: 3.990e-04  Data: 0.005 (0.009)
2024-04-07 06:38:00,246 - train - INFO - Train: 45 [ 300/781 ( 38%)]  Loss:  4.469871 (3.9595)  Time: 1.004s,  127.45/s  (0.900s,  142.20/s)  LR: 3.990e-04  Data: 0.011 (0.008)
2024-04-07 06:38:45,095 - train - INFO - Train: 45 [ 350/781 ( 45%)]  Loss:  4.377322 (3.9701)  Time: 0.852s,  150.17/s  (0.900s,  142.27/s)  LR: 3.990e-04  Data: 0.009 (0.008)
2024-04-07 06:39:29,346 - train - INFO - Train: 45 [ 400/781 ( 51%)]  Loss:  3.750648 (3.9733)  Time: 0.850s,  150.63/s  (0.898s,  142.56/s)  LR: 3.990e-04  Data: 0.009 (0.008)
2024-04-07 06:40:12,147 - train - INFO - Train: 45 [ 450/781 ( 58%)]  Loss:  4.341072 (3.9746)  Time: 0.854s,  149.96/s  (0.893s,  143.30/s)  LR: 3.990e-04  Data: 0.009 (0.008)
2024-04-07 06:40:56,268 - train - INFO - Train: 45 [ 500/781 ( 64%)]  Loss:  4.377595 (3.9817)  Time: 0.841s,  152.20/s  (0.892s,  143.47/s)  LR: 3.990e-04  Data: 0.007 (0.008)
2024-04-07 06:41:41,074 - train - INFO - Train: 45 [ 550/781 ( 71%)]  Loss:  3.196640 (3.9871)  Time: 0.844s,  151.72/s  (0.893s,  143.42/s)  LR: 3.990e-04  Data: 0.008 (0.008)
2024-04-07 06:42:26,368 - train - INFO - Train: 45 [ 600/781 ( 77%)]  Loss:  4.024969 (3.9858)  Time: 0.853s,  149.98/s  (0.894s,  143.24/s)  LR: 3.990e-04  Data: 0.007 (0.008)
2024-04-07 06:43:11,259 - train - INFO - Train: 45 [ 650/781 ( 83%)]  Loss:  4.407576 (3.9847)  Time: 0.844s,  151.62/s  (0.894s,  143.19/s)  LR: 3.990e-04  Data: 0.007 (0.008)
2024-04-07 06:43:55,716 - train - INFO - Train: 45 [ 700/781 ( 90%)]  Loss:  3.927509 (3.9789)  Time: 0.828s,  154.53/s  (0.894s,  143.24/s)  LR: 3.990e-04  Data: 0.008 (0.008)
2024-04-07 06:44:39,808 - train - INFO - Train: 45 [ 750/781 ( 96%)]  Loss:  4.068856 (3.9743)  Time: 0.838s,  152.78/s  (0.893s,  143.37/s)  LR: 3.990e-04  Data: 0.008 (0.008)
2024-04-07 06:45:06,783 - train - INFO - Train: 45 [ 780/781 (100%)]  Loss:  3.507444 (3.9776)  Time: 0.832s,  153.88/s  (0.893s,  143.33/s)  LR: 3.990e-04  Data: 0.000 (0.008)
2024-04-07 06:45:06,784 - train - INFO - True
2024-04-07 06:45:06,786 - train - INFO - alphas:tensor([0.1424, 0.0867, 0.1583, 0.2795, 0.3330], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:06,806 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:06,806 - train - INFO - True
2024-04-07 06:45:06,807 - train - INFO - alphas:tensor([0.2482, 0.0575, 0.0846, 0.1807, 0.4290], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:06,825 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:06,825 - train - INFO - True
2024-04-07 06:45:06,826 - train - INFO - alphas:tensor([0.7011, 0.0807, 0.0570, 0.0744, 0.0868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:06,858 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:06,858 - train - INFO - True
2024-04-07 06:45:06,859 - train - INFO - alphas:tensor([0.6020, 0.0551, 0.0635, 0.1125, 0.1669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:06,886 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:06,886 - train - INFO - True
2024-04-07 06:45:06,887 - train - INFO - alphas:tensor([0.4271, 0.0464, 0.0870, 0.1608, 0.2787], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:06,911 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:06,911 - train - INFO - True
2024-04-07 06:45:06,912 - train - INFO - alphas:tensor([0.5604, 0.0494, 0.0650, 0.1197, 0.2055], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:06,934 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:06,934 - train - INFO - True
2024-04-07 06:45:06,935 - train - INFO - alphas:tensor([0.7058, 0.0580, 0.0428, 0.0780, 0.1154], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:06,955 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:06,956 - train - INFO - True
2024-04-07 06:45:06,956 - train - INFO - alphas:tensor([0.5582, 0.0519, 0.0496, 0.1200, 0.2203], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:06,976 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:06,976 - train - INFO - True
2024-04-07 06:45:06,976 - train - INFO - alphas:tensor([0.4872, 0.0410, 0.0702, 0.1406, 0.2610], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:06,995 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:06,995 - train - INFO - True
2024-04-07 06:45:06,995 - train - INFO - alphas:tensor([0.6048, 0.0443, 0.0603, 0.1025, 0.1882], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,013 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,013 - train - INFO - True
2024-04-07 06:45:07,014 - train - INFO - alphas:tensor([0.6181, 0.0458, 0.0496, 0.1028, 0.1838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,036 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,036 - train - INFO - True
2024-04-07 06:45:07,036 - train - INFO - alphas:tensor([0.4982, 0.0339, 0.0488, 0.1387, 0.2803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,056 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,056 - train - INFO - True
2024-04-07 06:45:07,057 - train - INFO - alphas:tensor([0.5020, 0.0349, 0.0608, 0.1361, 0.2662], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,075 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,075 - train - INFO - True
2024-04-07 06:45:07,076 - train - INFO - alphas:tensor([0.5980, 0.0316, 0.0532, 0.1035, 0.2137], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,094 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,094 - train - INFO - True
2024-04-07 06:45:07,094 - train - INFO - alphas:tensor([0.5484, 0.0504, 0.0471, 0.1139, 0.2403], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,111 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,111 - train - INFO - True
2024-04-07 06:45:07,112 - train - INFO - alphas:tensor([0.4145, 0.0260, 0.0368, 0.1365, 0.3863], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,130 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,131 - train - INFO - True
2024-04-07 06:45:07,131 - train - INFO - alphas:tensor([0.4874, 0.0334, 0.0565, 0.1370, 0.2857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,152 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,152 - train - INFO - True
2024-04-07 06:45:07,153 - train - INFO - alphas:tensor([0.5938, 0.0288, 0.0518, 0.1044, 0.2212], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,172 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,172 - train - INFO - True
2024-04-07 06:45:07,172 - train - INFO - alphas:tensor([0.5578, 0.0372, 0.0439, 0.1148, 0.2463], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,191 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,191 - train - INFO - True
2024-04-07 06:45:07,192 - train - INFO - alphas:tensor([0.4111, 0.0223, 0.0322, 0.1293, 0.4052], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,209 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,209 - train - INFO - True
2024-04-07 06:45:07,210 - train - INFO - alphas:tensor([0.4364, 0.0275, 0.0593, 0.1495, 0.3273], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,226 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,226 - train - INFO - True
2024-04-07 06:45:07,227 - train - INFO - alphas:tensor([0.5930, 0.0265, 0.0491, 0.1004, 0.2311], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,247 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,247 - train - INFO - True
2024-04-07 06:45:07,248 - train - INFO - alphas:tensor([0.5829, 0.0439, 0.0411, 0.1044, 0.2277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,268 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,268 - train - INFO - True
2024-04-07 06:45:07,268 - train - INFO - alphas:tensor([0.4298, 0.0187, 0.0279, 0.1201, 0.4034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,287 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,287 - train - INFO - True
2024-04-07 06:45:07,288 - train - INFO - alphas:tensor([0.4256, 0.0234, 0.0564, 0.1494, 0.3452], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,305 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,305 - train - INFO - True
2024-04-07 06:45:07,306 - train - INFO - alphas:tensor([0.5745, 0.0253, 0.0487, 0.0966, 0.2548], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,323 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,323 - train - INFO - True
2024-04-07 06:45:07,323 - train - INFO - alphas:tensor([0.6114, 0.0292, 0.0361, 0.0965, 0.2268], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,339 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,339 - train - INFO - True
2024-04-07 06:45:07,340 - train - INFO - alphas:tensor([0.4574, 0.0193, 0.0258, 0.1141, 0.3835], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,362 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,363 - train - INFO - True
2024-04-07 06:45:07,363 - train - INFO - alphas:tensor([0.3961, 0.0194, 0.0561, 0.1557, 0.3726], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,382 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,382 - train - INFO - True
2024-04-07 06:45:07,383 - train - INFO - alphas:tensor([0.5461, 0.0215, 0.0458, 0.1066, 0.2800], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,401 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,401 - train - INFO - True
2024-04-07 06:45:07,401 - train - INFO - alphas:tensor([0.6229, 0.0277, 0.0339, 0.0907, 0.2247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,419 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,419 - train - INFO - True
2024-04-07 06:45:07,419 - train - INFO - alphas:tensor([0.5014, 0.0184, 0.0298, 0.1188, 0.3317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,436 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,436 - train - INFO - True
2024-04-07 06:45:07,437 - train - INFO - alphas:tensor([0.3721, 0.0176, 0.0552, 0.1538, 0.4012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,445 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,445 - train - INFO - True
2024-04-07 06:45:07,446 - train - INFO - alphas:tensor([0.4973, 0.0187, 0.0442, 0.1111, 0.3287], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,463 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,463 - train - INFO - True
2024-04-07 06:45:07,463 - train - INFO - alphas:tensor([0.6046, 0.0306, 0.0336, 0.0999, 0.2313], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,481 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,481 - train - INFO - True
2024-04-07 06:45:07,482 - train - INFO - alphas:tensor([0.5195, 0.0190, 0.0337, 0.1210, 0.3069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,503 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,503 - train - INFO - True
2024-04-07 06:45:07,504 - train - INFO - alphas:tensor([0.7030, 0.0509, 0.0991, 0.1471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:45:07,523 - train - INFO - tau:0.6491026283684022
2024-04-07 06:45:07,523 - train - INFO - avg block size:2.2162162162162162
2024-04-07 06:45:07,523 - train - INFO - current latency ratio:tensor(0.9150)
2024-04-07 06:45:07,769 - train - INFO - Test: [   0/78]  Time: 0.243 (0.243)  Loss:  0.9741 (0.9741)  Acc@1: 79.6875 (79.6875)  Acc@5: 93.7500 (93.7500)
2024-04-07 06:45:12,845 - train - INFO - Test: [  50/78]  Time: 0.109 (0.104)  Loss:  1.8320 (1.7030)  Acc@1: 54.6875 (60.4013)  Acc@5: 85.1562 (82.7053)
2024-04-07 06:45:15,301 - train - INFO - Test: [  78/78]  Time: 0.054 (0.098)  Loss:  1.7324 (1.7306)  Acc@1: 50.0000 (59.9400)  Acc@5: 87.5000 (82.2000)
2024-04-07 06:45:16,650 - train - INFO - Train: 46 [   0/781 (  0%)]  Loss:  4.236096 (4.2361)  Time: 1.280s,  100.02/s  (1.280s,  100.02/s)  LR: 3.948e-04  Data: 0.193 (0.193)
2024-04-07 06:46:02,200 - train - INFO - Train: 46 [  50/781 (  6%)]  Loss:  3.628916 (3.9122)  Time: 0.857s,  149.40/s  (0.918s,  139.40/s)  LR: 3.948e-04  Data: 0.008 (0.012)
2024-04-07 06:46:46,222 - train - INFO - Train: 46 [ 100/781 ( 13%)]  Loss:  4.585985 (3.9512)  Time: 1.084s,  118.08/s  (0.899s,  142.30/s)  LR: 3.948e-04  Data: 0.009 (0.010)
2024-04-07 06:47:29,375 - train - INFO - Train: 46 [ 150/781 ( 19%)]  Loss:  4.333569 (3.9556)  Time: 0.853s,  150.04/s  (0.887s,  144.24/s)  LR: 3.948e-04  Data: 0.008 (0.009)
2024-04-07 06:48:13,784 - train - INFO - Train: 46 [ 200/781 ( 26%)]  Loss:  3.788280 (3.9657)  Time: 0.834s,  153.42/s  (0.888s,  144.21/s)  LR: 3.948e-04  Data: 0.008 (0.009)
2024-04-07 06:48:56,604 - train - INFO - Train: 46 [ 250/781 ( 32%)]  Loss:  3.394088 (3.9716)  Time: 0.810s,  158.03/s  (0.881s,  145.23/s)  LR: 3.948e-04  Data: 0.006 (0.008)
2024-04-07 06:49:40,253 - train - INFO - Train: 46 [ 300/781 ( 38%)]  Loss:  4.571280 (3.9905)  Time: 0.805s,  159.03/s  (0.880s,  145.46/s)  LR: 3.948e-04  Data: 0.005 (0.008)
2024-04-07 06:50:23,980 - train - INFO - Train: 46 [ 350/781 ( 45%)]  Loss:  3.317166 (3.9935)  Time: 0.852s,  150.27/s  (0.879s,  145.59/s)  LR: 3.948e-04  Data: 0.008 (0.008)
2024-04-07 06:51:06,937 - train - INFO - Train: 46 [ 400/781 ( 51%)]  Loss:  4.189387 (3.9930)  Time: 1.087s,  117.73/s  (0.877s,  146.00/s)  LR: 3.948e-04  Data: 0.009 (0.008)
2024-04-07 06:51:50,091 - train - INFO - Train: 46 [ 450/781 ( 58%)]  Loss:  3.917333 (4.0077)  Time: 0.871s,  146.89/s  (0.875s,  146.26/s)  LR: 3.948e-04  Data: 0.008 (0.008)
2024-04-07 06:52:34,122 - train - INFO - Train: 46 [ 500/781 ( 64%)]  Loss:  3.544660 (4.0127)  Time: 0.809s,  158.30/s  (0.876s,  146.17/s)  LR: 3.948e-04  Data: 0.006 (0.008)
2024-04-07 06:53:17,934 - train - INFO - Train: 46 [ 550/781 ( 71%)]  Loss:  4.577812 (4.0102)  Time: 0.814s,  157.18/s  (0.876s,  146.16/s)  LR: 3.948e-04  Data: 0.006 (0.008)
2024-04-07 06:54:00,804 - train - INFO - Train: 46 [ 600/781 ( 77%)]  Loss:  3.431186 (4.0106)  Time: 0.838s,  152.67/s  (0.874s,  146.41/s)  LR: 3.948e-04  Data: 0.009 (0.008)
2024-04-07 06:54:45,961 - train - INFO - Train: 46 [ 650/781 ( 83%)]  Loss:  3.683316 (4.0112)  Time: 0.843s,  151.80/s  (0.876s,  146.04/s)  LR: 3.948e-04  Data: 0.008 (0.008)
2024-04-07 06:55:29,992 - train - INFO - Train: 46 [ 700/781 ( 90%)]  Loss:  3.666236 (4.0122)  Time: 0.809s,  158.27/s  (0.877s,  145.99/s)  LR: 3.948e-04  Data: 0.006 (0.008)
2024-04-07 06:56:12,481 - train - INFO - Train: 46 [ 750/781 ( 96%)]  Loss:  3.811454 (4.0048)  Time: 0.861s,  148.64/s  (0.875s,  146.29/s)  LR: 3.948e-04  Data: 0.008 (0.008)
2024-04-07 06:56:39,500 - train - INFO - Train: 46 [ 780/781 (100%)]  Loss:  3.543447 (4.0039)  Time: 1.059s,  120.85/s  (0.876s,  146.13/s)  LR: 3.948e-04  Data: 0.000 (0.008)
2024-04-07 06:56:39,501 - train - INFO - True
2024-04-07 06:56:39,504 - train - INFO - alphas:tensor([0.1346, 0.0831, 0.1561, 0.2857, 0.3406], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,528 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,528 - train - INFO - True
2024-04-07 06:56:39,529 - train - INFO - alphas:tensor([0.2419, 0.0558, 0.0825, 0.1806, 0.4392], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,549 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,549 - train - INFO - True
2024-04-07 06:56:39,551 - train - INFO - alphas:tensor([0.6952, 0.0819, 0.0576, 0.0761, 0.0892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,586 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,586 - train - INFO - True
2024-04-07 06:56:39,587 - train - INFO - alphas:tensor([0.5950, 0.0537, 0.0632, 0.1149, 0.1732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,616 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,616 - train - INFO - True
2024-04-07 06:56:39,617 - train - INFO - alphas:tensor([0.4235, 0.0446, 0.0855, 0.1609, 0.2856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,643 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,643 - train - INFO - True
2024-04-07 06:56:39,644 - train - INFO - alphas:tensor([0.5544, 0.0476, 0.0641, 0.1208, 0.2132], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,667 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,667 - train - INFO - True
2024-04-07 06:56:39,668 - train - INFO - alphas:tensor([0.7051, 0.0566, 0.0422, 0.0783, 0.1178], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,690 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,690 - train - INFO - True
2024-04-07 06:56:39,691 - train - INFO - alphas:tensor([0.5569, 0.0496, 0.0476, 0.1201, 0.2259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,711 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,711 - train - INFO - True
2024-04-07 06:56:39,712 - train - INFO - alphas:tensor([0.4826, 0.0398, 0.0694, 0.1410, 0.2672], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,732 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,732 - train - INFO - True
2024-04-07 06:56:39,733 - train - INFO - alphas:tensor([0.5997, 0.0430, 0.0598, 0.1034, 0.1941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,754 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,754 - train - INFO - True
2024-04-07 06:56:39,755 - train - INFO - alphas:tensor([0.6149, 0.0447, 0.0485, 0.1032, 0.1886], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,774 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,774 - train - INFO - True
2024-04-07 06:56:39,775 - train - INFO - alphas:tensor([0.4949, 0.0322, 0.0466, 0.1378, 0.2884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,793 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,793 - train - INFO - True
2024-04-07 06:56:39,794 - train - INFO - alphas:tensor([0.4975, 0.0334, 0.0596, 0.1367, 0.2729], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,813 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,813 - train - INFO - True
2024-04-07 06:56:39,814 - train - INFO - alphas:tensor([0.5951, 0.0299, 0.0518, 0.1034, 0.2198], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,830 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,831 - train - INFO - True
2024-04-07 06:56:39,831 - train - INFO - alphas:tensor([0.5386, 0.0495, 0.0462, 0.1160, 0.2498], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,847 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,847 - train - INFO - True
2024-04-07 06:56:39,848 - train - INFO - alphas:tensor([0.4095, 0.0247, 0.0350, 0.1357, 0.3952], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,865 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,865 - train - INFO - True
2024-04-07 06:56:39,866 - train - INFO - alphas:tensor([0.4823, 0.0319, 0.0552, 0.1369, 0.2937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,886 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,886 - train - INFO - True
2024-04-07 06:56:39,887 - train - INFO - alphas:tensor([0.5906, 0.0271, 0.0503, 0.1044, 0.2275], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,906 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,906 - train - INFO - True
2024-04-07 06:56:39,906 - train - INFO - alphas:tensor([0.5470, 0.0355, 0.0428, 0.1168, 0.2579], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,924 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,924 - train - INFO - True
2024-04-07 06:56:39,925 - train - INFO - alphas:tensor([0.4016, 0.0212, 0.0305, 0.1285, 0.4182], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,933 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,933 - train - INFO - True
2024-04-07 06:56:39,934 - train - INFO - alphas:tensor([0.4303, 0.0258, 0.0576, 0.1497, 0.3366], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,950 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,950 - train - INFO - True
2024-04-07 06:56:39,951 - train - INFO - alphas:tensor([0.5835, 0.0254, 0.0484, 0.1013, 0.2413], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,967 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,967 - train - INFO - True
2024-04-07 06:56:39,967 - train - INFO - alphas:tensor([0.5763, 0.0417, 0.0400, 0.1047, 0.2374], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,983 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,983 - train - INFO - True
2024-04-07 06:56:39,984 - train - INFO - alphas:tensor([0.4240, 0.0175, 0.0261, 0.1177, 0.4147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:39,999 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:39,999 - train - INFO - True
2024-04-07 06:56:40,000 - train - INFO - alphas:tensor([0.4178, 0.0222, 0.0550, 0.1494, 0.3557], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:40,021 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:40,021 - train - INFO - True
2024-04-07 06:56:40,022 - train - INFO - alphas:tensor([0.5683, 0.0240, 0.0473, 0.0960, 0.2644], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:40,041 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:40,041 - train - INFO - True
2024-04-07 06:56:40,042 - train - INFO - alphas:tensor([0.5984, 0.0285, 0.0355, 0.0989, 0.2387], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:40,061 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:40,061 - train - INFO - True
2024-04-07 06:56:40,061 - train - INFO - alphas:tensor([0.4512, 0.0178, 0.0242, 0.1123, 0.3944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:40,081 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:40,081 - train - INFO - True
2024-04-07 06:56:40,081 - train - INFO - alphas:tensor([0.3893, 0.0184, 0.0541, 0.1551, 0.3831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:40,098 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:40,098 - train - INFO - True
2024-04-07 06:56:40,099 - train - INFO - alphas:tensor([0.5346, 0.0203, 0.0447, 0.1075, 0.2929], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:40,115 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:40,115 - train - INFO - True
2024-04-07 06:56:40,116 - train - INFO - alphas:tensor([0.6201, 0.0264, 0.0324, 0.0903, 0.2309], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:40,134 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:40,134 - train - INFO - True
2024-04-07 06:56:40,135 - train - INFO - alphas:tensor([0.4941, 0.0170, 0.0282, 0.1178, 0.3429], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:40,155 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:40,155 - train - INFO - True
2024-04-07 06:56:40,156 - train - INFO - alphas:tensor([0.3651, 0.0168, 0.0536, 0.1527, 0.4118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:40,166 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:40,166 - train - INFO - True
2024-04-07 06:56:40,166 - train - INFO - alphas:tensor([0.4868, 0.0174, 0.0428, 0.1097, 0.3433], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:40,185 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:40,185 - train - INFO - True
2024-04-07 06:56:40,185 - train - INFO - alphas:tensor([0.5987, 0.0295, 0.0325, 0.0998, 0.2394], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:40,203 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:40,203 - train - INFO - True
2024-04-07 06:56:40,203 - train - INFO - alphas:tensor([0.5101, 0.0178, 0.0323, 0.1214, 0.3184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:40,220 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:40,220 - train - INFO - True
2024-04-07 06:56:40,221 - train - INFO - alphas:tensor([0.7021, 0.0503, 0.0991, 0.1485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 06:56:40,237 - train - INFO - tau:0.6426116020847181
2024-04-07 06:56:40,237 - train - INFO - avg block size:2.6216216216216215
2024-04-07 06:56:40,238 - train - INFO - current latency ratio:tensor(0.8900)
2024-04-07 06:56:40,238 - train - INFO - lasso_alpha:7.400249944258173e-05
2024-04-07 06:56:40,485 - train - INFO - Test: [   0/78]  Time: 0.244 (0.244)  Loss:  1.0723 (1.0723)  Acc@1: 80.4688 (80.4688)  Acc@5: 91.4062 (91.4062)
2024-04-07 06:56:44,886 - train - INFO - Test: [  50/78]  Time: 0.090 (0.091)  Loss:  1.8496 (1.7072)  Acc@1: 53.1250 (60.1103)  Acc@5: 82.0312 (83.0116)
2024-04-07 06:56:47,253 - train - INFO - Test: [  78/78]  Time: 0.053 (0.089)  Loss:  1.5752 (1.7293)  Acc@1: 56.2500 (59.6400)  Acc@5: 100.0000 (82.6000)
2024-04-07 06:56:48,588 - train - INFO - Train: 47 [   0/781 (  0%)]  Loss:  4.494088 (4.4941)  Time: 1.267s,  101.05/s  (1.267s,  101.05/s)  LR: 3.906e-04  Data: 0.186 (0.186)
2024-04-07 06:57:31,978 - train - INFO - Train: 47 [  50/781 (  6%)]  Loss:  4.448068 (4.0533)  Time: 0.843s,  151.77/s  (0.876s,  146.19/s)  LR: 3.906e-04  Data: 0.008 (0.011)
2024-04-07 06:58:15,399 - train - INFO - Train: 47 [ 100/781 ( 13%)]  Loss:  3.220555 (4.0103)  Time: 0.840s,  152.45/s  (0.872s,  146.78/s)  LR: 3.906e-04  Data: 0.008 (0.010)
2024-04-07 06:58:58,997 - train - INFO - Train: 47 [ 150/781 ( 19%)]  Loss:  3.972169 (4.0286)  Time: 0.840s,  152.33/s  (0.872s,  146.79/s)  LR: 3.906e-04  Data: 0.008 (0.009)
2024-04-07 06:59:41,153 - train - INFO - Train: 47 [ 200/781 ( 26%)]  Loss:  3.772609 (4.0329)  Time: 0.842s,  152.00/s  (0.865s,  148.01/s)  LR: 3.906e-04  Data: 0.008 (0.009)
2024-04-07 07:00:28,132 - train - INFO - Train: 47 [ 250/781 ( 32%)]  Loss:  3.448668 (4.0018)  Time: 0.869s,  147.27/s  (0.880s,  145.51/s)  LR: 3.906e-04  Data: 0.009 (0.009)
2024-04-07 07:01:15,081 - train - INFO - Train: 47 [ 300/781 ( 38%)]  Loss:  3.591754 (4.0076)  Time: 1.092s,  117.22/s  (0.890s,  143.90/s)  LR: 3.906e-04  Data: 0.008 (0.008)
2024-04-07 07:01:58,206 - train - INFO - Train: 47 [ 350/781 ( 45%)]  Loss:  4.474584 (4.0090)  Time: 0.840s,  152.43/s  (0.886s,  144.52/s)  LR: 3.906e-04  Data: 0.008 (0.008)
2024-04-07 07:02:42,672 - train - INFO - Train: 47 [ 400/781 ( 51%)]  Loss:  4.565723 (4.0026)  Time: 0.858s,  149.12/s  (0.886s,  144.45/s)  LR: 3.906e-04  Data: 0.008 (0.008)
2024-04-07 07:03:26,008 - train - INFO - Train: 47 [ 450/781 ( 58%)]  Loss:  3.951765 (3.9987)  Time: 0.829s,  154.41/s  (0.884s,  144.80/s)  LR: 3.906e-04  Data: 0.008 (0.008)
2024-04-07 07:04:09,477 - train - INFO - Train: 47 [ 500/781 ( 64%)]  Loss:  4.256016 (3.9985)  Time: 0.848s,  151.01/s  (0.883s,  145.04/s)  LR: 3.906e-04  Data: 0.008 (0.008)
2024-04-07 07:04:52,434 - train - INFO - Train: 47 [ 550/781 ( 71%)]  Loss:  4.354404 (4.0009)  Time: 0.864s,  148.13/s  (0.880s,  145.39/s)  LR: 3.906e-04  Data: 0.010 (0.008)
2024-04-07 07:05:36,593 - train - INFO - Train: 47 [ 600/781 ( 77%)]  Loss:  4.417076 (4.0038)  Time: 0.843s,  151.85/s  (0.881s,  145.35/s)  LR: 3.906e-04  Data: 0.009 (0.008)
2024-04-07 07:06:20,738 - train - INFO - Train: 47 [ 650/781 ( 83%)]  Loss:  4.145612 (4.0005)  Time: 0.833s,  153.59/s  (0.881s,  145.32/s)  LR: 3.906e-04  Data: 0.007 (0.008)
2024-04-07 07:07:04,562 - train - INFO - Train: 47 [ 700/781 ( 90%)]  Loss:  3.852663 (4.0041)  Time: 0.851s,  150.47/s  (0.880s,  145.38/s)  LR: 3.906e-04  Data: 0.009 (0.008)
2024-04-07 07:07:48,036 - train - INFO - Train: 47 [ 750/781 ( 96%)]  Loss:  3.511147 (3.9974)  Time: 0.827s,  154.85/s  (0.880s,  145.50/s)  LR: 3.906e-04  Data: 0.007 (0.008)
2024-04-07 07:08:14,933 - train - INFO - Train: 47 [ 780/781 (100%)]  Loss:  3.522498 (3.9972)  Time: 0.795s,  161.04/s  (0.880s,  145.39/s)  LR: 3.906e-04  Data: 0.000 (0.008)
2024-04-07 07:08:14,934 - train - INFO - True
2024-04-07 07:08:14,936 - train - INFO - alphas:tensor([0.1271, 0.0795, 0.1526, 0.2918, 0.3489], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:14,960 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:14,960 - train - INFO - True
2024-04-07 07:08:14,961 - train - INFO - alphas:tensor([0.2329, 0.0537, 0.0813, 0.1804, 0.4518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:14,982 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:14,982 - train - INFO - True
2024-04-07 07:08:14,983 - train - INFO - alphas:tensor([0.6894, 0.0823, 0.0584, 0.0779, 0.0919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,017 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,017 - train - INFO - True
2024-04-07 07:08:15,018 - train - INFO - alphas:tensor([0.5843, 0.0526, 0.0636, 0.1182, 0.1813], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,047 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,047 - train - INFO - True
2024-04-07 07:08:15,048 - train - INFO - alphas:tensor([0.4136, 0.0426, 0.0847, 0.1635, 0.2955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,074 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,074 - train - INFO - True
2024-04-07 07:08:15,075 - train - INFO - alphas:tensor([0.5412, 0.0463, 0.0643, 0.1241, 0.2242], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,098 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,098 - train - INFO - True
2024-04-07 07:08:15,099 - train - INFO - alphas:tensor([0.6941, 0.0573, 0.0427, 0.0817, 0.1243], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,121 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,121 - train - INFO - True
2024-04-07 07:08:15,121 - train - INFO - alphas:tensor([0.5434, 0.0479, 0.0468, 0.1233, 0.2386], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,142 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,142 - train - INFO - True
2024-04-07 07:08:15,142 - train - INFO - alphas:tensor([0.4739, 0.0385, 0.0689, 0.1424, 0.2764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,161 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,161 - train - INFO - True
2024-04-07 07:08:15,162 - train - INFO - alphas:tensor([0.5904, 0.0412, 0.0598, 0.1052, 0.2035], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,180 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,180 - train - INFO - True
2024-04-07 07:08:15,181 - train - INFO - alphas:tensor([0.6036, 0.0439, 0.0483, 0.1058, 0.1985], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,198 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,198 - train - INFO - True
2024-04-07 07:08:15,199 - train - INFO - alphas:tensor([0.4804, 0.0308, 0.0454, 0.1399, 0.3035], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,215 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,215 - train - INFO - True
2024-04-07 07:08:15,216 - train - INFO - alphas:tensor([0.4897, 0.0320, 0.0588, 0.1376, 0.2820], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,232 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,232 - train - INFO - True
2024-04-07 07:08:15,233 - train - INFO - alphas:tensor([0.5870, 0.0285, 0.0513, 0.1043, 0.2289], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,252 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,252 - train - INFO - True
2024-04-07 07:08:15,253 - train - INFO - alphas:tensor([0.5271, 0.0483, 0.0456, 0.1179, 0.2611], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,273 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,273 - train - INFO - True
2024-04-07 07:08:15,274 - train - INFO - alphas:tensor([0.3981, 0.0228, 0.0332, 0.1375, 0.4084], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,284 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,284 - train - INFO - True
2024-04-07 07:08:15,285 - train - INFO - alphas:tensor([0.4710, 0.0305, 0.0548, 0.1386, 0.3052], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,303 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,303 - train - INFO - True
2024-04-07 07:08:15,303 - train - INFO - alphas:tensor([0.5805, 0.0260, 0.0495, 0.1051, 0.2388], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,321 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,321 - train - INFO - True
2024-04-07 07:08:15,321 - train - INFO - alphas:tensor([0.5386, 0.0342, 0.0414, 0.1179, 0.2679], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,338 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,338 - train - INFO - True
2024-04-07 07:08:15,339 - train - INFO - alphas:tensor([0.3976, 0.0200, 0.0286, 0.1266, 0.4272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,347 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,347 - train - INFO - True
2024-04-07 07:08:15,348 - train - INFO - alphas:tensor([0.4229, 0.0244, 0.0559, 0.1498, 0.3470], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,364 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,364 - train - INFO - True
2024-04-07 07:08:15,365 - train - INFO - alphas:tensor([0.5749, 0.0244, 0.0472, 0.1014, 0.2521], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,382 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,382 - train - INFO - True
2024-04-07 07:08:15,383 - train - INFO - alphas:tensor([0.5676, 0.0401, 0.0385, 0.1059, 0.2479], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,405 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,405 - train - INFO - True
2024-04-07 07:08:15,406 - train - INFO - alphas:tensor([0.4178, 0.0163, 0.0240, 0.1163, 0.4255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,416 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,416 - train - INFO - True
2024-04-07 07:08:15,417 - train - INFO - alphas:tensor([0.4102, 0.0208, 0.0532, 0.1494, 0.3663], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,435 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,435 - train - INFO - True
2024-04-07 07:08:15,436 - train - INFO - alphas:tensor([0.5593, 0.0228, 0.0465, 0.0954, 0.2759], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,453 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,453 - train - INFO - True
2024-04-07 07:08:15,454 - train - INFO - alphas:tensor([0.5883, 0.0269, 0.0340, 0.1003, 0.2505], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,471 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,471 - train - INFO - True
2024-04-07 07:08:15,472 - train - INFO - alphas:tensor([0.4395, 0.0168, 0.0228, 0.1117, 0.4092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,488 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,488 - train - INFO - True
2024-04-07 07:08:15,489 - train - INFO - alphas:tensor([0.3808, 0.0172, 0.0528, 0.1543, 0.3949], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,497 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,497 - train - INFO - True
2024-04-07 07:08:15,497 - train - INFO - alphas:tensor([0.5252, 0.0185, 0.0430, 0.1074, 0.3058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,514 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,514 - train - INFO - True
2024-04-07 07:08:15,514 - train - INFO - alphas:tensor([0.6078, 0.0255, 0.0318, 0.0920, 0.2429], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,534 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,534 - train - INFO - True
2024-04-07 07:08:15,535 - train - INFO - alphas:tensor([0.4857, 0.0160, 0.0268, 0.1164, 0.3550], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,555 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,555 - train - INFO - True
2024-04-07 07:08:15,556 - train - INFO - alphas:tensor([0.3560, 0.0156, 0.0515, 0.1518, 0.4251], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,565 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,565 - train - INFO - True
2024-04-07 07:08:15,566 - train - INFO - alphas:tensor([0.4803, 0.0161, 0.0406, 0.1076, 0.3554], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,584 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,584 - train - INFO - True
2024-04-07 07:08:15,584 - train - INFO - alphas:tensor([0.5931, 0.0280, 0.0314, 0.1003, 0.2471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,601 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,601 - train - INFO - True
2024-04-07 07:08:15,602 - train - INFO - alphas:tensor([0.5034, 0.0164, 0.0302, 0.1205, 0.3295], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,618 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,618 - train - INFO - True
2024-04-07 07:08:15,619 - train - INFO - alphas:tensor([0.7029, 0.0493, 0.0985, 0.1492], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:08:15,635 - train - INFO - tau:0.6361854860638709
2024-04-07 07:08:15,635 - train - INFO - avg block size:3.8378378378378377
2024-04-07 07:08:15,635 - train - INFO - current latency ratio:tensor(0.8046)
2024-04-07 07:08:15,884 - train - INFO - Test: [   0/78]  Time: 0.246 (0.246)  Loss:  1.0010 (1.0010)  Acc@1: 80.4688 (80.4688)  Acc@5: 91.4062 (91.4062)
2024-04-07 07:08:20,507 - train - INFO - Test: [  50/78]  Time: 0.086 (0.095)  Loss:  1.8672 (1.7143)  Acc@1: 57.8125 (60.0337)  Acc@5: 82.8125 (82.8125)
2024-04-07 07:08:22,875 - train - INFO - Test: [  78/78]  Time: 0.052 (0.092)  Loss:  1.6445 (1.7357)  Acc@1: 56.2500 (59.6500)  Acc@5: 87.5000 (82.4800)
2024-04-07 07:08:24,178 - train - INFO - Train: 48 [   0/781 (  0%)]  Loss:  3.631386 (3.6314)  Time: 1.237s,  103.51/s  (1.237s,  103.51/s)  LR: 3.863e-04  Data: 0.178 (0.178)
2024-04-07 07:09:10,261 - train - INFO - Train: 48 [  50/781 (  6%)]  Loss:  3.222551 (3.9906)  Time: 0.859s,  148.95/s  (0.928s,  137.96/s)  LR: 3.863e-04  Data: 0.009 (0.011)
2024-04-07 07:09:56,446 - train - INFO - Train: 48 [ 100/781 ( 13%)]  Loss:  3.156369 (3.9447)  Time: 1.065s,  120.19/s  (0.926s,  138.26/s)  LR: 3.863e-04  Data: 0.007 (0.010)
2024-04-07 07:10:40,721 - train - INFO - Train: 48 [ 150/781 ( 19%)]  Loss:  3.973007 (3.9745)  Time: 1.088s,  117.67/s  (0.912s,  140.29/s)  LR: 3.863e-04  Data: 0.007 (0.009)
2024-04-07 07:11:25,106 - train - INFO - Train: 48 [ 200/781 ( 26%)]  Loss:  4.131225 (3.9727)  Time: 0.840s,  152.37/s  (0.906s,  141.24/s)  LR: 3.863e-04  Data: 0.008 (0.009)
2024-04-07 07:12:08,914 - train - INFO - Train: 48 [ 250/781 ( 32%)]  Loss:  4.492992 (3.9675)  Time: 1.079s,  118.64/s  (0.900s,  142.18/s)  LR: 3.863e-04  Data: 0.009 (0.008)
2024-04-07 07:12:53,362 - train - INFO - Train: 48 [ 300/781 ( 38%)]  Loss:  4.407170 (3.9738)  Time: 0.853s,  150.14/s  (0.898s,  142.48/s)  LR: 3.863e-04  Data: 0.007 (0.008)
2024-04-07 07:13:37,327 - train - INFO - Train: 48 [ 350/781 ( 45%)]  Loss:  4.576633 (3.9817)  Time: 1.077s,  118.85/s  (0.896s,  142.91/s)  LR: 3.863e-04  Data: 0.008 (0.008)
2024-04-07 07:14:20,229 - train - INFO - Train: 48 [ 400/781 ( 51%)]  Loss:  4.284361 (3.9800)  Time: 0.848s,  150.93/s  (0.891s,  143.67/s)  LR: 3.863e-04  Data: 0.008 (0.008)
2024-04-07 07:15:04,267 - train - INFO - Train: 48 [ 450/781 ( 58%)]  Loss:  3.698848 (3.9856)  Time: 0.789s,  162.31/s  (0.890s,  143.85/s)  LR: 3.863e-04  Data: 0.008 (0.008)
2024-04-07 07:15:48,006 - train - INFO - Train: 48 [ 500/781 ( 64%)]  Loss:  4.216451 (3.9975)  Time: 0.765s,  167.36/s  (0.888s,  144.09/s)  LR: 3.863e-04  Data: 0.005 (0.008)
2024-04-07 07:16:31,724 - train - INFO - Train: 48 [ 550/781 ( 71%)]  Loss:  4.038229 (4.0003)  Time: 0.847s,  151.05/s  (0.887s,  144.30/s)  LR: 3.863e-04  Data: 0.009 (0.008)
2024-04-07 07:17:14,943 - train - INFO - Train: 48 [ 600/781 ( 77%)]  Loss:  4.144515 (3.9980)  Time: 0.761s,  168.10/s  (0.885s,  144.61/s)  LR: 3.863e-04  Data: 0.005 (0.008)
2024-04-07 07:17:58,489 - train - INFO - Train: 48 [ 650/781 ( 83%)]  Loss:  4.183136 (3.9998)  Time: 0.833s,  153.64/s  (0.884s,  144.79/s)  LR: 3.863e-04  Data: 0.005 (0.008)
2024-04-07 07:18:41,587 - train - INFO - Train: 48 [ 700/781 ( 90%)]  Loss:  3.920504 (4.0029)  Time: 0.782s,  163.62/s  (0.882s,  145.04/s)  LR: 3.863e-04  Data: 0.005 (0.008)
2024-04-07 07:19:25,718 - train - INFO - Train: 48 [ 750/781 ( 96%)]  Loss:  3.728534 (3.9969)  Time: 0.828s,  154.67/s  (0.882s,  145.04/s)  LR: 3.863e-04  Data: 0.007 (0.008)
2024-04-07 07:19:51,629 - train - INFO - Train: 48 [ 780/781 (100%)]  Loss:  4.621226 (3.9962)  Time: 1.095s,  116.90/s  (0.882s,  145.16/s)  LR: 3.863e-04  Data: 0.000 (0.008)
2024-04-07 07:19:51,630 - train - INFO - True
2024-04-07 07:19:51,632 - train - INFO - alphas:tensor([0.1201, 0.0764, 0.1498, 0.2968, 0.3568], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,657 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,657 - train - INFO - True
2024-04-07 07:19:51,658 - train - INFO - alphas:tensor([0.2277, 0.0521, 0.0795, 0.1802, 0.4604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,679 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,679 - train - INFO - True
2024-04-07 07:19:51,680 - train - INFO - alphas:tensor([0.6836, 0.0831, 0.0590, 0.0798, 0.0945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,715 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,715 - train - INFO - True
2024-04-07 07:19:51,716 - train - INFO - alphas:tensor([0.5759, 0.0517, 0.0637, 0.1206, 0.1880], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,745 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,745 - train - INFO - True
2024-04-07 07:19:51,746 - train - INFO - alphas:tensor([0.4083, 0.0414, 0.0833, 0.1645, 0.3026], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,772 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,772 - train - INFO - True
2024-04-07 07:19:51,773 - train - INFO - alphas:tensor([0.5314, 0.0447, 0.0641, 0.1259, 0.2339], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,797 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,797 - train - INFO - True
2024-04-07 07:19:51,798 - train - INFO - alphas:tensor([0.6875, 0.0571, 0.0427, 0.0839, 0.1288], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,819 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,820 - train - INFO - True
2024-04-07 07:19:51,820 - train - INFO - alphas:tensor([0.5357, 0.0458, 0.0455, 0.1244, 0.2487], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,841 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,841 - train - INFO - True
2024-04-07 07:19:51,841 - train - INFO - alphas:tensor([0.4690, 0.0376, 0.0676, 0.1427, 0.2831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,860 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,860 - train - INFO - True
2024-04-07 07:19:51,861 - train - INFO - alphas:tensor([0.5818, 0.0397, 0.0596, 0.1065, 0.2124], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,879 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,879 - train - INFO - True
2024-04-07 07:19:51,880 - train - INFO - alphas:tensor([0.5950, 0.0427, 0.0478, 0.1077, 0.2068], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,897 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,897 - train - INFO - True
2024-04-07 07:19:51,898 - train - INFO - alphas:tensor([0.4727, 0.0295, 0.0438, 0.1400, 0.3140], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,918 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,918 - train - INFO - True
2024-04-07 07:19:51,919 - train - INFO - alphas:tensor([0.4828, 0.0306, 0.0574, 0.1385, 0.2907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,939 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,939 - train - INFO - True
2024-04-07 07:19:51,940 - train - INFO - alphas:tensor([0.5777, 0.0271, 0.0506, 0.1051, 0.2396], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,959 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,959 - train - INFO - True
2024-04-07 07:19:51,960 - train - INFO - alphas:tensor([0.5173, 0.0471, 0.0448, 0.1196, 0.2714], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,978 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,978 - train - INFO - True
2024-04-07 07:19:51,978 - train - INFO - alphas:tensor([0.3919, 0.0219, 0.0314, 0.1348, 0.4200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:51,987 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:51,987 - train - INFO - True
2024-04-07 07:19:51,988 - train - INFO - alphas:tensor([0.4652, 0.0292, 0.0535, 0.1387, 0.3134], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,004 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,004 - train - INFO - True
2024-04-07 07:19:52,005 - train - INFO - alphas:tensor([0.5738, 0.0246, 0.0487, 0.1055, 0.2474], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,021 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,021 - train - INFO - True
2024-04-07 07:19:52,022 - train - INFO - alphas:tensor([0.5292, 0.0331, 0.0402, 0.1187, 0.2788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,037 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,038 - train - INFO - True
2024-04-07 07:19:52,038 - train - INFO - alphas:tensor([0.3888, 0.0189, 0.0271, 0.1262, 0.4390], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,048 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,048 - train - INFO - True
2024-04-07 07:19:52,048 - train - INFO - alphas:tensor([0.4130, 0.0228, 0.0548, 0.1500, 0.3594], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,069 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,069 - train - INFO - True
2024-04-07 07:19:52,070 - train - INFO - alphas:tensor([0.5634, 0.0226, 0.0461, 0.1021, 0.2658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,088 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,088 - train - INFO - True
2024-04-07 07:19:52,089 - train - INFO - alphas:tensor([0.5584, 0.0388, 0.0373, 0.1063, 0.2593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,107 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,107 - train - INFO - True
2024-04-07 07:19:52,107 - train - INFO - alphas:tensor([0.4079, 0.0156, 0.0227, 0.1152, 0.4386], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,116 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,116 - train - INFO - True
2024-04-07 07:19:52,117 - train - INFO - alphas:tensor([0.4033, 0.0195, 0.0519, 0.1486, 0.3767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,133 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,133 - train - INFO - True
2024-04-07 07:19:52,134 - train - INFO - alphas:tensor([0.5523, 0.0214, 0.0447, 0.0948, 0.2868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,150 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,150 - train - INFO - True
2024-04-07 07:19:52,150 - train - INFO - alphas:tensor([0.5817, 0.0255, 0.0331, 0.1005, 0.2593], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,169 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,170 - train - INFO - True
2024-04-07 07:19:52,170 - train - INFO - alphas:tensor([0.4365, 0.0157, 0.0212, 0.1099, 0.4167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,190 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,191 - train - INFO - True
2024-04-07 07:19:52,191 - train - INFO - alphas:tensor([0.3762, 0.0162, 0.0507, 0.1531, 0.4037], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,201 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,201 - train - INFO - True
2024-04-07 07:19:52,202 - train - INFO - alphas:tensor([0.5198, 0.0172, 0.0414, 0.1060, 0.3156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,220 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,220 - train - INFO - True
2024-04-07 07:19:52,221 - train - INFO - alphas:tensor([0.6030, 0.0243, 0.0308, 0.0912, 0.2506], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,238 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,238 - train - INFO - True
2024-04-07 07:19:52,239 - train - INFO - alphas:tensor([0.4816, 0.0150, 0.0252, 0.1147, 0.3635], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,256 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,256 - train - INFO - True
2024-04-07 07:19:52,256 - train - INFO - alphas:tensor([0.3491, 0.0147, 0.0494, 0.1505, 0.4364], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,265 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,265 - train - INFO - True
2024-04-07 07:19:52,265 - train - INFO - alphas:tensor([0.4721, 0.0146, 0.0385, 0.1064, 0.3684], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,287 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,287 - train - INFO - True
2024-04-07 07:19:52,287 - train - INFO - alphas:tensor([0.5851, 0.0268, 0.0302, 0.1009, 0.2570], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,307 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,307 - train - INFO - True
2024-04-07 07:19:52,308 - train - INFO - alphas:tensor([0.4938, 0.0152, 0.0290, 0.1198, 0.3423], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,326 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,326 - train - INFO - True
2024-04-07 07:19:52,327 - train - INFO - alphas:tensor([0.7014, 0.0489, 0.0987, 0.1509], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:19:52,344 - train - INFO - tau:0.6298236312032323
2024-04-07 07:19:52,344 - train - INFO - avg block size:3.8378378378378377
2024-04-07 07:19:52,345 - train - INFO - current latency ratio:tensor(0.8046)
2024-04-07 07:19:52,345 - train - INFO - lasso_alpha:8.140274938683991e-05
2024-04-07 07:19:52,594 - train - INFO - Test: [   0/78]  Time: 0.246 (0.246)  Loss:  0.9595 (0.9595)  Acc@1: 80.4688 (80.4688)  Acc@5: 91.4062 (91.4062)
2024-04-07 07:19:57,018 - train - INFO - Test: [  50/78]  Time: 0.085 (0.092)  Loss:  1.8018 (1.7037)  Acc@1: 58.5938 (59.5435)  Acc@5: 82.8125 (82.8585)
2024-04-07 07:19:59,380 - train - INFO - Test: [  78/78]  Time: 0.056 (0.089)  Loss:  1.8047 (1.7233)  Acc@1: 56.2500 (59.1000)  Acc@5: 81.2500 (82.4800)
2024-04-07 07:20:00,621 - train - INFO - Train: 49 [   0/781 (  0%)]  Loss:  4.060254 (4.0603)  Time: 1.171s,  109.28/s  (1.171s,  109.28/s)  LR: 3.819e-04  Data: 0.182 (0.182)
2024-04-07 07:20:43,367 - train - INFO - Train: 49 [  50/781 (  6%)]  Loss:  4.158475 (3.9900)  Time: 0.836s,  153.11/s  (0.861s,  148.65/s)  LR: 3.819e-04  Data: 0.008 (0.011)
2024-04-07 07:21:26,609 - train - INFO - Train: 49 [ 100/781 ( 13%)]  Loss:  4.381245 (3.9883)  Time: 0.788s,  162.40/s  (0.863s,  148.33/s)  LR: 3.819e-04  Data: 0.004 (0.009)
2024-04-07 07:22:10,510 - train - INFO - Train: 49 [ 150/781 ( 19%)]  Loss:  3.987555 (4.0228)  Time: 0.833s,  153.72/s  (0.868s,  147.48/s)  LR: 3.819e-04  Data: 0.008 (0.009)
2024-04-07 07:22:53,294 - train - INFO - Train: 49 [ 200/781 ( 26%)]  Loss:  4.185773 (4.0235)  Time: 0.837s,  152.84/s  (0.865s,  148.00/s)  LR: 3.819e-04  Data: 0.008 (0.008)
2024-04-07 07:23:35,902 - train - INFO - Train: 49 [ 250/781 ( 32%)]  Loss:  4.532688 (4.0227)  Time: 0.835s,  153.33/s  (0.862s,  148.43/s)  LR: 3.819e-04  Data: 0.008 (0.008)
2024-04-07 07:24:20,167 - train - INFO - Train: 49 [ 300/781 ( 38%)]  Loss:  4.486804 (4.0351)  Time: 0.856s,  149.46/s  (0.866s,  147.78/s)  LR: 3.819e-04  Data: 0.009 (0.008)
2024-04-07 07:25:05,007 - train - INFO - Train: 49 [ 350/781 ( 45%)]  Loss:  4.120813 (4.0226)  Time: 0.835s,  153.28/s  (0.871s,  147.04/s)  LR: 3.819e-04  Data: 0.008 (0.008)
2024-04-07 07:25:49,698 - train - INFO - Train: 49 [ 400/781 ( 51%)]  Loss:  4.213243 (4.0309)  Time: 1.030s,  124.31/s  (0.873s,  146.55/s)  LR: 3.819e-04  Data: 0.007 (0.008)
2024-04-07 07:26:33,193 - train - INFO - Train: 49 [ 450/781 ( 58%)]  Loss:  4.238441 (4.0344)  Time: 0.832s,  153.91/s  (0.873s,  146.62/s)  LR: 3.819e-04  Data: 0.008 (0.008)
2024-04-07 07:27:16,695 - train - INFO - Train: 49 [ 500/781 ( 64%)]  Loss:  4.464859 (4.0398)  Time: 0.855s,  149.78/s  (0.873s,  146.67/s)  LR: 3.819e-04  Data: 0.008 (0.008)
2024-04-07 07:27:59,420 - train - INFO - Train: 49 [ 550/781 ( 71%)]  Loss:  4.431078 (4.0394)  Time: 1.028s,  124.49/s  (0.871s,  146.95/s)  LR: 3.819e-04  Data: 0.005 (0.008)
2024-04-07 07:28:42,586 - train - INFO - Train: 49 [ 600/781 ( 77%)]  Loss:  4.384437 (4.0375)  Time: 0.842s,  152.05/s  (0.870s,  147.06/s)  LR: 3.819e-04  Data: 0.008 (0.008)
2024-04-07 07:29:31,121 - train - INFO - Train: 49 [ 650/781 ( 83%)]  Loss:  3.544401 (4.0355)  Time: 1.055s,  121.32/s  (0.878s,  145.77/s)  LR: 3.819e-04  Data: 0.007 (0.008)
2024-04-07 07:30:16,064 - train - INFO - Train: 49 [ 700/781 ( 90%)]  Loss:  4.133445 (4.0373)  Time: 1.055s,  121.29/s  (0.880s,  145.52/s)  LR: 3.819e-04  Data: 0.009 (0.008)
2024-04-07 07:31:03,214 - train - INFO - Train: 49 [ 750/781 ( 96%)]  Loss:  4.388834 (4.0333)  Time: 0.862s,  148.44/s  (0.884s,  144.83/s)  LR: 3.819e-04  Data: 0.009 (0.008)
2024-04-07 07:31:31,532 - train - INFO - Train: 49 [ 780/781 (100%)]  Loss:  4.352837 (4.0312)  Time: 1.095s,  116.86/s  (0.886s,  144.45/s)  LR: 3.819e-04  Data: 0.000 (0.008)
2024-04-07 07:31:31,533 - train - INFO - True
2024-04-07 07:31:31,535 - train - INFO - alphas:tensor([0.1123, 0.0727, 0.1477, 0.3025, 0.3648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,549 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,549 - train - INFO - True
2024-04-07 07:31:31,550 - train - INFO - alphas:tensor([0.2198, 0.0502, 0.0776, 0.1799, 0.4725], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,565 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,565 - train - INFO - True
2024-04-07 07:31:31,566 - train - INFO - alphas:tensor([0.6762, 0.0844, 0.0599, 0.0819, 0.0976], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,594 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,594 - train - INFO - True
2024-04-07 07:31:31,595 - train - INFO - alphas:tensor([0.5650, 0.0511, 0.0639, 0.1239, 0.1961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,624 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,624 - train - INFO - True
2024-04-07 07:31:31,625 - train - INFO - alphas:tensor([0.4012, 0.0398, 0.0825, 0.1653, 0.3112], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,653 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,653 - train - INFO - True
2024-04-07 07:31:31,654 - train - INFO - alphas:tensor([0.5246, 0.0427, 0.0634, 0.1271, 0.2421], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,682 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,682 - train - INFO - True
2024-04-07 07:31:31,683 - train - INFO - alphas:tensor([0.6750, 0.0574, 0.0432, 0.0875, 0.1368], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,712 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,712 - train - INFO - True
2024-04-07 07:31:31,713 - train - INFO - alphas:tensor([0.5196, 0.0450, 0.0446, 0.1274, 0.2635], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,741 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,741 - train - INFO - True
2024-04-07 07:31:31,742 - train - INFO - alphas:tensor([0.4597, 0.0360, 0.0669, 0.1440, 0.2933], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,770 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,770 - train - INFO - True
2024-04-07 07:31:31,771 - train - INFO - alphas:tensor([0.5768, 0.0379, 0.0590, 0.1069, 0.2193], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,799 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,799 - train - INFO - True
2024-04-07 07:31:31,800 - train - INFO - alphas:tensor([0.5857, 0.0415, 0.0470, 0.1097, 0.2160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,828 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,829 - train - INFO - True
2024-04-07 07:31:31,830 - train - INFO - alphas:tensor([0.4648, 0.0278, 0.0419, 0.1404, 0.3251], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,858 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,858 - train - INFO - True
2024-04-07 07:31:31,859 - train - INFO - alphas:tensor([0.4761, 0.0292, 0.0562, 0.1389, 0.2995], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,887 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,887 - train - INFO - True
2024-04-07 07:31:31,888 - train - INFO - alphas:tensor([0.5735, 0.0255, 0.0494, 0.1044, 0.2473], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,916 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,916 - train - INFO - True
2024-04-07 07:31:31,917 - train - INFO - alphas:tensor([0.5050, 0.0458, 0.0437, 0.1218, 0.2838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,947 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,947 - train - INFO - True
2024-04-07 07:31:31,948 - train - INFO - alphas:tensor([0.3795, 0.0208, 0.0298, 0.1352, 0.4347], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,962 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,962 - train - INFO - True
2024-04-07 07:31:31,963 - train - INFO - alphas:tensor([0.4590, 0.0279, 0.0525, 0.1389, 0.3218], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:31,991 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:31,992 - train - INFO - True
2024-04-07 07:31:31,992 - train - INFO - alphas:tensor([0.5657, 0.0230, 0.0475, 0.1057, 0.2581], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,021 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,021 - train - INFO - True
2024-04-07 07:31:32,022 - train - INFO - alphas:tensor([0.5162, 0.0313, 0.0391, 0.1204, 0.2929], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,050 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,050 - train - INFO - True
2024-04-07 07:31:32,051 - train - INFO - alphas:tensor([0.3774, 0.0179, 0.0256, 0.1260, 0.4532], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,065 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,065 - train - INFO - True
2024-04-07 07:31:32,066 - train - INFO - alphas:tensor([0.4075, 0.0215, 0.0529, 0.1496, 0.3685], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,094 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,094 - train - INFO - True
2024-04-07 07:31:32,095 - train - INFO - alphas:tensor([0.5572, 0.0214, 0.0445, 0.1017, 0.2751], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,122 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,123 - train - INFO - True
2024-04-07 07:31:32,123 - train - INFO - alphas:tensor([0.5431, 0.0372, 0.0365, 0.1084, 0.2749], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,148 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,148 - train - INFO - True
2024-04-07 07:31:32,149 - train - INFO - alphas:tensor([0.3951, 0.0147, 0.0213, 0.1148, 0.4541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,161 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,161 - train - INFO - True
2024-04-07 07:31:32,162 - train - INFO - alphas:tensor([0.3933, 0.0183, 0.0504, 0.1485, 0.3895], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,184 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,184 - train - INFO - True
2024-04-07 07:31:32,184 - train - INFO - alphas:tensor([0.5401, 0.0204, 0.0439, 0.0951, 0.3005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,205 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,205 - train - INFO - True
2024-04-07 07:31:32,205 - train - INFO - alphas:tensor([0.5713, 0.0242, 0.0320, 0.1016, 0.2708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,225 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,225 - train - INFO - True
2024-04-07 07:31:32,225 - train - INFO - alphas:tensor([0.4230, 0.0148, 0.0197, 0.1099, 0.4327], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,235 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,235 - train - INFO - True
2024-04-07 07:31:32,235 - train - INFO - alphas:tensor([0.3657, 0.0150, 0.0494, 0.1528, 0.4171], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,244 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,244 - train - INFO - True
2024-04-07 07:31:32,245 - train - INFO - alphas:tensor([0.5066, 0.0158, 0.0401, 0.1057, 0.3319], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,265 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,265 - train - INFO - True
2024-04-07 07:31:32,265 - train - INFO - alphas:tensor([0.5911, 0.0230, 0.0296, 0.0925, 0.2638], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,286 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,286 - train - INFO - True
2024-04-07 07:31:32,286 - train - INFO - alphas:tensor([0.4693, 0.0140, 0.0238, 0.1143, 0.3784], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,305 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,305 - train - INFO - True
2024-04-07 07:31:32,306 - train - INFO - alphas:tensor([0.3447, 0.0139, 0.0471, 0.1476, 0.4468], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,315 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,315 - train - INFO - True
2024-04-07 07:31:32,316 - train - INFO - alphas:tensor([0.4626, 0.0132, 0.0368, 0.1050, 0.3823], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,333 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,333 - train - INFO - True
2024-04-07 07:31:32,334 - train - INFO - alphas:tensor([0.5770, 0.0256, 0.0291, 0.1016, 0.2667], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,350 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,351 - train - INFO - True
2024-04-07 07:31:32,351 - train - INFO - alphas:tensor([0.4835, 0.0141, 0.0277, 0.1202, 0.3546], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,368 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,368 - train - INFO - True
2024-04-07 07:31:32,369 - train - INFO - alphas:tensor([0.6988, 0.0485, 0.0994, 0.1532], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:31:32,385 - train - INFO - tau:0.6235253948912
2024-04-07 07:31:32,385 - train - INFO - avg block size:4.243243243243243
2024-04-07 07:31:32,386 - train - INFO - current latency ratio:tensor(0.7796)
2024-04-07 07:31:32,645 - train - INFO - Test: [   0/78]  Time: 0.256 (0.256)  Loss:  1.0605 (1.0605)  Acc@1: 78.9062 (78.9062)  Acc@5: 90.6250 (90.6250)
2024-04-07 07:31:37,222 - train - INFO - Test: [  50/78]  Time: 0.086 (0.095)  Loss:  1.8916 (1.6934)  Acc@1: 56.2500 (60.1716)  Acc@5: 79.6875 (82.8278)
2024-04-07 07:31:39,657 - train - INFO - Test: [  78/78]  Time: 0.058 (0.092)  Loss:  1.7354 (1.7186)  Acc@1: 50.0000 (59.7200)  Acc@5: 87.5000 (82.5100)
2024-04-07 07:31:40,983 - train - INFO - Train: 50 [   0/781 (  0%)]  Loss:  4.300737 (4.3007)  Time: 1.255s,  101.96/s  (1.255s,  101.96/s)  LR: 3.775e-04  Data: 0.183 (0.183)
2024-04-07 07:32:26,051 - train - INFO - Train: 50 [  50/781 (  6%)]  Loss:  4.400152 (4.1221)  Time: 0.831s,  153.94/s  (0.908s,  140.93/s)  LR: 3.775e-04  Data: 0.009 (0.011)
2024-04-07 07:33:11,896 - train - INFO - Train: 50 [ 100/781 ( 13%)]  Loss:  3.845752 (4.0534)  Time: 0.936s,  136.73/s  (0.913s,  140.27/s)  LR: 3.775e-04  Data: 0.010 (0.010)
2024-04-07 07:33:56,279 - train - INFO - Train: 50 [ 150/781 ( 19%)]  Loss:  3.625955 (4.0055)  Time: 0.802s,  159.63/s  (0.904s,  141.55/s)  LR: 3.775e-04  Data: 0.005 (0.009)
2024-04-07 07:34:40,826 - train - INFO - Train: 50 [ 200/781 ( 26%)]  Loss:  4.338736 (4.0126)  Time: 1.086s,  117.88/s  (0.901s,  142.07/s)  LR: 3.775e-04  Data: 0.008 (0.009)
2024-04-07 07:35:27,105 - train - INFO - Train: 50 [ 250/781 ( 32%)]  Loss:  4.103993 (4.0140)  Time: 0.819s,  156.21/s  (0.906s,  141.30/s)  LR: 3.775e-04  Data: 0.006 (0.008)
2024-04-07 07:36:12,507 - train - INFO - Train: 50 [ 300/781 ( 38%)]  Loss:  3.549921 (3.9904)  Time: 0.816s,  156.90/s  (0.906s,  141.25/s)  LR: 3.775e-04  Data: 0.005 (0.008)
2024-04-07 07:36:57,935 - train - INFO - Train: 50 [ 350/781 ( 45%)]  Loss:  3.744077 (3.9994)  Time: 0.801s,  159.83/s  (0.907s,  141.20/s)  LR: 3.775e-04  Data: 0.005 (0.008)
2024-04-07 07:37:42,256 - train - INFO - Train: 50 [ 400/781 ( 51%)]  Loss:  3.570733 (4.0027)  Time: 1.027s,  124.60/s  (0.904s,  141.59/s)  LR: 3.775e-04  Data: 0.005 (0.008)
2024-04-07 07:38:28,065 - train - INFO - Train: 50 [ 450/781 ( 58%)]  Loss:  4.359113 (4.0099)  Time: 0.869s,  147.29/s  (0.905s,  141.38/s)  LR: 3.775e-04  Data: 0.009 (0.008)
2024-04-07 07:39:14,163 - train - INFO - Train: 50 [ 500/781 ( 64%)]  Loss:  4.320090 (4.0114)  Time: 0.815s,  156.96/s  (0.907s,  141.12/s)  LR: 3.775e-04  Data: 0.008 (0.008)
2024-04-07 07:40:00,499 - train - INFO - Train: 50 [ 550/781 ( 71%)]  Loss:  3.540635 (4.0109)  Time: 1.125s,  113.77/s  (0.909s,  140.84/s)  LR: 3.775e-04  Data: 0.005 (0.008)
2024-04-07 07:40:47,889 - train - INFO - Train: 50 [ 600/781 ( 77%)]  Loss:  4.273601 (4.0098)  Time: 0.838s,  152.66/s  (0.912s,  140.34/s)  LR: 3.775e-04  Data: 0.007 (0.008)
2024-04-07 07:41:31,753 - train - INFO - Train: 50 [ 650/781 ( 83%)]  Loss:  4.577653 (4.0146)  Time: 0.958s,  133.66/s  (0.909s,  140.76/s)  LR: 3.775e-04  Data: 0.009 (0.008)
2024-04-07 07:42:15,756 - train - INFO - Train: 50 [ 700/781 ( 90%)]  Loss:  4.451934 (4.0160)  Time: 1.052s,  121.65/s  (0.907s,  141.08/s)  LR: 3.775e-04  Data: 0.009 (0.008)
2024-04-07 07:43:03,145 - train - INFO - Train: 50 [ 750/781 ( 96%)]  Loss:  4.022217 (4.0235)  Time: 0.799s,  160.22/s  (0.910s,  140.66/s)  LR: 3.775e-04  Data: 0.005 (0.008)
2024-04-07 07:43:29,962 - train - INFO - Train: 50 [ 780/781 (100%)]  Loss:  3.436900 (4.0270)  Time: 0.825s,  155.14/s  (0.909s,  140.76/s)  LR: 3.775e-04  Data: 0.000 (0.008)
2024-04-07 07:43:29,963 - train - INFO - True
2024-04-07 07:43:29,965 - train - INFO - alphas:tensor([0.1045, 0.0689, 0.1435, 0.3095, 0.3735], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:29,981 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:29,982 - train - INFO - True
2024-04-07 07:43:29,983 - train - INFO - alphas:tensor([0.2127, 0.0483, 0.0765, 0.1794, 0.4831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:29,998 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:29,998 - train - INFO - True
2024-04-07 07:43:29,999 - train - INFO - alphas:tensor([0.6710, 0.0849, 0.0603, 0.0836, 0.1001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,026 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,026 - train - INFO - True
2024-04-07 07:43:30,027 - train - INFO - alphas:tensor([0.5580, 0.0502, 0.0638, 0.1254, 0.2026], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,051 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,051 - train - INFO - True
2024-04-07 07:43:30,052 - train - INFO - alphas:tensor([0.3922, 0.0383, 0.0822, 0.1666, 0.3208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,074 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,074 - train - INFO - True
2024-04-07 07:43:30,075 - train - INFO - alphas:tensor([0.5148, 0.0409, 0.0626, 0.1283, 0.2534], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,096 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,096 - train - INFO - True
2024-04-07 07:43:30,096 - train - INFO - alphas:tensor([0.6698, 0.0564, 0.0428, 0.0894, 0.1416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,116 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,116 - train - INFO - True
2024-04-07 07:43:30,117 - train - INFO - alphas:tensor([0.5148, 0.0433, 0.0427, 0.1273, 0.2719], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,135 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,135 - train - INFO - True
2024-04-07 07:43:30,136 - train - INFO - alphas:tensor([0.4564, 0.0345, 0.0654, 0.1439, 0.2999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,153 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,153 - train - INFO - True
2024-04-07 07:43:30,155 - train - INFO - alphas:tensor([0.5708, 0.0366, 0.0583, 0.1072, 0.2271], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,172 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,172 - train - INFO - True
2024-04-07 07:43:30,173 - train - INFO - alphas:tensor([0.5753, 0.0409, 0.0463, 0.1119, 0.2255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,191 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,191 - train - INFO - True
2024-04-07 07:43:30,191 - train - INFO - alphas:tensor([0.4552, 0.0266, 0.0401, 0.1409, 0.3371], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,208 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,208 - train - INFO - True
2024-04-07 07:43:30,209 - train - INFO - alphas:tensor([0.4673, 0.0280, 0.0556, 0.1400, 0.3092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,226 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,226 - train - INFO - True
2024-04-07 07:43:30,226 - train - INFO - alphas:tensor([0.5656, 0.0242, 0.0483, 0.1047, 0.2571], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,243 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,243 - train - INFO - True
2024-04-07 07:43:30,244 - train - INFO - alphas:tensor([0.4985, 0.0447, 0.0422, 0.1218, 0.2928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,260 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,260 - train - INFO - True
2024-04-07 07:43:30,261 - train - INFO - alphas:tensor([0.3713, 0.0199, 0.0281, 0.1349, 0.4459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,269 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,270 - train - INFO - True
2024-04-07 07:43:30,270 - train - INFO - alphas:tensor([0.4528, 0.0265, 0.0511, 0.1386, 0.3310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,287 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,287 - train - INFO - True
2024-04-07 07:43:30,288 - train - INFO - alphas:tensor([0.5596, 0.0216, 0.0459, 0.1051, 0.2677], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,304 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,304 - train - INFO - True
2024-04-07 07:43:30,305 - train - INFO - alphas:tensor([0.5060, 0.0303, 0.0380, 0.1223, 0.3034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,322 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,322 - train - INFO - True
2024-04-07 07:43:30,323 - train - INFO - alphas:tensor([0.3692, 0.0172, 0.0239, 0.1247, 0.4650], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,331 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,331 - train - INFO - True
2024-04-07 07:43:30,332 - train - INFO - alphas:tensor([0.3998, 0.0205, 0.0516, 0.1492, 0.3790], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,349 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,349 - train - INFO - True
2024-04-07 07:43:30,349 - train - INFO - alphas:tensor([0.5516, 0.0202, 0.0433, 0.1004, 0.2845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,366 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,366 - train - INFO - True
2024-04-07 07:43:30,367 - train - INFO - alphas:tensor([0.5385, 0.0356, 0.0349, 0.1079, 0.2831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,383 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,383 - train - INFO - True
2024-04-07 07:43:30,384 - train - INFO - alphas:tensor([0.3910, 0.0139, 0.0197, 0.1134, 0.4621], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,393 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,393 - train - INFO - True
2024-04-07 07:43:30,393 - train - INFO - alphas:tensor([0.3852, 0.0172, 0.0483, 0.1476, 0.4016], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,402 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,402 - train - INFO - True
2024-04-07 07:43:30,403 - train - INFO - alphas:tensor([0.5322, 0.0191, 0.0423, 0.0944, 0.3121], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,419 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,419 - train - INFO - True
2024-04-07 07:43:30,420 - train - INFO - alphas:tensor([0.5612, 0.0230, 0.0312, 0.1021, 0.2824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,437 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,437 - train - INFO - True
2024-04-07 07:43:30,437 - train - INFO - alphas:tensor([0.4178, 0.0138, 0.0183, 0.1078, 0.4422], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,446 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,446 - train - INFO - True
2024-04-07 07:43:30,447 - train - INFO - alphas:tensor([0.3588, 0.0141, 0.0472, 0.1509, 0.4290], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,455 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,455 - train - INFO - True
2024-04-07 07:43:30,456 - train - INFO - alphas:tensor([0.4981, 0.0147, 0.0388, 0.1044, 0.3439], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,473 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,473 - train - INFO - True
2024-04-07 07:43:30,473 - train - INFO - alphas:tensor([0.5850, 0.0220, 0.0284, 0.0922, 0.2724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,490 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,490 - train - INFO - True
2024-04-07 07:43:30,491 - train - INFO - alphas:tensor([0.4649, 0.0131, 0.0220, 0.1124, 0.3876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,507 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,507 - train - INFO - True
2024-04-07 07:43:30,508 - train - INFO - alphas:tensor([0.3346, 0.0130, 0.0453, 0.1467, 0.4604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,516 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,516 - train - INFO - True
2024-04-07 07:43:30,517 - train - INFO - alphas:tensor([0.4539, 0.0123, 0.0350, 0.1025, 0.3963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,534 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,534 - train - INFO - True
2024-04-07 07:43:30,535 - train - INFO - alphas:tensor([0.5705, 0.0244, 0.0279, 0.1018, 0.2753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,551 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,551 - train - INFO - True
2024-04-07 07:43:30,552 - train - INFO - alphas:tensor([0.4783, 0.0130, 0.0261, 0.1186, 0.3641], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,568 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,568 - train - INFO - True
2024-04-07 07:43:30,569 - train - INFO - alphas:tensor([0.6976, 0.0478, 0.0993, 0.1552], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:43:30,586 - train - INFO - tau:0.617290140942288
2024-04-07 07:43:30,586 - train - INFO - avg block size:4.648648648648648
2024-04-07 07:43:30,586 - train - INFO - current latency ratio:tensor(0.7442)
2024-04-07 07:43:30,586 - train - INFO - lasso_alpha:8.954302432552392e-05
2024-04-07 07:43:30,813 - train - INFO - Test: [   0/78]  Time: 0.224 (0.224)  Loss:  0.9829 (0.9829)  Acc@1: 82.0312 (82.0312)  Acc@5: 91.4062 (91.4062)
2024-04-07 07:43:35,179 - train - INFO - Test: [  50/78]  Time: 0.089 (0.090)  Loss:  1.7891 (1.7075)  Acc@1: 59.3750 (59.9877)  Acc@5: 82.0312 (82.9657)
2024-04-07 07:43:37,853 - train - INFO - Test: [  78/78]  Time: 0.059 (0.092)  Loss:  1.8818 (1.7302)  Acc@1: 56.2500 (59.8000)  Acc@5: 81.2500 (82.4900)
2024-04-07 07:43:39,199 - train - INFO - Train: 51 [   0/781 (  0%)]  Loss:  3.861849 (3.8618)  Time: 1.280s,   99.98/s  (1.280s,   99.98/s)  LR: 3.730e-04  Data: 0.195 (0.195)
2024-04-07 07:44:24,881 - train - INFO - Train: 51 [  50/781 (  6%)]  Loss:  4.549621 (3.9362)  Time: 1.057s,  121.15/s  (0.921s,  139.01/s)  LR: 3.730e-04  Data: 0.006 (0.010)
2024-04-07 07:45:09,849 - train - INFO - Train: 51 [ 100/781 ( 13%)]  Loss:  4.393599 (3.9930)  Time: 0.898s,  142.56/s  (0.910s,  140.63/s)  LR: 3.730e-04  Data: 0.006 (0.009)
2024-04-07 07:45:55,608 - train - INFO - Train: 51 [ 150/781 ( 19%)]  Loss:  4.454542 (4.0240)  Time: 0.878s,  145.86/s  (0.912s,  140.38/s)  LR: 3.730e-04  Data: 0.006 (0.008)
2024-04-07 07:46:40,145 - train - INFO - Train: 51 [ 200/781 ( 26%)]  Loss:  4.207700 (4.0311)  Time: 0.798s,  160.44/s  (0.907s,  141.19/s)  LR: 3.730e-04  Data: 0.005 (0.008)
2024-04-07 07:47:25,025 - train - INFO - Train: 51 [ 250/781 ( 32%)]  Loss:  3.327982 (4.0240)  Time: 0.990s,  129.35/s  (0.905s,  141.47/s)  LR: 3.730e-04  Data: 0.005 (0.008)
2024-04-07 07:48:10,010 - train - INFO - Train: 51 [ 300/781 ( 38%)]  Loss:  3.818226 (4.0267)  Time: 0.803s,  159.40/s  (0.904s,  141.61/s)  LR: 3.730e-04  Data: 0.008 (0.008)
2024-04-07 07:48:55,022 - train - INFO - Train: 51 [ 350/781 ( 45%)]  Loss:  3.420741 (4.0151)  Time: 0.831s,  154.01/s  (0.903s,  141.69/s)  LR: 3.730e-04  Data: 0.008 (0.008)
2024-04-07 07:49:40,818 - train - INFO - Train: 51 [ 400/781 ( 51%)]  Loss:  3.451743 (4.0136)  Time: 0.855s,  149.75/s  (0.905s,  141.44/s)  LR: 3.730e-04  Data: 0.009 (0.008)
2024-04-07 07:50:24,840 - train - INFO - Train: 51 [ 450/781 ( 58%)]  Loss:  3.925101 (4.0211)  Time: 0.804s,  159.27/s  (0.902s,  141.87/s)  LR: 3.730e-04  Data: 0.004 (0.008)
2024-04-07 07:51:11,199 - train - INFO - Train: 51 [ 500/781 ( 64%)]  Loss:  3.625731 (4.0187)  Time: 0.825s,  155.07/s  (0.905s,  141.48/s)  LR: 3.730e-04  Data: 0.006 (0.008)
2024-04-07 07:51:55,207 - train - INFO - Train: 51 [ 550/781 ( 71%)]  Loss:  4.342905 (4.0201)  Time: 1.012s,  126.44/s  (0.902s,  141.83/s)  LR: 3.730e-04  Data: 0.009 (0.008)
2024-04-07 07:52:41,355 - train - INFO - Train: 51 [ 600/781 ( 77%)]  Loss:  4.296702 (4.0280)  Time: 0.950s,  134.71/s  (0.904s,  141.56/s)  LR: 3.730e-04  Data: 0.007 (0.007)
2024-04-07 07:53:26,101 - train - INFO - Train: 51 [ 650/781 ( 83%)]  Loss:  4.490298 (4.0367)  Time: 0.807s,  158.63/s  (0.903s,  141.68/s)  LR: 3.730e-04  Data: 0.005 (0.007)
2024-04-07 07:54:10,820 - train - INFO - Train: 51 [ 700/781 ( 90%)]  Loss:  4.531027 (4.0380)  Time: 0.813s,  157.40/s  (0.903s,  141.78/s)  LR: 3.730e-04  Data: 0.004 (0.007)
2024-04-07 07:54:55,195 - train - INFO - Train: 51 [ 750/781 ( 96%)]  Loss:  4.528352 (4.0374)  Time: 0.798s,  160.42/s  (0.902s,  141.94/s)  LR: 3.730e-04  Data: 0.005 (0.007)
2024-04-07 07:55:21,190 - train - INFO - Train: 51 [ 780/781 (100%)]  Loss:  3.703433 (4.0361)  Time: 0.853s,  150.04/s  (0.900s,  142.15/s)  LR: 3.730e-04  Data: 0.000 (0.007)
2024-04-07 07:55:21,191 - train - INFO - True
2024-04-07 07:55:21,192 - train - INFO - alphas:tensor([0.0976, 0.0656, 0.1406, 0.3149, 0.3813], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,206 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,206 - train - INFO - True
2024-04-07 07:55:21,207 - train - INFO - alphas:tensor([0.2061, 0.0468, 0.0749, 0.1787, 0.4935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,222 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,222 - train - INFO - True
2024-04-07 07:55:21,223 - train - INFO - alphas:tensor([0.6621, 0.0862, 0.0614, 0.0863, 0.1040], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,251 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,251 - train - INFO - True
2024-04-07 07:55:21,252 - train - INFO - alphas:tensor([0.5469, 0.0492, 0.0639, 0.1285, 0.2114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,280 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,280 - train - INFO - True
2024-04-07 07:55:21,281 - train - INFO - alphas:tensor([0.3841, 0.0369, 0.0810, 0.1680, 0.3301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,309 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,309 - train - INFO - True
2024-04-07 07:55:21,310 - train - INFO - alphas:tensor([0.5077, 0.0390, 0.0616, 0.1294, 0.2623], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,338 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,338 - train - INFO - True
2024-04-07 07:55:21,339 - train - INFO - alphas:tensor([0.6582, 0.0563, 0.0431, 0.0931, 0.1493], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,367 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,367 - train - INFO - True
2024-04-07 07:55:21,368 - train - INFO - alphas:tensor([0.5008, 0.0422, 0.0414, 0.1297, 0.2859], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,397 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,397 - train - INFO - True
2024-04-07 07:55:21,398 - train - INFO - alphas:tensor([0.4461, 0.0325, 0.0649, 0.1454, 0.3111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,426 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,426 - train - INFO - True
2024-04-07 07:55:21,427 - train - INFO - alphas:tensor([0.5601, 0.0348, 0.0576, 0.1091, 0.2383], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,455 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,455 - train - INFO - True
2024-04-07 07:55:21,456 - train - INFO - alphas:tensor([0.5640, 0.0397, 0.0460, 0.1140, 0.2364], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,484 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,484 - train - INFO - True
2024-04-07 07:55:21,485 - train - INFO - alphas:tensor([0.4438, 0.0255, 0.0387, 0.1415, 0.3506], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,513 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,513 - train - INFO - True
2024-04-07 07:55:21,514 - train - INFO - alphas:tensor([0.4607, 0.0268, 0.0547, 0.1402, 0.3176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,542 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,543 - train - INFO - True
2024-04-07 07:55:21,544 - train - INFO - alphas:tensor([0.5586, 0.0230, 0.0475, 0.1044, 0.2664], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,572 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,572 - train - INFO - True
2024-04-07 07:55:21,573 - train - INFO - alphas:tensor([0.4861, 0.0433, 0.0410, 0.1241, 0.3055], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,601 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,601 - train - INFO - True
2024-04-07 07:55:21,602 - train - INFO - alphas:tensor([0.3589, 0.0190, 0.0262, 0.1352, 0.4607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,616 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,616 - train - INFO - True
2024-04-07 07:55:21,617 - train - INFO - alphas:tensor([0.4435, 0.0253, 0.0499, 0.1394, 0.3419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,645 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,645 - train - INFO - True
2024-04-07 07:55:21,646 - train - INFO - alphas:tensor([0.5518, 0.0202, 0.0444, 0.1045, 0.2791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,674 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,674 - train - INFO - True
2024-04-07 07:55:21,675 - train - INFO - alphas:tensor([0.4970, 0.0289, 0.0363, 0.1222, 0.3156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,704 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,704 - train - INFO - True
2024-04-07 07:55:21,705 - train - INFO - alphas:tensor([0.3630, 0.0160, 0.0227, 0.1232, 0.4752], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,719 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,719 - train - INFO - True
2024-04-07 07:55:21,720 - train - INFO - alphas:tensor([0.3886, 0.0193, 0.0502, 0.1492, 0.3928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,734 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,734 - train - INFO - True
2024-04-07 07:55:21,735 - train - INFO - alphas:tensor([0.5361, 0.0187, 0.0421, 0.1013, 0.3017], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,763 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,763 - train - INFO - True
2024-04-07 07:55:21,764 - train - INFO - alphas:tensor([0.5242, 0.0342, 0.0338, 0.1100, 0.2978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,791 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,791 - train - INFO - True
2024-04-07 07:55:21,792 - train - INFO - alphas:tensor([0.3792, 0.0129, 0.0184, 0.1114, 0.4780], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,804 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,804 - train - INFO - True
2024-04-07 07:55:21,805 - train - INFO - alphas:tensor([0.3791, 0.0164, 0.0465, 0.1458, 0.4122], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,817 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,817 - train - INFO - True
2024-04-07 07:55:21,818 - train - INFO - alphas:tensor([0.5239, 0.0180, 0.0408, 0.0935, 0.3239], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,840 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,840 - train - INFO - True
2024-04-07 07:55:21,841 - train - INFO - alphas:tensor([0.5508, 0.0219, 0.0298, 0.1032, 0.2943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,862 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,862 - train - INFO - True
2024-04-07 07:55:21,863 - train - INFO - alphas:tensor([0.4084, 0.0130, 0.0169, 0.1052, 0.4565], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,872 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,873 - train - INFO - True
2024-04-07 07:55:21,873 - train - INFO - alphas:tensor([0.3507, 0.0134, 0.0449, 0.1501, 0.4408], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,883 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,883 - train - INFO - True
2024-04-07 07:55:21,884 - train - INFO - alphas:tensor([0.4879, 0.0135, 0.0370, 0.1037, 0.3579], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,905 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,905 - train - INFO - True
2024-04-07 07:55:21,906 - train - INFO - alphas:tensor([0.5733, 0.0210, 0.0274, 0.0934, 0.2849], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,926 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,926 - train - INFO - True
2024-04-07 07:55:21,927 - train - INFO - alphas:tensor([0.4525, 0.0119, 0.0208, 0.1120, 0.4028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,945 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,946 - train - INFO - True
2024-04-07 07:55:21,946 - train - INFO - alphas:tensor([0.3276, 0.0122, 0.0435, 0.1443, 0.4724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,955 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,955 - train - INFO - True
2024-04-07 07:55:21,956 - train - INFO - alphas:tensor([0.4453, 0.0111, 0.0337, 0.1005, 0.4094], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,973 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,974 - train - INFO - True
2024-04-07 07:55:21,974 - train - INFO - alphas:tensor([0.5611, 0.0233, 0.0273, 0.1021, 0.2862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:21,991 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:21,991 - train - INFO - True
2024-04-07 07:55:21,992 - train - INFO - alphas:tensor([0.4672, 0.0120, 0.0246, 0.1185, 0.3778], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:22,008 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:22,008 - train - INFO - True
2024-04-07 07:55:22,009 - train - INFO - alphas:tensor([0.6972, 0.0471, 0.0991, 0.1565], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 07:55:22,030 - train - INFO - tau:0.6111172395328651
2024-04-07 07:55:22,030 - train - INFO - avg block size:5.054054054054054
2024-04-07 07:55:22,030 - train - INFO - current latency ratio:tensor(0.7088)
2024-04-07 07:55:22,284 - train - INFO - Test: [   0/78]  Time: 0.250 (0.250)  Loss:  0.9458 (0.9458)  Acc@1: 81.2500 (81.2500)  Acc@5: 91.4062 (91.4062)
2024-04-07 07:55:27,112 - train - INFO - Test: [  50/78]  Time: 0.089 (0.100)  Loss:  1.9189 (1.6854)  Acc@1: 53.9062 (59.9571)  Acc@5: 80.4688 (83.1036)
2024-04-07 07:55:29,547 - train - INFO - Test: [  78/78]  Time: 0.059 (0.095)  Loss:  1.8076 (1.7175)  Acc@1: 56.2500 (59.5400)  Acc@5: 87.5000 (82.6700)
2024-04-07 07:55:30,747 - train - INFO - Train: 52 [   0/781 (  0%)]  Loss:  3.792369 (3.7924)  Time: 1.129s,  113.38/s  (1.129s,  113.38/s)  LR: 3.685e-04  Data: 0.169 (0.169)
2024-04-07 07:56:16,793 - train - INFO - Train: 52 [  50/781 (  6%)]  Loss:  3.886698 (3.9856)  Time: 0.803s,  159.42/s  (0.925s,  138.38/s)  LR: 3.685e-04  Data: 0.005 (0.011)
2024-04-07 07:57:02,005 - train - INFO - Train: 52 [ 100/781 ( 13%)]  Loss:  3.349511 (4.0037)  Time: 1.020s,  125.44/s  (0.915s,  139.94/s)  LR: 3.685e-04  Data: 0.007 (0.009)
2024-04-07 07:57:48,432 - train - INFO - Train: 52 [ 150/781 ( 19%)]  Loss:  3.744155 (3.9954)  Time: 0.814s,  157.21/s  (0.919s,  139.25/s)  LR: 3.685e-04  Data: 0.009 (0.008)
2024-04-07 07:58:33,697 - train - INFO - Train: 52 [ 200/781 ( 26%)]  Loss:  4.452302 (3.9962)  Time: 0.820s,  156.15/s  (0.916s,  139.78/s)  LR: 3.685e-04  Data: 0.006 (0.008)
2024-04-07 07:59:18,417 - train - INFO - Train: 52 [ 250/781 ( 32%)]  Loss:  4.559838 (4.0199)  Time: 1.083s,  118.19/s  (0.911s,  140.43/s)  LR: 3.685e-04  Data: 0.004 (0.008)
2024-04-07 08:00:03,019 - train - INFO - Train: 52 [ 300/781 ( 38%)]  Loss:  3.606684 (4.0309)  Time: 0.878s,  145.77/s  (0.908s,  140.93/s)  LR: 3.685e-04  Data: 0.008 (0.008)
2024-04-07 08:00:49,556 - train - INFO - Train: 52 [ 350/781 ( 45%)]  Loss:  3.730722 (4.0240)  Time: 1.090s,  117.43/s  (0.911s,  140.44/s)  LR: 3.685e-04  Data: 0.009 (0.008)
2024-04-07 08:01:34,056 - train - INFO - Train: 52 [ 400/781 ( 51%)]  Loss:  4.319188 (4.0257)  Time: 0.838s,  152.74/s  (0.909s,  140.85/s)  LR: 3.685e-04  Data: 0.007 (0.008)
2024-04-07 08:02:19,785 - train - INFO - Train: 52 [ 450/781 ( 58%)]  Loss:  4.550274 (4.0223)  Time: 0.847s,  151.14/s  (0.909s,  140.75/s)  LR: 3.685e-04  Data: 0.009 (0.008)
2024-04-07 08:03:06,287 - train - INFO - Train: 52 [ 500/781 ( 64%)]  Loss:  4.068067 (4.0266)  Time: 0.858s,  149.26/s  (0.911s,  140.43/s)  LR: 3.685e-04  Data: 0.008 (0.008)
2024-04-07 08:03:52,126 - train - INFO - Train: 52 [ 550/781 ( 71%)]  Loss:  4.165190 (4.0270)  Time: 0.820s,  156.15/s  (0.912s,  140.36/s)  LR: 3.685e-04  Data: 0.008 (0.008)
2024-04-07 08:04:38,820 - train - INFO - Train: 52 [ 600/781 ( 77%)]  Loss:  4.054058 (4.0202)  Time: 0.806s,  158.74/s  (0.914s,  140.08/s)  LR: 3.685e-04  Data: 0.005 (0.008)
2024-04-07 08:05:22,875 - train - INFO - Train: 52 [ 650/781 ( 83%)]  Loss:  3.475850 (4.0272)  Time: 0.798s,  160.45/s  (0.911s,  140.47/s)  LR: 3.685e-04  Data: 0.004 (0.008)
2024-04-07 08:06:07,801 - train - INFO - Train: 52 [ 700/781 ( 90%)]  Loss:  4.500737 (4.0355)  Time: 0.852s,  150.28/s  (0.910s,  140.61/s)  LR: 3.685e-04  Data: 0.008 (0.008)
2024-04-07 08:06:52,273 - train - INFO - Train: 52 [ 750/781 ( 96%)]  Loss:  3.927398 (4.0370)  Time: 0.960s,  133.31/s  (0.909s,  140.82/s)  LR: 3.685e-04  Data: 0.005 (0.007)
2024-04-07 08:07:19,213 - train - INFO - Train: 52 [ 780/781 (100%)]  Loss:  4.545408 (4.0338)  Time: 1.027s,  124.65/s  (0.909s,  140.89/s)  LR: 3.685e-04  Data: 0.000 (0.008)
2024-04-07 08:07:19,213 - train - INFO - True
2024-04-07 08:07:19,214 - train - INFO - alphas:tensor([0.0917, 0.0629, 0.1375, 0.3194, 0.3885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,224 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,224 - train - INFO - True
2024-04-07 08:07:19,224 - train - INFO - alphas:tensor([0.2004, 0.0453, 0.0733, 0.1787, 0.5024], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,233 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,234 - train - INFO - True
2024-04-07 08:07:19,234 - train - INFO - alphas:tensor([0.6566, 0.0865, 0.0620, 0.0881, 0.1068], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,252 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,252 - train - INFO - True
2024-04-07 08:07:19,253 - train - INFO - alphas:tensor([0.5407, 0.0480, 0.0630, 0.1300, 0.2182], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,274 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,274 - train - INFO - True
2024-04-07 08:07:19,275 - train - INFO - alphas:tensor([0.3785, 0.0355, 0.0799, 0.1679, 0.3382], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,294 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,294 - train - INFO - True
2024-04-07 08:07:19,295 - train - INFO - alphas:tensor([0.4972, 0.0378, 0.0610, 0.1311, 0.2729], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,313 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,313 - train - INFO - True
2024-04-07 08:07:19,314 - train - INFO - alphas:tensor([0.6503, 0.0559, 0.0429, 0.0953, 0.1556], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,331 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,332 - train - INFO - True
2024-04-07 08:07:19,332 - train - INFO - alphas:tensor([0.4978, 0.0406, 0.0394, 0.1282, 0.2940], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,349 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,349 - train - INFO - True
2024-04-07 08:07:19,350 - train - INFO - alphas:tensor([0.4403, 0.0313, 0.0637, 0.1452, 0.3194], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,369 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,369 - train - INFO - True
2024-04-07 08:07:19,369 - train - INFO - alphas:tensor([0.5558, 0.0328, 0.0563, 0.1089, 0.2462], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,390 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,390 - train - INFO - True
2024-04-07 08:07:19,391 - train - INFO - alphas:tensor([0.5547, 0.0387, 0.0451, 0.1159, 0.2456], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,411 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,411 - train - INFO - True
2024-04-07 08:07:19,411 - train - INFO - alphas:tensor([0.4365, 0.0242, 0.0371, 0.1412, 0.3610], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,430 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,430 - train - INFO - True
2024-04-07 08:07:19,430 - train - INFO - alphas:tensor([0.4520, 0.0255, 0.0537, 0.1410, 0.3278], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,448 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,448 - train - INFO - True
2024-04-07 08:07:19,449 - train - INFO - alphas:tensor([0.5515, 0.0218, 0.0464, 0.1045, 0.2758], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,465 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,465 - train - INFO - True
2024-04-07 08:07:19,466 - train - INFO - alphas:tensor([0.4775, 0.0420, 0.0399, 0.1243, 0.3163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,487 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,487 - train - INFO - True
2024-04-07 08:07:19,488 - train - INFO - alphas:tensor([0.3546, 0.0181, 0.0249, 0.1352, 0.4672], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,498 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,498 - train - INFO - True
2024-04-07 08:07:19,499 - train - INFO - alphas:tensor([0.4355, 0.0244, 0.0487, 0.1392, 0.3523], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,519 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,519 - train - INFO - True
2024-04-07 08:07:19,519 - train - INFO - alphas:tensor([0.5439, 0.0189, 0.0435, 0.1043, 0.2894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,538 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,538 - train - INFO - True
2024-04-07 08:07:19,539 - train - INFO - alphas:tensor([0.4860, 0.0279, 0.0351, 0.1238, 0.3272], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,557 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,557 - train - INFO - True
2024-04-07 08:07:19,557 - train - INFO - alphas:tensor([0.3553, 0.0150, 0.0211, 0.1223, 0.4863], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,566 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,566 - train - INFO - True
2024-04-07 08:07:19,567 - train - INFO - alphas:tensor([0.3832, 0.0182, 0.0485, 0.1479, 0.4021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,575 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,575 - train - INFO - True
2024-04-07 08:07:19,576 - train - INFO - alphas:tensor([0.5328, 0.0174, 0.0405, 0.0992, 0.3101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,597 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,597 - train - INFO - True
2024-04-07 08:07:19,598 - train - INFO - alphas:tensor([0.5183, 0.0326, 0.0322, 0.1093, 0.3076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,617 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,617 - train - INFO - True
2024-04-07 08:07:19,618 - train - INFO - alphas:tensor([0.3745, 0.0122, 0.0171, 0.1096, 0.4866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,628 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,628 - train - INFO - True
2024-04-07 08:07:19,628 - train - INFO - alphas:tensor([0.3712, 0.0153, 0.0447, 0.1447, 0.4241], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,638 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,638 - train - INFO - True
2024-04-07 08:07:19,638 - train - INFO - alphas:tensor([0.5156, 0.0168, 0.0393, 0.0921, 0.3362], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,656 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,656 - train - INFO - True
2024-04-07 08:07:19,657 - train - INFO - alphas:tensor([0.5458, 0.0207, 0.0286, 0.1029, 0.3020], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,673 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,673 - train - INFO - True
2024-04-07 08:07:19,674 - train - INFO - alphas:tensor([0.4014, 0.0121, 0.0155, 0.1027, 0.4683], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,683 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,683 - train - INFO - True
2024-04-07 08:07:19,683 - train - INFO - alphas:tensor([0.3462, 0.0127, 0.0431, 0.1480, 0.4500], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,693 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,694 - train - INFO - True
2024-04-07 08:07:19,694 - train - INFO - alphas:tensor([0.4806, 0.0126, 0.0351, 0.1016, 0.3700], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,715 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,715 - train - INFO - True
2024-04-07 08:07:19,715 - train - INFO - alphas:tensor([0.5691, 0.0197, 0.0260, 0.0928, 0.2923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,734 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,734 - train - INFO - True
2024-04-07 08:07:19,735 - train - INFO - alphas:tensor([0.4489, 0.0109, 0.0195, 0.1094, 0.4113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,753 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,753 - train - INFO - True
2024-04-07 08:07:19,754 - train - INFO - alphas:tensor([0.3217, 0.0115, 0.0416, 0.1421, 0.4831], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,762 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,762 - train - INFO - True
2024-04-07 08:07:19,763 - train - INFO - alphas:tensor([0.4377, 0.0100, 0.0317, 0.0982, 0.4224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,780 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,780 - train - INFO - True
2024-04-07 08:07:19,781 - train - INFO - alphas:tensor([0.5568, 0.0220, 0.0257, 0.1012, 0.2943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,799 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,799 - train - INFO - True
2024-04-07 08:07:19,800 - train - INFO - alphas:tensor([0.4654, 0.0111, 0.0229, 0.1160, 0.3846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,820 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,820 - train - INFO - True
2024-04-07 08:07:19,821 - train - INFO - alphas:tensor([0.6951, 0.0466, 0.0995, 0.1588], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:07:19,839 - train - INFO - tau:0.6050060671375365
2024-04-07 08:07:19,839 - train - INFO - avg block size:5.054054054054054
2024-04-07 08:07:19,839 - train - INFO - current latency ratio:tensor(0.7088)
2024-04-07 08:07:19,840 - train - INFO - lasso_alpha:9.849732675807631e-05
2024-04-07 08:07:20,099 - train - INFO - Test: [   0/78]  Time: 0.257 (0.257)  Loss:  1.0645 (1.0645)  Acc@1: 78.9062 (78.9062)  Acc@5: 91.4062 (91.4062)
2024-04-07 08:07:24,796 - train - INFO - Test: [  50/78]  Time: 0.088 (0.097)  Loss:  1.9277 (1.7066)  Acc@1: 57.8125 (60.1562)  Acc@5: 84.3750 (82.7819)
2024-04-07 08:07:27,625 - train - INFO - Test: [  78/78]  Time: 0.106 (0.099)  Loss:  1.8135 (1.7283)  Acc@1: 62.5000 (59.9300)  Acc@5: 81.2500 (82.4700)
2024-04-07 08:07:28,996 - train - INFO - Train: 53 [   0/781 (  0%)]  Loss:  4.562846 (4.5628)  Time: 1.266s,  101.14/s  (1.266s,  101.14/s)  LR: 3.639e-04  Data: 0.177 (0.177)
2024-04-07 08:08:14,148 - train - INFO - Train: 53 [  50/781 (  6%)]  Loss:  3.452628 (4.0996)  Time: 0.812s,  157.55/s  (0.910s,  140.64/s)  LR: 3.639e-04  Data: 0.006 (0.011)
2024-04-07 08:08:58,504 - train - INFO - Train: 53 [ 100/781 ( 13%)]  Loss:  3.739923 (4.0831)  Time: 0.905s,  141.51/s  (0.899s,  142.43/s)  LR: 3.639e-04  Data: 0.005 (0.009)
2024-04-07 08:09:43,685 - train - INFO - Train: 53 [ 150/781 ( 19%)]  Loss:  4.587337 (4.0678)  Time: 0.847s,  151.12/s  (0.900s,  142.17/s)  LR: 3.639e-04  Data: 0.008 (0.008)
2024-04-07 08:10:28,799 - train - INFO - Train: 53 [ 200/781 ( 26%)]  Loss:  4.418306 (4.0413)  Time: 0.845s,  151.48/s  (0.901s,  142.10/s)  LR: 3.639e-04  Data: 0.007 (0.008)
2024-04-07 08:11:12,975 - train - INFO - Train: 53 [ 250/781 ( 32%)]  Loss:  4.189607 (4.0303)  Time: 0.803s,  159.47/s  (0.897s,  142.64/s)  LR: 3.639e-04  Data: 0.006 (0.008)
2024-04-07 08:11:57,669 - train - INFO - Train: 53 [ 300/781 ( 38%)]  Loss:  3.956676 (4.0372)  Time: 0.815s,  157.14/s  (0.897s,  142.73/s)  LR: 3.639e-04  Data: 0.005 (0.008)
2024-04-07 08:12:43,472 - train - INFO - Train: 53 [ 350/781 ( 45%)]  Loss:  4.441000 (4.0380)  Time: 1.060s,  120.76/s  (0.900s,  142.30/s)  LR: 3.639e-04  Data: 0.008 (0.007)
2024-04-07 08:13:29,734 - train - INFO - Train: 53 [ 400/781 ( 51%)]  Loss:  3.477752 (4.0407)  Time: 0.828s,  154.66/s  (0.903s,  141.79/s)  LR: 3.639e-04  Data: 0.009 (0.007)
2024-04-07 08:14:14,469 - train - INFO - Train: 53 [ 450/781 ( 58%)]  Loss:  4.309550 (4.0365)  Time: 0.834s,  153.46/s  (0.902s,  141.93/s)  LR: 3.639e-04  Data: 0.008 (0.007)
2024-04-07 08:14:59,883 - train - INFO - Train: 53 [ 500/781 ( 64%)]  Loss:  3.987683 (4.0252)  Time: 0.866s,  147.76/s  (0.902s,  141.83/s)  LR: 3.639e-04  Data: 0.009 (0.007)
2024-04-07 08:15:46,052 - train - INFO - Train: 53 [ 550/781 ( 71%)]  Loss:  3.873292 (4.0291)  Time: 0.841s,  152.23/s  (0.904s,  141.54/s)  LR: 3.639e-04  Data: 0.008 (0.007)
2024-04-07 08:16:30,716 - train - INFO - Train: 53 [ 600/781 ( 77%)]  Loss:  4.494964 (4.0302)  Time: 0.944s,  135.55/s  (0.903s,  141.68/s)  LR: 3.639e-04  Data: 0.007 (0.007)
2024-04-07 08:17:16,148 - train - INFO - Train: 53 [ 650/781 ( 83%)]  Loss:  4.461064 (4.0390)  Time: 0.850s,  150.62/s  (0.904s,  141.62/s)  LR: 3.639e-04  Data: 0.009 (0.007)
2024-04-07 08:18:01,952 - train - INFO - Train: 53 [ 700/781 ( 90%)]  Loss:  3.442656 (4.0353)  Time: 0.844s,  151.61/s  (0.905s,  141.48/s)  LR: 3.639e-04  Data: 0.009 (0.007)
2024-04-07 08:18:47,528 - train - INFO - Train: 53 [ 750/781 ( 96%)]  Loss:  3.707175 (4.0315)  Time: 1.086s,  117.88/s  (0.905s,  141.41/s)  LR: 3.639e-04  Data: 0.013 (0.007)
2024-04-07 08:19:14,642 - train - INFO - Train: 53 [ 780/781 (100%)]  Loss:  4.122378 (4.0298)  Time: 1.058s,  120.97/s  (0.905s,  141.42/s)  LR: 3.639e-04  Data: 0.000 (0.007)
2024-04-07 08:19:14,643 - train - INFO - True
2024-04-07 08:19:14,645 - train - INFO - alphas:tensor([0.0847, 0.0592, 0.1337, 0.3252, 0.3972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:14,667 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:14,667 - train - INFO - True
2024-04-07 08:19:14,668 - train - INFO - alphas:tensor([0.1924, 0.0433, 0.0718, 0.1772, 0.5153], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:14,687 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:14,687 - train - INFO - True
2024-04-07 08:19:14,689 - train - INFO - alphas:tensor([0.6471, 0.0881, 0.0630, 0.0909, 0.1109], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:14,721 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:14,721 - train - INFO - True
2024-04-07 08:19:14,722 - train - INFO - alphas:tensor([0.5302, 0.0468, 0.0628, 0.1329, 0.2274], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:14,750 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:14,750 - train - INFO - True
2024-04-07 08:19:14,751 - train - INFO - alphas:tensor([0.3700, 0.0343, 0.0790, 0.1688, 0.3478], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:14,780 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:14,780 - train - INFO - True
2024-04-07 08:19:14,781 - train - INFO - alphas:tensor([0.4896, 0.0359, 0.0596, 0.1320, 0.2829], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:14,809 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:14,809 - train - INFO - True
2024-04-07 08:19:14,810 - train - INFO - alphas:tensor([0.6384, 0.0555, 0.0430, 0.0992, 0.1639], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:14,838 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:14,838 - train - INFO - True
2024-04-07 08:19:14,839 - train - INFO - alphas:tensor([0.4852, 0.0389, 0.0382, 0.1300, 0.3076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:14,867 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:14,867 - train - INFO - True
2024-04-07 08:19:14,868 - train - INFO - alphas:tensor([0.4314, 0.0304, 0.0627, 0.1458, 0.3297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:14,896 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:14,896 - train - INFO - True
2024-04-07 08:19:14,897 - train - INFO - alphas:tensor([0.5444, 0.0315, 0.0558, 0.1104, 0.2579], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:14,925 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:14,925 - train - INFO - True
2024-04-07 08:19:14,926 - train - INFO - alphas:tensor([0.5435, 0.0375, 0.0444, 0.1177, 0.2570], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:14,954 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:14,955 - train - INFO - True
2024-04-07 08:19:14,955 - train - INFO - alphas:tensor([0.4243, 0.0227, 0.0354, 0.1422, 0.3754], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:14,984 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:14,984 - train - INFO - True
2024-04-07 08:19:14,985 - train - INFO - alphas:tensor([0.4436, 0.0240, 0.0527, 0.1418, 0.3378], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,013 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,013 - train - INFO - True
2024-04-07 08:19:15,014 - train - INFO - alphas:tensor([0.5414, 0.0204, 0.0453, 0.1050, 0.2878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,042 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,042 - train - INFO - True
2024-04-07 08:19:15,043 - train - INFO - alphas:tensor([0.4643, 0.0411, 0.0386, 0.1267, 0.3294], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,071 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,071 - train - INFO - True
2024-04-07 08:19:15,072 - train - INFO - alphas:tensor([0.3440, 0.0171, 0.0230, 0.1340, 0.4818], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,086 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,086 - train - INFO - True
2024-04-07 08:19:15,087 - train - INFO - alphas:tensor([0.4263, 0.0233, 0.0473, 0.1396, 0.3635], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,115 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,116 - train - INFO - True
2024-04-07 08:19:15,117 - train - INFO - alphas:tensor([0.5372, 0.0180, 0.0421, 0.1033, 0.2994], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,145 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,145 - train - INFO - True
2024-04-07 08:19:15,146 - train - INFO - alphas:tensor([0.4739, 0.0266, 0.0337, 0.1245, 0.3414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,174 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,175 - train - INFO - True
2024-04-07 08:19:15,176 - train - INFO - alphas:tensor([0.3451, 0.0139, 0.0199, 0.1211, 0.5001], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,190 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,190 - train - INFO - True
2024-04-07 08:19:15,191 - train - INFO - alphas:tensor([0.3768, 0.0171, 0.0469, 0.1471, 0.4121], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,206 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,206 - train - INFO - True
2024-04-07 08:19:15,207 - train - INFO - alphas:tensor([0.5225, 0.0163, 0.0395, 0.0983, 0.3234], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,235 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,235 - train - INFO - True
2024-04-07 08:19:15,236 - train - INFO - alphas:tensor([0.5064, 0.0312, 0.0309, 0.1098, 0.3217], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,264 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,264 - train - INFO - True
2024-04-07 08:19:15,265 - train - INFO - alphas:tensor([0.3658, 0.0113, 0.0159, 0.1087, 0.4982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,280 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,280 - train - INFO - True
2024-04-07 08:19:15,281 - train - INFO - alphas:tensor([0.3642, 0.0145, 0.0435, 0.1433, 0.4345], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,295 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,295 - train - INFO - True
2024-04-07 08:19:15,296 - train - INFO - alphas:tensor([0.5081, 0.0155, 0.0381, 0.0913, 0.3470], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,324 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,324 - train - INFO - True
2024-04-07 08:19:15,326 - train - INFO - alphas:tensor([0.5360, 0.0196, 0.0273, 0.1025, 0.3146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,354 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,354 - train - INFO - True
2024-04-07 08:19:15,355 - train - INFO - alphas:tensor([0.3964, 0.0116, 0.0146, 0.1008, 0.4766], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,369 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,369 - train - INFO - True
2024-04-07 08:19:15,370 - train - INFO - alphas:tensor([0.3367, 0.0118, 0.0412, 0.1465, 0.4638], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,383 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,383 - train - INFO - True
2024-04-07 08:19:15,384 - train - INFO - alphas:tensor([0.4719, 0.0116, 0.0338, 0.0997, 0.3830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,408 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,408 - train - INFO - True
2024-04-07 08:19:15,409 - train - INFO - alphas:tensor([0.5596, 0.0181, 0.0251, 0.0936, 0.3036], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,431 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,431 - train - INFO - True
2024-04-07 08:19:15,432 - train - INFO - alphas:tensor([0.4410, 0.0101, 0.0181, 0.1079, 0.4229], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,453 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,453 - train - INFO - True
2024-04-07 08:19:15,454 - train - INFO - alphas:tensor([0.3143, 0.0108, 0.0394, 0.1399, 0.4955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,464 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,464 - train - INFO - True
2024-04-07 08:19:15,465 - train - INFO - alphas:tensor([0.4269, 0.0091, 0.0303, 0.0958, 0.4378], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,474 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,475 - train - INFO - True
2024-04-07 08:19:15,475 - train - INFO - alphas:tensor([0.5464, 0.0209, 0.0247, 0.1014, 0.3066], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,494 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,494 - train - INFO - True
2024-04-07 08:19:15,495 - train - INFO - alphas:tensor([0.4576, 0.0102, 0.0213, 0.1144, 0.3965], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,512 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,512 - train - INFO - True
2024-04-07 08:19:15,513 - train - INFO - alphas:tensor([0.6945, 0.0459, 0.0994, 0.1602], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:19:15,530 - train - INFO - tau:0.5989560064661611
2024-04-07 08:19:15,530 - train - INFO - avg block size:5.45945945945946
2024-04-07 08:19:15,530 - train - INFO - current latency ratio:tensor(0.6946)
2024-04-07 08:19:15,764 - train - INFO - Test: [   0/78]  Time: 0.230 (0.230)  Loss:  0.8872 (0.8872)  Acc@1: 83.5938 (83.5938)  Acc@5: 94.5312 (94.5312)
2024-04-07 08:19:20,489 - train - INFO - Test: [  50/78]  Time: 0.122 (0.097)  Loss:  1.8584 (1.6896)  Acc@1: 57.0312 (60.4320)  Acc@5: 82.0312 (83.1342)
2024-04-07 08:19:22,935 - train - INFO - Test: [  78/78]  Time: 0.055 (0.094)  Loss:  1.6377 (1.7205)  Acc@1: 56.2500 (59.6000)  Acc@5: 93.7500 (82.5300)
2024-04-07 08:19:24,224 - train - INFO - Train: 54 [   0/781 (  0%)]  Loss:  3.772046 (3.7720)  Time: 1.223s,  104.63/s  (1.223s,  104.63/s)  LR: 3.593e-04  Data: 0.170 (0.170)
2024-04-07 08:20:08,694 - train - INFO - Train: 54 [  50/781 (  6%)]  Loss:  4.409537 (4.0624)  Time: 0.843s,  151.85/s  (0.896s,  142.87/s)  LR: 3.593e-04  Data: 0.008 (0.010)
2024-04-07 08:20:52,188 - train - INFO - Train: 54 [ 100/781 ( 13%)]  Loss:  3.623365 (4.0383)  Time: 0.821s,  155.85/s  (0.883s,  144.96/s)  LR: 3.593e-04  Data: 0.006 (0.008)
2024-04-07 08:21:37,241 - train - INFO - Train: 54 [ 150/781 ( 19%)]  Loss:  3.447121 (4.0462)  Time: 1.011s,  126.63/s  (0.889s,  143.99/s)  LR: 3.593e-04  Data: 0.005 (0.008)
2024-04-07 08:22:21,904 - train - INFO - Train: 54 [ 200/781 ( 26%)]  Loss:  4.136106 (4.0357)  Time: 0.845s,  151.39/s  (0.890s,  143.81/s)  LR: 3.593e-04  Data: 0.008 (0.008)
2024-04-07 08:23:08,340 - train - INFO - Train: 54 [ 250/781 ( 32%)]  Loss:  4.009346 (4.0483)  Time: 0.840s,  152.35/s  (0.898s,  142.58/s)  LR: 3.593e-04  Data: 0.007 (0.008)
2024-04-07 08:23:51,331 - train - INFO - Train: 54 [ 300/781 ( 38%)]  Loss:  4.313321 (4.0499)  Time: 0.831s,  154.03/s  (0.891s,  143.59/s)  LR: 3.593e-04  Data: 0.008 (0.007)
2024-04-07 08:24:35,644 - train - INFO - Train: 54 [ 350/781 ( 45%)]  Loss:  4.357223 (4.0656)  Time: 0.844s,  151.72/s  (0.891s,  143.71/s)  LR: 3.593e-04  Data: 0.005 (0.007)
2024-04-07 08:25:19,212 - train - INFO - Train: 54 [ 400/781 ( 51%)]  Loss:  3.531717 (4.0646)  Time: 1.088s,  117.66/s  (0.888s,  144.10/s)  LR: 3.593e-04  Data: 0.009 (0.007)
2024-04-07 08:26:04,817 - train - INFO - Train: 54 [ 450/781 ( 58%)]  Loss:  3.653697 (4.0689)  Time: 1.023s,  125.09/s  (0.891s,  143.67/s)  LR: 3.593e-04  Data: 0.012 (0.007)
2024-04-07 08:26:49,467 - train - INFO - Train: 54 [ 500/781 ( 64%)]  Loss:  4.348874 (4.0665)  Time: 0.845s,  151.54/s  (0.891s,  143.64/s)  LR: 3.593e-04  Data: 0.007 (0.007)
2024-04-07 08:27:33,754 - train - INFO - Train: 54 [ 550/781 ( 71%)]  Loss:  4.022424 (4.0724)  Time: 0.854s,  149.87/s  (0.891s,  143.72/s)  LR: 3.593e-04  Data: 0.009 (0.007)
2024-04-07 08:28:18,378 - train - INFO - Train: 54 [ 600/781 ( 77%)]  Loss:  3.801195 (4.0657)  Time: 0.838s,  152.79/s  (0.891s,  143.70/s)  LR: 3.593e-04  Data: 0.013 (0.007)
2024-04-07 08:29:02,026 - train - INFO - Train: 54 [ 650/781 ( 83%)]  Loss:  3.852636 (4.0647)  Time: 0.804s,  159.17/s  (0.889s,  143.92/s)  LR: 3.593e-04  Data: 0.004 (0.007)
2024-04-07 08:29:44,631 - train - INFO - Train: 54 [ 700/781 ( 90%)]  Loss:  3.608062 (4.0636)  Time: 0.830s,  154.18/s  (0.887s,  144.35/s)  LR: 3.593e-04  Data: 0.008 (0.007)
2024-04-07 08:30:28,619 - train - INFO - Train: 54 [ 750/781 ( 96%)]  Loss:  4.179211 (4.0592)  Time: 1.013s,  126.37/s  (0.886s,  144.42/s)  LR: 3.593e-04  Data: 0.005 (0.007)
2024-04-07 08:30:55,998 - train - INFO - Train: 54 [ 780/781 (100%)]  Loss:  4.283074 (4.0564)  Time: 0.827s,  154.78/s  (0.887s,  144.26/s)  LR: 3.593e-04  Data: 0.000 (0.007)
2024-04-07 08:30:55,999 - train - INFO - True
2024-04-07 08:30:56,000 - train - INFO - alphas:tensor([0.0785, 0.0560, 0.1298, 0.3312, 0.4045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,019 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,019 - train - INFO - True
2024-04-07 08:30:56,020 - train - INFO - alphas:tensor([0.1866, 0.0419, 0.0698, 0.1765, 0.5252], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,037 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,037 - train - INFO - True
2024-04-07 08:30:56,038 - train - INFO - alphas:tensor([0.6402, 0.0889, 0.0636, 0.0931, 0.1142], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,068 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,068 - train - INFO - True
2024-04-07 08:30:56,069 - train - INFO - alphas:tensor([0.5236, 0.0453, 0.0618, 0.1343, 0.2350], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,097 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,097 - train - INFO - True
2024-04-07 08:30:56,098 - train - INFO - alphas:tensor([0.3622, 0.0329, 0.0774, 0.1698, 0.3576], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,126 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,127 - train - INFO - True
2024-04-07 08:30:56,128 - train - INFO - alphas:tensor([0.4804, 0.0346, 0.0587, 0.1327, 0.2937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,156 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,156 - train - INFO - True
2024-04-07 08:30:56,157 - train - INFO - alphas:tensor([0.6304, 0.0552, 0.0427, 0.1014, 0.1703], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,185 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,185 - train - INFO - True
2024-04-07 08:30:56,186 - train - INFO - alphas:tensor([0.4796, 0.0371, 0.0364, 0.1293, 0.3175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,214 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,214 - train - INFO - True
2024-04-07 08:30:56,215 - train - INFO - alphas:tensor([0.4263, 0.0292, 0.0611, 0.1455, 0.3380], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,243 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,244 - train - INFO - True
2024-04-07 08:30:56,244 - train - INFO - alphas:tensor([0.5374, 0.0305, 0.0547, 0.1113, 0.2662], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,273 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,273 - train - INFO - True
2024-04-07 08:30:56,274 - train - INFO - alphas:tensor([0.5374, 0.0360, 0.0430, 0.1182, 0.2654], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,302 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,302 - train - INFO - True
2024-04-07 08:30:56,303 - train - INFO - alphas:tensor([0.4198, 0.0217, 0.0336, 0.1411, 0.3839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,332 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,332 - train - INFO - True
2024-04-07 08:30:56,333 - train - INFO - alphas:tensor([0.4379, 0.0227, 0.0512, 0.1410, 0.3472], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,361 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,361 - train - INFO - True
2024-04-07 08:30:56,362 - train - INFO - alphas:tensor([0.5343, 0.0193, 0.0444, 0.1043, 0.2978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,390 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,391 - train - INFO - True
2024-04-07 08:30:56,392 - train - INFO - alphas:tensor([0.4540, 0.0399, 0.0377, 0.1279, 0.3406], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,420 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,420 - train - INFO - True
2024-04-07 08:30:56,421 - train - INFO - alphas:tensor([0.3352, 0.0162, 0.0217, 0.1329, 0.4941], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,435 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,435 - train - INFO - True
2024-04-07 08:30:56,436 - train - INFO - alphas:tensor([0.4217, 0.0223, 0.0457, 0.1387, 0.3717], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,464 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,464 - train - INFO - True
2024-04-07 08:30:56,465 - train - INFO - alphas:tensor([0.5299, 0.0170, 0.0408, 0.1022, 0.3101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,496 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,497 - train - INFO - True
2024-04-07 08:30:56,498 - train - INFO - alphas:tensor([0.4662, 0.0252, 0.0321, 0.1245, 0.3520], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,526 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,526 - train - INFO - True
2024-04-07 08:30:56,527 - train - INFO - alphas:tensor([0.3376, 0.0131, 0.0185, 0.1213, 0.5096], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,542 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,542 - train - INFO - True
2024-04-07 08:30:56,543 - train - INFO - alphas:tensor([0.3698, 0.0162, 0.0451, 0.1460, 0.4229], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,557 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,557 - train - INFO - True
2024-04-07 08:30:56,558 - train - INFO - alphas:tensor([0.5159, 0.0151, 0.0379, 0.0970, 0.3342], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,586 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,587 - train - INFO - True
2024-04-07 08:30:56,588 - train - INFO - alphas:tensor([0.5005, 0.0300, 0.0292, 0.1090, 0.3312], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,616 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,616 - train - INFO - True
2024-04-07 08:30:56,617 - train - INFO - alphas:tensor([0.3635, 0.0107, 0.0148, 0.1061, 0.5049], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,631 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,631 - train - INFO - True
2024-04-07 08:30:56,632 - train - INFO - alphas:tensor([0.3551, 0.0137, 0.0418, 0.1422, 0.4472], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,647 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,647 - train - INFO - True
2024-04-07 08:30:56,648 - train - INFO - alphas:tensor([0.4967, 0.0146, 0.0368, 0.0909, 0.3609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,676 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,676 - train - INFO - True
2024-04-07 08:30:56,677 - train - INFO - alphas:tensor([0.5262, 0.0187, 0.0261, 0.1026, 0.3264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,705 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,705 - train - INFO - True
2024-04-07 08:30:56,706 - train - INFO - alphas:tensor([0.3898, 0.0108, 0.0136, 0.1001, 0.4857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,719 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,719 - train - INFO - True
2024-04-07 08:30:56,720 - train - INFO - alphas:tensor([0.3304, 0.0110, 0.0392, 0.1449, 0.4745], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,734 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,734 - train - INFO - True
2024-04-07 08:30:56,735 - train - INFO - alphas:tensor([0.4641, 0.0107, 0.0325, 0.0982, 0.3946], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,758 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,759 - train - INFO - True
2024-04-07 08:30:56,759 - train - INFO - alphas:tensor([0.5540, 0.0170, 0.0236, 0.0927, 0.3127], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,781 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,781 - train - INFO - True
2024-04-07 08:30:56,782 - train - INFO - alphas:tensor([0.4370, 0.0094, 0.0169, 0.1056, 0.4311], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,801 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,802 - train - INFO - True
2024-04-07 08:30:56,802 - train - INFO - alphas:tensor([0.3069, 0.0100, 0.0378, 0.1377, 0.5076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,812 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,812 - train - INFO - True
2024-04-07 08:30:56,813 - train - INFO - alphas:tensor([0.4170, 0.0083, 0.0288, 0.0941, 0.4519], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,822 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,822 - train - INFO - True
2024-04-07 08:30:56,823 - train - INFO - alphas:tensor([0.5411, 0.0197, 0.0234, 0.1008, 0.3150], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,841 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,841 - train - INFO - True
2024-04-07 08:30:56,841 - train - INFO - alphas:tensor([0.4507, 0.0095, 0.0200, 0.1127, 0.4070], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,858 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,858 - train - INFO - True
2024-04-07 08:30:56,859 - train - INFO - alphas:tensor([0.6927, 0.0454, 0.0995, 0.1624], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:30:56,880 - train - INFO - tau:0.5929664464014994
2024-04-07 08:30:56,880 - train - INFO - avg block size:5.45945945945946
2024-04-07 08:30:56,880 - train - INFO - current latency ratio:tensor(0.6946)
2024-04-07 08:30:56,880 - train - INFO - lasso_alpha:0.00010834705943388396
2024-04-07 08:30:57,147 - train - INFO - Test: [   0/78]  Time: 0.263 (0.263)  Loss:  1.0234 (1.0234)  Acc@1: 77.3438 (77.3438)  Acc@5: 91.4062 (91.4062)
2024-04-07 08:31:02,029 - train - INFO - Test: [  50/78]  Time: 0.087 (0.101)  Loss:  2.0293 (1.6919)  Acc@1: 53.1250 (59.9571)  Acc@5: 76.5625 (83.3946)
2024-04-07 08:31:04,415 - train - INFO - Test: [  78/78]  Time: 0.058 (0.095)  Loss:  1.8506 (1.7130)  Acc@1: 50.0000 (59.6700)  Acc@5: 81.2500 (82.8900)
2024-04-07 08:31:05,750 - train - INFO - Train: 55 [   0/781 (  0%)]  Loss:  3.958998 (3.9590)  Time: 1.269s,  100.91/s  (1.269s,  100.91/s)  LR: 3.547e-04  Data: 0.197 (0.197)
2024-04-07 08:31:50,081 - train - INFO - Train: 55 [  50/781 (  6%)]  Loss:  4.429825 (4.0233)  Time: 0.846s,  151.24/s  (0.894s,  143.17/s)  LR: 3.547e-04  Data: 0.008 (0.011)
2024-04-07 08:32:35,286 - train - INFO - Train: 55 [ 100/781 ( 13%)]  Loss:  4.570499 (4.0451)  Time: 0.803s,  159.46/s  (0.899s,  142.38/s)  LR: 3.547e-04  Data: 0.005 (0.009)
2024-04-07 08:33:20,172 - train - INFO - Train: 55 [ 150/781 ( 19%)]  Loss:  3.706980 (4.0540)  Time: 0.806s,  158.83/s  (0.899s,  142.45/s)  LR: 3.547e-04  Data: 0.004 (0.008)
2024-04-07 08:34:04,221 - train - INFO - Train: 55 [ 200/781 ( 26%)]  Loss:  4.467502 (4.0804)  Time: 0.820s,  156.03/s  (0.894s,  143.15/s)  LR: 3.547e-04  Data: 0.006 (0.008)
2024-04-07 08:34:48,102 - train - INFO - Train: 55 [ 250/781 ( 32%)]  Loss:  4.128551 (4.0630)  Time: 0.797s,  160.57/s  (0.891s,  143.68/s)  LR: 3.547e-04  Data: 0.004 (0.008)
2024-04-07 08:35:35,169 - train - INFO - Train: 55 [ 300/781 ( 38%)]  Loss:  3.599615 (4.0704)  Time: 1.077s,  118.81/s  (0.899s,  142.34/s)  LR: 3.547e-04  Data: 0.008 (0.008)
2024-04-07 08:36:19,650 - train - INFO - Train: 55 [ 350/781 ( 45%)]  Loss:  4.595434 (4.0593)  Time: 0.835s,  153.33/s  (0.898s,  142.56/s)  LR: 3.547e-04  Data: 0.008 (0.008)
2024-04-07 08:37:02,843 - train - INFO - Train: 55 [ 400/781 ( 51%)]  Loss:  3.449693 (4.0682)  Time: 0.825s,  155.24/s  (0.894s,  143.24/s)  LR: 3.547e-04  Data: 0.006 (0.007)
2024-04-07 08:37:48,939 - train - INFO - Train: 55 [ 450/781 ( 58%)]  Loss:  4.432784 (4.0828)  Time: 1.073s,  119.25/s  (0.897s,  142.74/s)  LR: 3.547e-04  Data: 0.008 (0.007)
2024-04-07 08:38:35,553 - train - INFO - Train: 55 [ 500/781 ( 64%)]  Loss:  4.564278 (4.0808)  Time: 0.822s,  155.64/s  (0.900s,  142.17/s)  LR: 3.547e-04  Data: 0.008 (0.007)
2024-04-07 08:39:20,376 - train - INFO - Train: 55 [ 550/781 ( 71%)]  Loss:  3.859696 (4.0820)  Time: 0.862s,  148.52/s  (0.900s,  142.23/s)  LR: 3.547e-04  Data: 0.008 (0.007)
2024-04-07 08:40:06,353 - train - INFO - Train: 55 [ 600/781 ( 77%)]  Loss:  4.565993 (4.0871)  Time: 1.073s,  119.34/s  (0.902s,  141.97/s)  LR: 3.547e-04  Data: 0.008 (0.007)
2024-04-07 08:40:50,821 - train - INFO - Train: 55 [ 650/781 ( 83%)]  Loss:  4.097463 (4.0917)  Time: 0.845s,  151.47/s  (0.901s,  142.12/s)  LR: 3.547e-04  Data: 0.007 (0.007)
2024-04-07 08:41:34,824 - train - INFO - Train: 55 [ 700/781 ( 90%)]  Loss:  4.356808 (4.0855)  Time: 0.849s,  150.75/s  (0.899s,  142.35/s)  LR: 3.547e-04  Data: 0.007 (0.007)
2024-04-07 08:42:19,321 - train - INFO - Train: 55 [ 750/781 ( 96%)]  Loss:  4.001972 (4.0839)  Time: 0.840s,  152.37/s  (0.899s,  142.45/s)  LR: 3.547e-04  Data: 0.008 (0.007)
2024-04-07 08:42:47,044 - train - INFO - Train: 55 [ 780/781 (100%)]  Loss:  4.028877 (4.0834)  Time: 1.050s,  121.91/s  (0.900s,  142.30/s)  LR: 3.547e-04  Data: 0.000 (0.007)
2024-04-07 08:42:47,045 - train - INFO - True
2024-04-07 08:42:47,047 - train - INFO - alphas:tensor([0.0723, 0.0526, 0.1252, 0.3365, 0.4134], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,068 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,068 - train - INFO - True
2024-04-07 08:42:47,070 - train - INFO - alphas:tensor([0.1800, 0.0401, 0.0677, 0.1754, 0.5368], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,088 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,088 - train - INFO - True
2024-04-07 08:42:47,089 - train - INFO - alphas:tensor([0.6306, 0.0899, 0.0648, 0.0960, 0.1187], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,122 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,122 - train - INFO - True
2024-04-07 08:42:47,123 - train - INFO - alphas:tensor([0.5148, 0.0441, 0.0614, 0.1365, 0.2432], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,151 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,151 - train - INFO - True
2024-04-07 08:42:47,152 - train - INFO - alphas:tensor([0.3527, 0.0314, 0.0763, 0.1709, 0.3687], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,166 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,166 - train - INFO - True
2024-04-07 08:42:47,167 - train - INFO - alphas:tensor([0.4690, 0.0330, 0.0578, 0.1345, 0.3058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,195 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,196 - train - INFO - True
2024-04-07 08:42:47,197 - train - INFO - alphas:tensor([0.6189, 0.0549, 0.0425, 0.1043, 0.1794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,225 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,225 - train - INFO - True
2024-04-07 08:42:47,226 - train - INFO - alphas:tensor([0.4657, 0.0360, 0.0351, 0.1311, 0.3321], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,254 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,254 - train - INFO - True
2024-04-07 08:42:47,255 - train - INFO - alphas:tensor([0.4162, 0.0278, 0.0599, 0.1464, 0.3498], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,293 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,293 - train - INFO - True
2024-04-07 08:42:47,294 - train - INFO - alphas:tensor([0.5291, 0.0288, 0.0539, 0.1116, 0.2765], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,322 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,322 - train - INFO - True
2024-04-07 08:42:47,323 - train - INFO - alphas:tensor([0.5240, 0.0352, 0.0422, 0.1208, 0.2779], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,353 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,353 - train - INFO - True
2024-04-07 08:42:47,354 - train - INFO - alphas:tensor([0.4079, 0.0207, 0.0322, 0.1414, 0.3979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,384 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,387 - train - INFO - True
2024-04-07 08:42:47,388 - train - INFO - alphas:tensor([0.4292, 0.0218, 0.0500, 0.1408, 0.3583], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,416 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,416 - train - INFO - True
2024-04-07 08:42:47,417 - train - INFO - alphas:tensor([0.5249, 0.0180, 0.0432, 0.1045, 0.3094], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,445 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,445 - train - INFO - True
2024-04-07 08:42:47,446 - train - INFO - alphas:tensor([0.4444, 0.0386, 0.0364, 0.1282, 0.3523], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,474 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,474 - train - INFO - True
2024-04-07 08:42:47,475 - train - INFO - alphas:tensor([0.3275, 0.0151, 0.0202, 0.1321, 0.5051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,490 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,490 - train - INFO - True
2024-04-07 08:42:47,491 - train - INFO - alphas:tensor([0.4112, 0.0213, 0.0443, 0.1389, 0.3843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,519 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,519 - train - INFO - True
2024-04-07 08:42:47,520 - train - INFO - alphas:tensor([0.5187, 0.0158, 0.0394, 0.1023, 0.3238], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,548 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,548 - train - INFO - True
2024-04-07 08:42:47,549 - train - INFO - alphas:tensor([0.4516, 0.0240, 0.0307, 0.1262, 0.3675], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,577 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,577 - train - INFO - True
2024-04-07 08:42:47,578 - train - INFO - alphas:tensor([0.3282, 0.0123, 0.0173, 0.1204, 0.5218], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,593 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,593 - train - INFO - True
2024-04-07 08:42:47,594 - train - INFO - alphas:tensor([0.3618, 0.0153, 0.0431, 0.1449, 0.4349], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,608 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,608 - train - INFO - True
2024-04-07 08:42:47,609 - train - INFO - alphas:tensor([0.5043, 0.0138, 0.0364, 0.0963, 0.3493], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,637 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,637 - train - INFO - True
2024-04-07 08:42:47,638 - train - INFO - alphas:tensor([0.4866, 0.0288, 0.0280, 0.1098, 0.3467], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,668 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,668 - train - INFO - True
2024-04-07 08:42:47,669 - train - INFO - alphas:tensor([0.3526, 0.0099, 0.0135, 0.1050, 0.5189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,683 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,683 - train - INFO - True
2024-04-07 08:42:47,684 - train - INFO - alphas:tensor([0.3490, 0.0128, 0.0394, 0.1404, 0.4584], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,698 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,699 - train - INFO - True
2024-04-07 08:42:47,700 - train - INFO - alphas:tensor([0.4853, 0.0134, 0.0354, 0.0897, 0.3762], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,728 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,728 - train - INFO - True
2024-04-07 08:42:47,729 - train - INFO - alphas:tensor([0.5159, 0.0174, 0.0247, 0.1024, 0.3397], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,756 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,756 - train - INFO - True
2024-04-07 08:42:47,757 - train - INFO - alphas:tensor([0.3752, 0.0101, 0.0126, 0.0977, 0.5045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,770 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,770 - train - INFO - True
2024-04-07 08:42:47,771 - train - INFO - alphas:tensor([0.3226, 0.0103, 0.0373, 0.1424, 0.4874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,783 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,783 - train - INFO - True
2024-04-07 08:42:47,784 - train - INFO - alphas:tensor([0.4545, 0.0099, 0.0310, 0.0969, 0.4077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,806 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,806 - train - INFO - True
2024-04-07 08:42:47,807 - train - INFO - alphas:tensor([0.5426, 0.0161, 0.0225, 0.0931, 0.3256], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,828 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,828 - train - INFO - True
2024-04-07 08:42:47,829 - train - INFO - alphas:tensor([0.4249, 0.0085, 0.0156, 0.1055, 0.4455], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,840 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,840 - train - INFO - True
2024-04-07 08:42:47,840 - train - INFO - alphas:tensor([0.2994, 0.0094, 0.0355, 0.1353, 0.5205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,850 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,851 - train - INFO - True
2024-04-07 08:42:47,851 - train - INFO - alphas:tensor([0.4083, 0.0076, 0.0270, 0.0908, 0.4663], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,861 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,861 - train - INFO - True
2024-04-07 08:42:47,862 - train - INFO - alphas:tensor([0.5281, 0.0187, 0.0224, 0.1019, 0.3290], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,880 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,880 - train - INFO - True
2024-04-07 08:42:47,881 - train - INFO - alphas:tensor([0.4404, 0.0087, 0.0187, 0.1119, 0.4203], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,898 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,898 - train - INFO - True
2024-04-07 08:42:47,899 - train - INFO - alphas:tensor([0.6895, 0.0449, 0.1001, 0.1655], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:42:47,916 - train - INFO - tau:0.5870367819374844
2024-04-07 08:42:47,916 - train - INFO - avg block size:6.27027027027027
2024-04-07 08:42:47,916 - train - INFO - current latency ratio:tensor(0.6342)
2024-04-07 08:42:48,173 - train - INFO - Test: [   0/78]  Time: 0.254 (0.254)  Loss:  0.8862 (0.8862)  Acc@1: 83.5938 (83.5938)  Acc@5: 92.9688 (92.9688)
2024-04-07 08:42:52,869 - train - INFO - Test: [  50/78]  Time: 0.090 (0.097)  Loss:  1.9385 (1.6992)  Acc@1: 52.3438 (60.4320)  Acc@5: 81.2500 (83.2721)
2024-04-07 08:42:55,535 - train - INFO - Test: [  78/78]  Time: 0.055 (0.096)  Loss:  1.7725 (1.7299)  Acc@1: 56.2500 (59.6500)  Acc@5: 93.7500 (82.7000)
2024-04-07 08:42:56,882 - train - INFO - Train: 56 [   0/781 (  0%)]  Loss:  3.859837 (3.8598)  Time: 1.277s,  100.20/s  (1.277s,  100.20/s)  LR: 3.499e-04  Data: 0.198 (0.198)
2024-04-07 08:43:41,986 - train - INFO - Train: 56 [  50/781 (  6%)]  Loss:  3.870200 (4.1008)  Time: 0.862s,  148.52/s  (0.909s,  140.75/s)  LR: 3.499e-04  Data: 0.008 (0.011)
2024-04-07 08:44:26,142 - train - INFO - Train: 56 [ 100/781 ( 13%)]  Loss:  4.467608 (4.0745)  Time: 0.885s,  144.67/s  (0.896s,  142.80/s)  LR: 3.499e-04  Data: 0.010 (0.009)
2024-04-07 08:45:10,786 - train - INFO - Train: 56 [ 150/781 ( 19%)]  Loss:  4.388823 (4.1098)  Time: 0.836s,  153.03/s  (0.895s,  142.98/s)  LR: 3.499e-04  Data: 0.007 (0.009)
2024-04-07 08:45:54,661 - train - INFO - Train: 56 [ 200/781 ( 26%)]  Loss:  4.368793 (4.0991)  Time: 0.968s,  132.23/s  (0.891s,  143.69/s)  LR: 3.499e-04  Data: 0.004 (0.008)
2024-04-07 08:46:39,361 - train - INFO - Train: 56 [ 250/781 ( 32%)]  Loss:  3.932426 (4.0868)  Time: 0.826s,  154.98/s  (0.891s,  143.59/s)  LR: 3.499e-04  Data: 0.007 (0.008)
2024-04-07 08:47:22,603 - train - INFO - Train: 56 [ 300/781 ( 38%)]  Loss:  4.775180 (4.0990)  Time: 1.104s,  115.90/s  (0.887s,  144.31/s)  LR: 3.499e-04  Data: 0.005 (0.008)
2024-04-07 08:48:08,389 - train - INFO - Train: 56 [ 350/781 ( 45%)]  Loss:  4.661460 (4.0952)  Time: 0.852s,  150.24/s  (0.891s,  143.65/s)  LR: 3.499e-04  Data: 0.008 (0.008)
2024-04-07 08:48:52,354 - train - INFO - Train: 56 [ 400/781 ( 51%)]  Loss:  4.485754 (4.0771)  Time: 0.825s,  155.16/s  (0.890s,  143.88/s)  LR: 3.499e-04  Data: 0.006 (0.008)
2024-04-07 08:49:36,231 - train - INFO - Train: 56 [ 450/781 ( 58%)]  Loss:  4.519861 (4.0702)  Time: 0.850s,  150.61/s  (0.888s,  144.10/s)  LR: 3.499e-04  Data: 0.006 (0.008)
2024-04-07 08:50:22,711 - train - INFO - Train: 56 [ 500/781 ( 64%)]  Loss:  3.490620 (4.0695)  Time: 0.843s,  151.89/s  (0.892s,  143.44/s)  LR: 3.499e-04  Data: 0.008 (0.008)
2024-04-07 08:51:07,230 - train - INFO - Train: 56 [ 550/781 ( 71%)]  Loss:  3.404645 (4.0744)  Time: 0.838s,  152.74/s  (0.892s,  143.47/s)  LR: 3.499e-04  Data: 0.007 (0.008)
2024-04-07 08:51:51,285 - train - INFO - Train: 56 [ 600/781 ( 77%)]  Loss:  3.320955 (4.0693)  Time: 0.920s,  139.13/s  (0.891s,  143.62/s)  LR: 3.499e-04  Data: 0.005 (0.008)
2024-04-07 08:52:36,103 - train - INFO - Train: 56 [ 650/781 ( 83%)]  Loss:  3.444880 (4.0710)  Time: 0.838s,  152.69/s  (0.892s,  143.55/s)  LR: 3.499e-04  Data: 0.007 (0.007)
2024-04-07 08:53:21,505 - train - INFO - Train: 56 [ 700/781 ( 90%)]  Loss:  4.487218 (4.0737)  Time: 1.108s,  115.52/s  (0.893s,  143.37/s)  LR: 3.499e-04  Data: 0.006 (0.007)
2024-04-07 08:54:05,931 - train - INFO - Train: 56 [ 750/781 ( 96%)]  Loss:  4.176619 (4.0697)  Time: 0.840s,  152.34/s  (0.893s,  143.41/s)  LR: 3.499e-04  Data: 0.007 (0.007)
2024-04-07 08:54:32,679 - train - INFO - Train: 56 [ 780/781 (100%)]  Loss:  4.590665 (4.0721)  Time: 0.810s,  158.03/s  (0.892s,  143.42/s)  LR: 3.499e-04  Data: 0.000 (0.007)
2024-04-07 08:54:32,680 - train - INFO - True
2024-04-07 08:54:32,682 - train - INFO - alphas:tensor([0.0668, 0.0496, 0.1214, 0.3418, 0.4204], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,703 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,703 - train - INFO - True
2024-04-07 08:54:32,704 - train - INFO - alphas:tensor([0.1742, 0.0386, 0.0660, 0.1740, 0.5471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,722 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,722 - train - INFO - True
2024-04-07 08:54:32,723 - train - INFO - alphas:tensor([0.6218, 0.0905, 0.0657, 0.0989, 0.1232], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,755 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,756 - train - INFO - True
2024-04-07 08:54:32,757 - train - INFO - alphas:tensor([0.5051, 0.0429, 0.0608, 0.1389, 0.2523], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,784 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,784 - train - INFO - True
2024-04-07 08:54:32,785 - train - INFO - alphas:tensor([0.3487, 0.0302, 0.0744, 0.1700, 0.3766], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,797 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,797 - train - INFO - True
2024-04-07 08:54:32,798 - train - INFO - alphas:tensor([0.4643, 0.0314, 0.0564, 0.1334, 0.3146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,821 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,822 - train - INFO - True
2024-04-07 08:54:32,822 - train - INFO - alphas:tensor([0.6116, 0.0540, 0.0417, 0.1063, 0.1864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,844 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,844 - train - INFO - True
2024-04-07 08:54:32,845 - train - INFO - alphas:tensor([0.4604, 0.0346, 0.0335, 0.1304, 0.3411], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,865 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,865 - train - INFO - True
2024-04-07 08:54:32,865 - train - INFO - alphas:tensor([0.4119, 0.0268, 0.0589, 0.1455, 0.3568], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,884 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,884 - train - INFO - True
2024-04-07 08:54:32,885 - train - INFO - alphas:tensor([0.5229, 0.0271, 0.0526, 0.1117, 0.2857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,903 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,903 - train - INFO - True
2024-04-07 08:54:32,904 - train - INFO - alphas:tensor([0.5140, 0.0344, 0.0414, 0.1220, 0.2883], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,925 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,925 - train - INFO - True
2024-04-07 08:54:32,926 - train - INFO - alphas:tensor([0.3986, 0.0197, 0.0307, 0.1418, 0.4092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,936 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,936 - train - INFO - True
2024-04-07 08:54:32,937 - train - INFO - alphas:tensor([0.4217, 0.0205, 0.0487, 0.1411, 0.3680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,956 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,956 - train - INFO - True
2024-04-07 08:54:32,957 - train - INFO - alphas:tensor([0.5169, 0.0169, 0.0420, 0.1040, 0.3203], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,975 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,975 - train - INFO - True
2024-04-07 08:54:32,976 - train - INFO - alphas:tensor([0.4340, 0.0376, 0.0355, 0.1290, 0.3639], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:32,994 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:32,994 - train - INFO - True
2024-04-07 08:54:32,994 - train - INFO - alphas:tensor([0.3181, 0.0145, 0.0190, 0.1326, 0.5158], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,003 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,003 - train - INFO - True
2024-04-07 08:54:33,004 - train - INFO - alphas:tensor([0.4060, 0.0203, 0.0429, 0.1381, 0.3927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,020 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,020 - train - INFO - True
2024-04-07 08:54:33,021 - train - INFO - alphas:tensor([0.5162, 0.0148, 0.0381, 0.1002, 0.3307], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,038 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,038 - train - INFO - True
2024-04-07 08:54:33,039 - train - INFO - alphas:tensor([0.4444, 0.0229, 0.0290, 0.1257, 0.3780], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,060 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,060 - train - INFO - True
2024-04-07 08:54:33,061 - train - INFO - alphas:tensor([0.3202, 0.0115, 0.0162, 0.1197, 0.5324], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,071 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,071 - train - INFO - True
2024-04-07 08:54:33,071 - train - INFO - alphas:tensor([0.3563, 0.0144, 0.0413, 0.1430, 0.4450], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,081 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,081 - train - INFO - True
2024-04-07 08:54:33,082 - train - INFO - alphas:tensor([0.4998, 0.0127, 0.0348, 0.0945, 0.3582], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,101 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,101 - train - INFO - True
2024-04-07 08:54:33,101 - train - INFO - alphas:tensor([0.4802, 0.0277, 0.0266, 0.1086, 0.3568], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,119 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,119 - train - INFO - True
2024-04-07 08:54:33,119 - train - INFO - alphas:tensor([0.3476, 0.0093, 0.0125, 0.1047, 0.5258], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,128 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,128 - train - INFO - True
2024-04-07 08:54:33,129 - train - INFO - alphas:tensor([0.3431, 0.0120, 0.0379, 0.1379, 0.4692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,137 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,137 - train - INFO - True
2024-04-07 08:54:33,138 - train - INFO - alphas:tensor([0.4809, 0.0123, 0.0334, 0.0868, 0.3866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,155 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,155 - train - INFO - True
2024-04-07 08:54:33,155 - train - INFO - alphas:tensor([0.5074, 0.0163, 0.0234, 0.1022, 0.3507], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,172 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,172 - train - INFO - True
2024-04-07 08:54:33,173 - train - INFO - alphas:tensor([0.3726, 0.0097, 0.0114, 0.0964, 0.5099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,184 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,184 - train - INFO - True
2024-04-07 08:54:33,185 - train - INFO - alphas:tensor([0.3163, 0.0097, 0.0356, 0.1399, 0.4985], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,195 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,195 - train - INFO - True
2024-04-07 08:54:33,196 - train - INFO - alphas:tensor([0.4451, 0.0089, 0.0295, 0.0958, 0.4207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,215 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,215 - train - INFO - True
2024-04-07 08:54:33,216 - train - INFO - alphas:tensor([0.5343, 0.0156, 0.0215, 0.0930, 0.3355], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,235 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,235 - train - INFO - True
2024-04-07 08:54:33,236 - train - INFO - alphas:tensor([0.4145, 0.0079, 0.0146, 0.1047, 0.4583], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,245 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,245 - train - INFO - True
2024-04-07 08:54:33,245 - train - INFO - alphas:tensor([0.2949, 0.0088, 0.0335, 0.1325, 0.5303], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,255 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,255 - train - INFO - True
2024-04-07 08:54:33,255 - train - INFO - alphas:tensor([0.4052, 0.0068, 0.0248, 0.0878, 0.4755], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,265 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,265 - train - INFO - True
2024-04-07 08:54:33,265 - train - INFO - alphas:tensor([0.5227, 0.0178, 0.0213, 0.1011, 0.3372], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,283 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,283 - train - INFO - True
2024-04-07 08:54:33,284 - train - INFO - alphas:tensor([0.4352, 0.0079, 0.0172, 0.1099, 0.4298], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,301 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,301 - train - INFO - True
2024-04-07 08:54:33,302 - train - INFO - alphas:tensor([0.6872, 0.0443, 0.1005, 0.1680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 08:54:33,320 - train - INFO - tau:0.5811664141181095
2024-04-07 08:54:33,320 - train - INFO - avg block size:6.675675675675675
2024-04-07 08:54:33,320 - train - INFO - current latency ratio:tensor(0.6092)
2024-04-07 08:54:33,320 - train - INFO - lasso_alpha:0.00011918176537727237
2024-04-07 08:54:33,539 - train - INFO - Test: [   0/78]  Time: 0.215 (0.215)  Loss:  0.8950 (0.8950)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 08:54:38,582 - train - INFO - Test: [  50/78]  Time: 0.087 (0.103)  Loss:  1.9844 (1.6901)  Acc@1: 53.1250 (60.5239)  Acc@5: 79.6875 (83.3793)
2024-04-07 08:54:40,978 - train - INFO - Test: [  78/78]  Time: 0.053 (0.097)  Loss:  1.7051 (1.7184)  Acc@1: 56.2500 (60.1100)  Acc@5: 87.5000 (82.6900)
2024-04-07 08:54:42,276 - train - INFO - Train: 57 [   0/781 (  0%)]  Loss:  4.441334 (4.4413)  Time: 1.144s,  111.84/s  (1.144s,  111.84/s)  LR: 3.452e-04  Data: 0.174 (0.174)
2024-04-07 08:55:25,889 - train - INFO - Train: 57 [  50/781 (  6%)]  Loss:  4.040613 (4.0610)  Time: 0.845s,  151.49/s  (0.878s,  145.86/s)  LR: 3.452e-04  Data: 0.008 (0.010)
2024-04-07 08:56:08,944 - train - INFO - Train: 57 [ 100/781 ( 13%)]  Loss:  3.570827 (4.0743)  Time: 0.847s,  151.16/s  (0.869s,  147.23/s)  LR: 3.452e-04  Data: 0.007 (0.009)
2024-04-07 08:56:53,121 - train - INFO - Train: 57 [ 150/781 ( 19%)]  Loss:  4.461180 (4.0783)  Time: 0.826s,  154.99/s  (0.874s,  146.44/s)  LR: 3.452e-04  Data: 0.007 (0.008)
2024-04-07 08:57:38,231 - train - INFO - Train: 57 [ 200/781 ( 26%)]  Loss:  4.482038 (4.0677)  Time: 0.848s,  150.87/s  (0.881s,  145.28/s)  LR: 3.452e-04  Data: 0.009 (0.008)
2024-04-07 08:58:22,102 - train - INFO - Train: 57 [ 250/781 ( 32%)]  Loss:  4.508245 (4.0852)  Time: 0.788s,  162.39/s  (0.880s,  145.40/s)  LR: 3.452e-04  Data: 0.005 (0.008)
2024-04-07 08:59:05,650 - train - INFO - Train: 57 [ 300/781 ( 38%)]  Loss:  3.797701 (4.0709)  Time: 0.795s,  160.97/s  (0.879s,  145.66/s)  LR: 3.452e-04  Data: 0.006 (0.008)
2024-04-07 08:59:51,421 - train - INFO - Train: 57 [ 350/781 ( 45%)]  Loss:  3.826243 (4.0732)  Time: 1.121s,  114.15/s  (0.884s,  144.80/s)  LR: 3.452e-04  Data: 0.010 (0.007)
2024-04-07 09:00:35,312 - train - INFO - Train: 57 [ 400/781 ( 51%)]  Loss:  3.646523 (4.0815)  Time: 1.108s,  115.49/s  (0.883s,  144.93/s)  LR: 3.452e-04  Data: 0.008 (0.007)
2024-04-07 09:01:20,168 - train - INFO - Train: 57 [ 450/781 ( 58%)]  Loss:  4.194113 (4.0814)  Time: 0.800s,  160.07/s  (0.885s,  144.67/s)  LR: 3.452e-04  Data: 0.005 (0.007)
2024-04-07 09:02:04,223 - train - INFO - Train: 57 [ 500/781 ( 64%)]  Loss:  3.410756 (4.0969)  Time: 0.850s,  150.62/s  (0.884s,  144.73/s)  LR: 3.452e-04  Data: 0.008 (0.007)
2024-04-07 09:02:48,783 - train - INFO - Train: 57 [ 550/781 ( 71%)]  Loss:  4.358271 (4.0971)  Time: 0.835s,  153.24/s  (0.885s,  144.63/s)  LR: 3.452e-04  Data: 0.008 (0.007)
2024-04-07 09:03:35,477 - train - INFO - Train: 57 [ 600/781 ( 77%)]  Loss:  3.475468 (4.0922)  Time: 0.935s,  136.94/s  (0.889s,  143.97/s)  LR: 3.452e-04  Data: 0.006 (0.007)
2024-04-07 09:04:20,205 - train - INFO - Train: 57 [ 650/781 ( 83%)]  Loss:  3.421949 (4.0929)  Time: 1.086s,  117.86/s  (0.889s,  143.90/s)  LR: 3.452e-04  Data: 0.008 (0.007)
2024-04-07 09:05:05,103 - train - INFO - Train: 57 [ 700/781 ( 90%)]  Loss:  4.330891 (4.0936)  Time: 1.040s,  123.04/s  (0.890s,  143.81/s)  LR: 3.452e-04  Data: 0.006 (0.007)
2024-04-07 09:05:50,175 - train - INFO - Train: 57 [ 750/781 ( 96%)]  Loss:  3.945233 (4.0894)  Time: 0.821s,  155.91/s  (0.891s,  143.69/s)  LR: 3.452e-04  Data: 0.009 (0.007)
2024-04-07 09:06:16,422 - train - INFO - Train: 57 [ 780/781 (100%)]  Loss:  4.489525 (4.0857)  Time: 0.780s,  164.07/s  (0.890s,  143.78/s)  LR: 3.452e-04  Data: 0.000 (0.007)
2024-04-07 09:06:16,423 - train - INFO - True
2024-04-07 09:06:16,424 - train - INFO - alphas:tensor([0.0610, 0.0463, 0.1170, 0.3466, 0.4291], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,434 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,434 - train - INFO - True
2024-04-07 09:06:16,435 - train - INFO - alphas:tensor([0.1700, 0.0374, 0.0646, 0.1729, 0.5552], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,445 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,445 - train - INFO - True
2024-04-07 09:06:16,446 - train - INFO - alphas:tensor([0.6119, 0.0921, 0.0665, 0.1018, 0.1277], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,465 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,465 - train - INFO - True
2024-04-07 09:06:16,466 - train - INFO - alphas:tensor([0.4970, 0.0416, 0.0602, 0.1401, 0.2611], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,484 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,484 - train - INFO - True
2024-04-07 09:06:16,485 - train - INFO - alphas:tensor([0.3410, 0.0290, 0.0735, 0.1710, 0.3855], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,493 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,493 - train - INFO - True
2024-04-07 09:06:16,494 - train - INFO - alphas:tensor([0.4536, 0.0295, 0.0556, 0.1342, 0.3271], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,511 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,511 - train - INFO - True
2024-04-07 09:06:16,512 - train - INFO - alphas:tensor([0.5993, 0.0536, 0.0414, 0.1096, 0.1960], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,528 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,528 - train - INFO - True
2024-04-07 09:06:16,529 - train - INFO - alphas:tensor([0.4507, 0.0334, 0.0324, 0.1307, 0.3528], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,546 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,546 - train - INFO - True
2024-04-07 09:06:16,546 - train - INFO - alphas:tensor([0.4043, 0.0258, 0.0577, 0.1458, 0.3664], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,567 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,567 - train - INFO - True
2024-04-07 09:06:16,568 - train - INFO - alphas:tensor([0.5150, 0.0257, 0.0516, 0.1119, 0.2958], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,588 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,588 - train - INFO - True
2024-04-07 09:06:16,589 - train - INFO - alphas:tensor([0.5043, 0.0335, 0.0404, 0.1237, 0.2981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,607 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,607 - train - INFO - True
2024-04-07 09:06:16,608 - train - INFO - alphas:tensor([0.3913, 0.0186, 0.0292, 0.1413, 0.4196], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,617 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,617 - train - INFO - True
2024-04-07 09:06:16,618 - train - INFO - alphas:tensor([0.4142, 0.0193, 0.0475, 0.1405, 0.3785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,635 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,635 - train - INFO - True
2024-04-07 09:06:16,636 - train - INFO - alphas:tensor([0.5092, 0.0157, 0.0404, 0.1030, 0.3317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,653 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,653 - train - INFO - True
2024-04-07 09:06:16,653 - train - INFO - alphas:tensor([0.4225, 0.0366, 0.0341, 0.1301, 0.3767], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,670 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,670 - train - INFO - True
2024-04-07 09:06:16,671 - train - INFO - alphas:tensor([0.3085, 0.0135, 0.0177, 0.1324, 0.5278], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,679 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,679 - train - INFO - True
2024-04-07 09:06:16,680 - train - INFO - alphas:tensor([0.3982, 0.0191, 0.0417, 0.1371, 0.4039], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,688 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,688 - train - INFO - True
2024-04-07 09:06:16,689 - train - INFO - alphas:tensor([0.5056, 0.0139, 0.0368, 0.1000, 0.3438], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,710 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,710 - train - INFO - True
2024-04-07 09:06:16,711 - train - INFO - alphas:tensor([0.4299, 0.0216, 0.0278, 0.1269, 0.3937], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,731 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,731 - train - INFO - True
2024-04-07 09:06:16,732 - train - INFO - alphas:tensor([0.3097, 0.0108, 0.0147, 0.1182, 0.5465], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,741 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,742 - train - INFO - True
2024-04-07 09:06:16,742 - train - INFO - alphas:tensor([0.3482, 0.0135, 0.0400, 0.1418, 0.4565], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,752 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,752 - train - INFO - True
2024-04-07 09:06:16,752 - train - INFO - alphas:tensor([0.4847, 0.0118, 0.0338, 0.0940, 0.3757], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,770 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,770 - train - INFO - True
2024-04-07 09:06:16,771 - train - INFO - alphas:tensor([0.4674, 0.0262, 0.0256, 0.1095, 0.3712], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,788 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,788 - train - INFO - True
2024-04-07 09:06:16,789 - train - INFO - alphas:tensor([0.3366, 0.0085, 0.0115, 0.1032, 0.5401], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,797 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,797 - train - INFO - True
2024-04-07 09:06:16,798 - train - INFO - alphas:tensor([0.3342, 0.0110, 0.0361, 0.1360, 0.4827], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,806 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,806 - train - INFO - True
2024-04-07 09:06:16,807 - train - INFO - alphas:tensor([0.4689, 0.0115, 0.0326, 0.0863, 0.4006], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,827 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,827 - train - INFO - True
2024-04-07 09:06:16,828 - train - INFO - alphas:tensor([0.4971, 0.0153, 0.0222, 0.1017, 0.3638], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,848 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,848 - train - INFO - True
2024-04-07 09:06:16,848 - train - INFO - alphas:tensor([0.3629, 0.0089, 0.0105, 0.0951, 0.5227], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,858 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,858 - train - INFO - True
2024-04-07 09:06:16,859 - train - INFO - alphas:tensor([0.3089, 0.0091, 0.0343, 0.1381, 0.5097], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,868 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,869 - train - INFO - True
2024-04-07 09:06:16,869 - train - INFO - alphas:tensor([0.4380, 0.0082, 0.0284, 0.0936, 0.4317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,887 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,887 - train - INFO - True
2024-04-07 09:06:16,888 - train - INFO - alphas:tensor([0.5285, 0.0142, 0.0202, 0.0917, 0.3454], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,905 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,905 - train - INFO - True
2024-04-07 09:06:16,905 - train - INFO - alphas:tensor([0.4087, 0.0072, 0.0132, 0.1026, 0.4683], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,914 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,914 - train - INFO - True
2024-04-07 09:06:16,915 - train - INFO - alphas:tensor([0.2860, 0.0082, 0.0319, 0.1300, 0.5438], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,924 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,924 - train - INFO - True
2024-04-07 09:06:16,925 - train - INFO - alphas:tensor([0.3929, 0.0061, 0.0235, 0.0853, 0.4923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,936 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,936 - train - INFO - True
2024-04-07 09:06:16,936 - train - INFO - alphas:tensor([0.5145, 0.0169, 0.0200, 0.1003, 0.3482], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,956 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,956 - train - INFO - True
2024-04-07 09:06:16,957 - train - INFO - alphas:tensor([0.4263, 0.0073, 0.0157, 0.1089, 0.4418], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,967 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,967 - train - INFO - True
2024-04-07 09:06:16,967 - train - INFO - alphas:tensor([0.6854, 0.0437, 0.1006, 0.1703], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:06:16,986 - train - INFO - tau:0.5753547499769285
2024-04-07 09:06:16,986 - train - INFO - avg block size:7.486486486486487
2024-04-07 09:06:16,986 - train - INFO - current latency ratio:tensor(0.5488)
2024-04-07 09:06:17,243 - train - INFO - Test: [   0/78]  Time: 0.253 (0.253)  Loss:  0.9028 (0.9028)  Acc@1: 82.0312 (82.0312)  Acc@5: 92.9688 (92.9688)
2024-04-07 09:06:21,772 - train - INFO - Test: [  50/78]  Time: 0.088 (0.094)  Loss:  1.8965 (1.7052)  Acc@1: 56.2500 (60.2941)  Acc@5: 79.6875 (82.8585)
2024-04-07 09:06:24,185 - train - INFO - Test: [  78/78]  Time: 0.056 (0.091)  Loss:  1.9238 (1.7323)  Acc@1: 50.0000 (59.6600)  Acc@5: 93.7500 (82.3800)
2024-04-07 09:06:25,457 - train - INFO - Train: 58 [   0/781 (  0%)]  Loss:  3.795092 (3.7951)  Time: 1.206s,  106.13/s  (1.206s,  106.13/s)  LR: 3.404e-04  Data: 0.198 (0.198)
2024-04-07 09:07:11,498 - train - INFO - Train: 58 [  50/781 (  6%)]  Loss:  4.171193 (4.0673)  Time: 1.058s,  120.98/s  (0.926s,  138.17/s)  LR: 3.404e-04  Data: 0.009 (0.011)
2024-04-07 09:07:56,202 - train - INFO - Train: 58 [ 100/781 ( 13%)]  Loss:  4.418428 (4.0434)  Time: 0.912s,  140.39/s  (0.910s,  140.60/s)  LR: 3.404e-04  Data: 0.008 (0.009)
2024-04-07 09:08:41,194 - train - INFO - Train: 58 [ 150/781 ( 19%)]  Loss:  4.598678 (4.0671)  Time: 0.801s,  159.81/s  (0.907s,  141.14/s)  LR: 3.404e-04  Data: 0.004 (0.008)
2024-04-07 09:09:25,289 - train - INFO - Train: 58 [ 200/781 ( 26%)]  Loss:  4.018544 (4.0684)  Time: 0.888s,  144.20/s  (0.901s,  142.12/s)  LR: 3.404e-04  Data: 0.006 (0.008)
2024-04-07 09:10:10,371 - train - INFO - Train: 58 [ 250/781 ( 32%)]  Loss:  3.935952 (4.0980)  Time: 0.794s,  161.14/s  (0.901s,  142.09/s)  LR: 3.404e-04  Data: 0.004 (0.008)
2024-04-07 09:10:53,525 - train - INFO - Train: 58 [ 300/781 ( 38%)]  Loss:  4.234097 (4.0878)  Time: 0.842s,  152.02/s  (0.895s,  143.09/s)  LR: 3.404e-04  Data: 0.008 (0.008)
2024-04-07 09:11:38,563 - train - INFO - Train: 58 [ 350/781 ( 45%)]  Loss:  3.475946 (4.0820)  Time: 1.052s,  121.67/s  (0.895s,  142.95/s)  LR: 3.404e-04  Data: 0.008 (0.008)
2024-04-07 09:12:22,900 - train - INFO - Train: 58 [ 400/781 ( 51%)]  Loss:  4.559283 (4.0834)  Time: 0.951s,  134.59/s  (0.894s,  143.12/s)  LR: 3.404e-04  Data: 0.006 (0.008)
2024-04-07 09:13:06,094 - train - INFO - Train: 58 [ 450/781 ( 58%)]  Loss:  4.554965 (4.0919)  Time: 0.801s,  159.87/s  (0.891s,  143.66/s)  LR: 3.404e-04  Data: 0.008 (0.008)
2024-04-07 09:13:51,902 - train - INFO - Train: 58 [ 500/781 ( 64%)]  Loss:  3.834346 (4.0977)  Time: 0.858s,  149.21/s  (0.893s,  143.26/s)  LR: 3.404e-04  Data: 0.007 (0.008)
2024-04-07 09:14:37,885 - train - INFO - Train: 58 [ 550/781 ( 71%)]  Loss:  4.518062 (4.0999)  Time: 0.789s,  162.31/s  (0.896s,  142.88/s)  LR: 3.404e-04  Data: 0.004 (0.008)
2024-04-07 09:15:22,753 - train - INFO - Train: 58 [ 600/781 ( 77%)]  Loss:  4.474782 (4.1055)  Time: 1.017s,  125.89/s  (0.896s,  142.86/s)  LR: 3.404e-04  Data: 0.005 (0.007)
2024-04-07 09:16:05,718 - train - INFO - Train: 58 [ 650/781 ( 83%)]  Loss:  3.691028 (4.1027)  Time: 0.858s,  149.17/s  (0.893s,  143.31/s)  LR: 3.404e-04  Data: 0.009 (0.007)
2024-04-07 09:16:51,872 - train - INFO - Train: 58 [ 700/781 ( 90%)]  Loss:  4.719106 (4.1029)  Time: 1.115s,  114.76/s  (0.895s,  142.97/s)  LR: 3.404e-04  Data: 0.009 (0.007)
2024-04-07 09:17:35,895 - train - INFO - Train: 58 [ 750/781 ( 96%)]  Loss:  3.980499 (4.1047)  Time: 0.855s,  149.63/s  (0.894s,  143.13/s)  LR: 3.404e-04  Data: 0.008 (0.007)
2024-04-07 09:18:01,266 - train - INFO - Train: 58 [ 780/781 (100%)]  Loss:  4.037249 (4.0969)  Time: 0.837s,  152.89/s  (0.892s,  143.43/s)  LR: 3.404e-04  Data: 0.000 (0.007)
2024-04-07 09:18:01,267 - train - INFO - True
2024-04-07 09:18:01,269 - train - INFO - alphas:tensor([0.0557, 0.0433, 0.1126, 0.3505, 0.4379], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,289 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,289 - train - INFO - True
2024-04-07 09:18:01,290 - train - INFO - alphas:tensor([0.1640, 0.0359, 0.0627, 0.1709, 0.5665], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,308 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,308 - train - INFO - True
2024-04-07 09:18:01,309 - train - INFO - alphas:tensor([0.6023, 0.0929, 0.0675, 0.1048, 0.1324], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,340 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,340 - train - INFO - True
2024-04-07 09:18:01,341 - train - INFO - alphas:tensor([0.4895, 0.0401, 0.0593, 0.1418, 0.2692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,368 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,368 - train - INFO - True
2024-04-07 09:18:01,369 - train - INFO - alphas:tensor([0.3348, 0.0277, 0.0721, 0.1704, 0.3949], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,382 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,382 - train - INFO - True
2024-04-07 09:18:01,383 - train - INFO - alphas:tensor([0.4449, 0.0282, 0.0541, 0.1343, 0.3386], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,406 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,406 - train - INFO - True
2024-04-07 09:18:01,407 - train - INFO - alphas:tensor([0.5930, 0.0528, 0.0407, 0.1112, 0.2024], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,428 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,428 - train - INFO - True
2024-04-07 09:18:01,429 - train - INFO - alphas:tensor([0.4466, 0.0320, 0.0306, 0.1296, 0.3612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,450 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,450 - train - INFO - True
2024-04-07 09:18:01,451 - train - INFO - alphas:tensor([0.3969, 0.0248, 0.0562, 0.1456, 0.3765], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,472 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,472 - train - INFO - True
2024-04-07 09:18:01,472 - train - INFO - alphas:tensor([0.5070, 0.0241, 0.0505, 0.1119, 0.3064], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,492 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,492 - train - INFO - True
2024-04-07 09:18:01,493 - train - INFO - alphas:tensor([0.4946, 0.0322, 0.0398, 0.1248, 0.3086], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,512 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,512 - train - INFO - True
2024-04-07 09:18:01,512 - train - INFO - alphas:tensor([0.3833, 0.0177, 0.0276, 0.1406, 0.4307], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,521 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,522 - train - INFO - True
2024-04-07 09:18:01,522 - train - INFO - alphas:tensor([0.4071, 0.0183, 0.0462, 0.1403, 0.3881], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,539 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,540 - train - INFO - True
2024-04-07 09:18:01,540 - train - INFO - alphas:tensor([0.5021, 0.0145, 0.0386, 0.1023, 0.3425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,560 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,560 - train - INFO - True
2024-04-07 09:18:01,561 - train - INFO - alphas:tensor([0.4132, 0.0357, 0.0330, 0.1304, 0.3877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,581 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,581 - train - INFO - True
2024-04-07 09:18:01,581 - train - INFO - alphas:tensor([0.3023, 0.0127, 0.0166, 0.1318, 0.5365], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,591 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,591 - train - INFO - True
2024-04-07 09:18:01,592 - train - INFO - alphas:tensor([0.3912, 0.0181, 0.0398, 0.1359, 0.4150], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,601 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,601 - train - INFO - True
2024-04-07 09:18:01,602 - train - INFO - alphas:tensor([0.4969, 0.0127, 0.0357, 0.0993, 0.3554], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,619 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,619 - train - INFO - True
2024-04-07 09:18:01,620 - train - INFO - alphas:tensor([0.4231, 0.0205, 0.0265, 0.1264, 0.4036], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,637 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,637 - train - INFO - True
2024-04-07 09:18:01,637 - train - INFO - alphas:tensor([0.3051, 0.0101, 0.0137, 0.1167, 0.5543], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,646 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,646 - train - INFO - True
2024-04-07 09:18:01,647 - train - INFO - alphas:tensor([0.3403, 0.0128, 0.0383, 0.1409, 0.4676], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,655 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,655 - train - INFO - True
2024-04-07 09:18:01,656 - train - INFO - alphas:tensor([0.4768, 0.0109, 0.0323, 0.0926, 0.3875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,673 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,673 - train - INFO - True
2024-04-07 09:18:01,673 - train - INFO - alphas:tensor([0.4588, 0.0249, 0.0241, 0.1092, 0.3830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,692 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,692 - train - INFO - True
2024-04-07 09:18:01,693 - train - INFO - alphas:tensor([0.3293, 0.0080, 0.0105, 0.1017, 0.5504], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,704 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,704 - train - INFO - True
2024-04-07 09:18:01,705 - train - INFO - alphas:tensor([0.3289, 0.0103, 0.0341, 0.1334, 0.4932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,715 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,715 - train - INFO - True
2024-04-07 09:18:01,716 - train - INFO - alphas:tensor([0.4610, 0.0107, 0.0311, 0.0843, 0.4129], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,735 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,735 - train - INFO - True
2024-04-07 09:18:01,736 - train - INFO - alphas:tensor([0.4918, 0.0142, 0.0210, 0.1009, 0.3720], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,754 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,754 - train - INFO - True
2024-04-07 09:18:01,754 - train - INFO - alphas:tensor([0.3592, 0.0083, 0.0094, 0.0928, 0.5302], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,766 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,766 - train - INFO - True
2024-04-07 09:18:01,767 - train - INFO - alphas:tensor([0.3043, 0.0087, 0.0330, 0.1359, 0.5182], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,775 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,775 - train - INFO - True
2024-04-07 09:18:01,776 - train - INFO - alphas:tensor([0.4289, 0.0076, 0.0269, 0.0915, 0.4450], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,784 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,784 - train - INFO - True
2024-04-07 09:18:01,785 - train - INFO - alphas:tensor([0.5239, 0.0133, 0.0188, 0.0903, 0.3538], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,802 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,802 - train - INFO - True
2024-04-07 09:18:01,803 - train - INFO - alphas:tensor([0.4057, 0.0066, 0.0121, 0.1001, 0.4755], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,811 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,811 - train - INFO - True
2024-04-07 09:18:01,812 - train - INFO - alphas:tensor([0.2804, 0.0077, 0.0302, 0.1271, 0.5546], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,820 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,820 - train - INFO - True
2024-04-07 09:18:01,821 - train - INFO - alphas:tensor([0.3850, 0.0056, 0.0225, 0.0827, 0.5041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,831 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,831 - train - INFO - True
2024-04-07 09:18:01,832 - train - INFO - alphas:tensor([0.5078, 0.0160, 0.0190, 0.0990, 0.3582], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,853 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,853 - train - INFO - True
2024-04-07 09:18:01,853 - train - INFO - alphas:tensor([0.4213, 0.0066, 0.0144, 0.1060, 0.4517], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,863 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,863 - train - INFO - True
2024-04-07 09:18:01,864 - train - INFO - alphas:tensor([0.6820, 0.0434, 0.1012, 0.1734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:18:01,883 - train - INFO - tau:0.5696012024771592
2024-04-07 09:18:01,883 - train - INFO - avg block size:7.891891891891892
2024-04-07 09:18:01,883 - train - INFO - current latency ratio:tensor(0.5346)
2024-04-07 09:18:01,883 - train - INFO - lasso_alpha:0.0001310999419149996
2024-04-07 09:18:02,128 - train - INFO - Test: [   0/78]  Time: 0.242 (0.242)  Loss:  1.0674 (1.0674)  Acc@1: 77.3438 (77.3438)  Acc@5: 90.6250 (90.6250)
2024-04-07 09:18:06,943 - train - INFO - Test: [  50/78]  Time: 0.108 (0.099)  Loss:  2.0352 (1.7248)  Acc@1: 54.6875 (60.0643)  Acc@5: 78.1250 (82.6900)
2024-04-07 09:18:09,983 - train - INFO - Test: [  78/78]  Time: 0.065 (0.102)  Loss:  1.8066 (1.7497)  Acc@1: 50.0000 (59.5100)  Acc@5: 81.2500 (82.4200)
2024-04-07 09:18:11,306 - train - INFO - Train: 59 [   0/781 (  0%)]  Loss:  4.754698 (4.7547)  Time: 1.251s,  102.31/s  (1.251s,  102.31/s)  LR: 3.356e-04  Data: 0.196 (0.196)
2024-04-07 09:18:55,807 - train - INFO - Train: 59 [  50/781 (  6%)]  Loss:  3.482627 (4.2105)  Time: 0.843s,  151.82/s  (0.897s,  142.69/s)  LR: 3.356e-04  Data: 0.009 (0.011)
2024-04-07 09:19:41,576 - train - INFO - Train: 59 [ 100/781 ( 13%)]  Loss:  4.129849 (4.1136)  Time: 0.850s,  150.54/s  (0.906s,  141.26/s)  LR: 3.356e-04  Data: 0.008 (0.009)
2024-04-07 09:20:27,244 - train - INFO - Train: 59 [ 150/781 ( 19%)]  Loss:  4.368717 (4.1216)  Time: 0.841s,  152.14/s  (0.908s,  140.89/s)  LR: 3.356e-04  Data: 0.005 (0.008)
2024-04-07 09:21:11,125 - train - INFO - Train: 59 [ 200/781 ( 26%)]  Loss:  4.390909 (4.1259)  Time: 0.851s,  150.41/s  (0.901s,  142.10/s)  LR: 3.356e-04  Data: 0.008 (0.008)
2024-04-07 09:21:55,143 - train - INFO - Train: 59 [ 250/781 ( 32%)]  Loss:  4.209044 (4.1229)  Time: 1.026s,  124.71/s  (0.897s,  142.74/s)  LR: 3.356e-04  Data: 0.012 (0.008)
2024-04-07 09:22:39,329 - train - INFO - Train: 59 [ 300/781 ( 38%)]  Loss:  4.770055 (4.1215)  Time: 1.053s,  121.52/s  (0.895s,  143.09/s)  LR: 3.356e-04  Data: 0.007 (0.008)
2024-04-07 09:23:22,896 - train - INFO - Train: 59 [ 350/781 ( 45%)]  Loss:  4.238619 (4.1242)  Time: 0.850s,  150.60/s  (0.891s,  143.62/s)  LR: 3.356e-04  Data: 0.008 (0.008)
2024-04-07 09:24:08,460 - train - INFO - Train: 59 [ 400/781 ( 51%)]  Loss:  4.803322 (4.1203)  Time: 1.106s,  115.75/s  (0.894s,  143.22/s)  LR: 3.356e-04  Data: 0.008 (0.008)
2024-04-07 09:24:54,150 - train - INFO - Train: 59 [ 450/781 ( 58%)]  Loss:  4.353219 (4.1227)  Time: 0.959s,  133.46/s  (0.896s,  142.86/s)  LR: 3.356e-04  Data: 0.005 (0.007)
2024-04-07 09:25:39,044 - train - INFO - Train: 59 [ 500/781 ( 64%)]  Loss:  4.638124 (4.1260)  Time: 0.804s,  159.19/s  (0.896s,  142.83/s)  LR: 3.356e-04  Data: 0.004 (0.007)
2024-04-07 09:26:23,787 - train - INFO - Train: 59 [ 550/781 ( 71%)]  Loss:  4.269061 (4.1249)  Time: 1.091s,  117.37/s  (0.896s,  142.85/s)  LR: 3.356e-04  Data: 0.010 (0.007)
2024-04-07 09:27:08,377 - train - INFO - Train: 59 [ 600/781 ( 77%)]  Loss:  3.797688 (4.1271)  Time: 0.843s,  151.92/s  (0.896s,  142.91/s)  LR: 3.356e-04  Data: 0.009 (0.007)
2024-04-07 09:27:52,681 - train - INFO - Train: 59 [ 650/781 ( 83%)]  Loss:  4.695502 (4.1328)  Time: 0.856s,  149.57/s  (0.895s,  143.03/s)  LR: 3.356e-04  Data: 0.008 (0.007)
2024-04-07 09:28:36,103 - train - INFO - Train: 59 [ 700/781 ( 90%)]  Loss:  4.477366 (4.1344)  Time: 0.837s,  152.95/s  (0.893s,  143.33/s)  LR: 3.356e-04  Data: 0.007 (0.007)
2024-04-07 09:29:21,864 - train - INFO - Train: 59 [ 750/781 ( 96%)]  Loss:  3.583633 (4.1246)  Time: 0.843s,  151.92/s  (0.895s,  143.09/s)  LR: 3.356e-04  Data: 0.008 (0.007)
2024-04-07 09:29:47,757 - train - INFO - Train: 59 [ 780/781 (100%)]  Loss:  4.067533 (4.1295)  Time: 1.056s,  121.22/s  (0.893s,  143.29/s)  LR: 3.356e-04  Data: 0.000 (0.007)
2024-04-07 09:29:47,758 - train - INFO - True
2024-04-07 09:29:47,760 - train - INFO - alphas:tensor([0.0501, 0.0399, 0.1070, 0.3579, 0.4451], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:47,779 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:47,779 - train - INFO - True
2024-04-07 09:29:47,780 - train - INFO - alphas:tensor([0.1566, 0.0344, 0.0606, 0.1711, 0.5773], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:47,797 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:47,797 - train - INFO - True
2024-04-07 09:29:47,798 - train - INFO - alphas:tensor([0.5941, 0.0935, 0.0680, 0.1076, 0.1369], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:47,828 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:47,828 - train - INFO - True
2024-04-07 09:29:47,829 - train - INFO - alphas:tensor([0.4814, 0.0388, 0.0584, 0.1433, 0.2782], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:47,855 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:47,856 - train - INFO - True
2024-04-07 09:29:47,856 - train - INFO - alphas:tensor([0.3277, 0.0266, 0.0713, 0.1703, 0.4042], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:47,869 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:47,869 - train - INFO - True
2024-04-07 09:29:47,870 - train - INFO - alphas:tensor([0.4377, 0.0265, 0.0525, 0.1335, 0.3498], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:47,893 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:47,893 - train - INFO - True
2024-04-07 09:29:47,893 - train - INFO - alphas:tensor([0.5790, 0.0523, 0.0404, 0.1151, 0.2132], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:47,915 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:47,915 - train - INFO - True
2024-04-07 09:29:47,916 - train - INFO - alphas:tensor([0.4360, 0.0307, 0.0292, 0.1298, 0.3744], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:47,935 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:47,936 - train - INFO - True
2024-04-07 09:29:47,936 - train - INFO - alphas:tensor([0.3898, 0.0236, 0.0551, 0.1456, 0.3858], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:47,955 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:47,955 - train - INFO - True
2024-04-07 09:29:47,956 - train - INFO - alphas:tensor([0.5005, 0.0228, 0.0491, 0.1113, 0.3164], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:47,973 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:47,973 - train - INFO - True
2024-04-07 09:29:47,974 - train - INFO - alphas:tensor([0.4822, 0.0310, 0.0387, 0.1263, 0.3217], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:47,991 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:47,991 - train - INFO - True
2024-04-07 09:29:47,992 - train - INFO - alphas:tensor([0.3711, 0.0168, 0.0263, 0.1396, 0.4462], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,000 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,000 - train - INFO - True
2024-04-07 09:29:48,001 - train - INFO - alphas:tensor([0.4008, 0.0174, 0.0450, 0.1388, 0.3980], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,018 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,018 - train - INFO - True
2024-04-07 09:29:48,018 - train - INFO - alphas:tensor([0.4937, 0.0138, 0.0375, 0.1010, 0.3540], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,039 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,039 - train - INFO - True
2024-04-07 09:29:48,040 - train - INFO - alphas:tensor([0.3987, 0.0343, 0.0314, 0.1320, 0.4037], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,050 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,050 - train - INFO - True
2024-04-07 09:29:48,051 - train - INFO - alphas:tensor([0.2906, 0.0121, 0.0156, 0.1315, 0.5502], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,060 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,060 - train - INFO - True
2024-04-07 09:29:48,061 - train - INFO - alphas:tensor([0.3835, 0.0171, 0.0381, 0.1350, 0.4263], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,071 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,071 - train - INFO - True
2024-04-07 09:29:48,072 - train - INFO - alphas:tensor([0.4898, 0.0118, 0.0341, 0.0970, 0.3673], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,090 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,090 - train - INFO - True
2024-04-07 09:29:48,090 - train - INFO - alphas:tensor([0.4092, 0.0192, 0.0250, 0.1275, 0.4191], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,099 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,099 - train - INFO - True
2024-04-07 09:29:48,100 - train - INFO - alphas:tensor([0.2925, 0.0093, 0.0125, 0.1171, 0.5687], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,108 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,108 - train - INFO - True
2024-04-07 09:29:48,109 - train - INFO - alphas:tensor([0.3317, 0.0119, 0.0365, 0.1392, 0.4806], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,117 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,118 - train - INFO - True
2024-04-07 09:29:48,118 - train - INFO - alphas:tensor([0.4660, 0.0102, 0.0312, 0.0911, 0.4015], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,135 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,135 - train - INFO - True
2024-04-07 09:29:48,136 - train - INFO - alphas:tensor([0.4474, 0.0236, 0.0227, 0.1088, 0.3975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,153 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,153 - train - INFO - True
2024-04-07 09:29:48,153 - train - INFO - alphas:tensor([0.3204, 0.0074, 0.0095, 0.1009, 0.5619], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,162 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,162 - train - INFO - True
2024-04-07 09:29:48,163 - train - INFO - alphas:tensor([0.3202, 0.0098, 0.0328, 0.1314, 0.5058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,173 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,173 - train - INFO - True
2024-04-07 09:29:48,174 - train - INFO - alphas:tensor([0.4506, 0.0099, 0.0296, 0.0828, 0.4271], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,194 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,194 - train - INFO - True
2024-04-07 09:29:48,195 - train - INFO - alphas:tensor([0.4756, 0.0133, 0.0200, 0.1024, 0.3888], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,214 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,214 - train - INFO - True
2024-04-07 09:29:48,215 - train - INFO - alphas:tensor([0.3477, 0.0076, 0.0087, 0.0915, 0.5444], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,224 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,224 - train - INFO - True
2024-04-07 09:29:48,225 - train - INFO - alphas:tensor([0.2947, 0.0079, 0.0312, 0.1335, 0.5327], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,234 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,234 - train - INFO - True
2024-04-07 09:29:48,234 - train - INFO - alphas:tensor([0.4159, 0.0068, 0.0257, 0.0899, 0.4618], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,243 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,243 - train - INFO - True
2024-04-07 09:29:48,244 - train - INFO - alphas:tensor([0.5099, 0.0125, 0.0177, 0.0907, 0.3692], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,261 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,261 - train - INFO - True
2024-04-07 09:29:48,262 - train - INFO - alphas:tensor([0.3953, 0.0060, 0.0111, 0.0994, 0.4883], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,270 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,270 - train - INFO - True
2024-04-07 09:29:48,271 - train - INFO - alphas:tensor([0.2725, 0.0071, 0.0284, 0.1254, 0.5667], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,279 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,279 - train - INFO - True
2024-04-07 09:29:48,280 - train - INFO - alphas:tensor([0.3754, 0.0050, 0.0208, 0.0799, 0.5189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,289 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,289 - train - INFO - True
2024-04-07 09:29:48,289 - train - INFO - alphas:tensor([0.4978, 0.0151, 0.0178, 0.0992, 0.3700], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,306 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,306 - train - INFO - True
2024-04-07 09:29:48,307 - train - INFO - alphas:tensor([0.4094, 0.0060, 0.0133, 0.1051, 0.4661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,317 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,318 - train - INFO - True
2024-04-07 09:29:48,318 - train - INFO - alphas:tensor([0.6783, 0.0428, 0.1021, 0.1768], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:29:48,338 - train - INFO - tau:0.5639051904523876
2024-04-07 09:29:48,338 - train - INFO - avg block size:8.702702702702704
2024-04-07 09:29:48,339 - train - INFO - current latency ratio:tensor(0.4846)
2024-04-07 09:29:48,576 - train - INFO - Test: [   0/78]  Time: 0.234 (0.234)  Loss:  1.0146 (1.0146)  Acc@1: 78.9062 (78.9062)  Acc@5: 92.9688 (92.9688)
2024-04-07 09:29:53,158 - train - INFO - Test: [  50/78]  Time: 0.107 (0.094)  Loss:  1.8408 (1.7047)  Acc@1: 58.5938 (60.6158)  Acc@5: 83.5938 (83.1801)
2024-04-07 09:29:55,658 - train - INFO - Test: [  78/78]  Time: 0.056 (0.093)  Loss:  1.7041 (1.7327)  Acc@1: 56.2500 (59.9300)  Acc@5: 87.5000 (82.6400)
2024-04-07 09:29:56,962 - train - INFO - Train: 60 [   0/781 (  0%)]  Loss:  3.776022 (3.7760)  Time: 1.237s,  103.49/s  (1.237s,  103.49/s)  LR: 3.307e-04  Data: 0.175 (0.175)
2024-04-07 09:30:40,169 - train - INFO - Train: 60 [  50/781 (  6%)]  Loss:  4.303212 (4.1516)  Time: 0.847s,  151.10/s  (0.871s,  146.89/s)  LR: 3.307e-04  Data: 0.009 (0.010)
2024-04-07 09:31:25,368 - train - INFO - Train: 60 [ 100/781 ( 13%)]  Loss:  3.953370 (4.1438)  Time: 0.911s,  140.46/s  (0.888s,  144.22/s)  LR: 3.307e-04  Data: 0.005 (0.009)
2024-04-07 09:32:09,788 - train - INFO - Train: 60 [ 150/781 ( 19%)]  Loss:  3.373853 (4.1494)  Time: 0.837s,  152.86/s  (0.888s,  144.18/s)  LR: 3.307e-04  Data: 0.007 (0.008)
2024-04-07 09:32:54,081 - train - INFO - Train: 60 [ 200/781 ( 26%)]  Loss:  4.040255 (4.1269)  Time: 1.027s,  124.66/s  (0.887s,  144.26/s)  LR: 3.307e-04  Data: 0.006 (0.008)
2024-04-07 09:33:39,141 - train - INFO - Train: 60 [ 250/781 ( 32%)]  Loss:  3.982763 (4.1207)  Time: 0.833s,  153.74/s  (0.890s,  143.81/s)  LR: 3.307e-04  Data: 0.007 (0.008)
2024-04-07 09:34:23,657 - train - INFO - Train: 60 [ 300/781 ( 38%)]  Loss:  3.658446 (4.1049)  Time: 0.931s,  137.45/s  (0.890s,  143.80/s)  LR: 3.307e-04  Data: 0.009 (0.007)
2024-04-07 09:35:08,340 - train - INFO - Train: 60 [ 350/781 ( 45%)]  Loss:  4.412134 (4.0909)  Time: 1.076s,  118.95/s  (0.891s,  143.72/s)  LR: 3.307e-04  Data: 0.006 (0.007)
2024-04-07 09:35:52,986 - train - INFO - Train: 60 [ 400/781 ( 51%)]  Loss:  4.031147 (4.0899)  Time: 0.850s,  150.65/s  (0.891s,  143.68/s)  LR: 3.307e-04  Data: 0.008 (0.007)
2024-04-07 09:36:38,878 - train - INFO - Train: 60 [ 450/781 ( 58%)]  Loss:  4.487342 (4.0993)  Time: 0.837s,  152.90/s  (0.894s,  143.20/s)  LR: 3.307e-04  Data: 0.007 (0.007)
2024-04-07 09:37:23,400 - train - INFO - Train: 60 [ 500/781 ( 64%)]  Loss:  4.558840 (4.0996)  Time: 0.843s,  151.83/s  (0.894s,  143.25/s)  LR: 3.307e-04  Data: 0.008 (0.007)
2024-04-07 09:38:10,478 - train - INFO - Train: 60 [ 550/781 ( 71%)]  Loss:  4.558792 (4.1012)  Time: 0.853s,  150.14/s  (0.898s,  142.56/s)  LR: 3.307e-04  Data: 0.007 (0.007)
2024-04-07 09:38:55,561 - train - INFO - Train: 60 [ 600/781 ( 77%)]  Loss:  4.315092 (4.1037)  Time: 0.919s,  139.25/s  (0.898s,  142.51/s)  LR: 3.307e-04  Data: 0.008 (0.007)
2024-04-07 09:39:40,290 - train - INFO - Train: 60 [ 650/781 ( 83%)]  Loss:  4.448603 (4.0997)  Time: 0.832s,  153.78/s  (0.898s,  142.55/s)  LR: 3.307e-04  Data: 0.006 (0.007)
2024-04-07 09:40:25,807 - train - INFO - Train: 60 [ 700/781 ( 90%)]  Loss:  4.690342 (4.1015)  Time: 0.834s,  153.44/s  (0.899s,  142.41/s)  LR: 3.307e-04  Data: 0.008 (0.007)
2024-04-07 09:41:10,962 - train - INFO - Train: 60 [ 750/781 ( 96%)]  Loss:  4.463638 (4.1053)  Time: 1.108s,  115.48/s  (0.899s,  142.37/s)  LR: 3.307e-04  Data: 0.010 (0.007)
2024-04-07 09:41:37,884 - train - INFO - Train: 60 [ 780/781 (100%)]  Loss:  3.637074 (4.1069)  Time: 0.828s,  154.58/s  (0.899s,  142.38/s)  LR: 3.307e-04  Data: 0.000 (0.007)
2024-04-07 09:41:37,884 - train - INFO - True
2024-04-07 09:41:37,886 - train - INFO - alphas:tensor([0.0453, 0.0369, 0.1025, 0.3607, 0.4546], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:37,896 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:37,896 - train - INFO - True
2024-04-07 09:41:37,897 - train - INFO - alphas:tensor([0.1514, 0.0330, 0.0584, 0.1699, 0.5874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:37,908 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:37,908 - train - INFO - True
2024-04-07 09:41:37,909 - train - INFO - alphas:tensor([0.5848, 0.0942, 0.0687, 0.1106, 0.1417], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:37,930 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:37,930 - train - INFO - True
2024-04-07 09:41:37,931 - train - INFO - alphas:tensor([0.4719, 0.0381, 0.0577, 0.1446, 0.2877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:37,949 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:37,949 - train - INFO - True
2024-04-07 09:41:37,950 - train - INFO - alphas:tensor([0.3210, 0.0257, 0.0702, 0.1698, 0.4133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:37,959 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:37,959 - train - INFO - True
2024-04-07 09:41:37,959 - train - INFO - alphas:tensor([0.4288, 0.0251, 0.0513, 0.1340, 0.3609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:37,976 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:37,976 - train - INFO - True
2024-04-07 09:41:37,977 - train - INFO - alphas:tensor([0.5727, 0.0512, 0.0392, 0.1165, 0.2204], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:37,994 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:37,994 - train - INFO - True
2024-04-07 09:41:37,994 - train - INFO - alphas:tensor([0.4272, 0.0292, 0.0277, 0.1291, 0.3868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,015 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,016 - train - INFO - True
2024-04-07 09:41:38,016 - train - INFO - alphas:tensor([0.3826, 0.0224, 0.0539, 0.1450, 0.3962], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,026 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,026 - train - INFO - True
2024-04-07 09:41:38,027 - train - INFO - alphas:tensor([0.4898, 0.0216, 0.0485, 0.1117, 0.3283], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,045 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,045 - train - INFO - True
2024-04-07 09:41:38,046 - train - INFO - alphas:tensor([0.4763, 0.0302, 0.0375, 0.1259, 0.3301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,063 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,064 - train - INFO - True
2024-04-07 09:41:38,064 - train - INFO - alphas:tensor([0.3672, 0.0159, 0.0247, 0.1381, 0.4540], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,073 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,073 - train - INFO - True
2024-04-07 09:41:38,074 - train - INFO - alphas:tensor([0.3940, 0.0165, 0.0435, 0.1383, 0.4077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,082 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,082 - train - INFO - True
2024-04-07 09:41:38,083 - train - INFO - alphas:tensor([0.4858, 0.0127, 0.0361, 0.0995, 0.3659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,099 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,099 - train - INFO - True
2024-04-07 09:41:38,100 - train - INFO - alphas:tensor([0.3952, 0.0336, 0.0303, 0.1307, 0.4103], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,111 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,111 - train - INFO - True
2024-04-07 09:41:38,111 - train - INFO - alphas:tensor([0.2855, 0.0114, 0.0145, 0.1308, 0.5577], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,122 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,122 - train - INFO - True
2024-04-07 09:41:38,123 - train - INFO - alphas:tensor([0.3767, 0.0162, 0.0367, 0.1340, 0.4364], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,133 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,133 - train - INFO - True
2024-04-07 09:41:38,134 - train - INFO - alphas:tensor([0.4806, 0.0109, 0.0327, 0.0958, 0.3800], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,153 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,153 - train - INFO - True
2024-04-07 09:41:38,153 - train - INFO - alphas:tensor([0.4026, 0.0182, 0.0235, 0.1265, 0.4292], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,163 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,163 - train - INFO - True
2024-04-07 09:41:38,163 - train - INFO - alphas:tensor([0.2871, 0.0087, 0.0116, 0.1168, 0.5757], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,172 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,172 - train - INFO - True
2024-04-07 09:41:38,173 - train - INFO - alphas:tensor([0.3257, 0.0112, 0.0347, 0.1376, 0.4909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,182 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,182 - train - INFO - True
2024-04-07 09:41:38,182 - train - INFO - alphas:tensor([0.4611, 0.0093, 0.0296, 0.0886, 0.4114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,199 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,199 - train - INFO - True
2024-04-07 09:41:38,200 - train - INFO - alphas:tensor([0.4414, 0.0222, 0.0215, 0.1076, 0.4073], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,218 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,218 - train - INFO - True
2024-04-07 09:41:38,219 - train - INFO - alphas:tensor([0.3179, 0.0069, 0.0088, 0.0996, 0.5669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,230 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,230 - train - INFO - True
2024-04-07 09:41:38,231 - train - INFO - alphas:tensor([0.3139, 0.0091, 0.0314, 0.1292, 0.5163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,241 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,241 - train - INFO - True
2024-04-07 09:41:38,242 - train - INFO - alphas:tensor([0.4418, 0.0091, 0.0283, 0.0805, 0.4403], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,260 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,261 - train - INFO - True
2024-04-07 09:41:38,261 - train - INFO - alphas:tensor([0.4710, 0.0123, 0.0185, 0.1005, 0.3977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,279 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,279 - train - INFO - True
2024-04-07 09:41:38,280 - train - INFO - alphas:tensor([0.3421, 0.0072, 0.0078, 0.0891, 0.5539], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,288 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,288 - train - INFO - True
2024-04-07 09:41:38,289 - train - INFO - alphas:tensor([0.2899, 0.0074, 0.0294, 0.1312, 0.5420], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,298 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,298 - train - INFO - True
2024-04-07 09:41:38,298 - train - INFO - alphas:tensor([0.4120, 0.0062, 0.0242, 0.0874, 0.4702], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,307 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,307 - train - INFO - True
2024-04-07 09:41:38,307 - train - INFO - alphas:tensor([0.5036, 0.0115, 0.0164, 0.0898, 0.3786], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,326 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,326 - train - INFO - True
2024-04-07 09:41:38,327 - train - INFO - alphas:tensor([0.3888, 0.0055, 0.0103, 0.0974, 0.4981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,338 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,338 - train - INFO - True
2024-04-07 09:41:38,338 - train - INFO - alphas:tensor([0.2686, 0.0067, 0.0274, 0.1219, 0.5755], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,348 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,348 - train - INFO - True
2024-04-07 09:41:38,349 - train - INFO - alphas:tensor([0.3711, 0.0045, 0.0193, 0.0767, 0.5284], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,359 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,359 - train - INFO - True
2024-04-07 09:41:38,359 - train - INFO - alphas:tensor([0.4937, 0.0143, 0.0168, 0.0981, 0.3770], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,378 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,378 - train - INFO - True
2024-04-07 09:41:38,378 - train - INFO - alphas:tensor([0.4052, 0.0055, 0.0121, 0.1031, 0.4740], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,387 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,387 - train - INFO - True
2024-04-07 09:41:38,388 - train - INFO - alphas:tensor([0.6766, 0.0421, 0.1021, 0.1792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:41:38,405 - train - INFO - tau:0.5582661385478638
2024-04-07 09:41:38,405 - train - INFO - avg block size:9.513513513513514
2024-04-07 09:41:38,405 - train - INFO - current latency ratio:tensor(0.4138)
2024-04-07 09:41:38,405 - train - INFO - lasso_alpha:0.0001442099361064996
2024-04-07 09:41:38,651 - train - INFO - Test: [   0/78]  Time: 0.242 (0.242)  Loss:  0.9556 (0.9556)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 09:41:43,336 - train - INFO - Test: [  50/78]  Time: 0.088 (0.097)  Loss:  1.9102 (1.6686)  Acc@1: 53.9062 (61.2745)  Acc@5: 78.9062 (83.3946)
2024-04-07 09:41:45,773 - train - INFO - Test: [  78/78]  Time: 0.091 (0.093)  Loss:  1.8525 (1.7016)  Acc@1: 56.2500 (60.3200)  Acc@5: 87.5000 (82.8100)
2024-04-07 09:41:47,062 - train - INFO - Train: 61 [   0/781 (  0%)]  Loss:  4.713008 (4.7130)  Time: 1.165s,  109.85/s  (1.165s,  109.85/s)  LR: 3.258e-04  Data: 0.189 (0.189)
2024-04-07 09:42:32,212 - train - INFO - Train: 61 [  50/781 (  6%)]  Loss:  3.647470 (4.1776)  Time: 0.838s,  152.78/s  (0.908s,  140.95/s)  LR: 3.258e-04  Data: 0.008 (0.011)
2024-04-07 09:43:17,413 - train - INFO - Train: 61 [ 100/781 ( 13%)]  Loss:  4.313466 (4.1730)  Time: 0.832s,  153.85/s  (0.906s,  141.27/s)  LR: 3.258e-04  Data: 0.005 (0.009)
2024-04-07 09:44:00,675 - train - INFO - Train: 61 [ 150/781 ( 19%)]  Loss:  4.198969 (4.1716)  Time: 0.852s,  150.15/s  (0.893s,  143.41/s)  LR: 3.258e-04  Data: 0.009 (0.008)
2024-04-07 09:44:44,230 - train - INFO - Train: 61 [ 200/781 ( 26%)]  Loss:  4.521236 (4.1754)  Time: 0.799s,  160.19/s  (0.887s,  144.27/s)  LR: 3.258e-04  Data: 0.005 (0.008)
2024-04-07 09:45:28,664 - train - INFO - Train: 61 [ 250/781 ( 32%)]  Loss:  4.005915 (4.1773)  Time: 0.850s,  150.56/s  (0.887s,  144.23/s)  LR: 3.258e-04  Data: 0.010 (0.008)
2024-04-07 09:46:13,997 - train - INFO - Train: 61 [ 300/781 ( 38%)]  Loss:  4.200216 (4.1731)  Time: 0.889s,  143.98/s  (0.891s,  143.71/s)  LR: 3.258e-04  Data: 0.008 (0.008)
2024-04-07 09:46:57,097 - train - INFO - Train: 61 [ 350/781 ( 45%)]  Loss:  3.943661 (4.1782)  Time: 0.848s,  150.93/s  (0.887s,  144.38/s)  LR: 3.258e-04  Data: 0.009 (0.008)
2024-04-07 09:47:41,398 - train - INFO - Train: 61 [ 400/781 ( 51%)]  Loss:  3.956171 (4.1691)  Time: 0.823s,  155.56/s  (0.887s,  144.39/s)  LR: 3.258e-04  Data: 0.007 (0.008)
2024-04-07 09:48:24,513 - train - INFO - Train: 61 [ 450/781 ( 58%)]  Loss:  4.497026 (4.1704)  Time: 0.812s,  157.69/s  (0.884s,  144.83/s)  LR: 3.258e-04  Data: 0.004 (0.008)
2024-04-07 09:49:09,309 - train - INFO - Train: 61 [ 500/781 ( 64%)]  Loss:  3.691772 (4.1706)  Time: 0.805s,  159.02/s  (0.885s,  144.63/s)  LR: 3.258e-04  Data: 0.006 (0.007)
2024-04-07 09:49:54,155 - train - INFO - Train: 61 [ 550/781 ( 71%)]  Loss:  4.420803 (4.1761)  Time: 0.800s,  159.98/s  (0.886s,  144.45/s)  LR: 3.258e-04  Data: 0.004 (0.007)
2024-04-07 09:50:38,013 - train - INFO - Train: 61 [ 600/781 ( 77%)]  Loss:  3.756795 (4.1678)  Time: 1.101s,  116.22/s  (0.885s,  144.58/s)  LR: 3.258e-04  Data: 0.006 (0.007)
2024-04-07 09:51:23,617 - train - INFO - Train: 61 [ 650/781 ( 83%)]  Loss:  3.470961 (4.1672)  Time: 0.839s,  152.64/s  (0.887s,  144.24/s)  LR: 3.258e-04  Data: 0.007 (0.007)
2024-04-07 09:52:08,486 - train - INFO - Train: 61 [ 700/781 ( 90%)]  Loss:  4.712299 (4.1607)  Time: 0.819s,  156.26/s  (0.888s,  144.13/s)  LR: 3.258e-04  Data: 0.006 (0.007)
2024-04-07 09:52:53,271 - train - INFO - Train: 61 [ 750/781 ( 96%)]  Loss:  3.713032 (4.1582)  Time: 0.812s,  157.59/s  (0.889s,  144.04/s)  LR: 3.258e-04  Data: 0.005 (0.007)
2024-04-07 09:53:19,460 - train - INFO - Train: 61 [ 780/781 (100%)]  Loss:  3.728987 (4.1583)  Time: 0.823s,  155.58/s  (0.888s,  144.14/s)  LR: 3.258e-04  Data: 0.000 (0.007)
2024-04-07 09:53:19,461 - train - INFO - True
2024-04-07 09:53:19,463 - train - INFO - alphas:tensor([0.0402, 0.0335, 0.0960, 0.3656, 0.4646], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,486 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,486 - train - INFO - True
2024-04-07 09:53:19,487 - train - INFO - alphas:tensor([0.1445, 0.0314, 0.0567, 0.1681, 0.5993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,507 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,507 - train - INFO - True
2024-04-07 09:53:19,508 - train - INFO - alphas:tensor([0.5748, 0.0944, 0.0695, 0.1140, 0.1473], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,542 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,542 - train - INFO - True
2024-04-07 09:53:19,543 - train - INFO - alphas:tensor([0.4645, 0.0365, 0.0564, 0.1458, 0.2967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,572 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,572 - train - INFO - True
2024-04-07 09:53:19,573 - train - INFO - alphas:tensor([0.3116, 0.0244, 0.0695, 0.1705, 0.4240], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,586 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,586 - train - INFO - True
2024-04-07 09:53:19,587 - train - INFO - alphas:tensor([0.4198, 0.0236, 0.0498, 0.1330, 0.3738], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,611 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,611 - train - INFO - True
2024-04-07 09:53:19,612 - train - INFO - alphas:tensor([0.5610, 0.0499, 0.0388, 0.1194, 0.2308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,635 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,635 - train - INFO - True
2024-04-07 09:53:19,635 - train - INFO - alphas:tensor([0.4201, 0.0283, 0.0261, 0.1289, 0.3967], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,656 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,656 - train - INFO - True
2024-04-07 09:53:19,657 - train - INFO - alphas:tensor([0.3764, 0.0213, 0.0523, 0.1442, 0.4057], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,667 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,667 - train - INFO - True
2024-04-07 09:53:19,668 - train - INFO - alphas:tensor([0.4830, 0.0205, 0.0469, 0.1105, 0.3391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,687 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,687 - train - INFO - True
2024-04-07 09:53:19,687 - train - INFO - alphas:tensor([0.4638, 0.0291, 0.0363, 0.1277, 0.3431], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,705 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,705 - train - INFO - True
2024-04-07 09:53:19,706 - train - INFO - alphas:tensor([0.3560, 0.0150, 0.0233, 0.1382, 0.4675], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,715 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,715 - train - INFO - True
2024-04-07 09:53:19,716 - train - INFO - alphas:tensor([0.3842, 0.0157, 0.0423, 0.1381, 0.4197], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,725 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,725 - train - INFO - True
2024-04-07 09:53:19,725 - train - INFO - alphas:tensor([0.4786, 0.0116, 0.0351, 0.0977, 0.3770], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,742 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,742 - train - INFO - True
2024-04-07 09:53:19,743 - train - INFO - alphas:tensor([0.3807, 0.0322, 0.0290, 0.1320, 0.4261], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,753 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,753 - train - INFO - True
2024-04-07 09:53:19,754 - train - INFO - alphas:tensor([0.2739, 0.0106, 0.0135, 0.1312, 0.5707], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,764 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,764 - train - INFO - True
2024-04-07 09:53:19,765 - train - INFO - alphas:tensor([0.3699, 0.0155, 0.0353, 0.1328, 0.4465], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,783 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,783 - train - INFO - True
2024-04-07 09:53:19,785 - train - INFO - alphas:tensor([0.4713, 0.0101, 0.0313, 0.0941, 0.3932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,822 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,822 - train - INFO - True
2024-04-07 09:53:19,823 - train - INFO - alphas:tensor([0.3911, 0.0168, 0.0221, 0.1266, 0.4434], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,839 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,839 - train - INFO - True
2024-04-07 09:53:19,840 - train - INFO - alphas:tensor([0.2767, 0.0081, 0.0107, 0.1164, 0.5880], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,855 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,855 - train - INFO - True
2024-04-07 09:53:19,856 - train - INFO - alphas:tensor([0.3167, 0.0104, 0.0334, 0.1356, 0.5039], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,871 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,871 - train - INFO - True
2024-04-07 09:53:19,872 - train - INFO - alphas:tensor([0.4504, 0.0084, 0.0284, 0.0869, 0.4259], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,900 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,900 - train - INFO - True
2024-04-07 09:53:19,901 - train - INFO - alphas:tensor([0.4250, 0.0212, 0.0202, 0.1097, 0.4240], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,929 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,929 - train - INFO - True
2024-04-07 09:53:19,930 - train - INFO - alphas:tensor([0.3040, 0.0063, 0.0080, 0.0982, 0.5835], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,945 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,945 - train - INFO - True
2024-04-07 09:53:19,946 - train - INFO - alphas:tensor([0.3071, 0.0086, 0.0299, 0.1270, 0.5273], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,960 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,960 - train - INFO - True
2024-04-07 09:53:19,961 - train - INFO - alphas:tensor([0.4363, 0.0083, 0.0270, 0.0784, 0.4500], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:19,975 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:19,975 - train - INFO - True
2024-04-07 09:53:19,976 - train - INFO - alphas:tensor([0.4615, 0.0113, 0.0172, 0.0996, 0.4104], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:20,005 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:20,005 - train - INFO - True
2024-04-07 09:53:20,006 - train - INFO - alphas:tensor([0.3350, 0.0067, 0.0071, 0.0874, 0.5638], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:20,020 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:20,020 - train - INFO - True
2024-04-07 09:53:20,021 - train - INFO - alphas:tensor([0.2814, 0.0070, 0.0281, 0.1293, 0.5542], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:20,035 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:20,035 - train - INFO - True
2024-04-07 09:53:20,036 - train - INFO - alphas:tensor([0.3978, 0.0056, 0.0230, 0.0853, 0.4883], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:20,051 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:20,051 - train - INFO - True
2024-04-07 09:53:20,052 - train - INFO - alphas:tensor([0.4945, 0.0108, 0.0154, 0.0886, 0.3907], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:20,081 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:20,081 - train - INFO - True
2024-04-07 09:53:20,082 - train - INFO - alphas:tensor([0.3782, 0.0050, 0.0093, 0.0967, 0.5108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:20,097 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:20,097 - train - INFO - True
2024-04-07 09:53:20,098 - train - INFO - alphas:tensor([0.2619, 0.0063, 0.0257, 0.1202, 0.5860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:20,112 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:20,112 - train - INFO - True
2024-04-07 09:53:20,113 - train - INFO - alphas:tensor([0.3606, 0.0040, 0.0181, 0.0743, 0.5429], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:20,127 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:20,128 - train - INFO - True
2024-04-07 09:53:20,128 - train - INFO - alphas:tensor([0.4822, 0.0134, 0.0158, 0.0976, 0.3910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:20,157 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:20,157 - train - INFO - True
2024-04-07 09:53:20,158 - train - INFO - alphas:tensor([0.3949, 0.0051, 0.0111, 0.1019, 0.4870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:20,172 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:20,172 - train - INFO - True
2024-04-07 09:53:20,173 - train - INFO - alphas:tensor([0.6725, 0.0417, 0.1028, 0.1830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 09:53:20,201 - train - INFO - tau:0.5526834771623851
2024-04-07 09:53:20,201 - train - INFO - avg block size:9.91891891891892
2024-04-07 09:53:20,202 - train - INFO - current latency ratio:tensor(0.3996)
2024-04-07 09:53:20,435 - train - INFO - Test: [   0/78]  Time: 0.229 (0.229)  Loss:  0.9707 (0.9707)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 09:53:25,243 - train - INFO - Test: [  50/78]  Time: 0.086 (0.099)  Loss:  1.8770 (1.7140)  Acc@1: 53.9062 (60.1869)  Acc@5: 83.5938 (82.5061)
2024-04-07 09:53:27,657 - train - INFO - Test: [  78/78]  Time: 0.055 (0.094)  Loss:  1.7168 (1.7264)  Acc@1: 56.2500 (59.9000)  Acc@5: 87.5000 (82.2500)
2024-04-07 09:53:28,988 - train - INFO - Train: 62 [   0/781 (  0%)]  Loss:  4.002799 (4.0028)  Time: 1.267s,  101.00/s  (1.267s,  101.00/s)  LR: 3.209e-04  Data: 0.182 (0.182)
2024-04-07 09:54:15,157 - train - INFO - Train: 62 [  50/781 (  6%)]  Loss:  3.848396 (4.1979)  Time: 0.886s,  144.53/s  (0.930s,  137.62/s)  LR: 3.209e-04  Data: 0.005 (0.010)
2024-04-07 09:55:02,070 - train - INFO - Train: 62 [ 100/781 ( 13%)]  Loss:  3.522818 (4.1669)  Time: 0.960s,  133.40/s  (0.934s,  137.03/s)  LR: 3.209e-04  Data: 0.005 (0.009)
2024-04-07 09:55:46,272 - train - INFO - Train: 62 [ 150/781 ( 19%)]  Loss:  4.283976 (4.1832)  Time: 1.037s,  123.41/s  (0.918s,  139.51/s)  LR: 3.209e-04  Data: 0.006 (0.008)
2024-04-07 09:56:32,851 - train - INFO - Train: 62 [ 200/781 ( 26%)]  Loss:  4.096385 (4.1820)  Time: 0.847s,  151.20/s  (0.921s,  138.98/s)  LR: 3.209e-04  Data: 0.007 (0.008)
2024-04-07 09:57:18,558 - train - INFO - Train: 62 [ 250/781 ( 32%)]  Loss:  3.520567 (4.1738)  Time: 0.823s,  155.43/s  (0.920s,  139.19/s)  LR: 3.209e-04  Data: 0.004 (0.008)
2024-04-07 09:58:04,473 - train - INFO - Train: 62 [ 300/781 ( 38%)]  Loss:  4.258574 (4.1737)  Time: 0.848s,  150.87/s  (0.919s,  139.22/s)  LR: 3.209e-04  Data: 0.007 (0.008)
2024-04-07 09:58:50,307 - train - INFO - Train: 62 [ 350/781 ( 45%)]  Loss:  4.293067 (4.1615)  Time: 0.912s,  140.42/s  (0.919s,  139.28/s)  LR: 3.209e-04  Data: 0.006 (0.007)
2024-04-07 09:59:36,306 - train - INFO - Train: 62 [ 400/781 ( 51%)]  Loss:  4.026485 (4.1545)  Time: 0.808s,  158.46/s  (0.919s,  139.26/s)  LR: 3.209e-04  Data: 0.004 (0.007)
2024-04-07 10:00:22,359 - train - INFO - Train: 62 [ 450/781 ( 58%)]  Loss:  4.388696 (4.1496)  Time: 1.076s,  118.97/s  (0.919s,  139.23/s)  LR: 3.209e-04  Data: 0.008 (0.007)
2024-04-07 10:01:06,778 - train - INFO - Train: 62 [ 500/781 ( 64%)]  Loss:  4.604365 (4.1499)  Time: 0.821s,  155.96/s  (0.916s,  139.70/s)  LR: 3.209e-04  Data: 0.004 (0.007)
2024-04-07 10:01:52,395 - train - INFO - Train: 62 [ 550/781 ( 71%)]  Loss:  4.658199 (4.1448)  Time: 1.062s,  120.52/s  (0.916s,  139.76/s)  LR: 3.209e-04  Data: 0.008 (0.007)
2024-04-07 10:02:36,853 - train - INFO - Train: 62 [ 600/781 ( 77%)]  Loss:  3.849435 (4.1403)  Time: 0.895s,  142.95/s  (0.914s,  140.10/s)  LR: 3.209e-04  Data: 0.007 (0.007)
2024-04-07 10:03:23,134 - train - INFO - Train: 62 [ 650/781 ( 83%)]  Loss:  3.880476 (4.1426)  Time: 0.844s,  151.59/s  (0.915s,  139.96/s)  LR: 3.209e-04  Data: 0.007 (0.007)
2024-04-07 10:04:08,983 - train - INFO - Train: 62 [ 700/781 ( 90%)]  Loss:  4.676328 (4.1417)  Time: 0.873s,  146.57/s  (0.915s,  139.93/s)  LR: 3.209e-04  Data: 0.005 (0.007)
2024-04-07 10:04:54,980 - train - INFO - Train: 62 [ 750/781 ( 96%)]  Loss:  4.254361 (4.1374)  Time: 0.846s,  151.21/s  (0.915s,  139.88/s)  LR: 3.209e-04  Data: 0.007 (0.007)
2024-04-07 10:05:22,795 - train - INFO - Train: 62 [ 780/781 (100%)]  Loss:  4.555041 (4.1385)  Time: 1.085s,  117.95/s  (0.916s,  139.81/s)  LR: 3.209e-04  Data: 0.000 (0.007)
2024-04-07 10:05:22,796 - train - INFO - True
2024-04-07 10:05:22,799 - train - INFO - alphas:tensor([0.0361, 0.0308, 0.0915, 0.3667, 0.4749], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:22,825 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:22,825 - train - INFO - True
2024-04-07 10:05:22,826 - train - INFO - alphas:tensor([0.1395, 0.0301, 0.0549, 0.1657, 0.6099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:22,848 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:22,848 - train - INFO - True
2024-04-07 10:05:22,850 - train - INFO - alphas:tensor([0.5660, 0.0948, 0.0701, 0.1169, 0.1523], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:22,886 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:22,887 - train - INFO - True
2024-04-07 10:05:22,888 - train - INFO - alphas:tensor([0.4577, 0.0349, 0.0552, 0.1467, 0.3055], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:22,918 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:22,918 - train - INFO - True
2024-04-07 10:05:22,919 - train - INFO - alphas:tensor([0.3063, 0.0233, 0.0677, 0.1700, 0.4327], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:22,932 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:22,932 - train - INFO - True
2024-04-07 10:05:22,933 - train - INFO - alphas:tensor([0.4134, 0.0221, 0.0481, 0.1321, 0.3843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:22,958 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:22,958 - train - INFO - True
2024-04-07 10:05:22,959 - train - INFO - alphas:tensor([0.5519, 0.0489, 0.0380, 0.1213, 0.2399], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:22,982 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:22,982 - train - INFO - True
2024-04-07 10:05:22,983 - train - INFO - alphas:tensor([0.4120, 0.0273, 0.0246, 0.1288, 0.4073], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,005 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,005 - train - INFO - True
2024-04-07 10:05:23,006 - train - INFO - alphas:tensor([0.3676, 0.0203, 0.0513, 0.1438, 0.4170], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,016 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,016 - train - INFO - True
2024-04-07 10:05:23,017 - train - INFO - alphas:tensor([0.4759, 0.0193, 0.0456, 0.1092, 0.3499], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,036 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,036 - train - INFO - True
2024-04-07 10:05:23,036 - train - INFO - alphas:tensor([0.4557, 0.0279, 0.0348, 0.1280, 0.3535], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,056 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,056 - train - INFO - True
2024-04-07 10:05:23,057 - train - INFO - alphas:tensor([0.3513, 0.0142, 0.0220, 0.1378, 0.4746], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,068 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,068 - train - INFO - True
2024-04-07 10:05:23,069 - train - INFO - alphas:tensor([0.3782, 0.0149, 0.0412, 0.1365, 0.4291], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,079 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,079 - train - INFO - True
2024-04-07 10:05:23,080 - train - INFO - alphas:tensor([0.4718, 0.0108, 0.0336, 0.0959, 0.3879], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,099 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,099 - train - INFO - True
2024-04-07 10:05:23,099 - train - INFO - alphas:tensor([0.3711, 0.0313, 0.0279, 0.1326, 0.4371], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,109 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,109 - train - INFO - True
2024-04-07 10:05:23,110 - train - INFO - alphas:tensor([0.2669, 0.0101, 0.0125, 0.1312, 0.5793], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,119 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,119 - train - INFO - True
2024-04-07 10:05:23,120 - train - INFO - alphas:tensor([0.3636, 0.0146, 0.0337, 0.1308, 0.4572], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,129 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,129 - train - INFO - True
2024-04-07 10:05:23,129 - train - INFO - alphas:tensor([0.4674, 0.0094, 0.0299, 0.0919, 0.4014], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,146 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,146 - train - INFO - True
2024-04-07 10:05:23,147 - train - INFO - alphas:tensor([0.3821, 0.0159, 0.0209, 0.1270, 0.4541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,155 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,155 - train - INFO - True
2024-04-07 10:05:23,156 - train - INFO - alphas:tensor([0.2702, 0.0076, 0.0099, 0.1159, 0.5963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,164 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,164 - train - INFO - True
2024-04-07 10:05:23,165 - train - INFO - alphas:tensor([0.3131, 0.0098, 0.0320, 0.1334, 0.5117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,174 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,174 - train - INFO - True
2024-04-07 10:05:23,174 - train - INFO - alphas:tensor([0.4396, 0.0077, 0.0272, 0.0859, 0.4397], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,183 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,183 - train - INFO - True
2024-04-07 10:05:23,183 - train - INFO - alphas:tensor([0.4208, 0.0202, 0.0188, 0.1074, 0.4328], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,192 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,192 - train - INFO - True
2024-04-07 10:05:23,193 - train - INFO - alphas:tensor([0.2999, 0.0059, 0.0071, 0.0959, 0.5912], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,204 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,204 - train - INFO - True
2024-04-07 10:05:23,205 - train - INFO - alphas:tensor([0.3012, 0.0080, 0.0283, 0.1255, 0.5370], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,217 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,217 - train - INFO - True
2024-04-07 10:05:23,218 - train - INFO - alphas:tensor([0.4288, 0.0077, 0.0258, 0.0752, 0.4626], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,228 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,229 - train - INFO - True
2024-04-07 10:05:23,229 - train - INFO - alphas:tensor([0.4548, 0.0104, 0.0160, 0.0988, 0.4200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,249 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,249 - train - INFO - True
2024-04-07 10:05:23,250 - train - INFO - alphas:tensor([0.3285, 0.0062, 0.0065, 0.0860, 0.5729], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,259 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,259 - train - INFO - True
2024-04-07 10:05:23,260 - train - INFO - alphas:tensor([0.2762, 0.0066, 0.0268, 0.1270, 0.5634], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,269 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,269 - train - INFO - True
2024-04-07 10:05:23,270 - train - INFO - alphas:tensor([0.3954, 0.0051, 0.0217, 0.0824, 0.4954], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,279 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,279 - train - INFO - True
2024-04-07 10:05:23,279 - train - INFO - alphas:tensor([0.4883, 0.0101, 0.0143, 0.0874, 0.3999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,296 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,297 - train - INFO - True
2024-04-07 10:05:23,297 - train - INFO - alphas:tensor([0.3742, 0.0046, 0.0084, 0.0947, 0.5181], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,306 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,306 - train - INFO - True
2024-04-07 10:05:23,306 - train - INFO - alphas:tensor([0.2562, 0.0058, 0.0243, 0.1170, 0.5966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,315 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,315 - train - INFO - True
2024-04-07 10:05:23,316 - train - INFO - alphas:tensor([0.3532, 0.0036, 0.0172, 0.0712, 0.5548], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,324 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,324 - train - INFO - True
2024-04-07 10:05:23,325 - train - INFO - alphas:tensor([0.4767, 0.0127, 0.0148, 0.0962, 0.3997], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,342 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,342 - train - INFO - True
2024-04-07 10:05:23,342 - train - INFO - alphas:tensor([0.3909, 0.0046, 0.0101, 0.0990, 0.4953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,351 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,351 - train - INFO - True
2024-04-07 10:05:23,352 - train - INFO - alphas:tensor([0.6696, 0.0410, 0.1033, 0.1861], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:05:23,373 - train - INFO - tau:0.5471566423907612
2024-04-07 10:05:23,373 - train - INFO - avg block size:10.72972972972973
2024-04-07 10:05:23,373 - train - INFO - current latency ratio:tensor(0.3605)
2024-04-07 10:05:23,373 - train - INFO - lasso_alpha:0.00015863092971714956
2024-04-07 10:05:23,621 - train - INFO - Test: [   0/78]  Time: 0.243 (0.243)  Loss:  0.9585 (0.9585)  Acc@1: 79.6875 (79.6875)  Acc@5: 92.9688 (92.9688)
2024-04-07 10:05:28,422 - train - INFO - Test: [  50/78]  Time: 0.091 (0.099)  Loss:  1.7568 (1.6888)  Acc@1: 62.5000 (60.6464)  Acc@5: 83.5938 (83.1955)
2024-04-07 10:05:30,877 - train - INFO - Test: [  78/78]  Time: 0.057 (0.095)  Loss:  1.7656 (1.7181)  Acc@1: 56.2500 (60.0900)  Acc@5: 81.2500 (82.7300)
2024-04-07 10:05:32,133 - train - INFO - Train: 63 [   0/781 (  0%)]  Loss:  3.869877 (3.8699)  Time: 1.178s,  108.70/s  (1.178s,  108.70/s)  LR: 3.159e-04  Data: 0.187 (0.187)
2024-04-07 10:06:18,464 - train - INFO - Train: 63 [  50/781 (  6%)]  Loss:  4.468999 (4.2066)  Time: 0.830s,  154.22/s  (0.932s,  137.41/s)  LR: 3.159e-04  Data: 0.007 (0.011)
2024-04-07 10:07:05,093 - train - INFO - Train: 63 [ 100/781 ( 13%)]  Loss:  4.388620 (4.1875)  Time: 0.874s,  146.45/s  (0.932s,  137.34/s)  LR: 3.159e-04  Data: 0.010 (0.009)
2024-04-07 10:07:50,778 - train - INFO - Train: 63 [ 150/781 ( 19%)]  Loss:  4.334754 (4.1701)  Time: 0.985s,  129.89/s  (0.926s,  138.24/s)  LR: 3.159e-04  Data: 0.005 (0.008)
2024-04-07 10:08:36,830 - train - INFO - Train: 63 [ 200/781 ( 26%)]  Loss:  4.022813 (4.1702)  Time: 1.075s,  119.11/s  (0.925s,  138.42/s)  LR: 3.159e-04  Data: 0.005 (0.008)
2024-04-07 10:09:22,862 - train - INFO - Train: 63 [ 250/781 ( 32%)]  Loss:  4.617331 (4.1834)  Time: 0.854s,  149.94/s  (0.924s,  138.54/s)  LR: 3.159e-04  Data: 0.016 (0.008)
2024-04-07 10:10:08,099 - train - INFO - Train: 63 [ 300/781 ( 38%)]  Loss:  3.831978 (4.1829)  Time: 0.845s,  151.53/s  (0.921s,  139.02/s)  LR: 3.159e-04  Data: 0.009 (0.008)
2024-04-07 10:10:52,231 - train - INFO - Train: 63 [ 350/781 ( 45%)]  Loss:  3.704405 (4.1748)  Time: 0.853s,  150.06/s  (0.915s,  139.85/s)  LR: 3.159e-04  Data: 0.009 (0.008)
2024-04-07 10:11:37,146 - train - INFO - Train: 63 [ 400/781 ( 51%)]  Loss:  4.808867 (4.1763)  Time: 0.811s,  157.77/s  (0.913s,  140.17/s)  LR: 3.159e-04  Data: 0.005 (0.008)
2024-04-07 10:12:22,423 - train - INFO - Train: 63 [ 450/781 ( 58%)]  Loss:  4.738188 (4.1733)  Time: 0.857s,  149.42/s  (0.912s,  140.30/s)  LR: 3.159e-04  Data: 0.008 (0.007)
2024-04-07 10:13:07,152 - train - INFO - Train: 63 [ 500/781 ( 64%)]  Loss:  4.079889 (4.1772)  Time: 0.846s,  151.38/s  (0.911s,  140.58/s)  LR: 3.159e-04  Data: 0.009 (0.007)
2024-04-07 10:13:50,675 - train - INFO - Train: 63 [ 550/781 ( 71%)]  Loss:  4.527299 (4.1707)  Time: 0.843s,  151.78/s  (0.907s,  141.14/s)  LR: 3.159e-04  Data: 0.008 (0.007)
2024-04-07 10:14:37,939 - train - INFO - Train: 63 [ 600/781 ( 77%)]  Loss:  3.925278 (4.1640)  Time: 0.985s,  129.91/s  (0.910s,  140.65/s)  LR: 3.159e-04  Data: 0.007 (0.007)
2024-04-07 10:15:24,212 - train - INFO - Train: 63 [ 650/781 ( 83%)]  Loss:  4.629363 (4.1734)  Time: 0.850s,  150.52/s  (0.911s,  140.46/s)  LR: 3.159e-04  Data: 0.008 (0.007)
2024-04-07 10:16:10,781 - train - INFO - Train: 63 [ 700/781 ( 90%)]  Loss:  3.514257 (4.1689)  Time: 0.862s,  148.45/s  (0.913s,  140.24/s)  LR: 3.159e-04  Data: 0.008 (0.007)
2024-04-07 10:16:55,756 - train - INFO - Train: 63 [ 750/781 ( 96%)]  Loss:  4.497387 (4.1734)  Time: 0.839s,  152.61/s  (0.912s,  140.38/s)  LR: 3.159e-04  Data: 0.007 (0.007)
2024-04-07 10:17:23,229 - train - INFO - Train: 63 [ 780/781 (100%)]  Loss:  4.188189 (4.1765)  Time: 0.796s,  160.80/s  (0.912s,  140.36/s)  LR: 3.159e-04  Data: 0.000 (0.007)
2024-04-07 10:17:23,230 - train - INFO - True
2024-04-07 10:17:23,231 - train - INFO - alphas:tensor([0.0321, 0.0282, 0.0870, 0.3666, 0.4860], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,244 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,244 - train - INFO - True
2024-04-07 10:17:23,245 - train - INFO - alphas:tensor([0.1339, 0.0286, 0.0535, 0.1633, 0.6208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,256 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,256 - train - INFO - True
2024-04-07 10:17:23,257 - train - INFO - alphas:tensor([0.5554, 0.0958, 0.0708, 0.1200, 0.1580], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,279 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,279 - train - INFO - True
2024-04-07 10:17:23,280 - train - INFO - alphas:tensor([0.4515, 0.0339, 0.0541, 0.1472, 0.3133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,300 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,300 - train - INFO - True
2024-04-07 10:17:23,301 - train - INFO - alphas:tensor([0.3003, 0.0223, 0.0667, 0.1688, 0.4420], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,311 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,311 - train - INFO - True
2024-04-07 10:17:23,312 - train - INFO - alphas:tensor([0.4053, 0.0205, 0.0470, 0.1318, 0.3954], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,330 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,330 - train - INFO - True
2024-04-07 10:17:23,331 - train - INFO - alphas:tensor([0.5418, 0.0477, 0.0371, 0.1236, 0.2498], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,348 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,348 - train - INFO - True
2024-04-07 10:17:23,349 - train - INFO - alphas:tensor([0.4031, 0.0262, 0.0233, 0.1287, 0.4188], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,358 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,358 - train - INFO - True
2024-04-07 10:17:23,358 - train - INFO - alphas:tensor([0.3611, 0.0193, 0.0503, 0.1428, 0.4264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,367 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,367 - train - INFO - True
2024-04-07 10:17:23,368 - train - INFO - alphas:tensor([0.4656, 0.0180, 0.0443, 0.1090, 0.3631], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,385 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,385 - train - INFO - True
2024-04-07 10:17:23,386 - train - INFO - alphas:tensor([0.4449, 0.0274, 0.0337, 0.1284, 0.3656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,407 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,407 - train - INFO - True
2024-04-07 10:17:23,408 - train - INFO - alphas:tensor([0.3408, 0.0134, 0.0208, 0.1373, 0.4876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,418 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,418 - train - INFO - True
2024-04-07 10:17:23,419 - train - INFO - alphas:tensor([0.3716, 0.0142, 0.0400, 0.1355, 0.4386], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,429 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,429 - train - INFO - True
2024-04-07 10:17:23,429 - train - INFO - alphas:tensor([0.4634, 0.0100, 0.0323, 0.0946, 0.3998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,450 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,450 - train - INFO - True
2024-04-07 10:17:23,451 - train - INFO - alphas:tensor([0.3595, 0.0302, 0.0269, 0.1329, 0.4505], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,460 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,460 - train - INFO - True
2024-04-07 10:17:23,460 - train - INFO - alphas:tensor([0.2561, 0.0093, 0.0114, 0.1323, 0.5908], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,469 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,469 - train - INFO - True
2024-04-07 10:17:23,470 - train - INFO - alphas:tensor([0.3564, 0.0138, 0.0328, 0.1297, 0.4673], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,478 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,478 - train - INFO - True
2024-04-07 10:17:23,479 - train - INFO - alphas:tensor([0.4585, 0.0087, 0.0285, 0.0904, 0.4138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,496 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,496 - train - INFO - True
2024-04-07 10:17:23,497 - train - INFO - alphas:tensor([0.3687, 0.0149, 0.0195, 0.1274, 0.4696], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,505 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,505 - train - INFO - True
2024-04-07 10:17:23,506 - train - INFO - alphas:tensor([0.2594, 0.0070, 0.0090, 0.1166, 0.6079], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,514 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,514 - train - INFO - True
2024-04-07 10:17:23,515 - train - INFO - alphas:tensor([0.3030, 0.0091, 0.0307, 0.1321, 0.5251], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,524 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,524 - train - INFO - True
2024-04-07 10:17:23,524 - train - INFO - alphas:tensor([0.4297, 0.0070, 0.0262, 0.0832, 0.4538], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,535 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,535 - train - INFO - True
2024-04-07 10:17:23,536 - train - INFO - alphas:tensor([0.4058, 0.0190, 0.0177, 0.1076, 0.4499], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,547 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,547 - train - INFO - True
2024-04-07 10:17:23,547 - train - INFO - alphas:tensor([0.2892, 0.0056, 0.0066, 0.0957, 0.6030], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,557 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,557 - train - INFO - True
2024-04-07 10:17:23,558 - train - INFO - alphas:tensor([0.2951, 0.0075, 0.0271, 0.1232, 0.5472], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,567 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,568 - train - INFO - True
2024-04-07 10:17:23,568 - train - INFO - alphas:tensor([0.4178, 0.0069, 0.0243, 0.0727, 0.4783], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,578 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,578 - train - INFO - True
2024-04-07 10:17:23,578 - train - INFO - alphas:tensor([0.4399, 0.0097, 0.0150, 0.0993, 0.4362], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,596 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,596 - train - INFO - True
2024-04-07 10:17:23,597 - train - INFO - alphas:tensor([0.3172, 0.0057, 0.0058, 0.0850, 0.5862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,606 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,606 - train - INFO - True
2024-04-07 10:17:23,607 - train - INFO - alphas:tensor([0.2703, 0.0061, 0.0253, 0.1239, 0.5744], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,616 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,616 - train - INFO - True
2024-04-07 10:17:23,616 - train - INFO - alphas:tensor([0.3855, 0.0046, 0.0205, 0.0797, 0.5097], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,625 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,625 - train - INFO - True
2024-04-07 10:17:23,626 - train - INFO - alphas:tensor([0.4768, 0.0092, 0.0133, 0.0871, 0.4135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,643 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,643 - train - INFO - True
2024-04-07 10:17:23,644 - train - INFO - alphas:tensor([0.3651, 0.0042, 0.0076, 0.0927, 0.5304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,652 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,652 - train - INFO - True
2024-04-07 10:17:23,653 - train - INFO - alphas:tensor([0.2487, 0.0054, 0.0224, 0.1146, 0.6089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,662 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,662 - train - INFO - True
2024-04-07 10:17:23,663 - train - INFO - alphas:tensor([0.3455, 0.0032, 0.0163, 0.0674, 0.5676], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,674 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,674 - train - INFO - True
2024-04-07 10:17:23,674 - train - INFO - alphas:tensor([0.4658, 0.0118, 0.0138, 0.0954, 0.4132], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,694 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,694 - train - INFO - True
2024-04-07 10:17:23,695 - train - INFO - alphas:tensor([0.3813, 0.0042, 0.0092, 0.0969, 0.5084], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,705 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,705 - train - INFO - True
2024-04-07 10:17:23,706 - train - INFO - alphas:tensor([0.6670, 0.0405, 0.1035, 0.1890], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:17:23,724 - train - INFO - tau:0.5416850759668536
2024-04-07 10:17:23,724 - train - INFO - avg block size:11.135135135135135
2024-04-07 10:17:23,724 - train - INFO - current latency ratio:tensor(0.3354)
2024-04-07 10:17:23,973 - train - INFO - Test: [   0/78]  Time: 0.246 (0.246)  Loss:  0.8984 (0.8984)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 10:17:28,592 - train - INFO - Test: [  50/78]  Time: 0.084 (0.095)  Loss:  1.8848 (1.6943)  Acc@1: 52.3438 (60.6311)  Acc@5: 83.5938 (83.3793)
2024-04-07 10:17:31,193 - train - INFO - Test: [  78/78]  Time: 0.059 (0.095)  Loss:  1.6680 (1.7314)  Acc@1: 50.0000 (59.8200)  Acc@5: 93.7500 (82.6000)
2024-04-07 10:17:32,499 - train - INFO - Train: 64 [   0/781 (  0%)]  Loss:  3.776241 (3.7762)  Time: 1.243s,  102.97/s  (1.243s,  102.97/s)  LR: 3.109e-04  Data: 0.167 (0.167)
2024-04-07 10:18:17,832 - train - INFO - Train: 64 [  50/781 (  6%)]  Loss:  3.469115 (4.1237)  Time: 0.846s,  151.34/s  (0.913s,  140.16/s)  LR: 3.109e-04  Data: 0.007 (0.010)
2024-04-07 10:19:03,069 - train - INFO - Train: 64 [ 100/781 ( 13%)]  Loss:  4.773897 (4.1583)  Time: 1.094s,  116.97/s  (0.909s,  140.81/s)  LR: 3.109e-04  Data: 0.008 (0.009)
2024-04-07 10:19:47,552 - train - INFO - Train: 64 [ 150/781 ( 19%)]  Loss:  3.686146 (4.1736)  Time: 0.898s,  142.49/s  (0.903s,  141.81/s)  LR: 3.109e-04  Data: 0.007 (0.008)
2024-04-07 10:20:32,887 - train - INFO - Train: 64 [ 200/781 ( 26%)]  Loss:  3.823052 (4.1831)  Time: 0.860s,  148.85/s  (0.904s,  141.65/s)  LR: 3.109e-04  Data: 0.008 (0.008)
2024-04-07 10:21:19,146 - train - INFO - Train: 64 [ 250/781 ( 32%)]  Loss:  3.419755 (4.1742)  Time: 0.819s,  156.36/s  (0.908s,  140.99/s)  LR: 3.109e-04  Data: 0.006 (0.008)
2024-04-07 10:22:04,290 - train - INFO - Train: 64 [ 300/781 ( 38%)]  Loss:  4.554124 (4.1663)  Time: 0.811s,  157.90/s  (0.907s,  141.12/s)  LR: 3.109e-04  Data: 0.004 (0.007)
2024-04-07 10:22:48,941 - train - INFO - Train: 64 [ 350/781 ( 45%)]  Loss:  4.550771 (4.1680)  Time: 0.792s,  161.54/s  (0.905s,  141.43/s)  LR: 3.109e-04  Data: 0.005 (0.007)
2024-04-07 10:23:34,139 - train - INFO - Train: 64 [ 400/781 ( 51%)]  Loss:  4.247575 (4.1703)  Time: 0.833s,  153.73/s  (0.905s,  141.45/s)  LR: 3.109e-04  Data: 0.007 (0.007)
2024-04-07 10:24:18,909 - train - INFO - Train: 64 [ 450/781 ( 58%)]  Loss:  4.801371 (4.1810)  Time: 1.038s,  123.30/s  (0.904s,  141.62/s)  LR: 3.109e-04  Data: 0.010 (0.007)
2024-04-07 10:25:04,229 - train - INFO - Train: 64 [ 500/781 ( 64%)]  Loss:  4.390485 (4.1844)  Time: 1.083s,  118.22/s  (0.904s,  141.58/s)  LR: 3.109e-04  Data: 0.009 (0.007)
2024-04-07 10:25:50,205 - train - INFO - Train: 64 [ 550/781 ( 71%)]  Loss:  4.634127 (4.1788)  Time: 1.070s,  119.64/s  (0.905s,  141.36/s)  LR: 3.109e-04  Data: 0.006 (0.007)
2024-04-07 10:26:36,721 - train - INFO - Train: 64 [ 600/781 ( 77%)]  Loss:  3.879979 (4.1750)  Time: 0.867s,  147.60/s  (0.908s,  141.04/s)  LR: 3.109e-04  Data: 0.010 (0.007)
2024-04-07 10:27:24,304 - train - INFO - Train: 64 [ 650/781 ( 83%)]  Loss:  3.852454 (4.1719)  Time: 1.073s,  119.28/s  (0.911s,  140.51/s)  LR: 3.109e-04  Data: 0.008 (0.007)
2024-04-07 10:28:09,884 - train - INFO - Train: 64 [ 700/781 ( 90%)]  Loss:  4.096991 (4.1702)  Time: 0.810s,  158.06/s  (0.911s,  140.51/s)  LR: 3.109e-04  Data: 0.005 (0.007)
2024-04-07 10:28:56,345 - train - INFO - Train: 64 [ 750/781 ( 96%)]  Loss:  3.729017 (4.1696)  Time: 1.017s,  125.82/s  (0.912s,  140.32/s)  LR: 3.109e-04  Data: 0.006 (0.007)
2024-04-07 10:29:23,529 - train - INFO - Train: 64 [ 780/781 (100%)]  Loss:  4.632181 (4.1717)  Time: 1.053s,  121.56/s  (0.912s,  140.36/s)  LR: 3.109e-04  Data: 0.000 (0.007)
2024-04-07 10:29:23,530 - train - INFO - True
2024-04-07 10:29:23,532 - train - INFO - alphas:tensor([0.0285, 0.0256, 0.0821, 0.3645, 0.4993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,553 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,553 - train - INFO - True
2024-04-07 10:29:23,555 - train - INFO - alphas:tensor([0.1291, 0.0275, 0.0525, 0.1623, 0.6287], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,572 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,572 - train - INFO - True
2024-04-07 10:29:23,573 - train - INFO - alphas:tensor([0.5462, 0.0955, 0.0714, 0.1232, 0.1637], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,603 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,603 - train - INFO - True
2024-04-07 10:29:23,604 - train - INFO - alphas:tensor([0.4453, 0.0325, 0.0524, 0.1480, 0.3219], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,636 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,636 - train - INFO - True
2024-04-07 10:29:23,637 - train - INFO - alphas:tensor([0.2934, 0.0215, 0.0650, 0.1686, 0.4515], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,649 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,649 - train - INFO - True
2024-04-07 10:29:23,650 - train - INFO - alphas:tensor([0.3973, 0.0195, 0.0452, 0.1309, 0.4071], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,662 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,662 - train - INFO - True
2024-04-07 10:29:23,663 - train - INFO - alphas:tensor([0.5340, 0.0463, 0.0361, 0.1252, 0.2584], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,684 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,684 - train - INFO - True
2024-04-07 10:29:23,685 - train - INFO - alphas:tensor([0.3971, 0.0246, 0.0219, 0.1277, 0.4287], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,695 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,695 - train - INFO - True
2024-04-07 10:29:23,696 - train - INFO - alphas:tensor([0.3559, 0.0184, 0.0484, 0.1415, 0.4357], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,706 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,706 - train - INFO - True
2024-04-07 10:29:23,707 - train - INFO - alphas:tensor([0.4590, 0.0169, 0.0427, 0.1081, 0.3733], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,726 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,726 - train - INFO - True
2024-04-07 10:29:23,727 - train - INFO - alphas:tensor([0.4390, 0.0267, 0.0325, 0.1284, 0.3734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,745 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,745 - train - INFO - True
2024-04-07 10:29:23,746 - train - INFO - alphas:tensor([0.3365, 0.0128, 0.0195, 0.1360, 0.4953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,755 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,756 - train - INFO - True
2024-04-07 10:29:23,756 - train - INFO - alphas:tensor([0.3649, 0.0134, 0.0390, 0.1342, 0.4485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,766 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,766 - train - INFO - True
2024-04-07 10:29:23,767 - train - INFO - alphas:tensor([0.4577, 0.0093, 0.0312, 0.0924, 0.4094], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,788 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,788 - train - INFO - True
2024-04-07 10:29:23,789 - train - INFO - alphas:tensor([0.3540, 0.0292, 0.0259, 0.1331, 0.4579], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,799 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,799 - train - INFO - True
2024-04-07 10:29:23,800 - train - INFO - alphas:tensor([0.2533, 0.0089, 0.0107, 0.1319, 0.5953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,810 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,810 - train - INFO - True
2024-04-07 10:29:23,811 - train - INFO - alphas:tensor([0.3488, 0.0131, 0.0315, 0.1279, 0.4788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,820 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,820 - train - INFO - True
2024-04-07 10:29:23,821 - train - INFO - alphas:tensor([0.4485, 0.0080, 0.0272, 0.0890, 0.4273], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,840 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,840 - train - INFO - True
2024-04-07 10:29:23,840 - train - INFO - alphas:tensor([0.3642, 0.0141, 0.0181, 0.1264, 0.4772], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,850 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,850 - train - INFO - True
2024-04-07 10:29:23,850 - train - INFO - alphas:tensor([0.2568, 0.0066, 0.0083, 0.1165, 0.6118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,860 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,860 - train - INFO - True
2024-04-07 10:29:23,861 - train - INFO - alphas:tensor([0.2987, 0.0086, 0.0294, 0.1299, 0.5334], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,870 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,870 - train - INFO - True
2024-04-07 10:29:23,871 - train - INFO - alphas:tensor([0.4239, 0.0066, 0.0249, 0.0805, 0.4641], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,880 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,880 - train - INFO - True
2024-04-07 10:29:23,881 - train - INFO - alphas:tensor([0.3990, 0.0181, 0.0166, 0.1067, 0.4596], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,890 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,890 - train - INFO - True
2024-04-07 10:29:23,891 - train - INFO - alphas:tensor([0.2842, 0.0052, 0.0060, 0.0942, 0.6104], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,899 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,899 - train - INFO - True
2024-04-07 10:29:23,900 - train - INFO - alphas:tensor([0.2888, 0.0070, 0.0259, 0.1208, 0.5575], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,909 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,909 - train - INFO - True
2024-04-07 10:29:23,910 - train - INFO - alphas:tensor([0.4127, 0.0063, 0.0229, 0.0707, 0.4874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,921 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,921 - train - INFO - True
2024-04-07 10:29:23,922 - train - INFO - alphas:tensor([0.4371, 0.0089, 0.0139, 0.0976, 0.4425], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,932 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,932 - train - INFO - True
2024-04-07 10:29:23,933 - train - INFO - alphas:tensor([0.3163, 0.0054, 0.0053, 0.0831, 0.5900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,943 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,943 - train - INFO - True
2024-04-07 10:29:23,944 - train - INFO - alphas:tensor([0.2628, 0.0057, 0.0243, 0.1226, 0.5846], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,953 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,953 - train - INFO - True
2024-04-07 10:29:23,954 - train - INFO - alphas:tensor([0.3783, 0.0041, 0.0194, 0.0767, 0.5215], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,963 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,963 - train - INFO - True
2024-04-07 10:29:23,964 - train - INFO - alphas:tensor([0.4697, 0.0084, 0.0124, 0.0857, 0.4238], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,982 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,982 - train - INFO - True
2024-04-07 10:29:23,982 - train - INFO - alphas:tensor([0.3589, 0.0038, 0.0069, 0.0913, 0.5391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:23,991 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:23,991 - train - INFO - True
2024-04-07 10:29:23,992 - train - INFO - alphas:tensor([0.2444, 0.0050, 0.0211, 0.1117, 0.6177], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:24,000 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:24,000 - train - INFO - True
2024-04-07 10:29:24,001 - train - INFO - alphas:tensor([0.3417, 0.0029, 0.0149, 0.0641, 0.5764], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:24,010 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:24,010 - train - INFO - True
2024-04-07 10:29:24,010 - train - INFO - alphas:tensor([0.4579, 0.0111, 0.0129, 0.0943, 0.4238], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:24,027 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:24,027 - train - INFO - True
2024-04-07 10:29:24,028 - train - INFO - alphas:tensor([0.3770, 0.0038, 0.0083, 0.0949, 0.5160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:24,036 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:24,036 - train - INFO - True
2024-04-07 10:29:24,037 - train - INFO - alphas:tensor([0.6638, 0.0397, 0.1040, 0.1925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:29:24,054 - train - INFO - tau:0.536268225207185
2024-04-07 10:29:24,054 - train - INFO - avg block size:11.945945945945946
2024-04-07 10:29:24,054 - train - INFO - current latency ratio:tensor(0.2963)
2024-04-07 10:29:24,054 - train - INFO - lasso_alpha:0.00017449402268886454
2024-04-07 10:29:24,305 - train - INFO - Test: [   0/78]  Time: 0.248 (0.248)  Loss:  1.0303 (1.0303)  Acc@1: 77.3438 (77.3438)  Acc@5: 92.1875 (92.1875)
2024-04-07 10:29:29,012 - train - INFO - Test: [  50/78]  Time: 0.087 (0.097)  Loss:  1.9180 (1.6978)  Acc@1: 57.0312 (60.4013)  Acc@5: 81.2500 (83.0576)
2024-04-07 10:29:31,454 - train - INFO - Test: [  78/78]  Time: 0.060 (0.094)  Loss:  1.5762 (1.7198)  Acc@1: 56.2500 (59.9200)  Acc@5: 87.5000 (82.6400)
2024-04-07 10:29:32,708 - train - INFO - Train: 65 [   0/781 (  0%)]  Loss:  4.438405 (4.4384)  Time: 1.190s,  107.58/s  (1.190s,  107.58/s)  LR: 3.059e-04  Data: 0.181 (0.181)
2024-04-07 10:30:18,684 - train - INFO - Train: 65 [  50/781 (  6%)]  Loss:  4.463243 (4.2661)  Time: 0.814s,  157.24/s  (0.925s,  138.41/s)  LR: 3.059e-04  Data: 0.005 (0.010)
2024-04-07 10:31:05,050 - train - INFO - Train: 65 [ 100/781 ( 13%)]  Loss:  4.674716 (4.2265)  Time: 1.050s,  121.95/s  (0.926s,  138.23/s)  LR: 3.059e-04  Data: 0.007 (0.008)
2024-04-07 10:31:49,667 - train - INFO - Train: 65 [ 150/781 ( 19%)]  Loss:  4.081508 (4.2030)  Time: 0.806s,  158.74/s  (0.915s,  139.91/s)  LR: 3.059e-04  Data: 0.005 (0.008)
2024-04-07 10:32:32,933 - train - INFO - Train: 65 [ 200/781 ( 26%)]  Loss:  4.594928 (4.2175)  Time: 0.979s,  130.74/s  (0.903s,  141.82/s)  LR: 3.059e-04  Data: 0.006 (0.008)
2024-04-07 10:33:18,344 - train - INFO - Train: 65 [ 250/781 ( 32%)]  Loss:  4.507121 (4.2142)  Time: 0.829s,  154.41/s  (0.904s,  141.65/s)  LR: 3.059e-04  Data: 0.004 (0.007)
2024-04-07 10:34:02,302 - train - INFO - Train: 65 [ 300/781 ( 38%)]  Loss:  4.335407 (4.2041)  Time: 0.871s,  147.04/s  (0.900s,  142.29/s)  LR: 3.059e-04  Data: 0.022 (0.007)
2024-04-07 10:34:46,982 - train - INFO - Train: 65 [ 350/781 ( 45%)]  Loss:  4.647748 (4.2044)  Time: 1.007s,  127.13/s  (0.899s,  142.42/s)  LR: 3.059e-04  Data: 0.009 (0.007)
2024-04-07 10:35:32,614 - train - INFO - Train: 65 [ 400/781 ( 51%)]  Loss:  4.706721 (4.2040)  Time: 0.812s,  157.64/s  (0.900s,  142.15/s)  LR: 3.059e-04  Data: 0.004 (0.007)
2024-04-07 10:36:18,544 - train - INFO - Train: 65 [ 450/781 ( 58%)]  Loss:  4.586129 (4.2018)  Time: 1.119s,  114.34/s  (0.902s,  141.83/s)  LR: 3.059e-04  Data: 0.007 (0.007)
2024-04-07 10:37:04,370 - train - INFO - Train: 65 [ 500/781 ( 64%)]  Loss:  3.752654 (4.1989)  Time: 0.813s,  157.47/s  (0.904s,  141.61/s)  LR: 3.059e-04  Data: 0.004 (0.007)
2024-04-07 10:37:49,908 - train - INFO - Train: 65 [ 550/781 ( 71%)]  Loss:  4.855946 (4.2008)  Time: 1.090s,  117.46/s  (0.904s,  141.52/s)  LR: 3.059e-04  Data: 0.010 (0.007)
2024-04-07 10:38:35,866 - train - INFO - Train: 65 [ 600/781 ( 77%)]  Loss:  3.823667 (4.1947)  Time: 1.080s,  118.54/s  (0.906s,  141.33/s)  LR: 3.059e-04  Data: 0.007 (0.007)
2024-04-07 10:39:20,593 - train - INFO - Train: 65 [ 650/781 ( 83%)]  Loss:  4.047196 (4.1966)  Time: 0.816s,  156.94/s  (0.905s,  141.46/s)  LR: 3.059e-04  Data: 0.005 (0.007)
2024-04-07 10:40:05,225 - train - INFO - Train: 65 [ 700/781 ( 90%)]  Loss:  3.879701 (4.1939)  Time: 0.822s,  155.77/s  (0.904s,  141.60/s)  LR: 3.059e-04  Data: 0.006 (0.007)
2024-04-07 10:40:51,141 - train - INFO - Train: 65 [ 750/781 ( 96%)]  Loss:  3.827632 (4.1955)  Time: 0.809s,  158.13/s  (0.905s,  141.45/s)  LR: 3.059e-04  Data: 0.004 (0.007)
2024-04-07 10:41:18,270 - train - INFO - Train: 65 [ 780/781 (100%)]  Loss:  4.366345 (4.1983)  Time: 0.791s,  161.85/s  (0.905s,  141.45/s)  LR: 3.059e-04  Data: 0.000 (0.007)
2024-04-07 10:41:18,271 - train - INFO - True
2024-04-07 10:41:18,272 - train - INFO - alphas:tensor([0.0250, 0.0232, 0.0775, 0.3608, 0.5135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,282 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,282 - train - INFO - True
2024-04-07 10:41:18,282 - train - INFO - alphas:tensor([0.1236, 0.0261, 0.0501, 0.1602, 0.6401], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,292 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,292 - train - INFO - True
2024-04-07 10:41:18,292 - train - INFO - alphas:tensor([0.5358, 0.0959, 0.0721, 0.1266, 0.1696], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,310 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,310 - train - INFO - True
2024-04-07 10:41:18,311 - train - INFO - alphas:tensor([0.4372, 0.0316, 0.0518, 0.1486, 0.3308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,331 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,331 - train - INFO - True
2024-04-07 10:41:18,332 - train - INFO - alphas:tensor([0.2862, 0.0206, 0.0640, 0.1676, 0.4615], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,342 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,343 - train - INFO - True
2024-04-07 10:41:18,343 - train - INFO - alphas:tensor([0.3885, 0.0184, 0.0437, 0.1293, 0.4200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,353 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,353 - train - INFO - True
2024-04-07 10:41:18,354 - train - INFO - alphas:tensor([0.5223, 0.0457, 0.0353, 0.1277, 0.2691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,372 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,372 - train - INFO - True
2024-04-07 10:41:18,373 - train - INFO - alphas:tensor([0.3871, 0.0236, 0.0205, 0.1277, 0.4410], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,382 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,382 - train - INFO - True
2024-04-07 10:41:18,383 - train - INFO - alphas:tensor([0.3485, 0.0176, 0.0470, 0.1406, 0.4462], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,392 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,392 - train - INFO - True
2024-04-07 10:41:18,392 - train - INFO - alphas:tensor([0.4495, 0.0158, 0.0414, 0.1075, 0.3857], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,410 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,410 - train - INFO - True
2024-04-07 10:41:18,411 - train - INFO - alphas:tensor([0.4279, 0.0257, 0.0310, 0.1293, 0.3861], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,429 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,429 - train - INFO - True
2024-04-07 10:41:18,430 - train - INFO - alphas:tensor([0.3247, 0.0120, 0.0182, 0.1364, 0.5086], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,440 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,441 - train - INFO - True
2024-04-07 10:41:18,441 - train - INFO - alphas:tensor([0.3572, 0.0126, 0.0378, 0.1334, 0.4590], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,452 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,452 - train - INFO - True
2024-04-07 10:41:18,452 - train - INFO - alphas:tensor([0.4466, 0.0084, 0.0298, 0.0910, 0.4241], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,472 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,472 - train - INFO - True
2024-04-07 10:41:18,473 - train - INFO - alphas:tensor([0.3404, 0.0282, 0.0245, 0.1343, 0.4726], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,482 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,482 - train - INFO - True
2024-04-07 10:41:18,483 - train - INFO - alphas:tensor([0.2423, 0.0083, 0.0098, 0.1336, 0.6060], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,492 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,492 - train - INFO - True
2024-04-07 10:41:18,493 - train - INFO - alphas:tensor([0.3430, 0.0125, 0.0300, 0.1260, 0.4885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,502 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,502 - train - INFO - True
2024-04-07 10:41:18,503 - train - INFO - alphas:tensor([0.4399, 0.0072, 0.0258, 0.0870, 0.4401], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,512 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,512 - train - INFO - True
2024-04-07 10:41:18,512 - train - INFO - alphas:tensor([0.3509, 0.0131, 0.0169, 0.1267, 0.4924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,521 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,522 - train - INFO - True
2024-04-07 10:41:18,522 - train - INFO - alphas:tensor([0.2453, 0.0062, 0.0076, 0.1167, 0.6242], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,531 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,531 - train - INFO - True
2024-04-07 10:41:18,532 - train - INFO - alphas:tensor([0.2914, 0.0081, 0.0279, 0.1282, 0.5444], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,542 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,542 - train - INFO - True
2024-04-07 10:41:18,543 - train - INFO - alphas:tensor([0.4154, 0.0059, 0.0234, 0.0784, 0.4768], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,554 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,554 - train - INFO - True
2024-04-07 10:41:18,555 - train - INFO - alphas:tensor([0.3853, 0.0171, 0.0154, 0.1065, 0.4757], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,565 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,565 - train - INFO - True
2024-04-07 10:41:18,566 - train - INFO - alphas:tensor([0.2745, 0.0048, 0.0054, 0.0928, 0.6225], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,576 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,576 - train - INFO - True
2024-04-07 10:41:18,577 - train - INFO - alphas:tensor([0.2828, 0.0066, 0.0243, 0.1180, 0.5683], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,586 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,586 - train - INFO - True
2024-04-07 10:41:18,587 - train - INFO - alphas:tensor([0.4021, 0.0057, 0.0217, 0.0682, 0.5022], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,597 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,597 - train - INFO - True
2024-04-07 10:41:18,597 - train - INFO - alphas:tensor([0.4235, 0.0081, 0.0129, 0.0969, 0.4585], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,607 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,607 - train - INFO - True
2024-04-07 10:41:18,607 - train - INFO - alphas:tensor([0.3037, 0.0049, 0.0048, 0.0818, 0.6048], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,616 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,616 - train - INFO - True
2024-04-07 10:41:18,617 - train - INFO - alphas:tensor([0.2564, 0.0053, 0.0231, 0.1207, 0.5945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,626 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,626 - train - INFO - True
2024-04-07 10:41:18,627 - train - INFO - alphas:tensor([0.3688, 0.0037, 0.0181, 0.0751, 0.5343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,636 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,636 - train - INFO - True
2024-04-07 10:41:18,636 - train - INFO - alphas:tensor([0.4597, 0.0077, 0.0114, 0.0850, 0.4362], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,657 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,657 - train - INFO - True
2024-04-07 10:41:18,658 - train - INFO - alphas:tensor([0.3512, 0.0035, 0.0062, 0.0886, 0.5506], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,668 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,668 - train - INFO - True
2024-04-07 10:41:18,669 - train - INFO - alphas:tensor([0.2368, 0.0047, 0.0201, 0.1097, 0.6288], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,681 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,681 - train - INFO - True
2024-04-07 10:41:18,682 - train - INFO - alphas:tensor([0.3336, 0.0025, 0.0139, 0.0616, 0.5885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,692 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,692 - train - INFO - True
2024-04-07 10:41:18,692 - train - INFO - alphas:tensor([0.4485, 0.0102, 0.0120, 0.0936, 0.4357], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,711 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,711 - train - INFO - True
2024-04-07 10:41:18,711 - train - INFO - alphas:tensor([0.3654, 0.0034, 0.0076, 0.0935, 0.5301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,721 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,721 - train - INFO - True
2024-04-07 10:41:18,721 - train - INFO - alphas:tensor([0.6579, 0.0395, 0.1052, 0.1975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:41:18,739 - train - INFO - tau:0.5309055429551132
2024-04-07 10:41:18,739 - train - INFO - avg block size:12.35135135135135
2024-04-07 10:41:18,739 - train - INFO - current latency ratio:tensor(0.2821)
2024-04-07 10:41:18,986 - train - INFO - Test: [   0/78]  Time: 0.243 (0.243)  Loss:  0.9409 (0.9409)  Acc@1: 79.6875 (79.6875)  Acc@5: 93.7500 (93.7500)
2024-04-07 10:41:23,555 - train - INFO - Test: [  50/78]  Time: 0.086 (0.094)  Loss:  1.9375 (1.6999)  Acc@1: 56.2500 (60.1869)  Acc@5: 77.3438 (83.1801)
2024-04-07 10:41:25,957 - train - INFO - Test: [  78/78]  Time: 0.057 (0.091)  Loss:  1.8027 (1.7253)  Acc@1: 56.2500 (59.7400)  Acc@5: 93.7500 (82.7300)
2024-04-07 10:41:27,216 - train - INFO - Train: 66 [   0/781 (  0%)]  Loss:  3.734250 (3.7342)  Time: 1.192s,  107.40/s  (1.192s,  107.40/s)  LR: 3.009e-04  Data: 0.189 (0.189)
2024-04-07 10:42:12,999 - train - INFO - Train: 66 [  50/781 (  6%)]  Loss:  4.265006 (4.1520)  Time: 1.115s,  114.82/s  (0.921s,  138.97/s)  LR: 3.009e-04  Data: 0.009 (0.010)
2024-04-07 10:42:57,560 - train - INFO - Train: 66 [ 100/781 ( 13%)]  Loss:  3.808476 (4.1468)  Time: 0.829s,  154.36/s  (0.906s,  141.24/s)  LR: 3.009e-04  Data: 0.006 (0.009)
2024-04-07 10:43:42,695 - train - INFO - Train: 66 [ 150/781 ( 19%)]  Loss:  4.472451 (4.1775)  Time: 1.063s,  120.39/s  (0.905s,  141.43/s)  LR: 3.009e-04  Data: 0.008 (0.008)
2024-04-07 10:44:28,830 - train - INFO - Train: 66 [ 200/781 ( 26%)]  Loss:  4.467024 (4.1712)  Time: 0.808s,  158.47/s  (0.909s,  140.75/s)  LR: 3.009e-04  Data: 0.004 (0.008)
2024-04-07 10:45:13,167 - train - INFO - Train: 66 [ 250/781 ( 32%)]  Loss:  4.006669 (4.1939)  Time: 1.014s,  126.18/s  (0.905s,  141.45/s)  LR: 3.009e-04  Data: 0.013 (0.008)
2024-04-07 10:45:59,538 - train - INFO - Train: 66 [ 300/781 ( 38%)]  Loss:  4.655261 (4.2019)  Time: 0.854s,  149.82/s  (0.909s,  140.87/s)  LR: 3.009e-04  Data: 0.007 (0.008)
2024-04-07 10:46:45,462 - train - INFO - Train: 66 [ 350/781 ( 45%)]  Loss:  3.649518 (4.1983)  Time: 0.977s,  130.97/s  (0.910s,  140.65/s)  LR: 3.009e-04  Data: 0.005 (0.007)
2024-04-07 10:47:31,963 - train - INFO - Train: 66 [ 400/781 ( 51%)]  Loss:  4.511564 (4.2127)  Time: 0.866s,  147.80/s  (0.913s,  140.27/s)  LR: 3.009e-04  Data: 0.008 (0.007)
2024-04-07 10:48:18,199 - train - INFO - Train: 66 [ 450/781 ( 58%)]  Loss:  4.420967 (4.2174)  Time: 0.853s,  150.10/s  (0.914s,  140.06/s)  LR: 3.009e-04  Data: 0.009 (0.007)
2024-04-07 10:49:04,903 - train - INFO - Train: 66 [ 500/781 ( 64%)]  Loss:  3.582672 (4.2259)  Time: 0.872s,  146.77/s  (0.916s,  139.75/s)  LR: 3.009e-04  Data: 0.008 (0.007)
2024-04-07 10:49:51,211 - train - INFO - Train: 66 [ 550/781 ( 71%)]  Loss:  3.655391 (4.2222)  Time: 0.830s,  154.19/s  (0.917s,  139.61/s)  LR: 3.009e-04  Data: 0.005 (0.007)
2024-04-07 10:50:38,862 - train - INFO - Train: 66 [ 600/781 ( 77%)]  Loss:  3.971128 (4.2182)  Time: 0.843s,  151.82/s  (0.920s,  139.16/s)  LR: 3.009e-04  Data: 0.007 (0.007)
2024-04-07 10:51:23,671 - train - INFO - Train: 66 [ 650/781 ( 83%)]  Loss:  4.435244 (4.2282)  Time: 0.860s,  148.81/s  (0.918s,  139.43/s)  LR: 3.009e-04  Data: 0.009 (0.007)
2024-04-07 10:52:09,948 - train - INFO - Train: 66 [ 700/781 ( 90%)]  Loss:  4.759586 (4.2258)  Time: 0.946s,  135.28/s  (0.919s,  139.35/s)  LR: 3.009e-04  Data: 0.007 (0.007)
2024-04-07 10:52:55,922 - train - INFO - Train: 66 [ 750/781 ( 96%)]  Loss:  4.561208 (4.2253)  Time: 0.858s,  149.13/s  (0.919s,  139.34/s)  LR: 3.009e-04  Data: 0.004 (0.007)
2024-04-07 10:53:23,803 - train - INFO - Train: 66 [ 780/781 (100%)]  Loss:  4.440109 (4.2272)  Time: 0.865s,  147.99/s  (0.919s,  139.28/s)  LR: 3.009e-04  Data: 0.000 (0.007)
2024-04-07 10:53:23,804 - train - INFO - True
2024-04-07 10:53:23,806 - train - INFO - alphas:tensor([0.0221, 0.0209, 0.0730, 0.3600, 0.5240], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:23,822 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:23,822 - train - INFO - True
2024-04-07 10:53:23,824 - train - INFO - alphas:tensor([0.1197, 0.0250, 0.0485, 0.1589, 0.6480], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:23,839 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:23,839 - train - INFO - True
2024-04-07 10:53:23,840 - train - INFO - alphas:tensor([0.5258, 0.0965, 0.0723, 0.1297, 0.1756], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:23,868 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:23,868 - train - INFO - True
2024-04-07 10:53:23,869 - train - INFO - alphas:tensor([0.4292, 0.0303, 0.0507, 0.1491, 0.3407], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:23,897 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:23,897 - train - INFO - True
2024-04-07 10:53:23,898 - train - INFO - alphas:tensor([0.2801, 0.0198, 0.0625, 0.1668, 0.4707], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:23,913 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:23,913 - train - INFO - True
2024-04-07 10:53:23,914 - train - INFO - alphas:tensor([0.3813, 0.0171, 0.0422, 0.1282, 0.4311], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:23,928 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:23,928 - train - INFO - True
2024-04-07 10:53:23,933 - train - INFO - alphas:tensor([0.5155, 0.0444, 0.0344, 0.1288, 0.2769], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:23,969 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:23,969 - train - INFO - True
2024-04-07 10:53:23,973 - train - INFO - alphas:tensor([0.3825, 0.0227, 0.0192, 0.1263, 0.4493], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:23,992 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:23,992 - train - INFO - True
2024-04-07 10:53:23,993 - train - INFO - alphas:tensor([0.3421, 0.0170, 0.0458, 0.1397, 0.4554], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,010 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,010 - train - INFO - True
2024-04-07 10:53:24,011 - train - INFO - alphas:tensor([0.4422, 0.0148, 0.0403, 0.1064, 0.3963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,040 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,040 - train - INFO - True
2024-04-07 10:53:24,041 - train - INFO - alphas:tensor([0.4176, 0.0248, 0.0298, 0.1301, 0.3977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,069 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,069 - train - INFO - True
2024-04-07 10:53:24,070 - train - INFO - alphas:tensor([0.3190, 0.0114, 0.0172, 0.1363, 0.5161], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,087 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,087 - train - INFO - True
2024-04-07 10:53:24,088 - train - INFO - alphas:tensor([0.3512, 0.0118, 0.0362, 0.1320, 0.4687], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,102 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,102 - train - INFO - True
2024-04-07 10:53:24,103 - train - INFO - alphas:tensor([0.4429, 0.0078, 0.0286, 0.0890, 0.4317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,131 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,131 - train - INFO - True
2024-04-07 10:53:24,132 - train - INFO - alphas:tensor([0.3309, 0.0270, 0.0235, 0.1345, 0.4840], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,147 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,147 - train - INFO - True
2024-04-07 10:53:24,148 - train - INFO - alphas:tensor([0.2350, 0.0078, 0.0090, 0.1341, 0.6141], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,162 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,162 - train - INFO - True
2024-04-07 10:53:24,163 - train - INFO - alphas:tensor([0.3360, 0.0119, 0.0286, 0.1247, 0.4989], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,177 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,177 - train - INFO - True
2024-04-07 10:53:24,178 - train - INFO - alphas:tensor([0.4311, 0.0066, 0.0249, 0.0858, 0.4516], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,193 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,193 - train - INFO - True
2024-04-07 10:53:24,194 - train - INFO - alphas:tensor([0.3407, 0.0122, 0.0157, 0.1269, 0.5045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,208 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,208 - train - INFO - True
2024-04-07 10:53:24,209 - train - INFO - alphas:tensor([0.2376, 0.0058, 0.0070, 0.1165, 0.6331], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,223 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,223 - train - INFO - True
2024-04-07 10:53:24,224 - train - INFO - alphas:tensor([0.2855, 0.0075, 0.0266, 0.1261, 0.5543], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,238 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,239 - train - INFO - True
2024-04-07 10:53:24,239 - train - INFO - alphas:tensor([0.4073, 0.0054, 0.0219, 0.0763, 0.4891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,256 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,256 - train - INFO - True
2024-04-07 10:53:24,257 - train - INFO - alphas:tensor([0.3777, 0.0161, 0.0144, 0.1054, 0.4864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,271 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,272 - train - INFO - True
2024-04-07 10:53:24,273 - train - INFO - alphas:tensor([0.2684, 0.0044, 0.0049, 0.0919, 0.6305], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,287 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,287 - train - INFO - True
2024-04-07 10:53:24,288 - train - INFO - alphas:tensor([0.2757, 0.0062, 0.0229, 0.1160, 0.5792], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,302 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,302 - train - INFO - True
2024-04-07 10:53:24,303 - train - INFO - alphas:tensor([0.3940, 0.0052, 0.0205, 0.0657, 0.5146], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,317 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,318 - train - INFO - True
2024-04-07 10:53:24,319 - train - INFO - alphas:tensor([0.4135, 0.0073, 0.0120, 0.0966, 0.4705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,333 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,333 - train - INFO - True
2024-04-07 10:53:24,334 - train - INFO - alphas:tensor([0.2957, 0.0045, 0.0043, 0.0813, 0.6142], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,348 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,348 - train - INFO - True
2024-04-07 10:53:24,349 - train - INFO - alphas:tensor([0.2520, 0.0050, 0.0216, 0.1177, 0.6037], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,363 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,364 - train - INFO - True
2024-04-07 10:53:24,365 - train - INFO - alphas:tensor([0.3646, 0.0033, 0.0169, 0.0721, 0.5430], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,379 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,379 - train - INFO - True
2024-04-07 10:53:24,380 - train - INFO - alphas:tensor([0.4506, 0.0071, 0.0107, 0.0837, 0.4478], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,408 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,408 - train - INFO - True
2024-04-07 10:53:24,409 - train - INFO - alphas:tensor([0.3410, 0.0032, 0.0056, 0.0873, 0.5629], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,425 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,425 - train - INFO - True
2024-04-07 10:53:24,426 - train - INFO - alphas:tensor([0.2321, 0.0044, 0.0190, 0.1066, 0.6379], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,441 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,441 - train - INFO - True
2024-04-07 10:53:24,442 - train - INFO - alphas:tensor([0.3284, 0.0022, 0.0128, 0.0589, 0.5977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,456 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,456 - train - INFO - True
2024-04-07 10:53:24,457 - train - INFO - alphas:tensor([0.4446, 0.0095, 0.0111, 0.0914, 0.4434], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,485 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,485 - train - INFO - True
2024-04-07 10:53:24,486 - train - INFO - alphas:tensor([0.3606, 0.0031, 0.0068, 0.0911, 0.5384], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,500 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,501 - train - INFO - True
2024-04-07 10:53:24,501 - train - INFO - alphas:tensor([0.6542, 0.0388, 0.1057, 0.2014], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 10:53:24,530 - train - INFO - tau:0.525596487525562
2024-04-07 10:53:24,530 - train - INFO - avg block size:12.35135135135135
2024-04-07 10:53:24,530 - train - INFO - current latency ratio:tensor(0.2821)
2024-04-07 10:53:24,530 - train - INFO - lasso_alpha:0.000191943424957751
2024-04-07 10:53:24,777 - train - INFO - Test: [   0/78]  Time: 0.243 (0.243)  Loss:  0.9570 (0.9570)  Acc@1: 81.2500 (81.2500)  Acc@5: 96.0938 (96.0938)
2024-04-07 10:53:29,463 - train - INFO - Test: [  50/78]  Time: 0.086 (0.097)  Loss:  1.8633 (1.7139)  Acc@1: 55.4688 (59.8039)  Acc@5: 83.5938 (82.8431)
2024-04-07 10:53:31,898 - train - INFO - Test: [  78/78]  Time: 0.058 (0.093)  Loss:  1.7822 (1.7379)  Acc@1: 50.0000 (59.4900)  Acc@5: 93.7500 (82.3400)
2024-04-07 10:53:33,166 - train - INFO - Train: 67 [   0/781 (  0%)]  Loss:  4.606237 (4.6062)  Time: 1.197s,  106.91/s  (1.197s,  106.91/s)  LR: 2.959e-04  Data: 0.185 (0.185)
2024-04-07 10:54:19,281 - train - INFO - Train: 67 [  50/781 (  6%)]  Loss:  4.739867 (4.2413)  Time: 0.911s,  140.54/s  (0.928s,  137.98/s)  LR: 2.959e-04  Data: 0.007 (0.010)
2024-04-07 10:55:04,592 - train - INFO - Train: 67 [ 100/781 ( 13%)]  Loss:  4.070988 (4.2203)  Time: 0.862s,  148.52/s  (0.917s,  139.58/s)  LR: 2.959e-04  Data: 0.009 (0.009)
2024-04-07 10:55:51,173 - train - INFO - Train: 67 [ 150/781 ( 19%)]  Loss:  4.645043 (4.2183)  Time: 1.042s,  122.82/s  (0.922s,  138.85/s)  LR: 2.959e-04  Data: 0.016 (0.008)
2024-04-07 10:56:37,188 - train - INFO - Train: 67 [ 200/781 ( 26%)]  Loss:  4.074490 (4.2289)  Time: 1.050s,  121.92/s  (0.921s,  138.91/s)  LR: 2.959e-04  Data: 0.008 (0.008)
2024-04-07 10:57:21,652 - train - INFO - Train: 67 [ 250/781 ( 32%)]  Loss:  4.187325 (4.2211)  Time: 0.839s,  152.50/s  (0.915s,  139.88/s)  LR: 2.959e-04  Data: 0.008 (0.008)
2024-04-07 10:58:07,143 - train - INFO - Train: 67 [ 300/781 ( 38%)]  Loss:  3.853992 (4.2173)  Time: 1.034s,  123.82/s  (0.914s,  140.02/s)  LR: 2.959e-04  Data: 0.006 (0.008)
2024-04-07 10:58:53,822 - train - INFO - Train: 67 [ 350/781 ( 45%)]  Loss:  4.323948 (4.2261)  Time: 0.810s,  158.09/s  (0.917s,  139.60/s)  LR: 2.959e-04  Data: 0.004 (0.007)
2024-04-07 10:59:40,329 - train - INFO - Train: 67 [ 400/781 ( 51%)]  Loss:  4.322494 (4.2178)  Time: 1.136s,  112.70/s  (0.919s,  139.35/s)  LR: 2.959e-04  Data: 0.006 (0.007)
2024-04-07 11:00:26,001 - train - INFO - Train: 67 [ 450/781 ( 58%)]  Loss:  3.728311 (4.2185)  Time: 0.996s,  128.53/s  (0.918s,  139.43/s)  LR: 2.959e-04  Data: 0.008 (0.007)
2024-04-07 11:01:11,367 - train - INFO - Train: 67 [ 500/781 ( 64%)]  Loss:  4.245029 (4.2252)  Time: 0.765s,  167.37/s  (0.917s,  139.60/s)  LR: 2.959e-04  Data: 0.004 (0.007)
2024-04-07 11:01:57,036 - train - INFO - Train: 67 [ 550/781 ( 71%)]  Loss:  3.781285 (4.2190)  Time: 1.092s,  117.26/s  (0.917s,  139.65/s)  LR: 2.959e-04  Data: 0.010 (0.007)
2024-04-07 11:02:43,247 - train - INFO - Train: 67 [ 600/781 ( 77%)]  Loss:  3.846940 (4.2195)  Time: 1.116s,  114.72/s  (0.917s,  139.55/s)  LR: 2.959e-04  Data: 0.009 (0.007)
2024-04-07 11:03:30,708 - train - INFO - Train: 67 [ 650/781 ( 83%)]  Loss:  4.674867 (4.2173)  Time: 0.877s,  145.91/s  (0.920s,  139.18/s)  LR: 2.959e-04  Data: 0.009 (0.007)
2024-04-07 11:04:17,026 - train - INFO - Train: 67 [ 700/781 ( 90%)]  Loss:  4.063558 (4.2188)  Time: 0.805s,  158.96/s  (0.920s,  139.11/s)  LR: 2.959e-04  Data: 0.004 (0.007)
2024-04-07 11:05:03,841 - train - INFO - Train: 67 [ 750/781 ( 96%)]  Loss:  4.733023 (4.2217)  Time: 0.927s,  138.10/s  (0.921s,  138.94/s)  LR: 2.959e-04  Data: 0.006 (0.007)
2024-04-07 11:05:32,215 - train - INFO - Train: 67 [ 780/781 (100%)]  Loss:  3.793142 (4.2151)  Time: 1.062s,  120.53/s  (0.922s,  138.80/s)  LR: 2.959e-04  Data: 0.000 (0.007)
2024-04-07 11:05:32,229 - train - INFO - True
2024-04-07 11:05:32,231 - train - INFO - alphas:tensor([0.0191, 0.0186, 0.0679, 0.3561, 0.5383], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,253 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,253 - train - INFO - True
2024-04-07 11:05:32,255 - train - INFO - alphas:tensor([0.1141, 0.0238, 0.0465, 0.1568, 0.6587], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,274 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,274 - train - INFO - True
2024-04-07 11:05:32,275 - train - INFO - alphas:tensor([0.5156, 0.0961, 0.0729, 0.1333, 0.1820], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,308 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,308 - train - INFO - True
2024-04-07 11:05:32,309 - train - INFO - alphas:tensor([0.4237, 0.0291, 0.0494, 0.1490, 0.3487], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,338 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,338 - train - INFO - True
2024-04-07 11:05:32,339 - train - INFO - alphas:tensor([0.2740, 0.0189, 0.0609, 0.1662, 0.4800], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,352 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,352 - train - INFO - True
2024-04-07 11:05:32,353 - train - INFO - alphas:tensor([0.3743, 0.0160, 0.0409, 0.1270, 0.4418], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,365 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,365 - train - INFO - True
2024-04-07 11:05:32,366 - train - INFO - alphas:tensor([0.5045, 0.0433, 0.0336, 0.1309, 0.2877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,389 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,389 - train - INFO - True
2024-04-07 11:05:32,390 - train - INFO - alphas:tensor([0.3738, 0.0216, 0.0180, 0.1254, 0.4612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,401 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,401 - train - INFO - True
2024-04-07 11:05:32,402 - train - INFO - alphas:tensor([0.3333, 0.0160, 0.0445, 0.1390, 0.4672], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,412 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,412 - train - INFO - True
2024-04-07 11:05:32,413 - train - INFO - alphas:tensor([0.4360, 0.0138, 0.0387, 0.1048, 0.4067], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,433 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,433 - train - INFO - True
2024-04-07 11:05:32,434 - train - INFO - alphas:tensor([0.4060, 0.0241, 0.0285, 0.1304, 0.4109], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,443 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,443 - train - INFO - True
2024-04-07 11:05:32,444 - train - INFO - alphas:tensor([0.3074, 0.0109, 0.0160, 0.1362, 0.5295], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,453 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,453 - train - INFO - True
2024-04-07 11:05:32,454 - train - INFO - alphas:tensor([0.3433, 0.0111, 0.0349, 0.1308, 0.4799], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,463 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,464 - train - INFO - True
2024-04-07 11:05:32,464 - train - INFO - alphas:tensor([0.4322, 0.0071, 0.0273, 0.0875, 0.4459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,473 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,474 - train - INFO - True
2024-04-07 11:05:32,474 - train - INFO - alphas:tensor([0.3199, 0.0259, 0.0221, 0.1352, 0.4968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,484 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,484 - train - INFO - True
2024-04-07 11:05:32,485 - train - INFO - alphas:tensor([0.2246, 0.0072, 0.0083, 0.1356, 0.6243], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,496 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,496 - train - INFO - True
2024-04-07 11:05:32,497 - train - INFO - alphas:tensor([0.3297, 0.0112, 0.0272, 0.1227, 0.5091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,507 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,507 - train - INFO - True
2024-04-07 11:05:32,508 - train - INFO - alphas:tensor([0.4253, 0.0061, 0.0238, 0.0830, 0.4618], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,518 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,518 - train - INFO - True
2024-04-07 11:05:32,519 - train - INFO - alphas:tensor([0.3277, 0.0113, 0.0144, 0.1275, 0.5191], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,529 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,529 - train - INFO - True
2024-04-07 11:05:32,530 - train - INFO - alphas:tensor([0.2268, 0.0053, 0.0063, 0.1158, 0.6459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,539 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,539 - train - INFO - True
2024-04-07 11:05:32,540 - train - INFO - alphas:tensor([0.2788, 0.0070, 0.0250, 0.1235, 0.5658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,549 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,549 - train - INFO - True
2024-04-07 11:05:32,550 - train - INFO - alphas:tensor([0.4000, 0.0049, 0.0208, 0.0734, 0.5009], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,559 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,559 - train - INFO - True
2024-04-07 11:05:32,560 - train - INFO - alphas:tensor([0.3678, 0.0150, 0.0133, 0.1049, 0.4990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,569 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,569 - train - INFO - True
2024-04-07 11:05:32,570 - train - INFO - alphas:tensor([0.2579, 0.0041, 0.0044, 0.0917, 0.6419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,578 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,578 - train - INFO - True
2024-04-07 11:05:32,579 - train - INFO - alphas:tensor([0.2697, 0.0058, 0.0219, 0.1129, 0.5897], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,588 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,588 - train - INFO - True
2024-04-07 11:05:32,589 - train - INFO - alphas:tensor([0.3874, 0.0047, 0.0193, 0.0628, 0.5258], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,597 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,597 - train - INFO - True
2024-04-07 11:05:32,598 - train - INFO - alphas:tensor([0.4041, 0.0066, 0.0110, 0.0955, 0.4828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,606 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,607 - train - INFO - True
2024-04-07 11:05:32,607 - train - INFO - alphas:tensor([0.2916, 0.0042, 0.0038, 0.0791, 0.6214], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,616 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,616 - train - INFO - True
2024-04-07 11:05:32,616 - train - INFO - alphas:tensor([0.2452, 0.0046, 0.0201, 0.1154, 0.6147], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,628 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,628 - train - INFO - True
2024-04-07 11:05:32,629 - train - INFO - alphas:tensor([0.3546, 0.0030, 0.0156, 0.0699, 0.5569], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,640 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,640 - train - INFO - True
2024-04-07 11:05:32,640 - train - INFO - alphas:tensor([0.4409, 0.0066, 0.0098, 0.0829, 0.4598], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,651 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,651 - train - INFO - True
2024-04-07 11:05:32,652 - train - INFO - alphas:tensor([0.3346, 0.0029, 0.0050, 0.0864, 0.5711], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,661 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,661 - train - INFO - True
2024-04-07 11:05:32,662 - train - INFO - alphas:tensor([0.2279, 0.0041, 0.0179, 0.1031, 0.6471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,672 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,672 - train - INFO - True
2024-04-07 11:05:32,672 - train - INFO - alphas:tensor([0.3171, 0.0020, 0.0120, 0.0571, 0.6118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,682 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,682 - train - INFO - True
2024-04-07 11:05:32,682 - train - INFO - alphas:tensor([0.4350, 0.0088, 0.0102, 0.0903, 0.4555], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,692 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,692 - train - INFO - True
2024-04-07 11:05:32,692 - train - INFO - alphas:tensor([0.3526, 0.0028, 0.0061, 0.0890, 0.5495], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,701 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,702 - train - INFO - True
2024-04-07 11:05:32,702 - train - INFO - alphas:tensor([0.6508, 0.0381, 0.1060, 0.2051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:05:32,720 - train - INFO - tau:0.5203405226503064
2024-04-07 11:05:32,720 - train - INFO - avg block size:13.972972972972974
2024-04-07 11:05:32,720 - train - INFO - current latency ratio:tensor(0.1929)
2024-04-07 11:05:32,972 - train - INFO - Test: [   0/78]  Time: 0.248 (0.248)  Loss:  0.8945 (0.8945)  Acc@1: 82.0312 (82.0312)  Acc@5: 95.3125 (95.3125)
2024-04-07 11:05:37,706 - train - INFO - Test: [  50/78]  Time: 0.088 (0.098)  Loss:  1.9316 (1.6976)  Acc@1: 56.2500 (60.1103)  Acc@5: 79.6875 (83.2261)
2024-04-07 11:05:40,124 - train - INFO - Test: [  78/78]  Time: 0.053 (0.094)  Loss:  1.6904 (1.7267)  Acc@1: 56.2500 (59.4800)  Acc@5: 93.7500 (82.6500)
2024-04-07 11:05:41,475 - train - INFO - Train: 68 [   0/781 (  0%)]  Loss:  4.105393 (4.1054)  Time: 1.286s,   99.51/s  (1.286s,   99.51/s)  LR: 2.908e-04  Data: 0.208 (0.208)
2024-04-07 11:06:26,544 - train - INFO - Train: 68 [  50/781 (  6%)]  Loss:  3.858749 (4.2668)  Time: 0.967s,  132.37/s  (0.909s,  140.83/s)  LR: 2.908e-04  Data: 0.006 (0.011)
2024-04-07 11:07:13,828 - train - INFO - Train: 68 [ 100/781 ( 13%)]  Loss:  3.570089 (4.1831)  Time: 0.856s,  149.45/s  (0.927s,  138.07/s)  LR: 2.908e-04  Data: 0.011 (0.009)
2024-04-07 11:07:59,829 - train - INFO - Train: 68 [ 150/781 ( 19%)]  Loss:  4.024478 (4.1921)  Time: 1.030s,  124.29/s  (0.925s,  138.42/s)  LR: 2.908e-04  Data: 0.006 (0.008)
2024-04-07 11:08:46,012 - train - INFO - Train: 68 [ 200/781 ( 26%)]  Loss:  4.317039 (4.2138)  Time: 1.104s,  115.98/s  (0.924s,  138.46/s)  LR: 2.908e-04  Data: 0.010 (0.008)
2024-04-07 11:09:32,395 - train - INFO - Train: 68 [ 250/781 ( 32%)]  Loss:  3.543189 (4.2265)  Time: 1.004s,  127.43/s  (0.925s,  138.36/s)  LR: 2.908e-04  Data: 0.006 (0.008)
2024-04-07 11:10:17,354 - train - INFO - Train: 68 [ 300/781 ( 38%)]  Loss:  4.080808 (4.2215)  Time: 0.858s,  149.20/s  (0.921s,  139.01/s)  LR: 2.908e-04  Data: 0.009 (0.008)
2024-04-07 11:11:03,573 - train - INFO - Train: 68 [ 350/781 ( 45%)]  Loss:  4.213744 (4.2293)  Time: 0.829s,  154.49/s  (0.921s,  138.94/s)  LR: 2.908e-04  Data: 0.006 (0.008)
2024-04-07 11:11:49,639 - train - INFO - Train: 68 [ 400/781 ( 51%)]  Loss:  4.341199 (4.2205)  Time: 0.851s,  150.37/s  (0.921s,  138.94/s)  LR: 2.908e-04  Data: 0.008 (0.007)
2024-04-07 11:12:35,477 - train - INFO - Train: 68 [ 450/781 ( 58%)]  Loss:  4.510476 (4.2187)  Time: 0.836s,  153.12/s  (0.921s,  139.01/s)  LR: 2.908e-04  Data: 0.005 (0.007)
2024-04-07 11:13:21,541 - train - INFO - Train: 68 [ 500/781 ( 64%)]  Loss:  4.718229 (4.2185)  Time: 1.087s,  117.74/s  (0.921s,  139.01/s)  LR: 2.908e-04  Data: 0.014 (0.007)
2024-04-07 11:14:07,269 - train - INFO - Train: 68 [ 550/781 ( 71%)]  Loss:  3.834846 (4.2213)  Time: 1.007s,  127.17/s  (0.920s,  139.09/s)  LR: 2.908e-04  Data: 0.006 (0.007)
2024-04-07 11:14:53,652 - train - INFO - Train: 68 [ 600/781 ( 77%)]  Loss:  4.735400 (4.2377)  Time: 0.814s,  157.29/s  (0.921s,  139.00/s)  LR: 2.908e-04  Data: 0.004 (0.007)
2024-04-07 11:15:40,123 - train - INFO - Train: 68 [ 650/781 ( 83%)]  Loss:  3.768966 (4.2371)  Time: 0.858s,  149.26/s  (0.922s,  138.90/s)  LR: 2.908e-04  Data: 0.008 (0.007)
2024-04-07 11:16:26,986 - train - INFO - Train: 68 [ 700/781 ( 90%)]  Loss:  4.656967 (4.2429)  Time: 0.807s,  158.61/s  (0.923s,  138.73/s)  LR: 2.908e-04  Data: 0.004 (0.007)
2024-04-07 11:17:14,919 - train - INFO - Train: 68 [ 750/781 ( 96%)]  Loss:  3.554696 (4.2437)  Time: 0.858s,  149.25/s  (0.925s,  138.37/s)  LR: 2.908e-04  Data: 0.008 (0.007)
2024-04-07 11:17:41,666 - train - INFO - Train: 68 [ 780/781 (100%)]  Loss:  4.558070 (4.2474)  Time: 0.827s,  154.73/s  (0.924s,  138.57/s)  LR: 2.908e-04  Data: 0.000 (0.007)
2024-04-07 11:17:41,666 - train - INFO - True
2024-04-07 11:17:41,668 - train - INFO - alphas:tensor([0.0166, 0.0166, 0.0636, 0.3513, 0.5519], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,682 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,682 - train - INFO - True
2024-04-07 11:17:41,683 - train - INFO - alphas:tensor([0.1101, 0.0227, 0.0453, 0.1538, 0.6681], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,697 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,698 - train - INFO - True
2024-04-07 11:17:41,698 - train - INFO - alphas:tensor([0.5068, 0.0965, 0.0731, 0.1358, 0.1877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,727 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,727 - train - INFO - True
2024-04-07 11:17:41,728 - train - INFO - alphas:tensor([0.4169, 0.0279, 0.0483, 0.1495, 0.3574], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,756 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,756 - train - INFO - True
2024-04-07 11:17:41,757 - train - INFO - alphas:tensor([0.2691, 0.0182, 0.0604, 0.1651, 0.4872], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,771 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,771 - train - INFO - True
2024-04-07 11:17:41,772 - train - INFO - alphas:tensor([0.3688, 0.0150, 0.0392, 0.1253, 0.4516], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,786 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,787 - train - INFO - True
2024-04-07 11:17:41,788 - train - INFO - alphas:tensor([0.4939, 0.0423, 0.0327, 0.1333, 0.2978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,816 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,816 - train - INFO - True
2024-04-07 11:17:41,817 - train - INFO - alphas:tensor([0.3680, 0.0209, 0.0168, 0.1243, 0.4701], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,831 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,831 - train - INFO - True
2024-04-07 11:17:41,832 - train - INFO - alphas:tensor([0.3292, 0.0153, 0.0430, 0.1380, 0.4745], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,846 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,846 - train - INFO - True
2024-04-07 11:17:41,847 - train - INFO - alphas:tensor([0.4281, 0.0129, 0.0375, 0.1039, 0.4177], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,877 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,877 - train - INFO - True
2024-04-07 11:17:41,878 - train - INFO - alphas:tensor([0.3990, 0.0235, 0.0271, 0.1303, 0.4201], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,893 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,893 - train - INFO - True
2024-04-07 11:17:41,894 - train - INFO - alphas:tensor([0.3031, 0.0104, 0.0152, 0.1364, 0.5349], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,908 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,908 - train - INFO - True
2024-04-07 11:17:41,909 - train - INFO - alphas:tensor([0.3380, 0.0105, 0.0335, 0.1288, 0.4891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,923 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,923 - train - INFO - True
2024-04-07 11:17:41,924 - train - INFO - alphas:tensor([0.4259, 0.0066, 0.0260, 0.0854, 0.4560], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,939 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,939 - train - INFO - True
2024-04-07 11:17:41,940 - train - INFO - alphas:tensor([0.3136, 0.0253, 0.0211, 0.1358, 0.5042], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,954 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,954 - train - INFO - True
2024-04-07 11:17:41,955 - train - INFO - alphas:tensor([0.2183, 0.0068, 0.0077, 0.1360, 0.6312], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,969 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,969 - train - INFO - True
2024-04-07 11:17:41,970 - train - INFO - alphas:tensor([0.3224, 0.0106, 0.0265, 0.1209, 0.5195], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:41,985 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:41,985 - train - INFO - True
2024-04-07 11:17:41,986 - train - INFO - alphas:tensor([0.4159, 0.0055, 0.0226, 0.0808, 0.4752], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,000 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,000 - train - INFO - True
2024-04-07 11:17:42,001 - train - INFO - alphas:tensor([0.3186, 0.0105, 0.0133, 0.1280, 0.5297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,015 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,015 - train - INFO - True
2024-04-07 11:17:42,016 - train - INFO - alphas:tensor([0.2187, 0.0049, 0.0058, 0.1166, 0.6541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,030 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,031 - train - INFO - True
2024-04-07 11:17:42,031 - train - INFO - alphas:tensor([0.2743, 0.0066, 0.0238, 0.1212, 0.5740], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,047 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,047 - train - INFO - True
2024-04-07 11:17:42,048 - train - INFO - alphas:tensor([0.3940, 0.0044, 0.0196, 0.0708, 0.5113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,062 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,062 - train - INFO - True
2024-04-07 11:17:42,063 - train - INFO - alphas:tensor([0.3594, 0.0142, 0.0122, 0.1036, 0.5106], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,078 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,078 - train - INFO - True
2024-04-07 11:17:42,079 - train - INFO - alphas:tensor([0.2530, 0.0038, 0.0040, 0.0907, 0.6485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,093 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,093 - train - INFO - True
2024-04-07 11:17:42,094 - train - INFO - alphas:tensor([0.2638, 0.0054, 0.0208, 0.1108, 0.5993], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,108 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,108 - train - INFO - True
2024-04-07 11:17:42,109 - train - INFO - alphas:tensor([0.3804, 0.0044, 0.0183, 0.0610, 0.5359], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,124 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,124 - train - INFO - True
2024-04-07 11:17:42,125 - train - INFO - alphas:tensor([0.3975, 0.0061, 0.0101, 0.0945, 0.4918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,139 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,139 - train - INFO - True
2024-04-07 11:17:42,140 - train - INFO - alphas:tensor([0.2847, 0.0039, 0.0034, 0.0776, 0.6304], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,154 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,154 - train - INFO - True
2024-04-07 11:17:42,155 - train - INFO - alphas:tensor([0.2395, 0.0044, 0.0194, 0.1124, 0.6243], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,169 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,170 - train - INFO - True
2024-04-07 11:17:42,170 - train - INFO - alphas:tensor([0.3478, 0.0027, 0.0145, 0.0671, 0.5679], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,185 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,185 - train - INFO - True
2024-04-07 11:17:42,186 - train - INFO - alphas:tensor([0.4326, 0.0060, 0.0090, 0.0820, 0.4705], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,200 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,200 - train - INFO - True
2024-04-07 11:17:42,201 - train - INFO - alphas:tensor([0.3276, 0.0026, 0.0045, 0.0850, 0.5803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,215 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,215 - train - INFO - True
2024-04-07 11:17:42,216 - train - INFO - alphas:tensor([0.2212, 0.0038, 0.0170, 0.1007, 0.6574], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,231 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,231 - train - INFO - True
2024-04-07 11:17:42,232 - train - INFO - alphas:tensor([0.3127, 0.0018, 0.0110, 0.0542, 0.6203], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,246 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,247 - train - INFO - True
2024-04-07 11:17:42,248 - train - INFO - alphas:tensor([0.4250, 0.0082, 0.0095, 0.0888, 0.4685], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,260 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,261 - train - INFO - True
2024-04-07 11:17:42,261 - train - INFO - alphas:tensor([0.3437, 0.0025, 0.0055, 0.0874, 0.5608], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,274 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,274 - train - INFO - True
2024-04-07 11:17:42,275 - train - INFO - alphas:tensor([0.6470, 0.0376, 0.1062, 0.2092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:17:42,297 - train - INFO - tau:0.5151371174238033
2024-04-07 11:17:42,297 - train - INFO - avg block size:13.972972972972974
2024-04-07 11:17:42,298 - train - INFO - current latency ratio:tensor(0.1929)
2024-04-07 11:17:42,298 - train - INFO - lasso_alpha:0.00017449402268886454
2024-04-07 11:17:42,554 - train - INFO - Test: [   0/78]  Time: 0.253 (0.253)  Loss:  0.9546 (0.9546)  Acc@1: 80.4688 (80.4688)  Acc@5: 93.7500 (93.7500)
2024-04-07 11:17:47,308 - train - INFO - Test: [  50/78]  Time: 0.086 (0.098)  Loss:  1.9297 (1.7159)  Acc@1: 57.8125 (59.9571)  Acc@5: 80.4688 (82.9504)
2024-04-07 11:17:49,747 - train - INFO - Test: [  78/78]  Time: 0.056 (0.094)  Loss:  1.6680 (1.7378)  Acc@1: 56.2500 (59.3900)  Acc@5: 93.7500 (82.5600)
2024-04-07 11:17:51,047 - train - INFO - Train: 69 [   0/781 (  0%)]  Loss:  3.912868 (3.9129)  Time: 1.229s,  104.17/s  (1.229s,  104.17/s)  LR: 2.857e-04  Data: 0.216 (0.216)
2024-04-07 11:18:34,917 - train - INFO - Train: 69 [  50/781 (  6%)]  Loss:  4.632287 (4.1926)  Time: 0.917s,  139.66/s  (0.884s,  144.76/s)  LR: 2.857e-04  Data: 0.004 (0.011)
2024-04-07 11:19:22,025 - train - INFO - Train: 69 [ 100/781 ( 13%)]  Loss:  4.205535 (4.1795)  Time: 0.850s,  150.55/s  (0.913s,  140.21/s)  LR: 2.857e-04  Data: 0.010 (0.009)
2024-04-07 11:20:08,939 - train - INFO - Train: 69 [ 150/781 ( 19%)]  Loss:  3.496842 (4.1960)  Time: 0.848s,  150.97/s  (0.921s,  138.93/s)  LR: 2.857e-04  Data: 0.007 (0.008)
2024-04-07 11:20:55,527 - train - INFO - Train: 69 [ 200/781 ( 26%)]  Loss:  4.006437 (4.1800)  Time: 0.812s,  157.58/s  (0.924s,  138.54/s)  LR: 2.857e-04  Data: 0.005 (0.008)
2024-04-07 11:21:42,391 - train - INFO - Train: 69 [ 250/781 ( 32%)]  Loss:  4.120414 (4.1720)  Time: 1.012s,  126.46/s  (0.927s,  138.15/s)  LR: 2.857e-04  Data: 0.006 (0.008)
2024-04-07 11:22:28,210 - train - INFO - Train: 69 [ 300/781 ( 38%)]  Loss:  4.417077 (4.1753)  Time: 1.106s,  115.70/s  (0.925s,  138.40/s)  LR: 2.857e-04  Data: 0.007 (0.008)
2024-04-07 11:23:14,645 - train - INFO - Train: 69 [ 350/781 ( 45%)]  Loss:  4.683951 (4.1712)  Time: 0.867s,  147.59/s  (0.925s,  138.32/s)  LR: 2.857e-04  Data: 0.008 (0.008)
2024-04-07 11:24:00,585 - train - INFO - Train: 69 [ 400/781 ( 51%)]  Loss:  3.775651 (4.1792)  Time: 0.851s,  150.38/s  (0.925s,  138.44/s)  LR: 2.857e-04  Data: 0.007 (0.008)
2024-04-07 11:24:46,652 - train - INFO - Train: 69 [ 450/781 ( 58%)]  Loss:  3.581018 (4.1886)  Time: 1.045s,  122.47/s  (0.924s,  138.50/s)  LR: 2.857e-04  Data: 0.007 (0.008)
2024-04-07 11:25:33,491 - train - INFO - Train: 69 [ 500/781 ( 64%)]  Loss:  3.525259 (4.1898)  Time: 0.826s,  155.05/s  (0.925s,  138.31/s)  LR: 2.857e-04  Data: 0.005 (0.008)
2024-04-07 11:26:20,558 - train - INFO - Train: 69 [ 550/781 ( 71%)]  Loss:  4.525125 (4.1907)  Time: 0.857s,  149.40/s  (0.927s,  138.10/s)  LR: 2.857e-04  Data: 0.006 (0.008)
2024-04-07 11:27:06,655 - train - INFO - Train: 69 [ 600/781 ( 77%)]  Loss:  4.594199 (4.1889)  Time: 0.852s,  150.21/s  (0.926s,  138.16/s)  LR: 2.857e-04  Data: 0.008 (0.007)
2024-04-07 11:27:52,345 - train - INFO - Train: 69 [ 650/781 ( 83%)]  Loss:  4.660460 (4.1972)  Time: 0.861s,  148.68/s  (0.926s,  138.30/s)  LR: 2.857e-04  Data: 0.011 (0.007)
2024-04-07 11:28:39,385 - train - INFO - Train: 69 [ 700/781 ( 90%)]  Loss:  3.522181 (4.1990)  Time: 0.854s,  149.86/s  (0.927s,  138.14/s)  LR: 2.857e-04  Data: 0.007 (0.007)
2024-04-07 11:29:23,633 - train - INFO - Train: 69 [ 750/781 ( 96%)]  Loss:  3.518390 (4.1915)  Time: 0.856s,  149.56/s  (0.924s,  138.56/s)  LR: 2.857e-04  Data: 0.009 (0.007)
2024-04-07 11:29:50,666 - train - INFO - Train: 69 [ 780/781 (100%)]  Loss:  4.080483 (4.1953)  Time: 0.854s,  149.88/s  (0.923s,  138.69/s)  LR: 2.857e-04  Data: 0.000 (0.007)
2024-04-07 11:29:50,667 - train - INFO - True
2024-04-07 11:29:50,669 - train - INFO - alphas:tensor([0.0147, 0.0151, 0.0603, 0.3483, 0.5616], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,692 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,692 - train - INFO - True
2024-04-07 11:29:50,693 - train - INFO - alphas:tensor([0.1079, 0.0220, 0.0444, 0.1516, 0.6741], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,713 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,713 - train - INFO - True
2024-04-07 11:29:50,714 - train - INFO - alphas:tensor([0.5020, 0.0963, 0.0727, 0.1374, 0.1916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,748 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,748 - train - INFO - True
2024-04-07 11:29:50,749 - train - INFO - alphas:tensor([0.4155, 0.0270, 0.0467, 0.1485, 0.3622], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,777 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,777 - train - INFO - True
2024-04-07 11:29:50,778 - train - INFO - alphas:tensor([0.2654, 0.0175, 0.0591, 0.1632, 0.4948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,791 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,792 - train - INFO - True
2024-04-07 11:29:50,792 - train - INFO - alphas:tensor([0.3634, 0.0143, 0.0379, 0.1239, 0.4605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,805 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,805 - train - INFO - True
2024-04-07 11:29:50,806 - train - INFO - alphas:tensor([0.4954, 0.0408, 0.0312, 0.1321, 0.3005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,829 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,829 - train - INFO - True
2024-04-07 11:29:50,830 - train - INFO - alphas:tensor([0.3714, 0.0202, 0.0157, 0.1219, 0.4707], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,841 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,841 - train - INFO - True
2024-04-07 11:29:50,842 - train - INFO - alphas:tensor([0.3251, 0.0147, 0.0415, 0.1364, 0.4823], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,852 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,852 - train - INFO - True
2024-04-07 11:29:50,853 - train - INFO - alphas:tensor([0.4256, 0.0121, 0.0359, 0.1020, 0.4244], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,873 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,873 - train - INFO - True
2024-04-07 11:29:50,874 - train - INFO - alphas:tensor([0.3992, 0.0226, 0.0259, 0.1293, 0.4231], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,884 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,884 - train - INFO - True
2024-04-07 11:29:50,884 - train - INFO - alphas:tensor([0.3035, 0.0099, 0.0141, 0.1341, 0.5384], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,894 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,894 - train - INFO - True
2024-04-07 11:29:50,894 - train - INFO - alphas:tensor([0.3344, 0.0100, 0.0323, 0.1270, 0.4963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,904 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,904 - train - INFO - True
2024-04-07 11:29:50,904 - train - INFO - alphas:tensor([0.4233, 0.0062, 0.0250, 0.0833, 0.4623], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,913 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,913 - train - INFO - True
2024-04-07 11:29:50,914 - train - INFO - alphas:tensor([0.3111, 0.0246, 0.0201, 0.1353, 0.5089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,923 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,923 - train - INFO - True
2024-04-07 11:29:50,923 - train - INFO - alphas:tensor([0.2170, 0.0065, 0.0072, 0.1368, 0.6325], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,932 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,932 - train - INFO - True
2024-04-07 11:29:50,933 - train - INFO - alphas:tensor([0.3210, 0.0102, 0.0252, 0.1196, 0.5239], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,942 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,942 - train - INFO - True
2024-04-07 11:29:50,942 - train - INFO - alphas:tensor([0.4162, 0.0051, 0.0214, 0.0785, 0.4788], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,951 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,951 - train - INFO - True
2024-04-07 11:29:50,952 - train - INFO - alphas:tensor([0.3175, 0.0099, 0.0125, 0.1260, 0.5341], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,960 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,960 - train - INFO - True
2024-04-07 11:29:50,961 - train - INFO - alphas:tensor([0.2200, 0.0047, 0.0054, 0.1164, 0.6535], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,970 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,970 - train - INFO - True
2024-04-07 11:29:50,970 - train - INFO - alphas:tensor([0.2723, 0.0063, 0.0230, 0.1188, 0.5797], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,979 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,979 - train - INFO - True
2024-04-07 11:29:50,980 - train - INFO - alphas:tensor([0.3914, 0.0041, 0.0187, 0.0685, 0.5174], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,988 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,988 - train - INFO - True
2024-04-07 11:29:50,989 - train - INFO - alphas:tensor([0.3628, 0.0136, 0.0113, 0.1008, 0.5115], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:50,997 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:50,997 - train - INFO - True
2024-04-07 11:29:50,998 - train - INFO - alphas:tensor([0.2548, 0.0036, 0.0036, 0.0894, 0.6485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:51,007 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:51,007 - train - INFO - True
2024-04-07 11:29:51,008 - train - INFO - alphas:tensor([0.2618, 0.0051, 0.0200, 0.1085, 0.6045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:51,016 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:51,016 - train - INFO - True
2024-04-07 11:29:51,017 - train - INFO - alphas:tensor([0.3781, 0.0040, 0.0175, 0.0587, 0.5416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:51,025 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:51,026 - train - INFO - True
2024-04-07 11:29:51,026 - train - INFO - alphas:tensor([0.3964, 0.0056, 0.0093, 0.0924, 0.4964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:51,035 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:51,035 - train - INFO - True
2024-04-07 11:29:51,036 - train - INFO - alphas:tensor([0.2859, 0.0037, 0.0031, 0.0765, 0.6308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:51,044 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:51,044 - train - INFO - True
2024-04-07 11:29:51,045 - train - INFO - alphas:tensor([0.2377, 0.0041, 0.0185, 0.1102, 0.6295], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:51,053 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:51,053 - train - INFO - True
2024-04-07 11:29:51,054 - train - INFO - alphas:tensor([0.3484, 0.0024, 0.0133, 0.0643, 0.5715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:51,062 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:51,062 - train - INFO - True
2024-04-07 11:29:51,063 - train - INFO - alphas:tensor([0.4348, 0.0054, 0.0082, 0.0795, 0.4721], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:51,072 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:51,072 - train - INFO - True
2024-04-07 11:29:51,072 - train - INFO - alphas:tensor([0.3314, 0.0024, 0.0041, 0.0830, 0.5791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:51,081 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:51,081 - train - INFO - True
2024-04-07 11:29:51,082 - train - INFO - alphas:tensor([0.2198, 0.0035, 0.0158, 0.0979, 0.6629], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:51,090 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:51,090 - train - INFO - True
2024-04-07 11:29:51,091 - train - INFO - alphas:tensor([0.3150, 0.0016, 0.0103, 0.0511, 0.6220], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:51,099 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:51,099 - train - INFO - True
2024-04-07 11:29:51,100 - train - INFO - alphas:tensor([0.4264, 0.0077, 0.0088, 0.0868, 0.4703], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:51,109 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:51,109 - train - INFO - True
2024-04-07 11:29:51,109 - train - INFO - alphas:tensor([0.3473, 0.0023, 0.0050, 0.0847, 0.5607], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:51,118 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:51,118 - train - INFO - True
2024-04-07 11:29:51,119 - train - INFO - alphas:tensor([0.6427, 0.0368, 0.1069, 0.2135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:29:51,135 - train - INFO - tau:0.5099857462495653
2024-04-07 11:29:51,135 - train - INFO - avg block size:13.972972972972974
2024-04-07 11:29:51,136 - train - INFO - current latency ratio:tensor(0.1929)
2024-04-07 11:29:51,388 - train - INFO - Test: [   0/78]  Time: 0.249 (0.249)  Loss:  0.9824 (0.9824)  Acc@1: 81.2500 (81.2500)  Acc@5: 94.5312 (94.5312)
2024-04-07 11:29:56,009 - train - INFO - Test: [  50/78]  Time: 0.086 (0.095)  Loss:  1.9004 (1.6997)  Acc@1: 57.0312 (60.7077)  Acc@5: 81.2500 (83.2874)
2024-04-07 11:29:58,712 - train - INFO - Test: [  78/78]  Time: 0.055 (0.096)  Loss:  1.7041 (1.7317)  Acc@1: 50.0000 (60.0800)  Acc@5: 87.5000 (82.5500)
2024-04-07 11:30:00,017 - train - INFO - Train: 70 [   0/781 (  0%)]  Loss:  4.518719 (4.5187)  Time: 1.229s,  104.15/s  (1.229s,  104.15/s)  LR: 2.806e-04  Data: 0.150 (0.150)
2024-04-07 11:30:46,370 - train - INFO - Train: 70 [  50/781 (  6%)]  Loss:  4.233303 (4.1022)  Time: 0.964s,  132.71/s  (0.933s,  137.20/s)  LR: 2.806e-04  Data: 0.010 (0.010)
2024-04-07 11:31:34,261 - train - INFO - Train: 70 [ 100/781 ( 13%)]  Loss:  3.673959 (4.1394)  Time: 1.103s,  116.02/s  (0.945s,  135.41/s)  LR: 2.806e-04  Data: 0.010 (0.009)
2024-04-07 11:32:20,753 - train - INFO - Train: 70 [ 150/781 ( 19%)]  Loss:  4.368288 (4.1674)  Time: 0.849s,  150.74/s  (0.940s,  136.15/s)  LR: 2.806e-04  Data: 0.009 (0.008)
2024-04-07 11:33:06,375 - train - INFO - Train: 70 [ 200/781 ( 26%)]  Loss:  3.802789 (4.1834)  Time: 0.833s,  153.66/s  (0.933s,  137.16/s)  LR: 2.806e-04  Data: 0.005 (0.008)
2024-04-07 11:33:51,487 - train - INFO - Train: 70 [ 250/781 ( 32%)]  Loss:  3.401383 (4.1684)  Time: 0.843s,  151.84/s  (0.927s,  138.07/s)  LR: 2.806e-04  Data: 0.008 (0.008)
2024-04-07 11:34:36,504 - train - INFO - Train: 70 [ 300/781 ( 38%)]  Loss:  4.705031 (4.1753)  Time: 1.070s,  119.61/s  (0.923s,  138.74/s)  LR: 2.806e-04  Data: 0.008 (0.007)
2024-04-07 11:35:22,304 - train - INFO - Train: 70 [ 350/781 ( 45%)]  Loss:  4.706063 (4.1840)  Time: 0.918s,  139.40/s  (0.922s,  138.88/s)  LR: 2.806e-04  Data: 0.008 (0.007)
2024-04-07 11:36:09,372 - train - INFO - Train: 70 [ 400/781 ( 51%)]  Loss:  4.566326 (4.1853)  Time: 0.761s,  168.30/s  (0.924s,  138.51/s)  LR: 2.806e-04  Data: 0.004 (0.007)
2024-04-07 11:36:54,272 - train - INFO - Train: 70 [ 450/781 ( 58%)]  Loss:  4.647097 (4.1874)  Time: 1.105s,  115.83/s  (0.921s,  138.95/s)  LR: 2.806e-04  Data: 0.008 (0.007)
2024-04-07 11:37:39,351 - train - INFO - Train: 70 [ 500/781 ( 64%)]  Loss:  4.637053 (4.1930)  Time: 0.853s,  150.11/s  (0.919s,  139.24/s)  LR: 2.806e-04  Data: 0.009 (0.007)
2024-04-07 11:38:25,232 - train - INFO - Train: 70 [ 550/781 ( 71%)]  Loss:  3.811313 (4.1869)  Time: 0.857s,  149.29/s  (0.919s,  139.27/s)  LR: 2.806e-04  Data: 0.004 (0.007)
2024-04-07 11:39:11,051 - train - INFO - Train: 70 [ 600/781 ( 77%)]  Loss:  4.130342 (4.1888)  Time: 0.817s,  156.59/s  (0.919s,  139.30/s)  LR: 2.806e-04  Data: 0.005 (0.007)
2024-04-07 11:39:54,948 - train - INFO - Train: 70 [ 650/781 ( 83%)]  Loss:  3.847221 (4.1965)  Time: 0.817s,  156.73/s  (0.916s,  139.78/s)  LR: 2.806e-04  Data: 0.005 (0.007)
2024-04-07 11:40:41,513 - train - INFO - Train: 70 [ 700/781 ( 90%)]  Loss:  4.586799 (4.1915)  Time: 1.060s,  120.73/s  (0.917s,  139.61/s)  LR: 2.806e-04  Data: 0.008 (0.007)
2024-04-07 11:41:27,429 - train - INFO - Train: 70 [ 750/781 ( 96%)]  Loss:  3.643206 (4.1908)  Time: 0.831s,  154.09/s  (0.917s,  139.60/s)  LR: 2.806e-04  Data: 0.005 (0.007)
2024-04-07 11:41:53,753 - train - INFO - Train: 70 [ 780/781 (100%)]  Loss:  3.714641 (4.1919)  Time: 1.038s,  123.34/s  (0.915s,  139.83/s)  LR: 2.806e-04  Data: 0.000 (0.007)
2024-04-07 11:41:53,755 - train - INFO - True
2024-04-07 11:41:53,757 - train - INFO - alphas:tensor([0.0129, 0.0136, 0.0566, 0.3434, 0.5734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:53,779 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:53,779 - train - INFO - True
2024-04-07 11:41:53,781 - train - INFO - alphas:tensor([0.1046, 0.0212, 0.0430, 0.1509, 0.6803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:53,800 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:53,800 - train - INFO - True
2024-04-07 11:41:53,801 - train - INFO - alphas:tensor([0.4964, 0.0953, 0.0724, 0.1396, 0.1963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:53,834 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:53,834 - train - INFO - True
2024-04-07 11:41:53,835 - train - INFO - alphas:tensor([0.4121, 0.0263, 0.0452, 0.1481, 0.3684], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:53,864 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:53,864 - train - INFO - True
2024-04-07 11:41:53,865 - train - INFO - alphas:tensor([0.2621, 0.0169, 0.0581, 0.1617, 0.5012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:53,882 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:53,882 - train - INFO - True
2024-04-07 11:41:53,883 - train - INFO - alphas:tensor([0.3594, 0.0134, 0.0365, 0.1220, 0.4686], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:53,898 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:53,898 - train - INFO - True
2024-04-07 11:41:53,899 - train - INFO - alphas:tensor([0.4900, 0.0398, 0.0300, 0.1322, 0.3079], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:53,927 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:53,927 - train - INFO - True
2024-04-07 11:41:53,928 - train - INFO - alphas:tensor([0.3677, 0.0194, 0.0148, 0.1206, 0.4776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:53,942 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:53,942 - train - INFO - True
2024-04-07 11:41:53,943 - train - INFO - alphas:tensor([0.3219, 0.0140, 0.0402, 0.1345, 0.4894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:53,958 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:53,958 - train - INFO - True
2024-04-07 11:41:53,959 - train - INFO - alphas:tensor([0.4229, 0.0114, 0.0344, 0.1002, 0.4310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:53,973 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:53,973 - train - INFO - True
2024-04-07 11:41:53,974 - train - INFO - alphas:tensor([0.3952, 0.0220, 0.0247, 0.1285, 0.4297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:53,988 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:53,988 - train - INFO - True
2024-04-07 11:41:53,989 - train - INFO - alphas:tensor([0.3012, 0.0095, 0.0132, 0.1333, 0.5428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,004 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,004 - train - INFO - True
2024-04-07 11:41:54,005 - train - INFO - alphas:tensor([0.3307, 0.0095, 0.0310, 0.1250, 0.5038], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,019 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,019 - train - INFO - True
2024-04-07 11:41:54,020 - train - INFO - alphas:tensor([0.4210, 0.0056, 0.0238, 0.0809, 0.4687], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,034 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,034 - train - INFO - True
2024-04-07 11:41:54,035 - train - INFO - alphas:tensor([0.3081, 0.0240, 0.0190, 0.1337, 0.5152], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,049 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,050 - train - INFO - True
2024-04-07 11:41:54,051 - train - INFO - alphas:tensor([0.2150, 0.0062, 0.0067, 0.1379, 0.6342], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,065 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,065 - train - INFO - True
2024-04-07 11:41:54,066 - train - INFO - alphas:tensor([0.3166, 0.0097, 0.0243, 0.1174, 0.5320], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,080 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,080 - train - INFO - True
2024-04-07 11:41:54,081 - train - INFO - alphas:tensor([0.4110, 0.0047, 0.0204, 0.0765, 0.4874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,095 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,096 - train - INFO - True
2024-04-07 11:41:54,097 - train - INFO - alphas:tensor([0.3154, 0.0094, 0.0116, 0.1248, 0.5386], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,111 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,111 - train - INFO - True
2024-04-07 11:41:54,112 - train - INFO - alphas:tensor([0.2171, 0.0044, 0.0049, 0.1174, 0.6561], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,126 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,126 - train - INFO - True
2024-04-07 11:41:54,127 - train - INFO - alphas:tensor([0.2683, 0.0059, 0.0221, 0.1166, 0.5871], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,141 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,142 - train - INFO - True
2024-04-07 11:41:54,143 - train - INFO - alphas:tensor([0.3869, 0.0037, 0.0177, 0.0659, 0.5257], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,157 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,157 - train - INFO - True
2024-04-07 11:41:54,158 - train - INFO - alphas:tensor([0.3590, 0.0129, 0.0105, 0.0994, 0.5182], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,172 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,172 - train - INFO - True
2024-04-07 11:41:54,173 - train - INFO - alphas:tensor([0.2556, 0.0034, 0.0033, 0.0879, 0.6498], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,187 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,187 - train - INFO - True
2024-04-07 11:41:54,188 - train - INFO - alphas:tensor([0.2596, 0.0048, 0.0189, 0.1063, 0.6104], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,203 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,203 - train - INFO - True
2024-04-07 11:41:54,204 - train - INFO - alphas:tensor([0.3765, 0.0037, 0.0169, 0.0568, 0.5461], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,221 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,221 - train - INFO - True
2024-04-07 11:41:54,222 - train - INFO - alphas:tensor([0.3969, 0.0052, 0.0086, 0.0901, 0.4992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,236 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,236 - train - INFO - True
2024-04-07 11:41:54,237 - train - INFO - alphas:tensor([0.2866, 0.0035, 0.0028, 0.0742, 0.6329], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,251 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,251 - train - INFO - True
2024-04-07 11:41:54,252 - train - INFO - alphas:tensor([0.2365, 0.0039, 0.0174, 0.1070, 0.6352], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,267 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,267 - train - INFO - True
2024-04-07 11:41:54,268 - train - INFO - alphas:tensor([0.3457, 0.0022, 0.0124, 0.0621, 0.5777], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,282 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,282 - train - INFO - True
2024-04-07 11:41:54,283 - train - INFO - alphas:tensor([0.4317, 0.0050, 0.0076, 0.0783, 0.4774], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,297 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,297 - train - INFO - True
2024-04-07 11:41:54,298 - train - INFO - alphas:tensor([0.3299, 0.0022, 0.0037, 0.0812, 0.5830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,312 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,313 - train - INFO - True
2024-04-07 11:41:54,314 - train - INFO - alphas:tensor([0.2173, 0.0034, 0.0151, 0.0946, 0.6697], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,328 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,328 - train - INFO - True
2024-04-07 11:41:54,329 - train - INFO - alphas:tensor([0.3101, 0.0014, 0.0096, 0.0492, 0.6297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,343 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,343 - train - INFO - True
2024-04-07 11:41:54,344 - train - INFO - alphas:tensor([0.4254, 0.0073, 0.0081, 0.0849, 0.4743], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,358 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,359 - train - INFO - True
2024-04-07 11:41:54,360 - train - INFO - alphas:tensor([0.3487, 0.0021, 0.0045, 0.0822, 0.5624], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,374 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,374 - train - INFO - True
2024-04-07 11:41:54,375 - train - INFO - alphas:tensor([0.6393, 0.0363, 0.1072, 0.2172], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:41:54,403 - train - INFO - tau:0.5048858887870696
2024-04-07 11:41:54,403 - train - INFO - avg block size:14.378378378378379
2024-04-07 11:41:54,404 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 11:41:54,404 - train - INFO - lasso_alpha:0.00015863092971714956
2024-04-07 11:41:54,665 - train - INFO - Test: [   0/78]  Time: 0.257 (0.257)  Loss:  0.9150 (0.9150)  Acc@1: 82.8125 (82.8125)  Acc@5: 94.5312 (94.5312)
2024-04-07 11:41:59,107 - train - INFO - Test: [  50/78]  Time: 0.088 (0.092)  Loss:  1.8135 (1.6802)  Acc@1: 57.0312 (60.8762)  Acc@5: 84.3750 (83.7316)
2024-04-07 11:42:01,535 - train - INFO - Test: [  78/78]  Time: 0.057 (0.090)  Loss:  1.9814 (1.7200)  Acc@1: 43.7500 (60.0200)  Acc@5: 81.2500 (82.8500)
2024-04-07 11:42:02,739 - train - INFO - Train: 71 [   0/781 (  0%)]  Loss:  4.661908 (4.6619)  Time: 1.145s,  111.82/s  (1.145s,  111.82/s)  LR: 2.755e-04  Data: 0.185 (0.185)
2024-04-07 11:42:48,814 - train - INFO - Train: 71 [  50/781 (  6%)]  Loss:  4.193750 (4.0964)  Time: 1.112s,  115.09/s  (0.926s,  138.25/s)  LR: 2.755e-04  Data: 0.009 (0.010)
2024-04-07 11:43:33,399 - train - INFO - Train: 71 [ 100/781 ( 13%)]  Loss:  4.601485 (4.1026)  Time: 0.855s,  149.65/s  (0.909s,  140.83/s)  LR: 2.755e-04  Data: 0.019 (0.009)
2024-04-07 11:44:18,302 - train - INFO - Train: 71 [ 150/781 ( 19%)]  Loss:  4.128780 (4.1204)  Time: 0.889s,  143.97/s  (0.905s,  141.39/s)  LR: 2.755e-04  Data: 0.007 (0.008)
2024-04-07 11:45:03,977 - train - INFO - Train: 71 [ 200/781 ( 26%)]  Loss:  3.878628 (4.1481)  Time: 0.794s,  161.17/s  (0.907s,  141.07/s)  LR: 2.755e-04  Data: 0.007 (0.008)
2024-04-07 11:45:48,986 - train - INFO - Train: 71 [ 250/781 ( 32%)]  Loss:  4.430433 (4.1458)  Time: 0.825s,  155.13/s  (0.906s,  141.29/s)  LR: 2.755e-04  Data: 0.009 (0.008)
2024-04-07 11:46:34,276 - train - INFO - Train: 71 [ 300/781 ( 38%)]  Loss:  4.075344 (4.1374)  Time: 0.825s,  155.06/s  (0.906s,  141.30/s)  LR: 2.755e-04  Data: 0.005 (0.008)
2024-04-07 11:47:18,956 - train - INFO - Train: 71 [ 350/781 ( 45%)]  Loss:  3.927160 (4.1563)  Time: 0.935s,  136.87/s  (0.904s,  141.57/s)  LR: 2.755e-04  Data: 0.005 (0.008)
2024-04-07 11:48:04,284 - train - INFO - Train: 71 [ 400/781 ( 51%)]  Loss:  3.490017 (4.1588)  Time: 0.824s,  155.28/s  (0.904s,  141.53/s)  LR: 2.755e-04  Data: 0.005 (0.007)
2024-04-07 11:48:51,198 - train - INFO - Train: 71 [ 450/781 ( 58%)]  Loss:  3.454749 (4.1513)  Time: 0.853s,  150.06/s  (0.908s,  140.94/s)  LR: 2.755e-04  Data: 0.007 (0.007)
2024-04-07 11:49:37,256 - train - INFO - Train: 71 [ 500/781 ( 64%)]  Loss:  3.680092 (4.1442)  Time: 0.830s,  154.20/s  (0.909s,  140.74/s)  LR: 2.755e-04  Data: 0.006 (0.007)
2024-04-07 11:50:21,895 - train - INFO - Train: 71 [ 550/781 ( 71%)]  Loss:  4.553602 (4.1488)  Time: 0.820s,  156.15/s  (0.908s,  140.98/s)  LR: 2.755e-04  Data: 0.006 (0.007)
2024-04-07 11:51:07,736 - train - INFO - Train: 71 [ 600/781 ( 77%)]  Loss:  4.096919 (4.1487)  Time: 1.031s,  124.14/s  (0.909s,  140.86/s)  LR: 2.755e-04  Data: 0.007 (0.007)
2024-04-07 11:51:52,780 - train - INFO - Train: 71 [ 650/781 ( 83%)]  Loss:  4.182338 (4.1474)  Time: 0.833s,  153.58/s  (0.908s,  140.96/s)  LR: 2.755e-04  Data: 0.005 (0.007)
2024-04-07 11:52:38,960 - train - INFO - Train: 71 [ 700/781 ( 90%)]  Loss:  4.191830 (4.1479)  Time: 1.101s,  116.21/s  (0.909s,  140.78/s)  LR: 2.755e-04  Data: 0.006 (0.007)
2024-04-07 11:53:25,052 - train - INFO - Train: 71 [ 750/781 ( 96%)]  Loss:  3.715375 (4.1441)  Time: 0.852s,  150.21/s  (0.910s,  140.66/s)  LR: 2.755e-04  Data: 0.008 (0.007)
2024-04-07 11:53:52,286 - train - INFO - Train: 71 [ 780/781 (100%)]  Loss:  3.729409 (4.1409)  Time: 0.833s,  153.58/s  (0.910s,  140.67/s)  LR: 2.755e-04  Data: 0.000 (0.007)
2024-04-07 11:53:52,287 - train - INFO - True
2024-04-07 11:53:52,288 - train - INFO - alphas:tensor([0.0115, 0.0124, 0.0537, 0.3407, 0.5817], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,298 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,298 - train - INFO - True
2024-04-07 11:53:52,299 - train - INFO - alphas:tensor([0.1047, 0.0208, 0.0424, 0.1486, 0.6835], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,308 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,308 - train - INFO - True
2024-04-07 11:53:52,309 - train - INFO - alphas:tensor([0.4950, 0.0947, 0.0714, 0.1400, 0.1989], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,327 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,327 - train - INFO - True
2024-04-07 11:53:52,328 - train - INFO - alphas:tensor([0.4122, 0.0253, 0.0438, 0.1462, 0.3725], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,345 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,345 - train - INFO - True
2024-04-07 11:53:52,346 - train - INFO - alphas:tensor([0.2601, 0.0165, 0.0567, 0.1599, 0.5068], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,355 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,355 - train - INFO - True
2024-04-07 11:53:52,356 - train - INFO - alphas:tensor([0.3574, 0.0126, 0.0350, 0.1202, 0.4747], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,385 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,385 - train - INFO - True
2024-04-07 11:53:52,387 - train - INFO - alphas:tensor([0.4884, 0.0389, 0.0290, 0.1317, 0.3120], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,428 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,428 - train - INFO - True
2024-04-07 11:53:52,429 - train - INFO - alphas:tensor([0.3676, 0.0187, 0.0139, 0.1187, 0.4811], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,447 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,447 - train - INFO - True
2024-04-07 11:53:52,448 - train - INFO - alphas:tensor([0.3202, 0.0135, 0.0390, 0.1328, 0.4945], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,464 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,464 - train - INFO - True
2024-04-07 11:53:52,465 - train - INFO - alphas:tensor([0.4231, 0.0108, 0.0329, 0.0979, 0.4352], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,480 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,480 - train - INFO - True
2024-04-07 11:53:52,481 - train - INFO - alphas:tensor([0.3968, 0.0215, 0.0237, 0.1270, 0.4310], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,495 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,495 - train - INFO - True
2024-04-07 11:53:52,496 - train - INFO - alphas:tensor([0.3055, 0.0092, 0.0124, 0.1313, 0.5416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,510 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,510 - train - INFO - True
2024-04-07 11:53:52,511 - train - INFO - alphas:tensor([0.3295, 0.0090, 0.0299, 0.1225, 0.5091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,526 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,526 - train - INFO - True
2024-04-07 11:53:52,527 - train - INFO - alphas:tensor([0.4192, 0.0053, 0.0228, 0.0789, 0.4738], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,541 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,541 - train - INFO - True
2024-04-07 11:53:52,542 - train - INFO - alphas:tensor([0.3096, 0.0236, 0.0182, 0.1333, 0.5152], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,556 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,556 - train - INFO - True
2024-04-07 11:53:52,557 - train - INFO - alphas:tensor([0.2171, 0.0060, 0.0063, 0.1388, 0.6317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,571 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,571 - train - INFO - True
2024-04-07 11:53:52,572 - train - INFO - alphas:tensor([0.3136, 0.0091, 0.0232, 0.1153, 0.5387], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,587 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,587 - train - INFO - True
2024-04-07 11:53:52,588 - train - INFO - alphas:tensor([0.4128, 0.0043, 0.0195, 0.0737, 0.4897], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,602 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,602 - train - INFO - True
2024-04-07 11:53:52,603 - train - INFO - alphas:tensor([0.3168, 0.0091, 0.0109, 0.1240, 0.5391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,617 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,617 - train - INFO - True
2024-04-07 11:53:52,618 - train - INFO - alphas:tensor([0.2179, 0.0042, 0.0046, 0.1173, 0.6560], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,633 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,633 - train - INFO - True
2024-04-07 11:53:52,634 - train - INFO - alphas:tensor([0.2673, 0.0056, 0.0213, 0.1138, 0.5919], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,649 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,649 - train - INFO - True
2024-04-07 11:53:52,650 - train - INFO - alphas:tensor([0.3878, 0.0034, 0.0168, 0.0640, 0.5280], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,664 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,664 - train - INFO - True
2024-04-07 11:53:52,665 - train - INFO - alphas:tensor([0.3595, 0.0124, 0.0098, 0.0969, 0.5214], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,679 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,679 - train - INFO - True
2024-04-07 11:53:52,680 - train - INFO - alphas:tensor([0.2573, 0.0032, 0.0030, 0.0873, 0.6492], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,694 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,694 - train - INFO - True
2024-04-07 11:53:52,695 - train - INFO - alphas:tensor([0.2581, 0.0046, 0.0179, 0.1037, 0.6158], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,709 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,710 - train - INFO - True
2024-04-07 11:53:52,711 - train - INFO - alphas:tensor([0.3768, 0.0034, 0.0160, 0.0547, 0.5490], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,725 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,725 - train - INFO - True
2024-04-07 11:53:52,726 - train - INFO - alphas:tensor([0.3999, 0.0048, 0.0078, 0.0877, 0.4998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,740 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,740 - train - INFO - True
2024-04-07 11:53:52,741 - train - INFO - alphas:tensor([0.2913, 0.0033, 0.0026, 0.0728, 0.6301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,755 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,755 - train - INFO - True
2024-04-07 11:53:52,756 - train - INFO - alphas:tensor([0.2377, 0.0037, 0.0167, 0.1043, 0.6376], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,770 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,771 - train - INFO - True
2024-04-07 11:53:52,771 - train - INFO - alphas:tensor([0.3482, 0.0020, 0.0120, 0.0592, 0.5786], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,786 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,786 - train - INFO - True
2024-04-07 11:53:52,787 - train - INFO - alphas:tensor([0.4344, 0.0047, 0.0070, 0.0760, 0.4779], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,801 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,801 - train - INFO - True
2024-04-07 11:53:52,802 - train - INFO - alphas:tensor([0.3328, 0.0020, 0.0034, 0.0788, 0.5830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,816 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,816 - train - INFO - True
2024-04-07 11:53:52,817 - train - INFO - alphas:tensor([0.2167, 0.0032, 0.0145, 0.0926, 0.6730], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,831 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,832 - train - INFO - True
2024-04-07 11:53:52,832 - train - INFO - alphas:tensor([0.3121, 0.0013, 0.0090, 0.0471, 0.6305], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,847 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,847 - train - INFO - True
2024-04-07 11:53:52,848 - train - INFO - alphas:tensor([0.4262, 0.0067, 0.0075, 0.0824, 0.4772], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,862 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,862 - train - INFO - True
2024-04-07 11:53:52,863 - train - INFO - alphas:tensor([0.3509, 0.0020, 0.0041, 0.0798, 0.5632], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,877 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,877 - train - INFO - True
2024-04-07 11:53:52,878 - train - INFO - alphas:tensor([0.6358, 0.0358, 0.1075, 0.2208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 11:53:52,906 - train - INFO - tau:0.4998370298991989
2024-04-07 11:53:52,906 - train - INFO - avg block size:14.378378378378379
2024-04-07 11:53:52,907 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 11:53:53,146 - train - INFO - Test: [   0/78]  Time: 0.235 (0.235)  Loss:  0.8828 (0.8828)  Acc@1: 83.5938 (83.5938)  Acc@5: 93.7500 (93.7500)
2024-04-07 11:53:57,563 - train - INFO - Test: [  50/78]  Time: 0.086 (0.091)  Loss:  1.8965 (1.6888)  Acc@1: 57.8125 (60.6158)  Acc@5: 81.2500 (83.5478)
2024-04-07 11:53:59,978 - train - INFO - Test: [  78/78]  Time: 0.058 (0.089)  Loss:  1.9473 (1.7246)  Acc@1: 43.7500 (59.9800)  Acc@5: 93.7500 (82.8000)
2024-04-07 11:54:01,278 - train - INFO - Train: 72 [   0/781 (  0%)]  Loss:  4.024096 (4.0241)  Time: 1.234s,  103.70/s  (1.234s,  103.70/s)  LR: 2.704e-04  Data: 0.198 (0.198)
2024-04-07 11:54:47,061 - train - INFO - Train: 72 [  50/781 (  6%)]  Loss:  4.661232 (4.1263)  Time: 1.096s,  116.81/s  (0.922s,  138.85/s)  LR: 2.704e-04  Data: 0.016 (0.010)
2024-04-07 11:55:33,394 - train - INFO - Train: 72 [ 100/781 ( 13%)]  Loss:  4.646046 (4.1544)  Time: 0.935s,  136.92/s  (0.924s,  138.49/s)  LR: 2.704e-04  Data: 0.005 (0.009)
2024-04-07 11:56:19,570 - train - INFO - Train: 72 [ 150/781 ( 19%)]  Loss:  3.865402 (4.1337)  Time: 0.859s,  149.04/s  (0.924s,  138.53/s)  LR: 2.704e-04  Data: 0.008 (0.008)
2024-04-07 11:57:05,146 - train - INFO - Train: 72 [ 200/781 ( 26%)]  Loss:  3.913598 (4.1262)  Time: 0.817s,  156.60/s  (0.921s,  139.00/s)  LR: 2.704e-04  Data: 0.005 (0.008)
2024-04-07 11:57:51,529 - train - INFO - Train: 72 [ 250/781 ( 32%)]  Loss:  3.958975 (4.1174)  Time: 1.091s,  117.27/s  (0.922s,  138.80/s)  LR: 2.704e-04  Data: 0.009 (0.008)
2024-04-07 11:58:37,342 - train - INFO - Train: 72 [ 300/781 ( 38%)]  Loss:  3.443038 (4.1233)  Time: 0.807s,  158.56/s  (0.921s,  138.95/s)  LR: 2.704e-04  Data: 0.005 (0.008)
2024-04-07 11:59:22,202 - train - INFO - Train: 72 [ 350/781 ( 45%)]  Loss:  4.602192 (4.1231)  Time: 1.050s,  121.91/s  (0.918s,  139.46/s)  LR: 2.704e-04  Data: 0.007 (0.008)
2024-04-07 12:00:07,577 - train - INFO - Train: 72 [ 400/781 ( 51%)]  Loss:  4.072502 (4.1251)  Time: 0.864s,  148.14/s  (0.917s,  139.66/s)  LR: 2.704e-04  Data: 0.009 (0.007)
2024-04-07 12:00:52,562 - train - INFO - Train: 72 [ 450/781 ( 58%)]  Loss:  3.757082 (4.1179)  Time: 0.852s,  150.26/s  (0.915s,  139.95/s)  LR: 2.704e-04  Data: 0.007 (0.007)
2024-04-07 12:01:38,082 - train - INFO - Train: 72 [ 500/781 ( 64%)]  Loss:  4.554140 (4.1166)  Time: 0.848s,  150.86/s  (0.914s,  140.01/s)  LR: 2.704e-04  Data: 0.007 (0.007)
2024-04-07 12:02:23,763 - train - INFO - Train: 72 [ 550/781 ( 71%)]  Loss:  3.560555 (4.1268)  Time: 0.841s,  152.25/s  (0.914s,  140.02/s)  LR: 2.704e-04  Data: 0.007 (0.007)
2024-04-07 12:03:08,881 - train - INFO - Train: 72 [ 600/781 ( 77%)]  Loss:  4.414938 (4.1339)  Time: 0.843s,  151.91/s  (0.913s,  140.17/s)  LR: 2.704e-04  Data: 0.008 (0.007)
2024-04-07 12:03:53,692 - train - INFO - Train: 72 [ 650/781 ( 83%)]  Loss:  3.912023 (4.1358)  Time: 0.811s,  157.74/s  (0.912s,  140.37/s)  LR: 2.704e-04  Data: 0.005 (0.007)
2024-04-07 12:04:39,234 - train - INFO - Train: 72 [ 700/781 ( 90%)]  Loss:  4.686500 (4.1334)  Time: 0.985s,  129.91/s  (0.912s,  140.38/s)  LR: 2.704e-04  Data: 0.005 (0.007)
2024-04-07 12:05:24,693 - train - INFO - Train: 72 [ 750/781 ( 96%)]  Loss:  4.133070 (4.1340)  Time: 0.847s,  151.12/s  (0.912s,  140.41/s)  LR: 2.704e-04  Data: 0.007 (0.007)
2024-04-07 12:05:51,387 - train - INFO - Train: 72 [ 780/781 (100%)]  Loss:  3.646311 (4.1333)  Time: 1.014s,  126.23/s  (0.911s,  140.54/s)  LR: 2.704e-04  Data: 0.000 (0.007)
2024-04-07 12:05:51,388 - train - INFO - True
2024-04-07 12:05:51,389 - train - INFO - alphas:tensor([0.0103, 0.0113, 0.0513, 0.3384, 0.5888], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,405 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,406 - train - INFO - True
2024-04-07 12:05:51,407 - train - INFO - alphas:tensor([0.1037, 0.0203, 0.0420, 0.1476, 0.6864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,421 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,421 - train - INFO - True
2024-04-07 12:05:51,422 - train - INFO - alphas:tensor([0.4912, 0.0938, 0.0711, 0.1415, 0.2024], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,451 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,451 - train - INFO - True
2024-04-07 12:05:51,452 - train - INFO - alphas:tensor([0.4095, 0.0246, 0.0428, 0.1452, 0.3779], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,480 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,480 - train - INFO - True
2024-04-07 12:05:51,481 - train - INFO - alphas:tensor([0.2578, 0.0160, 0.0555, 0.1589, 0.5117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,495 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,496 - train - INFO - True
2024-04-07 12:05:51,496 - train - INFO - alphas:tensor([0.3568, 0.0121, 0.0340, 0.1181, 0.4791], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,511 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,511 - train - INFO - True
2024-04-07 12:05:51,512 - train - INFO - alphas:tensor([0.4863, 0.0375, 0.0280, 0.1312, 0.3169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,540 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,540 - train - INFO - True
2024-04-07 12:05:51,541 - train - INFO - alphas:tensor([0.3660, 0.0181, 0.0132, 0.1174, 0.4853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,555 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,556 - train - INFO - True
2024-04-07 12:05:51,556 - train - INFO - alphas:tensor([0.3174, 0.0130, 0.0379, 0.1311, 0.5006], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,571 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,571 - train - INFO - True
2024-04-07 12:05:51,572 - train - INFO - alphas:tensor([0.4207, 0.0102, 0.0319, 0.0960, 0.4412], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,586 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,586 - train - INFO - True
2024-04-07 12:05:51,587 - train - INFO - alphas:tensor([0.3939, 0.0208, 0.0227, 0.1264, 0.4361], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,602 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,602 - train - INFO - True
2024-04-07 12:05:51,603 - train - INFO - alphas:tensor([0.3026, 0.0088, 0.0117, 0.1297, 0.5472], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,617 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,617 - train - INFO - True
2024-04-07 12:05:51,618 - train - INFO - alphas:tensor([0.3282, 0.0086, 0.0290, 0.1206, 0.5135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,632 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,632 - train - INFO - True
2024-04-07 12:05:51,633 - train - INFO - alphas:tensor([0.4168, 0.0049, 0.0217, 0.0766, 0.4801], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,648 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,648 - train - INFO - True
2024-04-07 12:05:51,649 - train - INFO - alphas:tensor([0.3105, 0.0235, 0.0175, 0.1329, 0.5157], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,663 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,663 - train - INFO - True
2024-04-07 12:05:51,664 - train - INFO - alphas:tensor([0.2159, 0.0058, 0.0059, 0.1383, 0.6341], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,678 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,678 - train - INFO - True
2024-04-07 12:05:51,679 - train - INFO - alphas:tensor([0.3130, 0.0088, 0.0226, 0.1128, 0.5428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,694 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,694 - train - INFO - True
2024-04-07 12:05:51,695 - train - INFO - alphas:tensor([0.4116, 0.0040, 0.0184, 0.0720, 0.4939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,709 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,709 - train - INFO - True
2024-04-07 12:05:51,710 - train - INFO - alphas:tensor([0.3147, 0.0085, 0.0101, 0.1229, 0.5439], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,724 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,724 - train - INFO - True
2024-04-07 12:05:51,725 - train - INFO - alphas:tensor([0.2167, 0.0039, 0.0042, 0.1175, 0.6577], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,740 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,740 - train - INFO - True
2024-04-07 12:05:51,741 - train - INFO - alphas:tensor([0.2650, 0.0053, 0.0205, 0.1121, 0.5972], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,755 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,755 - train - INFO - True
2024-04-07 12:05:51,756 - train - INFO - alphas:tensor([0.3866, 0.0031, 0.0160, 0.0620, 0.5323], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,770 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,770 - train - INFO - True
2024-04-07 12:05:51,771 - train - INFO - alphas:tensor([0.3581, 0.0120, 0.0091, 0.0955, 0.5253], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,786 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,786 - train - INFO - True
2024-04-07 12:05:51,787 - train - INFO - alphas:tensor([0.2568, 0.0030, 0.0028, 0.0856, 0.6518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,801 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,801 - train - INFO - True
2024-04-07 12:05:51,802 - train - INFO - alphas:tensor([0.2568, 0.0043, 0.0169, 0.1012, 0.6207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,816 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,816 - train - INFO - True
2024-04-07 12:05:51,817 - train - INFO - alphas:tensor([0.3747, 0.0031, 0.0153, 0.0528, 0.5541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,831 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,832 - train - INFO - True
2024-04-07 12:05:51,833 - train - INFO - alphas:tensor([0.3967, 0.0045, 0.0073, 0.0863, 0.5053], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,847 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,847 - train - INFO - True
2024-04-07 12:05:51,848 - train - INFO - alphas:tensor([0.2885, 0.0031, 0.0023, 0.0717, 0.6344], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,862 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,862 - train - INFO - True
2024-04-07 12:05:51,863 - train - INFO - alphas:tensor([0.2336, 0.0035, 0.0160, 0.1023, 0.6446], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,878 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,878 - train - INFO - True
2024-04-07 12:05:51,879 - train - INFO - alphas:tensor([0.3451, 0.0018, 0.0115, 0.0576, 0.5840], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,893 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,893 - train - INFO - True
2024-04-07 12:05:51,894 - train - INFO - alphas:tensor([0.4316, 0.0043, 0.0063, 0.0741, 0.4837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,908 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,908 - train - INFO - True
2024-04-07 12:05:51,909 - train - INFO - alphas:tensor([0.3318, 0.0019, 0.0031, 0.0768, 0.5865], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,924 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,924 - train - INFO - True
2024-04-07 12:05:51,925 - train - INFO - alphas:tensor([0.2146, 0.0030, 0.0140, 0.0899, 0.6784], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,939 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,939 - train - INFO - True
2024-04-07 12:05:51,940 - train - INFO - alphas:tensor([0.3075, 0.0012, 0.0085, 0.0452, 0.6376], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,954 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,954 - train - INFO - True
2024-04-07 12:05:51,955 - train - INFO - alphas:tensor([0.4230, 0.0064, 0.0069, 0.0808, 0.4830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,970 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,970 - train - INFO - True
2024-04-07 12:05:51,971 - train - INFO - alphas:tensor([0.3493, 0.0018, 0.0037, 0.0776, 0.5677], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:51,985 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:51,985 - train - INFO - True
2024-04-07 12:05:51,986 - train - INFO - alphas:tensor([0.6335, 0.0351, 0.1076, 0.2237], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:05:52,014 - train - INFO - tau:0.49483865960020695
2024-04-07 12:05:52,014 - train - INFO - avg block size:14.378378378378379
2024-04-07 12:05:52,015 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 12:05:52,015 - train - INFO - lasso_alpha:0.0001442099361064996
2024-04-07 12:05:52,237 - train - INFO - Test: [   0/78]  Time: 0.218 (0.218)  Loss:  0.9683 (0.9683)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 12:05:56,715 - train - INFO - Test: [  50/78]  Time: 0.088 (0.092)  Loss:  1.8389 (1.6850)  Acc@1: 56.2500 (60.5545)  Acc@5: 84.3750 (83.4406)
2024-04-07 12:05:59,330 - train - INFO - Test: [  78/78]  Time: 0.059 (0.093)  Loss:  1.9375 (1.7213)  Acc@1: 56.2500 (59.8200)  Acc@5: 93.7500 (82.7000)
2024-04-07 12:06:00,648 - train - INFO - Train: 73 [   0/781 (  0%)]  Loss:  4.295450 (4.2954)  Time: 1.251s,  102.28/s  (1.251s,  102.28/s)  LR: 2.653e-04  Data: 0.182 (0.182)
2024-04-07 12:06:48,966 - train - INFO - Train: 73 [  50/781 (  6%)]  Loss:  4.366751 (4.0529)  Time: 1.081s,  118.37/s  (0.972s,  131.70/s)  LR: 2.653e-04  Data: 0.008 (0.011)
2024-04-07 12:07:34,466 - train - INFO - Train: 73 [ 100/781 ( 13%)]  Loss:  3.809265 (4.0466)  Time: 1.121s,  114.16/s  (0.941s,  135.99/s)  LR: 2.653e-04  Data: 0.009 (0.009)
2024-04-07 12:08:20,782 - train - INFO - Train: 73 [ 150/781 ( 19%)]  Loss:  3.951839 (4.0701)  Time: 0.863s,  148.28/s  (0.936s,  136.71/s)  LR: 2.653e-04  Data: 0.009 (0.008)
2024-04-07 12:09:06,113 - train - INFO - Train: 73 [ 200/781 ( 26%)]  Loss:  4.576892 (4.0938)  Time: 0.803s,  159.42/s  (0.929s,  137.80/s)  LR: 2.653e-04  Data: 0.004 (0.008)
2024-04-07 12:09:51,747 - train - INFO - Train: 73 [ 250/781 ( 32%)]  Loss:  4.388677 (4.0886)  Time: 1.082s,  118.30/s  (0.926s,  138.28/s)  LR: 2.653e-04  Data: 0.007 (0.008)
2024-04-07 12:10:36,357 - train - INFO - Train: 73 [ 300/781 ( 38%)]  Loss:  4.638257 (4.0980)  Time: 1.064s,  120.27/s  (0.920s,  139.12/s)  LR: 2.653e-04  Data: 0.008 (0.008)
2024-04-07 12:11:22,207 - train - INFO - Train: 73 [ 350/781 ( 45%)]  Loss:  4.165102 (4.0969)  Time: 0.955s,  134.02/s  (0.920s,  139.18/s)  LR: 2.653e-04  Data: 0.004 (0.008)
2024-04-07 12:12:06,584 - train - INFO - Train: 73 [ 400/781 ( 51%)]  Loss:  4.518754 (4.0971)  Time: 0.825s,  155.23/s  (0.916s,  139.79/s)  LR: 2.653e-04  Data: 0.006 (0.008)
2024-04-07 12:12:51,889 - train - INFO - Train: 73 [ 450/781 ( 58%)]  Loss:  3.730980 (4.1021)  Time: 0.832s,  153.91/s  (0.915s,  139.95/s)  LR: 2.653e-04  Data: 0.005 (0.008)
2024-04-07 12:13:38,663 - train - INFO - Train: 73 [ 500/781 ( 64%)]  Loss:  3.515964 (4.1012)  Time: 0.828s,  154.52/s  (0.917s,  139.64/s)  LR: 2.653e-04  Data: 0.004 (0.007)
2024-04-07 12:14:24,354 - train - INFO - Train: 73 [ 550/781 ( 71%)]  Loss:  4.664579 (4.1068)  Time: 0.838s,  152.73/s  (0.916s,  139.68/s)  LR: 2.653e-04  Data: 0.008 (0.007)
2024-04-07 12:15:11,181 - train - INFO - Train: 73 [ 600/781 ( 77%)]  Loss:  4.519177 (4.1131)  Time: 1.074s,  119.13/s  (0.918s,  139.42/s)  LR: 2.653e-04  Data: 0.009 (0.007)
2024-04-07 12:15:57,388 - train - INFO - Train: 73 [ 650/781 ( 83%)]  Loss:  4.514155 (4.1075)  Time: 1.038s,  123.30/s  (0.919s,  139.35/s)  LR: 2.653e-04  Data: 0.014 (0.007)
2024-04-07 12:16:42,995 - train - INFO - Train: 73 [ 700/781 ( 90%)]  Loss:  4.158080 (4.1054)  Time: 0.912s,  140.36/s  (0.918s,  139.42/s)  LR: 2.653e-04  Data: 0.010 (0.007)
2024-04-07 12:17:27,808 - train - INFO - Train: 73 [ 750/781 ( 96%)]  Loss:  3.957851 (4.1069)  Time: 0.819s,  156.33/s  (0.917s,  139.64/s)  LR: 2.653e-04  Data: 0.004 (0.007)
2024-04-07 12:17:56,061 - train - INFO - Train: 73 [ 780/781 (100%)]  Loss:  4.282149 (4.1038)  Time: 0.850s,  150.51/s  (0.918s,  139.50/s)  LR: 2.653e-04  Data: 0.000 (0.007)
2024-04-07 12:17:56,062 - train - INFO - True
2024-04-07 12:17:56,063 - train - INFO - alphas:tensor([0.0092, 0.0104, 0.0493, 0.3380, 0.5930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,078 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,078 - train - INFO - True
2024-04-07 12:17:56,079 - train - INFO - alphas:tensor([0.1034, 0.0199, 0.0412, 0.1454, 0.6900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,093 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,093 - train - INFO - True
2024-04-07 12:17:56,094 - train - INFO - alphas:tensor([0.4918, 0.0924, 0.0697, 0.1414, 0.2046], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,122 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,123 - train - INFO - True
2024-04-07 12:17:56,124 - train - INFO - alphas:tensor([0.4120, 0.0238, 0.0413, 0.1432, 0.3797], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,152 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,152 - train - INFO - True
2024-04-07 12:17:56,153 - train - INFO - alphas:tensor([0.2579, 0.0155, 0.0545, 0.1566, 0.5154], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,167 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,167 - train - INFO - True
2024-04-07 12:17:56,168 - train - INFO - alphas:tensor([0.3564, 0.0115, 0.0327, 0.1158, 0.4837], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,182 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,182 - train - INFO - True
2024-04-07 12:17:56,183 - train - INFO - alphas:tensor([0.4878, 0.0366, 0.0268, 0.1302, 0.3185], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,212 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,212 - train - INFO - True
2024-04-07 12:17:56,213 - train - INFO - alphas:tensor([0.3690, 0.0176, 0.0124, 0.1154, 0.4856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,227 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,227 - train - INFO - True
2024-04-07 12:17:56,228 - train - INFO - alphas:tensor([0.3162, 0.0126, 0.0367, 0.1291, 0.5055], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,242 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,242 - train - INFO - True
2024-04-07 12:17:56,243 - train - INFO - alphas:tensor([0.4201, 0.0096, 0.0309, 0.0942, 0.4451], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,257 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,257 - train - INFO - True
2024-04-07 12:17:56,258 - train - INFO - alphas:tensor([0.3972, 0.0204, 0.0215, 0.1244, 0.4366], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,273 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,273 - train - INFO - True
2024-04-07 12:17:56,274 - train - INFO - alphas:tensor([0.3038, 0.0084, 0.0110, 0.1296, 0.5471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,289 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,289 - train - INFO - True
2024-04-07 12:17:56,290 - train - INFO - alphas:tensor([0.3252, 0.0082, 0.0278, 0.1191, 0.5196], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,305 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,305 - train - INFO - True
2024-04-07 12:17:56,306 - train - INFO - alphas:tensor([0.4189, 0.0045, 0.0207, 0.0744, 0.4815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,320 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,320 - train - INFO - True
2024-04-07 12:17:56,321 - train - INFO - alphas:tensor([0.3094, 0.0228, 0.0170, 0.1319, 0.5189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,335 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,335 - train - INFO - True
2024-04-07 12:17:56,336 - train - INFO - alphas:tensor([0.2177, 0.0056, 0.0056, 0.1389, 0.6323], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,351 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,351 - train - INFO - True
2024-04-07 12:17:56,352 - train - INFO - alphas:tensor([0.3128, 0.0084, 0.0214, 0.1105, 0.5469], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,366 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,366 - train - INFO - True
2024-04-07 12:17:56,367 - train - INFO - alphas:tensor([0.4098, 0.0037, 0.0177, 0.0702, 0.4986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,381 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,381 - train - INFO - True
2024-04-07 12:17:56,382 - train - INFO - alphas:tensor([0.3205, 0.0082, 0.0095, 0.1208, 0.5410], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,396 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,397 - train - INFO - True
2024-04-07 12:17:56,398 - train - INFO - alphas:tensor([0.2205, 0.0038, 0.0040, 0.1173, 0.6545], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,412 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,412 - train - INFO - True
2024-04-07 12:17:56,413 - train - INFO - alphas:tensor([0.2645, 0.0051, 0.0194, 0.1099, 0.6011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,427 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,427 - train - INFO - True
2024-04-07 12:17:56,428 - train - INFO - alphas:tensor([0.3874, 0.0029, 0.0152, 0.0606, 0.5339], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,442 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,443 - train - INFO - True
2024-04-07 12:17:56,443 - train - INFO - alphas:tensor([0.3647, 0.0115, 0.0086, 0.0930, 0.5222], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,461 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,461 - train - INFO - True
2024-04-07 12:17:56,462 - train - INFO - alphas:tensor([0.2617, 0.0029, 0.0026, 0.0845, 0.6483], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,476 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,476 - train - INFO - True
2024-04-07 12:17:56,477 - train - INFO - alphas:tensor([0.2572, 0.0041, 0.0164, 0.0986, 0.6237], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,492 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,492 - train - INFO - True
2024-04-07 12:17:56,493 - train - INFO - alphas:tensor([0.3758, 0.0029, 0.0147, 0.0507, 0.5559], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,507 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,507 - train - INFO - True
2024-04-07 12:17:56,508 - train - INFO - alphas:tensor([0.4039, 0.0042, 0.0066, 0.0834, 0.5018], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,522 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,522 - train - INFO - True
2024-04-07 12:17:56,523 - train - INFO - alphas:tensor([0.2937, 0.0030, 0.0021, 0.0697, 0.6315], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,538 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,538 - train - INFO - True
2024-04-07 12:17:56,539 - train - INFO - alphas:tensor([0.2344, 0.0033, 0.0153, 0.1000, 0.6470], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,553 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,553 - train - INFO - True
2024-04-07 12:17:56,554 - train - INFO - alphas:tensor([0.3456, 0.0017, 0.0108, 0.0558, 0.5862], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,568 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,568 - train - INFO - True
2024-04-07 12:17:56,569 - train - INFO - alphas:tensor([0.4373, 0.0041, 0.0058, 0.0719, 0.4809], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,583 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,584 - train - INFO - True
2024-04-07 12:17:56,584 - train - INFO - alphas:tensor([0.3381, 0.0018, 0.0028, 0.0745, 0.5828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,599 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,599 - train - INFO - True
2024-04-07 12:17:56,600 - train - INFO - alphas:tensor([0.2162, 0.0029, 0.0136, 0.0870, 0.6803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,614 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,614 - train - INFO - True
2024-04-07 12:17:56,615 - train - INFO - alphas:tensor([0.3116, 0.0011, 0.0078, 0.0431, 0.6364], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,629 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,629 - train - INFO - True
2024-04-07 12:17:56,630 - train - INFO - alphas:tensor([0.4259, 0.0060, 0.0063, 0.0787, 0.4830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,644 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,645 - train - INFO - True
2024-04-07 12:17:56,646 - train - INFO - alphas:tensor([0.3537, 0.0017, 0.0033, 0.0752, 0.5661], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,660 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,660 - train - INFO - True
2024-04-07 12:17:56,661 - train - INFO - alphas:tensor([0.6304, 0.0346, 0.1075, 0.2275], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:17:56,689 - train - INFO - tau:0.4898902730042049
2024-04-07 12:17:56,689 - train - INFO - avg block size:14.378378378378379
2024-04-07 12:17:56,689 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 12:17:56,947 - train - INFO - Test: [   0/78]  Time: 0.253 (0.253)  Loss:  0.8701 (0.8701)  Acc@1: 83.5938 (83.5938)  Acc@5: 93.7500 (93.7500)
2024-04-07 12:18:01,513 - train - INFO - Test: [  50/78]  Time: 0.090 (0.094)  Loss:  1.9473 (1.6949)  Acc@1: 57.0312 (60.1716)  Acc@5: 79.6875 (83.2261)
2024-04-07 12:18:04,052 - train - INFO - Test: [  78/78]  Time: 0.060 (0.093)  Loss:  1.7158 (1.7229)  Acc@1: 62.5000 (59.7200)  Acc@5: 93.7500 (82.7100)
2024-04-07 12:18:05,384 - train - INFO - Train: 74 [   0/781 (  0%)]  Loss:  4.365859 (4.3659)  Time: 1.264s,  101.25/s  (1.264s,  101.25/s)  LR: 2.601e-04  Data: 0.202 (0.202)
2024-04-07 12:18:51,374 - train - INFO - Train: 74 [  50/781 (  6%)]  Loss:  3.661744 (4.1527)  Time: 1.091s,  117.34/s  (0.927s,  138.15/s)  LR: 2.601e-04  Data: 0.008 (0.011)
2024-04-07 12:19:36,855 - train - INFO - Train: 74 [ 100/781 ( 13%)]  Loss:  3.819564 (4.1036)  Time: 0.822s,  155.78/s  (0.918s,  139.41/s)  LR: 2.601e-04  Data: 0.004 (0.009)
2024-04-07 12:20:22,942 - train - INFO - Train: 74 [ 150/781 ( 19%)]  Loss:  4.639955 (4.1255)  Time: 0.858s,  149.16/s  (0.919s,  139.23/s)  LR: 2.601e-04  Data: 0.007 (0.008)
2024-04-07 12:21:07,631 - train - INFO - Train: 74 [ 200/781 ( 26%)]  Loss:  3.915299 (4.1222)  Time: 0.852s,  150.19/s  (0.913s,  140.20/s)  LR: 2.601e-04  Data: 0.009 (0.008)
2024-04-07 12:21:53,095 - train - INFO - Train: 74 [ 250/781 ( 32%)]  Loss:  4.298280 (4.1278)  Time: 0.851s,  150.35/s  (0.912s,  140.32/s)  LR: 2.601e-04  Data: 0.007 (0.008)
2024-04-07 12:22:38,105 - train - INFO - Train: 74 [ 300/781 ( 38%)]  Loss:  3.506736 (4.1167)  Time: 0.863s,  148.29/s  (0.910s,  140.63/s)  LR: 2.601e-04  Data: 0.011 (0.008)
2024-04-07 12:23:26,256 - train - INFO - Train: 74 [ 350/781 ( 45%)]  Loss:  4.224195 (4.1177)  Time: 0.849s,  150.70/s  (0.918s,  139.47/s)  LR: 2.601e-04  Data: 0.006 (0.007)
2024-04-07 12:24:12,460 - train - INFO - Train: 74 [ 400/781 ( 51%)]  Loss:  4.595115 (4.1136)  Time: 1.017s,  125.83/s  (0.919s,  139.35/s)  LR: 2.601e-04  Data: 0.007 (0.007)
2024-04-07 12:24:58,514 - train - INFO - Train: 74 [ 450/781 ( 58%)]  Loss:  3.827670 (4.1032)  Time: 1.214s,  105.44/s  (0.919s,  139.31/s)  LR: 2.601e-04  Data: 0.007 (0.007)
2024-04-07 12:25:45,749 - train - INFO - Train: 74 [ 500/781 ( 64%)]  Loss:  3.457222 (4.0943)  Time: 0.874s,  146.46/s  (0.921s,  138.92/s)  LR: 2.601e-04  Data: 0.010 (0.008)
2024-04-07 12:26:31,551 - train - INFO - Train: 74 [ 550/781 ( 71%)]  Loss:  4.521927 (4.0976)  Time: 0.849s,  150.77/s  (0.921s,  139.00/s)  LR: 2.601e-04  Data: 0.008 (0.008)
2024-04-07 12:27:18,149 - train - INFO - Train: 74 [ 600/781 ( 77%)]  Loss:  3.937409 (4.0944)  Time: 0.837s,  152.97/s  (0.922s,  138.86/s)  LR: 2.601e-04  Data: 0.007 (0.008)
2024-04-07 12:28:05,810 - train - INFO - Train: 74 [ 650/781 ( 83%)]  Loss:  4.237347 (4.0959)  Time: 1.088s,  117.62/s  (0.924s,  138.50/s)  LR: 2.601e-04  Data: 0.010 (0.008)
2024-04-07 12:28:54,172 - train - INFO - Train: 74 [ 700/781 ( 90%)]  Loss:  3.709293 (4.0952)  Time: 0.877s,  145.93/s  (0.927s,  138.04/s)  LR: 2.601e-04  Data: 0.011 (0.008)
2024-04-07 12:29:41,931 - train - INFO - Train: 74 [ 750/781 ( 96%)]  Loss:  3.387417 (4.1017)  Time: 1.007s,  127.09/s  (0.929s,  137.76/s)  LR: 2.601e-04  Data: 0.012 (0.008)
2024-04-07 12:30:10,179 - train - INFO - Train: 74 [ 780/781 (100%)]  Loss:  4.695622 (4.1015)  Time: 0.833s,  153.64/s  (0.930s,  137.69/s)  LR: 2.601e-04  Data: 0.000 (0.008)
2024-04-07 12:30:10,181 - train - INFO - True
2024-04-07 12:30:10,183 - train - INFO - alphas:tensor([0.0083, 0.0096, 0.0475, 0.3367, 0.5978], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,219 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,221 - train - INFO - True
2024-04-07 12:30:10,223 - train - INFO - alphas:tensor([0.1029, 0.0196, 0.0407, 0.1452, 0.6916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,247 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,247 - train - INFO - True
2024-04-07 12:30:10,248 - train - INFO - alphas:tensor([0.4889, 0.0922, 0.0690, 0.1423, 0.2075], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,286 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,286 - train - INFO - True
2024-04-07 12:30:10,287 - train - INFO - alphas:tensor([0.4102, 0.0231, 0.0403, 0.1424, 0.3840], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,318 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,319 - train - INFO - True
2024-04-07 12:30:10,320 - train - INFO - alphas:tensor([0.2562, 0.0150, 0.0536, 0.1552, 0.5200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,334 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,334 - train - INFO - True
2024-04-07 12:30:10,335 - train - INFO - alphas:tensor([0.3568, 0.0110, 0.0317, 0.1139, 0.4866], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,349 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,349 - train - INFO - True
2024-04-07 12:30:10,350 - train - INFO - alphas:tensor([0.4878, 0.0354, 0.0259, 0.1291, 0.3217], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,378 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,378 - train - INFO - True
2024-04-07 12:30:10,379 - train - INFO - alphas:tensor([0.3695, 0.0170, 0.0116, 0.1141, 0.4878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,394 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,394 - train - INFO - True
2024-04-07 12:30:10,395 - train - INFO - alphas:tensor([0.3150, 0.0121, 0.0357, 0.1272, 0.5099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,409 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,409 - train - INFO - True
2024-04-07 12:30:10,410 - train - INFO - alphas:tensor([0.4188, 0.0091, 0.0297, 0.0922, 0.4502], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,424 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,424 - train - INFO - True
2024-04-07 12:30:10,425 - train - INFO - alphas:tensor([0.3970, 0.0198, 0.0206, 0.1230, 0.4396], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,440 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,440 - train - INFO - True
2024-04-07 12:30:10,441 - train - INFO - alphas:tensor([0.3035, 0.0082, 0.0105, 0.1284, 0.5493], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,455 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,455 - train - INFO - True
2024-04-07 12:30:10,456 - train - INFO - alphas:tensor([0.3236, 0.0078, 0.0269, 0.1170, 0.5247], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,470 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,470 - train - INFO - True
2024-04-07 12:30:10,471 - train - INFO - alphas:tensor([0.4196, 0.0042, 0.0199, 0.0722, 0.4842], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,486 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,486 - train - INFO - True
2024-04-07 12:30:10,487 - train - INFO - alphas:tensor([0.3103, 0.0224, 0.0162, 0.1310, 0.5200], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,501 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,501 - train - INFO - True
2024-04-07 12:30:10,502 - train - INFO - alphas:tensor([0.2174, 0.0053, 0.0052, 0.1382, 0.6338], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,516 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,516 - train - INFO - True
2024-04-07 12:30:10,517 - train - INFO - alphas:tensor([0.3114, 0.0081, 0.0204, 0.1082, 0.5519], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,531 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,532 - train - INFO - True
2024-04-07 12:30:10,532 - train - INFO - alphas:tensor([0.4096, 0.0035, 0.0170, 0.0684, 0.5015], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,547 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,547 - train - INFO - True
2024-04-07 12:30:10,548 - train - INFO - alphas:tensor([0.3149, 0.0077, 0.0089, 0.1203, 0.5482], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,562 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,562 - train - INFO - True
2024-04-07 12:30:10,563 - train - INFO - alphas:tensor([0.2206, 0.0036, 0.0037, 0.1174, 0.6547], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,577 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,577 - train - INFO - True
2024-04-07 12:30:10,578 - train - INFO - alphas:tensor([0.2646, 0.0049, 0.0187, 0.1078, 0.6041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,593 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,593 - train - INFO - True
2024-04-07 12:30:10,594 - train - INFO - alphas:tensor([0.3856, 0.0027, 0.0144, 0.0584, 0.5389], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,608 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,608 - train - INFO - True
2024-04-07 12:30:10,609 - train - INFO - alphas:tensor([0.3641, 0.0111, 0.0081, 0.0923, 0.5244], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,623 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,623 - train - INFO - True
2024-04-07 12:30:10,624 - train - INFO - alphas:tensor([0.2624, 0.0027, 0.0024, 0.0838, 0.6487], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,639 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,639 - train - INFO - True
2024-04-07 12:30:10,640 - train - INFO - alphas:tensor([0.2572, 0.0039, 0.0159, 0.0965, 0.6265], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,654 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,654 - train - INFO - True
2024-04-07 12:30:10,655 - train - INFO - alphas:tensor([0.3792, 0.0027, 0.0141, 0.0490, 0.5550], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,669 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,669 - train - INFO - True
2024-04-07 12:30:10,670 - train - INFO - alphas:tensor([0.4015, 0.0039, 0.0061, 0.0819, 0.5065], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,684 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,685 - train - INFO - True
2024-04-07 12:30:10,686 - train - INFO - alphas:tensor([0.2932, 0.0028, 0.0020, 0.0684, 0.6337], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,700 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,700 - train - INFO - True
2024-04-07 12:30:10,701 - train - INFO - alphas:tensor([0.2342, 0.0032, 0.0148, 0.0975, 0.6504], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,715 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,715 - train - INFO - True
2024-04-07 12:30:10,716 - train - INFO - alphas:tensor([0.3451, 0.0015, 0.0100, 0.0530, 0.5904], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,730 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,730 - train - INFO - True
2024-04-07 12:30:10,731 - train - INFO - alphas:tensor([0.4354, 0.0038, 0.0054, 0.0700, 0.4855], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,746 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,746 - train - INFO - True
2024-04-07 12:30:10,747 - train - INFO - alphas:tensor([0.3357, 0.0016, 0.0026, 0.0736, 0.5864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,761 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,761 - train - INFO - True
2024-04-07 12:30:10,762 - train - INFO - alphas:tensor([0.2152, 0.0027, 0.0130, 0.0849, 0.6841], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,776 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,776 - train - INFO - True
2024-04-07 12:30:10,777 - train - INFO - alphas:tensor([0.3126, 0.0010, 0.0073, 0.0414, 0.6377], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,792 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,792 - train - INFO - True
2024-04-07 12:30:10,793 - train - INFO - alphas:tensor([0.4239, 0.0055, 0.0059, 0.0770, 0.4877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,807 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,807 - train - INFO - True
2024-04-07 12:30:10,808 - train - INFO - alphas:tensor([0.3537, 0.0015, 0.0031, 0.0733, 0.5683], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,822 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,822 - train - INFO - True
2024-04-07 12:30:10,823 - train - INFO - alphas:tensor([0.6292, 0.0337, 0.1071, 0.2299], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:30:10,851 - train - INFO - tau:0.48499137027416284
2024-04-07 12:30:10,852 - train - INFO - avg block size:14.378378378378379
2024-04-07 12:30:10,852 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 12:30:10,852 - train - INFO - lasso_alpha:0.0001310999419149996
2024-04-07 12:30:11,115 - train - INFO - Test: [   0/78]  Time: 0.260 (0.260)  Loss:  0.9697 (0.9697)  Acc@1: 75.7812 (75.7812)  Acc@5: 93.7500 (93.7500)
2024-04-07 12:30:16,167 - train - INFO - Test: [  50/78]  Time: 0.106 (0.104)  Loss:  1.8867 (1.6845)  Acc@1: 56.2500 (60.2635)  Acc@5: 81.2500 (83.7623)
2024-04-07 12:30:18,694 - train - INFO - Test: [  78/78]  Time: 0.076 (0.099)  Loss:  1.8564 (1.7098)  Acc@1: 56.2500 (59.8600)  Acc@5: 93.7500 (83.0900)
2024-04-07 12:30:20,083 - train - INFO - Train: 75 [   0/781 (  0%)]  Loss:  4.713219 (4.7132)  Time: 1.293s,   99.01/s  (1.293s,   99.01/s)  LR: 2.550e-04  Data: 0.198 (0.198)
2024-04-07 12:31:06,080 - train - INFO - Train: 75 [  50/781 (  6%)]  Loss:  3.658607 (4.0311)  Time: 0.846s,  151.38/s  (0.927s,  138.05/s)  LR: 2.550e-04  Data: 0.009 (0.012)
2024-04-07 12:31:52,641 - train - INFO - Train: 75 [ 100/781 ( 13%)]  Loss:  3.318498 (4.0326)  Time: 0.831s,  153.97/s  (0.929s,  137.76/s)  LR: 2.550e-04  Data: 0.008 (0.011)
2024-04-07 12:32:36,446 - train - INFO - Train: 75 [ 150/781 ( 19%)]  Loss:  3.537204 (4.0429)  Time: 0.841s,  152.12/s  (0.912s,  140.41/s)  LR: 2.550e-04  Data: 0.009 (0.010)
2024-04-07 12:33:22,423 - train - INFO - Train: 75 [ 200/781 ( 26%)]  Loss:  4.524201 (4.0533)  Time: 1.033s,  123.94/s  (0.914s,  140.11/s)  LR: 2.550e-04  Data: 0.005 (0.009)
2024-04-07 12:34:07,109 - train - INFO - Train: 75 [ 250/781 ( 32%)]  Loss:  3.684806 (4.0367)  Time: 0.840s,  152.37/s  (0.910s,  140.72/s)  LR: 2.550e-04  Data: 0.008 (0.009)
2024-04-07 12:34:53,281 - train - INFO - Train: 75 [ 300/781 ( 38%)]  Loss:  4.474009 (4.0477)  Time: 0.843s,  151.87/s  (0.912s,  140.37/s)  LR: 2.550e-04  Data: 0.006 (0.009)
2024-04-07 12:35:37,581 - train - INFO - Train: 75 [ 350/781 ( 45%)]  Loss:  4.034216 (4.0543)  Time: 1.049s,  121.99/s  (0.908s,  140.94/s)  LR: 2.550e-04  Data: 0.008 (0.009)
2024-04-07 12:36:22,460 - train - INFO - Train: 75 [ 400/781 ( 51%)]  Loss:  4.187157 (4.0503)  Time: 0.839s,  152.65/s  (0.907s,  141.14/s)  LR: 2.550e-04  Data: 0.008 (0.009)
2024-04-07 12:37:06,800 - train - INFO - Train: 75 [ 450/781 ( 58%)]  Loss:  3.456212 (4.0544)  Time: 0.845s,  151.49/s  (0.905s,  141.49/s)  LR: 2.550e-04  Data: 0.008 (0.009)
2024-04-07 12:37:50,447 - train - INFO - Train: 75 [ 500/781 ( 64%)]  Loss:  3.785954 (4.0520)  Time: 0.752s,  170.22/s  (0.901s,  141.99/s)  LR: 2.550e-04  Data: 0.005 (0.009)
2024-04-07 12:38:35,616 - train - INFO - Train: 75 [ 550/781 ( 71%)]  Loss:  4.658111 (4.0476)  Time: 0.754s,  169.74/s  (0.902s,  141.96/s)  LR: 2.550e-04  Data: 0.005 (0.009)
2024-04-07 12:39:20,029 - train - INFO - Train: 75 [ 600/781 ( 77%)]  Loss:  3.338305 (4.0428)  Time: 0.882s,  145.11/s  (0.901s,  142.14/s)  LR: 2.550e-04  Data: 0.007 (0.009)
2024-04-07 12:40:03,453 - train - INFO - Train: 75 [ 650/781 ( 83%)]  Loss:  4.335189 (4.0444)  Time: 0.799s,  160.29/s  (0.898s,  142.53/s)  LR: 2.550e-04  Data: 0.005 (0.009)
2024-04-07 12:40:47,148 - train - INFO - Train: 75 [ 700/781 ( 90%)]  Loss:  4.318974 (4.0495)  Time: 1.076s,  118.98/s  (0.896s,  142.80/s)  LR: 2.550e-04  Data: 0.007 (0.008)
2024-04-07 12:41:30,025 - train - INFO - Train: 75 [ 750/781 ( 96%)]  Loss:  4.516657 (4.0537)  Time: 0.845s,  151.49/s  (0.894s,  143.22/s)  LR: 2.550e-04  Data: 0.009 (0.008)
2024-04-07 12:41:57,167 - train - INFO - Train: 75 [ 780/781 (100%)]  Loss:  4.538313 (4.0555)  Time: 0.816s,  156.82/s  (0.894s,  143.15/s)  LR: 2.550e-04  Data: 0.000 (0.008)
2024-04-07 12:41:57,168 - train - INFO - True
2024-04-07 12:41:57,171 - train - INFO - alphas:tensor([0.0076, 0.0089, 0.0460, 0.3384, 0.5992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,207 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,207 - train - INFO - True
2024-04-07 12:41:57,209 - train - INFO - alphas:tensor([0.1029, 0.0193, 0.0402, 0.1438, 0.6938], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,228 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,228 - train - INFO - True
2024-04-07 12:41:57,229 - train - INFO - alphas:tensor([0.4905, 0.0907, 0.0679, 0.1421, 0.2088], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,261 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,261 - train - INFO - True
2024-04-07 12:41:57,262 - train - INFO - alphas:tensor([0.4128, 0.0223, 0.0389, 0.1403, 0.3856], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,291 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,291 - train - INFO - True
2024-04-07 12:41:57,292 - train - INFO - alphas:tensor([0.2564, 0.0146, 0.0523, 0.1533, 0.5234], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,305 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,305 - train - INFO - True
2024-04-07 12:41:57,306 - train - INFO - alphas:tensor([0.3567, 0.0105, 0.0309, 0.1122, 0.4897], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,318 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,318 - train - INFO - True
2024-04-07 12:41:57,319 - train - INFO - alphas:tensor([0.4892, 0.0347, 0.0249, 0.1277, 0.3234], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,342 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,342 - train - INFO - True
2024-04-07 12:41:57,343 - train - INFO - alphas:tensor([0.3736, 0.0166, 0.0110, 0.1121, 0.4867], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,354 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,354 - train - INFO - True
2024-04-07 12:41:57,354 - train - INFO - alphas:tensor([0.3144, 0.0116, 0.0347, 0.1256, 0.5136], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,365 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,365 - train - INFO - True
2024-04-07 12:41:57,366 - train - INFO - alphas:tensor([0.4180, 0.0085, 0.0288, 0.0907, 0.4540], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,376 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,376 - train - INFO - True
2024-04-07 12:41:57,377 - train - INFO - alphas:tensor([0.3975, 0.0193, 0.0199, 0.1218, 0.4415], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,386 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,387 - train - INFO - True
2024-04-07 12:41:57,387 - train - INFO - alphas:tensor([0.3047, 0.0079, 0.0100, 0.1274, 0.5500], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,397 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,397 - train - INFO - True
2024-04-07 12:41:57,398 - train - INFO - alphas:tensor([0.3236, 0.0075, 0.0261, 0.1148, 0.5280], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,407 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,407 - train - INFO - True
2024-04-07 12:41:57,408 - train - INFO - alphas:tensor([0.4166, 0.0039, 0.0191, 0.0708, 0.4897], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,419 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,419 - train - INFO - True
2024-04-07 12:41:57,419 - train - INFO - alphas:tensor([0.3132, 0.0220, 0.0155, 0.1302, 0.5192], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,430 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,430 - train - INFO - True
2024-04-07 12:41:57,431 - train - INFO - alphas:tensor([0.2204, 0.0051, 0.0049, 0.1379, 0.6316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,441 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,441 - train - INFO - True
2024-04-07 12:41:57,442 - train - INFO - alphas:tensor([0.3099, 0.0078, 0.0198, 0.1068, 0.5557], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,451 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,452 - train - INFO - True
2024-04-07 12:41:57,452 - train - INFO - alphas:tensor([0.4110, 0.0032, 0.0161, 0.0656, 0.5041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,462 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,462 - train - INFO - True
2024-04-07 12:41:57,462 - train - INFO - alphas:tensor([0.3200, 0.0073, 0.0083, 0.1174, 0.5469], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,472 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,472 - train - INFO - True
2024-04-07 12:41:57,472 - train - INFO - alphas:tensor([0.2246, 0.0034, 0.0035, 0.1170, 0.6515], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,481 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,481 - train - INFO - True
2024-04-07 12:41:57,482 - train - INFO - alphas:tensor([0.2643, 0.0047, 0.0178, 0.1055, 0.6077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,491 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,491 - train - INFO - True
2024-04-07 12:41:57,491 - train - INFO - alphas:tensor([0.3856, 0.0025, 0.0139, 0.0568, 0.5412], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,500 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,500 - train - INFO - True
2024-04-07 12:41:57,501 - train - INFO - alphas:tensor([0.3698, 0.0108, 0.0075, 0.0900, 0.5219], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,509 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,509 - train - INFO - True
2024-04-07 12:41:57,510 - train - INFO - alphas:tensor([0.2667, 0.0026, 0.0022, 0.0828, 0.6457], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,518 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,518 - train - INFO - True
2024-04-07 12:41:57,519 - train - INFO - alphas:tensor([0.2546, 0.0037, 0.0152, 0.0945, 0.6320], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,527 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,528 - train - INFO - True
2024-04-07 12:41:57,528 - train - INFO - alphas:tensor([0.3765, 0.0025, 0.0133, 0.0473, 0.5604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,537 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,537 - train - INFO - True
2024-04-07 12:41:57,537 - train - INFO - alphas:tensor([0.4056, 0.0037, 0.0057, 0.0798, 0.5052], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,547 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,547 - train - INFO - True
2024-04-07 12:41:57,548 - train - INFO - alphas:tensor([0.2968, 0.0027, 0.0018, 0.0662, 0.6326], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,559 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,559 - train - INFO - True
2024-04-07 12:41:57,560 - train - INFO - alphas:tensor([0.2334, 0.0030, 0.0141, 0.0949, 0.6546], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,570 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,570 - train - INFO - True
2024-04-07 12:41:57,571 - train - INFO - alphas:tensor([0.3473, 0.0014, 0.0097, 0.0513, 0.5903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,581 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,581 - train - INFO - True
2024-04-07 12:41:57,582 - train - INFO - alphas:tensor([0.4408, 0.0035, 0.0049, 0.0680, 0.4827], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,592 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,592 - train - INFO - True
2024-04-07 12:41:57,593 - train - INFO - alphas:tensor([0.3411, 0.0015, 0.0024, 0.0722, 0.5828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,602 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,602 - train - INFO - True
2024-04-07 12:41:57,603 - train - INFO - alphas:tensor([0.2149, 0.0026, 0.0125, 0.0829, 0.6870], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,612 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,612 - train - INFO - True
2024-04-07 12:41:57,613 - train - INFO - alphas:tensor([0.3113, 0.0009, 0.0069, 0.0399, 0.6411], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,623 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,624 - train - INFO - True
2024-04-07 12:41:57,624 - train - INFO - alphas:tensor([0.4266, 0.0052, 0.0055, 0.0751, 0.4876], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,633 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,633 - train - INFO - True
2024-04-07 12:41:57,634 - train - INFO - alphas:tensor([0.3572, 0.0014, 0.0028, 0.0712, 0.5674], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,643 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,643 - train - INFO - True
2024-04-07 12:41:57,643 - train - INFO - alphas:tensor([0.6291, 0.0328, 0.1065, 0.2316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:41:57,660 - train - INFO - tau:0.4801414565714212
2024-04-07 12:41:57,660 - train - INFO - avg block size:14.378378378378379
2024-04-07 12:41:57,660 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 12:41:57,914 - train - INFO - Test: [   0/78]  Time: 0.251 (0.251)  Loss:  0.9214 (0.9214)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 12:42:02,672 - train - INFO - Test: [  50/78]  Time: 0.107 (0.098)  Loss:  1.8096 (1.6658)  Acc@1: 57.0312 (60.0490)  Acc@5: 84.3750 (83.4865)
2024-04-07 12:42:05,379 - train - INFO - Test: [  78/78]  Time: 0.058 (0.098)  Loss:  1.7070 (1.6962)  Acc@1: 56.2500 (59.4700)  Acc@5: 87.5000 (83.0200)
2024-04-07 12:42:06,812 - train - INFO - Train: 76 [   0/781 (  0%)]  Loss:  3.413051 (3.4131)  Time: 1.283s,   99.74/s  (1.283s,   99.74/s)  LR: 2.499e-04  Data: 0.198 (0.198)
2024-04-07 12:42:50,690 - train - INFO - Train: 76 [  50/781 (  6%)]  Loss:  4.607810 (4.0379)  Time: 0.854s,  149.82/s  (0.885s,  144.55/s)  LR: 2.499e-04  Data: 0.007 (0.012)
2024-04-07 12:43:35,703 - train - INFO - Train: 76 [ 100/781 ( 13%)]  Loss:  4.420535 (4.0631)  Time: 0.853s,  150.02/s  (0.893s,  143.37/s)  LR: 2.499e-04  Data: 0.009 (0.010)
2024-04-07 12:44:20,603 - train - INFO - Train: 76 [ 150/781 ( 19%)]  Loss:  4.464041 (4.0348)  Time: 0.835s,  153.35/s  (0.894s,  143.10/s)  LR: 2.499e-04  Data: 0.008 (0.009)
2024-04-07 12:45:05,803 - train - INFO - Train: 76 [ 200/781 ( 26%)]  Loss:  4.454839 (4.0481)  Time: 0.887s,  144.33/s  (0.897s,  142.72/s)  LR: 2.499e-04  Data: 0.009 (0.009)
2024-04-07 12:45:51,300 - train - INFO - Train: 76 [ 250/781 ( 32%)]  Loss:  3.905344 (4.0465)  Time: 0.844s,  151.57/s  (0.899s,  142.31/s)  LR: 2.499e-04  Data: 0.009 (0.009)
2024-04-07 12:46:36,025 - train - INFO - Train: 76 [ 300/781 ( 38%)]  Loss:  4.553129 (4.0684)  Time: 0.873s,  146.54/s  (0.899s,  142.44/s)  LR: 2.499e-04  Data: 0.008 (0.009)
2024-04-07 12:47:20,135 - train - INFO - Train: 76 [ 350/781 ( 45%)]  Loss:  3.698464 (4.0788)  Time: 0.844s,  151.58/s  (0.896s,  142.81/s)  LR: 2.499e-04  Data: 0.008 (0.009)
2024-04-07 12:48:03,809 - train - INFO - Train: 76 [ 400/781 ( 51%)]  Loss:  4.162298 (4.0910)  Time: 0.816s,  156.80/s  (0.893s,  143.27/s)  LR: 2.499e-04  Data: 0.006 (0.008)
2024-04-07 12:48:46,804 - train - INFO - Train: 76 [ 450/781 ( 58%)]  Loss:  4.265109 (4.0905)  Time: 0.839s,  152.58/s  (0.890s,  143.87/s)  LR: 2.499e-04  Data: 0.007 (0.008)
2024-04-07 12:49:31,443 - train - INFO - Train: 76 [ 500/781 ( 64%)]  Loss:  3.494559 (4.0805)  Time: 0.851s,  150.47/s  (0.890s,  143.82/s)  LR: 2.499e-04  Data: 0.008 (0.008)
2024-04-07 12:50:15,004 - train - INFO - Train: 76 [ 550/781 ( 71%)]  Loss:  4.336063 (4.0777)  Time: 0.832s,  153.79/s  (0.888s,  144.09/s)  LR: 2.499e-04  Data: 0.006 (0.008)
2024-04-07 12:50:59,180 - train - INFO - Train: 76 [ 600/781 ( 77%)]  Loss:  3.454001 (4.0810)  Time: 0.998s,  128.19/s  (0.888s,  144.16/s)  LR: 2.499e-04  Data: 0.005 (0.008)
2024-04-07 12:51:43,856 - train - INFO - Train: 76 [ 650/781 ( 83%)]  Loss:  4.238233 (4.0827)  Time: 1.067s,  119.93/s  (0.888s,  144.09/s)  LR: 2.499e-04  Data: 0.007 (0.008)
2024-04-07 12:52:26,990 - train - INFO - Train: 76 [ 700/781 ( 90%)]  Loss:  4.464903 (4.0829)  Time: 0.811s,  157.75/s  (0.887s,  144.39/s)  LR: 2.499e-04  Data: 0.006 (0.008)
2024-04-07 12:53:12,189 - train - INFO - Train: 76 [ 750/781 ( 96%)]  Loss:  4.631389 (4.0807)  Time: 0.857s,  149.35/s  (0.888s,  144.20/s)  LR: 2.499e-04  Data: 0.008 (0.008)
2024-04-07 12:53:38,090 - train - INFO - Train: 76 [ 780/781 (100%)]  Loss:  4.089299 (4.0803)  Time: 0.846s,  151.25/s  (0.887s,  144.35/s)  LR: 2.499e-04  Data: 0.000 (0.008)
2024-04-07 12:53:38,090 - train - INFO - True
2024-04-07 12:53:38,092 - train - INFO - alphas:tensor([0.0068, 0.0082, 0.0443, 0.3381, 0.6025], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,115 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,115 - train - INFO - True
2024-04-07 12:53:38,117 - train - INFO - alphas:tensor([0.1032, 0.0191, 0.0400, 0.1427, 0.6950], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,136 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,136 - train - INFO - True
2024-04-07 12:53:38,137 - train - INFO - alphas:tensor([0.4896, 0.0895, 0.0671, 0.1424, 0.2113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,171 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,171 - train - INFO - True
2024-04-07 12:53:38,172 - train - INFO - alphas:tensor([0.4119, 0.0215, 0.0379, 0.1393, 0.3894], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,201 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,201 - train - INFO - True
2024-04-07 12:53:38,202 - train - INFO - alphas:tensor([0.2560, 0.0142, 0.0513, 0.1513, 0.5273], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,215 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,215 - train - INFO - True
2024-04-07 12:53:38,216 - train - INFO - alphas:tensor([0.3565, 0.0100, 0.0301, 0.1100, 0.4934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,228 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,229 - train - INFO - True
2024-04-07 12:53:38,229 - train - INFO - alphas:tensor([0.4901, 0.0340, 0.0240, 0.1264, 0.3256], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,253 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,253 - train - INFO - True
2024-04-07 12:53:38,253 - train - INFO - alphas:tensor([0.3745, 0.0161, 0.0104, 0.1106, 0.4884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,264 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,264 - train - INFO - True
2024-04-07 12:53:38,265 - train - INFO - alphas:tensor([0.3140, 0.0112, 0.0341, 0.1240, 0.5168], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,276 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,276 - train - INFO - True
2024-04-07 12:53:38,277 - train - INFO - alphas:tensor([0.4183, 0.0081, 0.0277, 0.0888, 0.4570], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,287 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,287 - train - INFO - True
2024-04-07 12:53:38,288 - train - INFO - alphas:tensor([0.3992, 0.0189, 0.0191, 0.1204, 0.4424], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,298 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,298 - train - INFO - True
2024-04-07 12:53:38,298 - train - INFO - alphas:tensor([0.3072, 0.0077, 0.0095, 0.1260, 0.5496], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,308 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,308 - train - INFO - True
2024-04-07 12:53:38,309 - train - INFO - alphas:tensor([0.3231, 0.0072, 0.0250, 0.1127, 0.5320], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,318 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,318 - train - INFO - True
2024-04-07 12:53:38,319 - train - INFO - alphas:tensor([0.4155, 0.0036, 0.0184, 0.0691, 0.4934], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,328 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,328 - train - INFO - True
2024-04-07 12:53:38,329 - train - INFO - alphas:tensor([0.3103, 0.0215, 0.0150, 0.1302, 0.5231], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,338 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,338 - train - INFO - True
2024-04-07 12:53:38,338 - train - INFO - alphas:tensor([0.2196, 0.0049, 0.0046, 0.1378, 0.6331], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,347 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,347 - train - INFO - True
2024-04-07 12:53:38,348 - train - INFO - alphas:tensor([0.3089, 0.0074, 0.0191, 0.1049, 0.5596], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,356 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,356 - train - INFO - True
2024-04-07 12:53:38,357 - train - INFO - alphas:tensor([0.4113, 0.0030, 0.0153, 0.0642, 0.5062], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,365 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,365 - train - INFO - True
2024-04-07 12:53:38,366 - train - INFO - alphas:tensor([0.3231, 0.0071, 0.0078, 0.1160, 0.5461], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,375 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,375 - train - INFO - True
2024-04-07 12:53:38,376 - train - INFO - alphas:tensor([0.2263, 0.0033, 0.0032, 0.1165, 0.6507], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,387 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,387 - train - INFO - True
2024-04-07 12:53:38,387 - train - INFO - alphas:tensor([0.2629, 0.0044, 0.0172, 0.1034, 0.6121], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,398 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,398 - train - INFO - True
2024-04-07 12:53:38,399 - train - INFO - alphas:tensor([0.3856, 0.0024, 0.0133, 0.0553, 0.5435], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,409 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,409 - train - INFO - True
2024-04-07 12:53:38,410 - train - INFO - alphas:tensor([0.3700, 0.0104, 0.0071, 0.0886, 0.5240], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,420 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,420 - train - INFO - True
2024-04-07 12:53:38,420 - train - INFO - alphas:tensor([0.2683, 0.0025, 0.0020, 0.0804, 0.6468], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,430 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,430 - train - INFO - True
2024-04-07 12:53:38,431 - train - INFO - alphas:tensor([0.2559, 0.0036, 0.0145, 0.0928, 0.6332], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,440 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,440 - train - INFO - True
2024-04-07 12:53:38,441 - train - INFO - alphas:tensor([0.3783, 0.0023, 0.0126, 0.0457, 0.5610], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,450 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,450 - train - INFO - True
2024-04-07 12:53:38,450 - train - INFO - alphas:tensor([0.4068, 0.0034, 0.0053, 0.0780, 0.5064], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,459 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,459 - train - INFO - True
2024-04-07 12:53:38,460 - train - INFO - alphas:tensor([0.2980, 0.0025, 0.0016, 0.0646, 0.6333], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,468 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,468 - train - INFO - True
2024-04-07 12:53:38,469 - train - INFO - alphas:tensor([0.2337, 0.0029, 0.0135, 0.0932, 0.6568], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,477 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,477 - train - INFO - True
2024-04-07 12:53:38,478 - train - INFO - alphas:tensor([0.3481, 0.0013, 0.0093, 0.0492, 0.5922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,487 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,487 - train - INFO - True
2024-04-07 12:53:38,488 - train - INFO - alphas:tensor([0.4416, 0.0034, 0.0046, 0.0665, 0.4839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,499 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,499 - train - INFO - True
2024-04-07 12:53:38,500 - train - INFO - alphas:tensor([0.3387, 0.0014, 0.0022, 0.0702, 0.5875], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,510 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,510 - train - INFO - True
2024-04-07 12:53:38,511 - train - INFO - alphas:tensor([0.2150, 0.0025, 0.0120, 0.0801, 0.6903], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,521 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,521 - train - INFO - True
2024-04-07 12:53:38,522 - train - INFO - alphas:tensor([0.3125, 0.0008, 0.0065, 0.0382, 0.6419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,531 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,531 - train - INFO - True
2024-04-07 12:53:38,532 - train - INFO - alphas:tensor([0.4277, 0.0049, 0.0051, 0.0735, 0.4887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,541 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,541 - train - INFO - True
2024-04-07 12:53:38,542 - train - INFO - alphas:tensor([0.3581, 0.0013, 0.0025, 0.0694, 0.5686], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,551 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,551 - train - INFO - True
2024-04-07 12:53:38,552 - train - INFO - alphas:tensor([0.6263, 0.0322, 0.1065, 0.2350], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 12:53:38,569 - train - INFO - tau:0.475340042005707
2024-04-07 12:53:38,569 - train - INFO - avg block size:14.378378378378379
2024-04-07 12:53:38,569 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 12:53:38,569 - train - INFO - lasso_alpha:0.00011918176537727237
2024-04-07 12:53:38,821 - train - INFO - Test: [   0/78]  Time: 0.249 (0.249)  Loss:  0.9185 (0.9185)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 12:53:44,322 - train - INFO - Test: [  50/78]  Time: 0.103 (0.113)  Loss:  1.7998 (1.6802)  Acc@1: 60.9375 (60.5852)  Acc@5: 81.2500 (83.4099)
2024-04-07 12:53:46,971 - train - INFO - Test: [  78/78]  Time: 0.058 (0.106)  Loss:  1.7393 (1.7142)  Acc@1: 56.2500 (59.8200)  Acc@5: 87.5000 (82.8100)
2024-04-07 12:53:48,304 - train - INFO - Train: 77 [   0/781 (  0%)]  Loss:  3.230566 (3.2306)  Time: 1.267s,  101.06/s  (1.267s,  101.06/s)  LR: 2.447e-04  Data: 0.186 (0.186)
2024-04-07 12:54:32,470 - train - INFO - Train: 77 [  50/781 (  6%)]  Loss:  4.039175 (4.0237)  Time: 1.096s,  116.80/s  (0.891s,  143.69/s)  LR: 2.447e-04  Data: 0.019 (0.012)
2024-04-07 12:55:17,496 - train - INFO - Train: 77 [ 100/781 ( 13%)]  Loss:  4.470850 (3.9947)  Time: 1.043s,  122.71/s  (0.896s,  142.92/s)  LR: 2.447e-04  Data: 0.010 (0.010)
2024-04-07 12:56:02,269 - train - INFO - Train: 77 [ 150/781 ( 19%)]  Loss:  3.833755 (3.9798)  Time: 0.839s,  152.53/s  (0.896s,  142.93/s)  LR: 2.447e-04  Data: 0.008 (0.009)
2024-04-07 12:56:46,365 - train - INFO - Train: 77 [ 200/781 ( 26%)]  Loss:  3.996098 (3.9733)  Time: 0.846s,  151.39/s  (0.892s,  143.47/s)  LR: 2.447e-04  Data: 0.009 (0.009)
2024-04-07 12:57:30,885 - train - INFO - Train: 77 [ 250/781 ( 32%)]  Loss:  4.543190 (3.9794)  Time: 0.864s,  148.09/s  (0.892s,  143.53/s)  LR: 2.447e-04  Data: 0.011 (0.009)
2024-04-07 12:58:15,181 - train - INFO - Train: 77 [ 300/781 ( 38%)]  Loss:  3.630124 (3.9799)  Time: 0.837s,  152.85/s  (0.891s,  143.69/s)  LR: 2.447e-04  Data: 0.008 (0.009)
2024-04-07 12:59:00,432 - train - INFO - Train: 77 [ 350/781 ( 45%)]  Loss:  4.656582 (3.9958)  Time: 0.837s,  153.00/s  (0.893s,  143.36/s)  LR: 2.447e-04  Data: 0.008 (0.008)
2024-04-07 12:59:45,801 - train - INFO - Train: 77 [ 400/781 ( 51%)]  Loss:  3.953943 (3.9910)  Time: 1.051s,  121.81/s  (0.895s,  143.07/s)  LR: 2.447e-04  Data: 0.008 (0.008)
2024-04-07 13:00:29,937 - train - INFO - Train: 77 [ 450/781 ( 58%)]  Loss:  3.364270 (3.9910)  Time: 1.114s,  114.94/s  (0.893s,  143.29/s)  LR: 2.447e-04  Data: 0.008 (0.008)
2024-04-07 13:01:14,093 - train - INFO - Train: 77 [ 500/781 ( 64%)]  Loss:  4.104365 (3.9919)  Time: 0.854s,  149.84/s  (0.892s,  143.45/s)  LR: 2.447e-04  Data: 0.008 (0.008)
2024-04-07 13:01:58,655 - train - INFO - Train: 77 [ 550/781 ( 71%)]  Loss:  3.913056 (3.9920)  Time: 0.843s,  151.81/s  (0.892s,  143.47/s)  LR: 2.447e-04  Data: 0.007 (0.008)
2024-04-07 13:02:41,679 - train - INFO - Train: 77 [ 600/781 ( 77%)]  Loss:  3.430078 (3.9940)  Time: 0.834s,  153.53/s  (0.890s,  143.89/s)  LR: 2.447e-04  Data: 0.007 (0.008)
2024-04-07 13:03:27,229 - train - INFO - Train: 77 [ 650/781 ( 83%)]  Loss:  3.500040 (3.9928)  Time: 0.833s,  153.61/s  (0.891s,  143.63/s)  LR: 2.447e-04  Data: 0.007 (0.008)
2024-04-07 13:04:12,344 - train - INFO - Train: 77 [ 700/781 ( 90%)]  Loss:  3.496684 (3.9993)  Time: 0.998s,  128.24/s  (0.892s,  143.50/s)  LR: 2.447e-04  Data: 0.005 (0.008)
2024-04-07 13:04:56,553 - train - INFO - Train: 77 [ 750/781 ( 96%)]  Loss:  4.176767 (4.0058)  Time: 1.085s,  118.02/s  (0.891s,  143.58/s)  LR: 2.447e-04  Data: 0.008 (0.008)
2024-04-07 13:05:23,997 - train - INFO - Train: 77 [ 780/781 (100%)]  Loss:  3.600490 (4.0038)  Time: 0.848s,  150.92/s  (0.892s,  143.44/s)  LR: 2.447e-04  Data: 0.000 (0.008)
2024-04-07 13:05:23,997 - train - INFO - True
2024-04-07 13:05:23,999 - train - INFO - alphas:tensor([0.0062, 0.0077, 0.0429, 0.3358, 0.6073], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,013 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,013 - train - INFO - True
2024-04-07 13:05:24,014 - train - INFO - alphas:tensor([0.1034, 0.0188, 0.0394, 0.1411, 0.6973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,028 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,028 - train - INFO - True
2024-04-07 13:05:24,029 - train - INFO - alphas:tensor([0.4912, 0.0891, 0.0659, 0.1420, 0.2118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,057 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,058 - train - INFO - True
2024-04-07 13:05:24,058 - train - INFO - alphas:tensor([0.4149, 0.0208, 0.0367, 0.1372, 0.3904], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,087 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,087 - train - INFO - True
2024-04-07 13:05:24,088 - train - INFO - alphas:tensor([0.2551, 0.0139, 0.0502, 0.1500, 0.5308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,102 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,102 - train - INFO - True
2024-04-07 13:05:24,103 - train - INFO - alphas:tensor([0.3562, 0.0095, 0.0287, 0.1081, 0.4976], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,117 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,117 - train - INFO - True
2024-04-07 13:05:24,118 - train - INFO - alphas:tensor([0.4917, 0.0331, 0.0229, 0.1252, 0.3271], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,146 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,146 - train - INFO - True
2024-04-07 13:05:24,147 - train - INFO - alphas:tensor([0.3763, 0.0157, 0.0099, 0.1089, 0.4892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,162 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,162 - train - INFO - True
2024-04-07 13:05:24,163 - train - INFO - alphas:tensor([0.3132, 0.0109, 0.0332, 0.1218, 0.5208], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,177 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,177 - train - INFO - True
2024-04-07 13:05:24,178 - train - INFO - alphas:tensor([0.4176, 0.0077, 0.0267, 0.0868, 0.4613], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,192 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,192 - train - INFO - True
2024-04-07 13:05:24,193 - train - INFO - alphas:tensor([0.4009, 0.0185, 0.0183, 0.1191, 0.4431], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,207 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,208 - train - INFO - True
2024-04-07 13:05:24,208 - train - INFO - alphas:tensor([0.3111, 0.0074, 0.0090, 0.1240, 0.5486], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,223 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,223 - train - INFO - True
2024-04-07 13:05:24,224 - train - INFO - alphas:tensor([0.3227, 0.0068, 0.0245, 0.1111, 0.5349], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,238 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,238 - train - INFO - True
2024-04-07 13:05:24,239 - train - INFO - alphas:tensor([0.4192, 0.0034, 0.0176, 0.0669, 0.4929], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,253 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,253 - train - INFO - True
2024-04-07 13:05:24,254 - train - INFO - alphas:tensor([0.3150, 0.0212, 0.0145, 0.1279, 0.5214], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,269 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,269 - train - INFO - True
2024-04-07 13:05:24,270 - train - INFO - alphas:tensor([0.2233, 0.0047, 0.0043, 0.1379, 0.6298], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,284 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,284 - train - INFO - True
2024-04-07 13:05:24,285 - train - INFO - alphas:tensor([0.3094, 0.0072, 0.0184, 0.1026, 0.5624], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,299 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,299 - train - INFO - True
2024-04-07 13:05:24,300 - train - INFO - alphas:tensor([0.4129, 0.0028, 0.0148, 0.0623, 0.5072], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,314 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,315 - train - INFO - True
2024-04-07 13:05:24,316 - train - INFO - alphas:tensor([0.3256, 0.0069, 0.0073, 0.1148, 0.5454], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,330 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,330 - train - INFO - True
2024-04-07 13:05:24,331 - train - INFO - alphas:tensor([0.2286, 0.0031, 0.0030, 0.1154, 0.6498], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,345 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,345 - train - INFO - True
2024-04-07 13:05:24,346 - train - INFO - alphas:tensor([0.2644, 0.0042, 0.0162, 0.1013, 0.6139], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,360 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,360 - train - INFO - True
2024-04-07 13:05:24,361 - train - INFO - alphas:tensor([0.3888, 0.0022, 0.0127, 0.0535, 0.5427], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,376 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,376 - train - INFO - True
2024-04-07 13:05:24,377 - train - INFO - alphas:tensor([0.3789, 0.0099, 0.0065, 0.0857, 0.5189], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,391 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,391 - train - INFO - True
2024-04-07 13:05:24,392 - train - INFO - alphas:tensor([0.2755, 0.0024, 0.0018, 0.0796, 0.6407], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,406 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,406 - train - INFO - True
2024-04-07 13:05:24,407 - train - INFO - alphas:tensor([0.2569, 0.0034, 0.0142, 0.0908, 0.6347], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,421 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,422 - train - INFO - True
2024-04-07 13:05:24,422 - train - INFO - alphas:tensor([0.3821, 0.0022, 0.0121, 0.0442, 0.5594], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,437 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,437 - train - INFO - True
2024-04-07 13:05:24,438 - train - INFO - alphas:tensor([0.4138, 0.0032, 0.0049, 0.0759, 0.5022], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,452 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,452 - train - INFO - True
2024-04-07 13:05:24,453 - train - INFO - alphas:tensor([0.3048, 0.0024, 0.0015, 0.0628, 0.6285], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,467 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,468 - train - INFO - True
2024-04-07 13:05:24,468 - train - INFO - alphas:tensor([0.2332, 0.0027, 0.0132, 0.0909, 0.6599], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,483 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,483 - train - INFO - True
2024-04-07 13:05:24,484 - train - INFO - alphas:tensor([0.3489, 0.0012, 0.0089, 0.0478, 0.5932], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,498 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,498 - train - INFO - True
2024-04-07 13:05:24,499 - train - INFO - alphas:tensor([0.4443, 0.0032, 0.0042, 0.0648, 0.4834], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,513 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,513 - train - INFO - True
2024-04-07 13:05:24,514 - train - INFO - alphas:tensor([0.3458, 0.0013, 0.0020, 0.0685, 0.5824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,529 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,529 - train - INFO - True
2024-04-07 13:05:24,530 - train - INFO - alphas:tensor([0.2150, 0.0024, 0.0116, 0.0782, 0.6929], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,544 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,544 - train - INFO - True
2024-04-07 13:05:24,545 - train - INFO - alphas:tensor([0.3132, 0.0007, 0.0062, 0.0368, 0.6430], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,559 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,559 - train - INFO - True
2024-04-07 13:05:24,560 - train - INFO - alphas:tensor([0.4275, 0.0047, 0.0048, 0.0718, 0.4912], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,575 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,575 - train - INFO - True
2024-04-07 13:05:24,576 - train - INFO - alphas:tensor([0.3608, 0.0012, 0.0023, 0.0677, 0.5680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,590 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,590 - train - INFO - True
2024-04-07 13:05:24,591 - train - INFO - alphas:tensor([0.6257, 0.0316, 0.1060, 0.2368], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:05:24,619 - train - INFO - tau:0.47058664158564995
2024-04-07 13:05:24,619 - train - INFO - avg block size:14.378378378378379
2024-04-07 13:05:24,619 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 13:05:24,862 - train - INFO - Test: [   0/78]  Time: 0.240 (0.240)  Loss:  0.9243 (0.9243)  Acc@1: 80.4688 (80.4688)  Acc@5: 92.1875 (92.1875)
2024-04-07 13:05:29,350 - train - INFO - Test: [  50/78]  Time: 0.083 (0.093)  Loss:  1.9844 (1.6641)  Acc@1: 53.1250 (60.6158)  Acc@5: 79.6875 (83.6397)
2024-04-07 13:05:31,711 - train - INFO - Test: [  78/78]  Time: 0.055 (0.090)  Loss:  1.6143 (1.6903)  Acc@1: 56.2500 (60.2700)  Acc@5: 100.0000 (83.0700)
2024-04-07 13:05:33,032 - train - INFO - Train: 78 [   0/781 (  0%)]  Loss:  4.009303 (4.0093)  Time: 1.246s,  102.76/s  (1.246s,  102.76/s)  LR: 2.396e-04  Data: 0.180 (0.180)
2024-04-07 13:06:17,478 - train - INFO - Train: 78 [  50/781 (  6%)]  Loss:  3.367814 (4.0494)  Time: 0.829s,  154.35/s  (0.896s,  142.87/s)  LR: 2.396e-04  Data: 0.007 (0.011)
2024-04-07 13:07:02,050 - train - INFO - Train: 78 [ 100/781 ( 13%)]  Loss:  3.362094 (4.0553)  Time: 0.853s,  150.11/s  (0.894s,  143.23/s)  LR: 2.396e-04  Data: 0.008 (0.009)
2024-04-07 13:07:45,502 - train - INFO - Train: 78 [ 150/781 ( 19%)]  Loss:  3.724462 (4.0463)  Time: 0.799s,  160.29/s  (0.886s,  144.55/s)  LR: 2.396e-04  Data: 0.008 (0.009)
2024-04-07 13:08:30,312 - train - INFO - Train: 78 [ 200/781 ( 26%)]  Loss:  3.919282 (4.0420)  Time: 1.119s,  114.43/s  (0.888s,  144.12/s)  LR: 2.396e-04  Data: 0.009 (0.009)
2024-04-07 13:09:14,815 - train - INFO - Train: 78 [ 250/781 ( 32%)]  Loss:  4.636864 (4.0455)  Time: 0.799s,  160.21/s  (0.889s,  144.06/s)  LR: 2.396e-04  Data: 0.004 (0.008)
2024-04-07 13:09:58,731 - train - INFO - Train: 78 [ 300/781 ( 38%)]  Loss:  4.249006 (4.0399)  Time: 1.082s,  118.31/s  (0.887s,  144.33/s)  LR: 2.396e-04  Data: 0.008 (0.008)
2024-04-07 13:10:42,418 - train - INFO - Train: 78 [ 350/781 ( 45%)]  Loss:  4.506196 (4.0348)  Time: 1.117s,  114.57/s  (0.885s,  144.64/s)  LR: 2.396e-04  Data: 0.008 (0.008)
2024-04-07 13:11:26,901 - train - INFO - Train: 78 [ 400/781 ( 51%)]  Loss:  3.986552 (4.0377)  Time: 0.802s,  159.54/s  (0.886s,  144.54/s)  LR: 2.396e-04  Data: 0.006 (0.008)
2024-04-07 13:12:11,733 - train - INFO - Train: 78 [ 450/781 ( 58%)]  Loss:  4.683599 (4.0336)  Time: 0.833s,  153.72/s  (0.887s,  144.34/s)  LR: 2.396e-04  Data: 0.008 (0.008)
2024-04-07 13:12:57,796 - train - INFO - Train: 78 [ 500/781 ( 64%)]  Loss:  4.390610 (4.0392)  Time: 1.014s,  126.17/s  (0.890s,  143.79/s)  LR: 2.396e-04  Data: 0.005 (0.008)
2024-04-07 13:13:42,516 - train - INFO - Train: 78 [ 550/781 ( 71%)]  Loss:  3.280012 (4.0392)  Time: 1.013s,  126.39/s  (0.891s,  143.73/s)  LR: 2.396e-04  Data: 0.005 (0.008)
2024-04-07 13:14:28,308 - train - INFO - Train: 78 [ 600/781 ( 77%)]  Loss:  3.654525 (4.0378)  Time: 0.888s,  144.13/s  (0.893s,  143.39/s)  LR: 2.396e-04  Data: 0.010 (0.008)
2024-04-07 13:15:12,481 - train - INFO - Train: 78 [ 650/781 ( 83%)]  Loss:  3.843016 (4.0253)  Time: 0.840s,  152.33/s  (0.892s,  143.50/s)  LR: 2.396e-04  Data: 0.008 (0.008)
2024-04-07 13:15:56,919 - train - INFO - Train: 78 [ 700/781 ( 90%)]  Loss:  4.702611 (4.0258)  Time: 0.826s,  154.96/s  (0.892s,  143.54/s)  LR: 2.396e-04  Data: 0.005 (0.008)
2024-04-07 13:16:40,328 - train - INFO - Train: 78 [ 750/781 ( 96%)]  Loss:  3.730646 (4.0298)  Time: 0.851s,  150.47/s  (0.890s,  143.79/s)  LR: 2.396e-04  Data: 0.009 (0.008)
2024-04-07 13:17:06,910 - train - INFO - Train: 78 [ 780/781 (100%)]  Loss:  3.739832 (4.0284)  Time: 0.858s,  149.22/s  (0.890s,  143.82/s)  LR: 2.396e-04  Data: 0.000 (0.008)
2024-04-07 13:17:06,911 - train - INFO - True
2024-04-07 13:17:06,913 - train - INFO - alphas:tensor([0.0057, 0.0071, 0.0415, 0.3367, 0.6091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:06,933 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:06,933 - train - INFO - True
2024-04-07 13:17:06,935 - train - INFO - alphas:tensor([0.1039, 0.0186, 0.0392, 0.1388, 0.6994], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:06,953 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:06,953 - train - INFO - True
2024-04-07 13:17:06,954 - train - INFO - alphas:tensor([0.4922, 0.0874, 0.0650, 0.1421, 0.2132], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:06,985 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:06,985 - train - INFO - True
2024-04-07 13:17:06,986 - train - INFO - alphas:tensor([0.4160, 0.0203, 0.0357, 0.1356, 0.3924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,014 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,014 - train - INFO - True
2024-04-07 13:17:07,015 - train - INFO - alphas:tensor([0.2549, 0.0135, 0.0494, 0.1484, 0.5338], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,027 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,027 - train - INFO - True
2024-04-07 13:17:07,028 - train - INFO - alphas:tensor([0.3568, 0.0091, 0.0281, 0.1062, 0.4999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,040 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,041 - train - INFO - True
2024-04-07 13:17:07,041 - train - INFO - alphas:tensor([0.4913, 0.0321, 0.0222, 0.1247, 0.3297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,064 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,064 - train - INFO - True
2024-04-07 13:17:07,065 - train - INFO - alphas:tensor([0.3767, 0.0151, 0.0093, 0.1071, 0.4917], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,075 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,075 - train - INFO - True
2024-04-07 13:17:07,076 - train - INFO - alphas:tensor([0.3139, 0.0105, 0.0323, 0.1202, 0.5231], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,086 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,086 - train - INFO - True
2024-04-07 13:17:07,087 - train - INFO - alphas:tensor([0.4189, 0.0073, 0.0258, 0.0851, 0.4630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,097 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,097 - train - INFO - True
2024-04-07 13:17:07,098 - train - INFO - alphas:tensor([0.4020, 0.0179, 0.0175, 0.1173, 0.4454], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,108 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,108 - train - INFO - True
2024-04-07 13:17:07,109 - train - INFO - alphas:tensor([0.3111, 0.0071, 0.0084, 0.1231, 0.5503], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,118 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,118 - train - INFO - True
2024-04-07 13:17:07,119 - train - INFO - alphas:tensor([0.3220, 0.0066, 0.0236, 0.1090, 0.5387], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,128 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,128 - train - INFO - True
2024-04-07 13:17:07,129 - train - INFO - alphas:tensor([0.4195, 0.0032, 0.0168, 0.0652, 0.4953], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,137 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,137 - train - INFO - True
2024-04-07 13:17:07,138 - train - INFO - alphas:tensor([0.3167, 0.0209, 0.0139, 0.1266, 0.5218], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,147 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,147 - train - INFO - True
2024-04-07 13:17:07,148 - train - INFO - alphas:tensor([0.2253, 0.0046, 0.0041, 0.1372, 0.6289], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,156 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,156 - train - INFO - True
2024-04-07 13:17:07,157 - train - INFO - alphas:tensor([0.3088, 0.0069, 0.0177, 0.1007, 0.5659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,165 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,166 - train - INFO - True
2024-04-07 13:17:07,166 - train - INFO - alphas:tensor([0.4098, 0.0026, 0.0143, 0.0611, 0.5121], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,175 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,175 - train - INFO - True
2024-04-07 13:17:07,176 - train - INFO - alphas:tensor([0.3281, 0.0066, 0.0068, 0.1130, 0.5455], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,186 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,187 - train - INFO - True
2024-04-07 13:17:07,187 - train - INFO - alphas:tensor([0.2318, 0.0030, 0.0028, 0.1152, 0.6472], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,198 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,198 - train - INFO - True
2024-04-07 13:17:07,199 - train - INFO - alphas:tensor([0.2649, 0.0041, 0.0157, 0.0986, 0.6167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,209 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,209 - train - INFO - True
2024-04-07 13:17:07,210 - train - INFO - alphas:tensor([0.3911, 0.0021, 0.0121, 0.0519, 0.5428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,219 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,219 - train - INFO - True
2024-04-07 13:17:07,220 - train - INFO - alphas:tensor([0.3738, 0.0095, 0.0061, 0.0846, 0.5260], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,229 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,229 - train - INFO - True
2024-04-07 13:17:07,230 - train - INFO - alphas:tensor([0.2723, 0.0022, 0.0017, 0.0794, 0.6444], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,239 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,239 - train - INFO - True
2024-04-07 13:17:07,240 - train - INFO - alphas:tensor([0.2551, 0.0032, 0.0135, 0.0887, 0.6395], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,249 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,249 - train - INFO - True
2024-04-07 13:17:07,249 - train - INFO - alphas:tensor([0.3772, 0.0020, 0.0114, 0.0426, 0.5669], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,258 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,258 - train - INFO - True
2024-04-07 13:17:07,259 - train - INFO - alphas:tensor([0.4148, 0.0030, 0.0045, 0.0741, 0.5036], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,267 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,267 - train - INFO - True
2024-04-07 13:17:07,268 - train - INFO - alphas:tensor([0.3044, 0.0022, 0.0013, 0.0613, 0.6307], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,276 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,276 - train - INFO - True
2024-04-07 13:17:07,277 - train - INFO - alphas:tensor([0.2346, 0.0026, 0.0128, 0.0887, 0.6613], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,285 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,285 - train - INFO - True
2024-04-07 13:17:07,286 - train - INFO - alphas:tensor([0.3497, 0.0011, 0.0085, 0.0464, 0.5943], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,294 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,294 - train - INFO - True
2024-04-07 13:17:07,295 - train - INFO - alphas:tensor([0.4422, 0.0030, 0.0040, 0.0635, 0.4873], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,303 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,303 - train - INFO - True
2024-04-07 13:17:07,303 - train - INFO - alphas:tensor([0.3441, 0.0012, 0.0018, 0.0664, 0.5865], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,312 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,312 - train - INFO - True
2024-04-07 13:17:07,312 - train - INFO - alphas:tensor([0.2151, 0.0023, 0.0113, 0.0766, 0.6948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,321 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,321 - train - INFO - True
2024-04-07 13:17:07,322 - train - INFO - alphas:tensor([0.3137, 0.0007, 0.0058, 0.0356, 0.6442], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,333 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,333 - train - INFO - True
2024-04-07 13:17:07,336 - train - INFO - alphas:tensor([0.4270, 0.0046, 0.0045, 0.0703, 0.4936], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,346 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,346 - train - INFO - True
2024-04-07 13:17:07,348 - train - INFO - alphas:tensor([0.3638, 0.0011, 0.0021, 0.0663, 0.5666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,357 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,357 - train - INFO - True
2024-04-07 13:17:07,358 - train - INFO - alphas:tensor([0.6248, 0.0310, 0.1054, 0.2388], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:17:07,377 - train - INFO - tau:0.4658807751697934
2024-04-07 13:17:07,377 - train - INFO - avg block size:14.378378378378379
2024-04-07 13:17:07,377 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 13:17:07,377 - train - INFO - lasso_alpha:0.00010834705943388396
2024-04-07 13:17:07,623 - train - INFO - Test: [   0/78]  Time: 0.242 (0.242)  Loss:  0.9062 (0.9062)  Acc@1: 81.2500 (81.2500)  Acc@5: 94.5312 (94.5312)
2024-04-07 13:17:12,110 - train - INFO - Test: [  50/78]  Time: 0.088 (0.093)  Loss:  1.8154 (1.6618)  Acc@1: 57.8125 (60.6464)  Acc@5: 79.6875 (83.6857)
2024-04-07 13:17:14,825 - train - INFO - Test: [  78/78]  Time: 0.056 (0.094)  Loss:  1.7217 (1.6902)  Acc@1: 62.5000 (60.0900)  Acc@5: 93.7500 (83.2100)
2024-04-07 13:17:15,900 - train - INFO - Train: 79 [   0/781 (  0%)]  Loss:  3.469708 (3.4697)  Time: 1.012s,  126.52/s  (1.012s,  126.52/s)  LR: 2.345e-04  Data: 0.204 (0.204)
2024-04-07 13:17:59,456 - train - INFO - Train: 79 [  50/781 (  6%)]  Loss:  3.998365 (4.0079)  Time: 0.840s,  152.43/s  (0.874s,  146.48/s)  LR: 2.345e-04  Data: 0.007 (0.011)
2024-04-07 13:18:43,274 - train - INFO - Train: 79 [ 100/781 ( 13%)]  Loss:  3.757044 (4.0173)  Time: 1.054s,  121.43/s  (0.875s,  146.27/s)  LR: 2.345e-04  Data: 0.007 (0.009)
2024-04-07 13:19:25,946 - train - INFO - Train: 79 [ 150/781 ( 19%)]  Loss:  3.547956 (3.9820)  Time: 0.834s,  153.42/s  (0.868s,  147.48/s)  LR: 2.345e-04  Data: 0.008 (0.009)
2024-04-07 13:20:12,379 - train - INFO - Train: 79 [ 200/781 ( 26%)]  Loss:  4.345774 (3.9696)  Time: 1.017s,  125.83/s  (0.883s,  144.96/s)  LR: 2.345e-04  Data: 0.005 (0.009)
2024-04-07 13:20:56,681 - train - INFO - Train: 79 [ 250/781 ( 32%)]  Loss:  3.846476 (3.9738)  Time: 0.831s,  154.12/s  (0.884s,  144.86/s)  LR: 2.345e-04  Data: 0.007 (0.009)
2024-04-07 13:21:40,820 - train - INFO - Train: 79 [ 300/781 ( 38%)]  Loss:  3.600247 (3.9866)  Time: 0.844s,  151.62/s  (0.883s,  144.88/s)  LR: 2.345e-04  Data: 0.009 (0.009)
2024-04-07 13:22:25,358 - train - INFO - Train: 79 [ 350/781 ( 45%)]  Loss:  4.026342 (3.9899)  Time: 0.992s,  129.09/s  (0.884s,  144.71/s)  LR: 2.345e-04  Data: 0.005 (0.009)
2024-04-07 13:23:10,104 - train - INFO - Train: 79 [ 400/781 ( 51%)]  Loss:  4.393375 (3.9807)  Time: 1.039s,  123.19/s  (0.886s,  144.50/s)  LR: 2.345e-04  Data: 0.008 (0.008)
2024-04-07 13:23:55,009 - train - INFO - Train: 79 [ 450/781 ( 58%)]  Loss:  3.538071 (3.9742)  Time: 0.858s,  149.14/s  (0.887s,  144.28/s)  LR: 2.345e-04  Data: 0.008 (0.008)
2024-04-07 13:24:39,683 - train - INFO - Train: 79 [ 500/781 ( 64%)]  Loss:  3.701828 (3.9802)  Time: 0.830s,  154.23/s  (0.888s,  144.18/s)  LR: 2.345e-04  Data: 0.007 (0.008)
2024-04-07 13:25:22,709 - train - INFO - Train: 79 [ 550/781 ( 71%)]  Loss:  3.659926 (3.9781)  Time: 0.796s,  160.77/s  (0.885s,  144.58/s)  LR: 2.345e-04  Data: 0.005 (0.008)
2024-04-07 13:26:06,807 - train - INFO - Train: 79 [ 600/781 ( 77%)]  Loss:  4.361112 (3.9821)  Time: 0.765s,  167.37/s  (0.885s,  144.63/s)  LR: 2.345e-04  Data: 0.005 (0.008)
2024-04-07 13:26:50,288 - train - INFO - Train: 79 [ 650/781 ( 83%)]  Loss:  3.665159 (3.9831)  Time: 0.785s,  163.04/s  (0.884s,  144.82/s)  LR: 2.345e-04  Data: 0.006 (0.008)
2024-04-07 13:27:33,676 - train - INFO - Train: 79 [ 700/781 ( 90%)]  Loss:  3.338004 (3.9887)  Time: 0.847s,  151.20/s  (0.883s,  145.01/s)  LR: 2.345e-04  Data: 0.008 (0.008)
2024-04-07 13:28:20,715 - train - INFO - Train: 79 [ 750/781 ( 96%)]  Loss:  3.997627 (3.9868)  Time: 1.001s,  127.91/s  (0.887s,  144.38/s)  LR: 2.345e-04  Data: 0.007 (0.008)
2024-04-07 13:28:46,304 - train - INFO - Train: 79 [ 780/781 (100%)]  Loss:  3.991519 (3.9914)  Time: 0.835s,  153.22/s  (0.885s,  144.59/s)  LR: 2.345e-04  Data: 0.000 (0.008)
2024-04-07 13:28:46,305 - train - INFO - True
2024-04-07 13:28:46,307 - train - INFO - alphas:tensor([0.0052, 0.0067, 0.0403, 0.3386, 0.6092], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,328 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,328 - train - INFO - True
2024-04-07 13:28:46,329 - train - INFO - alphas:tensor([0.1045, 0.0184, 0.0385, 0.1375, 0.7011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,348 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,348 - train - INFO - True
2024-04-07 13:28:46,349 - train - INFO - alphas:tensor([0.4931, 0.0865, 0.0642, 0.1418, 0.2143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,381 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,381 - train - INFO - True
2024-04-07 13:28:46,382 - train - INFO - alphas:tensor([0.4164, 0.0197, 0.0347, 0.1343, 0.3950], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,410 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,410 - train - INFO - True
2024-04-07 13:28:46,411 - train - INFO - alphas:tensor([0.2558, 0.0132, 0.0489, 0.1464, 0.5357], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,424 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,424 - train - INFO - True
2024-04-07 13:28:46,425 - train - INFO - alphas:tensor([0.3580, 0.0087, 0.0270, 0.1044, 0.5019], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,437 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,437 - train - INFO - True
2024-04-07 13:28:46,438 - train - INFO - alphas:tensor([0.4959, 0.0316, 0.0213, 0.1225, 0.3287], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,461 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,461 - train - INFO - True
2024-04-07 13:28:46,462 - train - INFO - alphas:tensor([0.3810, 0.0148, 0.0088, 0.1048, 0.4905], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,473 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,473 - train - INFO - True
2024-04-07 13:28:46,473 - train - INFO - alphas:tensor([0.3136, 0.0101, 0.0316, 0.1182, 0.5265], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,487 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,487 - train - INFO - True
2024-04-07 13:28:46,487 - train - INFO - alphas:tensor([0.4211, 0.0070, 0.0250, 0.0831, 0.4639], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,497 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,497 - train - INFO - True
2024-04-07 13:28:46,498 - train - INFO - alphas:tensor([0.4052, 0.0176, 0.0169, 0.1157, 0.4447], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,508 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,508 - train - INFO - True
2024-04-07 13:28:46,509 - train - INFO - alphas:tensor([0.3146, 0.0069, 0.0081, 0.1216, 0.5489], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,518 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,518 - train - INFO - True
2024-04-07 13:28:46,519 - train - INFO - alphas:tensor([0.3231, 0.0063, 0.0230, 0.1071, 0.5405], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,528 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,528 - train - INFO - True
2024-04-07 13:28:46,529 - train - INFO - alphas:tensor([0.4199, 0.0030, 0.0161, 0.0640, 0.4970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,538 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,538 - train - INFO - True
2024-04-07 13:28:46,538 - train - INFO - alphas:tensor([0.3196, 0.0205, 0.0134, 0.1261, 0.5205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,548 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,548 - train - INFO - True
2024-04-07 13:28:46,549 - train - INFO - alphas:tensor([0.2280, 0.0044, 0.0039, 0.1364, 0.6273], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,560 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,560 - train - INFO - True
2024-04-07 13:28:46,561 - train - INFO - alphas:tensor([0.3092, 0.0066, 0.0170, 0.0989, 0.5683], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,571 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,571 - train - INFO - True
2024-04-07 13:28:46,572 - train - INFO - alphas:tensor([0.4135, 0.0024, 0.0136, 0.0588, 0.5117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,582 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,582 - train - INFO - True
2024-04-07 13:28:46,583 - train - INFO - alphas:tensor([0.3310, 0.0063, 0.0065, 0.1114, 0.5448], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,593 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,593 - train - INFO - True
2024-04-07 13:28:46,593 - train - INFO - alphas:tensor([0.2354, 0.0029, 0.0026, 0.1134, 0.6457], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,603 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,603 - train - INFO - True
2024-04-07 13:28:46,604 - train - INFO - alphas:tensor([0.2650, 0.0039, 0.0151, 0.0965, 0.6196], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,613 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,613 - train - INFO - True
2024-04-07 13:28:46,614 - train - INFO - alphas:tensor([0.3888, 0.0019, 0.0117, 0.0505, 0.5471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,622 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,623 - train - INFO - True
2024-04-07 13:28:46,623 - train - INFO - alphas:tensor([0.3797, 0.0093, 0.0057, 0.0829, 0.5225], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,632 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,632 - train - INFO - True
2024-04-07 13:28:46,633 - train - INFO - alphas:tensor([0.2779, 0.0021, 0.0016, 0.0775, 0.6409], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,641 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,641 - train - INFO - True
2024-04-07 13:28:46,642 - train - INFO - alphas:tensor([0.2576, 0.0031, 0.0129, 0.0872, 0.6392], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,650 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,650 - train - INFO - True
2024-04-07 13:28:46,651 - train - INFO - alphas:tensor([0.3804, 0.0019, 0.0109, 0.0412, 0.5656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,659 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,659 - train - INFO - True
2024-04-07 13:28:46,660 - train - INFO - alphas:tensor([0.4181, 0.0028, 0.0043, 0.0723, 0.5024], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,668 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,668 - train - INFO - True
2024-04-07 13:28:46,669 - train - INFO - alphas:tensor([0.3099, 0.0022, 0.0012, 0.0602, 0.6265], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,677 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,677 - train - INFO - True
2024-04-07 13:28:46,678 - train - INFO - alphas:tensor([0.2362, 0.0025, 0.0125, 0.0867, 0.6621], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,688 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,688 - train - INFO - True
2024-04-07 13:28:46,689 - train - INFO - alphas:tensor([0.3536, 0.0010, 0.0082, 0.0451, 0.5922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,700 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,700 - train - INFO - True
2024-04-07 13:28:46,701 - train - INFO - alphas:tensor([0.4473, 0.0027, 0.0037, 0.0617, 0.4845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,710 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,711 - train - INFO - True
2024-04-07 13:28:46,711 - train - INFO - alphas:tensor([0.3496, 0.0011, 0.0017, 0.0650, 0.5826], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,721 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,721 - train - INFO - True
2024-04-07 13:28:46,722 - train - INFO - alphas:tensor([0.2157, 0.0022, 0.0108, 0.0748, 0.6966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,731 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,731 - train - INFO - True
2024-04-07 13:28:46,732 - train - INFO - alphas:tensor([3.1709e-01, 6.2338e-04, 5.4179e-03, 3.3961e-02, 6.4290e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,741 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,741 - train - INFO - True
2024-04-07 13:28:46,742 - train - INFO - alphas:tensor([0.4315, 0.0043, 0.0042, 0.0687, 0.4913], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,751 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,751 - train - INFO - True
2024-04-07 13:28:46,751 - train - INFO - alphas:tensor([0.3695, 0.0011, 0.0020, 0.0645, 0.5630], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,762 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,762 - train - INFO - True
2024-04-07 13:28:46,763 - train - INFO - alphas:tensor([0.6235, 0.0304, 0.1050, 0.2411], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:28:46,779 - train - INFO - tau:0.4612219674180955
2024-04-07 13:28:46,780 - train - INFO - avg block size:14.378378378378379
2024-04-07 13:28:46,780 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 13:28:47,047 - train - INFO - Test: [   0/78]  Time: 0.264 (0.264)  Loss:  0.8457 (0.8457)  Acc@1: 85.1562 (85.1562)  Acc@5: 93.7500 (93.7500)
2024-04-07 13:28:51,625 - train - INFO - Test: [  50/78]  Time: 0.084 (0.095)  Loss:  1.7939 (1.6667)  Acc@1: 57.8125 (60.9528)  Acc@5: 83.5938 (83.9154)
2024-04-07 13:28:54,011 - train - INFO - Test: [  78/78]  Time: 0.058 (0.091)  Loss:  1.7246 (1.6963)  Acc@1: 56.2500 (60.3100)  Acc@5: 93.7500 (83.3000)
2024-04-07 13:28:55,317 - train - INFO - Train: 80 [   0/781 (  0%)]  Loss:  4.042730 (4.0427)  Time: 1.234s,  103.72/s  (1.234s,  103.72/s)  LR: 2.294e-04  Data: 0.176 (0.176)
2024-04-07 13:29:40,563 - train - INFO - Train: 80 [  50/781 (  6%)]  Loss:  3.422472 (4.0235)  Time: 0.838s,  152.66/s  (0.911s,  140.45/s)  LR: 2.294e-04  Data: 0.009 (0.011)
2024-04-07 13:30:24,879 - train - INFO - Train: 80 [ 100/781 ( 13%)]  Loss:  3.759216 (3.9928)  Time: 0.853s,  149.99/s  (0.899s,  142.39/s)  LR: 2.294e-04  Data: 0.009 (0.009)
2024-04-07 13:31:07,911 - train - INFO - Train: 80 [ 150/781 ( 19%)]  Loss:  3.353344 (4.0081)  Time: 0.822s,  155.68/s  (0.886s,  144.43/s)  LR: 2.294e-04  Data: 0.006 (0.009)
2024-04-07 13:31:53,108 - train - INFO - Train: 80 [ 200/781 ( 26%)]  Loss:  4.114429 (4.0117)  Time: 0.846s,  151.29/s  (0.891s,  143.72/s)  LR: 2.294e-04  Data: 0.009 (0.009)
2024-04-07 13:32:37,343 - train - INFO - Train: 80 [ 250/781 ( 32%)]  Loss:  4.566525 (4.0210)  Time: 0.835s,  153.30/s  (0.889s,  143.91/s)  LR: 2.294e-04  Data: 0.007 (0.008)
2024-04-07 13:33:22,590 - train - INFO - Train: 80 [ 300/781 ( 38%)]  Loss:  3.674868 (3.9836)  Time: 0.831s,  154.01/s  (0.892s,  143.50/s)  LR: 2.294e-04  Data: 0.009 (0.008)
2024-04-07 13:34:07,031 - train - INFO - Train: 80 [ 350/781 ( 45%)]  Loss:  4.156150 (4.0005)  Time: 0.866s,  147.79/s  (0.892s,  143.57/s)  LR: 2.294e-04  Data: 0.009 (0.008)
2024-04-07 13:34:51,700 - train - INFO - Train: 80 [ 400/781 ( 51%)]  Loss:  4.294008 (3.9894)  Time: 1.093s,  117.13/s  (0.892s,  143.53/s)  LR: 2.294e-04  Data: 0.009 (0.008)
2024-04-07 13:35:34,766 - train - INFO - Train: 80 [ 450/781 ( 58%)]  Loss:  4.441192 (3.9840)  Time: 0.860s,  148.91/s  (0.888s,  144.08/s)  LR: 2.294e-04  Data: 0.008 (0.008)
2024-04-07 13:36:18,959 - train - INFO - Train: 80 [ 500/781 ( 64%)]  Loss:  4.459478 (3.9884)  Time: 0.834s,  153.41/s  (0.888s,  144.15/s)  LR: 2.294e-04  Data: 0.008 (0.008)
2024-04-07 13:37:02,909 - train - INFO - Train: 80 [ 550/781 ( 71%)]  Loss:  3.692566 (3.9843)  Time: 0.833s,  153.75/s  (0.887s,  144.29/s)  LR: 2.294e-04  Data: 0.008 (0.008)
2024-04-07 13:37:45,929 - train - INFO - Train: 80 [ 600/781 ( 77%)]  Loss:  4.169755 (3.9799)  Time: 0.743s,  172.33/s  (0.885s,  144.65/s)  LR: 2.294e-04  Data: 0.005 (0.008)
2024-04-07 13:38:24,136 - train - INFO - Train: 80 [ 650/781 ( 83%)]  Loss:  3.490968 (3.9798)  Time: 0.757s,  169.11/s  (0.876s,  146.18/s)  LR: 2.294e-04  Data: 0.005 (0.008)
2024-04-07 13:39:02,728 - train - INFO - Train: 80 [ 700/781 ( 90%)]  Loss:  4.608546 (3.9802)  Time: 0.764s,  167.48/s  (0.868s,  147.43/s)  LR: 2.294e-04  Data: 0.005 (0.008)
2024-04-07 13:39:40,932 - train - INFO - Train: 80 [ 750/781 ( 96%)]  Loss:  4.450961 (3.9787)  Time: 0.765s,  167.41/s  (0.861s,  148.61/s)  LR: 2.294e-04  Data: 0.005 (0.007)
2024-04-07 13:40:04,037 - train - INFO - Train: 80 [ 780/781 (100%)]  Loss:  4.301897 (3.9803)  Time: 0.757s,  169.03/s  (0.858s,  149.22/s)  LR: 2.294e-04  Data: 0.000 (0.007)
2024-04-07 13:40:04,037 - train - INFO - True
2024-04-07 13:40:04,039 - train - INFO - alphas:tensor([0.0048, 0.0062, 0.0392, 0.3397, 0.6101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,052 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,052 - train - INFO - True
2024-04-07 13:40:04,053 - train - INFO - alphas:tensor([0.1043, 0.0180, 0.0380, 0.1368, 0.7029], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,066 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,066 - train - INFO - True
2024-04-07 13:40:04,067 - train - INFO - alphas:tensor([0.4947, 0.0859, 0.0631, 0.1412, 0.2151], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,091 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,091 - train - INFO - True
2024-04-07 13:40:04,092 - train - INFO - alphas:tensor([0.4189, 0.0192, 0.0337, 0.1323, 0.3959], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,113 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,114 - train - INFO - True
2024-04-07 13:40:04,114 - train - INFO - alphas:tensor([0.2567, 0.0129, 0.0476, 0.1447, 0.5381], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,125 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,125 - train - INFO - True
2024-04-07 13:40:04,126 - train - INFO - alphas:tensor([0.3589, 0.0083, 0.0263, 0.1027, 0.5038], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,136 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,136 - train - INFO - True
2024-04-07 13:40:04,136 - train - INFO - alphas:tensor([0.4961, 0.0308, 0.0205, 0.1219, 0.3308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,155 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,155 - train - INFO - True
2024-04-07 13:40:04,156 - train - INFO - alphas:tensor([0.3816, 0.0143, 0.0084, 0.1032, 0.4925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,165 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,165 - train - INFO - True
2024-04-07 13:40:04,166 - train - INFO - alphas:tensor([0.3156, 0.0099, 0.0305, 0.1161, 0.5280], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,175 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,175 - train - INFO - True
2024-04-07 13:40:04,176 - train - INFO - alphas:tensor([0.4223, 0.0066, 0.0241, 0.0811, 0.4659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,185 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,185 - train - INFO - True
2024-04-07 13:40:04,185 - train - INFO - alphas:tensor([0.4058, 0.0170, 0.0164, 0.1143, 0.4465], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,194 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,194 - train - INFO - True
2024-04-07 13:40:04,194 - train - INFO - alphas:tensor([0.3138, 0.0067, 0.0076, 0.1206, 0.5513], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,203 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,203 - train - INFO - True
2024-04-07 13:40:04,204 - train - INFO - alphas:tensor([0.3230, 0.0061, 0.0222, 0.1050, 0.5437], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,212 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,212 - train - INFO - True
2024-04-07 13:40:04,213 - train - INFO - alphas:tensor([0.4232, 0.0028, 0.0153, 0.0622, 0.4966], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,221 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,221 - train - INFO - True
2024-04-07 13:40:04,222 - train - INFO - alphas:tensor([0.3236, 0.0202, 0.0128, 0.1242, 0.5191], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,230 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,230 - train - INFO - True
2024-04-07 13:40:04,230 - train - INFO - alphas:tensor([0.2320, 0.0043, 0.0037, 0.1366, 0.6235], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,239 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,239 - train - INFO - True
2024-04-07 13:40:04,239 - train - INFO - alphas:tensor([0.3100, 0.0064, 0.0164, 0.0967, 0.5704], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,248 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,248 - train - INFO - True
2024-04-07 13:40:04,248 - train - INFO - alphas:tensor([0.4115, 0.0022, 0.0130, 0.0576, 0.5157], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,257 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,257 - train - INFO - True
2024-04-07 13:40:04,257 - train - INFO - alphas:tensor([0.3314, 0.0061, 0.0061, 0.1105, 0.5459], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,266 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,266 - train - INFO - True
2024-04-07 13:40:04,266 - train - INFO - alphas:tensor([0.2346, 0.0027, 0.0024, 0.1129, 0.6473], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,275 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,275 - train - INFO - True
2024-04-07 13:40:04,275 - train - INFO - alphas:tensor([0.2668, 0.0037, 0.0146, 0.0941, 0.6207], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,284 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,284 - train - INFO - True
2024-04-07 13:40:04,285 - train - INFO - alphas:tensor([0.3911, 0.0018, 0.0112, 0.0488, 0.5471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,293 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,293 - train - INFO - True
2024-04-07 13:40:04,294 - train - INFO - alphas:tensor([0.3818, 0.0089, 0.0053, 0.0806, 0.5234], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,302 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,302 - train - INFO - True
2024-04-07 13:40:04,303 - train - INFO - alphas:tensor([0.2792, 0.0020, 0.0014, 0.0768, 0.6406], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,311 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,311 - train - INFO - True
2024-04-07 13:40:04,311 - train - INFO - alphas:tensor([0.2586, 0.0030, 0.0126, 0.0847, 0.6412], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,320 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,320 - train - INFO - True
2024-04-07 13:40:04,320 - train - INFO - alphas:tensor([0.3818, 0.0017, 0.0104, 0.0402, 0.5658], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,329 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,329 - train - INFO - True
2024-04-07 13:40:04,330 - train - INFO - alphas:tensor([0.4193, 0.0027, 0.0040, 0.0711, 0.5029], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,338 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,338 - train - INFO - True
2024-04-07 13:40:04,339 - train - INFO - alphas:tensor([0.3115, 0.0020, 0.0011, 0.0589, 0.6264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,347 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,347 - train - INFO - True
2024-04-07 13:40:04,348 - train - INFO - alphas:tensor([0.2371, 0.0024, 0.0119, 0.0853, 0.6633], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,356 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,356 - train - INFO - True
2024-04-07 13:40:04,357 - train - INFO - alphas:tensor([0.3534, 0.0009, 0.0077, 0.0441, 0.5939], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,365 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,365 - train - INFO - True
2024-04-07 13:40:04,366 - train - INFO - alphas:tensor([0.4512, 0.0026, 0.0034, 0.0600, 0.4828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,374 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,374 - train - INFO - True
2024-04-07 13:40:04,375 - train - INFO - alphas:tensor([0.3510, 0.0011, 0.0016, 0.0640, 0.5824], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,383 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,383 - train - INFO - True
2024-04-07 13:40:04,384 - train - INFO - alphas:tensor([0.2174, 0.0021, 0.0105, 0.0732, 0.6968], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,392 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,392 - train - INFO - True
2024-04-07 13:40:04,393 - train - INFO - alphas:tensor([3.1585e-01, 5.6100e-04, 5.0723e-03, 3.2795e-02, 6.4572e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,401 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,401 - train - INFO - True
2024-04-07 13:40:04,402 - train - INFO - alphas:tensor([0.4320, 0.0041, 0.0039, 0.0672, 0.4927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,410 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,410 - train - INFO - True
2024-04-07 13:40:04,411 - train - INFO - alphas:tensor([0.3718, 0.0010, 0.0018, 0.0628, 0.5627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,419 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,419 - train - INFO - True
2024-04-07 13:40:04,420 - train - INFO - alphas:tensor([0.6238, 0.0296, 0.1041, 0.2424], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:40:04,436 - train - INFO - tau:0.45660974774391455
2024-04-07 13:40:04,436 - train - INFO - avg block size:14.378378378378379
2024-04-07 13:40:04,436 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 13:40:04,436 - train - INFO - lasso_alpha:9.849732675807631e-05
2024-04-07 13:40:04,690 - train - INFO - Test: [   0/78]  Time: 0.251 (0.251)  Loss:  0.8530 (0.8530)  Acc@1: 82.8125 (82.8125)  Acc@5: 94.5312 (94.5312)
2024-04-07 13:40:08,987 - train - INFO - Test: [  50/78]  Time: 0.083 (0.089)  Loss:  1.8945 (1.6642)  Acc@1: 56.2500 (61.2132)  Acc@5: 80.4688 (83.6550)
2024-04-07 13:40:11,272 - train - INFO - Test: [  78/78]  Time: 0.052 (0.086)  Loss:  1.7314 (1.6944)  Acc@1: 62.5000 (60.5000)  Acc@5: 93.7500 (83.1300)
2024-04-07 13:40:12,629 - train - INFO - Train: 81 [   0/781 (  0%)]  Loss:  4.246025 (4.2460)  Time: 1.294s,   98.95/s  (1.294s,   98.95/s)  LR: 2.243e-04  Data: 0.179 (0.179)
2024-04-07 13:40:52,271 - train - INFO - Train: 81 [  50/781 (  6%)]  Loss:  4.005590 (4.0689)  Time: 0.761s,  168.11/s  (0.803s,  159.48/s)  LR: 2.243e-04  Data: 0.005 (0.010)
2024-04-07 13:41:31,316 - train - INFO - Train: 81 [ 100/781 ( 13%)]  Loss:  3.571662 (4.0312)  Time: 0.808s,  158.34/s  (0.792s,  161.64/s)  LR: 2.243e-04  Data: 0.008 (0.008)
2024-04-07 13:42:10,485 - train - INFO - Train: 81 [ 150/781 ( 19%)]  Loss:  4.445730 (3.9756)  Time: 0.790s,  162.05/s  (0.789s,  162.22/s)  LR: 2.243e-04  Data: 0.005 (0.007)
2024-04-07 13:42:55,162 - train - INFO - Train: 81 [ 200/781 ( 26%)]  Loss:  3.267506 (3.9604)  Time: 0.787s,  162.58/s  (0.815s,  157.05/s)  LR: 2.243e-04  Data: 0.005 (0.007)
2024-04-07 13:43:41,206 - train - INFO - Train: 81 [ 250/781 ( 32%)]  Loss:  4.469665 (3.9608)  Time: 1.041s,  122.92/s  (0.836s,  153.09/s)  LR: 2.243e-04  Data: 0.006 (0.008)
2024-04-07 13:44:25,751 - train - INFO - Train: 81 [ 300/781 ( 38%)]  Loss:  4.258156 (3.9626)  Time: 0.851s,  150.36/s  (0.845s,  151.44/s)  LR: 2.243e-04  Data: 0.009 (0.008)
2024-04-07 13:45:10,501 - train - INFO - Train: 81 [ 350/781 ( 45%)]  Loss:  3.425495 (3.9711)  Time: 0.829s,  154.38/s  (0.852s,  150.18/s)  LR: 2.243e-04  Data: 0.007 (0.008)
2024-04-07 13:45:54,862 - train - INFO - Train: 81 [ 400/781 ( 51%)]  Loss:  3.973636 (3.9653)  Time: 0.843s,  151.80/s  (0.857s,  149.42/s)  LR: 2.243e-04  Data: 0.007 (0.008)
2024-04-07 13:46:38,410 - train - INFO - Train: 81 [ 450/781 ( 58%)]  Loss:  3.653001 (3.9673)  Time: 0.812s,  157.62/s  (0.858s,  149.14/s)  LR: 2.243e-04  Data: 0.004 (0.008)
2024-04-07 13:47:21,491 - train - INFO - Train: 81 [ 500/781 ( 64%)]  Loss:  3.964537 (3.9706)  Time: 1.073s,  119.25/s  (0.859s,  149.09/s)  LR: 2.243e-04  Data: 0.009 (0.008)
2024-04-07 13:48:06,436 - train - INFO - Train: 81 [ 550/781 ( 71%)]  Loss:  4.298105 (3.9740)  Time: 0.877s,  145.88/s  (0.862s,  148.45/s)  LR: 2.243e-04  Data: 0.008 (0.008)
2024-04-07 13:48:50,129 - train - INFO - Train: 81 [ 600/781 ( 77%)]  Loss:  4.327983 (3.9801)  Time: 0.822s,  155.76/s  (0.863s,  148.29/s)  LR: 2.243e-04  Data: 0.006 (0.008)
2024-04-07 13:49:35,320 - train - INFO - Train: 81 [ 650/781 ( 83%)]  Loss:  4.296692 (3.9847)  Time: 0.824s,  155.35/s  (0.866s,  147.75/s)  LR: 2.243e-04  Data: 0.007 (0.008)
2024-04-07 13:50:20,487 - train - INFO - Train: 81 [ 700/781 ( 90%)]  Loss:  3.230883 (3.9773)  Time: 0.922s,  138.90/s  (0.869s,  147.31/s)  LR: 2.243e-04  Data: 0.005 (0.008)
2024-04-07 13:51:05,331 - train - INFO - Train: 81 [ 750/781 ( 96%)]  Loss:  4.503314 (3.9835)  Time: 0.845s,  151.54/s  (0.871s,  146.99/s)  LR: 2.243e-04  Data: 0.007 (0.008)
2024-04-07 13:51:32,139 - train - INFO - Train: 81 [ 780/781 (100%)]  Loss:  3.543275 (3.9803)  Time: 0.793s,  161.39/s  (0.872s,  146.84/s)  LR: 2.243e-04  Data: 0.000 (0.008)
2024-04-07 13:51:32,139 - train - INFO - True
2024-04-07 13:51:32,140 - train - INFO - alphas:tensor([0.0044, 0.0059, 0.0383, 0.3421, 0.6093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,151 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,151 - train - INFO - True
2024-04-07 13:51:32,152 - train - INFO - alphas:tensor([0.1058, 0.0179, 0.0378, 0.1360, 0.7024], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,163 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,163 - train - INFO - True
2024-04-07 13:51:32,164 - train - INFO - alphas:tensor([0.4958, 0.0852, 0.0621, 0.1406, 0.2163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,184 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,184 - train - INFO - True
2024-04-07 13:51:32,185 - train - INFO - alphas:tensor([0.4205, 0.0185, 0.0329, 0.1307, 0.3973], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,204 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,204 - train - INFO - True
2024-04-07 13:51:32,205 - train - INFO - alphas:tensor([0.2579, 0.0126, 0.0470, 0.1431, 0.5394], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,214 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,214 - train - INFO - True
2024-04-07 13:51:32,215 - train - INFO - alphas:tensor([0.3625, 0.0080, 0.0256, 0.1003, 0.5036], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,224 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,224 - train - INFO - True
2024-04-07 13:51:32,225 - train - INFO - alphas:tensor([0.4993, 0.0300, 0.0197, 0.1201, 0.3309], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,242 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,242 - train - INFO - True
2024-04-07 13:51:32,243 - train - INFO - alphas:tensor([0.3847, 0.0139, 0.0079, 0.1018, 0.4916], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,251 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,251 - train - INFO - True
2024-04-07 13:51:32,252 - train - INFO - alphas:tensor([0.3163, 0.0096, 0.0295, 0.1141, 0.5306], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,261 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,261 - train - INFO - True
2024-04-07 13:51:32,261 - train - INFO - alphas:tensor([0.4244, 0.0062, 0.0232, 0.0796, 0.4666], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,270 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,270 - train - INFO - True
2024-04-07 13:51:32,270 - train - INFO - alphas:tensor([0.4097, 0.0167, 0.0157, 0.1127, 0.4452], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,279 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,279 - train - INFO - True
2024-04-07 13:51:32,280 - train - INFO - alphas:tensor([0.3201, 0.0065, 0.0072, 0.1184, 0.5478], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,288 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,288 - train - INFO - True
2024-04-07 13:51:32,289 - train - INFO - alphas:tensor([0.3229, 0.0059, 0.0216, 0.1033, 0.5463], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,300 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,300 - train - INFO - True
2024-04-07 13:51:32,301 - train - INFO - alphas:tensor([0.4200, 0.0026, 0.0147, 0.0611, 0.5015], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,312 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,312 - train - INFO - True
2024-04-07 13:51:32,312 - train - INFO - alphas:tensor([0.3241, 0.0197, 0.0123, 0.1230, 0.5209], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,323 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,323 - train - INFO - True
2024-04-07 13:51:32,323 - train - INFO - alphas:tensor([0.2341, 0.0041, 0.0035, 0.1350, 0.6233], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,333 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,333 - train - INFO - True
2024-04-07 13:51:32,334 - train - INFO - alphas:tensor([0.3102, 0.0061, 0.0158, 0.0952, 0.5727], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,343 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,344 - train - INFO - True
2024-04-07 13:51:32,344 - train - INFO - alphas:tensor([0.4166, 0.0021, 0.0124, 0.0565, 0.5124], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,353 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,354 - train - INFO - True
2024-04-07 13:51:32,354 - train - INFO - alphas:tensor([0.3368, 0.0058, 0.0058, 0.1085, 0.5431], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,363 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,363 - train - INFO - True
2024-04-07 13:51:32,364 - train - INFO - alphas:tensor([0.2403, 0.0027, 0.0023, 0.1114, 0.6433], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,373 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,373 - train - INFO - True
2024-04-07 13:51:32,374 - train - INFO - alphas:tensor([0.2688, 0.0036, 0.0143, 0.0922, 0.6211], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,383 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,383 - train - INFO - True
2024-04-07 13:51:32,383 - train - INFO - alphas:tensor([0.3959, 0.0017, 0.0109, 0.0474, 0.5441], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,392 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,392 - train - INFO - True
2024-04-07 13:51:32,392 - train - INFO - alphas:tensor([0.3871, 0.0086, 0.0051, 0.0790, 0.5203], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,401 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,401 - train - INFO - True
2024-04-07 13:51:32,402 - train - INFO - alphas:tensor([0.2833, 0.0019, 0.0013, 0.0752, 0.6383], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,412 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,412 - train - INFO - True
2024-04-07 13:51:32,413 - train - INFO - alphas:tensor([0.2578, 0.0028, 0.0122, 0.0828, 0.6444], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,421 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,421 - train - INFO - True
2024-04-07 13:51:32,422 - train - INFO - alphas:tensor([0.3838, 0.0016, 0.0099, 0.0387, 0.5660], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,432 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,432 - train - INFO - True
2024-04-07 13:51:32,433 - train - INFO - alphas:tensor([0.4213, 0.0026, 0.0037, 0.0695, 0.5029], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,444 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,444 - train - INFO - True
2024-04-07 13:51:32,445 - train - INFO - alphas:tensor([0.3137, 0.0019, 0.0010, 0.0578, 0.6255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,455 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,455 - train - INFO - True
2024-04-07 13:51:32,456 - train - INFO - alphas:tensor([0.2369, 0.0023, 0.0115, 0.0838, 0.6656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,466 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,466 - train - INFO - True
2024-04-07 13:51:32,467 - train - INFO - alphas:tensor([0.3560, 0.0008, 0.0075, 0.0431, 0.5927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,476 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,476 - train - INFO - True
2024-04-07 13:51:32,477 - train - INFO - alphas:tensor([0.4540, 0.0024, 0.0032, 0.0589, 0.4815], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,486 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,486 - train - INFO - True
2024-04-07 13:51:32,487 - train - INFO - alphas:tensor([0.3554, 0.0010, 0.0014, 0.0624, 0.5798], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,496 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,496 - train - INFO - True
2024-04-07 13:51:32,497 - train - INFO - alphas:tensor([0.2174, 0.0020, 0.0102, 0.0717, 0.6988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,506 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,506 - train - INFO - True
2024-04-07 13:51:32,507 - train - INFO - alphas:tensor([3.2088e-01, 5.1975e-04, 4.8081e-03, 3.1522e-02, 6.4227e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,515 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,515 - train - INFO - True
2024-04-07 13:51:32,516 - train - INFO - alphas:tensor([0.4333, 0.0039, 0.0037, 0.0657, 0.4935], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,525 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,525 - train - INFO - True
2024-04-07 13:51:32,525 - train - INFO - alphas:tensor([0.3723, 0.0009, 0.0017, 0.0611, 0.5640], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,534 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,534 - train - INFO - True
2024-04-07 13:51:32,535 - train - INFO - alphas:tensor([0.6230, 0.0293, 0.1036, 0.2441], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 13:51:32,552 - train - INFO - tau:0.4520436502664754
2024-04-07 13:51:32,552 - train - INFO - avg block size:14.378378378378379
2024-04-07 13:51:32,552 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 13:51:32,801 - train - INFO - Test: [   0/78]  Time: 0.245 (0.245)  Loss:  0.8325 (0.8325)  Acc@1: 83.5938 (83.5938)  Acc@5: 94.5312 (94.5312)
2024-04-07 13:51:37,903 - train - INFO - Test: [  50/78]  Time: 0.101 (0.105)  Loss:  1.7793 (1.6566)  Acc@1: 59.3750 (61.0294)  Acc@5: 84.3750 (83.6857)
2024-04-07 13:51:40,267 - train - INFO - Test: [  78/78]  Time: 0.057 (0.098)  Loss:  1.7627 (1.6879)  Acc@1: 56.2500 (60.6600)  Acc@5: 100.0000 (83.1000)
2024-04-07 13:51:41,590 - train - INFO - Train: 82 [   0/781 (  0%)]  Loss:  3.541863 (3.5419)  Time: 1.254s,  102.09/s  (1.254s,  102.09/s)  LR: 2.192e-04  Data: 0.162 (0.162)
2024-04-07 13:52:25,496 - train - INFO - Train: 82 [  50/781 (  6%)]  Loss:  3.702096 (4.0166)  Time: 0.846s,  151.25/s  (0.885s,  144.56/s)  LR: 2.192e-04  Data: 0.007 (0.011)
2024-04-07 13:53:10,630 - train - INFO - Train: 82 [ 100/781 ( 13%)]  Loss:  4.448444 (3.9839)  Time: 0.851s,  150.48/s  (0.894s,  143.18/s)  LR: 2.192e-04  Data: 0.009 (0.009)
2024-04-07 13:53:55,197 - train - INFO - Train: 82 [ 150/781 ( 19%)]  Loss:  4.227280 (3.9779)  Time: 0.856s,  149.53/s  (0.893s,  143.32/s)  LR: 2.192e-04  Data: 0.009 (0.009)
2024-04-07 13:54:39,700 - train - INFO - Train: 82 [ 200/781 ( 26%)]  Loss:  4.024899 (3.9801)  Time: 0.844s,  151.71/s  (0.892s,  143.45/s)  LR: 2.192e-04  Data: 0.008 (0.009)
2024-04-07 13:55:23,412 - train - INFO - Train: 82 [ 250/781 ( 32%)]  Loss:  3.431511 (3.9904)  Time: 0.873s,  146.69/s  (0.889s,  144.03/s)  LR: 2.192e-04  Data: 0.008 (0.008)
2024-04-07 13:56:08,566 - train - INFO - Train: 82 [ 300/781 ( 38%)]  Loss:  4.443632 (3.9825)  Time: 0.866s,  147.88/s  (0.891s,  143.64/s)  LR: 2.192e-04  Data: 0.004 (0.008)
2024-04-07 13:56:56,381 - train - INFO - Train: 82 [ 350/781 ( 45%)]  Loss:  4.230278 (3.9698)  Time: 0.862s,  148.57/s  (0.900s,  142.16/s)  LR: 2.192e-04  Data: 0.009 (0.008)
2024-04-07 13:57:39,658 - train - INFO - Train: 82 [ 400/781 ( 51%)]  Loss:  3.747000 (3.9626)  Time: 0.842s,  152.05/s  (0.896s,  142.85/s)  LR: 2.192e-04  Data: 0.007 (0.008)
2024-04-07 13:58:23,188 - train - INFO - Train: 82 [ 450/781 ( 58%)]  Loss:  3.338426 (3.9585)  Time: 0.828s,  154.55/s  (0.893s,  143.30/s)  LR: 2.192e-04  Data: 0.006 (0.008)
2024-04-07 13:59:07,518 - train - INFO - Train: 82 [ 500/781 ( 64%)]  Loss:  4.319140 (3.9678)  Time: 0.830s,  154.30/s  (0.893s,  143.41/s)  LR: 2.192e-04  Data: 0.007 (0.008)
2024-04-07 13:59:51,105 - train - INFO - Train: 82 [ 550/781 ( 71%)]  Loss:  3.630510 (3.9640)  Time: 1.086s,  117.86/s  (0.891s,  143.71/s)  LR: 2.192e-04  Data: 0.009 (0.008)
2024-04-07 14:00:36,121 - train - INFO - Train: 82 [ 600/781 ( 77%)]  Loss:  3.880960 (3.9678)  Time: 0.852s,  150.16/s  (0.891s,  143.59/s)  LR: 2.192e-04  Data: 0.008 (0.008)
2024-04-07 14:01:22,070 - train - INFO - Train: 82 [ 650/781 ( 83%)]  Loss:  4.468597 (3.9685)  Time: 0.843s,  151.88/s  (0.894s,  143.25/s)  LR: 2.192e-04  Data: 0.008 (0.008)
2024-04-07 14:02:06,319 - train - INFO - Train: 82 [ 700/781 ( 90%)]  Loss:  3.802878 (3.9627)  Time: 0.843s,  151.83/s  (0.893s,  143.34/s)  LR: 2.192e-04  Data: 0.008 (0.008)
2024-04-07 14:02:49,797 - train - INFO - Train: 82 [ 750/781 ( 96%)]  Loss:  3.503263 (3.9649)  Time: 0.845s,  151.42/s  (0.891s,  143.60/s)  LR: 2.192e-04  Data: 0.009 (0.008)
2024-04-07 14:03:15,806 - train - INFO - Train: 82 [ 780/781 (100%)]  Loss:  3.691179 (3.9671)  Time: 1.101s,  116.30/s  (0.890s,  143.75/s)  LR: 2.192e-04  Data: 0.000 (0.008)
2024-04-07 14:03:15,808 - train - INFO - True
2024-04-07 14:03:15,810 - train - INFO - alphas:tensor([0.0040, 0.0055, 0.0374, 0.3439, 0.6091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:15,834 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:15,834 - train - INFO - True
2024-04-07 14:03:15,835 - train - INFO - alphas:tensor([0.1063, 0.0176, 0.0374, 0.1338, 0.7048], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:15,856 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:15,856 - train - INFO - True
2024-04-07 14:03:15,857 - train - INFO - alphas:tensor([0.4976, 0.0839, 0.0611, 0.1403, 0.2171], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:15,893 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:15,893 - train - INFO - True
2024-04-07 14:03:15,894 - train - INFO - alphas:tensor([0.4214, 0.0180, 0.0321, 0.1294, 0.3992], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:15,923 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:15,923 - train - INFO - True
2024-04-07 14:03:15,924 - train - INFO - alphas:tensor([0.2575, 0.0122, 0.0467, 0.1418, 0.5417], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:15,937 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:15,937 - train - INFO - True
2024-04-07 14:03:15,938 - train - INFO - alphas:tensor([0.3639, 0.0077, 0.0247, 0.0986, 0.5051], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:15,951 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:15,951 - train - INFO - True
2024-04-07 14:03:15,952 - train - INFO - alphas:tensor([0.5019, 0.0294, 0.0189, 0.1185, 0.3313], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:15,975 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:15,975 - train - INFO - True
2024-04-07 14:03:15,976 - train - INFO - alphas:tensor([0.3859, 0.0134, 0.0074, 0.1002, 0.4931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:15,987 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:15,987 - train - INFO - True
2024-04-07 14:03:15,988 - train - INFO - alphas:tensor([0.3156, 0.0092, 0.0287, 0.1126, 0.5338], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:15,999 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:15,999 - train - INFO - True
2024-04-07 14:03:15,999 - train - INFO - alphas:tensor([0.4223, 0.0059, 0.0224, 0.0781, 0.4713], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,010 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,010 - train - INFO - True
2024-04-07 14:03:16,011 - train - INFO - alphas:tensor([0.4098, 0.0164, 0.0150, 0.1122, 0.4467], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,022 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,022 - train - INFO - True
2024-04-07 14:03:16,023 - train - INFO - alphas:tensor([0.3195, 0.0062, 0.0069, 0.1175, 0.5499], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,033 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,033 - train - INFO - True
2024-04-07 14:03:16,034 - train - INFO - alphas:tensor([0.3234, 0.0056, 0.0211, 0.1013, 0.5485], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,044 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,044 - train - INFO - True
2024-04-07 14:03:16,045 - train - INFO - alphas:tensor([0.4250, 0.0024, 0.0142, 0.0593, 0.4990], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,055 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,055 - train - INFO - True
2024-04-07 14:03:16,055 - train - INFO - alphas:tensor([0.3304, 0.0193, 0.0119, 0.1218, 0.5167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,066 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,066 - train - INFO - True
2024-04-07 14:03:16,067 - train - INFO - alphas:tensor([0.2371, 0.0040, 0.0033, 0.1343, 0.6213], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,076 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,076 - train - INFO - True
2024-04-07 14:03:16,077 - train - INFO - alphas:tensor([0.3111, 0.0059, 0.0151, 0.0935, 0.5743], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,086 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,086 - train - INFO - True
2024-04-07 14:03:16,086 - train - INFO - alphas:tensor([0.4183, 0.0020, 0.0119, 0.0552, 0.5126], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,095 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,095 - train - INFO - True
2024-04-07 14:03:16,096 - train - INFO - alphas:tensor([0.3411, 0.0056, 0.0054, 0.1068, 0.5410], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,105 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,105 - train - INFO - True
2024-04-07 14:03:16,105 - train - INFO - alphas:tensor([0.2436, 0.0025, 0.0022, 0.1099, 0.6418], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,114 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,114 - train - INFO - True
2024-04-07 14:03:16,114 - train - INFO - alphas:tensor([0.2677, 0.0034, 0.0139, 0.0912, 0.6239], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,123 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,123 - train - INFO - True
2024-04-07 14:03:16,123 - train - INFO - alphas:tensor([0.3948, 0.0015, 0.0104, 0.0462, 0.5471], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,132 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,132 - train - INFO - True
2024-04-07 14:03:16,132 - train - INFO - alphas:tensor([0.3917, 0.0083, 0.0048, 0.0771, 0.5182], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,142 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,142 - train - INFO - True
2024-04-07 14:03:16,143 - train - INFO - alphas:tensor([0.2837, 0.0018, 0.0012, 0.0742, 0.6391], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,154 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,154 - train - INFO - True
2024-04-07 14:03:16,155 - train - INFO - alphas:tensor([0.2581, 0.0027, 0.0118, 0.0809, 0.6466], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,164 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,165 - train - INFO - True
2024-04-07 14:03:16,165 - train - INFO - alphas:tensor([0.3840, 0.0015, 0.0095, 0.0377, 0.5674], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,175 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,175 - train - INFO - True
2024-04-07 14:03:16,175 - train - INFO - alphas:tensor([0.4260, 0.0024, 0.0034, 0.0675, 0.5006], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,185 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,185 - train - INFO - True
2024-04-07 14:03:16,185 - train - INFO - alphas:tensor([0.3169, 0.0018, 0.0010, 0.0566, 0.6237], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,194 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,194 - train - INFO - True
2024-04-07 14:03:16,195 - train - INFO - alphas:tensor([0.2388, 0.0022, 0.0109, 0.0821, 0.6659], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,204 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,204 - train - INFO - True
2024-04-07 14:03:16,204 - train - INFO - alphas:tensor([0.3575, 0.0008, 0.0071, 0.0419, 0.5928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,213 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,213 - train - INFO - True
2024-04-07 14:03:16,214 - train - INFO - alphas:tensor([0.4553, 0.0023, 0.0030, 0.0574, 0.4819], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,222 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,222 - train - INFO - True
2024-04-07 14:03:16,223 - train - INFO - alphas:tensor([0.3573, 0.0009, 0.0013, 0.0610, 0.5795], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,231 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,231 - train - INFO - True
2024-04-07 14:03:16,232 - train - INFO - alphas:tensor([0.2183, 0.0019, 0.0099, 0.0700, 0.6999], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,240 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,240 - train - INFO - True
2024-04-07 14:03:16,241 - train - INFO - alphas:tensor([3.2179e-01, 4.8058e-04, 4.4630e-03, 3.0583e-02, 6.4269e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,249 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,249 - train - INFO - True
2024-04-07 14:03:16,250 - train - INFO - alphas:tensor([0.4356, 0.0037, 0.0034, 0.0642, 0.4931], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,258 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,258 - train - INFO - True
2024-04-07 14:03:16,259 - train - INFO - alphas:tensor([0.3742, 0.0009, 0.0015, 0.0595, 0.5639], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,267 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,267 - train - INFO - True
2024-04-07 14:03:16,268 - train - INFO - alphas:tensor([0.6237, 0.0287, 0.1028, 0.2448], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:03:16,287 - train - INFO - tau:0.44752321376381066
2024-04-07 14:03:16,287 - train - INFO - avg block size:14.378378378378379
2024-04-07 14:03:16,287 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 14:03:16,287 - train - INFO - lasso_alpha:8.954302432552392e-05
2024-04-07 14:03:16,533 - train - INFO - Test: [   0/78]  Time: 0.243 (0.243)  Loss:  0.9395 (0.9395)  Acc@1: 82.8125 (82.8125)  Acc@5: 93.7500 (93.7500)
2024-04-07 14:03:21,209 - train - INFO - Test: [  50/78]  Time: 0.089 (0.096)  Loss:  1.9258 (1.6617)  Acc@1: 53.9062 (60.9988)  Acc@5: 82.0312 (83.5478)
2024-04-07 14:03:23,615 - train - INFO - Test: [  78/78]  Time: 0.057 (0.093)  Loss:  1.5879 (1.6943)  Acc@1: 62.5000 (60.3300)  Acc@5: 93.7500 (82.9600)
2024-04-07 14:03:24,941 - train - INFO - Train: 83 [   0/781 (  0%)]  Loss:  4.244865 (4.2449)  Time: 1.247s,  102.67/s  (1.247s,  102.67/s)  LR: 2.141e-04  Data: 0.162 (0.162)
2024-04-07 14:04:09,230 - train - INFO - Train: 83 [  50/781 (  6%)]  Loss:  4.360168 (4.0095)  Time: 0.798s,  160.38/s  (0.893s,  143.36/s)  LR: 2.141e-04  Data: 0.006 (0.011)
2024-04-07 14:04:55,042 - train - INFO - Train: 83 [ 100/781 ( 13%)]  Loss:  3.468070 (3.9216)  Time: 1.041s,  123.01/s  (0.904s,  141.53/s)  LR: 2.141e-04  Data: 0.008 (0.009)
2024-04-07 14:05:39,703 - train - INFO - Train: 83 [ 150/781 ( 19%)]  Loss:  3.511370 (3.9170)  Time: 0.760s,  168.43/s  (0.901s,  142.11/s)  LR: 2.141e-04  Data: 0.005 (0.009)
2024-04-07 14:06:24,340 - train - INFO - Train: 83 [ 200/781 ( 26%)]  Loss:  4.184472 (3.9000)  Time: 0.807s,  158.52/s  (0.899s,  142.43/s)  LR: 2.141e-04  Data: 0.008 (0.008)
2024-04-07 14:07:09,827 - train - INFO - Train: 83 [ 250/781 ( 32%)]  Loss:  4.042116 (3.9201)  Time: 0.756s,  169.22/s  (0.901s,  142.08/s)  LR: 2.141e-04  Data: 0.006 (0.008)
2024-04-07 14:07:54,075 - train - INFO - Train: 83 [ 300/781 ( 38%)]  Loss:  4.375814 (3.9318)  Time: 0.809s,  158.16/s  (0.898s,  142.50/s)  LR: 2.141e-04  Data: 0.008 (0.008)
2024-04-07 14:08:37,876 - train - INFO - Train: 83 [ 350/781 ( 45%)]  Loss:  4.405714 (3.9366)  Time: 1.077s,  118.80/s  (0.895s,  143.00/s)  LR: 2.141e-04  Data: 0.007 (0.008)
2024-04-07 14:09:21,723 - train - INFO - Train: 83 [ 400/781 ( 51%)]  Loss:  3.977491 (3.9272)  Time: 0.835s,  153.35/s  (0.893s,  143.37/s)  LR: 2.141e-04  Data: 0.007 (0.008)
2024-04-07 14:10:06,366 - train - INFO - Train: 83 [ 450/781 ( 58%)]  Loss:  4.443254 (3.9283)  Time: 0.842s,  151.99/s  (0.893s,  143.37/s)  LR: 2.141e-04  Data: 0.009 (0.008)
2024-04-07 14:10:49,360 - train - INFO - Train: 83 [ 500/781 ( 64%)]  Loss:  4.377573 (3.9267)  Time: 0.848s,  150.95/s  (0.890s,  143.90/s)  LR: 2.141e-04  Data: 0.009 (0.008)
2024-04-07 14:11:33,106 - train - INFO - Train: 83 [ 550/781 ( 71%)]  Loss:  3.984789 (3.9210)  Time: 0.835s,  153.38/s  (0.888s,  144.11/s)  LR: 2.141e-04  Data: 0.006 (0.008)
2024-04-07 14:12:17,129 - train - INFO - Train: 83 [ 600/781 ( 77%)]  Loss:  3.805755 (3.9183)  Time: 0.830s,  154.30/s  (0.888s,  144.22/s)  LR: 2.141e-04  Data: 0.007 (0.008)
2024-04-07 14:13:01,811 - train - INFO - Train: 83 [ 650/781 ( 83%)]  Loss:  4.511098 (3.9144)  Time: 1.006s,  127.21/s  (0.888s,  144.14/s)  LR: 2.141e-04  Data: 0.005 (0.008)
2024-04-07 14:13:46,942 - train - INFO - Train: 83 [ 700/781 ( 90%)]  Loss:  4.128618 (3.9117)  Time: 1.067s,  119.92/s  (0.889s,  143.97/s)  LR: 2.141e-04  Data: 0.009 (0.008)
2024-04-07 14:14:32,872 - train - INFO - Train: 83 [ 750/781 ( 96%)]  Loss:  3.604519 (3.9140)  Time: 0.844s,  151.60/s  (0.891s,  143.66/s)  LR: 2.141e-04  Data: 0.008 (0.008)
2024-04-07 14:15:00,079 - train - INFO - Train: 83 [ 780/781 (100%)]  Loss:  4.116831 (3.9085)  Time: 0.758s,  168.82/s  (0.892s,  143.56/s)  LR: 2.141e-04  Data: 0.000 (0.008)
2024-04-07 14:15:00,080 - train - INFO - True
2024-04-07 14:15:00,082 - train - INFO - alphas:tensor([0.0037, 0.0052, 0.0366, 0.3447, 0.6098], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,105 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,105 - train - INFO - True
2024-04-07 14:15:00,107 - train - INFO - alphas:tensor([0.1078, 0.0175, 0.0370, 0.1321, 0.7057], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,126 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,127 - train - INFO - True
2024-04-07 14:15:00,128 - train - INFO - alphas:tensor([0.5005, 0.0832, 0.0598, 0.1393, 0.2172], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,161 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,161 - train - INFO - True
2024-04-07 14:15:00,162 - train - INFO - alphas:tensor([0.4233, 0.0174, 0.0312, 0.1281, 0.4000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,191 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,191 - train - INFO - True
2024-04-07 14:15:00,192 - train - INFO - alphas:tensor([0.2590, 0.0120, 0.0458, 0.1398, 0.5434], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,206 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,206 - train - INFO - True
2024-04-07 14:15:00,207 - train - INFO - alphas:tensor([0.3653, 0.0073, 0.0240, 0.0974, 0.5060], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,219 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,219 - train - INFO - True
2024-04-07 14:15:00,220 - train - INFO - alphas:tensor([0.5059, 0.0287, 0.0182, 0.1167, 0.3306], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,243 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,243 - train - INFO - True
2024-04-07 14:15:00,244 - train - INFO - alphas:tensor([0.3896, 0.0130, 0.0071, 0.0989, 0.4914], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,255 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,255 - train - INFO - True
2024-04-07 14:15:00,256 - train - INFO - alphas:tensor([0.3158, 0.0089, 0.0279, 0.1114, 0.5360], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,267 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,267 - train - INFO - True
2024-04-07 14:15:00,267 - train - INFO - alphas:tensor([0.4278, 0.0056, 0.0215, 0.0761, 0.4690], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,278 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,278 - train - INFO - True
2024-04-07 14:15:00,278 - train - INFO - alphas:tensor([0.4163, 0.0160, 0.0144, 0.1099, 0.4434], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,288 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,288 - train - INFO - True
2024-04-07 14:15:00,289 - train - INFO - alphas:tensor([0.3245, 0.0060, 0.0065, 0.1160, 0.5470], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,299 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,299 - train - INFO - True
2024-04-07 14:15:00,299 - train - INFO - alphas:tensor([0.3243, 0.0053, 0.0203, 0.0998, 0.5502], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,309 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,309 - train - INFO - True
2024-04-07 14:15:00,309 - train - INFO - alphas:tensor([0.4277, 0.0023, 0.0136, 0.0581, 0.4982], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,319 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,319 - train - INFO - True
2024-04-07 14:15:00,319 - train - INFO - alphas:tensor([0.3346, 0.0190, 0.0115, 0.1197, 0.5153], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,328 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,328 - train - INFO - True
2024-04-07 14:15:00,329 - train - INFO - alphas:tensor([0.2416, 0.0039, 0.0031, 0.1329, 0.6185], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,337 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,338 - train - INFO - True
2024-04-07 14:15:00,338 - train - INFO - alphas:tensor([0.3121, 0.0057, 0.0145, 0.0920, 0.5758], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,347 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,347 - train - INFO - True
2024-04-07 14:15:00,347 - train - INFO - alphas:tensor([0.4189, 0.0018, 0.0114, 0.0539, 0.5138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,356 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,356 - train - INFO - True
2024-04-07 14:15:00,356 - train - INFO - alphas:tensor([0.3444, 0.0053, 0.0052, 0.1057, 0.5395], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,364 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,364 - train - INFO - True
2024-04-07 14:15:00,365 - train - INFO - alphas:tensor([0.2483, 0.0024, 0.0020, 0.1093, 0.6379], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,373 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,373 - train - INFO - True
2024-04-07 14:15:00,374 - train - INFO - alphas:tensor([0.2700, 0.0033, 0.0133, 0.0885, 0.6250], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,382 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,382 - train - INFO - True
2024-04-07 14:15:00,382 - train - INFO - alphas:tensor([0.4015, 0.0014, 0.0099, 0.0448, 0.5424], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,390 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,390 - train - INFO - True
2024-04-07 14:15:00,391 - train - INFO - alphas:tensor([0.3964, 0.0079, 0.0045, 0.0752, 0.5160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,399 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,399 - train - INFO - True
2024-04-07 14:15:00,400 - train - INFO - alphas:tensor([0.2908, 0.0017, 0.0012, 0.0725, 0.6338], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,410 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,410 - train - INFO - True
2024-04-07 14:15:00,410 - train - INFO - alphas:tensor([0.2601, 0.0026, 0.0114, 0.0790, 0.6470], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,421 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,421 - train - INFO - True
2024-04-07 14:15:00,422 - train - INFO - alphas:tensor([0.3875, 0.0014, 0.0091, 0.0365, 0.5655], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,432 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,432 - train - INFO - True
2024-04-07 14:15:00,433 - train - INFO - alphas:tensor([0.4294, 0.0023, 0.0032, 0.0656, 0.4996], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,443 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,443 - train - INFO - True
2024-04-07 14:15:00,444 - train - INFO - alphas:tensor([0.3221, 0.0017, 0.0009, 0.0552, 0.6201], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,453 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,453 - train - INFO - True
2024-04-07 14:15:00,454 - train - INFO - alphas:tensor([0.2397, 0.0021, 0.0105, 0.0801, 0.6676], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,463 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,463 - train - INFO - True
2024-04-07 14:15:00,464 - train - INFO - alphas:tensor([0.3607, 0.0007, 0.0068, 0.0408, 0.5911], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,473 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,473 - train - INFO - True
2024-04-07 14:15:00,473 - train - INFO - alphas:tensor([0.4615, 0.0021, 0.0028, 0.0557, 0.4780], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,482 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,482 - train - INFO - True
2024-04-07 14:15:00,483 - train - INFO - alphas:tensor([0.3636, 0.0009, 0.0012, 0.0595, 0.5748], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,491 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,491 - train - INFO - True
2024-04-07 14:15:00,492 - train - INFO - alphas:tensor([0.2194, 0.0018, 0.0096, 0.0685, 0.7007], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,500 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,500 - train - INFO - True
2024-04-07 14:15:00,501 - train - INFO - alphas:tensor([3.2403e-01, 4.3732e-04, 4.2663e-03, 2.9370e-02, 6.4190e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,509 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,509 - train - INFO - True
2024-04-07 14:15:00,510 - train - INFO - alphas:tensor([0.4419, 0.0035, 0.0032, 0.0626, 0.4888], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,520 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,520 - train - INFO - True
2024-04-07 14:15:00,521 - train - INFO - alphas:tensor([0.3790, 0.0008, 0.0014, 0.0577, 0.5612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,531 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,531 - train - INFO - True
2024-04-07 14:15:00,532 - train - INFO - alphas:tensor([0.6241, 0.0280, 0.1021, 0.2457], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:15:00,552 - train - INFO - tau:0.44304798162617254
2024-04-07 14:15:00,552 - train - INFO - avg block size:14.378378378378379
2024-04-07 14:15:00,552 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 14:15:00,758 - train - INFO - Test: [   0/78]  Time: 0.202 (0.202)  Loss:  0.9087 (0.9087)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 14:15:05,088 - train - INFO - Test: [  50/78]  Time: 0.084 (0.089)  Loss:  1.8330 (1.6560)  Acc@1: 57.0312 (61.1366)  Acc@5: 83.5938 (83.9154)
2024-04-07 14:15:07,487 - train - INFO - Test: [  78/78]  Time: 0.058 (0.088)  Loss:  1.6641 (1.6846)  Acc@1: 56.2500 (60.6900)  Acc@5: 100.0000 (83.4700)
2024-04-07 14:15:08,841 - train - INFO - Train: 84 [   0/781 (  0%)]  Loss:  3.558265 (3.5583)  Time: 1.283s,   99.78/s  (1.283s,   99.78/s)  LR: 2.091e-04  Data: 0.192 (0.192)
2024-04-07 14:15:53,260 - train - INFO - Train: 84 [  50/781 (  6%)]  Loss:  3.446961 (3.9949)  Time: 1.090s,  117.48/s  (0.896s,  142.85/s)  LR: 2.091e-04  Data: 0.008 (0.012)
2024-04-07 14:16:36,333 - train - INFO - Train: 84 [ 100/781 ( 13%)]  Loss:  4.569144 (3.9610)  Time: 1.019s,  125.67/s  (0.879s,  145.63/s)  LR: 2.091e-04  Data: 0.005 (0.010)
2024-04-07 14:17:20,975 - train - INFO - Train: 84 [ 150/781 ( 19%)]  Loss:  4.383973 (3.9730)  Time: 0.848s,  150.89/s  (0.884s,  144.87/s)  LR: 2.091e-04  Data: 0.009 (0.009)
2024-04-07 14:18:05,361 - train - INFO - Train: 84 [ 200/781 ( 26%)]  Loss:  4.094141 (3.9608)  Time: 0.850s,  150.62/s  (0.885s,  144.71/s)  LR: 2.091e-04  Data: 0.008 (0.009)
2024-04-07 14:18:49,865 - train - INFO - Train: 84 [ 250/781 ( 32%)]  Loss:  3.983530 (3.9543)  Time: 0.848s,  150.86/s  (0.886s,  144.53/s)  LR: 2.091e-04  Data: 0.008 (0.008)
2024-04-07 14:19:33,717 - train - INFO - Train: 84 [ 300/781 ( 38%)]  Loss:  3.764183 (3.9528)  Time: 0.874s,  146.50/s  (0.884s,  144.76/s)  LR: 2.091e-04  Data: 0.009 (0.008)
2024-04-07 14:20:18,835 - train - INFO - Train: 84 [ 350/781 ( 45%)]  Loss:  3.465050 (3.9524)  Time: 0.844s,  151.72/s  (0.887s,  144.34/s)  LR: 2.091e-04  Data: 0.009 (0.008)
2024-04-07 14:21:02,284 - train - INFO - Train: 84 [ 400/781 ( 51%)]  Loss:  4.371538 (3.9434)  Time: 0.804s,  159.26/s  (0.885s,  144.70/s)  LR: 2.091e-04  Data: 0.005 (0.008)
2024-04-07 14:21:46,915 - train - INFO - Train: 84 [ 450/781 ( 58%)]  Loss:  4.333326 (3.9494)  Time: 1.052s,  121.67/s  (0.885s,  144.56/s)  LR: 2.091e-04  Data: 0.005 (0.008)
2024-04-07 14:22:32,261 - train - INFO - Train: 84 [ 500/781 ( 64%)]  Loss:  3.553300 (3.9410)  Time: 0.793s,  161.32/s  (0.888s,  144.21/s)  LR: 2.091e-04  Data: 0.004 (0.008)
2024-04-07 14:23:16,321 - train - INFO - Train: 84 [ 550/781 ( 71%)]  Loss:  4.014619 (3.9333)  Time: 0.843s,  151.79/s  (0.887s,  144.30/s)  LR: 2.091e-04  Data: 0.009 (0.008)
2024-04-07 14:23:59,901 - train - INFO - Train: 84 [ 600/781 ( 77%)]  Loss:  3.697047 (3.9290)  Time: 0.856s,  149.47/s  (0.886s,  144.51/s)  LR: 2.091e-04  Data: 0.010 (0.008)
2024-04-07 14:24:44,333 - train - INFO - Train: 84 [ 650/781 ( 83%)]  Loss:  4.607083 (3.9317)  Time: 0.817s,  156.69/s  (0.886s,  144.48/s)  LR: 2.091e-04  Data: 0.006 (0.008)
2024-04-07 14:25:28,599 - train - INFO - Train: 84 [ 700/781 ( 90%)]  Loss:  4.270753 (3.9322)  Time: 0.840s,  152.42/s  (0.886s,  144.49/s)  LR: 2.091e-04  Data: 0.008 (0.008)
2024-04-07 14:26:13,099 - train - INFO - Train: 84 [ 750/781 ( 96%)]  Loss:  3.827617 (3.9396)  Time: 0.844s,  151.70/s  (0.886s,  144.44/s)  LR: 2.091e-04  Data: 0.008 (0.008)
2024-04-07 14:26:39,700 - train - INFO - Train: 84 [ 780/781 (100%)]  Loss:  3.266220 (3.9412)  Time: 0.827s,  154.71/s  (0.886s,  144.44/s)  LR: 2.091e-04  Data: 0.000 (0.008)
2024-04-07 14:26:39,701 - train - INFO - True
2024-04-07 14:26:39,702 - train - INFO - alphas:tensor([0.0034, 0.0049, 0.0358, 0.3460, 0.6099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,717 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,717 - train - INFO - True
2024-04-07 14:26:39,718 - train - INFO - alphas:tensor([0.1080, 0.0172, 0.0363, 0.1314, 0.7070], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,732 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,732 - train - INFO - True
2024-04-07 14:26:39,733 - train - INFO - alphas:tensor([0.5028, 0.0818, 0.0590, 0.1386, 0.2178], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,761 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,761 - train - INFO - True
2024-04-07 14:26:39,762 - train - INFO - alphas:tensor([0.4248, 0.0169, 0.0303, 0.1265, 0.4014], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,790 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,790 - train - INFO - True
2024-04-07 14:26:39,791 - train - INFO - alphas:tensor([0.2595, 0.0116, 0.0453, 0.1388, 0.5449], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,805 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,806 - train - INFO - True
2024-04-07 14:26:39,807 - train - INFO - alphas:tensor([0.3666, 0.0071, 0.0233, 0.0957, 0.5073], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,821 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,821 - train - INFO - True
2024-04-07 14:26:39,822 - train - INFO - alphas:tensor([0.5074, 0.0280, 0.0175, 0.1156, 0.3315], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,850 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,850 - train - INFO - True
2024-04-07 14:26:39,851 - train - INFO - alphas:tensor([0.3905, 0.0125, 0.0066, 0.0975, 0.4928], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,865 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,865 - train - INFO - True
2024-04-07 14:26:39,866 - train - INFO - alphas:tensor([0.3176, 0.0086, 0.0272, 0.1094, 0.5372], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,881 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,881 - train - INFO - True
2024-04-07 14:26:39,882 - train - INFO - alphas:tensor([0.4282, 0.0053, 0.0209, 0.0747, 0.4709], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,896 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,896 - train - INFO - True
2024-04-07 14:26:39,897 - train - INFO - alphas:tensor([0.4170, 0.0155, 0.0139, 0.1089, 0.4446], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,911 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,911 - train - INFO - True
2024-04-07 14:26:39,912 - train - INFO - alphas:tensor([0.3269, 0.0058, 0.0062, 0.1156, 0.5456], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,926 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,926 - train - INFO - True
2024-04-07 14:26:39,927 - train - INFO - alphas:tensor([0.3251, 0.0052, 0.0199, 0.0985, 0.5514], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,942 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,942 - train - INFO - True
2024-04-07 14:26:39,943 - train - INFO - alphas:tensor([0.4257, 0.0021, 0.0131, 0.0568, 0.5023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,957 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,957 - train - INFO - True
2024-04-07 14:26:39,958 - train - INFO - alphas:tensor([0.3345, 0.0186, 0.0111, 0.1192, 0.5166], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,972 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,972 - train - INFO - True
2024-04-07 14:26:39,973 - train - INFO - alphas:tensor([0.2439, 0.0038, 0.0029, 0.1327, 0.6167], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:39,988 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:39,988 - train - INFO - True
2024-04-07 14:26:39,989 - train - INFO - alphas:tensor([0.3129, 0.0055, 0.0142, 0.0902, 0.5773], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,003 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,003 - train - INFO - True
2024-04-07 14:26:40,004 - train - INFO - alphas:tensor([0.4205, 0.0017, 0.0109, 0.0524, 0.5145], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,018 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,018 - train - INFO - True
2024-04-07 14:26:40,019 - train - INFO - alphas:tensor([0.3476, 0.0051, 0.0049, 0.1040, 0.5385], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,033 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,033 - train - INFO - True
2024-04-07 14:26:40,034 - train - INFO - alphas:tensor([0.2512, 0.0023, 0.0019, 0.1083, 0.6363], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,049 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,049 - train - INFO - True
2024-04-07 14:26:40,050 - train - INFO - alphas:tensor([0.2695, 0.0031, 0.0127, 0.0868, 0.6279], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,064 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,064 - train - INFO - True
2024-04-07 14:26:40,065 - train - INFO - alphas:tensor([0.3999, 0.0013, 0.0095, 0.0440, 0.5452], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,079 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,079 - train - INFO - True
2024-04-07 14:26:40,080 - train - INFO - alphas:tensor([0.3969, 0.0076, 0.0043, 0.0742, 0.5170], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,095 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,095 - train - INFO - True
2024-04-07 14:26:40,096 - train - INFO - alphas:tensor([0.2907, 0.0016, 0.0011, 0.0723, 0.6343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,110 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,110 - train - INFO - True
2024-04-07 14:26:40,111 - train - INFO - alphas:tensor([0.2607, 0.0025, 0.0110, 0.0775, 0.6483], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,125 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,125 - train - INFO - True
2024-04-07 14:26:40,126 - train - INFO - alphas:tensor([0.3896, 0.0013, 0.0087, 0.0351, 0.5652], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,141 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,141 - train - INFO - True
2024-04-07 14:26:40,142 - train - INFO - alphas:tensor([0.4293, 0.0021, 0.0029, 0.0644, 0.5012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,156 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,156 - train - INFO - True
2024-04-07 14:26:40,157 - train - INFO - alphas:tensor([0.3222, 0.0016, 0.0008, 0.0537, 0.6216], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,171 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,171 - train - INFO - True
2024-04-07 14:26:40,172 - train - INFO - alphas:tensor([0.2400, 0.0020, 0.0101, 0.0790, 0.6689], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,187 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,187 - train - INFO - True
2024-04-07 14:26:40,188 - train - INFO - alphas:tensor([0.3605, 0.0007, 0.0064, 0.0401, 0.5923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,202 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,202 - train - INFO - True
2024-04-07 14:26:40,203 - train - INFO - alphas:tensor([0.4605, 0.0020, 0.0026, 0.0546, 0.4803], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,217 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,217 - train - INFO - True
2024-04-07 14:26:40,218 - train - INFO - alphas:tensor([0.3635, 0.0008, 0.0011, 0.0580, 0.5766], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,233 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,233 - train - INFO - True
2024-04-07 14:26:40,234 - train - INFO - alphas:tensor([0.2188, 0.0017, 0.0092, 0.0671, 0.7032], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,248 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,248 - train - INFO - True
2024-04-07 14:26:40,249 - train - INFO - alphas:tensor([3.2576e-01, 3.9724e-04, 3.9747e-03, 2.8491e-02, 6.4138e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,263 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,263 - train - INFO - True
2024-04-07 14:26:40,264 - train - INFO - alphas:tensor([0.4407, 0.0033, 0.0030, 0.0612, 0.4918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,278 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,279 - train - INFO - True
2024-04-07 14:26:40,279 - train - INFO - alphas:tensor([0.3810, 0.0007, 0.0013, 0.0564, 0.5606], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,294 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,294 - train - INFO - True
2024-04-07 14:26:40,295 - train - INFO - alphas:tensor([0.6234, 0.0274, 0.1017, 0.2475], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:26:40,323 - train - INFO - tau:0.4386175018099108
2024-04-07 14:26:40,323 - train - INFO - avg block size:14.378378378378379
2024-04-07 14:26:40,323 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 14:26:40,324 - train - INFO - lasso_alpha:8.140274938683991e-05
2024-04-07 14:26:40,575 - train - INFO - Test: [   0/78]  Time: 0.248 (0.248)  Loss:  0.8804 (0.8804)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.9688 (92.9688)
2024-04-07 14:26:44,909 - train - INFO - Test: [  50/78]  Time: 0.086 (0.090)  Loss:  1.8848 (1.6477)  Acc@1: 56.2500 (61.1366)  Acc@5: 79.6875 (83.7469)
2024-04-07 14:26:47,290 - train - INFO - Test: [  78/78]  Time: 0.059 (0.088)  Loss:  1.6953 (1.6795)  Acc@1: 62.5000 (60.6900)  Acc@5: 93.7500 (83.3700)
2024-04-07 14:26:48,629 - train - INFO - Train: 85 [   0/781 (  0%)]  Loss:  3.767036 (3.7670)  Time: 1.272s,  100.61/s  (1.272s,  100.61/s)  LR: 2.041e-04  Data: 0.181 (0.181)
2024-04-07 14:27:33,044 - train - INFO - Train: 85 [  50/781 (  6%)]  Loss:  3.873209 (3.9174)  Time: 0.870s,  147.11/s  (0.896s,  142.89/s)  LR: 2.041e-04  Data: 0.014 (0.011)
2024-04-07 14:28:16,797 - train - INFO - Train: 85 [ 100/781 ( 13%)]  Loss:  3.502383 (3.8983)  Time: 0.812s,  157.60/s  (0.886s,  144.55/s)  LR: 2.041e-04  Data: 0.006 (0.010)
2024-04-07 14:29:02,047 - train - INFO - Train: 85 [ 150/781 ( 19%)]  Loss:  4.341396 (3.8920)  Time: 1.075s,  119.09/s  (0.892s,  143.50/s)  LR: 2.041e-04  Data: 0.010 (0.009)
2024-04-07 14:29:46,938 - train - INFO - Train: 85 [ 200/781 ( 26%)]  Loss:  4.059873 (3.9008)  Time: 0.848s,  150.99/s  (0.893s,  143.27/s)  LR: 2.041e-04  Data: 0.009 (0.009)
2024-04-07 14:30:30,291 - train - INFO - Train: 85 [ 250/781 ( 32%)]  Loss:  4.477351 (3.9136)  Time: 0.840s,  152.40/s  (0.888s,  144.12/s)  LR: 2.041e-04  Data: 0.008 (0.009)
2024-04-07 14:31:14,439 - train - INFO - Train: 85 [ 300/781 ( 38%)]  Loss:  4.141979 (3.9285)  Time: 0.865s,  147.96/s  (0.887s,  144.26/s)  LR: 2.041e-04  Data: 0.008 (0.008)
2024-04-07 14:31:59,653 - train - INFO - Train: 85 [ 350/781 ( 45%)]  Loss:  4.251635 (3.9399)  Time: 0.868s,  147.45/s  (0.890s,  143.87/s)  LR: 2.041e-04  Data: 0.025 (0.008)
2024-04-07 14:32:44,916 - train - INFO - Train: 85 [ 400/781 ( 51%)]  Loss:  4.224094 (3.9359)  Time: 0.874s,  146.46/s  (0.892s,  143.56/s)  LR: 2.041e-04  Data: 0.010 (0.008)
2024-04-07 14:33:29,170 - train - INFO - Train: 85 [ 450/781 ( 58%)]  Loss:  3.367961 (3.9296)  Time: 1.086s,  117.91/s  (0.891s,  143.68/s)  LR: 2.041e-04  Data: 0.010 (0.008)
2024-04-07 14:34:29,913 - train - INFO - Train: 85 [ 500/781 ( 64%)]  Loss:  3.535720 (3.9276)  Time: 1.390s,   92.06/s  (0.923s,  138.64/s)  LR: 2.041e-04  Data: 0.007 (0.008)
2024-04-07 14:35:29,411 - train - INFO - Train: 85 [ 550/781 ( 71%)]  Loss:  3.786001 (3.9203)  Time: 0.843s,  151.87/s  (0.947s,  135.10/s)  LR: 2.041e-04  Data: 0.008 (0.008)
2024-04-07 14:36:14,681 - train - INFO - Train: 85 [ 600/781 ( 77%)]  Loss:  4.389524 (3.9178)  Time: 0.848s,  150.95/s  (0.944s,  135.60/s)  LR: 2.041e-04  Data: 0.008 (0.008)
2024-04-07 14:36:57,966 - train - INFO - Train: 85 [ 650/781 ( 83%)]  Loss:  4.423667 (3.9200)  Time: 0.831s,  153.98/s  (0.938s,  136.47/s)  LR: 2.041e-04  Data: 0.007 (0.008)
2024-04-07 14:37:43,802 - train - INFO - Train: 85 [ 700/781 ( 90%)]  Loss:  4.407032 (3.9127)  Time: 1.101s,  116.28/s  (0.936s,  136.69/s)  LR: 2.041e-04  Data: 0.008 (0.008)
2024-04-07 14:38:28,591 - train - INFO - Train: 85 [ 750/781 ( 96%)]  Loss:  3.567312 (3.9089)  Time: 0.816s,  156.82/s  (0.934s,  137.09/s)  LR: 2.041e-04  Data: 0.007 (0.008)
2024-04-07 14:38:54,741 - train - INFO - Train: 85 [ 780/781 (100%)]  Loss:  3.325167 (3.9076)  Time: 1.070s,  119.66/s  (0.931s,  137.44/s)  LR: 2.041e-04  Data: 0.000 (0.008)
2024-04-07 14:38:54,741 - train - INFO - True
2024-04-07 14:38:54,744 - train - INFO - alphas:tensor([0.0032, 0.0046, 0.0351, 0.3485, 0.6086], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,768 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,768 - train - INFO - True
2024-04-07 14:38:54,769 - train - INFO - alphas:tensor([0.1097, 0.0171, 0.0363, 0.1304, 0.7064], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,790 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,790 - train - INFO - True
2024-04-07 14:38:54,791 - train - INFO - alphas:tensor([0.5055, 0.0810, 0.0579, 0.1379, 0.2177], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,826 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,826 - train - INFO - True
2024-04-07 14:38:54,827 - train - INFO - alphas:tensor([0.4272, 0.0165, 0.0294, 0.1251, 0.4019], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,857 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,857 - train - INFO - True
2024-04-07 14:38:54,858 - train - INFO - alphas:tensor([0.2611, 0.0114, 0.0445, 0.1372, 0.5457], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,871 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,871 - train - INFO - True
2024-04-07 14:38:54,872 - train - INFO - alphas:tensor([0.3688, 0.0068, 0.0225, 0.0937, 0.5083], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,885 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,885 - train - INFO - True
2024-04-07 14:38:54,886 - train - INFO - alphas:tensor([0.5104, 0.0271, 0.0168, 0.1141, 0.3316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,909 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,909 - train - INFO - True
2024-04-07 14:38:54,910 - train - INFO - alphas:tensor([0.3946, 0.0123, 0.0063, 0.0959, 0.4909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,921 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,921 - train - INFO - True
2024-04-07 14:38:54,922 - train - INFO - alphas:tensor([0.3184, 0.0083, 0.0263, 0.1079, 0.5390], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,933 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,933 - train - INFO - True
2024-04-07 14:38:54,934 - train - INFO - alphas:tensor([0.4316, 0.0051, 0.0202, 0.0731, 0.4700], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,944 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,944 - train - INFO - True
2024-04-07 14:38:54,945 - train - INFO - alphas:tensor([0.4199, 0.0152, 0.0134, 0.1072, 0.4442], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,955 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,955 - train - INFO - True
2024-04-07 14:38:54,956 - train - INFO - alphas:tensor([0.3307, 0.0056, 0.0060, 0.1138, 0.5439], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,965 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,965 - train - INFO - True
2024-04-07 14:38:54,966 - train - INFO - alphas:tensor([0.3271, 0.0049, 0.0192, 0.0965, 0.5523], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,976 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,976 - train - INFO - True
2024-04-07 14:38:54,976 - train - INFO - alphas:tensor([0.4290, 0.0020, 0.0125, 0.0554, 0.5010], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,985 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,986 - train - INFO - True
2024-04-07 14:38:54,986 - train - INFO - alphas:tensor([0.3378, 0.0181, 0.0106, 0.1172, 0.5163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:54,996 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:54,996 - train - INFO - True
2024-04-07 14:38:54,997 - train - INFO - alphas:tensor([0.2474, 0.0037, 0.0028, 0.1322, 0.6139], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,008 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,008 - train - INFO - True
2024-04-07 14:38:55,009 - train - INFO - alphas:tensor([0.3128, 0.0053, 0.0137, 0.0889, 0.5794], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,019 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,019 - train - INFO - True
2024-04-07 14:38:55,020 - train - INFO - alphas:tensor([0.4222, 0.0016, 0.0106, 0.0511, 0.5144], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,030 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,030 - train - INFO - True
2024-04-07 14:38:55,031 - train - INFO - alphas:tensor([0.3523, 0.0049, 0.0046, 0.1018, 0.5363], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,041 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,041 - train - INFO - True
2024-04-07 14:38:55,041 - train - INFO - alphas:tensor([0.2545, 0.0022, 0.0018, 0.1067, 0.6348], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,051 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,051 - train - INFO - True
2024-04-07 14:38:55,052 - train - INFO - alphas:tensor([0.2707, 0.0030, 0.0125, 0.0857, 0.6282], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,061 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,061 - train - INFO - True
2024-04-07 14:38:55,062 - train - INFO - alphas:tensor([0.4013, 0.0013, 0.0092, 0.0424, 0.5458], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,071 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,071 - train - INFO - True
2024-04-07 14:38:55,072 - train - INFO - alphas:tensor([0.4000, 0.0073, 0.0041, 0.0728, 0.5159], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,081 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,081 - train - INFO - True
2024-04-07 14:38:55,081 - train - INFO - alphas:tensor([0.2964, 0.0016, 0.0010, 0.0710, 0.6301], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,090 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,090 - train - INFO - True
2024-04-07 14:38:55,091 - train - INFO - alphas:tensor([0.2627, 0.0023, 0.0106, 0.0759, 0.6484], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,099 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,099 - train - INFO - True
2024-04-07 14:38:55,100 - train - INFO - alphas:tensor([0.3904, 0.0012, 0.0083, 0.0339, 0.5662], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,108 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,108 - train - INFO - True
2024-04-07 14:38:55,109 - train - INFO - alphas:tensor([0.4353, 0.0020, 0.0028, 0.0624, 0.4975], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,117 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,117 - train - INFO - True
2024-04-07 14:38:55,118 - train - INFO - alphas:tensor([0.3263, 0.0016, 0.0008, 0.0530, 0.6184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,126 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,126 - train - INFO - True
2024-04-07 14:38:55,127 - train - INFO - alphas:tensor([0.2419, 0.0019, 0.0098, 0.0773, 0.6691], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,135 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,135 - train - INFO - True
2024-04-07 14:38:55,136 - train - INFO - alphas:tensor([0.3657, 0.0006, 0.0061, 0.0386, 0.5891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,147 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,147 - train - INFO - True
2024-04-07 14:38:55,148 - train - INFO - alphas:tensor([0.4652, 0.0019, 0.0024, 0.0530, 0.4776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,158 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,158 - train - INFO - True
2024-04-07 14:38:55,159 - train - INFO - alphas:tensor([0.3686, 0.0007, 0.0010, 0.0562, 0.5734], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,169 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,169 - train - INFO - True
2024-04-07 14:38:55,169 - train - INFO - alphas:tensor([0.2209, 0.0016, 0.0089, 0.0655, 0.7031], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,179 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,179 - train - INFO - True
2024-04-07 14:38:55,180 - train - INFO - alphas:tensor([3.2910e-01, 3.6530e-04, 3.7791e-03, 2.7382e-02, 6.3937e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,189 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,189 - train - INFO - True
2024-04-07 14:38:55,190 - train - INFO - alphas:tensor([0.4420, 0.0032, 0.0028, 0.0597, 0.4923], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,199 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,199 - train - INFO - True
2024-04-07 14:38:55,200 - train - INFO - alphas:tensor([0.3846, 0.0007, 0.0012, 0.0548, 0.5588], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,209 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,209 - train - INFO - True
2024-04-07 14:38:55,209 - train - INFO - alphas:tensor([0.6235, 0.0269, 0.1010, 0.2486], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:38:55,226 - train - INFO - tau:0.4342313267918117
2024-04-07 14:38:55,226 - train - INFO - avg block size:14.378378378378379
2024-04-07 14:38:55,227 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 14:38:55,478 - train - INFO - Test: [   0/78]  Time: 0.249 (0.249)  Loss:  0.9683 (0.9683)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.1875 (92.1875)
2024-04-07 14:39:00,166 - train - INFO - Test: [  50/78]  Time: 0.087 (0.097)  Loss:  1.8301 (1.6406)  Acc@1: 57.0312 (61.9945)  Acc@5: 82.0312 (83.9308)
2024-04-07 14:39:02,736 - train - INFO - Test: [  78/78]  Time: 0.053 (0.095)  Loss:  1.5498 (1.6734)  Acc@1: 62.5000 (61.2400)  Acc@5: 93.7500 (83.4800)
2024-04-07 14:39:04,069 - train - INFO - Train: 86 [   0/781 (  0%)]  Loss:  3.991440 (3.9914)  Time: 1.263s,  101.38/s  (1.263s,  101.38/s)  LR: 1.991e-04  Data: 0.179 (0.179)
2024-04-07 14:39:47,857 - train - INFO - Train: 86 [  50/781 (  6%)]  Loss:  3.733629 (3.9112)  Time: 0.844s,  151.57/s  (0.883s,  144.91/s)  LR: 1.991e-04  Data: 0.009 (0.011)
2024-04-07 14:40:40,635 - train - INFO - Train: 86 [ 100/781 ( 13%)]  Loss:  4.326168 (3.8988)  Time: 1.389s,   92.15/s  (0.969s,  132.15/s)  LR: 1.991e-04  Data: 0.008 (0.009)
2024-04-07 14:41:53,466 - train - INFO - Train: 86 [ 150/781 ( 19%)]  Loss:  4.364334 (3.8968)  Time: 1.332s,   96.09/s  (1.130s,  113.26/s)  LR: 1.991e-04  Data: 0.007 (0.008)
2024-04-07 14:43:05,640 - train - INFO - Train: 86 [ 200/781 ( 26%)]  Loss:  4.261765 (3.9024)  Time: 1.383s,   92.53/s  (1.208s,  105.95/s)  LR: 1.991e-04  Data: 0.008 (0.008)
2024-04-07 14:44:18,288 - train - INFO - Train: 86 [ 250/781 ( 32%)]  Loss:  4.517916 (3.9020)  Time: 1.664s,   76.94/s  (1.257s,  101.84/s)  LR: 1.991e-04  Data: 0.008 (0.008)
2024-04-07 14:45:28,815 - train - INFO - Train: 86 [ 300/781 ( 38%)]  Loss:  4.273671 (3.9213)  Time: 1.383s,   92.56/s  (1.282s,   99.81/s)  LR: 1.991e-04  Data: 0.006 (0.008)
2024-04-07 14:46:41,223 - train - INFO - Train: 86 [ 350/781 ( 45%)]  Loss:  3.834558 (3.9106)  Time: 1.375s,   93.12/s  (1.306s,   98.01/s)  LR: 1.991e-04  Data: 0.008 (0.008)
2024-04-07 14:47:53,834 - train - INFO - Train: 86 [ 400/781 ( 51%)]  Loss:  3.718140 (3.8985)  Time: 1.460s,   87.68/s  (1.324s,   96.66/s)  LR: 1.991e-04  Data: 0.007 (0.008)
2024-04-07 14:49:06,027 - train - INFO - Train: 86 [ 450/781 ( 58%)]  Loss:  3.954158 (3.8923)  Time: 1.584s,   80.81/s  (1.337s,   95.70/s)  LR: 1.991e-04  Data: 0.007 (0.008)
2024-04-07 14:50:17,349 - train - INFO - Train: 86 [ 500/781 ( 64%)]  Loss:  3.472063 (3.8986)  Time: 1.377s,   92.93/s  (1.346s,   95.07/s)  LR: 1.991e-04  Data: 0.007 (0.008)
2024-04-07 14:51:30,135 - train - INFO - Train: 86 [ 550/781 ( 71%)]  Loss:  3.952978 (3.9018)  Time: 1.394s,   91.83/s  (1.356s,   94.38/s)  LR: 1.991e-04  Data: 0.008 (0.008)
2024-04-07 14:52:43,703 - train - INFO - Train: 86 [ 600/781 ( 77%)]  Loss:  3.380992 (3.8993)  Time: 1.569s,   81.59/s  (1.366s,   93.71/s)  LR: 1.991e-04  Data: 0.007 (0.008)
2024-04-07 14:53:55,941 - train - INFO - Train: 86 [ 650/781 ( 83%)]  Loss:  3.870340 (3.8955)  Time: 1.475s,   86.77/s  (1.372s,   93.30/s)  LR: 1.991e-04  Data: 0.005 (0.007)
2024-04-07 14:55:06,947 - train - INFO - Train: 86 [ 700/781 ( 90%)]  Loss:  3.204104 (3.8933)  Time: 1.603s,   79.85/s  (1.375s,   93.07/s)  LR: 1.991e-04  Data: 0.011 (0.007)
2024-04-07 14:56:19,804 - train - INFO - Train: 86 [ 750/781 ( 96%)]  Loss:  4.179478 (3.8974)  Time: 1.391s,   91.99/s  (1.381s,   92.70/s)  LR: 1.991e-04  Data: 0.005 (0.007)
2024-04-07 14:57:02,954 - train - INFO - Train: 86 [ 780/781 (100%)]  Loss:  3.273738 (3.8941)  Time: 1.556s,   82.24/s  (1.383s,   92.55/s)  LR: 1.991e-04  Data: 0.000 (0.007)
2024-04-07 14:57:02,955 - train - INFO - True
2024-04-07 14:57:02,968 - train - INFO - alphas:tensor([0.0030, 0.0043, 0.0345, 0.3505, 0.6078], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:02,986 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:02,986 - train - INFO - True
2024-04-07 14:57:02,999 - train - INFO - alphas:tensor([0.1105, 0.0169, 0.0361, 0.1307, 0.7058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,014 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,014 - train - INFO - True
2024-04-07 14:57:03,016 - train - INFO - alphas:tensor([0.5084, 0.0800, 0.0569, 0.1371, 0.2177], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,044 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,044 - train - INFO - True
2024-04-07 14:57:03,045 - train - INFO - alphas:tensor([0.4292, 0.0160, 0.0286, 0.1233, 0.4028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,074 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,074 - train - INFO - True
2024-04-07 14:57:03,080 - train - INFO - alphas:tensor([0.2617, 0.0111, 0.0438, 0.1360, 0.5474], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,094 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,094 - train - INFO - True
2024-04-07 14:57:03,101 - train - INFO - alphas:tensor([0.3705, 0.0065, 0.0219, 0.0922, 0.5088], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,117 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,118 - train - INFO - True
2024-04-07 14:57:03,125 - train - INFO - alphas:tensor([0.5146, 0.0267, 0.0162, 0.1120, 0.3305], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,154 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,154 - train - INFO - True
2024-04-07 14:57:03,158 - train - INFO - alphas:tensor([0.3985, 0.0118, 0.0060, 0.0941, 0.4896], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,172 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,172 - train - INFO - True
2024-04-07 14:57:03,178 - train - INFO - alphas:tensor([0.3184, 0.0081, 0.0259, 0.1065, 0.5412], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,192 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,192 - train - INFO - True
2024-04-07 14:57:03,198 - train - INFO - alphas:tensor([0.4314, 0.0048, 0.0195, 0.0716, 0.4726], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,212 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,212 - train - INFO - True
2024-04-07 14:57:03,214 - train - INFO - alphas:tensor([0.4217, 0.0149, 0.0129, 0.1058, 0.4448], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,228 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,228 - train - INFO - True
2024-04-07 14:57:03,231 - train - INFO - alphas:tensor([0.3333, 0.0054, 0.0057, 0.1124, 0.5433], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,245 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,246 - train - INFO - True
2024-04-07 14:57:03,256 - train - INFO - alphas:tensor([0.3269, 0.0048, 0.0185, 0.0952, 0.5547], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,270 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,270 - train - INFO - True
2024-04-07 14:57:03,284 - train - INFO - alphas:tensor([0.4294, 0.0019, 0.0121, 0.0539, 0.5027], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,299 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,299 - train - INFO - True
2024-04-07 14:57:03,311 - train - INFO - alphas:tensor([0.3424, 0.0178, 0.0102, 0.1159, 0.5138], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,325 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,325 - train - INFO - True
2024-04-07 14:57:03,340 - train - INFO - alphas:tensor([0.2483, 0.0035, 0.0026, 0.1308, 0.6148], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,354 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,354 - train - INFO - True
2024-04-07 14:57:03,369 - train - INFO - alphas:tensor([0.3131, 0.0051, 0.0132, 0.0876, 0.5810], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,383 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,383 - train - INFO - True
2024-04-07 14:57:03,397 - train - INFO - alphas:tensor([0.4232, 0.0015, 0.0103, 0.0496, 0.5154], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,411 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,412 - train - INFO - True
2024-04-07 14:57:03,424 - train - INFO - alphas:tensor([0.3565, 0.0047, 0.0044, 0.1004, 0.5340], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,438 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,438 - train - INFO - True
2024-04-07 14:57:03,453 - train - INFO - alphas:tensor([0.2576, 0.0021, 0.0017, 0.1051, 0.6334], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,467 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,467 - train - INFO - True
2024-04-07 14:57:03,479 - train - INFO - alphas:tensor([0.2714, 0.0028, 0.0120, 0.0841, 0.6297], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,493 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,494 - train - INFO - True
2024-04-07 14:57:03,508 - train - INFO - alphas:tensor([0.4042, 0.0012, 0.0088, 0.0415, 0.5443], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,522 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,522 - train - INFO - True
2024-04-07 14:57:03,535 - train - INFO - alphas:tensor([0.4043, 0.0070, 0.0038, 0.0718, 0.5131], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,549 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,549 - train - INFO - True
2024-04-07 14:57:03,551 - train - INFO - alphas:tensor([0.3001, 0.0015, 0.0009, 0.0694, 0.6280], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,565 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,565 - train - INFO - True
2024-04-07 14:57:03,567 - train - INFO - alphas:tensor([0.2629, 0.0022, 0.0102, 0.0745, 0.6503], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,581 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,581 - train - INFO - True
2024-04-07 14:57:03,584 - train - INFO - alphas:tensor([0.3910, 0.0012, 0.0080, 0.0331, 0.5668], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,597 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,597 - train - INFO - True
2024-04-07 14:57:03,604 - train - INFO - alphas:tensor([0.4365, 0.0019, 0.0026, 0.0613, 0.4977], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,617 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,617 - train - INFO - True
2024-04-07 14:57:03,621 - train - INFO - alphas:tensor([0.3270, 0.0015, 0.0007, 0.0518, 0.6190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,633 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,633 - train - INFO - True
2024-04-07 14:57:03,639 - train - INFO - alphas:tensor([0.2421, 0.0018, 0.0095, 0.0758, 0.6708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,650 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,650 - train - INFO - True
2024-04-07 14:57:03,653 - train - INFO - alphas:tensor([3.6597e-01, 5.7031e-04, 5.7772e-03, 3.7701e-02, 5.8998e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,664 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,664 - train - INFO - True
2024-04-07 14:57:03,667 - train - INFO - alphas:tensor([0.4668, 0.0018, 0.0022, 0.0518, 0.4773], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,677 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,677 - train - INFO - True
2024-04-07 14:57:03,683 - train - INFO - alphas:tensor([0.3715, 0.0007, 0.0010, 0.0555, 0.5714], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,692 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,693 - train - INFO - True
2024-04-07 14:57:03,696 - train - INFO - alphas:tensor([0.2220, 0.0016, 0.0087, 0.0644, 0.7034], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,706 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,706 - train - INFO - True
2024-04-07 14:57:03,707 - train - INFO - alphas:tensor([3.3093e-01, 3.3488e-04, 3.5791e-03, 2.6225e-02, 6.3893e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,716 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,717 - train - INFO - True
2024-04-07 14:57:03,720 - train - INFO - alphas:tensor([0.4452, 0.0030, 0.0026, 0.0582, 0.4909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,729 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,729 - train - INFO - True
2024-04-07 14:57:03,733 - train - INFO - alphas:tensor([0.3875, 0.0006, 0.0010, 0.0534, 0.5574], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,742 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,742 - train - INFO - True
2024-04-07 14:57:03,744 - train - INFO - alphas:tensor([0.6262, 0.0261, 0.0997, 0.2480], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 14:57:03,760 - train - INFO - tau:0.4298890135238936
2024-04-07 14:57:03,760 - train - INFO - avg block size:14.378378378378379
2024-04-07 14:57:03,760 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 14:57:03,760 - train - INFO - lasso_alpha:7.400249944258173e-05
2024-04-07 14:57:04,359 - train - INFO - Test: [   0/78]  Time: 0.596 (0.596)  Loss:  0.9502 (0.9502)  Acc@1: 79.6875 (79.6875)  Acc@5: 94.5312 (94.5312)
2024-04-07 14:57:30,819 - train - INFO - Test: [  50/78]  Time: 0.568 (0.530)  Loss:  1.7832 (1.6362)  Acc@1: 57.0312 (60.9988)  Acc@5: 83.5938 (83.9614)
2024-04-07 14:57:45,152 - train - INFO - Test: [  78/78]  Time: 0.430 (0.524)  Loss:  1.7070 (1.6644)  Acc@1: 56.2500 (60.7500)  Acc@5: 93.7500 (83.4000)
2024-04-07 14:57:47,012 - train - INFO - Train: 87 [   0/781 (  0%)]  Loss:  4.013284 (4.0133)  Time: 1.790s,   71.52/s  (1.790s,   71.52/s)  LR: 1.941e-04  Data: 0.186 (0.186)
2024-04-07 14:58:58,384 - train - INFO - Train: 87 [  50/781 (  6%)]  Loss:  3.145348 (3.8827)  Time: 1.305s,   98.10/s  (1.435s,   89.23/s)  LR: 1.941e-04  Data: 0.007 (0.010)
2024-04-07 15:00:11,797 - train - INFO - Train: 87 [ 100/781 ( 13%)]  Loss:  3.142399 (3.8807)  Time: 1.452s,   88.15/s  (1.451s,   88.20/s)  LR: 1.941e-04  Data: 0.007 (0.009)
2024-04-07 15:01:23,563 - train - INFO - Train: 87 [ 150/781 ( 19%)]  Loss:  3.511547 (3.8824)  Time: 1.370s,   93.43/s  (1.446s,   88.52/s)  LR: 1.941e-04  Data: 0.008 (0.008)
2024-04-07 15:02:37,095 - train - INFO - Train: 87 [ 200/781 ( 26%)]  Loss:  4.500404 (3.9074)  Time: 1.369s,   93.53/s  (1.452s,   88.15/s)  LR: 1.941e-04  Data: 0.007 (0.008)
2024-04-07 15:03:48,340 - train - INFO - Train: 87 [ 250/781 ( 32%)]  Loss:  3.722313 (3.9092)  Time: 1.421s,   90.05/s  (1.447s,   88.48/s)  LR: 1.941e-04  Data: 0.007 (0.008)
2024-04-07 15:05:00,497 - train - INFO - Train: 87 [ 300/781 ( 38%)]  Loss:  3.994829 (3.9139)  Time: 1.432s,   89.36/s  (1.446s,   88.52/s)  LR: 1.941e-04  Data: 0.008 (0.008)
2024-04-07 15:06:13,630 - train - INFO - Train: 87 [ 350/781 ( 45%)]  Loss:  4.287164 (3.9233)  Time: 1.490s,   85.89/s  (1.448s,   88.37/s)  LR: 1.941e-04  Data: 0.007 (0.008)
2024-04-07 15:07:25,478 - train - INFO - Train: 87 [ 400/781 ( 51%)]  Loss:  4.214447 (3.9072)  Time: 1.493s,   85.75/s  (1.447s,   88.46/s)  LR: 1.941e-04  Data: 0.006 (0.008)
2024-04-07 15:08:36,255 - train - INFO - Train: 87 [ 450/781 ( 58%)]  Loss:  3.668077 (3.9007)  Time: 1.546s,   82.80/s  (1.444s,   88.67/s)  LR: 1.941e-04  Data: 0.007 (0.008)
2024-04-07 15:09:48,411 - train - INFO - Train: 87 [ 500/781 ( 64%)]  Loss:  3.781312 (3.8968)  Time: 1.390s,   92.07/s  (1.443s,   88.68/s)  LR: 1.941e-04  Data: 0.013 (0.008)
2024-04-07 15:11:02,676 - train - INFO - Train: 87 [ 550/781 ( 71%)]  Loss:  3.748266 (3.9030)  Time: 1.562s,   81.95/s  (1.447s,   88.44/s)  LR: 1.941e-04  Data: 0.007 (0.008)
2024-04-07 15:12:16,986 - train - INFO - Train: 87 [ 600/781 ( 77%)]  Loss:  3.440969 (3.9002)  Time: 1.547s,   82.76/s  (1.450s,   88.25/s)  LR: 1.941e-04  Data: 0.008 (0.007)
2024-04-07 15:13:29,001 - train - INFO - Train: 87 [ 650/781 ( 83%)]  Loss:  3.672203 (3.9038)  Time: 1.486s,   86.16/s  (1.450s,   88.29/s)  LR: 1.941e-04  Data: 0.007 (0.007)
2024-04-07 15:14:41,881 - train - INFO - Train: 87 [ 700/781 ( 90%)]  Loss:  3.238574 (3.9065)  Time: 1.475s,   86.75/s  (1.450s,   88.26/s)  LR: 1.941e-04  Data: 0.008 (0.007)
2024-04-07 15:15:54,655 - train - INFO - Train: 87 [ 750/781 ( 96%)]  Loss:  4.473926 (3.9043)  Time: 1.466s,   87.29/s  (1.451s,   88.24/s)  LR: 1.941e-04  Data: 0.009 (0.007)
2024-04-07 15:16:37,381 - train - INFO - Train: 87 [ 780/781 (100%)]  Loss:  3.797574 (3.9076)  Time: 1.416s,   90.39/s  (1.450s,   88.30/s)  LR: 1.941e-04  Data: 0.000 (0.007)
2024-04-07 15:16:37,382 - train - INFO - True
2024-04-07 15:16:37,385 - train - INFO - alphas:tensor([0.0027, 0.0041, 0.0337, 0.3516, 0.6079], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,399 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,400 - train - INFO - True
2024-04-07 15:16:37,413 - train - INFO - alphas:tensor([0.1108, 0.0167, 0.0354, 0.1294, 0.7077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,426 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,426 - train - INFO - True
2024-04-07 15:16:37,440 - train - INFO - alphas:tensor([0.5112, 0.0791, 0.0559, 0.1363, 0.2176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,462 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,462 - train - INFO - True
2024-04-07 15:16:37,475 - train - INFO - alphas:tensor([0.4324, 0.0155, 0.0277, 0.1215, 0.4030], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,495 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,495 - train - INFO - True
2024-04-07 15:16:37,507 - train - INFO - alphas:tensor([0.2626, 0.0108, 0.0427, 0.1344, 0.5495], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,517 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,517 - train - INFO - True
2024-04-07 15:16:37,530 - train - INFO - alphas:tensor([0.3737, 0.0063, 0.0212, 0.0903, 0.5085], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,541 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,541 - train - INFO - True
2024-04-07 15:16:37,554 - train - INFO - alphas:tensor([0.5158, 0.0259, 0.0157, 0.1109, 0.3316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,574 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,574 - train - INFO - True
2024-04-07 15:16:37,587 - train - INFO - alphas:tensor([0.3994, 0.0114, 0.0057, 0.0929, 0.4906], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,597 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,597 - train - INFO - True
2024-04-07 15:16:37,610 - train - INFO - alphas:tensor([0.3196, 0.0078, 0.0253, 0.1053, 0.5420], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,618 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,618 - train - INFO - True
2024-04-07 15:16:37,632 - train - INFO - alphas:tensor([0.4344, 0.0045, 0.0189, 0.0704, 0.4717], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,641 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,641 - train - INFO - True
2024-04-07 15:16:37,654 - train - INFO - alphas:tensor([0.4231, 0.0146, 0.0124, 0.1046, 0.4453], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,663 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,663 - train - INFO - True
2024-04-07 15:16:37,664 - train - INFO - alphas:tensor([0.3337, 0.0052, 0.0054, 0.1115, 0.5442], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,674 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,674 - train - INFO - True
2024-04-07 15:16:37,675 - train - INFO - alphas:tensor([0.3283, 0.0046, 0.0179, 0.0940, 0.5552], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,686 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,686 - train - INFO - True
2024-04-07 15:16:37,688 - train - INFO - alphas:tensor([0.4333, 0.0017, 0.0116, 0.0523, 0.5011], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,698 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,698 - train - INFO - True
2024-04-07 15:16:37,700 - train - INFO - alphas:tensor([0.3439, 0.0174, 0.0099, 0.1139, 0.5150], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,710 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,710 - train - INFO - True
2024-04-07 15:16:37,715 - train - INFO - alphas:tensor([0.2505, 0.0034, 0.0025, 0.1294, 0.6142], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,725 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,725 - train - INFO - True
2024-04-07 15:16:37,733 - train - INFO - alphas:tensor([0.3150, 0.0049, 0.0126, 0.0862, 0.5813], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,742 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,742 - train - INFO - True
2024-04-07 15:16:37,749 - train - INFO - alphas:tensor([0.4262, 0.0014, 0.0098, 0.0485, 0.5141], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,757 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,757 - train - INFO - True
2024-04-07 15:16:37,764 - train - INFO - alphas:tensor([0.3613, 0.0046, 0.0041, 0.0983, 0.5317], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,772 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,772 - train - INFO - True
2024-04-07 15:16:37,779 - train - INFO - alphas:tensor([0.2617, 0.0020, 0.0016, 0.1039, 0.6307], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,787 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,787 - train - INFO - True
2024-04-07 15:16:37,791 - train - INFO - alphas:tensor([0.2725, 0.0027, 0.0115, 0.0827, 0.6305], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,799 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,799 - train - INFO - True
2024-04-07 15:16:37,803 - train - INFO - alphas:tensor([0.4074, 0.0011, 0.0084, 0.0402, 0.5429], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,812 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,812 - train - INFO - True
2024-04-07 15:16:37,816 - train - INFO - alphas:tensor([0.4072, 0.0067, 0.0036, 0.0700, 0.5125], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,829 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,829 - train - INFO - True
2024-04-07 15:16:37,833 - train - INFO - alphas:tensor([0.3036, 0.0014, 0.0009, 0.0678, 0.6264], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,843 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,843 - train - INFO - True
2024-04-07 15:16:37,849 - train - INFO - alphas:tensor([0.2635, 0.0021, 0.0100, 0.0733, 0.6510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,859 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,859 - train - INFO - True
2024-04-07 15:16:37,863 - train - INFO - alphas:tensor([0.3964, 0.0011, 0.0077, 0.0321, 0.5627], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,872 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,872 - train - INFO - True
2024-04-07 15:16:37,874 - train - INFO - alphas:tensor([0.4412, 0.0018, 0.0024, 0.0602, 0.4944], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,883 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,883 - train - INFO - True
2024-04-07 15:16:37,894 - train - INFO - alphas:tensor([0.3326, 0.0014, 0.0006, 0.0505, 0.6148], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,903 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,903 - train - INFO - True
2024-04-07 15:16:37,904 - train - INFO - alphas:tensor([0.2439, 0.0018, 0.0093, 0.0744, 0.6706], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,913 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,913 - train - INFO - True
2024-04-07 15:16:37,921 - train - INFO - alphas:tensor([3.6881e-01, 5.2972e-04, 5.5119e-03, 3.6852e-02, 5.8829e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,929 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,929 - train - INFO - True
2024-04-07 15:16:37,943 - train - INFO - alphas:tensor([0.4717, 0.0017, 0.0021, 0.0500, 0.4746], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,951 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,952 - train - INFO - True
2024-04-07 15:16:37,965 - train - INFO - alphas:tensor([0.3741, 0.0007, 0.0009, 0.0541, 0.5702], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,974 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,974 - train - INFO - True
2024-04-07 15:16:37,988 - train - INFO - alphas:tensor([0.2222, 0.0015, 0.0083, 0.0628, 0.7052], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:37,999 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:37,999 - train - INFO - True
2024-04-07 15:16:38,008 - train - INFO - alphas:tensor([3.3630e-01, 3.0897e-04, 3.3827e-03, 2.5304e-02, 6.3470e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:38,018 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:38,018 - train - INFO - True
2024-04-07 15:16:38,030 - train - INFO - alphas:tensor([0.4469, 0.0028, 0.0025, 0.0569, 0.4909], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:38,040 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:38,040 - train - INFO - True
2024-04-07 15:16:38,053 - train - INFO - alphas:tensor([0.3908, 0.0006, 0.0010, 0.0518, 0.5559], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:38,062 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:38,062 - train - INFO - True
2024-04-07 15:16:38,075 - train - INFO - alphas:tensor([0.6253, 0.0257, 0.0992, 0.2498], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:16:38,092 - train - INFO - tau:0.42559012338865465
2024-04-07 15:16:38,092 - train - INFO - avg block size:14.378378378378379
2024-04-07 15:16:38,092 - train - INFO - current latency ratio:tensor(0.1787)
2024-04-07 15:16:38,734 - train - INFO - Test: [   0/78]  Time: 0.638 (0.638)  Loss:  0.8999 (0.8999)  Acc@1: 83.5938 (83.5938)  Acc@5: 93.7500 (93.7500)
2024-04-07 15:17:04,618 - train - INFO - Test: [  50/78]  Time: 0.504 (0.520)  Loss:  1.8242 (1.6503)  Acc@1: 57.0312 (61.0447)  Acc@5: 84.3750 (84.1759)
2024-04-07 15:17:18,939 - train - INFO - Test: [  78/78]  Time: 0.511 (0.517)  Loss:  1.7334 (1.6778)  Acc@1: 56.2500 (60.8800)  Acc@5: 87.5000 (83.4500)
2024-04-07 15:17:20,754 - train - INFO - Train: 88 [   0/781 (  0%)]  Loss:  3.366901 (3.3669)  Time: 1.748s,   73.23/s  (1.748s,   73.23/s)  LR: 1.891e-04  Data: 0.194 (0.194)
2024-04-07 15:18:32,345 - train - INFO - Train: 88 [  50/781 (  6%)]  Loss:  4.412872 (3.8917)  Time: 1.530s,   83.67/s  (1.438s,   89.01/s)  LR: 1.891e-04  Data: 0.006 (0.011)
2024-04-07 15:19:44,343 - train - INFO - Train: 88 [ 100/781 ( 13%)]  Loss:  3.157436 (3.8744)  Time: 1.707s,   75.00/s  (1.439s,   88.95/s)  LR: 1.891e-04  Data: 0.005 (0.009)
2024-04-07 15:20:57,836 - train - INFO - Train: 88 [ 150/781 ( 19%)]  Loss:  4.295515 (3.8620)  Time: 1.427s,   89.68/s  (1.449s,   88.33/s)  LR: 1.891e-04  Data: 0.008 (0.008)
2024-04-07 15:22:10,945 - train - INFO - Train: 88 [ 200/781 ( 26%)]  Loss:  4.155369 (3.8640)  Time: 1.447s,   88.43/s  (1.452s,   88.13/s)  LR: 1.891e-04  Data: 0.007 (0.008)
2024-04-07 15:23:24,053 - train - INFO - Train: 88 [ 250/781 ( 32%)]  Loss:  3.386144 (3.8651)  Time: 1.625s,   78.75/s  (1.454s,   88.01/s)  LR: 1.891e-04  Data: 0.006 (0.008)
2024-04-07 15:24:38,687 - train - INFO - Train: 88 [ 300/781 ( 38%)]  Loss:  4.290268 (3.8846)  Time: 1.596s,   80.21/s  (1.461s,   87.63/s)  LR: 1.891e-04  Data: 0.008 (0.008)
2024-04-07 15:25:52,275 - train - INFO - Train: 88 [ 350/781 ( 45%)]  Loss:  3.551486 (3.8898)  Time: 1.541s,   83.05/s  (1.462s,   87.54/s)  LR: 1.891e-04  Data: 0.008 (0.008)
2024-04-07 15:27:03,517 - train - INFO - Train: 88 [ 400/781 ( 51%)]  Loss:  3.917324 (3.8887)  Time: 1.494s,   85.68/s  (1.458s,   87.82/s)  LR: 1.891e-04  Data: 0.007 (0.008)
2024-04-07 15:28:17,448 - train - INFO - Train: 88 [ 450/781 ( 58%)]  Loss:  3.823989 (3.8891)  Time: 1.550s,   82.57/s  (1.460s,   87.68/s)  LR: 1.891e-04  Data: 0.007 (0.008)
2024-04-07 15:29:30,814 - train - INFO - Train: 88 [ 500/781 ( 64%)]  Loss:  4.416997 (3.8784)  Time: 1.432s,   89.36/s  (1.461s,   87.63/s)  LR: 1.891e-04  Data: 0.007 (0.008)
2024-04-07 15:30:44,414 - train - INFO - Train: 88 [ 550/781 ( 71%)]  Loss:  3.538626 (3.8803)  Time: 1.624s,   78.84/s  (1.462s,   87.57/s)  LR: 1.891e-04  Data: 0.005 (0.008)
2024-04-07 15:31:57,174 - train - INFO - Train: 88 [ 600/781 ( 77%)]  Loss:  4.384497 (3.8777)  Time: 1.598s,   80.10/s  (1.461s,   87.60/s)  LR: 1.891e-04  Data: 0.006 (0.007)
2024-04-07 15:33:11,646 - train - INFO - Train: 88 [ 650/781 ( 83%)]  Loss:  4.419125 (3.8801)  Time: 1.445s,   88.59/s  (1.463s,   87.47/s)  LR: 1.891e-04  Data: 0.007 (0.007)
2024-04-07 15:34:24,039 - train - INFO - Train: 88 [ 700/781 ( 90%)]  Loss:  4.264517 (3.8789)  Time: 1.543s,   82.96/s  (1.462s,   87.54/s)  LR: 1.891e-04  Data: 0.004 (0.007)
2024-04-07 15:35:38,151 - train - INFO - Train: 88 [ 750/781 ( 96%)]  Loss:  4.208957 (3.8847)  Time: 1.349s,   94.90/s  (1.464s,   87.46/s)  LR: 1.891e-04  Data: 0.004 (0.007)
2024-04-07 15:36:21,434 - train - INFO - Train: 88 [ 780/781 (100%)]  Loss:  4.476695 (3.8854)  Time: 1.402s,   91.33/s  (1.463s,   87.51/s)  LR: 1.891e-04  Data: 0.000 (0.007)
2024-04-07 15:36:21,435 - train - INFO - True
2024-04-07 15:36:21,449 - train - INFO - alphas:tensor([0.0025, 0.0039, 0.0331, 0.3536, 0.6069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,460 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,460 - train - INFO - True
2024-04-07 15:36:21,473 - train - INFO - alphas:tensor([0.1125, 0.0165, 0.0352, 0.1282, 0.7075], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,484 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,484 - train - INFO - True
2024-04-07 15:36:21,498 - train - INFO - alphas:tensor([0.5144, 0.0781, 0.0548, 0.1353, 0.2174], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,531 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,531 - train - INFO - True
2024-04-07 15:36:21,533 - train - INFO - alphas:tensor([0.4338, 0.0150, 0.0269, 0.1201, 0.4041], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,555 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,556 - train - INFO - True
2024-04-07 15:36:21,560 - train - INFO - alphas:tensor([0.2627, 0.0105, 0.0425, 0.1336, 0.5507], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,571 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,571 - train - INFO - True
2024-04-07 15:36:21,574 - train - INFO - alphas:tensor([0.3731, 0.0061, 0.0209, 0.0889, 0.5110], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,585 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,585 - train - INFO - True
2024-04-07 15:36:21,588 - train - INFO - alphas:tensor([0.5193, 0.0253, 0.0151, 0.1090, 0.3312], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,616 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,617 - train - INFO - True
2024-04-07 15:36:21,622 - train - INFO - alphas:tensor([0.4027, 0.0110, 0.0054, 0.0911, 0.4898], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,636 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,637 - train - INFO - True
2024-04-07 15:36:21,641 - train - INFO - alphas:tensor([0.3212, 0.0076, 0.0246, 0.1039, 0.5427], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,656 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,656 - train - INFO - True
2024-04-07 15:36:21,661 - train - INFO - alphas:tensor([0.4369, 0.0043, 0.0183, 0.0689, 0.4716], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,675 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,675 - train - INFO - True
2024-04-07 15:36:21,682 - train - INFO - alphas:tensor([0.4277, 0.0141, 0.0119, 0.1027, 0.4437], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,696 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,696 - train - INFO - True
2024-04-07 15:36:21,702 - train - INFO - alphas:tensor([0.3369, 0.0050, 0.0051, 0.1103, 0.5427], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,717 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,717 - train - INFO - True
2024-04-07 15:36:21,720 - train - INFO - alphas:tensor([0.3287, 0.0044, 0.0175, 0.0924, 0.5569], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,736 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,736 - train - INFO - True
2024-04-07 15:36:21,749 - train - INFO - alphas:tensor([0.4360, 0.0016, 0.0113, 0.0511, 0.5000], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,764 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,764 - train - INFO - True
2024-04-07 15:36:21,778 - train - INFO - alphas:tensor([0.3494, 0.0173, 0.0094, 0.1126, 0.5113], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,792 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,792 - train - INFO - True
2024-04-07 15:36:21,807 - train - INFO - alphas:tensor([0.2556, 0.0033, 0.0024, 0.1271, 0.6117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,821 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,821 - train - INFO - True
2024-04-07 15:36:21,835 - train - INFO - alphas:tensor([0.3163, 0.0047, 0.0122, 0.0841, 0.5828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,850 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,850 - train - INFO - True
2024-04-07 15:36:21,864 - train - INFO - alphas:tensor([0.4259, 0.0013, 0.0094, 0.0471, 0.5163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,878 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,878 - train - INFO - True
2024-04-07 15:36:21,890 - train - INFO - alphas:tensor([0.3634, 0.0044, 0.0039, 0.0967, 0.5316], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,905 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,905 - train - INFO - True
2024-04-07 15:36:21,919 - train - INFO - alphas:tensor([0.2643, 0.0019, 0.0015, 0.1024, 0.6298], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,933 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,934 - train - INFO - True
2024-04-07 15:36:21,946 - train - INFO - alphas:tensor([0.2743, 0.0026, 0.0111, 0.0814, 0.6306], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,960 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,960 - train - INFO - True
2024-04-07 15:36:21,974 - train - INFO - alphas:tensor([0.4076, 0.0010, 0.0080, 0.0392, 0.5441], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:21,989 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:21,989 - train - INFO - True
2024-04-07 15:36:22,001 - train - INFO - alphas:tensor([0.4113, 0.0065, 0.0034, 0.0687, 0.5101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,023 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,024 - train - INFO - True
2024-04-07 15:36:22,031 - train - INFO - alphas:tensor([0.3053, 0.0013, 0.0008, 0.0665, 0.6261], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,049 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,049 - train - INFO - True
2024-04-07 15:36:22,051 - train - INFO - alphas:tensor([0.2649, 0.0020, 0.0096, 0.0716, 0.6519], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,068 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,068 - train - INFO - True
2024-04-07 15:36:22,069 - train - INFO - alphas:tensor([0.3947, 0.0010, 0.0074, 0.0315, 0.5654], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,085 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,085 - train - INFO - True
2024-04-07 15:36:22,090 - train - INFO - alphas:tensor([0.4448, 0.0017, 0.0023, 0.0588, 0.4924], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,105 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,105 - train - INFO - True
2024-04-07 15:36:22,109 - train - INFO - alphas:tensor([3.3701e-01, 1.3253e-03, 6.0734e-04, 5.0025e-02, 6.1103e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,123 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,123 - train - INFO - True
2024-04-07 15:36:22,129 - train - INFO - alphas:tensor([0.2442, 0.0017, 0.0089, 0.0729, 0.6724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,143 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,143 - train - INFO - True
2024-04-07 15:36:22,147 - train - INFO - alphas:tensor([3.7088e-01, 4.8563e-04, 5.3252e-03, 3.5775e-02, 5.8753e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,161 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,161 - train - INFO - True
2024-04-07 15:36:22,166 - train - INFO - alphas:tensor([0.4751, 0.0016, 0.0019, 0.0490, 0.4724], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,195 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,195 - train - INFO - True
2024-04-07 15:36:22,197 - train - INFO - alphas:tensor([0.3778, 0.0006, 0.0008, 0.0529, 0.5680], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,211 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,212 - train - INFO - True
2024-04-07 15:36:22,218 - train - INFO - alphas:tensor([0.2225, 0.0014, 0.0081, 0.0617, 0.7063], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,232 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,232 - train - INFO - True
2024-04-07 15:36:22,235 - train - INFO - alphas:tensor([3.3485e-01, 2.8630e-04, 3.2193e-03, 2.4633e-02, 6.3701e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,249 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,249 - train - INFO - True
2024-04-07 15:36:22,253 - train - INFO - alphas:tensor([0.4483, 0.0027, 0.0023, 0.0557, 0.4910], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,267 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,268 - train - INFO - True
2024-04-07 15:36:22,273 - train - INFO - alphas:tensor([3.9254e-01, 5.3878e-04, 8.7696e-04, 5.0418e-02, 5.5562e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,287 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,287 - train - INFO - True
2024-04-07 15:36:22,300 - train - INFO - alphas:tensor([0.6260, 0.0251, 0.0985, 0.2504], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:36:22,328 - train - INFO - tau:0.4213342221547681
2024-04-07 15:36:22,329 - train - INFO - avg block size:13.972972972972974
2024-04-07 15:36:22,329 - train - INFO - current latency ratio:tensor(0.2038)
2024-04-07 15:36:22,329 - train - INFO - lasso_alpha:6.727499949325611e-05
2024-04-07 15:36:22,915 - train - INFO - Test: [   0/78]  Time: 0.582 (0.582)  Loss:  0.9380 (0.9380)  Acc@1: 82.8125 (82.8125)  Acc@5: 92.9688 (92.9688)
2024-04-07 15:36:49,234 - train - INFO - Test: [  50/78]  Time: 0.577 (0.527)  Loss:  1.8125 (1.6344)  Acc@1: 57.8125 (61.7494)  Acc@5: 82.8125 (83.9767)
2024-04-07 15:37:03,227 - train - INFO - Test: [  78/78]  Time: 0.344 (0.518)  Loss:  1.8154 (1.6654)  Acc@1: 56.2500 (61.2500)  Acc@5: 100.0000 (83.5300)
2024-04-07 15:37:05,008 - train - INFO - Train: 89 [   0/781 (  0%)]  Loss:  4.046558 (4.0466)  Time: 1.708s,   74.95/s  (1.708s,   74.95/s)  LR: 1.842e-04  Data: 0.172 (0.172)
2024-04-07 15:38:19,932 - train - INFO - Train: 89 [  50/781 (  6%)]  Loss:  3.301605 (3.9409)  Time: 1.498s,   85.46/s  (1.503s,   85.19/s)  LR: 1.842e-04  Data: 0.007 (0.010)
2024-04-07 15:39:33,289 - train - INFO - Train: 89 [ 100/781 ( 13%)]  Loss:  3.408928 (3.9289)  Time: 1.424s,   89.87/s  (1.485s,   86.20/s)  LR: 1.842e-04  Data: 0.007 (0.009)
2024-04-07 15:40:47,087 - train - INFO - Train: 89 [ 150/781 ( 19%)]  Loss:  4.237644 (3.8973)  Time: 1.301s,   98.42/s  (1.482s,   86.37/s)  LR: 1.842e-04  Data: 0.004 (0.008)
2024-04-07 15:42:02,400 - train - INFO - Train: 89 [ 200/781 ( 26%)]  Loss:  4.127713 (3.8938)  Time: 1.493s,   85.72/s  (1.488s,   86.02/s)  LR: 1.842e-04  Data: 0.008 (0.008)
2024-04-07 15:43:18,313 - train - INFO - Train: 89 [ 250/781 ( 32%)]  Loss:  3.543955 (3.8802)  Time: 1.579s,   81.08/s  (1.494s,   85.67/s)  LR: 1.842e-04  Data: 0.007 (0.008)
2024-04-07 15:44:31,899 - train - INFO - Train: 89 [ 300/781 ( 38%)]  Loss:  3.886163 (3.8692)  Time: 1.669s,   76.69/s  (1.490s,   85.89/s)  LR: 1.842e-04  Data: 0.008 (0.008)
2024-04-07 15:45:43,859 - train - INFO - Train: 89 [ 350/781 ( 45%)]  Loss:  4.531217 (3.8721)  Time: 1.658s,   77.18/s  (1.483s,   86.31/s)  LR: 1.842e-04  Data: 0.007 (0.008)
2024-04-07 15:46:58,940 - train - INFO - Train: 89 [ 400/781 ( 51%)]  Loss:  4.130429 (3.8774)  Time: 1.497s,   85.53/s  (1.485s,   86.17/s)  LR: 1.842e-04  Data: 0.008 (0.008)
2024-04-07 15:48:13,136 - train - INFO - Train: 89 [ 450/781 ( 58%)]  Loss:  3.819785 (3.8832)  Time: 1.785s,   71.70/s  (1.485s,   86.18/s)  LR: 1.842e-04  Data: 0.007 (0.008)
2024-04-07 15:49:34,205 - train - INFO - Train: 89 [ 500/781 ( 64%)]  Loss:  3.822742 (3.8817)  Time: 1.702s,   75.20/s  (1.499s,   85.40/s)  LR: 1.842e-04  Data: 0.007 (0.008)
2024-04-07 15:50:53,038 - train - INFO - Train: 89 [ 550/781 ( 71%)]  Loss:  4.419012 (3.8794)  Time: 1.396s,   91.66/s  (1.506s,   85.00/s)  LR: 1.842e-04  Data: 0.007 (0.008)
2024-04-07 15:52:06,698 - train - INFO - Train: 89 [ 600/781 ( 77%)]  Loss:  3.315000 (3.8771)  Time: 1.376s,   93.01/s  (1.503s,   85.16/s)  LR: 1.842e-04  Data: 0.007 (0.008)
2024-04-07 15:53:20,312 - train - INFO - Train: 89 [ 650/781 ( 83%)]  Loss:  3.382855 (3.8849)  Time: 1.475s,   86.79/s  (1.501s,   85.29/s)  LR: 1.842e-04  Data: 0.004 (0.008)
2024-04-07 15:54:32,973 - train - INFO - Train: 89 [ 700/781 ( 90%)]  Loss:  3.369107 (3.8797)  Time: 1.287s,   99.49/s  (1.497s,   85.48/s)  LR: 1.842e-04  Data: 0.007 (0.008)
2024-04-07 15:55:45,482 - train - INFO - Train: 89 [ 750/781 ( 96%)]  Loss:  3.791077 (3.8829)  Time: 1.297s,   98.65/s  (1.494s,   85.66/s)  LR: 1.842e-04  Data: 0.006 (0.008)
2024-04-07 15:56:29,807 - train - INFO - Train: 89 [ 780/781 (100%)]  Loss:  3.817296 (3.8853)  Time: 1.476s,   86.74/s  (1.494s,   85.70/s)  LR: 1.842e-04  Data: 0.000 (0.008)
2024-04-07 15:56:29,808 - train - INFO - True
2024-04-07 15:56:29,821 - train - INFO - alphas:tensor([0.0024, 0.0037, 0.0325, 0.3565, 0.6049], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:29,839 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:29,839 - train - INFO - True
2024-04-07 15:56:29,853 - train - INFO - alphas:tensor([0.1146, 0.0165, 0.0352, 0.1282, 0.7055], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:29,868 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:29,869 - train - INFO - True
2024-04-07 15:56:29,882 - train - INFO - alphas:tensor([0.5159, 0.0778, 0.0539, 0.1348, 0.2176], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:29,908 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:29,908 - train - INFO - True
2024-04-07 15:56:29,921 - train - INFO - alphas:tensor([0.4360, 0.0146, 0.0261, 0.1184, 0.4049], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:29,944 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:29,944 - train - INFO - True
2024-04-07 15:56:29,958 - train - INFO - alphas:tensor([0.2652, 0.0103, 0.0418, 0.1318, 0.5510], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:29,968 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:29,968 - train - INFO - True
2024-04-07 15:56:29,982 - train - INFO - alphas:tensor([0.3766, 0.0058, 0.0203, 0.0873, 0.5100], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:29,992 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:29,992 - train - INFO - True
2024-04-07 15:56:30,005 - train - INFO - alphas:tensor([0.5227, 0.0246, 0.0145, 0.1074, 0.3308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,026 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,026 - train - INFO - True
2024-04-07 15:56:30,040 - train - INFO - alphas:tensor([0.4059, 0.0107, 0.0051, 0.0898, 0.4884], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,050 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,050 - train - INFO - True
2024-04-07 15:56:30,062 - train - INFO - alphas:tensor([0.3223, 0.0074, 0.0240, 0.1024, 0.5438], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,071 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,072 - train - INFO - True
2024-04-07 15:56:30,085 - train - INFO - alphas:tensor([0.4391, 0.0041, 0.0176, 0.0674, 0.4718], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,093 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,093 - train - INFO - True
2024-04-07 15:56:30,104 - train - INFO - alphas:tensor([0.4305, 0.0136, 0.0115, 0.1017, 0.4427], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,112 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,112 - train - INFO - True
2024-04-07 15:56:30,114 - train - INFO - alphas:tensor([0.3397, 0.0049, 0.0049, 0.1090, 0.5416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,122 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,122 - train - INFO - True
2024-04-07 15:56:30,123 - train - INFO - alphas:tensor([0.3304, 0.0042, 0.0169, 0.0911, 0.5573], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,132 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,132 - train - INFO - True
2024-04-07 15:56:30,133 - train - INFO - alphas:tensor([0.4369, 0.0015, 0.0107, 0.0498, 0.5010], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,142 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,142 - train - INFO - True
2024-04-07 15:56:30,143 - train - INFO - alphas:tensor([0.3517, 0.0170, 0.0091, 0.1115, 0.5107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,154 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,154 - train - INFO - True
2024-04-07 15:56:30,155 - train - INFO - alphas:tensor([0.2577, 0.0032, 0.0022, 0.1265, 0.6104], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,166 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,166 - train - INFO - True
2024-04-07 15:56:30,171 - train - INFO - alphas:tensor([0.3179, 0.0046, 0.0119, 0.0826, 0.5830], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,181 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,181 - train - INFO - True
2024-04-07 15:56:30,185 - train - INFO - alphas:tensor([0.4297, 0.0013, 0.0090, 0.0456, 0.5144], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,194 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,194 - train - INFO - True
2024-04-07 15:56:30,199 - train - INFO - alphas:tensor([0.3676, 0.0042, 0.0037, 0.0956, 0.5290], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,208 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,208 - train - INFO - True
2024-04-07 15:56:30,214 - train - INFO - alphas:tensor([0.2655, 0.0018, 0.0014, 0.1022, 0.6290], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,222 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,222 - train - INFO - True
2024-04-07 15:56:30,228 - train - INFO - alphas:tensor([0.2744, 0.0025, 0.0107, 0.0801, 0.6324], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,236 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,236 - train - INFO - True
2024-04-07 15:56:30,243 - train - INFO - alphas:tensor([0.4106, 0.0009, 0.0077, 0.0378, 0.5429], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,251 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,251 - train - INFO - True
2024-04-07 15:56:30,255 - train - INFO - alphas:tensor([0.4159, 0.0062, 0.0032, 0.0676, 0.5071], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,264 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,264 - train - INFO - True
2024-04-07 15:56:30,266 - train - INFO - alphas:tensor([0.3089, 0.0012, 0.0007, 0.0652, 0.6239], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,274 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,274 - train - INFO - True
2024-04-07 15:56:30,276 - train - INFO - alphas:tensor([0.2691, 0.0020, 0.0093, 0.0699, 0.6497], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,285 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,285 - train - INFO - True
2024-04-07 15:56:30,289 - train - INFO - alphas:tensor([0.4016, 0.0009, 0.0070, 0.0303, 0.5601], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,298 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,298 - train - INFO - True
2024-04-07 15:56:30,301 - train - INFO - alphas:tensor([0.4510, 0.0016, 0.0021, 0.0570, 0.4883], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,312 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,312 - train - INFO - True
2024-04-07 15:56:30,314 - train - INFO - alphas:tensor([3.4011e-01, 1.2601e-03, 5.6292e-04, 4.9105e-02, 6.0897e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,325 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,325 - train - INFO - True
2024-04-07 15:56:30,328 - train - INFO - alphas:tensor([0.2450, 0.0016, 0.0087, 0.0721, 0.6726], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,338 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,338 - train - INFO - True
2024-04-07 15:56:30,340 - train - INFO - alphas:tensor([3.7298e-01, 4.5807e-04, 5.0404e-03, 3.4670e-02, 5.8685e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,350 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,350 - train - INFO - True
2024-04-07 15:56:30,363 - train - INFO - alphas:tensor([0.4774, 0.0015, 0.0018, 0.0477, 0.4716], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,380 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,380 - train - INFO - True
2024-04-07 15:56:30,389 - train - INFO - alphas:tensor([3.7971e-01, 5.6629e-04, 7.4421e-04, 5.2237e-02, 5.6674e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,398 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,398 - train - INFO - True
2024-04-07 15:56:30,412 - train - INFO - alphas:tensor([0.2249, 0.0014, 0.0079, 0.0603, 0.7055], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,420 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,420 - train - INFO - True
2024-04-07 15:56:30,429 - train - INFO - alphas:tensor([3.3583e-01, 2.6138e-04, 3.0730e-03, 2.3952e-02, 6.3689e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,438 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,438 - train - INFO - True
2024-04-07 15:56:30,452 - train - INFO - alphas:tensor([0.4511, 0.0025, 0.0022, 0.0544, 0.4898], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,463 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,463 - train - INFO - True
2024-04-07 15:56:30,472 - train - INFO - alphas:tensor([3.9804e-01, 4.9728e-04, 7.9753e-04, 4.8745e-02, 5.5192e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,483 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,483 - train - INFO - True
2024-04-07 15:56:30,496 - train - INFO - alphas:tensor([0.6271, 0.0246, 0.0975, 0.2508], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 15:56:30,514 - train - INFO - tau:0.41712087993322045
2024-04-07 15:56:30,514 - train - INFO - avg block size:13.972972972972974
2024-04-07 15:56:30,514 - train - INFO - current latency ratio:tensor(0.2038)
2024-04-07 15:56:31,143 - train - INFO - Test: [   0/78]  Time: 0.625 (0.625)  Loss:  0.9199 (0.9199)  Acc@1: 82.0312 (82.0312)  Acc@5: 93.7500 (93.7500)
2024-04-07 15:56:56,427 - train - INFO - Test: [  50/78]  Time: 0.523 (0.508)  Loss:  1.7344 (1.6456)  Acc@1: 60.9375 (61.4583)  Acc@5: 82.8125 (83.9308)
2024-04-07 15:57:10,427 - train - INFO - Test: [  78/78]  Time: 0.456 (0.505)  Loss:  1.6631 (1.6676)  Acc@1: 56.2500 (61.2000)  Acc@5: 87.5000 (83.4600)
2024-04-07 15:57:12,213 - train - INFO - Train: 90 [   0/781 (  0%)]  Loss:  3.945667 (3.9457)  Time: 1.717s,   74.56/s  (1.717s,   74.56/s)  LR: 1.793e-04  Data: 0.195 (0.195)
2024-04-07 15:58:25,817 - train - INFO - Train: 90 [  50/781 (  6%)]  Loss:  3.313507 (3.8818)  Time: 1.486s,   86.14/s  (1.477s,   86.67/s)  LR: 1.793e-04  Data: 0.008 (0.010)
2024-04-07 15:59:38,743 - train - INFO - Train: 90 [ 100/781 ( 13%)]  Loss:  3.905256 (3.8456)  Time: 1.378s,   92.91/s  (1.468s,   87.21/s)  LR: 1.793e-04  Data: 0.008 (0.009)
2024-04-07 16:00:53,127 - train - INFO - Train: 90 [ 150/781 ( 19%)]  Loss:  3.283834 (3.8332)  Time: 1.395s,   91.74/s  (1.474s,   86.82/s)  LR: 1.793e-04  Data: 0.008 (0.008)
2024-04-07 16:02:05,581 - train - INFO - Train: 90 [ 200/781 ( 26%)]  Loss:  3.430100 (3.8362)  Time: 1.397s,   91.62/s  (1.468s,   87.19/s)  LR: 1.793e-04  Data: 0.007 (0.008)
2024-04-07 16:03:19,230 - train - INFO - Train: 90 [ 250/781 ( 32%)]  Loss:  4.411581 (3.8321)  Time: 1.368s,   93.60/s  (1.469s,   87.13/s)  LR: 1.793e-04  Data: 0.007 (0.008)
2024-04-07 16:04:30,759 - train - INFO - Train: 90 [ 300/781 ( 38%)]  Loss:  3.256697 (3.8333)  Time: 1.432s,   89.40/s  (1.463s,   87.51/s)  LR: 1.793e-04  Data: 0.006 (0.008)
2024-04-07 16:05:44,197 - train - INFO - Train: 90 [ 350/781 ( 45%)]  Loss:  3.380085 (3.8449)  Time: 1.357s,   94.31/s  (1.463s,   87.46/s)  LR: 1.793e-04  Data: 0.007 (0.008)
2024-04-07 16:06:57,566 - train - INFO - Train: 90 [ 400/781 ( 51%)]  Loss:  3.866003 (3.8482)  Time: 1.412s,   90.63/s  (1.464s,   87.43/s)  LR: 1.793e-04  Data: 0.009 (0.008)
2024-04-07 16:08:11,565 - train - INFO - Train: 90 [ 450/781 ( 58%)]  Loss:  3.832772 (3.8517)  Time: 1.568s,   81.62/s  (1.466s,   87.33/s)  LR: 1.793e-04  Data: 0.005 (0.008)
2024-04-07 16:09:24,902 - train - INFO - Train: 90 [ 500/781 ( 64%)]  Loss:  4.041133 (3.8642)  Time: 1.462s,   87.55/s  (1.466s,   87.32/s)  LR: 1.793e-04  Data: 0.007 (0.008)
2024-04-07 16:10:38,394 - train - INFO - Train: 90 [ 550/781 ( 71%)]  Loss:  3.570310 (3.8663)  Time: 1.516s,   84.46/s  (1.466s,   87.30/s)  LR: 1.793e-04  Data: 0.008 (0.008)
2024-04-07 16:11:52,862 - train - INFO - Train: 90 [ 600/781 ( 77%)]  Loss:  4.320978 (3.8685)  Time: 1.471s,   87.00/s  (1.468s,   87.19/s)  LR: 1.793e-04  Data: 0.015 (0.007)
2024-04-07 16:13:06,531 - train - INFO - Train: 90 [ 650/781 ( 83%)]  Loss:  4.048818 (3.8681)  Time: 1.428s,   89.62/s  (1.469s,   87.16/s)  LR: 1.793e-04  Data: 0.005 (0.007)
2024-04-07 16:14:19,230 - train - INFO - Train: 90 [ 700/781 ( 90%)]  Loss:  3.563410 (3.8747)  Time: 1.551s,   82.52/s  (1.467s,   87.22/s)  LR: 1.793e-04  Data: 0.008 (0.007)
2024-04-07 16:15:32,247 - train - INFO - Train: 90 [ 750/781 ( 96%)]  Loss:  3.723481 (3.8806)  Time: 1.472s,   86.93/s  (1.467s,   87.25/s)  LR: 1.793e-04  Data: 0.007 (0.007)
2024-04-07 16:16:16,076 - train - INFO - Train: 90 [ 780/781 (100%)]  Loss:  3.652778 (3.8797)  Time: 1.357s,   94.30/s  (1.467s,   87.27/s)  LR: 1.793e-04  Data: 0.000 (0.007)
2024-04-07 16:16:16,076 - train - INFO - True
2024-04-07 16:16:16,079 - train - INFO - alphas:tensor([0.0022, 0.0035, 0.0319, 0.3595, 0.6028], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,097 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,097 - train - INFO - True
2024-04-07 16:16:16,101 - train - INFO - alphas:tensor([0.1155, 0.0162, 0.0347, 0.1268, 0.7068], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,117 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,117 - train - INFO - True
2024-04-07 16:16:16,120 - train - INFO - alphas:tensor([0.5190, 0.0774, 0.0529, 0.1337, 0.2171], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,149 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,149 - train - INFO - True
2024-04-07 16:16:16,162 - train - INFO - alphas:tensor([0.4390, 0.0142, 0.0254, 0.1171, 0.4043], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,187 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,187 - train - INFO - True
2024-04-07 16:16:16,199 - train - INFO - alphas:tensor([0.2658, 0.0100, 0.0412, 0.1305, 0.5525], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,211 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,211 - train - INFO - True
2024-04-07 16:16:16,224 - train - INFO - alphas:tensor([0.3790, 0.0056, 0.0196, 0.0858, 0.5101], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,234 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,234 - train - INFO - True
2024-04-07 16:16:16,248 - train - INFO - alphas:tensor([0.5253, 0.0240, 0.0139, 0.1059, 0.3308], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,267 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,267 - train - INFO - True
2024-04-07 16:16:16,279 - train - INFO - alphas:tensor([0.4073, 0.0104, 0.0049, 0.0883, 0.4891], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,288 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,288 - train - INFO - True
2024-04-07 16:16:16,302 - train - INFO - alphas:tensor([0.3237, 0.0072, 0.0234, 0.1006, 0.5452], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,310 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,310 - train - INFO - True
2024-04-07 16:16:16,324 - train - INFO - alphas:tensor([0.4402, 0.0039, 0.0170, 0.0663, 0.4726], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,333 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,333 - train - INFO - True
2024-04-07 16:16:16,346 - train - INFO - alphas:tensor([0.4331, 0.0134, 0.0110, 0.1006, 0.4419], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,356 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,356 - train - INFO - True
2024-04-07 16:16:16,369 - train - INFO - alphas:tensor([0.3425, 0.0047, 0.0046, 0.1071, 0.5411], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,380 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,380 - train - INFO - True
2024-04-07 16:16:16,393 - train - INFO - alphas:tensor([0.3302, 0.0040, 0.0165, 0.0899, 0.5594], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,403 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,403 - train - INFO - True
2024-04-07 16:16:16,404 - train - INFO - alphas:tensor([0.4394, 0.0014, 0.0102, 0.0486, 0.5003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,414 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,414 - train - INFO - True
2024-04-07 16:16:16,415 - train - INFO - alphas:tensor([0.3532, 0.0167, 0.0087, 0.1100, 0.5114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,424 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,424 - train - INFO - True
2024-04-07 16:16:16,426 - train - INFO - alphas:tensor([0.2590, 0.0030, 0.0021, 0.1248, 0.6111], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,435 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,435 - train - INFO - True
2024-04-07 16:16:16,437 - train - INFO - alphas:tensor([0.3177, 0.0043, 0.0115, 0.0811, 0.5854], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,446 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,446 - train - INFO - True
2024-04-07 16:16:16,451 - train - INFO - alphas:tensor([0.4333, 0.0012, 0.0086, 0.0444, 0.5125], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,460 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,460 - train - INFO - True
2024-04-07 16:16:16,465 - train - INFO - alphas:tensor([0.3710, 0.0040, 0.0035, 0.0942, 0.5273], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,474 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,474 - train - INFO - True
2024-04-07 16:16:16,479 - train - INFO - alphas:tensor([0.2713, 0.0018, 0.0013, 0.1006, 0.6250], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,487 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,487 - train - INFO - True
2024-04-07 16:16:16,493 - train - INFO - alphas:tensor([0.2763, 0.0024, 0.0104, 0.0788, 0.6322], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,504 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,504 - train - INFO - True
2024-04-07 16:16:16,511 - train - INFO - alphas:tensor([0.4116, 0.0009, 0.0074, 0.0371, 0.5430], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,522 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,522 - train - INFO - True
2024-04-07 16:16:16,525 - train - INFO - alphas:tensor([0.4176, 0.0059, 0.0030, 0.0663, 0.5072], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,535 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,535 - train - INFO - True
2024-04-07 16:16:16,539 - train - INFO - alphas:tensor([0.3113, 0.0012, 0.0007, 0.0645, 0.6224], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,549 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,549 - train - INFO - True
2024-04-07 16:16:16,554 - train - INFO - alphas:tensor([0.2687, 0.0019, 0.0090, 0.0688, 0.6516], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,563 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,563 - train - INFO - True
2024-04-07 16:16:16,566 - train - INFO - alphas:tensor([0.4024, 0.0009, 0.0068, 0.0294, 0.5606], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,575 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,575 - train - INFO - True
2024-04-07 16:16:16,578 - train - INFO - alphas:tensor([0.4524, 0.0015, 0.0020, 0.0557, 0.4885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,587 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,587 - train - INFO - True
2024-04-07 16:16:16,589 - train - INFO - alphas:tensor([3.4124e-01, 1.1939e-03, 5.1993e-04, 4.8007e-02, 6.0903e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,598 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,598 - train - INFO - True
2024-04-07 16:16:16,600 - train - INFO - alphas:tensor([0.2476, 0.0016, 0.0084, 0.0703, 0.6722], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,609 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,609 - train - INFO - True
2024-04-07 16:16:16,611 - train - INFO - alphas:tensor([3.7531e-01, 4.1981e-04, 4.8822e-03, 3.3875e-02, 5.8551e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,620 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,620 - train - INFO - True
2024-04-07 16:16:16,622 - train - INFO - alphas:tensor([0.4778, 0.0014, 0.0017, 0.0469, 0.4722], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,639 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,639 - train - INFO - True
2024-04-07 16:16:16,642 - train - INFO - alphas:tensor([3.8095e-01, 5.2900e-04, 6.8834e-04, 5.0982e-02, 5.6685e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,653 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,653 - train - INFO - True
2024-04-07 16:16:16,665 - train - INFO - alphas:tensor([0.2251, 0.0013, 0.0075, 0.0588, 0.7073], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,675 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,675 - train - INFO - True
2024-04-07 16:16:16,683 - train - INFO - alphas:tensor([3.3792e-01, 2.4291e-04, 2.8982e-03, 2.3424e-02, 6.3551e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,693 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,693 - train - INFO - True
2024-04-07 16:16:16,706 - train - INFO - alphas:tensor([0.4516, 0.0024, 0.0020, 0.0534, 0.4906], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,715 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,715 - train - INFO - True
2024-04-07 16:16:16,723 - train - INFO - alphas:tensor([3.9947e-01, 4.6022e-04, 7.4318e-04, 4.7782e-02, 5.5155e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,732 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,732 - train - INFO - True
2024-04-07 16:16:16,746 - train - INFO - alphas:tensor([0.6269, 0.0240, 0.0970, 0.2521], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:16:16,762 - train - INFO - tau:0.41294967113388825
2024-04-07 16:16:16,763 - train - INFO - avg block size:13.972972972972974
2024-04-07 16:16:16,763 - train - INFO - current latency ratio:tensor(0.2038)
2024-04-07 16:16:16,763 - train - INFO - lasso_alpha:6.115909044841464e-05
2024-04-07 16:16:17,290 - train - INFO - Test: [   0/78]  Time: 0.524 (0.524)  Loss:  0.8906 (0.8906)  Acc@1: 82.8125 (82.8125)  Acc@5: 94.5312 (94.5312)
2024-04-07 16:16:42,731 - train - INFO - Test: [  50/78]  Time: 0.563 (0.509)  Loss:  1.8877 (1.6343)  Acc@1: 54.6875 (61.2745)  Acc@5: 82.8125 (84.0993)
2024-04-07 16:16:56,708 - train - INFO - Test: [  78/78]  Time: 0.396 (0.506)  Loss:  1.6016 (1.6648)  Acc@1: 56.2500 (60.8100)  Acc@5: 93.7500 (83.5300)
2024-04-07 16:16:58,464 - train - INFO - Train: 91 [   0/781 (  0%)]  Loss:  3.210793 (3.2108)  Time: 1.686s,   75.91/s  (1.686s,   75.91/s)  LR: 1.744e-04  Data: 0.179 (0.179)
2024-04-07 16:18:09,670 - train - INFO - Train: 91 [  50/781 (  6%)]  Loss:  4.282567 (3.8331)  Time: 1.467s,   87.23/s  (1.429s,   89.56/s)  LR: 1.744e-04  Data: 0.007 (0.010)
2024-04-07 16:19:23,329 - train - INFO - Train: 91 [ 100/781 ( 13%)]  Loss:  3.730451 (3.8247)  Time: 1.584s,   80.81/s  (1.451s,   88.22/s)  LR: 1.744e-04  Data: 0.008 (0.009)
2024-04-07 16:20:37,506 - train - INFO - Train: 91 [ 150/781 ( 19%)]  Loss:  3.747794 (3.8537)  Time: 1.538s,   83.21/s  (1.462s,   87.57/s)  LR: 1.744e-04  Data: 0.008 (0.009)
2024-04-07 16:21:51,798 - train - INFO - Train: 91 [ 200/781 ( 26%)]  Loss:  4.143100 (3.8458)  Time: 1.505s,   85.03/s  (1.468s,   87.21/s)  LR: 1.744e-04  Data: 0.007 (0.008)
2024-04-07 16:23:03,852 - train - INFO - Train: 91 [ 250/781 ( 32%)]  Loss:  3.413399 (3.8483)  Time: 1.390s,   92.08/s  (1.462s,   87.53/s)  LR: 1.744e-04  Data: 0.007 (0.008)
2024-04-07 16:24:17,808 - train - INFO - Train: 91 [ 300/781 ( 38%)]  Loss:  3.220960 (3.8657)  Time: 1.395s,   91.77/s  (1.465s,   87.36/s)  LR: 1.744e-04  Data: 0.007 (0.008)
2024-04-07 16:25:31,653 - train - INFO - Train: 91 [ 350/781 ( 45%)]  Loss:  4.048737 (3.8670)  Time: 1.440s,   88.92/s  (1.467s,   87.26/s)  LR: 1.744e-04  Data: 0.006 (0.008)
2024-04-07 16:26:46,348 - train - INFO - Train: 91 [ 400/781 ( 51%)]  Loss:  4.376175 (3.8579)  Time: 1.459s,   87.73/s  (1.470s,   87.06/s)  LR: 1.744e-04  Data: 0.007 (0.008)
2024-04-07 16:27:58,036 - train - INFO - Train: 91 [ 450/781 ( 58%)]  Loss:  4.444102 (3.8674)  Time: 1.382s,   92.60/s  (1.466s,   87.30/s)  LR: 1.744e-04  Data: 0.008 (0.008)
2024-04-07 16:29:11,431 - train - INFO - Train: 91 [ 500/781 ( 64%)]  Loss:  3.499542 (3.8689)  Time: 1.459s,   87.75/s  (1.466s,   87.29/s)  LR: 1.744e-04  Data: 0.008 (0.008)
2024-04-07 16:30:24,666 - train - INFO - Train: 91 [ 550/781 ( 71%)]  Loss:  3.043922 (3.8744)  Time: 1.400s,   91.40/s  (1.466s,   87.30/s)  LR: 1.744e-04  Data: 0.006 (0.008)
2024-04-07 16:31:37,501 - train - INFO - Train: 91 [ 600/781 ( 77%)]  Loss:  3.470722 (3.8758)  Time: 1.398s,   91.54/s  (1.465s,   87.35/s)  LR: 1.744e-04  Data: 0.006 (0.008)
2024-04-07 16:32:50,408 - train - INFO - Train: 91 [ 650/781 ( 83%)]  Loss:  3.850651 (3.8744)  Time: 1.486s,   86.15/s  (1.465s,   87.38/s)  LR: 1.744e-04  Data: 0.008 (0.008)
2024-04-07 16:34:03,696 - train - INFO - Train: 91 [ 700/781 ( 90%)]  Loss:  3.297371 (3.8753)  Time: 1.593s,   80.34/s  (1.465s,   87.38/s)  LR: 1.744e-04  Data: 0.007 (0.008)
2024-04-07 16:35:16,176 - train - INFO - Train: 91 [ 750/781 ( 96%)]  Loss:  3.649144 (3.8713)  Time: 1.452s,   88.18/s  (1.464s,   87.44/s)  LR: 1.744e-04  Data: 0.007 (0.008)
2024-04-07 16:36:00,441 - train - INFO - Train: 91 [ 780/781 (100%)]  Loss:  3.336568 (3.8702)  Time: 1.469s,   87.10/s  (1.464s,   87.41/s)  LR: 1.744e-04  Data: 0.000 (0.008)
2024-04-07 16:36:00,442 - train - INFO - True
2024-04-07 16:36:00,449 - train - INFO - alphas:tensor([0.0021, 0.0033, 0.0315, 0.3616, 0.6016], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,470 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,470 - train - INFO - True
2024-04-07 16:36:00,473 - train - INFO - alphas:tensor([0.1164, 0.0160, 0.0344, 0.1257, 0.7075], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,491 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,491 - train - INFO - True
2024-04-07 16:36:00,497 - train - INFO - alphas:tensor([0.5221, 0.0764, 0.0520, 0.1326, 0.2169], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,528 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,528 - train - INFO - True
2024-04-07 16:36:00,532 - train - INFO - alphas:tensor([0.4415, 0.0138, 0.0247, 0.1156, 0.4043], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,559 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,559 - train - INFO - True
2024-04-07 16:36:00,569 - train - INFO - alphas:tensor([0.2673, 0.0098, 0.0406, 0.1292, 0.5530], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,581 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,582 - train - INFO - True
2024-04-07 16:36:00,595 - train - INFO - alphas:tensor([0.3800, 0.0053, 0.0190, 0.0849, 0.5108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,606 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,607 - train - INFO - True
2024-04-07 16:36:00,620 - train - INFO - alphas:tensor([0.5280, 0.0234, 0.0134, 0.1047, 0.3305], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,640 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,640 - train - INFO - True
2024-04-07 16:36:00,653 - train - INFO - alphas:tensor([0.4114, 0.0100, 0.0046, 0.0863, 0.4877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,662 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,662 - train - INFO - True
2024-04-07 16:36:00,675 - train - INFO - alphas:tensor([0.3244, 0.0069, 0.0228, 0.0991, 0.5467], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,684 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,684 - train - INFO - True
2024-04-07 16:36:00,698 - train - INFO - alphas:tensor([0.4418, 0.0037, 0.0165, 0.0647, 0.4733], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,709 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,709 - train - INFO - True
2024-04-07 16:36:00,722 - train - INFO - alphas:tensor([0.4366, 0.0129, 0.0105, 0.0986, 0.4414], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,732 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,732 - train - INFO - True
2024-04-07 16:36:00,745 - train - INFO - alphas:tensor([0.3470, 0.0045, 0.0044, 0.1059, 0.5383], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,754 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,754 - train - INFO - True
2024-04-07 16:36:00,767 - train - INFO - alphas:tensor([0.3329, 0.0039, 0.0160, 0.0883, 0.5590], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,776 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,776 - train - INFO - True
2024-04-07 16:36:00,790 - train - INFO - alphas:tensor([0.4426, 0.0013, 0.0099, 0.0473, 0.4988], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,798 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,798 - train - INFO - True
2024-04-07 16:36:00,812 - train - INFO - alphas:tensor([0.3606, 0.0162, 0.0084, 0.1082, 0.5066], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,821 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,821 - train - INFO - True
2024-04-07 16:36:00,835 - train - INFO - alphas:tensor([0.2659, 0.0029, 0.0020, 0.1238, 0.6054], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,845 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,845 - train - INFO - True
2024-04-07 16:36:00,855 - train - INFO - alphas:tensor([0.3193, 0.0042, 0.0112, 0.0802, 0.5851], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,865 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,865 - train - INFO - True
2024-04-07 16:36:00,867 - train - INFO - alphas:tensor([0.4350, 0.0011, 0.0082, 0.0432, 0.5124], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,877 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,877 - train - INFO - True
2024-04-07 16:36:00,878 - train - INFO - alphas:tensor([0.3757, 0.0038, 0.0033, 0.0926, 0.5246], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,888 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,888 - train - INFO - True
2024-04-07 16:36:00,889 - train - INFO - alphas:tensor([0.2754, 0.0017, 0.0012, 0.0997, 0.6220], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,899 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,899 - train - INFO - True
2024-04-07 16:36:00,901 - train - INFO - alphas:tensor([0.2767, 0.0023, 0.0101, 0.0773, 0.6336], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,910 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,910 - train - INFO - True
2024-04-07 16:36:00,912 - train - INFO - alphas:tensor([0.4145, 0.0008, 0.0071, 0.0360, 0.5416], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,921 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,921 - train - INFO - True
2024-04-07 16:36:00,925 - train - INFO - alphas:tensor([0.4225, 0.0056, 0.0028, 0.0646, 0.5044], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,933 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,933 - train - INFO - True
2024-04-07 16:36:00,936 - train - INFO - alphas:tensor([3.1591e-01, 1.1145e-03, 6.1446e-04, 6.2586e-02, 6.1977e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,944 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,944 - train - INFO - True
2024-04-07 16:36:00,949 - train - INFO - alphas:tensor([0.2690, 0.0018, 0.0086, 0.0675, 0.6531], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,958 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,958 - train - INFO - True
2024-04-07 16:36:00,964 - train - INFO - alphas:tensor([0.4068, 0.0008, 0.0065, 0.0285, 0.5575], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,972 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,972 - train - INFO - True
2024-04-07 16:36:00,975 - train - INFO - alphas:tensor([0.4565, 0.0014, 0.0018, 0.0542, 0.4861], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,983 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,984 - train - INFO - True
2024-04-07 16:36:00,985 - train - INFO - alphas:tensor([3.4502e-01, 1.1380e-03, 4.8446e-04, 4.6713e-02, 6.0664e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:00,994 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:00,994 - train - INFO - True
2024-04-07 16:36:00,998 - train - INFO - alphas:tensor([0.2493, 0.0015, 0.0081, 0.0689, 0.6722], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:01,009 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:01,009 - train - INFO - True
2024-04-07 16:36:01,013 - train - INFO - alphas:tensor([3.7899e-01, 3.9164e-04, 4.6488e-03, 3.2843e-02, 5.8313e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:01,023 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:01,023 - train - INFO - True
2024-04-07 16:36:01,027 - train - INFO - alphas:tensor([0.4834, 0.0013, 0.0016, 0.0456, 0.4681], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:01,046 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:01,046 - train - INFO - True
2024-04-07 16:36:01,048 - train - INFO - alphas:tensor([3.8555e-01, 4.9453e-04, 6.3420e-04, 4.9666e-02, 5.6366e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:01,057 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:01,057 - train - INFO - True
2024-04-07 16:36:01,059 - train - INFO - alphas:tensor([0.2263, 0.0012, 0.0073, 0.0575, 0.7077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:01,068 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:01,068 - train - INFO - True
2024-04-07 16:36:01,070 - train - INFO - alphas:tensor([3.4202e-01, 2.2180e-04, 2.7288e-03, 2.2340e-02, 6.3269e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:01,079 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:01,079 - train - INFO - True
2024-04-07 16:36:01,082 - train - INFO - alphas:tensor([0.4565, 0.0023, 0.0019, 0.0519, 0.4874], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:01,090 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:01,090 - train - INFO - True
2024-04-07 16:36:01,099 - train - INFO - alphas:tensor([4.0503e-01, 4.2792e-04, 6.7755e-04, 4.6575e-02, 5.4729e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:01,107 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:01,107 - train - INFO - True
2024-04-07 16:36:01,109 - train - INFO - alphas:tensor([0.6291, 0.0234, 0.0959, 0.2516], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:36:01,125 - train - INFO - tau:0.40882017442254937
2024-04-07 16:36:01,126 - train - INFO - avg block size:13.972972972972974
2024-04-07 16:36:01,126 - train - INFO - current latency ratio:tensor(0.2038)
2024-04-07 16:36:01,702 - train - INFO - Test: [   0/78]  Time: 0.573 (0.573)  Loss:  0.8779 (0.8779)  Acc@1: 83.5938 (83.5938)  Acc@5: 94.5312 (94.5312)
2024-04-07 16:36:26,986 - train - INFO - Test: [  50/78]  Time: 0.457 (0.507)  Loss:  1.8369 (1.6394)  Acc@1: 56.2500 (61.6422)  Acc@5: 83.5938 (83.8388)
2024-04-07 16:36:38,967 - train - INFO - Test: [  78/78]  Time: 0.486 (0.479)  Loss:  1.5732 (1.6703)  Acc@1: 56.2500 (61.0300)  Acc@5: 81.2500 (83.3800)
2024-04-07 16:36:40,868 - train - INFO - Train: 92 [   0/781 (  0%)]  Loss:  4.313515 (4.3135)  Time: 1.829s,   70.00/s  (1.829s,   70.00/s)  LR: 1.696e-04  Data: 0.192 (0.192)
2024-04-07 16:37:53,570 - train - INFO - Train: 92 [  50/781 (  6%)]  Loss:  4.125465 (3.8307)  Time: 1.415s,   90.45/s  (1.461s,   87.59/s)  LR: 1.696e-04  Data: 0.007 (0.011)
2024-04-07 16:39:06,853 - train - INFO - Train: 92 [ 100/781 ( 13%)]  Loss:  3.835939 (3.8633)  Time: 1.398s,   91.58/s  (1.463s,   87.46/s)  LR: 1.696e-04  Data: 0.008 (0.009)
2024-04-07 16:40:21,053 - train - INFO - Train: 92 [ 150/781 ( 19%)]  Loss:  4.029932 (3.9010)  Time: 1.633s,   78.37/s  (1.470s,   87.06/s)  LR: 1.696e-04  Data: 0.008 (0.008)
2024-04-07 16:41:32,627 - train - INFO - Train: 92 [ 200/781 ( 26%)]  Loss:  4.315247 (3.9061)  Time: 1.383s,   92.52/s  (1.461s,   87.64/s)  LR: 1.696e-04  Data: 0.005 (0.008)
2024-04-07 16:42:47,956 - train - INFO - Train: 92 [ 250/781 ( 32%)]  Loss:  3.521254 (3.9213)  Time: 1.380s,   92.76/s  (1.470s,   87.09/s)  LR: 1.696e-04  Data: 0.004 (0.008)
2024-04-07 16:44:02,241 - train - INFO - Train: 92 [ 300/781 ( 38%)]  Loss:  3.295355 (3.8994)  Time: 1.371s,   93.36/s  (1.472s,   86.93/s)  LR: 1.696e-04  Data: 0.006 (0.008)
2024-04-07 16:45:16,784 - train - INFO - Train: 92 [ 350/781 ( 45%)]  Loss:  3.271416 (3.8835)  Time: 1.425s,   89.82/s  (1.475s,   86.78/s)  LR: 1.696e-04  Data: 0.007 (0.008)
2024-04-07 16:46:29,616 - train - INFO - Train: 92 [ 400/781 ( 51%)]  Loss:  4.400302 (3.8860)  Time: 1.498s,   85.47/s  (1.473s,   86.91/s)  LR: 1.696e-04  Data: 0.007 (0.008)
2024-04-07 16:47:42,921 - train - INFO - Train: 92 [ 450/781 ( 58%)]  Loss:  3.728634 (3.8831)  Time: 1.489s,   85.98/s  (1.472s,   86.96/s)  LR: 1.696e-04  Data: 0.008 (0.008)
2024-04-07 16:48:57,097 - train - INFO - Train: 92 [ 500/781 ( 64%)]  Loss:  4.465134 (3.8867)  Time: 1.390s,   92.11/s  (1.473s,   86.89/s)  LR: 1.696e-04  Data: 0.007 (0.008)
2024-04-07 16:50:10,574 - train - INFO - Train: 92 [ 550/781 ( 71%)]  Loss:  4.292574 (3.8810)  Time: 1.428s,   89.62/s  (1.473s,   86.91/s)  LR: 1.696e-04  Data: 0.007 (0.008)
2024-04-07 16:51:22,925 - train - INFO - Train: 92 [ 600/781 ( 77%)]  Loss:  4.431381 (3.8825)  Time: 1.451s,   88.23/s  (1.471s,   87.04/s)  LR: 1.696e-04  Data: 0.007 (0.008)
2024-04-07 16:52:36,857 - train - INFO - Train: 92 [ 650/781 ( 83%)]  Loss:  3.913221 (3.8813)  Time: 1.437s,   89.07/s  (1.471s,   87.00/s)  LR: 1.696e-04  Data: 0.005 (0.008)
2024-04-07 16:53:50,565 - train - INFO - Train: 92 [ 700/781 ( 90%)]  Loss:  3.801555 (3.8810)  Time: 1.398s,   91.54/s  (1.471s,   86.99/s)  LR: 1.696e-04  Data: 0.007 (0.008)
2024-04-07 16:55:02,546 - train - INFO - Train: 92 [ 750/781 ( 96%)]  Loss:  3.658567 (3.8826)  Time: 1.335s,   95.88/s  (1.469s,   87.11/s)  LR: 1.696e-04  Data: 0.008 (0.008)
2024-04-07 16:55:44,876 - train - INFO - Train: 92 [ 780/781 (100%)]  Loss:  3.912466 (3.8829)  Time: 1.374s,   93.16/s  (1.467s,   87.25/s)  LR: 1.696e-04  Data: 0.000 (0.008)
2024-04-07 16:55:44,877 - train - INFO - True
2024-04-07 16:55:44,883 - train - INFO - alphas:tensor([0.0019, 0.0031, 0.0310, 0.3626, 0.6013], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:44,901 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:44,901 - train - INFO - True
2024-04-07 16:55:44,907 - train - INFO - alphas:tensor([0.1175, 0.0159, 0.0341, 0.1245, 0.7080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:44,923 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:44,923 - train - INFO - True
2024-04-07 16:55:44,925 - train - INFO - alphas:tensor([0.5257, 0.0756, 0.0511, 0.1314, 0.2163], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:44,953 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:44,954 - train - INFO - True
2024-04-07 16:55:44,966 - train - INFO - alphas:tensor([0.4437, 0.0134, 0.0240, 0.1142, 0.4047], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:44,991 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:44,991 - train - INFO - True
2024-04-07 16:55:45,004 - train - INFO - alphas:tensor([0.2691, 0.0096, 0.0396, 0.1275, 0.5541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,015 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,015 - train - INFO - True
2024-04-07 16:55:45,029 - train - INFO - alphas:tensor([0.3818, 0.0051, 0.0184, 0.0835, 0.5112], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,039 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,040 - train - INFO - True
2024-04-07 16:55:45,053 - train - INFO - alphas:tensor([0.5300, 0.0228, 0.0129, 0.1034, 0.3309], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,074 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,074 - train - INFO - True
2024-04-07 16:55:45,088 - train - INFO - alphas:tensor([0.4119, 0.0096, 0.0043, 0.0850, 0.4892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,098 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,098 - train - INFO - True
2024-04-07 16:55:45,111 - train - INFO - alphas:tensor([0.3248, 0.0066, 0.0223, 0.0979, 0.5484], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,120 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,120 - train - INFO - True
2024-04-07 16:55:45,133 - train - INFO - alphas:tensor([0.4439, 0.0035, 0.0160, 0.0633, 0.4733], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,142 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,142 - train - INFO - True
2024-04-07 16:55:45,155 - train - INFO - alphas:tensor([0.4371, 0.0125, 0.0101, 0.0975, 0.4428], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,164 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,164 - train - INFO - True
2024-04-07 16:55:45,178 - train - INFO - alphas:tensor([0.3485, 0.0043, 0.0042, 0.1041, 0.5389], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,186 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,186 - train - INFO - True
2024-04-07 16:55:45,200 - train - INFO - alphas:tensor([0.3331, 0.0037, 0.0155, 0.0872, 0.5605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,211 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,211 - train - INFO - True
2024-04-07 16:55:45,225 - train - INFO - alphas:tensor([0.4444, 0.0013, 0.0095, 0.0461, 0.4987], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,234 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,234 - train - INFO - True
2024-04-07 16:55:45,246 - train - INFO - alphas:tensor([0.3618, 0.0158, 0.0080, 0.1069, 0.5076], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,255 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,256 - train - INFO - True
2024-04-07 16:55:45,257 - train - INFO - alphas:tensor([0.2653, 0.0028, 0.0019, 0.1225, 0.6075], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,266 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,266 - train - INFO - True
2024-04-07 16:55:45,267 - train - INFO - alphas:tensor([0.3203, 0.0040, 0.0108, 0.0785, 0.5864], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,276 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,276 - train - INFO - True
2024-04-07 16:55:45,277 - train - INFO - alphas:tensor([0.4382, 0.0010, 0.0079, 0.0423, 0.5107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,286 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,286 - train - INFO - True
2024-04-07 16:55:45,286 - train - INFO - alphas:tensor([0.3772, 0.0037, 0.0031, 0.0913, 0.5248], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,295 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,295 - train - INFO - True
2024-04-07 16:55:45,300 - train - INFO - alphas:tensor([0.2777, 0.0016, 0.0012, 0.0986, 0.6210], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,309 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,309 - train - INFO - True
2024-04-07 16:55:45,315 - train - INFO - alphas:tensor([0.2778, 0.0022, 0.0099, 0.0758, 0.6344], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,323 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,323 - train - INFO - True
2024-04-07 16:55:45,329 - train - INFO - alphas:tensor([0.4175, 0.0008, 0.0068, 0.0351, 0.5397], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,338 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,338 - train - INFO - True
2024-04-07 16:55:45,343 - train - INFO - alphas:tensor([0.4271, 0.0054, 0.0026, 0.0629, 0.5020], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,354 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,354 - train - INFO - True
2024-04-07 16:55:45,357 - train - INFO - alphas:tensor([3.1844e-01, 1.0611e-03, 5.6575e-04, 6.1730e-02, 6.1820e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,367 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,367 - train - INFO - True
2024-04-07 16:55:45,372 - train - INFO - alphas:tensor([0.2699, 0.0017, 0.0083, 0.0663, 0.6538], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,382 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,382 - train - INFO - True
2024-04-07 16:55:45,387 - train - INFO - alphas:tensor([0.4050, 0.0008, 0.0062, 0.0276, 0.5605], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,396 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,396 - train - INFO - True
2024-04-07 16:55:45,398 - train - INFO - alphas:tensor([0.4569, 0.0013, 0.0017, 0.0533, 0.4868], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,407 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,407 - train - INFO - True
2024-04-07 16:55:45,411 - train - INFO - alphas:tensor([3.4631e-01, 1.0677e-03, 4.4634e-04, 4.5640e-02, 6.0653e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,420 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,420 - train - INFO - True
2024-04-07 16:55:45,425 - train - INFO - alphas:tensor([0.2488, 0.0014, 0.0078, 0.0675, 0.6744], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,433 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,433 - train - INFO - True
2024-04-07 16:55:45,436 - train - INFO - alphas:tensor([3.7885e-01, 3.5790e-04, 4.4292e-03, 3.2105e-02, 5.8426e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,445 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,445 - train - INFO - True
2024-04-07 16:55:45,451 - train - INFO - alphas:tensor([0.4873, 0.0012, 0.0015, 0.0444, 0.4656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,467 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,467 - train - INFO - True
2024-04-07 16:55:45,468 - train - INFO - alphas:tensor([3.8745e-01, 4.5526e-04, 5.8460e-04, 4.8573e-02, 5.6294e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,477 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,477 - train - INFO - True
2024-04-07 16:55:45,490 - train - INFO - alphas:tensor([0.2269, 0.0012, 0.0070, 0.0561, 0.7089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,499 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,499 - train - INFO - True
2024-04-07 16:55:45,500 - train - INFO - alphas:tensor([3.4313e-01, 2.0170e-04, 2.5829e-03, 2.1595e-02, 6.3249e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,510 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,510 - train - INFO - True
2024-04-07 16:55:45,523 - train - INFO - alphas:tensor([0.4561, 0.0021, 0.0018, 0.0511, 0.4888], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,533 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,533 - train - INFO - True
2024-04-07 16:55:45,541 - train - INFO - alphas:tensor([4.0646e-01, 3.9881e-04, 6.2337e-04, 4.5516e-02, 5.4700e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,550 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,550 - train - INFO - True
2024-04-07 16:55:45,563 - train - INFO - alphas:tensor([0.6292, 0.0229, 0.0954, 0.2526], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 16:55:45,581 - train - INFO - tau:0.4047319726783239
2024-04-07 16:55:45,581 - train - INFO - avg block size:13.972972972972974
2024-04-07 16:55:45,581 - train - INFO - current latency ratio:tensor(0.2038)
2024-04-07 16:55:45,581 - train - INFO - lasso_alpha:5.5599173134922395e-05
2024-04-07 16:55:46,203 - train - INFO - Test: [   0/78]  Time: 0.619 (0.619)  Loss:  0.9077 (0.9077)  Acc@1: 81.2500 (81.2500)  Acc@5: 94.5312 (94.5312)
2024-04-07 16:56:13,385 - train - INFO - Test: [  50/78]  Time: 0.480 (0.545)  Loss:  1.8643 (1.6483)  Acc@1: 57.8125 (61.7647)  Acc@5: 81.2500 (83.9920)
2024-04-07 16:56:28,034 - train - INFO - Test: [  78/78]  Time: 0.482 (0.537)  Loss:  1.7676 (1.6683)  Acc@1: 56.2500 (61.3300)  Acc@5: 87.5000 (83.5700)
2024-04-07 16:56:29,840 - train - INFO - Train: 93 [   0/781 (  0%)]  Loss:  4.212684 (4.2127)  Time: 1.729s,   74.03/s  (1.729s,   74.03/s)  LR: 1.648e-04  Data: 0.190 (0.190)
2024-04-07 16:57:43,013 - train - INFO - Train: 93 [  50/781 (  6%)]  Loss:  3.674054 (3.8405)  Time: 1.494s,   85.65/s  (1.469s,   87.16/s)  LR: 1.648e-04  Data: 0.008 (0.011)
2024-04-07 16:58:56,157 - train - INFO - Train: 93 [ 100/781 ( 13%)]  Loss:  3.432978 (3.8866)  Time: 1.610s,   79.51/s  (1.466s,   87.33/s)  LR: 1.648e-04  Data: 0.007 (0.009)
2024-04-07 17:00:07,798 - train - INFO - Train: 93 [ 150/781 ( 19%)]  Loss:  3.740615 (3.8525)  Time: 1.466s,   87.32/s  (1.455s,   87.98/s)  LR: 1.648e-04  Data: 0.008 (0.008)
2024-04-07 17:01:21,035 - train - INFO - Train: 93 [ 200/781 ( 26%)]  Loss:  3.162451 (3.8442)  Time: 1.370s,   93.44/s  (1.457s,   87.83/s)  LR: 1.648e-04  Data: 0.007 (0.008)
2024-04-07 17:02:32,252 - train - INFO - Train: 93 [ 250/781 ( 32%)]  Loss:  3.331755 (3.8108)  Time: 1.429s,   89.56/s  (1.451s,   88.23/s)  LR: 1.648e-04  Data: 0.007 (0.008)
2024-04-07 17:03:44,808 - train - INFO - Train: 93 [ 300/781 ( 38%)]  Loss:  4.402629 (3.8092)  Time: 1.692s,   75.66/s  (1.451s,   88.23/s)  LR: 1.648e-04  Data: 0.007 (0.008)
2024-04-07 17:04:54,891 - train - INFO - Train: 93 [ 350/781 ( 45%)]  Loss:  4.386216 (3.8097)  Time: 1.454s,   88.06/s  (1.444s,   88.66/s)  LR: 1.648e-04  Data: 0.006 (0.008)
2024-04-07 17:06:06,797 - train - INFO - Train: 93 [ 400/781 ( 51%)]  Loss:  4.339074 (3.8067)  Time: 1.424s,   89.90/s  (1.443s,   88.70/s)  LR: 1.648e-04  Data: 0.005 (0.008)
2024-04-07 17:07:19,087 - train - INFO - Train: 93 [ 450/781 ( 58%)]  Loss:  4.329111 (3.8137)  Time: 1.558s,   82.17/s  (1.443s,   88.68/s)  LR: 1.648e-04  Data: 0.007 (0.008)
2024-04-07 17:08:31,918 - train - INFO - Train: 93 [ 500/781 ( 64%)]  Loss:  3.933588 (3.8025)  Time: 1.448s,   88.38/s  (1.445s,   88.60/s)  LR: 1.648e-04  Data: 0.007 (0.008)
2024-04-07 17:09:42,393 - train - INFO - Train: 93 [ 550/781 ( 71%)]  Loss:  4.417296 (3.7990)  Time: 1.300s,   98.49/s  (1.441s,   88.80/s)  LR: 1.648e-04  Data: 0.006 (0.007)
2024-04-07 17:10:55,710 - train - INFO - Train: 93 [ 600/781 ( 77%)]  Loss:  4.333417 (3.8039)  Time: 1.361s,   94.04/s  (1.444s,   88.67/s)  LR: 1.648e-04  Data: 0.005 (0.007)
2024-04-07 17:12:07,426 - train - INFO - Train: 93 [ 650/781 ( 83%)]  Loss:  4.267653 (3.8158)  Time: 1.609s,   79.58/s  (1.443s,   88.71/s)  LR: 1.648e-04  Data: 0.006 (0.007)
2024-04-07 17:13:20,570 - train - INFO - Train: 93 [ 700/781 ( 90%)]  Loss:  3.727166 (3.8140)  Time: 1.377s,   92.98/s  (1.444s,   88.63/s)  LR: 1.648e-04  Data: 0.007 (0.007)
2024-04-07 17:14:31,760 - train - INFO - Train: 93 [ 750/781 ( 96%)]  Loss:  3.426421 (3.8090)  Time: 1.562s,   81.95/s  (1.443s,   88.71/s)  LR: 1.648e-04  Data: 0.007 (0.007)
2024-04-07 17:15:14,259 - train - INFO - Train: 93 [ 780/781 (100%)]  Loss:  4.153186 (3.8103)  Time: 1.376s,   93.00/s  (1.442s,   88.77/s)  LR: 1.648e-04  Data: 0.000 (0.007)
2024-04-07 17:15:14,260 - train - INFO - True
2024-04-07 17:15:14,266 - train - INFO - alphas:tensor([0.0018, 0.0030, 0.0305, 0.3661, 0.5986], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,286 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,286 - train - INFO - True
2024-04-07 17:15:14,288 - train - INFO - alphas:tensor([0.1186, 0.0157, 0.0338, 0.1237, 0.7082], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,305 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,305 - train - INFO - True
2024-04-07 17:15:14,319 - train - INFO - alphas:tensor([0.5289, 0.0745, 0.0501, 0.1305, 0.2160], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,361 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,361 - train - INFO - True
2024-04-07 17:15:14,373 - train - INFO - alphas:tensor([0.4458, 0.0129, 0.0234, 0.1128, 0.4052], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,397 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,397 - train - INFO - True
2024-04-07 17:15:14,410 - train - INFO - alphas:tensor([0.2695, 0.0092, 0.0391, 0.1266, 0.5556], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,421 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,421 - train - INFO - True
2024-04-07 17:15:14,435 - train - INFO - alphas:tensor([0.3841, 0.0049, 0.0178, 0.0822, 0.5110], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,445 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,445 - train - INFO - True
2024-04-07 17:15:14,457 - train - INFO - alphas:tensor([0.5351, 0.0222, 0.0124, 0.1015, 0.3289], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,477 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,477 - train - INFO - True
2024-04-07 17:15:14,490 - train - INFO - alphas:tensor([0.4185, 0.0094, 0.0041, 0.0834, 0.4845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,501 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,501 - train - INFO - True
2024-04-07 17:15:14,515 - train - INFO - alphas:tensor([0.3273, 0.0064, 0.0216, 0.0966, 0.5481], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,525 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,525 - train - INFO - True
2024-04-07 17:15:14,539 - train - INFO - alphas:tensor([0.4469, 0.0034, 0.0153, 0.0620, 0.4723], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,550 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,550 - train - INFO - True
2024-04-07 17:15:14,564 - train - INFO - alphas:tensor([0.4428, 0.0122, 0.0098, 0.0956, 0.4396], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,583 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,583 - train - INFO - True
2024-04-07 17:15:14,585 - train - INFO - alphas:tensor([0.3538, 0.0041, 0.0039, 0.1027, 0.5354], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,594 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,594 - train - INFO - True
2024-04-07 17:15:14,595 - train - INFO - alphas:tensor([0.3337, 0.0036, 0.0151, 0.0858, 0.5618], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,605 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,605 - train - INFO - True
2024-04-07 17:15:14,606 - train - INFO - alphas:tensor([0.4469, 0.0012, 0.0091, 0.0448, 0.4981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,615 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,615 - train - INFO - True
2024-04-07 17:15:14,620 - train - INFO - alphas:tensor([0.3668, 0.0155, 0.0077, 0.1046, 0.5054], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,629 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,629 - train - INFO - True
2024-04-07 17:15:14,634 - train - INFO - alphas:tensor([0.2718, 0.0027, 0.0017, 0.1222, 0.6015], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,645 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,645 - train - INFO - True
2024-04-07 17:15:14,649 - train - INFO - alphas:tensor([0.3219, 0.0039, 0.0103, 0.0770, 0.5869], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,660 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,660 - train - INFO - True
2024-04-07 17:15:14,665 - train - INFO - alphas:tensor([0.4419, 0.0010, 0.0076, 0.0411, 0.5084], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,675 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,675 - train - INFO - True
2024-04-07 17:15:14,680 - train - INFO - alphas:tensor([0.3840, 0.0035, 0.0030, 0.0890, 0.5205], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,689 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,689 - train - INFO - True
2024-04-07 17:15:14,693 - train - INFO - alphas:tensor([0.2816, 0.0015, 0.0011, 0.0974, 0.6184], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,702 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,702 - train - INFO - True
2024-04-07 17:15:14,704 - train - INFO - alphas:tensor([0.2805, 0.0021, 0.0096, 0.0743, 0.6335], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,713 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,713 - train - INFO - True
2024-04-07 17:15:14,718 - train - INFO - alphas:tensor([0.4203, 0.0007, 0.0065, 0.0341, 0.5384], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,726 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,726 - train - INFO - True
2024-04-07 17:15:14,731 - train - INFO - alphas:tensor([0.4294, 0.0051, 0.0025, 0.0617, 0.5012], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,739 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,739 - train - INFO - True
2024-04-07 17:15:14,744 - train - INFO - alphas:tensor([3.2311e-01, 1.0027e-03, 5.2299e-04, 6.0352e-02, 6.1502e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,753 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,753 - train - INFO - True
2024-04-07 17:15:14,758 - train - INFO - alphas:tensor([0.2711, 0.0016, 0.0080, 0.0651, 0.6541], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,767 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,767 - train - INFO - True
2024-04-07 17:15:14,769 - train - INFO - alphas:tensor([0.4087, 0.0007, 0.0059, 0.0267, 0.5580], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,778 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,778 - train - INFO - True
2024-04-07 17:15:14,782 - train - INFO - alphas:tensor([0.4617, 0.0012, 0.0016, 0.0519, 0.4836], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,793 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,793 - train - INFO - True
2024-04-07 17:15:14,802 - train - INFO - alphas:tensor([3.5377e-01, 1.0151e-03, 4.1106e-04, 4.4467e-02, 6.0033e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,813 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,813 - train - INFO - True
2024-04-07 17:15:14,814 - train - INFO - alphas:tensor([0.2516, 0.0014, 0.0075, 0.0664, 0.6732], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,824 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,824 - train - INFO - True
2024-04-07 17:15:14,832 - train - INFO - alphas:tensor([3.8416e-01, 3.3786e-04, 4.2663e-03, 3.1442e-02, 5.7979e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,841 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,841 - train - INFO - True
2024-04-07 17:15:14,854 - train - INFO - alphas:tensor([0.4890, 0.0011, 0.0013, 0.0429, 0.4656], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,871 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,871 - train - INFO - True
2024-04-07 17:15:14,880 - train - INFO - alphas:tensor([3.9300e-01, 4.2769e-04, 5.4118e-04, 4.7607e-02, 5.5842e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,888 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,888 - train - INFO - True
2024-04-07 17:15:14,902 - train - INFO - alphas:tensor([0.2285, 0.0011, 0.0068, 0.0547, 0.7089], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,911 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,911 - train - INFO - True
2024-04-07 17:15:14,920 - train - INFO - alphas:tensor([3.4303e-01, 1.8638e-04, 2.4316e-03, 2.0882e-02, 6.3347e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,929 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,929 - train - INFO - True
2024-04-07 17:15:14,942 - train - INFO - alphas:tensor([0.4623, 0.0020, 0.0017, 0.0496, 0.4843], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,953 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,953 - train - INFO - True
2024-04-07 17:15:14,962 - train - INFO - alphas:tensor([4.1199e-01, 3.7362e-04, 5.8041e-04, 4.4096e-02, 5.4296e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:14,972 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:14,973 - train - INFO - True
2024-04-07 17:15:14,985 - train - INFO - alphas:tensor([0.6322, 0.0224, 0.0939, 0.2514], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:15:15,003 - train - INFO - tau:0.40068465295154065
2024-04-07 17:15:15,003 - train - INFO - avg block size:13.567567567567568
2024-04-07 17:15:15,004 - train - INFO - current latency ratio:tensor(0.2288)
2024-04-07 17:15:15,701 - train - INFO - Test: [   0/78]  Time: 0.694 (0.694)  Loss:  0.9722 (0.9722)  Acc@1: 80.4688 (80.4688)  Acc@5: 93.7500 (93.7500)
2024-04-07 17:15:40,473 - train - INFO - Test: [  50/78]  Time: 0.576 (0.499)  Loss:  1.8330 (1.6311)  Acc@1: 58.5938 (61.7188)  Acc@5: 83.5938 (84.1452)
2024-04-07 17:15:54,499 - train - INFO - Test: [  78/78]  Time: 0.270 (0.500)  Loss:  1.6592 (1.6590)  Acc@1: 56.2500 (61.1100)  Acc@5: 93.7500 (83.7100)
2024-04-07 17:15:56,199 - train - INFO - Train: 94 [   0/781 (  0%)]  Loss:  3.988138 (3.9881)  Time: 1.630s,   78.53/s  (1.630s,   78.53/s)  LR: 1.601e-04  Data: 0.189 (0.189)
2024-04-07 17:17:08,751 - train - INFO - Train: 94 [  50/781 (  6%)]  Loss:  3.105610 (3.8209)  Time: 1.543s,   82.96/s  (1.455s,   88.00/s)  LR: 1.601e-04  Data: 0.006 (0.011)
2024-04-07 17:18:19,713 - train - INFO - Train: 94 [ 100/781 ( 13%)]  Loss:  3.367680 (3.8684)  Time: 1.314s,   97.40/s  (1.437s,   89.07/s)  LR: 1.601e-04  Data: 0.008 (0.009)
2024-04-07 17:19:31,949 - train - INFO - Train: 94 [ 150/781 ( 19%)]  Loss:  4.198669 (3.8673)  Time: 1.359s,   94.21/s  (1.440s,   88.92/s)  LR: 1.601e-04  Data: 0.007 (0.009)
2024-04-07 17:20:45,076 - train - INFO - Train: 94 [ 200/781 ( 26%)]  Loss:  3.466249 (3.8380)  Time: 1.476s,   86.75/s  (1.445s,   88.56/s)  LR: 1.601e-04  Data: 0.009 (0.008)
2024-04-07 17:21:58,870 - train - INFO - Train: 94 [ 250/781 ( 32%)]  Loss:  4.357299 (3.8188)  Time: 1.496s,   85.59/s  (1.451s,   88.19/s)  LR: 1.601e-04  Data: 0.007 (0.008)
2024-04-07 17:23:09,935 - train - INFO - Train: 94 [ 300/781 ( 38%)]  Loss:  4.106325 (3.8163)  Time: 1.253s,  102.19/s  (1.446s,   88.50/s)  LR: 1.601e-04  Data: 0.005 (0.008)
2024-04-07 17:24:22,521 - train - INFO - Train: 94 [ 350/781 ( 45%)]  Loss:  4.175991 (3.8280)  Time: 1.383s,   92.54/s  (1.447s,   88.45/s)  LR: 1.601e-04  Data: 0.008 (0.008)
2024-04-07 17:25:35,413 - train - INFO - Train: 94 [ 400/781 ( 51%)]  Loss:  3.847171 (3.8316)  Time: 1.475s,   86.75/s  (1.448s,   88.37/s)  LR: 1.601e-04  Data: 0.008 (0.008)
2024-04-07 17:26:47,989 - train - INFO - Train: 94 [ 450/781 ( 58%)]  Loss:  4.209469 (3.8363)  Time: 1.317s,   97.16/s  (1.449s,   88.35/s)  LR: 1.601e-04  Data: 0.007 (0.008)
2024-04-07 17:27:58,721 - train - INFO - Train: 94 [ 500/781 ( 64%)]  Loss:  4.095824 (3.8296)  Time: 1.617s,   79.14/s  (1.445s,   88.56/s)  LR: 1.601e-04  Data: 0.018 (0.008)
2024-04-07 17:29:11,167 - train - INFO - Train: 94 [ 550/781 ( 71%)]  Loss:  3.448735 (3.8311)  Time: 1.672s,   76.56/s  (1.446s,   88.54/s)  LR: 1.601e-04  Data: 0.007 (0.008)
2024-04-07 17:30:24,797 - train - INFO - Train: 94 [ 600/781 ( 77%)]  Loss:  3.934726 (3.8220)  Time: 1.402s,   91.27/s  (1.448s,   88.40/s)  LR: 1.601e-04  Data: 0.007 (0.008)
2024-04-07 17:31:37,751 - train - INFO - Train: 94 [ 650/781 ( 83%)]  Loss:  4.366868 (3.8262)  Time: 1.377s,   92.94/s  (1.449s,   88.35/s)  LR: 1.601e-04  Data: 0.007 (0.008)
2024-04-07 17:32:47,865 - train - INFO - Train: 94 [ 700/781 ( 90%)]  Loss:  3.585174 (3.8296)  Time: 1.454s,   88.00/s  (1.445s,   88.55/s)  LR: 1.601e-04  Data: 0.007 (0.008)
2024-04-07 17:34:00,363 - train - INFO - Train: 94 [ 750/781 ( 96%)]  Loss:  3.530300 (3.8321)  Time: 1.356s,   94.41/s  (1.446s,   88.53/s)  LR: 1.601e-04  Data: 0.006 (0.008)
2024-04-07 17:34:43,530 - train - INFO - Train: 94 [ 780/781 (100%)]  Loss:  3.488852 (3.8347)  Time: 1.629s,   78.55/s  (1.445s,   88.55/s)  LR: 1.601e-04  Data: 0.000 (0.008)
2024-04-07 17:34:43,531 - train - INFO - True
2024-04-07 17:34:43,544 - train - INFO - alphas:tensor([0.0017, 0.0028, 0.0300, 0.3674, 0.5981], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,559 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,559 - train - INFO - True
2024-04-07 17:34:43,572 - train - INFO - alphas:tensor([0.1196, 0.0155, 0.0335, 0.1234, 0.7080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,586 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,586 - train - INFO - True
2024-04-07 17:34:43,587 - train - INFO - alphas:tensor([0.5326, 0.0734, 0.0490, 0.1295, 0.2156], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,612 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,612 - train - INFO - True
2024-04-07 17:34:43,613 - train - INFO - alphas:tensor([0.4485, 0.0125, 0.0226, 0.1112, 0.4053], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,635 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,636 - train - INFO - True
2024-04-07 17:34:43,641 - train - INFO - alphas:tensor([0.2709, 0.0090, 0.0384, 0.1253, 0.5564], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,652 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,652 - train - INFO - True
2024-04-07 17:34:43,658 - train - INFO - alphas:tensor([0.3879, 0.0047, 0.0174, 0.0807, 0.5093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,668 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,668 - train - INFO - True
2024-04-07 17:34:43,675 - train - INFO - alphas:tensor([0.5386, 0.0216, 0.0119, 0.1001, 0.3278], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,693 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,694 - train - INFO - True
2024-04-07 17:34:43,696 - train - INFO - alphas:tensor([0.4193, 0.0091, 0.0039, 0.0822, 0.4854], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,705 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,705 - train - INFO - True
2024-04-07 17:34:43,707 - train - INFO - alphas:tensor([0.3282, 0.0062, 0.0212, 0.0950, 0.5494], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,718 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,718 - train - INFO - True
2024-04-07 17:34:43,722 - train - INFO - alphas:tensor([0.4500, 0.0032, 0.0148, 0.0607, 0.4713], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,733 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,733 - train - INFO - True
2024-04-07 17:34:43,735 - train - INFO - alphas:tensor([0.4447, 0.0119, 0.0094, 0.0945, 0.4395], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,756 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,757 - train - INFO - True
2024-04-07 17:34:43,761 - train - INFO - alphas:tensor([0.3532, 0.0040, 0.0037, 0.1016, 0.5375], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,772 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,772 - train - INFO - True
2024-04-07 17:34:43,776 - train - INFO - alphas:tensor([0.3353, 0.0035, 0.0146, 0.0843, 0.5623], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,787 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,787 - train - INFO - True
2024-04-07 17:34:43,791 - train - INFO - alphas:tensor([0.4485, 0.0011, 0.0087, 0.0438, 0.4979], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,802 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,802 - train - INFO - True
2024-04-07 17:34:43,805 - train - INFO - alphas:tensor([0.3670, 0.0150, 0.0074, 0.1037, 0.5069], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,816 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,816 - train - INFO - True
2024-04-07 17:34:43,825 - train - INFO - alphas:tensor([0.2736, 0.0026, 0.0016, 0.1199, 0.6023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,835 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,836 - train - INFO - True
2024-04-07 17:34:43,849 - train - INFO - alphas:tensor([0.3226, 0.0037, 0.0100, 0.0758, 0.5878], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,859 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,859 - train - INFO - True
2024-04-07 17:34:43,872 - train - INFO - alphas:tensor([0.4436, 0.0009, 0.0073, 0.0402, 0.5080], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,881 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,881 - train - INFO - True
2024-04-07 17:34:43,894 - train - INFO - alphas:tensor([0.3874, 0.0034, 0.0028, 0.0875, 0.5190], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,905 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,905 - train - INFO - True
2024-04-07 17:34:43,919 - train - INFO - alphas:tensor([0.2845, 0.0014, 0.0010, 0.0955, 0.6175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,930 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,930 - train - INFO - True
2024-04-07 17:34:43,943 - train - INFO - alphas:tensor([0.2814, 0.0020, 0.0093, 0.0732, 0.6342], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,954 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,954 - train - INFO - True
2024-04-07 17:34:43,968 - train - INFO - alphas:tensor([0.4222, 0.0007, 0.0062, 0.0333, 0.5376], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:43,978 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:43,979 - train - INFO - True
2024-04-07 17:34:43,992 - train - INFO - alphas:tensor([0.4327, 0.0049, 0.0023, 0.0603, 0.4998], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,003 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,003 - train - INFO - True
2024-04-07 17:34:44,012 - train - INFO - alphas:tensor([3.2472e-01, 9.3969e-04, 4.8361e-04, 5.9013e-02, 6.1485e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,023 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,023 - train - INFO - True
2024-04-07 17:34:44,037 - train - INFO - alphas:tensor([0.2726, 0.0015, 0.0077, 0.0641, 0.6540], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,047 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,047 - train - INFO - True
2024-04-07 17:34:44,061 - train - INFO - alphas:tensor([0.4095, 0.0007, 0.0057, 0.0260, 0.5582], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,072 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,072 - train - INFO - True
2024-04-07 17:34:44,086 - train - INFO - alphas:tensor([0.4626, 0.0011, 0.0015, 0.0509, 0.4839], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,096 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,096 - train - INFO - True
2024-04-07 17:34:44,103 - train - INFO - alphas:tensor([3.5356e-01, 9.4740e-04, 3.7474e-04, 4.3267e-02, 6.0185e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,113 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,113 - train - INFO - True
2024-04-07 17:34:44,114 - train - INFO - alphas:tensor([0.2525, 0.0013, 0.0073, 0.0652, 0.6737], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,123 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,123 - train - INFO - True
2024-04-07 17:34:44,124 - train - INFO - alphas:tensor([3.8385e-01, 3.1002e-04, 4.0887e-03, 3.0565e-02, 5.8118e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,133 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,133 - train - INFO - True
2024-04-07 17:34:44,135 - train - INFO - alphas:tensor([0.4916, 0.0010, 0.0013, 0.0418, 0.4643], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,151 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,151 - train - INFO - True
2024-04-07 17:34:44,153 - train - INFO - alphas:tensor([3.9457e-01, 3.9754e-04, 5.0186e-04, 4.6686e-02, 5.5784e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,161 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,161 - train - INFO - True
2024-04-07 17:34:44,163 - train - INFO - alphas:tensor([0.2298, 0.0011, 0.0066, 0.0534, 0.7091], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,172 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,172 - train - INFO - True
2024-04-07 17:34:44,173 - train - INFO - alphas:tensor([3.4783e-01, 1.7264e-04, 2.2935e-03, 2.0322e-02, 6.2938e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,184 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,184 - train - INFO - True
2024-04-07 17:34:44,189 - train - INFO - alphas:tensor([0.4628, 0.0019, 0.0016, 0.0487, 0.4849], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,198 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,198 - train - INFO - True
2024-04-07 17:34:44,204 - train - INFO - alphas:tensor([4.1429e-01, 3.4308e-04, 5.3559e-04, 4.3044e-02, 5.4179e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,212 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,212 - train - INFO - True
2024-04-07 17:34:44,218 - train - INFO - alphas:tensor([0.6334, 0.0220, 0.0932, 0.2515], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:34:44,235 - train - INFO - tau:0.39667780642202527
2024-04-07 17:34:44,235 - train - INFO - avg block size:13.567567567567568
2024-04-07 17:34:44,235 - train - INFO - current latency ratio:tensor(0.2288)
2024-04-07 17:34:44,235 - train - INFO - lasso_alpha:5.0544702849929444e-05
2024-04-07 17:34:44,888 - train - INFO - Test: [   0/78]  Time: 0.649 (0.649)  Loss:  0.8862 (0.8862)  Acc@1: 83.5938 (83.5938)  Acc@5: 92.9688 (92.9688)
2024-04-07 17:35:10,896 - train - INFO - Test: [  50/78]  Time: 0.554 (0.523)  Loss:  1.7705 (1.6263)  Acc@1: 58.5938 (61.6422)  Acc@5: 83.5938 (84.3903)
2024-04-07 17:35:24,460 - train - INFO - Test: [  78/78]  Time: 0.231 (0.509)  Loss:  1.6416 (1.6593)  Acc@1: 56.2500 (61.0800)  Acc@5: 93.7500 (83.8000)
2024-04-07 17:35:26,298 - train - INFO - Train: 95 [   0/781 (  0%)]  Loss:  3.553405 (3.5534)  Time: 1.675s,   76.41/s  (1.675s,   76.41/s)  LR: 1.553e-04  Data: 0.193 (0.193)
2024-04-07 17:36:38,848 - train - INFO - Train: 95 [  50/781 (  6%)]  Loss:  4.282212 (3.8150)  Time: 1.388s,   92.22/s  (1.455s,   87.95/s)  LR: 1.553e-04  Data: 0.010 (0.011)
2024-04-07 17:37:49,691 - train - INFO - Train: 95 [ 100/781 ( 13%)]  Loss:  3.700223 (3.8304)  Time: 1.462s,   87.55/s  (1.436s,   89.12/s)  LR: 1.553e-04  Data: 0.008 (0.009)
2024-04-07 17:39:02,090 - train - INFO - Train: 95 [ 150/781 ( 19%)]  Loss:  3.738019 (3.8221)  Time: 1.375s,   93.12/s  (1.440s,   88.88/s)  LR: 1.553e-04  Data: 0.005 (0.008)
2024-04-07 17:40:15,426 - train - INFO - Train: 95 [ 200/781 ( 26%)]  Loss:  3.267194 (3.8214)  Time: 1.430s,   89.54/s  (1.447s,   88.47/s)  LR: 1.553e-04  Data: 0.007 (0.008)
2024-04-07 17:41:29,417 - train - INFO - Train: 95 [ 250/781 ( 32%)]  Loss:  4.458667 (3.8203)  Time: 1.650s,   77.60/s  (1.453s,   88.07/s)  LR: 1.553e-04  Data: 0.007 (0.008)
2024-04-07 17:42:40,606 - train - INFO - Train: 95 [ 300/781 ( 38%)]  Loss:  3.229084 (3.8129)  Time: 1.412s,   90.66/s  (1.448s,   88.37/s)  LR: 1.553e-04  Data: 0.010 (0.008)
2024-04-07 17:43:54,556 - train - INFO - Train: 95 [ 350/781 ( 45%)]  Loss:  3.780511 (3.8228)  Time: 1.678s,   76.30/s  (1.453s,   88.11/s)  LR: 1.553e-04  Data: 0.007 (0.008)
2024-04-07 17:45:07,368 - train - INFO - Train: 95 [ 400/781 ( 51%)]  Loss:  3.355885 (3.8230)  Time: 1.533s,   83.48/s  (1.453s,   88.08/s)  LR: 1.553e-04  Data: 0.008 (0.008)
2024-04-07 17:46:19,057 - train - INFO - Train: 95 [ 450/781 ( 58%)]  Loss:  3.290900 (3.8235)  Time: 1.423s,   89.92/s  (1.451s,   88.21/s)  LR: 1.553e-04  Data: 0.007 (0.008)
2024-04-07 17:47:31,051 - train - INFO - Train: 95 [ 500/781 ( 64%)]  Loss:  3.245568 (3.8260)  Time: 1.576s,   81.20/s  (1.450s,   88.28/s)  LR: 1.553e-04  Data: 0.007 (0.008)
2024-04-07 17:48:43,725 - train - INFO - Train: 95 [ 550/781 ( 71%)]  Loss:  4.038409 (3.8255)  Time: 1.402s,   91.28/s  (1.450s,   88.26/s)  LR: 1.553e-04  Data: 0.004 (0.008)
2024-04-07 17:49:57,397 - train - INFO - Train: 95 [ 600/781 ( 77%)]  Loss:  3.704089 (3.8245)  Time: 1.501s,   85.30/s  (1.452s,   88.14/s)  LR: 1.553e-04  Data: 0.007 (0.008)
2024-04-07 17:51:09,649 - train - INFO - Train: 95 [ 650/781 ( 83%)]  Loss:  3.759401 (3.8296)  Time: 1.402s,   91.31/s  (1.452s,   88.18/s)  LR: 1.553e-04  Data: 0.013 (0.008)
2024-04-07 17:52:21,760 - train - INFO - Train: 95 [ 700/781 ( 90%)]  Loss:  3.430294 (3.8335)  Time: 1.389s,   92.18/s  (1.451s,   88.22/s)  LR: 1.553e-04  Data: 0.005 (0.008)
2024-04-07 17:53:33,050 - train - INFO - Train: 95 [ 750/781 ( 96%)]  Loss:  3.263772 (3.8302)  Time: 1.492s,   85.81/s  (1.449s,   88.32/s)  LR: 1.553e-04  Data: 0.007 (0.008)
2024-04-07 17:54:16,184 - train - INFO - Train: 95 [ 780/781 (100%)]  Loss:  4.269611 (3.8249)  Time: 1.368s,   93.58/s  (1.449s,   88.35/s)  LR: 1.553e-04  Data: 0.000 (0.008)
2024-04-07 17:54:16,185 - train - INFO - True
2024-04-07 17:54:16,191 - train - INFO - alphas:tensor([0.0016, 0.0027, 0.0296, 0.3697, 0.5964], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,212 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,212 - train - INFO - True
2024-04-07 17:54:16,217 - train - INFO - alphas:tensor([0.1209, 0.0153, 0.0332, 0.1232, 0.7075], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,236 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,236 - train - INFO - True
2024-04-07 17:54:16,241 - train - INFO - alphas:tensor([0.5345, 0.0729, 0.0483, 0.1286, 0.2158], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,272 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,272 - train - INFO - True
2024-04-07 17:54:16,284 - train - INFO - alphas:tensor([0.4496, 0.0121, 0.0221, 0.1101, 0.4061], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,312 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,312 - train - INFO - True
2024-04-07 17:54:16,326 - train - INFO - alphas:tensor([0.2726, 0.0088, 0.0377, 0.1239, 0.5570], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,340 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,340 - train - INFO - True
2024-04-07 17:54:16,352 - train - INFO - alphas:tensor([0.3879, 0.0045, 0.0169, 0.0796, 0.5112], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,366 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,367 - train - INFO - True
2024-04-07 17:54:16,379 - train - INFO - alphas:tensor([0.5414, 0.0210, 0.0115, 0.0990, 0.3271], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,407 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,407 - train - INFO - True
2024-04-07 17:54:16,420 - train - INFO - alphas:tensor([0.4223, 0.0088, 0.0037, 0.0809, 0.4844], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,434 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,435 - train - INFO - True
2024-04-07 17:54:16,447 - train - INFO - alphas:tensor([0.3296, 0.0060, 0.0206, 0.0935, 0.5502], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,461 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,461 - train - INFO - True
2024-04-07 17:54:16,473 - train - INFO - alphas:tensor([0.4516, 0.0030, 0.0143, 0.0596, 0.4715], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,488 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,488 - train - INFO - True
2024-04-07 17:54:16,500 - train - INFO - alphas:tensor([0.4507, 0.0115, 0.0090, 0.0926, 0.4361], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,528 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,528 - train - INFO - True
2024-04-07 17:54:16,541 - train - INFO - alphas:tensor([0.3574, 0.0038, 0.0035, 0.0999, 0.5354], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,556 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,556 - train - INFO - True
2024-04-07 17:54:16,564 - train - INFO - alphas:tensor([0.3384, 0.0033, 0.0143, 0.0829, 0.5610], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,579 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,579 - train - INFO - True
2024-04-07 17:54:16,580 - train - INFO - alphas:tensor([0.4516, 0.0010, 0.0084, 0.0426, 0.4963], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,595 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,595 - train - INFO - True
2024-04-07 17:54:16,598 - train - INFO - alphas:tensor([0.3715, 0.0147, 0.0071, 0.1022, 0.5045], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,612 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,612 - train - INFO - True
2024-04-07 17:54:16,620 - train - INFO - alphas:tensor([0.2772, 0.0025, 0.0015, 0.1183, 0.6005], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,634 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,634 - train - INFO - True
2024-04-07 17:54:16,643 - train - INFO - alphas:tensor([0.3246, 0.0036, 0.0096, 0.0745, 0.5877], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,658 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,658 - train - INFO - True
2024-04-07 17:54:16,664 - train - INFO - alphas:tensor([0.4458, 0.0008, 0.0069, 0.0393, 0.5071], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,678 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,678 - train - INFO - True
2024-04-07 17:54:16,684 - train - INFO - alphas:tensor([0.3904, 0.0032, 0.0026, 0.0863, 0.5175], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,698 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,699 - train - INFO - True
2024-04-07 17:54:16,704 - train - INFO - alphas:tensor([0.2902, 0.0014, 0.0009, 0.0933, 0.6142], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,719 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,719 - train - INFO - True
2024-04-07 17:54:16,725 - train - INFO - alphas:tensor([0.2840, 0.0019, 0.0088, 0.0715, 0.6337], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,739 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,739 - train - INFO - True
2024-04-07 17:54:16,744 - train - INFO - alphas:tensor([0.4267, 0.0006, 0.0060, 0.0324, 0.5343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,759 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,759 - train - INFO - True
2024-04-07 17:54:16,762 - train - INFO - alphas:tensor([0.4388, 0.0047, 0.0022, 0.0588, 0.4955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,776 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,777 - train - INFO - True
2024-04-07 17:54:16,785 - train - INFO - alphas:tensor([3.3005e-01, 8.8912e-04, 4.5081e-04, 5.8186e-02, 6.1043e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,799 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,799 - train - INFO - True
2024-04-07 17:54:16,813 - train - INFO - alphas:tensor([0.2745, 0.0015, 0.0075, 0.0627, 0.6539], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,827 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,827 - train - INFO - True
2024-04-07 17:54:16,840 - train - INFO - alphas:tensor([0.4144, 0.0006, 0.0054, 0.0251, 0.5544], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,854 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,854 - train - INFO - True
2024-04-07 17:54:16,866 - train - INFO - alphas:tensor([0.4696, 0.0011, 0.0014, 0.0494, 0.4785], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,880 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,880 - train - INFO - True
2024-04-07 17:54:16,888 - train - INFO - alphas:tensor([3.6095e-01, 8.9543e-04, 3.4375e-04, 4.2336e-02, 5.9547e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,901 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,902 - train - INFO - True
2024-04-07 17:54:16,915 - train - INFO - alphas:tensor([0.2534, 0.0012, 0.0071, 0.0635, 0.6748], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,927 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,927 - train - INFO - True
2024-04-07 17:54:16,935 - train - INFO - alphas:tensor([3.8718e-01, 2.8557e-04, 3.8861e-03, 2.9487e-02, 5.7916e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,946 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,946 - train - INFO - True
2024-04-07 17:54:16,959 - train - INFO - alphas:tensor([0.4964, 0.0010, 0.0012, 0.0405, 0.4609], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:16,980 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:16,980 - train - INFO - True
2024-04-07 17:54:16,990 - train - INFO - alphas:tensor([3.9803e-01, 3.6606e-04, 4.6500e-04, 4.5534e-02, 5.5560e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:17,000 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:17,000 - train - INFO - True
2024-04-07 17:54:17,014 - train - INFO - alphas:tensor([0.2305, 0.0010, 0.0063, 0.0524, 0.7099], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:17,024 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:17,024 - train - INFO - True
2024-04-07 17:54:17,032 - train - INFO - alphas:tensor([3.5105e-01, 1.5625e-04, 2.1731e-03, 1.9402e-02, 6.2722e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:17,042 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:17,042 - train - INFO - True
2024-04-07 17:54:17,054 - train - INFO - alphas:tensor([0.4637, 0.0018, 0.0015, 0.0477, 0.4853], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:17,063 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:17,063 - train - INFO - True
2024-04-07 17:54:17,066 - train - INFO - alphas:tensor([4.1721e-01, 3.2121e-04, 4.9077e-04, 4.1797e-02, 5.4018e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:17,075 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:17,075 - train - INFO - True
2024-04-07 17:54:17,076 - train - INFO - alphas:tensor([0.6354, 0.0213, 0.0920, 0.2513], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 17:54:17,093 - train - INFO - tau:0.392711028357805
2024-04-07 17:54:17,093 - train - INFO - avg block size:13.567567567567568
2024-04-07 17:54:17,093 - train - INFO - current latency ratio:tensor(0.2288)
2024-04-07 17:54:17,766 - train - INFO - Test: [   0/78]  Time: 0.670 (0.670)  Loss:  0.8613 (0.8613)  Acc@1: 84.3750 (84.3750)  Acc@5: 96.0938 (96.0938)
2024-04-07 17:54:43,434 - train - INFO - Test: [  50/78]  Time: 0.518 (0.516)  Loss:  1.8447 (1.6266)  Acc@1: 56.2500 (61.6115)  Acc@5: 81.2500 (84.1759)
2024-04-07 17:54:57,503 - train - INFO - Test: [  78/78]  Time: 0.373 (0.511)  Loss:  1.7471 (1.6601)  Acc@1: 56.2500 (61.0900)  Acc@5: 100.0000 (83.6200)
2024-04-07 17:54:59,536 - train - INFO - Train: 96 [   0/781 (  0%)]  Loss:  4.055726 (4.0557)  Time: 1.961s,   65.26/s  (1.961s,   65.26/s)  LR: 1.507e-04  Data: 0.171 (0.171)
2024-04-07 17:56:10,523 - train - INFO - Train: 96 [  50/781 (  6%)]  Loss:  3.491586 (3.7732)  Time: 1.592s,   80.39/s  (1.430s,   89.49/s)  LR: 1.507e-04  Data: 0.007 (0.010)
2024-04-07 17:57:23,836 - train - INFO - Train: 96 [ 100/781 ( 13%)]  Loss:  4.303729 (3.8193)  Time: 1.561s,   82.01/s  (1.448s,   88.39/s)  LR: 1.507e-04  Data: 0.007 (0.009)
2024-04-07 17:58:36,393 - train - INFO - Train: 96 [ 150/781 ( 19%)]  Loss:  4.082464 (3.8168)  Time: 1.473s,   86.91/s  (1.449s,   88.33/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-07 17:59:49,764 - train - INFO - Train: 96 [ 200/781 ( 26%)]  Loss:  4.056097 (3.8432)  Time: 1.450s,   88.29/s  (1.454s,   88.05/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-07 18:01:00,262 - train - INFO - Train: 96 [ 250/781 ( 32%)]  Loss:  3.182326 (3.8215)  Time: 1.317s,   97.22/s  (1.445s,   88.59/s)  LR: 1.507e-04  Data: 0.005 (0.008)
2024-04-07 18:02:12,301 - train - INFO - Train: 96 [ 300/781 ( 38%)]  Loss:  3.295111 (3.8164)  Time: 1.475s,   86.79/s  (1.444s,   88.63/s)  LR: 1.507e-04  Data: 0.006 (0.008)
2024-04-07 18:03:24,403 - train - INFO - Train: 96 [ 350/781 ( 45%)]  Loss:  4.322257 (3.8251)  Time: 1.490s,   85.88/s  (1.444s,   88.65/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-07 18:04:36,451 - train - INFO - Train: 96 [ 400/781 ( 51%)]  Loss:  4.447736 (3.8259)  Time: 1.441s,   88.82/s  (1.444s,   88.67/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-07 18:05:46,686 - train - INFO - Train: 96 [ 450/781 ( 58%)]  Loss:  3.235293 (3.8331)  Time: 1.400s,   91.44/s  (1.439s,   88.94/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-07 18:06:59,234 - train - INFO - Train: 96 [ 500/781 ( 64%)]  Loss:  3.353570 (3.8277)  Time: 1.469s,   87.12/s  (1.440s,   88.86/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-07 18:08:12,297 - train - INFO - Train: 96 [ 550/781 ( 71%)]  Loss:  3.383607 (3.8328)  Time: 1.525s,   83.96/s  (1.442s,   88.75/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-07 18:09:23,877 - train - INFO - Train: 96 [ 600/781 ( 77%)]  Loss:  4.110790 (3.8308)  Time: 1.270s,  100.77/s  (1.441s,   88.80/s)  LR: 1.507e-04  Data: 0.006 (0.008)
2024-04-07 18:10:33,686 - train - INFO - Train: 96 [ 650/781 ( 83%)]  Loss:  4.233039 (3.8268)  Time: 1.379s,   92.80/s  (1.438s,   89.02/s)  LR: 1.507e-04  Data: 0.008 (0.008)
2024-04-07 18:11:44,742 - train - INFO - Train: 96 [ 700/781 ( 90%)]  Loss:  3.724518 (3.8280)  Time: 1.598s,   80.08/s  (1.437s,   89.09/s)  LR: 1.507e-04  Data: 0.009 (0.007)
2024-04-07 18:12:57,711 - train - INFO - Train: 96 [ 750/781 ( 96%)]  Loss:  4.336030 (3.8191)  Time: 1.769s,   72.37/s  (1.438s,   89.00/s)  LR: 1.507e-04  Data: 0.010 (0.007)
2024-04-07 18:13:40,977 - train - INFO - Train: 96 [ 780/781 (100%)]  Loss:  3.132087 (3.8171)  Time: 1.505s,   85.07/s  (1.438s,   88.99/s)  LR: 1.507e-04  Data: 0.000 (0.008)
2024-04-07 18:13:40,978 - train - INFO - True
2024-04-07 18:13:40,991 - train - INFO - alphas:tensor([0.0015, 0.0025, 0.0290, 0.3719, 0.5950], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,010 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,010 - train - INFO - True
2024-04-07 18:13:41,024 - train - INFO - alphas:tensor([0.1211, 0.0150, 0.0328, 0.1229, 0.7082], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,040 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,040 - train - INFO - True
2024-04-07 18:13:41,042 - train - INFO - alphas:tensor([0.5398, 0.0716, 0.0471, 0.1272, 0.2143], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,071 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,071 - train - INFO - True
2024-04-07 18:13:41,072 - train - INFO - alphas:tensor([0.4534, 0.0118, 0.0214, 0.1084, 0.4050], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,100 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,100 - train - INFO - True
2024-04-07 18:13:41,105 - train - INFO - alphas:tensor([0.2726, 0.0085, 0.0374, 0.1230, 0.5585], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,119 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,119 - train - INFO - True
2024-04-07 18:13:41,127 - train - INFO - alphas:tensor([0.3906, 0.0043, 0.0164, 0.0783, 0.5105], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,142 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,142 - train - INFO - True
2024-04-07 18:13:41,148 - train - INFO - alphas:tensor([0.5437, 0.0206, 0.0111, 0.0979, 0.3268], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,177 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,177 - train - INFO - True
2024-04-07 18:13:41,182 - train - INFO - alphas:tensor([0.4245, 0.0085, 0.0035, 0.0795, 0.4840], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,196 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,197 - train - INFO - True
2024-04-07 18:13:41,202 - train - INFO - alphas:tensor([0.3307, 0.0058, 0.0201, 0.0922, 0.5512], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,216 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,216 - train - INFO - True
2024-04-07 18:13:41,222 - train - INFO - alphas:tensor([0.4530, 0.0028, 0.0138, 0.0583, 0.4720], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,236 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,236 - train - INFO - True
2024-04-07 18:13:41,238 - train - INFO - alphas:tensor([0.4521, 0.0112, 0.0087, 0.0915, 0.4365], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,266 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,266 - train - INFO - True
2024-04-07 18:13:41,279 - train - INFO - alphas:tensor([0.3602, 0.0037, 0.0034, 0.0992, 0.5335], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,294 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,294 - train - INFO - True
2024-04-07 18:13:41,307 - train - INFO - alphas:tensor([0.3377, 0.0032, 0.0138, 0.0815, 0.5638], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,321 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,321 - train - INFO - True
2024-04-07 18:13:41,333 - train - INFO - alphas:tensor([0.4533, 0.0010, 0.0081, 0.0415, 0.4961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,348 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,348 - train - INFO - True
2024-04-07 18:13:41,360 - train - INFO - alphas:tensor([0.3756, 0.0145, 0.0069, 0.1008, 0.5023], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,374 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,374 - train - INFO - True
2024-04-07 18:13:41,387 - train - INFO - alphas:tensor([0.2833, 0.0024, 0.0014, 0.1159, 0.5970], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,401 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,401 - train - INFO - True
2024-04-07 18:13:41,413 - train - INFO - alphas:tensor([0.3257, 0.0034, 0.0094, 0.0730, 0.5885], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,427 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,428 - train - INFO - True
2024-04-07 18:13:41,440 - train - INFO - alphas:tensor([0.4465, 0.0008, 0.0066, 0.0384, 0.5077], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,454 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,454 - train - INFO - True
2024-04-07 18:13:41,466 - train - INFO - alphas:tensor([0.3931, 0.0030, 0.0025, 0.0848, 0.5166], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,481 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,481 - train - INFO - True
2024-04-07 18:13:41,493 - train - INFO - alphas:tensor([0.2904, 0.0013, 0.0009, 0.0921, 0.6152], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,507 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,507 - train - INFO - True
2024-04-07 18:13:41,520 - train - INFO - alphas:tensor([0.2848, 0.0018, 0.0086, 0.0707, 0.6341], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,534 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,534 - train - INFO - True
2024-04-07 18:13:41,546 - train - INFO - alphas:tensor([0.4277, 0.0006, 0.0057, 0.0316, 0.5343], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,561 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,561 - train - INFO - True
2024-04-07 18:13:41,562 - train - INFO - alphas:tensor([0.4411, 0.0045, 0.0020, 0.0575, 0.4948], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,577 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,577 - train - INFO - True
2024-04-07 18:13:41,578 - train - INFO - alphas:tensor([3.3218e-01, 8.3888e-04, 4.1716e-04, 5.6823e-02, 6.0974e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,592 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,592 - train - INFO - True
2024-04-07 18:13:41,594 - train - INFO - alphas:tensor([0.2757, 0.0014, 0.0072, 0.0614, 0.6544], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,608 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,608 - train - INFO - True
2024-04-07 18:13:41,614 - train - INFO - alphas:tensor([0.4151, 0.0006, 0.0052, 0.0246, 0.5545], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,628 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,628 - train - INFO - True
2024-04-07 18:13:41,633 - train - INFO - alphas:tensor([0.4718, 0.0010, 0.0013, 0.0483, 0.4776], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,648 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,648 - train - INFO - True
2024-04-07 18:13:41,654 - train - INFO - alphas:tensor([3.6258e-01, 8.3775e-04, 3.1428e-04, 4.1438e-02, 5.9483e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,668 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,668 - train - INFO - True
2024-04-07 18:13:41,675 - train - INFO - alphas:tensor([0.2540, 0.0012, 0.0069, 0.0627, 0.6752], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,689 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,689 - train - INFO - True
2024-04-07 18:13:41,693 - train - INFO - alphas:tensor([3.8816e-01, 2.6595e-04, 3.6784e-03, 2.9080e-02, 5.7882e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,706 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,706 - train - INFO - True
2024-04-07 18:13:41,709 - train - INFO - alphas:tensor([0.4982, 0.0009, 0.0011, 0.0394, 0.4604], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,733 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,733 - train - INFO - True
2024-04-07 18:13:41,737 - train - INFO - alphas:tensor([4.0101e-01, 3.4071e-04, 4.2419e-04, 4.4519e-02, 5.5370e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,748 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,748 - train - INFO - True
2024-04-07 18:13:41,753 - train - INFO - alphas:tensor([0.2322, 0.0010, 0.0060, 0.0511, 0.7097], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,764 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,764 - train - INFO - True
2024-04-07 18:13:41,766 - train - INFO - alphas:tensor([3.5493e-01, 1.4257e-04, 2.0559e-03, 1.8597e-02, 6.2427e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,776 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,777 - train - INFO - True
2024-04-07 18:13:41,780 - train - INFO - alphas:tensor([0.4652, 0.0017, 0.0014, 0.0467, 0.4850], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,790 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,790 - train - INFO - True
2024-04-07 18:13:41,799 - train - INFO - alphas:tensor([4.2125e-01, 2.9551e-04, 4.5403e-04, 4.0568e-02, 5.3743e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,808 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,808 - train - INFO - True
2024-04-07 18:13:41,809 - train - INFO - alphas:tensor([0.6372, 0.0209, 0.0910, 0.2509], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:13:41,827 - train - INFO - tau:0.38878391807422696
2024-04-07 18:13:41,827 - train - INFO - avg block size:13.567567567567568
2024-04-07 18:13:41,827 - train - INFO - current latency ratio:tensor(0.2288)
2024-04-07 18:13:41,827 - train - INFO - lasso_alpha:4.594972986357222e-05
2024-04-07 18:13:42,385 - train - INFO - Test: [   0/78]  Time: 0.555 (0.555)  Loss:  0.9048 (0.9048)  Acc@1: 80.4688 (80.4688)  Acc@5: 92.1875 (92.1875)
2024-04-07 18:14:08,784 - train - INFO - Test: [  50/78]  Time: 0.583 (0.529)  Loss:  1.7998 (1.6176)  Acc@1: 59.3750 (62.0404)  Acc@5: 85.1562 (84.3903)
2024-04-07 18:14:22,692 - train - INFO - Test: [  78/78]  Time: 0.441 (0.517)  Loss:  1.6895 (1.6518)  Acc@1: 50.0000 (61.4800)  Acc@5: 87.5000 (83.8000)
2024-04-07 18:14:24,222 - train - INFO - Train: 97 [   0/781 (  0%)]  Loss:  4.222725 (4.2227)  Time: 1.455s,   88.00/s  (1.455s,   88.00/s)  LR: 1.461e-04  Data: 0.193 (0.193)
2024-04-07 18:15:36,404 - train - INFO - Train: 97 [  50/781 (  6%)]  Loss:  4.024534 (3.8108)  Time: 1.442s,   88.75/s  (1.444s,   88.65/s)  LR: 1.461e-04  Data: 0.007 (0.011)
2024-04-07 18:16:48,121 - train - INFO - Train: 97 [ 100/781 ( 13%)]  Loss:  3.205838 (3.7799)  Time: 1.397s,   91.65/s  (1.439s,   88.94/s)  LR: 1.461e-04  Data: 0.007 (0.009)
2024-04-07 18:18:01,306 - train - INFO - Train: 97 [ 150/781 ( 19%)]  Loss:  4.158983 (3.8011)  Time: 1.473s,   86.92/s  (1.447s,   88.44/s)  LR: 1.461e-04  Data: 0.007 (0.009)
2024-04-07 18:19:11,816 - train - INFO - Train: 97 [ 200/781 ( 26%)]  Loss:  4.280066 (3.8050)  Time: 1.354s,   94.52/s  (1.438s,   89.01/s)  LR: 1.461e-04  Data: 0.006 (0.008)
2024-04-07 18:20:23,473 - train - INFO - Train: 97 [ 250/781 ( 32%)]  Loss:  3.781394 (3.8038)  Time: 1.382s,   92.65/s  (1.437s,   89.07/s)  LR: 1.461e-04  Data: 0.008 (0.008)
2024-04-07 18:21:35,326 - train - INFO - Train: 97 [ 300/781 ( 38%)]  Loss:  3.628454 (3.7878)  Time: 1.453s,   88.10/s  (1.437s,   89.07/s)  LR: 1.461e-04  Data: 0.005 (0.008)
2024-04-07 18:22:47,735 - train - INFO - Train: 97 [ 350/781 ( 45%)]  Loss:  3.285189 (3.7915)  Time: 1.732s,   73.91/s  (1.439s,   88.97/s)  LR: 1.461e-04  Data: 0.007 (0.008)
2024-04-07 18:23:58,434 - train - INFO - Train: 97 [ 400/781 ( 51%)]  Loss:  3.398799 (3.7907)  Time: 1.245s,  102.82/s  (1.436s,   89.16/s)  LR: 1.461e-04  Data: 0.007 (0.008)
2024-04-07 18:25:11,915 - train - INFO - Train: 97 [ 450/781 ( 58%)]  Loss:  4.233040 (3.7873)  Time: 1.366s,   93.70/s  (1.439s,   88.93/s)  LR: 1.461e-04  Data: 0.008 (0.008)
2024-04-07 18:26:24,157 - train - INFO - Train: 97 [ 500/781 ( 64%)]  Loss:  4.154891 (3.7976)  Time: 1.475s,   86.81/s  (1.440s,   88.90/s)  LR: 1.461e-04  Data: 0.008 (0.008)
2024-04-07 18:27:35,438 - train - INFO - Train: 97 [ 550/781 ( 71%)]  Loss:  4.246090 (3.8084)  Time: 1.327s,   96.46/s  (1.439s,   88.98/s)  LR: 1.461e-04  Data: 0.004 (0.008)
2024-04-07 18:28:45,946 - train - INFO - Train: 97 [ 600/781 ( 77%)]  Loss:  4.194789 (3.8121)  Time: 1.387s,   92.27/s  (1.436s,   89.12/s)  LR: 1.461e-04  Data: 0.004 (0.008)
2024-04-07 18:29:59,164 - train - INFO - Train: 97 [ 650/781 ( 83%)]  Loss:  3.599926 (3.8109)  Time: 1.406s,   91.06/s  (1.438s,   88.99/s)  LR: 1.461e-04  Data: 0.007 (0.008)
2024-04-07 18:31:10,447 - train - INFO - Train: 97 [ 700/781 ( 90%)]  Loss:  4.198241 (3.8044)  Time: 1.324s,   96.68/s  (1.437s,   89.05/s)  LR: 1.461e-04  Data: 0.008 (0.008)
2024-04-07 18:32:23,292 - train - INFO - Train: 97 [ 750/781 ( 96%)]  Loss:  4.218920 (3.8078)  Time: 1.385s,   92.42/s  (1.439s,   88.97/s)  LR: 1.461e-04  Data: 0.007 (0.008)
2024-04-07 18:33:06,408 - train - INFO - Train: 97 [ 780/781 (100%)]  Loss:  4.162473 (3.8113)  Time: 1.271s,  100.71/s  (1.439s,   88.97/s)  LR: 1.461e-04  Data: 0.000 (0.008)
2024-04-07 18:33:06,409 - train - INFO - True
2024-04-07 18:33:06,415 - train - INFO - alphas:tensor([0.0014, 0.0024, 0.0287, 0.3753, 0.5922], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,428 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,428 - train - INFO - True
2024-04-07 18:33:06,434 - train - INFO - alphas:tensor([0.1226, 0.0149, 0.0322, 0.1211, 0.7093], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,447 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,447 - train - INFO - True
2024-04-07 18:33:06,453 - train - INFO - alphas:tensor([0.5423, 0.0709, 0.0463, 0.1263, 0.2142], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,475 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,475 - train - INFO - True
2024-04-07 18:33:06,480 - train - INFO - alphas:tensor([0.4561, 0.0114, 0.0208, 0.1070, 0.4046], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,501 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,501 - train - INFO - True
2024-04-07 18:33:06,502 - train - INFO - alphas:tensor([0.2743, 0.0083, 0.0367, 0.1216, 0.5591], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,512 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,512 - train - INFO - True
2024-04-07 18:33:06,516 - train - INFO - alphas:tensor([0.3940, 0.0041, 0.0159, 0.0770, 0.5090], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,526 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,526 - train - INFO - True
2024-04-07 18:33:06,531 - train - INFO - alphas:tensor([0.5478, 0.0200, 0.0106, 0.0961, 0.3255], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,549 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,549 - train - INFO - True
2024-04-07 18:33:06,556 - train - INFO - alphas:tensor([0.4274, 0.0082, 0.0033, 0.0782, 0.4828], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,565 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,565 - train - INFO - True
2024-04-07 18:33:06,572 - train - INFO - alphas:tensor([0.3321, 0.0056, 0.0195, 0.0909, 0.5518], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,580 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,580 - train - INFO - True
2024-04-07 18:33:06,585 - train - INFO - alphas:tensor([0.4561, 0.0027, 0.0134, 0.0570, 0.4708], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,593 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,593 - train - INFO - True
2024-04-07 18:33:06,598 - train - INFO - alphas:tensor([0.4549, 0.0110, 0.0083, 0.0904, 0.4354], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,615 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,615 - train - INFO - True
2024-04-07 18:33:06,621 - train - INFO - alphas:tensor([0.3615, 0.0036, 0.0033, 0.0975, 0.5341], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,629 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,629 - train - INFO - True
2024-04-07 18:33:06,638 - train - INFO - alphas:tensor([0.3392, 0.0030, 0.0134, 0.0803, 0.5640], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,646 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,646 - train - INFO - True
2024-04-07 18:33:06,649 - train - INFO - alphas:tensor([0.4561, 0.0009, 0.0077, 0.0404, 0.4949], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,657 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,657 - train - INFO - True
2024-04-07 18:33:06,661 - train - INFO - alphas:tensor([0.3778, 0.0141, 0.0066, 0.0994, 0.5021], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,669 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,669 - train - INFO - True
2024-04-07 18:33:06,671 - train - INFO - alphas:tensor([0.2849, 0.0023, 0.0014, 0.1154, 0.5961], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,680 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,680 - train - INFO - True
2024-04-07 18:33:06,685 - train - INFO - alphas:tensor([0.3271, 0.0033, 0.0091, 0.0719, 0.5887], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,693 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,693 - train - INFO - True
2024-04-07 18:33:06,699 - train - INFO - alphas:tensor([0.4506, 0.0007, 0.0064, 0.0374, 0.5049], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,707 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,708 - train - INFO - True
2024-04-07 18:33:06,716 - train - INFO - alphas:tensor([0.3986, 0.0029, 0.0023, 0.0832, 0.5130], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,725 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,725 - train - INFO - True
2024-04-07 18:33:06,732 - train - INFO - alphas:tensor([0.2952, 0.0012, 0.0008, 0.0909, 0.6118], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,741 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,741 - train - INFO - True
2024-04-07 18:33:06,747 - train - INFO - alphas:tensor([0.2864, 0.0017, 0.0083, 0.0690, 0.6345], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,755 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,755 - train - INFO - True
2024-04-07 18:33:06,761 - train - INFO - alphas:tensor([0.4325, 0.0006, 0.0055, 0.0307, 0.5309], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,769 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,769 - train - INFO - True
2024-04-07 18:33:06,774 - train - INFO - alphas:tensor([0.4443, 0.0044, 0.0019, 0.0564, 0.4930], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,783 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,783 - train - INFO - True
2024-04-07 18:33:06,787 - train - INFO - alphas:tensor([3.3481e-01, 7.8951e-04, 3.8655e-04, 5.5451e-02, 6.0856e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,795 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,795 - train - INFO - True
2024-04-07 18:33:06,801 - train - INFO - alphas:tensor([0.2771, 0.0013, 0.0070, 0.0600, 0.6545], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,809 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,809 - train - INFO - True
2024-04-07 18:33:06,814 - train - INFO - alphas:tensor([4.1693e-01, 5.3516e-04, 4.9178e-03, 2.3734e-02, 5.5388e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,822 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,822 - train - INFO - True
2024-04-07 18:33:06,827 - train - INFO - alphas:tensor([0.4768, 0.0009, 0.0012, 0.0469, 0.4742], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,843 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,843 - train - INFO - True
2024-04-07 18:33:06,847 - train - INFO - alphas:tensor([3.6594e-01, 7.7838e-04, 2.8997e-04, 4.0523e-02, 5.9247e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,855 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,855 - train - INFO - True
2024-04-07 18:33:06,861 - train - INFO - alphas:tensor([0.2557, 0.0011, 0.0067, 0.0612, 0.6753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,870 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,870 - train - INFO - True
2024-04-07 18:33:06,873 - train - INFO - alphas:tensor([3.9206e-01, 2.4607e-04, 3.4909e-03, 2.8148e-02, 5.7606e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,881 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,881 - train - INFO - True
2024-04-07 18:33:06,889 - train - INFO - alphas:tensor([0.5002, 0.0009, 0.0010, 0.0387, 0.4592], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,905 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,905 - train - INFO - True
2024-04-07 18:33:06,909 - train - INFO - alphas:tensor([4.0374e-01, 3.1671e-04, 3.8891e-04, 4.3655e-02, 5.5189e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,917 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,917 - train - INFO - True
2024-04-07 18:33:06,923 - train - INFO - alphas:tensor([0.2329, 0.0009, 0.0058, 0.0501, 0.7102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,931 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,931 - train - INFO - True
2024-04-07 18:33:06,934 - train - INFO - alphas:tensor([3.5494e-01, 1.2979e-04, 1.9610e-03, 1.8051e-02, 6.2492e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,942 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,942 - train - INFO - True
2024-04-07 18:33:06,948 - train - INFO - alphas:tensor([0.4670, 0.0017, 0.0013, 0.0455, 0.4845], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,957 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,957 - train - INFO - True
2024-04-07 18:33:06,961 - train - INFO - alphas:tensor([4.2255e-01, 2.7178e-04, 4.1820e-04, 3.9467e-02, 5.3729e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,969 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,969 - train - INFO - True
2024-04-07 18:33:06,974 - train - INFO - alphas:tensor([0.6390, 0.0204, 0.0899, 0.2507], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:33:06,991 - train - INFO - tau:0.3848960788934847
2024-04-07 18:33:06,991 - train - INFO - avg block size:13.162162162162161
2024-04-07 18:33:06,991 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 18:33:07,601 - train - INFO - Test: [   0/78]  Time: 0.608 (0.608)  Loss:  0.9136 (0.9136)  Acc@1: 82.0312 (82.0312)  Acc@5: 92.9688 (92.9688)
2024-04-07 18:33:30,246 - train - INFO - Test: [  50/78]  Time: 0.521 (0.456)  Loss:  1.8838 (1.6273)  Acc@1: 56.2500 (62.0404)  Acc@5: 81.2500 (84.1759)
2024-04-07 18:33:44,192 - train - INFO - Test: [  78/78]  Time: 0.244 (0.471)  Loss:  1.7373 (1.6551)  Acc@1: 56.2500 (61.4200)  Acc@5: 87.5000 (83.5400)
2024-04-07 18:33:45,955 - train - INFO - Train: 98 [   0/781 (  0%)]  Loss:  3.488171 (3.4882)  Time: 1.689s,   75.77/s  (1.689s,   75.77/s)  LR: 1.415e-04  Data: 0.184 (0.184)
2024-04-07 18:34:57,715 - train - INFO - Train: 98 [  50/781 (  6%)]  Loss:  4.165768 (3.7789)  Time: 1.374s,   93.16/s  (1.440s,   88.88/s)  LR: 1.415e-04  Data: 0.008 (0.010)
2024-04-07 18:36:11,051 - train - INFO - Train: 98 [ 100/781 ( 13%)]  Loss:  3.142863 (3.7941)  Time: 1.476s,   86.73/s  (1.453s,   88.08/s)  LR: 1.415e-04  Data: 0.007 (0.009)
2024-04-07 18:37:23,638 - train - INFO - Train: 98 [ 150/781 ( 19%)]  Loss:  3.525899 (3.8034)  Time: 1.570s,   81.51/s  (1.453s,   88.11/s)  LR: 1.415e-04  Data: 0.007 (0.008)
2024-04-07 18:38:34,628 - train - INFO - Train: 98 [ 200/781 ( 26%)]  Loss:  3.431246 (3.7946)  Time: 1.432s,   89.37/s  (1.445s,   88.61/s)  LR: 1.415e-04  Data: 0.008 (0.008)
2024-04-07 18:39:46,829 - train - INFO - Train: 98 [ 250/781 ( 32%)]  Loss:  3.649087 (3.7869)  Time: 1.398s,   91.58/s  (1.444s,   88.62/s)  LR: 1.415e-04  Data: 0.008 (0.008)
2024-04-07 18:40:59,100 - train - INFO - Train: 98 [ 300/781 ( 38%)]  Loss:  4.243013 (3.7859)  Time: 1.436s,   89.14/s  (1.445s,   88.61/s)  LR: 1.415e-04  Data: 0.007 (0.008)
2024-04-07 18:42:10,708 - train - INFO - Train: 98 [ 350/781 ( 45%)]  Loss:  3.702554 (3.7881)  Time: 1.416s,   90.41/s  (1.443s,   88.71/s)  LR: 1.415e-04  Data: 0.007 (0.008)
2024-04-07 18:43:22,492 - train - INFO - Train: 98 [ 400/781 ( 51%)]  Loss:  3.318553 (3.7986)  Time: 1.374s,   93.15/s  (1.442s,   88.77/s)  LR: 1.415e-04  Data: 0.007 (0.008)
2024-04-07 18:44:34,815 - train - INFO - Train: 98 [ 450/781 ( 58%)]  Loss:  4.044034 (3.8075)  Time: 1.399s,   91.49/s  (1.442s,   88.74/s)  LR: 1.415e-04  Data: 0.007 (0.008)
2024-04-07 18:45:45,321 - train - INFO - Train: 98 [ 500/781 ( 64%)]  Loss:  4.216571 (3.8039)  Time: 1.347s,   95.06/s  (1.439s,   88.94/s)  LR: 1.415e-04  Data: 0.007 (0.008)
2024-04-07 18:46:56,702 - train - INFO - Train: 98 [ 550/781 ( 71%)]  Loss:  3.885589 (3.8041)  Time: 1.401s,   91.39/s  (1.438s,   89.00/s)  LR: 1.415e-04  Data: 0.008 (0.008)
2024-04-07 18:48:06,930 - train - INFO - Train: 98 [ 600/781 ( 77%)]  Loss:  4.391596 (3.8004)  Time: 1.469s,   87.13/s  (1.435s,   89.18/s)  LR: 1.415e-04  Data: 0.006 (0.008)
2024-04-07 18:49:20,046 - train - INFO - Train: 98 [ 650/781 ( 83%)]  Loss:  4.265633 (3.8047)  Time: 1.443s,   88.69/s  (1.437s,   89.05/s)  LR: 1.415e-04  Data: 0.007 (0.008)
2024-04-07 18:50:34,066 - train - INFO - Train: 98 [ 700/781 ( 90%)]  Loss:  4.213771 (3.8080)  Time: 1.630s,   78.51/s  (1.440s,   88.86/s)  LR: 1.415e-04  Data: 0.008 (0.008)
2024-04-07 18:51:47,176 - train - INFO - Train: 98 [ 750/781 ( 96%)]  Loss:  3.568929 (3.8037)  Time: 1.398s,   91.55/s  (1.442s,   88.77/s)  LR: 1.415e-04  Data: 0.007 (0.008)
2024-04-07 18:52:30,588 - train - INFO - Train: 98 [ 780/781 (100%)]  Loss:  3.166085 (3.8000)  Time: 1.656s,   77.30/s  (1.442s,   88.76/s)  LR: 1.415e-04  Data: 0.000 (0.008)
2024-04-07 18:52:30,589 - train - INFO - True
2024-04-07 18:52:30,591 - train - INFO - alphas:tensor([0.0013, 0.0023, 0.0283, 0.3779, 0.5902], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,611 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,611 - train - INFO - True
2024-04-07 18:52:30,614 - train - INFO - alphas:tensor([0.1236, 0.0146, 0.0320, 0.1213, 0.7084], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,631 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,631 - train - INFO - True
2024-04-07 18:52:30,636 - train - INFO - alphas:tensor([0.5451, 0.0698, 0.0455, 0.1255, 0.2141], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,666 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,666 - train - INFO - True
2024-04-07 18:52:30,672 - train - INFO - alphas:tensor([0.4566, 0.0111, 0.0203, 0.1062, 0.4058], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,700 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,700 - train - INFO - True
2024-04-07 18:52:30,708 - train - INFO - alphas:tensor([0.2761, 0.0080, 0.0360, 0.1202, 0.5598], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,722 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,722 - train - INFO - True
2024-04-07 18:52:30,726 - train - INFO - alphas:tensor([0.3941, 0.0039, 0.0154, 0.0757, 0.5108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,740 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,740 - train - INFO - True
2024-04-07 18:52:30,745 - train - INFO - alphas:tensor([0.5497, 0.0196, 0.0102, 0.0947, 0.3258], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,773 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,773 - train - INFO - True
2024-04-07 18:52:30,778 - train - INFO - alphas:tensor([0.4300, 0.0080, 0.0031, 0.0770, 0.4819], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,792 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,792 - train - INFO - True
2024-04-07 18:52:30,793 - train - INFO - alphas:tensor([0.3337, 0.0054, 0.0189, 0.0895, 0.5525], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,807 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,807 - train - INFO - True
2024-04-07 18:52:30,810 - train - INFO - alphas:tensor([0.4593, 0.0026, 0.0129, 0.0556, 0.4698], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,825 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,825 - train - INFO - True
2024-04-07 18:52:30,830 - train - INFO - alphas:tensor([0.4581, 0.0106, 0.0080, 0.0887, 0.4346], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,858 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,858 - train - INFO - True
2024-04-07 18:52:30,872 - train - INFO - alphas:tensor([0.3655, 0.0034, 0.0031, 0.0961, 0.5319], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,886 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,886 - train - INFO - True
2024-04-07 18:52:30,900 - train - INFO - alphas:tensor([0.3404, 0.0029, 0.0130, 0.0789, 0.5648], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,915 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,915 - train - INFO - True
2024-04-07 18:52:30,927 - train - INFO - alphas:tensor([0.4598, 0.0008, 0.0074, 0.0393, 0.4927], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,941 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,941 - train - INFO - True
2024-04-07 18:52:30,956 - train - INFO - alphas:tensor([0.3818, 0.0137, 0.0063, 0.0979, 0.5003], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,970 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,970 - train - INFO - True
2024-04-07 18:52:30,984 - train - INFO - alphas:tensor([0.2867, 0.0022, 0.0013, 0.1144, 0.5954], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:30,999 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:30,999 - train - INFO - True
2024-04-07 18:52:31,013 - train - INFO - alphas:tensor([0.3280, 0.0032, 0.0088, 0.0708, 0.5892], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,027 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,027 - train - INFO - True
2024-04-07 18:52:31,042 - train - INFO - alphas:tensor([0.4514, 0.0007, 0.0061, 0.0365, 0.5053], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,056 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,056 - train - INFO - True
2024-04-07 18:52:31,071 - train - INFO - alphas:tensor([0.3994, 0.0028, 0.0022, 0.0820, 0.5136], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,085 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,085 - train - INFO - True
2024-04-07 18:52:31,099 - train - INFO - alphas:tensor([0.2975, 0.0012, 0.0008, 0.0902, 0.6103], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,114 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,114 - train - INFO - True
2024-04-07 18:52:31,115 - train - INFO - alphas:tensor([0.2847, 0.0016, 0.0080, 0.0682, 0.6375], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,130 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,130 - train - INFO - True
2024-04-07 18:52:31,131 - train - INFO - alphas:tensor([4.3171e-01, 5.1375e-04, 5.2612e-03, 3.0050e-02, 5.3247e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,145 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,145 - train - INFO - True
2024-04-07 18:52:31,147 - train - INFO - alphas:tensor([0.4468, 0.0042, 0.0018, 0.0554, 0.4918], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,161 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,161 - train - INFO - True
2024-04-07 18:52:31,162 - train - INFO - alphas:tensor([3.3762e-01, 7.3708e-04, 3.5578e-04, 5.4440e-02, 6.0685e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,176 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,177 - train - INFO - True
2024-04-07 18:52:31,179 - train - INFO - alphas:tensor([0.2777, 0.0013, 0.0068, 0.0592, 0.6551], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,194 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,194 - train - INFO - True
2024-04-07 18:52:31,197 - train - INFO - alphas:tensor([4.1950e-01, 4.9481e-04, 4.7107e-03, 2.3096e-02, 5.5220e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,212 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,212 - train - INFO - True
2024-04-07 18:52:31,217 - train - INFO - alphas:tensor([0.4783, 0.0009, 0.0012, 0.0460, 0.4737], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,245 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,245 - train - INFO - True
2024-04-07 18:52:31,249 - train - INFO - alphas:tensor([3.6590e-01, 7.2783e-04, 2.6600e-04, 3.9482e-02, 5.9363e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,264 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,264 - train - INFO - True
2024-04-07 18:52:31,269 - train - INFO - alphas:tensor([0.2572, 0.0011, 0.0064, 0.0600, 0.6753], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,283 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,284 - train - INFO - True
2024-04-07 18:52:31,286 - train - INFO - alphas:tensor([3.9427e-01, 2.2511e-04, 3.3134e-03, 2.7479e-02, 5.7472e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,300 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,300 - train - INFO - True
2024-04-07 18:52:31,305 - train - INFO - alphas:tensor([0.5039, 0.0008, 0.0009, 0.0377, 0.4566], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,329 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,329 - train - INFO - True
2024-04-07 18:52:31,332 - train - INFO - alphas:tensor([4.0561e-01, 2.9321e-04, 3.5699e-04, 4.2609e-02, 5.5113e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,344 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,344 - train - INFO - True
2024-04-07 18:52:31,357 - train - INFO - alphas:tensor([0.2333, 0.0009, 0.0056, 0.0494, 0.7108], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,368 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,368 - train - INFO - True
2024-04-07 18:52:31,369 - train - INFO - alphas:tensor([3.6032e-01, 1.2022e-04, 1.8504e-03, 1.7508e-02, 6.2020e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,379 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,379 - train - INFO - True
2024-04-07 18:52:31,393 - train - INFO - alphas:tensor([0.4707, 0.0016, 0.0012, 0.0444, 0.4821], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,402 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,402 - train - INFO - True
2024-04-07 18:52:31,411 - train - INFO - alphas:tensor([4.2760e-01, 2.5008e-04, 3.8422e-04, 3.8406e-02, 5.3335e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,420 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,420 - train - INFO - True
2024-04-07 18:52:31,433 - train - INFO - alphas:tensor([0.6401, 0.0199, 0.0892, 0.2508], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 18:52:31,454 - train - INFO - tau:0.38104711810454983
2024-04-07 18:52:31,454 - train - INFO - avg block size:13.162162162162161
2024-04-07 18:52:31,454 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 18:52:31,455 - train - INFO - lasso_alpha:5.0544702849929444e-05
2024-04-07 18:52:32,000 - train - INFO - Test: [   0/78]  Time: 0.542 (0.542)  Loss:  0.8911 (0.8911)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)
2024-04-07 18:52:57,458 - train - INFO - Test: [  50/78]  Time: 0.575 (0.510)  Loss:  1.7715 (1.6108)  Acc@1: 59.3750 (62.0711)  Acc@5: 83.5938 (84.2984)
2024-04-07 18:53:11,459 - train - INFO - Test: [  78/78]  Time: 0.379 (0.506)  Loss:  1.8965 (1.6462)  Acc@1: 50.0000 (61.5400)  Acc@5: 81.2500 (83.5600)
2024-04-07 18:53:13,148 - train - INFO - Train: 99 [   0/781 (  0%)]  Loss:  3.463513 (3.4635)  Time: 1.620s,   79.00/s  (1.620s,   79.00/s)  LR: 1.370e-04  Data: 0.190 (0.190)
2024-04-07 18:54:24,425 - train - INFO - Train: 99 [  50/781 (  6%)]  Loss:  3.161521 (3.8470)  Time: 1.376s,   93.01/s  (1.429s,   89.55/s)  LR: 1.370e-04  Data: 0.006 (0.011)
2024-04-07 18:55:37,038 - train - INFO - Train: 99 [ 100/781 ( 13%)]  Loss:  3.073784 (3.8711)  Time: 1.391s,   92.01/s  (1.441s,   88.85/s)  LR: 1.370e-04  Data: 0.007 (0.009)
2024-04-07 18:56:47,483 - train - INFO - Train: 99 [ 150/781 ( 19%)]  Loss:  4.270831 (3.8236)  Time: 1.521s,   84.15/s  (1.430s,   89.50/s)  LR: 1.370e-04  Data: 0.007 (0.008)
2024-04-07 18:57:59,894 - train - INFO - Train: 99 [ 200/781 ( 26%)]  Loss:  3.174489 (3.7991)  Time: 1.569s,   81.57/s  (1.435s,   89.22/s)  LR: 1.370e-04  Data: 0.008 (0.008)
2024-04-07 18:59:12,292 - train - INFO - Train: 99 [ 250/781 ( 32%)]  Loss:  3.163651 (3.8005)  Time: 1.366s,   93.67/s  (1.437s,   89.06/s)  LR: 1.370e-04  Data: 0.007 (0.008)
2024-04-07 19:00:23,078 - train - INFO - Train: 99 [ 300/781 ( 38%)]  Loss:  3.492176 (3.8217)  Time: 1.331s,   96.17/s  (1.434s,   89.28/s)  LR: 1.370e-04  Data: 0.004 (0.008)
2024-04-07 19:01:33,803 - train - INFO - Train: 99 [ 350/781 ( 45%)]  Loss:  4.086408 (3.8186)  Time: 1.393s,   91.86/s  (1.431s,   89.45/s)  LR: 1.370e-04  Data: 0.007 (0.008)
2024-04-07 19:02:46,780 - train - INFO - Train: 99 [ 400/781 ( 51%)]  Loss:  4.206847 (3.8254)  Time: 1.376s,   93.02/s  (1.435s,   89.23/s)  LR: 1.370e-04  Data: 0.007 (0.008)
2024-04-07 19:03:58,830 - train - INFO - Train: 99 [ 450/781 ( 58%)]  Loss:  4.156940 (3.8282)  Time: 1.522s,   84.08/s  (1.435s,   89.18/s)  LR: 1.370e-04  Data: 0.007 (0.008)
2024-04-07 19:05:11,871 - train - INFO - Train: 99 [ 500/781 ( 64%)]  Loss:  4.267531 (3.8298)  Time: 1.350s,   94.80/s  (1.438s,   89.03/s)  LR: 1.370e-04  Data: 0.006 (0.008)
2024-04-07 19:06:22,690 - train - INFO - Train: 99 [ 550/781 ( 71%)]  Loss:  4.148020 (3.8299)  Time: 1.376s,   93.05/s  (1.436s,   89.15/s)  LR: 1.370e-04  Data: 0.006 (0.008)
2024-04-07 19:07:35,905 - train - INFO - Train: 99 [ 600/781 ( 77%)]  Loss:  3.970901 (3.8261)  Time: 1.442s,   88.77/s  (1.438s,   89.00/s)  LR: 1.370e-04  Data: 0.008 (0.007)
2024-04-07 19:08:48,239 - train - INFO - Train: 99 [ 650/781 ( 83%)]  Loss:  3.526562 (3.8180)  Time: 1.413s,   90.58/s  (1.439s,   88.96/s)  LR: 1.370e-04  Data: 0.006 (0.007)
2024-04-07 19:10:00,163 - train - INFO - Train: 99 [ 700/781 ( 90%)]  Loss:  3.910789 (3.8129)  Time: 1.413s,   90.60/s  (1.439s,   88.96/s)  LR: 1.370e-04  Data: 0.008 (0.007)
2024-04-07 19:11:10,817 - train - INFO - Train: 99 [ 750/781 ( 96%)]  Loss:  4.388318 (3.8142)  Time: 1.472s,   86.98/s  (1.437s,   89.07/s)  LR: 1.370e-04  Data: 0.006 (0.007)
2024-04-07 19:11:53,493 - train - INFO - Train: 99 [ 780/781 (100%)]  Loss:  4.215576 (3.8134)  Time: 1.333s,   96.05/s  (1.437s,   89.10/s)  LR: 1.370e-04  Data: 0.000 (0.007)
2024-04-07 19:11:53,494 - train - INFO - True
2024-04-07 19:11:53,500 - train - INFO - alphas:tensor([0.0012, 0.0022, 0.0276, 0.3789, 0.5901], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,522 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,522 - train - INFO - True
2024-04-07 19:11:53,528 - train - INFO - alphas:tensor([0.1238, 0.0143, 0.0314, 0.1198, 0.7107], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,547 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,547 - train - INFO - True
2024-04-07 19:11:53,552 - train - INFO - alphas:tensor([0.5480, 0.0693, 0.0446, 0.1246, 0.2135], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,583 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,583 - train - INFO - True
2024-04-07 19:11:53,585 - train - INFO - alphas:tensor([0.4586, 0.0108, 0.0197, 0.1047, 0.4062], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,612 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,612 - train - INFO - True
2024-04-07 19:11:53,624 - train - INFO - alphas:tensor([0.2764, 0.0078, 0.0356, 0.1191, 0.5612], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,636 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,637 - train - INFO - True
2024-04-07 19:11:53,649 - train - INFO - alphas:tensor([0.3954, 0.0037, 0.0148, 0.0744, 0.5117], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,660 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,660 - train - INFO - True
2024-04-07 19:11:53,673 - train - INFO - alphas:tensor([0.5517, 0.0189, 0.0099, 0.0936, 0.3260], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,693 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,693 - train - INFO - True
2024-04-07 19:11:53,706 - train - INFO - alphas:tensor([0.4301, 0.0077, 0.0030, 0.0760, 0.4833], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,716 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,716 - train - INFO - True
2024-04-07 19:11:53,728 - train - INFO - alphas:tensor([0.3344, 0.0052, 0.0184, 0.0885, 0.5535], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,739 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,739 - train - INFO - True
2024-04-07 19:11:53,753 - train - INFO - alphas:tensor([0.4613, 0.0024, 0.0125, 0.0546, 0.4693], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,763 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,763 - train - INFO - True
2024-04-07 19:11:53,775 - train - INFO - alphas:tensor([0.4581, 0.0102, 0.0077, 0.0880, 0.4359], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,793 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,793 - train - INFO - True
2024-04-07 19:11:53,806 - train - INFO - alphas:tensor([0.3670, 0.0033, 0.0029, 0.0950, 0.5318], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,815 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,815 - train - INFO - True
2024-04-07 19:11:53,829 - train - INFO - alphas:tensor([0.3417, 0.0028, 0.0126, 0.0777, 0.5652], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,837 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,837 - train - INFO - True
2024-04-07 19:11:53,851 - train - INFO - alphas:tensor([0.4610, 0.0008, 0.0071, 0.0385, 0.4925], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,862 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,862 - train - INFO - True
2024-04-07 19:11:53,863 - train - INFO - alphas:tensor([0.3836, 0.0133, 0.0060, 0.0964, 0.5006], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,874 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,874 - train - INFO - True
2024-04-07 19:11:53,875 - train - INFO - alphas:tensor([0.2868, 0.0021, 0.0012, 0.1144, 0.5955], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,885 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,885 - train - INFO - True
2024-04-07 19:11:53,886 - train - INFO - alphas:tensor([0.3287, 0.0030, 0.0084, 0.0698, 0.5900], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,895 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,895 - train - INFO - True
2024-04-07 19:11:53,896 - train - INFO - alphas:tensor([0.4523, 0.0006, 0.0059, 0.0357, 0.5056], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,905 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,905 - train - INFO - True
2024-04-07 19:11:53,909 - train - INFO - alphas:tensor([0.4013, 0.0026, 0.0021, 0.0807, 0.5133], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,918 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,918 - train - INFO - True
2024-04-07 19:11:53,923 - train - INFO - alphas:tensor([0.2990, 0.0011, 0.0007, 0.0889, 0.6102], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,932 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,932 - train - INFO - True
2024-04-07 19:11:53,937 - train - INFO - alphas:tensor([0.2863, 0.0015, 0.0078, 0.0670, 0.6374], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,945 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,945 - train - INFO - True
2024-04-07 19:11:53,949 - train - INFO - alphas:tensor([4.3387e-01, 4.7888e-04, 5.0254e-03, 2.9110e-02, 5.3151e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,958 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,958 - train - INFO - True
2024-04-07 19:11:53,961 - train - INFO - alphas:tensor([0.4487, 0.0040, 0.0017, 0.0541, 0.4915], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,969 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,969 - train - INFO - True
2024-04-07 19:11:53,973 - train - INFO - alphas:tensor([3.4000e-01, 6.9790e-04, 3.2892e-04, 5.3557e-02, 6.0542e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,982 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,982 - train - INFO - True
2024-04-07 19:11:53,986 - train - INFO - alphas:tensor([0.2787, 0.0012, 0.0065, 0.0579, 0.6556], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:53,996 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:53,996 - train - INFO - True
2024-04-07 19:11:53,998 - train - INFO - alphas:tensor([4.2039e-01, 4.6252e-04, 4.5434e-03, 2.2748e-02, 5.5186e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:54,008 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:54,009 - train - INFO - True
2024-04-07 19:11:54,013 - train - INFO - alphas:tensor([0.4780, 0.0008, 0.0011, 0.0452, 0.4749], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:54,033 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:54,033 - train - INFO - True
2024-04-07 19:11:54,038 - train - INFO - alphas:tensor([3.6792e-01, 6.8072e-04, 2.4524e-04, 3.8819e-02, 5.9234e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:54,047 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:54,047 - train - INFO - True
2024-04-07 19:11:54,054 - train - INFO - alphas:tensor([0.2577, 0.0010, 0.0062, 0.0589, 0.6762], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:54,063 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:54,063 - train - INFO - True
2024-04-07 19:11:54,066 - train - INFO - alphas:tensor([3.9389e-01, 2.0736e-04, 3.1658e-03, 2.6619e-02, 5.7612e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:54,075 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:54,075 - train - INFO - True
2024-04-07 19:11:54,078 - train - INFO - alphas:tensor([0.5061, 0.0008, 0.0009, 0.0367, 0.4555], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:54,094 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:54,094 - train - INFO - True
2024-04-07 19:11:54,104 - train - INFO - alphas:tensor([4.0669e-01, 2.7073e-04, 3.2945e-04, 4.1636e-02, 5.5107e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:54,112 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:54,112 - train - INFO - True
2024-04-07 19:11:54,115 - train - INFO - alphas:tensor([0.2342, 0.0008, 0.0054, 0.0482, 0.7114], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:54,124 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:54,124 - train - INFO - True
2024-04-07 19:11:54,132 - train - INFO - alphas:tensor([3.5761e-01, 1.1058e-04, 1.7472e-03, 1.6856e-02, 6.2368e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:54,143 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:54,143 - train - INFO - True
2024-04-07 19:11:54,157 - train - INFO - alphas:tensor([0.4702, 0.0015, 0.0012, 0.0434, 0.4838], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:54,167 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:54,167 - train - INFO - True
2024-04-07 19:11:54,175 - train - INFO - alphas:tensor([4.2765e-01, 2.2970e-04, 3.5103e-04, 3.7680e-02, 5.3409e-01],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:54,184 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:54,184 - train - INFO - True
2024-04-07 19:11:54,197 - train - INFO - alphas:tensor([0.6415, 0.0195, 0.0885, 0.2505], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
2024-04-07 19:11:54,215 - train - INFO - tau:0.37723664692350434
2024-04-07 19:11:54,215 - train - INFO - avg block size:13.162162162162161
2024-04-07 19:11:54,215 - train - INFO - current latency ratio:tensor(0.2538)
2024-04-07 19:11:54,783 - train - INFO - Test: [   0/78]  Time: 0.564 (0.564)  Loss:  0.9282 (0.9282)  Acc@1: 83.5938 (83.5938)  Acc@5: 93.7500 (93.7500)
2024-04-07 19:12:19,729 - train - INFO - Test: [  50/78]  Time: 0.575 (0.500)  Loss:  1.7871 (1.6290)  Acc@1: 60.9375 (61.7341)  Acc@5: 82.0312 (84.0686)
2024-04-07 19:12:34,069 - train - INFO - Test: [  78/78]  Time: 0.433 (0.504)  Loss:  1.6592 (1.6551)  Acc@1: 56.2500 (61.4500)  Acc@5: 87.5000 (83.5700)
2024-04-07 19:12:35,890 - train - INFO - Train: 100 [   0/781 (  0%)]  Loss:  3.702785 (3.7028)  Time: 1.751s,   73.11/s  (1.751s,   73.11/s)  LR: 1.325e-04  Data: 0.190 (0.190)
2024-04-07 19:13:46,986 - train - INFO - Train: 100 [  50/781 (  6%)]  Loss:  4.358596 (3.8209)  Time: 1.416s,   90.38/s  (1.428s,   89.61/s)  LR: 1.325e-04  Data: 0.007 (0.010)
2024-04-07 19:14:57,794 - train - INFO - Train: 100 [ 100/781 ( 13%)]  Loss:  3.228271 (3.7425)  Time: 1.364s,   93.82/s  (1.422s,   90.00/s)  LR: 1.325e-04  Data: 0.007 (0.009)
2024-04-07 19:16:09,249 - train - INFO - Train: 100 [ 150/781 ( 19%)]  Loss:  3.798031 (3.7347)  Time: 1.476s,   86.69/s  (1.425s,   89.85/s)  LR: 1.325e-04  Data: 0.007 (0.008)
2024-04-07 19:17:21,590 - train - INFO - Train: 100 [ 200/781 ( 26%)]  Loss:  4.003211 (3.7700)  Time: 1.432s,   89.37/s  (1.430s,   89.51/s)  LR: 1.325e-04  Data: 0.005 (0.008)
2024-04-07 19:18:33,317 - train - INFO - Train: 100 [ 250/781 ( 32%)]  Loss:  4.165245 (3.7648)  Time: 1.386s,   92.36/s  (1.431s,   89.45/s)  LR: 1.325e-04  Data: 0.008 (0.008)
2024-04-07 19:19:44,481 - train - INFO - Train: 100 [ 300/781 ( 38%)]  Loss:  4.316006 (3.7845)  Time: 1.352s,   94.70/s  (1.430s,   89.53/s)  LR: 1.325e-04  Data: 0.008 (0.008)
2024-04-07 19:20:54,696 - train - INFO - Train: 100 [ 350/781 ( 45%)]  Loss:  3.157418 (3.7830)  Time: 1.581s,   80.95/s  (1.426s,   89.76/s)  LR: 1.325e-04  Data: 0.007 (0.008)
2024-04-07 19:22:05,725 - train - INFO - Train: 100 [ 400/781 ( 51%)]  Loss:  4.158974 (3.7915)  Time: 1.440s,   88.86/s  (1.425s,   89.80/s)  LR: 1.325e-04  Data: 0.007 (0.008)
2024-04-07 19:23:16,700 - train - INFO - Train: 100 [ 450/781 ( 58%)]  Loss:  4.031271 (3.8113)  Time: 1.482s,   86.35/s  (1.425s,   89.84/s)  LR: 1.325e-04  Data: 0.009 (0.008)
2024-04-07 19:24:29,190 - train - INFO - Train: 100 [ 500/781 ( 64%)]  Loss:  3.369338 (3.8117)  Time: 1.284s,   99.67/s  (1.427s,   89.68/s)  LR: 1.325e-04  Data: 0.008 (0.008)
2024-04-07 19:25:40,025 - train - INFO - Train: 100 [ 550/781 ( 71%)]  Loss:  4.260043 (3.8062)  Time: 1.437s,   89.07/s  (1.426s,   89.75/s)  LR: 1.325e-04  Data: 0.007 (0.008)
2024-04-07 19:26:52,023 - train - INFO - Train: 100 [ 600/781 ( 77%)]  Loss:  3.948454 (3.8039)  Time: 1.462s,   87.54/s  (1.427s,   89.67/s)  LR: 1.325e-04  Data: 0.008 (0.007)
